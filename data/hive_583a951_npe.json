[
    {
        "repo": "hive",
        "commit": "https://github.com/apache/hive/commit/583a9511ba8809d81595a5fa4da32ed2c2f8912e",
        "bug_id": "hive_583a951",
        "message": "HIVE-17535 Select 1 EXCEPT Select 1 fails with NPE (Vineet Garg,reviewed by Ashutosh Chauhan)",
        "parent": "https://github.com/apache/hive/commit/c5b3ccc41016afd94035637cb011eacbeb9e5893",
        "patched_files": [
            "mapjoin2.q.out",
            "udtf_stack.q.out",
            "explainuser_1.q.out",
            "subquery_select_no_source.q.out",
            "timestamptz_1.q.out",
            "subquery_missing_from.q",
            "subquery_missing_from.q.out",
            "decimal_precision2.q.out",
            "vector_tablesample_rows.q.out",
            "subquery_select_no_source.q",
            "testconfiguration.properties",
            "select_dummy_source.q.out",
            "SemanticAnalyzer.java"
        ],
        "file": [
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/itests/src/test/resources/testconfiguration.properties",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/itests/src/test/resources/testconfiguration.properties?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "itests/src/test/resources/testconfiguration.properties",
                "deletions": 0,
                "sha": "efa690db10836b0c21723bfe51adb22f4ab53bac",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/itests/src/test/resources/testconfiguration.properties",
                "patch": "@@ -30,6 +30,7 @@ disabled.query.files=ql_rewrite_gbtoidx.q,\\\n   cbo_rp_subq_not_in.q,\\\n   cbo_rp_subq_exists.q,\\\n   orc_llap.q,\\\n+  min_structvalue.q,\\\n   ql_rewrite_gbtoidx_cbo_2.q,\\\n   rcfile_merge1.q,\\\n   smb_mapjoin_8.q,\\",
                "changes": 1
            },
            {
                "status": "modified",
                "additions": 6,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java",
                "deletions": 13,
                "sha": "28953b9d030f33d1c26789453b97335f4e848a5b",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java",
                "patch": "@@ -709,7 +709,7 @@ boolean canCBOHandleAst(ASTNode ast, QB qb, PreCboCtx cboCtx) {\n     boolean isSupportedRoot = root == HiveParser.TOK_QUERY || root == HiveParser.TOK_EXPLAIN\n         || qb.isCTAS() || qb.isMaterializedView();\n     // Queries without a source table currently are not supported by CBO\n-    boolean isSupportedType = (qb.getIsQuery() && !qb.containsQueryWithoutSourceTable())\n+    boolean isSupportedType = (qb.getIsQuery())\n         || qb.isCTAS() || qb.isMaterializedView() || cboCtx.type == PreCboCtx.Type.INSERT\n         || cboCtx.type == PreCboCtx.Type.MULTI_INSERT;\n     boolean noBadTokens = HiveCalciteUtil.validateASTForUnsupportedTokens(ast);\n@@ -4164,18 +4164,11 @@ private RelNode genLogicalPlan(QB qb, boolean outerMostQB,\n \n       if (aliasToRel.isEmpty()) {\n         // // This may happen for queries like select 1; (no source table)\n-        // We can do following which is same, as what Hive does.\n-        // With this, we will be able to generate Calcite plan.\n-        // qb.getMetaData().setSrcForAlias(DUMMY_TABLE, getDummyTable());\n-        // RelNode op = genTableLogicalPlan(DUMMY_TABLE, qb);\n-        // qb.addAlias(DUMMY_TABLE);\n-        // qb.setTabAlias(DUMMY_TABLE, DUMMY_TABLE);\n-        // aliasToRel.put(DUMMY_TABLE, op);\n-        // However, Hive trips later while trying to get Metadata for this dummy\n-        // table\n-        // So, for now lets just disable this. Anyway there is nothing much to\n-        // optimize in such cases.\n-        throw new CalciteSemanticException(\"Unsupported\", UnsupportedFeature.Others);\n+        qb.getMetaData().setSrcForAlias(DUMMY_TABLE, getDummyTable());\n+        qb.addAlias(DUMMY_TABLE);\n+        qb.setTabAlias(DUMMY_TABLE, DUMMY_TABLE);\n+        RelNode op = genTableLogicalPlan(DUMMY_TABLE, qb);\n+        aliasToRel.put(DUMMY_TABLE, op);\n \n       }\n ",
                "changes": 19
            },
            {
                "status": "modified",
                "additions": 7,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java",
                "deletions": 1,
                "sha": "d56fd21c63cdce35613c02b115d3f2c4dcaca08e",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java",
                "patch": "@@ -2019,6 +2019,9 @@ private void getMetaData(QB qb, ReadEntity parentInput)\n       }\n \n       if (tab == null) {\n+        if(tabName.equals(DUMMY_DATABASE + \".\" + DUMMY_TABLE)) {\n+          continue;\n+        }\n         ASTNode src = qb.getParseInfo().getSrcForAlias(alias);\n         if (null != src) {\n           throw new SemanticException(ErrorMsg.INVALID_TABLE.getMsg(src));\n@@ -10611,6 +10614,9 @@ public Operator genPlan(QB qb, boolean skipAmbiguityCheck)\n \n     // Recurse over all the source tables\n     for (String alias : qb.getTabAliases()) {\n+      if(alias.equals(DUMMY_TABLE)) {\n+        continue;\n+      }\n       Operator op = genTablePlan(alias, qb);\n       aliasToOpInfo.put(alias, op);\n     }\n@@ -10738,7 +10744,7 @@ private void rewriteRRForSubQ(String alias, Operator operator, boolean skipAmbig\n     opParseCtx.get(operator).setRowResolver(newRR);\n   }\n \n-  private Table getDummyTable() throws SemanticException {\n+  protected Table getDummyTable() throws SemanticException {\n     Path dummyPath = createDummyFile();\n     Table desc = new Table(DUMMY_DATABASE, DUMMY_TABLE);\n     desc.getTTable().getSd().setLocation(dummyPath.toString());",
                "changes": 8
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/hive/raw/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/queries/clientnegative/subquery_missing_from.q",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/queries/clientnegative/subquery_missing_from.q?ref=c5b3ccc41016afd94035637cb011eacbeb9e5893",
                "filename": "ql/src/test/queries/clientnegative/subquery_missing_from.q",
                "deletions": 1,
                "sha": "3b49ac6a0a8f00dbc26a4071042d6e05574f0767",
                "blob_url": "https://github.com/apache/hive/blob/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/queries/clientnegative/subquery_missing_from.q",
                "patch": "@@ -1 +0,0 @@\n-select * from src where src.key in (select key);\n\\ No newline at end of file",
                "changes": 1
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/hive/raw/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/queries/clientnegative/subquery_select_no_source.q",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/queries/clientnegative/subquery_select_no_source.q?ref=c5b3ccc41016afd94035637cb011eacbeb9e5893",
                "filename": "ql/src/test/queries/clientnegative/subquery_select_no_source.q",
                "deletions": 2,
                "sha": "75cae51e6af638c5bca38c983bf7dc7161c30fee",
                "blob_url": "https://github.com/apache/hive/blob/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/queries/clientnegative/subquery_select_no_source.q",
                "patch": "@@ -1,2 +0,0 @@\n--- since CBO doesn't allow such queries we can not support subqueries here\n-explain select (select max(p_size) from part);",
                "changes": 2
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/hive/raw/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/results/clientnegative/subquery_missing_from.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientnegative/subquery_missing_from.q.out?ref=c5b3ccc41016afd94035637cb011eacbeb9e5893",
                "filename": "ql/src/test/results/clientnegative/subquery_missing_from.q.out",
                "deletions": 3,
                "sha": "b09a8e311f5e7b2ef0c35b28ade81dfb4033fed3",
                "blob_url": "https://github.com/apache/hive/blob/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/results/clientnegative/subquery_missing_from.q.out",
                "patch": "@@ -1,3 +0,0 @@\n-FAILED: SemanticException Line 0:-1 Invalid SubQuery expression 'key' in definition of SubQuery sq_1 [\n-src.key in (select key)\n-] used as sq_1 at Line 0:-1: From clause is missing in SubQuery.",
                "changes": 3
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/hive/raw/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/results/clientnegative/subquery_select_no_source.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientnegative/subquery_select_no_source.q.out?ref=c5b3ccc41016afd94035637cb011eacbeb9e5893",
                "filename": "ql/src/test/results/clientnegative/subquery_select_no_source.q.out",
                "deletions": 1,
                "sha": "37c4e57813a61d4f6832df610265962fffc92240",
                "blob_url": "https://github.com/apache/hive/blob/c5b3ccc41016afd94035637cb011eacbeb9e5893/ql/src/test/results/clientnegative/subquery_select_no_source.q.out",
                "patch": "@@ -1 +0,0 @@\n-FAILED: CalciteSubquerySemanticException [Error 10249]: Unsupported SubQuery Expression  Currently SubQuery expressions are only allowed as Where and Having Clause predicates",
                "changes": 1
            },
            {
                "status": "modified",
                "additions": 4,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/beeline/mapjoin2.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/beeline/mapjoin2.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/beeline/mapjoin2.q.out",
                "deletions": 0,
                "sha": "7e7084160df06263534e64b490dcb20d810a26ec",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/beeline/mapjoin2.q.out",
                "patch": "@@ -53,6 +53,7 @@ POSTHOOK: Input: default@tbl\n #### A masked pattern was here ####\n false\tfalse\ttrue\ttrue\n true\ttrue\tfalse\tfalse\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -62,6 +63,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a left outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -71,6 +73,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a right outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -80,6 +83,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Shuffle Join JOIN[6][tables = [$hdt$_0, $hdt$_1]] in Stage 'Stage-1:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a full outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table",
                "changes": 4
            },
            {
                "status": "modified",
                "additions": 15,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/beeline/select_dummy_source.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/beeline/select_dummy_source.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/beeline/select_dummy_source.q.out",
                "deletions": 7,
                "sha": "0b73e84e9aea6855e91fd547bfb7a973b55d6613",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/beeline/select_dummy_source.q.out",
                "patch": "@@ -89,13 +89,17 @@ STAGE PLANS:\n               UDTF Operator\n                 Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n                 function name: explode\n-                File Output Operator\n-                  compressed: false\n+                Select Operator\n+                  expressions: col (type: string)\n+                  outputColumnNames: _col0\n                   Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n-                  table:\n-                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n-                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n+                  File Output Operator\n+                    compressed: false\n+                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n+                    table:\n+                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n+                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n \n   Stage: Stage-0\n     Fetch Operator\n@@ -204,7 +208,11 @@ STAGE PLANS:\n             UDTF Operator\n               Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n               function name: explode\n-              ListSink\n+              Select Operator\n+                expressions: col (type: string)\n+                outputColumnNames: _col0\n+                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n+                ListSink\n \n PREHOOK: query: select explode(array('a', 'b'))\n PREHOOK: type: QUERY",
                "changes": 22
            },
            {
                "status": "modified",
                "additions": 5,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/decimal_precision2.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/decimal_precision2.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/decimal_precision2.q.out",
                "deletions": 5,
                "sha": "4ce7e1cca7d43da1a88b153e6c6cdeeff5b2adf7",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/decimal_precision2.q.out",
                "patch": "@@ -37,9 +37,9 @@ STAGE PLANS:\n           Row Limit Per Split: 1\n           Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE\n           Select Operator\n-            expressions: 100 (type: decimal(3,0))\n+            expressions: 100 (type: int)\n             outputColumnNames: _col0\n-            Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE\n+            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n             ListSink\n \n PREHOOK: query: explain select 0.000BD\n@@ -59,9 +59,9 @@ STAGE PLANS:\n           Row Limit Per Split: 1\n           Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE\n           Select Operator\n-            expressions: 0 (type: decimal(1,0))\n+            expressions: 0 (type: int)\n             outputColumnNames: _col0\n-            Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE\n+            Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n             ListSink\n \n PREHOOK: query: explain select 0.100BD\n@@ -147,7 +147,7 @@ STAGE PLANS:\n           Row Limit Per Split: 1\n           Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE\n           Select Operator\n-            expressions: 69.0212249755859375 (type: decimal(27,20))\n+            expressions: 69.0212249755859375 (type: decimal(18,16))\n             outputColumnNames: _col0\n             Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE\n             ListSink",
                "changes": 10
            },
            {
                "status": "modified",
                "additions": 8,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/explainuser_1.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/llap/explainuser_1.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/llap/explainuser_1.q.out",
                "deletions": 6,
                "sha": "a47d791fad073baa52e6374252e0c734a9310b8c",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/explainuser_1.q.out",
                "patch": "@@ -5150,16 +5150,18 @@ PREHOOK: query: explain select explode(array('a', 'b'))\n PREHOOK: type: QUERY\n POSTHOOK: query: explain select explode(array('a', 'b'))\n POSTHOOK: type: QUERY\n-Plan not optimized by CBO.\n+Plan optimized by CBO.\n \n Stage-0\n   Fetch Operator\n     limit:-1\n-    UDTF Operator [UDTF_2]\n-      function name:explode\n-      Select Operator [SEL_1]\n-        Output:[\"_col0\"]\n-        TableScan [TS_0]\n+    Select Operator [SEL_3]\n+      Output:[\"_col0\"]\n+      UDTF Operator [UDTF_2]\n+        function name:explode\n+        Select Operator [SEL_1]\n+          Output:[\"_col0\"]\n+          TableScan [TS_0]\n \n PREHOOK: query: CREATE TABLE T1(key STRING, val STRING) STORED AS TEXTFILE\n PREHOOK: type: CREATETABLE",
                "changes": 14
            },
            {
                "status": "modified",
                "additions": 4,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/mapjoin2.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/llap/mapjoin2.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/llap/mapjoin2.q.out",
                "deletions": 0,
                "sha": "ce65c6ddbfb6b4cdb7c058a05c583835d0631e06",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/mapjoin2.q.out",
                "patch": "@@ -53,6 +53,7 @@ POSTHOOK: Input: default@tbl\n #### A masked pattern was here ####\n false\tfalse\ttrue\ttrue\n true\ttrue\tfalse\tfalse\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Map 1' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -62,6 +63,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Map 1' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a left outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -71,6 +73,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Map 2' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a right outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -80,6 +83,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Shuffle Join MERGEJOIN[9][tables = [$hdt$_0, $hdt$_1]] in Stage 'Reducer 2' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a full outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table",
                "changes": 4
            },
            {
                "status": "modified",
                "additions": 8,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/select_dummy_source.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/llap/select_dummy_source.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/llap/select_dummy_source.q.out",
                "deletions": 2,
                "sha": "b7f939fb8e8fd4138e447df9840583a4955ec035",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/llap/select_dummy_source.q.out",
                "patch": "@@ -82,7 +82,10 @@ STAGE PLANS:\n             outputColumnNames: _col0\n             UDTF Operator\n               function name: explode\n-              ListSink\n+              Select Operator\n+                expressions: col (type: string)\n+                outputColumnNames: _col0\n+                ListSink\n \n PREHOOK: query: select explode(array('a', 'b'))\n PREHOOK: type: QUERY\n@@ -178,7 +181,10 @@ STAGE PLANS:\n             outputColumnNames: _col0\n             UDTF Operator\n               function name: explode\n-              ListSink\n+              Select Operator\n+                expressions: col (type: string)\n+                outputColumnNames: _col0\n+                ListSink\n \n PREHOOK: query: select explode(array('a', 'b'))\n PREHOOK: type: QUERY",
                "changes": 10
            },
            {
                "status": "modified",
                "additions": 4,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/mapjoin2.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/mapjoin2.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/mapjoin2.q.out",
                "deletions": 0,
                "sha": "7e7084160df06263534e64b490dcb20d810a26ec",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/mapjoin2.q.out",
                "patch": "@@ -53,6 +53,7 @@ POSTHOOK: Input: default@tbl\n #### A masked pattern was here ####\n false\tfalse\ttrue\ttrue\n true\ttrue\tfalse\tfalse\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -62,6 +63,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a left outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -71,6 +73,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Map Join MAPJOIN[9][bigTable=?] in task 'Stage-3:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a right outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table\n@@ -80,6 +83,7 @@ POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n #### A masked pattern was here ####\n 11\t1\t1\t0\t0\n+Warning: Shuffle Join JOIN[6][tables = [$hdt$_0, $hdt$_1]] in Stage 'Stage-1:MAPRED' is a cross product\n PREHOOK: query: select a.key, a.a_one, b.b_one, a.a_zero, b.b_zero from ( SELECT 11 key, 0 confuse_you, 1 a_one, 0 a_zero ) a full outer join ( SELECT 11 key, 0 confuse_you, 1 b_one, 0 b_zero ) b on a.key = b.key\n PREHOOK: type: QUERY\n PREHOOK: Input: _dummy_database@_dummy_table",
                "changes": 4
            },
            {
                "status": "modified",
                "additions": 15,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/select_dummy_source.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/select_dummy_source.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/select_dummy_source.q.out",
                "deletions": 7,
                "sha": "0b73e84e9aea6855e91fd547bfb7a973b55d6613",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/select_dummy_source.q.out",
                "patch": "@@ -89,13 +89,17 @@ STAGE PLANS:\n               UDTF Operator\n                 Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n                 function name: explode\n-                File Output Operator\n-                  compressed: false\n+                Select Operator\n+                  expressions: col (type: string)\n+                  outputColumnNames: _col0\n                   Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n-                  table:\n-                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n-                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n+                  File Output Operator\n+                    compressed: false\n+                    Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n+                    table:\n+                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n+                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n \n   Stage: Stage-0\n     Fetch Operator\n@@ -204,7 +208,11 @@ STAGE PLANS:\n             UDTF Operator\n               Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n               function name: explode\n-              ListSink\n+              Select Operator\n+                expressions: col (type: string)\n+                outputColumnNames: _col0\n+                Statistics: Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: COMPLETE\n+                ListSink\n \n PREHOOK: query: select explode(array('a', 'b'))\n PREHOOK: type: QUERY",
                "changes": 22
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/timestamptz_1.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/timestamptz_1.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/timestamptz_1.q.out",
                "deletions": 1,
                "sha": "b4ef3e41ad814de385e094a8bda12242203469b6",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/timestamptz_1.q.out",
                "patch": "@@ -18,7 +18,7 @@ POSTHOOK: query: insert overwrite table tstz1 select cast('2016-01-03 12:26:34 A\n POSTHOOK: type: QUERY\n POSTHOOK: Input: _dummy_database@_dummy_table\n POSTHOOK: Output: default@tstz1\n-POSTHOOK: Lineage: tstz1.t EXPRESSION []\n+POSTHOOK: Lineage: tstz1.t SIMPLE []\n PREHOOK: query: select cast(t as string) from tstz1\n PREHOOK: type: QUERY\n PREHOOK: Input: default@tstz1",
                "changes": 2
            },
            {
                "status": "modified",
                "additions": 11,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/udtf_stack.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/udtf_stack.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/udtf_stack.q.out",
                "deletions": 7,
                "sha": "3192a44e41d9063af2b17f7350795dc9d2834b19",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/udtf_stack.q.out",
                "patch": "@@ -182,13 +182,17 @@ STAGE PLANS:\n               UDTF Operator\n                 Statistics: Num rows: 1 Data size: 185 Basic stats: COMPLETE Column stats: COMPLETE\n                 function name: stack\n-                File Output Operator\n-                  compressed: false\n-                  Statistics: Num rows: 1 Data size: 185 Basic stats: COMPLETE Column stats: COMPLETE\n-                  table:\n-                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n-                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n-                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n+                Select Operator\n+                  expressions: col0 (type: string), col1 (type: string), null (type: void)\n+                  outputColumnNames: _col0, _col1, _col2\n+                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n+                  File Output Operator\n+                    compressed: false\n+                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n+                    table:\n+                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat\n+                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat\n+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n \n   Stage: Stage-0\n     Fetch Operator",
                "changes": 18
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/vector_tablesample_rows.q.out",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/test/results/clientpositive/vector_tablesample_rows.q.out?ref=583a9511ba8809d81595a5fa4da32ed2c2f8912e",
                "filename": "ql/src/test/results/clientpositive/vector_tablesample_rows.q.out",
                "deletions": 1,
                "sha": "2d86d8c70834b1dbae3adf3a1d10a2188ffcd385",
                "blob_url": "https://github.com/apache/hive/blob/583a9511ba8809d81595a5fa4da32ed2c2f8912e/ql/src/test/results/clientpositive/vector_tablesample_rows.q.out",
                "patch": "@@ -251,7 +251,7 @@ STAGE PLANS:\n             Select Operator\n               Statistics: Num rows: 1 Data size: 1 Basic stats: COMPLETE Column stats: COMPLETE\n               Group By Operator\n-                aggregations: count(1)\n+                aggregations: count()\n                 Group By Vectorization:\n                     groupByMode: HASH\n                     vectorOutput: false",
                "changes": 2
            }
        ],
        "unit_tests": [
            "TestSemanticAnalyzer.java"
        ]
    },
    {
        "buggy": false,
        "test_file": "ql/src/test/org/apache/hadoop/hive/ql/parse/TestSemanticAnalyzer.java",
        "buggy_files": [
            "ql/src/test/results/clientpositive/mapjoin2.q.out",
            "ql/src/test/results/clientpositive/llap/mapjoin2.q.out",
            "ql/src/test/results/clientpositive/beeline/mapjoin2.q.out",
            "ql/src/test/results/clientpositive/udtf_stack.q.out",
            "ql/src/test/results/clientpositive/llap/explainuser_1.q.out",
            "ql/src/test/results/clientpositive/timestamptz_1.q.out",
            "ql/src/test/results/clientpositive/decimal_precision2.q.out",
            "ql/src/test/results/clientpositive/vector_tablesample_rows.q.out",
            "ql/src/test/results/clientpositive/llap/vector_tablesample_rows.q.out",
            "ql/src/test/results/clientpositive/spark/vector_tablesample_rows.q.out",
            "itests/hive-blobstore/src/test/resources/testconfiguration.properties",
            "itests/src/test/resources/testconfiguration.properties",
            "ql/src/test/results/clientpositive/select_dummy_source.q.out",
            "ql/src/test/results/clientpositive/llap/select_dummy_source.q.out",
            "ql/src/test/results/clientpositive/beeline/select_dummy_source.q.out",
            "ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java"
        ],
        "fixed": true
    }
]