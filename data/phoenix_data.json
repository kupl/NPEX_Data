[{"commit": "https://github.com/apache/phoenix/commit/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0", "parent": "https://github.com/apache/phoenix/commit/665e224e4d9a0e991e38083b983ec38989dfd5e7", "message": "PHOENIX-5415: NPE in getting conf from addHbaseResources in IndexUpgradeTool", "bug_id": "phoenix_1", "file": [{"additions": 88, "raw_url": "https://github.com/apache/phoenix/raw/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java", "blob_url": "https://github.com/apache/phoenix/blob/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java", "sha": "daac60456c320fa583d961a65af8bd4f40d7a3ee", "changes": 141, "status": "modified", "deletions": 53, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java?ref=0b5eddc38a566b2c83cc30aff5a1b9f679efdad0", "patch": "@@ -18,6 +18,7 @@\n package org.apache.phoenix.mapreduce.index;\n \n import com.google.common.annotations.VisibleForTesting;\n+import com.google.gson.Gson;\n import org.apache.commons.cli.CommandLine;\n import org.apache.commons.cli.CommandLineParser;\n import org.apache.commons.cli.DefaultParser;\n@@ -26,6 +27,8 @@\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.hadoop.conf.Configured;\n+import org.apache.hadoop.util.Tool;\n+import org.apache.hadoop.util.ToolRunner;\n \n import org.apache.hadoop.hbase.HBaseConfiguration;\n import org.apache.hadoop.hbase.TableName;\n@@ -55,6 +58,7 @@\n import java.util.logging.Logger;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.StringUtil;\n \n import java.io.IOException;\n import java.nio.file.Files;\n@@ -70,7 +74,7 @@\n \n import static org.apache.phoenix.query.QueryServicesOptions.GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN;\n \n-public class IndexUpgradeTool extends Configured {\n+public class IndexUpgradeTool extends Configured implements Tool {\n \n     private static final Logger LOGGER = Logger.getLogger(IndexUpgradeTool.class.getName());\n \n@@ -145,21 +149,6 @@ public String getOperation() {\n         return operation;\n     }\n \n-    public static void main (String[] args) {\n-        CommandLine cmdLine = null;\n-\n-        IndexUpgradeTool iut = new IndexUpgradeTool();\n-        try {\n-            cmdLine = iut.parseOptions(args);\n-            LOGGER.info(\"Index Upgrade tool initiated: \"+ String.join(\",\", args));\n-        } catch (IllegalStateException e) {\n-            iut.printHelpAndExit(e.getMessage(), iut.getOptions());\n-        }\n-        iut.initializeTool(cmdLine);\n-        iut.prepareToolSetup();\n-        iut.executeTool();\n-    }\n-\n     public IndexUpgradeTool(String mode, String tables, String inputFile,\n             String outputFile, boolean dryRun, IndexTool indexTool) {\n         this.operation = mode;\n@@ -172,6 +161,21 @@ public IndexUpgradeTool(String mode, String tables, String inputFile,\n \n     public IndexUpgradeTool () { }\n \n+    @Override\n+    public int run(String[] args) throws Exception {\n+        CommandLine cmdLine = null;\n+        try {\n+            cmdLine = parseOptions(args);\n+            LOGGER.info(\"Index Upgrade tool initiated: \" + String.join(\",\", args));\n+        } catch (IllegalStateException e) {\n+            printHelpAndExit(e.getMessage(), getOptions());\n+        }\n+        initializeTool(cmdLine);\n+        prepareToolSetup();\n+        executeTool();\n+        return 0;\n+    }\n+\n     /**\n      * Parses the commandline arguments, throws IllegalStateException if mandatory arguments are\n      * missing.\n@@ -329,7 +333,7 @@ private int executeTool(Connection conn, ConnectionQueryServices queryServices,\n                 boolean mutable = !(dataTable.isImmutableRows());\n                 if (!mutable) {\n                     LOGGER.fine(\"Data table is immutable, waiting for \"\n-                            + GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN + 1\n+                            + (GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN + 1)\n                             + \" minutes for client cache to expire\");\n                     if (!test) {\n                         Thread.sleep(\n@@ -368,7 +372,7 @@ private void disableTable(Admin admin, String dataTable, HashSet<String>indexes)\n             }\n             LOGGER.info(\"Disabled data table \" + dataTable);\n         } else {\n-            LOGGER.info( \"Data table \" + dataTable +\" is already disabled\");\n+            LOGGER.info( \"Data table \" + dataTable + \" is already disabled\");\n         }\n         for (String indexName : indexes) {\n             if (admin.isTableEnabled(TableName.valueOf(indexName))) {\n@@ -377,7 +381,7 @@ private void disableTable(Admin admin, String dataTable, HashSet<String>indexes)\n                 }\n                 LOGGER.info(\"Disabled index table \" + indexName);\n             } else {\n-                LOGGER.info( \"Index table \" + indexName +\" is already disabled\");\n+                LOGGER.info( \"Index table \" + indexName + \" is already disabled\");\n             }\n         }\n     }\n@@ -390,7 +394,7 @@ private void enableTable(Admin admin, String dataTable, HashSet<String>indexes)\n             }\n             LOGGER.info(\"Enabled data table \" + dataTable);\n         } else {\n-            LOGGER.info( \"Data table \" + dataTable +\" is already enabled\");\n+            LOGGER.info( \"Data table \" + dataTable + \" is already enabled\");\n         }\n         for (String indexName : indexes) {\n             if(!admin.isTableEnabled(TableName.valueOf(indexName))) {\n@@ -399,7 +403,7 @@ private void enableTable(Admin admin, String dataTable, HashSet<String>indexes)\n                 }\n                 LOGGER.info(\"Enabled index table \" + indexName);\n             } else {\n-                LOGGER.info( \"Index table \" + indexName +\" is already enabled\");\n+                LOGGER.info( \"Index table \" + indexName + \" is already enabled\");\n             }\n         }\n     }\n@@ -431,26 +435,28 @@ private void modifyDataTable(Admin admin, String tableName)\n         }\n     }\n \n-    private void addCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder, String coprocName) throws IOException {\n+    private void addCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder,\n+            String coprocName) throws IOException {\n         if (!admin.getDescriptor(TableName.valueOf(tableName)).hasCoprocessor(coprocName)) {\n             if (!dryRun) {\n                 tableDescBuilder.addCoprocessor(coprocName,\n                         null, QueryServicesOptions.DEFAULT_COPROCESSOR_PRIORITY, prop);\n             }\n-            LOGGER.info(\"Loaded \"+coprocName+\" coprocessor on table \" + tableName);\n+            LOGGER.info(\"Loaded \" + coprocName + \" coprocessor on table \" + tableName);\n         } else {\n-            LOGGER.info(coprocName+\" coprocessor on table \" + tableName + \"is already loaded\");\n+            LOGGER.info(coprocName + \" coprocessor on table \" + tableName + \"is already loaded\");\n         }\n     }\n \n-    private void removeCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder, String coprocName) throws IOException {\n+    private void removeCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder,\n+            String coprocName) throws IOException {\n         if (admin.getDescriptor(TableName.valueOf(tableName)).hasCoprocessor(coprocName)) {\n             if (!dryRun) {\n                 tableDescBuilder.removeCoprocessor(coprocName);\n             }\n             LOGGER.info(\"Unloaded \"+ coprocName +\"coprocessor on table \" + tableName);\n         } else {\n-            LOGGER.info(coprocName+\" coprocessor on table \" + tableName + \" is already unloaded\");\n+            LOGGER.info(coprocName + \" coprocessor on table \" + tableName + \" is already unloaded\");\n         }\n     }\n \n@@ -534,7 +540,7 @@ private boolean extractTablesAndIndexes(PhoenixConnection conn) {\n                     //for upgrade or rollback\n                     tablesAndIndexes.put(physicalTableName, physicalIndexes);\n                 } else {\n-                    LOGGER.info(\"Skipping Table \" + tableName + \" because it is \"+\n+                    LOGGER.info(\"Skipping Table \" + tableName + \" because it is \" +\n                             (dataTable.isTransactional() ? \"transactional\" : \"not a data table\"));\n                 }\n             }\n@@ -550,13 +556,13 @@ private boolean extractTablesAndIndexes(PhoenixConnection conn) {\n \n     private void prepareToRebuildIndexes(Connection conn, String dataTableFullName) {\n         try {\n+            Gson gson = new Gson();\n             HashMap<String, IndexInfo> rebuildIndexes = new HashMap<>();\n             HashSet<String> physicalIndexes = tablesAndIndexes.get(dataTableFullName);\n \n             String viewIndexPhysicalName = MetaDataUtil\n                     .getViewIndexPhysicalName(dataTableFullName);\n             boolean hasViewIndex =  physicalIndexes.contains(viewIndexPhysicalName);\n-\n             String schemaName = SchemaUtil.getSchemaNameFromFullName(dataTableFullName);\n             String tableName = SchemaUtil.getTableNameFromFullName(dataTableFullName);\n \n@@ -572,40 +578,64 @@ private void prepareToRebuildIndexes(Connection conn, String dataTableFullName)\n             }\n \n             if (hasViewIndex) {\n-                ResultSet\n-                        rs =\n-                        conn.createStatement().executeQuery(\n-                                \"SELECT DISTINCT TABLE_NAME, TENANT_ID FROM \"\n-                                        + \"SYSTEM.CATALOG WHERE COLUMN_FAMILY = \\'\"\n-                                        + viewIndexPhysicalName\n-                                        + \"\\' AND TABLE_TYPE = \\'i\\' AND \" + \"LINK_TYPE = \"\n-                                        + PTable.LinkType.PHYSICAL_TABLE.getSerializedValue());\n+                String viewSql = \"SELECT DISTINCT TABLE_NAME, TENANT_ID FROM \"\n+                        + \"SYSTEM.CATALOG \"\n+                        + \"WHERE COLUMN_FAMILY = \\'\" + dataTableFullName + \"\\' \"\n+                        + (!StringUtil.EMPTY_STRING.equals(schemaName) ? \"AND TABLE_SCHEM = \\'\"\n+                        + schemaName + \"\\' \" : \"\")\n+                        + \"AND LINK_TYPE = \"\n+                        + PTable.LinkType.PHYSICAL_TABLE.getSerializedValue();\n+\n+                ResultSet rs = conn.createStatement().executeQuery(viewSql);\n+\n                 while (rs.next()) {\n-                    String viewIndexName = rs.getString(1);\n+                    String viewName = rs.getString(1);\n                     String tenantId = rs.getString(2);\n-                    ResultSet\n-                            innerRS =\n-                            conn.createStatement().executeQuery(\n-                                    \"SELECT DISTINCT TABLE_NAME FROM \"\n-                                            + \"SYSTEM.CATALOG WHERE COLUMN_FAMILY = \\'\"\n-                                            + viewIndexName\n-                                            + \"\\' AND TABLE_TYPE = \\'i\\' AND \" + \"LINK_TYPE = \"\n-                                            + PTable.LinkType.INDEX_TABLE.getSerializedValue());\n-                    innerRS.next();\n-                    String viewName = innerRS.getString(1);\n-                    IndexInfo indexInfo = new IndexInfo(schemaName, viewName, tenantId == null ?\n-                            GLOBAL_INDEX_ID: tenantId, viewIndexName);\n-                    rebuildIndexes.put(viewIndexName, indexInfo);\n+                    ArrayList<String> viewIndexes = findViewIndexes(conn, schemaName, viewName,\n+                           tenantId);\n+                    for (String viewIndex : viewIndexes) {\n+                        IndexInfo indexInfo = new IndexInfo(schemaName, viewName,\n+                               tenantId == null ? GLOBAL_INDEX_ID : tenantId, viewIndex);\n+                        rebuildIndexes.put(viewIndex, indexInfo);\n+                    }\n                 }\n             }\n-            //for rebuilding indexes in case of upgrade.\n-            rebuildMap.put(dataTableFullName, rebuildIndexes);\n+            //for rebuilding indexes in case of upgrade and if there are indexes on the table/view.\n+            if (!rebuildIndexes.isEmpty()) {\n+                rebuildMap.put(dataTableFullName, rebuildIndexes);\n+                String json = gson.toJson(rebuildMap);\n+                LOGGER.info(\"Index rebuild map \" + json);\n+            } else {\n+                LOGGER.info(\"No indexes to rebuild for table \" + dataTableFullName);\n+            }\n+\n         } catch (SQLException e) {\n-            LOGGER.severe(\"Failed to prepare the map for index rebuilds \"+e);\n+            LOGGER.severe(\"Failed to prepare the map for index rebuilds \" + e);\n             throw new RuntimeException(\"Failed to prepare the map for index rebuilds\");\n         }\n     }\n \n+    private ArrayList<String> findViewIndexes(Connection conn, String schemaName, String viewName,\n+            String tenantId) throws SQLException {\n+\n+        String viewIndexesSql = \"SELECT DISTINCT COLUMN_FAMILY FROM \"\n+                + \"SYSTEM.CATALOG \"\n+                + \"WHERE TABLE_NAME = \\'\" + viewName + \"\\'\"\n+                + (!StringUtil.EMPTY_STRING.equals(schemaName) ? \"AND TABLE_SCHEM = \\'\"\n+                + schemaName + \"\\' \" : \"\")\n+                + \"AND LINK_TYPE = \" + PTable.LinkType.INDEX_TABLE.getSerializedValue()\n+                + (tenantId != null ? \" AND TENANT_ID = \\'\" + tenantId + \"\\'\" : \"\");\n+        ArrayList<String> viewIndexes = new ArrayList<>();\n+        ResultSet\n+                rs =\n+                conn.createStatement().executeQuery(viewIndexesSql);\n+        while(rs.next()) {\n+            String viewIndexName = rs.getString(1);\n+            viewIndexes.add(viewIndexName);\n+        }\n+        return viewIndexes;\n+    }\n+\n     private class IndexInfo {\n         final private String schemaName;\n         final private String baseTable;\n@@ -635,4 +665,9 @@ public String getIndexName() {\n             return indexName;\n         }\n     }\n+\n+    public static void main (String[] args) throws Exception {\n+        int result = ToolRunner.run(new IndexUpgradeTool(), args);\n+        System.exit(result);\n+    }\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/9f1f295b61581da86355e175b8923f5eae12fd88", "parent": "https://github.com/apache/phoenix/commit/eb02a0ce6eb0168b134676c6d9e929bf4ce91c0e", "message": "PHOENIX-5379 : Avoid possible NPE while closing CSVParser", "bug_id": "phoenix_2", "file": [{"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/9f1f295b61581da86355e175b8923f5eae12fd88/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/impl/CSVFileResultHandler.java", "blob_url": "https://github.com/apache/phoenix/blob/9f1f295b61581da86355e175b8923f5eae12fd88/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/impl/CSVFileResultHandler.java", "sha": "a2dcab33961eeb2d1f789a25f5d5f4735a343fd8", "changes": 9, "status": "modified", "deletions": 6, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/impl/CSVFileResultHandler.java?ref=9f1f295b61581da86355e175b8923f5eae12fd88", "patch": "@@ -47,11 +47,10 @@ public synchronized void write(Result result) throws IOException{\n     }\n \n     public synchronized List<Result> read() throws IOException {\n-        CSVParser parser = null;\n         util.ensureBaseResultDirExists();\n-        try {\n-            File file = new File(resultFileName);\n-            parser = CSVParser.parse(file, Charset.defaultCharset(), CSVFormat.DEFAULT);\n+        File file = new File(resultFileName);\n+        try (CSVParser parser = CSVParser\n+                .parse(file, Charset.defaultCharset(), CSVFormat.DEFAULT)) {\n             List<CSVRecord> records = parser.getRecords();\n             List<Result> results = new ArrayList<>();\n             String header = null;\n@@ -70,8 +69,6 @@ public synchronized void write(Result result) throws IOException{\n                 results.add(result);\n             }\n             return results;\n-        } finally {\n-            parser.close();\n         }\n     }\n ", "filename": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/impl/CSVFileResultHandler.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/bb1327ef89fb0844094470ada74cbe5071b43a0d", "parent": "https://github.com/apache/phoenix/commit/4eec41f3f2b04865b6d59ebd3fbd3aa1e0a0fd80", "message": "PHOENIX-5101 ScanningResultIterator getScanMetrics throws NPE", "bug_id": "phoenix_3", "file": [{"additions": 16, "raw_url": "https://github.com/apache/phoenix/raw/bb1327ef89fb0844094470ada74cbe5071b43a0d/phoenix-core/src/it/java/org/apache/phoenix/monitoring/PhoenixMetricsIT.java", "blob_url": "https://github.com/apache/phoenix/blob/bb1327ef89fb0844094470ada74cbe5071b43a0d/phoenix-core/src/it/java/org/apache/phoenix/monitoring/PhoenixMetricsIT.java", "sha": "8f1abf0dc807150917a6216c5b25ad67caa16c3d", "changes": 16, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/monitoring/PhoenixMetricsIT.java?ref=bb1327ef89fb0844094470ada74cbe5071b43a0d", "patch": "@@ -271,6 +271,22 @@ public void testOverallQueryMetricsForSelect() throws Exception {\n         conn.createStatement().execute(ddl);\n     }\n \n+    // See PHOENIX-5101\n+    @Test\n+    public void testMetricsLargeQuery() throws Exception {\n+        String tableName = \"MY_TABLE\";\n+        String ddl = \"CREATE TABLE \" + tableName + \" (K VARCHAR NOT NULL PRIMARY KEY, V VARCHAR)\";\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        conn.createStatement().execute(ddl);\n+        long numRows = 18750;\n+        insertRowsInTable(tableName, numRows);\n+        String query = \"SELECT * FROM \" + tableName;\n+        Statement stmt = conn.createStatement();\n+        ResultSet rs = stmt.executeQuery(query);\n+        while (rs.next()) {}\n+        rs.close();\n+    }\n+\n     @Test\n     public void testReadMetricsForSelect() throws Exception {\n         String tableName = generateUniqueName();", "filename": "phoenix-core/src/it/java/org/apache/phoenix/monitoring/PhoenixMetricsIT.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/bb1327ef89fb0844094470ada74cbe5071b43a0d/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java", "blob_url": "https://github.com/apache/phoenix/blob/bb1327ef89fb0844094470ada74cbe5071b43a0d/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java", "sha": "d86a27a4df66795fd61d57420d2380f593ed2aa6", "changes": 5, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java?ref=bb1327ef89fb0844094470ada74cbe5071b43a0d", "patch": "@@ -72,8 +72,9 @@ public ScanningResultIterator(ResultScanner scanner, Scan scan, ScanMetricsHolde\n \n     @Override\n     public void close() throws SQLException {\n-        getScanMetrics();\n+        // close the scanner so that metrics are available\n         scanner.close();\n+        updateMetrics();\n     }\n \n     private void changeMetric(CombinableMetric metric, Long value) {\n@@ -88,7 +89,7 @@ private void changeMetric(GlobalClientMetrics metric, Long value) {\n         }\n     }\n \n-    private void getScanMetrics() {\n+    private void updateMetrics() {\n \n         if (scanMetricsEnabled && !scanMetricsUpdated) {\n             ScanMetrics scanMetrics = scanner.getScanMetrics();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/e8664d14d29ed3803e884f17d341593d41dcef6a", "parent": "https://github.com/apache/phoenix/commit/507e6b5a0f0c94cd85ed359cd04d92e849743a31", "message": "PHOENIX-5101 ScanningResultIterator getScanMetrics throws NPE", "bug_id": "phoenix_4", "file": [{"additions": 46, "raw_url": "https://github.com/apache/phoenix/raw/e8664d14d29ed3803e884f17d341593d41dcef6a/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java", "blob_url": "https://github.com/apache/phoenix/blob/e8664d14d29ed3803e884f17d341593d41dcef6a/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java", "sha": "9a656ee12e28a392cb1b148165eb89d37353bd3d", "changes": 85, "status": "modified", "deletions": 39, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java?ref=e8664d14d29ed3803e884f17d341593d41dcef6a", "patch": "@@ -17,6 +17,17 @@\n  */\n package org.apache.phoenix.iterate;\n \n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.BYTES_IN_REMOTE_RESULTS_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.BYTES_IN_RESULTS_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.MILLIS_BETWEEN_NEXTS_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.NOT_SERVING_REGION_EXCEPTION_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.REGIONS_SCANNED_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.REMOTE_RPC_CALLS_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.REMOTE_RPC_RETRIES_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.RPC_CALLS_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ScanMetrics.RPC_RETRIES_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.COUNT_OF_ROWS_FILTERED_KEY_METRIC_NAME;\n+import static org.apache.hadoop.hbase.client.metrics.ServerSideScanMetrics.COUNT_OF_ROWS_SCANNED_KEY_METRIC_NAME;\n import static org.apache.phoenix.monitoring.GlobalClientMetrics.GLOBAL_HBASE_COUNT_BYTES_IN_REMOTE_RESULTS;\n import static org.apache.phoenix.monitoring.GlobalClientMetrics.GLOBAL_HBASE_COUNT_BYTES_REGION_SERVER_RESULTS;\n import static org.apache.phoenix.monitoring.GlobalClientMetrics.GLOBAL_HBASE_COUNT_MILLS_BETWEEN_NEXTS;\n@@ -40,36 +51,20 @@\n import org.apache.hadoop.hbase.client.Scan;\n import org.apache.hadoop.hbase.client.metrics.ScanMetrics;\n import org.apache.phoenix.monitoring.CombinableMetric;\n+import org.apache.phoenix.monitoring.GlobalClientMetrics;\n import org.apache.phoenix.monitoring.ScanMetricsHolder;\n import org.apache.phoenix.schema.tuple.ResultTuple;\n import org.apache.phoenix.schema.tuple.Tuple;\n import org.apache.phoenix.util.ServerUtil;\n \n public class ScanningResultIterator implements ResultIterator {\n     private final ResultScanner scanner;\n-    private final Scan scan;\n     private final ScanMetricsHolder scanMetricsHolder;\n     boolean scanMetricsUpdated;\n     boolean scanMetricsEnabled;\n \n-    // These metric names are how HBase refers them\n-    // Since HBase stores these strings as static final, we are using the same here\n-    static final String RPC_CALLS_METRIC_NAME = \"RPC_CALLS\";\n-    static final String REMOTE_RPC_CALLS_METRIC_NAME = \"REMOTE_RPC_CALLS\";\n-    static final String MILLIS_BETWEEN_NEXTS_METRIC_NAME = \"MILLIS_BETWEEN_NEXTS\";\n-    static final String NOT_SERVING_REGION_EXCEPTION_METRIC_NAME = \"NOT_SERVING_REGION_EXCEPTION\";\n-    static final String BYTES_IN_RESULTS_METRIC_NAME = \"BYTES_IN_RESULTS\";\n-    static final String BYTES_IN_REMOTE_RESULTS_METRIC_NAME = \"BYTES_IN_REMOTE_RESULTS\";\n-    static final String REGIONS_SCANNED_METRIC_NAME = \"REGIONS_SCANNED\";\n-    static final String RPC_RETRIES_METRIC_NAME = \"RPC_RETRIES\";\n-    static final String REMOTE_RPC_RETRIES_METRIC_NAME = \"REMOTE_RPC_RETRIES\";\n-    static final String COUNT_OF_ROWS_SCANNED_KEY_METRIC_NAME = \"ROWS_SCANNED\";\n-    static final String COUNT_OF_ROWS_FILTERED_KEY_METRIC_NAME = \"ROWS_FILTERED\";\n-    static final String GLOBAL_BYTES_IN_RESULTS_METRIC_NAME = \"BYTES_IN_RESULTS\";\n-\n     public ScanningResultIterator(ResultScanner scanner, Scan scan, ScanMetricsHolder scanMetricsHolder) {\n         this.scanner = scanner;\n-        this.scan = scan;\n         this.scanMetricsHolder = scanMetricsHolder;\n         scanMetricsUpdated = false;\n         scanMetricsEnabled = scan.isScanMetricsEnabled();\n@@ -81,24 +76,25 @@ public void close() throws SQLException {\n         scanner.close();\n     }\n \n-    private static void changeMetric(CombinableMetric metric, Long value) {\n+    private void changeMetric(CombinableMetric metric, Long value) {\n         if(value != null) {\n             metric.change(value);\n         }\n     }\n \n+    private void changeMetric(GlobalClientMetrics metric, Long value) {\n+        if(value != null) {\n+            metric.update(value);\n+        }\n+    }\n+\n     private void getScanMetrics() {\n \n-        if (!scanMetricsUpdated && scanMetricsEnabled) {\n-            ScanMetrics scanMetrics = scan.getScanMetrics();\n-            if (scanMetrics == null) {\n-                return;\n-            }\n+        if (scanMetricsEnabled && !scanMetricsUpdated) {\n+            ScanMetrics scanMetrics = scanner.getScanMetrics();\n             Map<String, Long> scanMetricsMap = scanMetrics.getMetricsMap();\n-            if(scanMetricsMap == null) {\n-                return;\n-            }\n             scanMetricsHolder.setScanMetricMap(scanMetricsMap);\n+\n             changeMetric(scanMetricsHolder.getCountOfRPCcalls(),\n                     scanMetricsMap.get(RPC_CALLS_METRIC_NAME));\n             changeMetric(scanMetricsHolder.getCountOfRemoteRPCcalls(),\n@@ -122,19 +118,30 @@ private void getScanMetrics() {\n             changeMetric(scanMetricsHolder.getCountOfRowsFiltered(),\n                     scanMetricsMap.get(COUNT_OF_ROWS_FILTERED_KEY_METRIC_NAME));\n \n-            GLOBAL_SCAN_BYTES.update(scanMetricsMap.get(GLOBAL_BYTES_IN_RESULTS_METRIC_NAME));\n-\n-            GLOBAL_HBASE_COUNT_RPC_CALLS.update(scanMetricsMap.get(RPC_CALLS_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_REMOTE_RPC_CALLS.update(scanMetricsMap.get(REMOTE_RPC_CALLS_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_MILLS_BETWEEN_NEXTS.update(scanMetricsMap.get(MILLIS_BETWEEN_NEXTS_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_NOT_SERVING_REGION_EXCEPTION.update(scanMetricsMap.get(NOT_SERVING_REGION_EXCEPTION_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_BYTES_REGION_SERVER_RESULTS.update(scanMetricsMap.get(BYTES_IN_RESULTS_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_BYTES_IN_REMOTE_RESULTS.update(scanMetricsMap.get(BYTES_IN_REMOTE_RESULTS_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_SCANNED_REGIONS.update(scanMetricsMap.get(REGIONS_SCANNED_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_RPC_RETRIES.update(scanMetricsMap.get(RPC_RETRIES_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_REMOTE_RPC_RETRIES.update(scanMetricsMap.get(REMOTE_RPC_RETRIES_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_ROWS_SCANNED.update(scanMetricsMap.get(COUNT_OF_ROWS_SCANNED_KEY_METRIC_NAME));\n-            GLOBAL_HBASE_COUNT_ROWS_FILTERED.update(scanMetricsMap.get(COUNT_OF_ROWS_FILTERED_KEY_METRIC_NAME));\n+            changeMetric(GLOBAL_SCAN_BYTES,\n+                    scanMetricsMap.get(BYTES_IN_RESULTS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_RPC_CALLS,\n+                    scanMetricsMap.get(RPC_CALLS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_REMOTE_RPC_CALLS\n+                    , scanMetricsMap.get(REMOTE_RPC_CALLS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_MILLS_BETWEEN_NEXTS,\n+                    scanMetricsMap.get(MILLIS_BETWEEN_NEXTS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_NOT_SERVING_REGION_EXCEPTION,\n+                    scanMetricsMap.get(NOT_SERVING_REGION_EXCEPTION_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_BYTES_REGION_SERVER_RESULTS,\n+                    scanMetricsMap.get(BYTES_IN_RESULTS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_BYTES_IN_REMOTE_RESULTS,\n+                    scanMetricsMap.get(BYTES_IN_REMOTE_RESULTS_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_SCANNED_REGIONS,\n+                    scanMetricsMap.get(REGIONS_SCANNED_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_RPC_RETRIES,\n+                    scanMetricsMap.get(RPC_RETRIES_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_REMOTE_RPC_RETRIES,\n+                    scanMetricsMap.get(REMOTE_RPC_RETRIES_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_ROWS_SCANNED,\n+                    scanMetricsMap.get(COUNT_OF_ROWS_SCANNED_KEY_METRIC_NAME));\n+            changeMetric(GLOBAL_HBASE_COUNT_ROWS_FILTERED,\n+                    scanMetricsMap.get(COUNT_OF_ROWS_FILTERED_KEY_METRIC_NAME));\n \n             scanMetricsUpdated = true;\n         }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/ScanningResultIterator.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/85ab5d616bfefee9c23e70a29b6733861694af9f", "parent": "https://github.com/apache/phoenix/commit/69d2d76923ae7a070373431bb774188d3d6c5571", "message": "PHOENIX-5070 NPE when upgrading Phoenix 4.13.0 to Phoenix 4.14.1 with hbase-1.x branch in secure setup", "bug_id": "phoenix_5", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/85ab5d616bfefee9c23e70a29b6733861694af9f/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/PhoenixAccessController.java", "blob_url": "https://github.com/apache/phoenix/blob/85ab5d616bfefee9c23e70a29b6733861694af9f/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/PhoenixAccessController.java", "sha": "d07f4f7c7e11c78c5cd6ccc1c0b2e7624e91fed9", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/PhoenixAccessController.java?ref=85ab5d616bfefee9c23e70a29b6733861694af9f", "patch": "@@ -419,7 +419,7 @@ public void preIndexUpdate(ObserverContext<PhoenixMetaDataControllerEnvironment>\n                 final List<UserPermission> userPermissions = new ArrayList<UserPermission>();\n                 try (Connection connection = ConnectionFactory.createConnection(env.getConfiguration())) {\n                     // Merge permissions from all accessController coprocessors loaded in memory\n-                    for (MasterObserver service : accessControllers) {\n+                    for (MasterObserver service : getAccessControllers()) {\n                         // Use AccessControlClient API's if the accessController is an instance of org.apache.hadoop.hbase.security.access.AccessController\n                         if (service.getClass().getName().equals(org.apache.hadoop.hbase.security.access.AccessController.class.getName())) {\n                             userPermissions.addAll(AccessControlClient.getUserPermissions(connection, tableName.getNameAsString()));", "filename": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/PhoenixAccessController.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/f3af541705233e003ce64e024608eed56680692c", "parent": "https://github.com/apache/phoenix/commit/7110894420db286dfa7a688dc587c559f8a9c812", "message": "PHOENIX-4933 DELETE FROM throws NPE when a local index is present.", "bug_id": "phoenix_6", "file": [{"additions": 22, "raw_url": "https://github.com/apache/phoenix/raw/f3af541705233e003ce64e024608eed56680692c/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/f3af541705233e003ce64e024608eed56680692c/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java", "sha": "3ff35d1b570d5d8bdb32d11fc64dedde0000632b", "changes": 22, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java?ref=f3af541705233e003ce64e024608eed56680692c", "patch": "@@ -79,7 +79,29 @@\n     public LocalIndexIT(boolean isNamespaceMapped) {\n         super(isNamespaceMapped);\n     }\n+\n+    @Test\n+    public void testDeleteFromLocalIndex() throws Exception {\n+        String tableName = schemaName + \".\" + generateUniqueName();\n+        String indexName = \"IDX_\" + generateUniqueName();\n     \n+        Connection conn = getConnection();\n+        conn.setAutoCommit(true);\n+        if (isNamespaceMapped) {\n+            conn.createStatement().execute(\"CREATE SCHEMA IF NOT EXISTS \" + schemaName);\n+        }\n+\n+        conn.createStatement().execute(\"CREATE TABLE \" + tableName + \" (pk INTEGER PRIMARY KEY, v1 FLOAT, v2 FLOAT)\");\n+        conn.createStatement().execute(\"CREATE LOCAL INDEX \" + indexName + \" ON \" + tableName + \"(v2)\");\n+        conn.createStatement().execute(\"UPSERT INTO \" + tableName + \" VALUES(1, rand(), rand())\");\n+        // This would fail with an NPE before PHOENIX-4933\n+        conn.createStatement().execute(\"DELETE FROM \" + tableName + \" WHERE v1 < 1\");\n+        ResultSet rs = conn.createStatement().executeQuery(\"SELECT COUNT(*) FROM \"+tableName);\n+        rs.next();\n+        assertEquals(0, rs.getInt(1));\n+        rs.close();\n+    }\n+\n     @Test\n     public void testLocalIndexRoundTrip() throws Exception {\n         String tableName = schemaName + \".\" + generateUniqueName();", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java"}, {"additions": 17, "raw_url": "https://github.com/apache/phoenix/raw/f3af541705233e003ce64e024608eed56680692c/phoenix-core/src/main/java/org/apache/phoenix/schema/tuple/EncodedColumnQualiferCellsList.java", "blob_url": "https://github.com/apache/phoenix/blob/f3af541705233e003ce64e024608eed56680692c/phoenix-core/src/main/java/org/apache/phoenix/schema/tuple/EncodedColumnQualiferCellsList.java", "sha": "db3647da70ca2461d71ab62c8a05c13a05f10181", "changes": 25, "status": "modified", "deletions": 8, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/tuple/EncodedColumnQualiferCellsList.java?ref=f3af541705233e003ce64e024608eed56680692c", "patch": "@@ -175,14 +175,7 @@ public boolean remove(Object o) {\n                     firstNonNullElementIdx = -1;\n                 } else if (firstNonNullElementIdx == i) {\n                     // the element being removed was the first non-null element we knew\n-                    while (i < array.length && (array[i]) == null) {\n-                        i++;\n-                    }\n-                    if (i < array.length) {\n-                        firstNonNullElementIdx = i;\n-                    } else {\n-                        firstNonNullElementIdx = -1;\n-                    }\n+                    adjustFirstNonNullElement();\n                 }\n                 modCount++;\n                 return true;\n@@ -383,6 +376,18 @@ public Cell getCellForColumnQualifier(byte[] qualifierBytes, int offset, int len\n         return getCellForColumnQualifier(columnQualifier);\n     }\n \n+    private void adjustFirstNonNullElement() {\n+        int i = firstNonNullElementIdx;\n+        while (i < array.length && (array[i]) == null) {\n+            i++;\n+        }\n+        if (i < array.length) {\n+            firstNonNullElementIdx = i;\n+        } else {\n+            firstNonNullElementIdx = -1;\n+        }\n+\n+    }\n     private Cell getCellForColumnQualifier(int columnQualifier) {\n         checkQualifierRange(columnQualifier);\n         int idx = getArrayIndex(columnQualifier);\n@@ -461,6 +466,10 @@ public void remove() {\n             }\n             checkForCoModification();\n             array[lastRet] = null;\n+            if (firstNonNullElementIdx == lastRet) {\n+                // the element being removed was the first non-null element we knew\n+                adjustFirstNonNullElement();\n+            }\n             lastRet = -1;\n             numNonNullElements--;\n             modCount++;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/tuple/EncodedColumnQualiferCellsList.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/d9308c56b53d4008ba791cf87d3111c21accc422", "parent": "https://github.com/apache/phoenix/commit/0a554fcfb6a181f681a1d9d3c221b4d1f62ad850", "message": "PHOENIX-4733 NPE while running sql through file using psql", "bug_id": "phoenix_7", "file": [{"additions": 17, "raw_url": "https://github.com/apache/phoenix/raw/d9308c56b53d4008ba791cf87d3111c21accc422/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/d9308c56b53d4008ba791cf87d3111c21accc422/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "sha": "d5c48782cb71bf014a71c2b36f790cda984b65fa", "changes": 24, "status": "modified", "deletions": 7, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java?ref=d9308c56b53d4008ba791cf87d3111c21accc422", "patch": "@@ -30,10 +30,14 @@\n \n public class QueryLoggerUtil {\n \n-    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId,\n-            ConnectionQueryServices queryServices, String query, long startTime, List<Object> bindParameters) {\n-        queryLogger.log(QueryLogState.STARTED,\n-                getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n+    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId, ConnectionQueryServices queryServices,\n+            String query, long startTime, List<Object> bindParameters) {\n+        try {\n+            queryLogger.log(QueryLogState.STARTED,\n+                    getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n+        } catch (Exception e) {\n+            // Ignore for now\n+        }\n \n     }\n \n@@ -46,15 +50,21 @@ public static void logInitialDetails(QueryLogger queryLogger, PName tenantId,\n         } catch (UnknownHostException e) {\n             clientIP = \"UnknownHost\";\n         }\n-        queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n-        queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n+\n+        if (clientIP != null) {\n+            queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n+        }\n+        if (query != null) {\n+            queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n+        }\n         queryLogBuilder.put(QueryLogInfo.START_TIME_I, startTime);\n         if (bindParameters != null) {\n-            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters,\",\"));\n+            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters, \",\"));\n         }\n         if (tenantId != null) {\n             queryLogBuilder.put(QueryLogInfo.TENANT_ID_I, tenantId.getString());\n         }\n+\n         queryLogBuilder.put(QueryLogInfo.USER_I, queryServices.getUserName() != null ? queryServices.getUserName()\n                 : queryServices.getUser().getShortName());\n         return queryLogBuilder.build();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/a83afc4a6dc1500400890c263ceaae896fe04f55", "parent": "https://github.com/apache/phoenix/commit/ff0b8089d8c15154cbe875a535c33a62d72fe26a", "message": "NPE while running sql through file using psql", "bug_id": "phoenix_8", "file": [{"additions": 17, "raw_url": "https://github.com/apache/phoenix/raw/a83afc4a6dc1500400890c263ceaae896fe04f55/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/a83afc4a6dc1500400890c263ceaae896fe04f55/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "sha": "d5c48782cb71bf014a71c2b36f790cda984b65fa", "changes": 24, "status": "modified", "deletions": 7, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java?ref=a83afc4a6dc1500400890c263ceaae896fe04f55", "patch": "@@ -30,10 +30,14 @@\n \n public class QueryLoggerUtil {\n \n-    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId,\n-            ConnectionQueryServices queryServices, String query, long startTime, List<Object> bindParameters) {\n-        queryLogger.log(QueryLogState.STARTED,\n-                getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n+    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId, ConnectionQueryServices queryServices,\n+            String query, long startTime, List<Object> bindParameters) {\n+        try {\n+            queryLogger.log(QueryLogState.STARTED,\n+                    getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n+        } catch (Exception e) {\n+            // Ignore for now\n+        }\n \n     }\n \n@@ -46,15 +50,21 @@ public static void logInitialDetails(QueryLogger queryLogger, PName tenantId,\n         } catch (UnknownHostException e) {\n             clientIP = \"UnknownHost\";\n         }\n-        queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n-        queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n+\n+        if (clientIP != null) {\n+            queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n+        }\n+        if (query != null) {\n+            queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n+        }\n         queryLogBuilder.put(QueryLogInfo.START_TIME_I, startTime);\n         if (bindParameters != null) {\n-            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters,\",\"));\n+            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters, \",\"));\n         }\n         if (tenantId != null) {\n             queryLogBuilder.put(QueryLogInfo.TENANT_ID_I, tenantId.getString());\n         }\n+\n         queryLogBuilder.put(QueryLogInfo.USER_I, queryServices.getUserName() != null ? queryServices.getUserName()\n                 : queryServices.getUser().getShortName());\n         return queryLogBuilder.build();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/0a554fcfb6a181f681a1d9d3c221b4d1f62ad850", "parent": "https://github.com/apache/phoenix/commit/a83afc4a6dc1500400890c263ceaae896fe04f55", "message": "Revert \"NPE while running sql through file using psql\"\n\nNeeds a JIRA number\nThis reverts commit a83afc4a6dc1500400890c263ceaae896fe04f55.", "bug_id": "phoenix_9", "file": [{"additions": 7, "raw_url": "https://github.com/apache/phoenix/raw/0a554fcfb6a181f681a1d9d3c221b4d1f62ad850/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/0a554fcfb6a181f681a1d9d3c221b4d1f62ad850/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java", "sha": "2f22931acd2309c0d72c56ac508dc01b8ca6a163", "changes": 24, "status": "modified", "deletions": 17, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java?ref=0a554fcfb6a181f681a1d9d3c221b4d1f62ad850", "patch": "@@ -30,14 +30,10 @@\n \n public class QueryLoggerUtil {\n \n-    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId, ConnectionQueryServices queryServices,\n-            String query, long startTime, List<Object> bindParameters) {\n-        try {\n-            queryLogger.log(QueryLogState.STARTED,\n-                    getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n-        } catch (Exception e) {\n-            // Ignore for now\n-        }\n+    public static void logInitialDetails(QueryLogger queryLogger, PName tenantId,\n+            ConnectionQueryServices queryServices, String query, long startTime, List<Object> bindParameters) {\n+        queryLogger.log(QueryLogState.STARTED,\n+                getInitialDetails(tenantId, queryServices, query, startTime, bindParameters));\n \n     }\n \n@@ -50,21 +46,15 @@ public static void logInitialDetails(QueryLogger queryLogger, PName tenantId, Co\n         } catch (UnknownHostException e) {\n             clientIP = \"UnknownHost\";\n         }\n-\n-        if (clientIP != null) {\n-            queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n-        }\n-        if (query != null) {\n-            queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n-        }\n+        queryLogBuilder.put(QueryLogInfo.CLIENT_IP_I, clientIP);\n+        queryLogBuilder.put(QueryLogInfo.QUERY_I, query);\n         queryLogBuilder.put(QueryLogInfo.START_TIME_I, startTime);\n         if (bindParameters != null) {\n-            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters, \",\"));\n+            queryLogBuilder.put(QueryLogInfo.BIND_PARAMETERS_I, StringUtils.join(bindParameters,\",\"));\n         }\n         if (tenantId != null) {\n             queryLogBuilder.put(QueryLogInfo.TENANT_ID_I, tenantId.getString());\n         }\n-\n         queryLogBuilder.put(QueryLogInfo.USER_I, queryServices.getUserName() != null ? queryServices.getUserName()\n                 : queryServices.getUser().getShortName());\n         return queryLogBuilder.build();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/log/QueryLoggerUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/2689b0a4598b2c8ac3ed1addf221208769c4fab2", "parent": "https://github.com/apache/phoenix/commit/0bcf1227b28085c90625092728174f1f8a5427cc", "message": "PHOENIX-4662 Avoid NPE when server-caches are null (Csaba Skrabak)", "bug_id": "phoenix_10", "file": [{"additions": 5, "raw_url": "https://github.com/apache/phoenix/raw/2689b0a4598b2c8ac3ed1addf221208769c4fab2/phoenix-core/src/main/java/org/apache/phoenix/iterate/TableResultIterator.java", "blob_url": "https://github.com/apache/phoenix/blob/2689b0a4598b2c8ac3ed1addf221208769c4fab2/phoenix-core/src/main/java/org/apache/phoenix/iterate/TableResultIterator.java", "sha": "92903c7cd5d7966858259e8a67b166f97e172fc0", "changes": 7, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/TableResultIterator.java?ref=2689b0a4598b2c8ac3ed1addf221208769c4fab2", "patch": "@@ -198,9 +198,12 @@ public Tuple next() throws SQLException {\n \t\t\t\t\t\t\tretry--;\n \t\t\t\t\t\t\ttry {\n \t\t\t\t\t\t\t\tLong cacheId = ((HashJoinCacheNotFoundException) e1).getCacheId();\n+\n+\t\t\t\t\t\t\t\tServerCache cache = caches == null ? null :\n+\t\t\t\t\t\t\t\t\t\tcaches.get(new ImmutableBytesPtr(Bytes.toBytes(cacheId)));\n+\n \t\t\t\t\t\t\t\tif (!hashCacheClient.addHashCacheToServer(newScan.getStartRow(),\n-\t\t\t\t\t\t\t\t\t\tcaches.get(new ImmutableBytesPtr(Bytes.toBytes(cacheId))),\n-\t\t\t\t\t\t\t\t\t\tplan.getTableRef().getTable())) {\n+\t\t\t\t\t\t\t\t\t\tcache, plan.getTableRef().getTable())) {\n \t\t\t\t\t\t\t\t\tthrow e1;\n \t\t\t\t\t\t\t\t}\n \t\t\t\t\t\t\t\tthis.scanIterator = ((BaseQueryPlan) plan).iterator(caches, scanGrouper, newScan);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/TableResultIterator.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/b4ccdd2c97494b3ce40f2594e48baecd0e72bf31", "parent": "https://github.com/apache/phoenix/commit/2af8aaf6be3048cd9e08e79ca7763654af189885", "message": "PHOENIX-4495 Fix possible NPE/ClassCastException in Stats IT tests(Rajeshbabu)", "bug_id": "phoenix_11", "file": [{"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/b4ccdd2c97494b3ce40f2594e48baecd0e72bf31/phoenix-core/src/it/java/org/apache/phoenix/schema/stats/StatsCollectorIT.java", "blob_url": "https://github.com/apache/phoenix/blob/b4ccdd2c97494b3ce40f2594e48baecd0e72bf31/phoenix-core/src/it/java/org/apache/phoenix/schema/stats/StatsCollectorIT.java", "sha": "f7a2edda61247cb72b56c67b600f9e98dea2ea94", "changes": 5, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/schema/stats/StatsCollectorIT.java?ref=b4ccdd2c97494b3ce40f2594e48baecd0e72bf31", "patch": "@@ -824,9 +824,8 @@ private DefaultStatisticsCollector getDefaultStatsCollectorForTable(String table\n \n     private RegionCoprocessorEnvironment getRegionEnvrionment(String tableName)\n             throws IOException, InterruptedException {\n-        return getUtility()\n-                .getRSForFirstRegionInTable(TableName.valueOf(tableName))\n-                .getOnlineRegionsLocalContext().iterator().next().getCoprocessorHost()\n+        return getUtility().getMiniHBaseCluster().getRegions(TableName.valueOf(tableName)).get(0)\n+                .getCoprocessorHost()\n                 .findCoprocessorEnvironment(UngroupedAggregateRegionObserver.class.getName());\n     }\n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/schema/stats/StatsCollectorIT.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/119f86e0c29ed6331df35028d37f6964393f122b", "parent": "https://github.com/apache/phoenix/commit/aaa41a33d025ad6daa832fe8b42fc235e7154648", "message": "PHOENIX-4265 NPE when ROW_TIMESTAMP is SQL timestamp column", "bug_id": "phoenix_12", "file": [{"additions": 66, "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "sha": "275d72dc31ddb1ba2088849e90cd831ff36dd0a1", "changes": 66, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=119f86e0c29ed6331df35028d37f6964393f122b", "patch": "@@ -42,10 +42,12 @@\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n import java.sql.SQLException;\n+import java.sql.Timestamp;\n import java.util.Properties;\n \n import org.apache.phoenix.compile.QueryPlan;\n import org.apache.phoenix.exception.SQLExceptionCode;\n+import org.apache.phoenix.jdbc.PhoenixResultSet;\n import org.apache.phoenix.jdbc.PhoenixStatement;\n import org.apache.phoenix.query.QueryConstants;\n import org.apache.phoenix.query.QueryServices;\n@@ -1420,6 +1422,70 @@ public void testParallelUpsertSelect() throws Exception {\n         conn.close();\n     }\n \n+    @Test // See https://issues.apache.org/jira/browse/PHOENIX-4265\n+    public void testLongCodecUsedForRowTimestamp() throws Exception {\n+        String tableName = generateUniqueName();\n+        String indexName = generateUniqueName();\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.createStatement().execute(\"CREATE IMMUTABLE TABLE \" + tableName\n+                    + \" (k1 TIMESTAMP not null, k2 bigint not null, v bigint, constraint pk primary key (k1 row_timestamp, k2)) SALT_BUCKETS = 9\");\n+            conn.createStatement().execute(\n+                \"CREATE INDEX \" + indexName + \" ON \" + tableName + \" (v) INCLUDE (k2)\");\n+            PreparedStatement stmt =\n+                    conn.prepareStatement(\"UPSERT INTO \" + tableName + \" VALUES (?, ?, ?) \");\n+            stmt.setTimestamp(1, new Timestamp(1000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 1000);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(2000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(3000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(4000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(5000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 10);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(6000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 20);\n+            stmt.executeUpdate();\n+            conn.commit();\n+            ResultSet rs = conn.createStatement().executeQuery(\"SELECT \" +\n+                    \" K2 FROM \" + tableName + \" WHERE V = 5\");\n+            assertTrue(\"Index \" + indexName + \" should have been used\",\n+                rs.unwrap(PhoenixResultSet.class).getStatement().getQueryPlan().getTableRef()\n+                        .getTable().getName().getString().equals(indexName));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertFalse(rs.next());\n+            rs =\n+                    conn.createStatement().executeQuery(\"SELECT /*+ INDEX(\" + tableName + \" \"\n+                            + indexName + \") */ \" + \" K2 FROM \" + tableName + \" WHERE V = 5\");\n+            assertTrue(\"Index \" + indexName + \" should have been used\",\n+                rs.unwrap(PhoenixResultSet.class).getStatement().getQueryPlan().getTableRef()\n+                        .getTable().getName().getString().equals(indexName));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertFalse(rs.next());\n+        }\n+    }\n+\n     private static Connection getTenantConnection(String tenantId) throws Exception {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(TENANT_ID_ATTRIB, tenantId);", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java"}, {"additions": 9, "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java", "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java", "sha": "79bf3b9d8b20faffc366002d0d6033ffe7ff9f17", "changes": 14, "status": "modified", "deletions": 5, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java?ref=119f86e0c29ed6331df35028d37f6964393f122b", "patch": "@@ -41,7 +41,10 @@\n import org.apache.phoenix.schema.SaltingUtil;\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.ValueSchema.Field;\n+import org.apache.phoenix.schema.types.PDataType.PDataCodec;\n+import org.apache.phoenix.schema.types.PLong;\n import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.util.DateUtil;\n import org.apache.phoenix.util.ScanUtil;\n import org.apache.phoenix.util.ScanUtil.BytesComparator;\n import org.apache.phoenix.util.SchemaUtil;\n@@ -668,16 +671,17 @@ private static TimeRange getAscTimeRange(KeyRange lowestRange, KeyRange highestR\n             throws IOException {\n         long low;\n         long high;\n+        PDataCodec codec = PLong.INSTANCE.getCodec();\n         if (lowestRange.lowerUnbound()) {\n             low = 0;\n         } else {\n-            long lowerRange = f.getDataType().getCodec().decodeLong(lowestRange.getLowerRange(), 0, SortOrder.ASC);\n+            long lowerRange = codec.decodeLong(lowestRange.getLowerRange(), 0, SortOrder.ASC);\n             low = lowestRange.isLowerInclusive() ? lowerRange : safelyIncrement(lowerRange);\n         }\n         if (highestRange.upperUnbound()) {\n             high = HConstants.LATEST_TIMESTAMP;\n         } else {\n-            long upperRange = f.getDataType().getCodec().decodeLong(highestRange.getUpperRange(), 0, SortOrder.ASC);\n+            long upperRange = codec.decodeLong(highestRange.getUpperRange(), 0, SortOrder.ASC);\n             if (highestRange.isUpperInclusive()) {\n                 high = safelyIncrement(upperRange);\n             } else {\n@@ -692,9 +696,9 @@ public static TimeRange getDescTimeRange(KeyRange lowestKeyRange, KeyRange highe\n         boolean lowerInclusive = lowestKeyRange.isLowerInclusive();\n         boolean upperUnbound = highestKeyRange.upperUnbound();\n         boolean upperInclusive = highestKeyRange.isUpperInclusive();\n-\n-        long low = lowerUnbound ? -1 : f.getDataType().getCodec().decodeLong(lowestKeyRange.getLowerRange(), 0, SortOrder.DESC);\n-        long high = upperUnbound ? -1 : f.getDataType().getCodec().decodeLong(highestKeyRange.getUpperRange(), 0, SortOrder.DESC);\n+        PDataCodec codec = PLong.INSTANCE.getCodec();\n+        long low = lowerUnbound ? -1 : codec.decodeLong(lowestKeyRange.getLowerRange(), 0, SortOrder.DESC);\n+        long high = upperUnbound ? -1 : codec.decodeLong(highestKeyRange.getUpperRange(), 0, SortOrder.DESC);\n         long newHigh;\n         long newLow;\n         if (!lowerUnbound && !upperUnbound) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java"}, {"additions": 5, "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java", "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java", "sha": "0402c6e92cb49e49a60e11f5d54cb91088d8a612", "changes": 6, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java?ref=119f86e0c29ed6331df35028d37f6964393f122b", "patch": "@@ -230,7 +230,11 @@ public Object toObject(String value) {\n \n     @Override\n     public Object getSampleValue(Integer maxLength, Integer arrayLength) {\n-        return RANDOM.get().nextLong();\n+        long val = RANDOM.get().nextLong();\n+        if (val == Long.MIN_VALUE) {\n+            return Long.MAX_VALUE;\n+        }\n+        return Math.abs(val);\n     }\n \n     static class LongCodec extends BaseCodec {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/1c5caff2bd439a56fb065360799fb36651da0bba", "parent": "https://github.com/apache/phoenix/commit/c75d766bccb5cea6452bbbbb44a5939a14cf001c", "message": "PHOENIX-4409 Fix all IT tests failing with NPE in Encoded columns(Rajeshbabu)", "bug_id": "phoenix_13", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/1c5caff2bd439a56fb065360799fb36651da0bba/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java", "blob_url": "https://github.com/apache/phoenix/blob/1c5caff2bd439a56fb065360799fb36651da0bba/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java", "sha": "a3d219f6506c2e4b7badc3065a25dc9120ee779c", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java?ref=1c5caff2bd439a56fb065360799fb36651da0bba", "patch": "@@ -307,7 +307,7 @@ public static void serializeIntoScan(Scan scan) {\n     @Override\n     public void preScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext<RegionCoprocessorEnvironment> c,\n             Scan scan) throws IOException {\n-    \n+        super.preScannerOpen(c, scan);\n         if (ScanUtil.isAnalyzeTable(scan)) {\n             // We are setting the start row and stop row such that it covers the entire region. As part\n             // of Phonenix-1263 we are storing the guideposts against the physical table rather than", "filename": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/d762c6a83e8260297fd8d6afcb51bc1c49dce23f", "parent": "https://github.com/apache/phoenix/commit/1e74895ad83dfe1ada90897f95fb5c93e2cc8eee", "message": "PHOENIX-4072 Prevent NPE for PreparedStatement.setObject of null", "bug_id": "phoenix_14", "file": [{"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/d762c6a83e8260297fd8d6afcb51bc1c49dce23f/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java", "blob_url": "https://github.com/apache/phoenix/blob/d762c6a83e8260297fd8d6afcb51bc1c49dce23f/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java", "sha": "71ecb8d3c56d4dac7689ad101a3ca1e9007f51ed", "changes": 6, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java?ref=d762c6a83e8260297fd8d6afcb51bc1c49dce23f", "patch": "@@ -444,8 +444,10 @@ public void setObject(int parameterIndex, Object o) throws SQLException {\n     @Override\n     public void setObject(int parameterIndex, Object o, int targetSqlType) throws SQLException {\n         PDataType targetType = PDataType.fromTypeId(targetSqlType);\n-        PDataType sourceType = PDataType.fromLiteral(o);\n-        o = targetType.toObject(o, sourceType);\n+        if (o != null) {\n+            PDataType sourceType = PDataType.fromLiteral(o);\n+            o = targetType.toObject(o, sourceType);\n+        }\n         setParameter(parameterIndex, o);\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/53910f9f88cd47f51f68691042306c89118b6ab3", "parent": "https://github.com/apache/phoenix/commit/0461fe855aaed27e23cb5d17e8be022a82626162", "message": "PHOENIX-4242 Fix Indexer post-compact hook logging of NPE and TableNotFound", "bug_id": "phoenix_15", "file": [{"additions": 171, "raw_url": "https://github.com/apache/phoenix/raw/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/it/java/org/apache/phoenix/end2end/UngroupedAggregateRegionObserverIT.java", "blob_url": "https://github.com/apache/phoenix/blob/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/it/java/org/apache/phoenix/end2end/UngroupedAggregateRegionObserverIT.java", "sha": "3efd40e5a2ce83c3e86f175b4929cb844450ddef", "changes": 171, "status": "added", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UngroupedAggregateRegionObserverIT.java?ref=53910f9f88cd47f51f68691042306c89118b6ab3", "patch": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.never;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+\n+import org.apache.hadoop.hbase.HBaseTestingUtility;\n+import org.apache.log4j.Appender;\n+import org.apache.log4j.Level;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.spi.LoggingEvent;\n+import org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver;\n+import org.apache.phoenix.jdbc.PhoenixConnection;\n+import org.apache.phoenix.schema.PIndexState;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.IndexUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.Mockito;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class UngroupedAggregateRegionObserverIT extends ParallelStatsDisabledIT {\n+\n+    private String dataTableName;\n+    private String indexTableName;\n+    private String schemaName;\n+    private String dataTableFullName;\n+    private static String indexTableFullName;\n+\n+    @Mock\n+    private Appender mockAppender;\n+\n+    @Captor\n+    private ArgumentCaptor<LoggingEvent> captorLoggingEvent;\n+    private UngroupedAggregateRegionObserver ungroupedObserver;\n+\n+    @Before\n+    public void setup() {\n+        ungroupedObserver = new UngroupedAggregateRegionObserver();\n+        ungroupedObserver.setCompactionConfig(PropertiesUtil.cloneConfig(config));\n+    }\n+\n+    /**\n+     * Tests the that post compact hook doesn't log any NPE for a System table\n+     */\n+    @Test\n+    public void testPostCompactSystemSequence() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            startCapturingIndexLog();\n+            // run the post-compact hook\n+            ungroupedObserver.clearTsOnDisabledIndexes(\"SYSTEM.SEQUENCE\");\n+            stopCapturingIndexLog();\n+            // uneventful - nothing should be logged\n+            Mockito.verify(mockAppender, never())\n+                    .doAppend((LoggingEvent) captorLoggingEvent.capture());\n+        }\n+    }\n+\n+    /**\n+     * Tests that calling the post compact hook on the data table permanently disables an index that\n+     * is being rebuilt (i.e. already disabled or inactive)\n+     */\n+    @Test\n+    public void testPostCompactDataTableDuringRebuild() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            generateUniqueTableNames();\n+            testRebuildPostCompact(conn, dataTableFullName);\n+        }\n+    }\n+\n+    /**\n+     * Tests that calling the post compact hook on the index table permanently disables an index\n+     * that is being rebuilt (i.e. already disabled or inactive)\n+     */\n+    @Test\n+    public void testPostCompactIndexTableDuringRebuild() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            generateUniqueTableNames();\n+            testRebuildPostCompact(conn, indexTableFullName);\n+        }\n+    }\n+\n+    private void testRebuildPostCompact(Connection conn, String tableToCompact)\n+            throws SQLException {\n+        conn.createStatement().execute(\n+            String.format(PartialScannerResultsDisabledIT.TEST_TABLE_DDL, dataTableFullName));\n+        conn.createStatement().execute(String.format(PartialScannerResultsDisabledIT.INDEX_1_DDL,\n+            indexTableName, dataTableFullName));\n+        // disable the index, simulating an index write failure\n+        PhoenixConnection pConn = conn.unwrap(PhoenixConnection.class);\n+        IndexUtil.updateIndexState(pConn, indexTableFullName, PIndexState.DISABLE,\n+            EnvironmentEdgeManager.currentTimeMillis());\n+\n+        // run the post-compact hook on the data table\n+        startCapturingIndexLog();\n+        ungroupedObserver.clearTsOnDisabledIndexes(tableToCompact);\n+        stopCapturingIndexLog();\n+        // an event should've been logged\n+        Mockito.verify(mockAppender).doAppend((LoggingEvent) captorLoggingEvent.capture());\n+        LoggingEvent loggingEvent = (LoggingEvent) captorLoggingEvent.getValue();\n+        assertThat(loggingEvent.getLevel(), is(Level.INFO));\n+        // index should be permanently disabled (disabletime of 0)\n+        assertTrue(TestUtil.checkIndexState(pConn, indexTableFullName, PIndexState.DISABLE, 0L));\n+    }\n+\n+    /**\n+     * Tests that a non-Phoenix table (created purely through HBase) doesn't log a warning in\n+     * postCompact\n+     */\n+    @Test\n+    public void testPostCompactTableNotFound() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            HBaseTestingUtility utility = getUtility();\n+            String nonPhoenixTable = \"NOT_A_PHOENIX_TABLE\";\n+            utility.getHBaseAdmin().createTable(utility.createTableDescriptor(nonPhoenixTable));\n+            startCapturingIndexLog();\n+            ungroupedObserver.clearTsOnDisabledIndexes(nonPhoenixTable);\n+            stopCapturingIndexLog();\n+            // a debug level event should've been logged\n+            Mockito.verify(mockAppender).doAppend((LoggingEvent) captorLoggingEvent.capture());\n+            LoggingEvent loggingEvent = (LoggingEvent) captorLoggingEvent.getValue();\n+            assertThat(loggingEvent.getLevel(), is(Level.DEBUG));\n+        }\n+    }\n+\n+    private void stopCapturingIndexLog() {\n+        LogManager.getLogger(UngroupedAggregateRegionObserver.class).removeAppender(mockAppender);\n+    }\n+\n+    private void startCapturingIndexLog() {\n+        LogManager.getLogger(UngroupedAggregateRegionObserver.class).addAppender(mockAppender);\n+    }\n+\n+    private void generateUniqueTableNames() {\n+        schemaName = generateUniqueName();\n+        dataTableName = generateUniqueName() + \"_DATA\";\n+        dataTableFullName = SchemaUtil.getTableName(schemaName, dataTableName);\n+        indexTableName = generateUniqueName() + \"_IDX\";\n+        indexTableFullName = SchemaUtil.getTableName(schemaName, indexTableName);\n+    }\n+}", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UngroupedAggregateRegionObserverIT.java"}, {"additions": 65, "raw_url": "https://github.com/apache/phoenix/raw/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java", "blob_url": "https://github.com/apache/phoenix/blob/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java", "sha": "af50420c94eaaa854f46561827a823482f50a5a4", "changes": 103, "status": "modified", "deletions": 38, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java?ref=53910f9f88cd47f51f68691042306c89118b6ab3", "patch": "@@ -97,6 +97,7 @@\n import org.apache.phoenix.hbase.index.util.KeyValueBuilder;\n import org.apache.phoenix.index.IndexMaintainer;\n import org.apache.phoenix.index.PhoenixIndexCodec;\n+import org.apache.phoenix.jdbc.PhoenixConnection;\n import org.apache.phoenix.jdbc.PhoenixDatabaseMetaData;\n import org.apache.phoenix.join.HashJoinInfo;\n import org.apache.phoenix.query.QueryConstants;\n@@ -108,8 +109,10 @@\n import org.apache.phoenix.schema.PRow;\n import org.apache.phoenix.schema.PTable;\n import org.apache.phoenix.schema.PTableImpl;\n+import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.schema.RowKeySchema;\n import org.apache.phoenix.schema.SortOrder;\n+import org.apache.phoenix.schema.TableNotFoundException;\n import org.apache.phoenix.schema.TableRef;\n import org.apache.phoenix.schema.ValueSchema.Field;\n import org.apache.phoenix.schema.stats.StatisticsCollectionRunTracker;\n@@ -133,7 +136,10 @@\n import org.apache.phoenix.util.IndexUtil;\n import org.apache.phoenix.util.KeyValueUtil;\n import org.apache.phoenix.util.LogUtil;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PhoenixRuntime;\n import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.QueryUtil;\n import org.apache.phoenix.util.ScanUtil;\n import org.apache.phoenix.util.SchemaUtil;\n import org.apache.phoenix.util.ServerUtil;\n@@ -142,7 +148,10 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Predicate;\n import com.google.common.base.Throwables;\n+import com.google.common.collect.Iterables;\n import com.google.common.collect.Lists;\n import com.google.common.collect.Sets;\n import com.google.common.primitives.Ints;\n@@ -926,7 +935,7 @@ public InternalScanner run() throws Exception {\n     }\n \n     @Override\n-    public void postCompact(final ObserverContext<RegionCoprocessorEnvironment> e, final Store store,\n+    public void postCompact(final ObserverContext<RegionCoprocessorEnvironment> c, final Store store,\n             final StoreFile resultFile, CompactionRequest request) throws IOException {\n         // If we're compacting all files, then delete markers are removed\n         // and we must permanently disable an index that needs to be\n@@ -940,49 +949,67 @@ public void postCompact(final ObserverContext<RegionCoprocessorEnvironment> e, f\n             User.runAsLoginUser(new PrivilegedExceptionAction<Void>() {\n                 @Override\n                 public Void run() throws Exception {\n-                    MutationCode mutationCode = null;\n-                    long disableIndexTimestamp = 0;\n-\n-                    try (CoprocessorHConnection coprocessorHConnection =\n-                            new CoprocessorHConnection(compactionConfig,\n-                                    (HRegionServer) e.getEnvironment()\n-                                            .getRegionServerServices());\n-                            HTableInterface htable =\n-                                    coprocessorHConnection\n-                                            .getTable(SchemaUtil.getPhysicalTableName(\n-                                                PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME_BYTES,\n-                                                compactionConfig))) {\n-                        String tableName = e.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();\n-                        // FIXME: if this is an index on a view, we won't find a row for it in SYSTEM.CATALOG\n-                        // Instead, we need to disable all indexes on the view.\n-                        byte[] tableKey = SchemaUtil.getTableKeyFromFullName(tableName);\n-                        Get get = new Get(tableKey);\n-                        get.addColumn(PhoenixDatabaseMetaData.TABLE_FAMILY_BYTES, PhoenixDatabaseMetaData.INDEX_DISABLE_TIMESTAMP_BYTES);\n-                        Result result = htable.get(get);\n-                        if (!result.isEmpty()) {\n-                            Cell cell = result.listCells().get(0);\n-                            if (cell.getValueLength() > 0) {\n-                                disableIndexTimestamp = PLong.INSTANCE.getCodec().decodeLong(cell.getValueArray(), cell.getValueOffset(), SortOrder.getDefault());\n-                                if (disableIndexTimestamp != 0) {\n-                                    logger.info(\"Major compaction running while index on table is disabled.  Clearing index disable timestamp: \" + tableName);\n-                                    mutationCode = IndexUtil.updateIndexState(tableKey, 0L, htable, PIndexState.DISABLE).getMutationCode();\n-                                }\n-                            }\n-                        }\n-                    } catch (Throwable t) { // log, but swallow exception as we don't want to impact compaction\n-                        logger.warn(\"Potential failure to permanently disable index during compaction \" +  e.getEnvironment().getRegionInfo().getTable().getNameAsString(), t);\n-                    } finally {\n-                        if (disableIndexTimestamp != 0 && mutationCode != MutationCode.TABLE_ALREADY_EXISTS && mutationCode != MutationCode.TABLE_NOT_FOUND) {\n-                            logger.warn(\"Attempt to permanently disable index \" + e.getEnvironment().getRegionInfo().getTable().getNameAsString() + \n-                                    \" during compaction\" + (mutationCode == null ? \"\" : \" failed with code = \" + mutationCode));\n-                        }\n-                    }\n+                    String fullTableName = c.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();\n+                    clearTsOnDisabledIndexes(fullTableName);\n                     return null;\n                 }\n             });\n         }\n     }\n \n+    @VisibleForTesting\n+    public void clearTsOnDisabledIndexes(final String fullTableName) {\n+        try (PhoenixConnection conn =\n+                QueryUtil.getConnectionOnServer(compactionConfig).unwrap(PhoenixConnection.class)) {\n+            String baseTable = fullTableName;\n+            PTable table = PhoenixRuntime.getTableNoCache(conn, baseTable);\n+            List<PTable> indexes;\n+            // if it's an index table, we just need to check if it's disabled\n+            if (PTableType.INDEX.equals(table.getType())) {\n+                indexes = Lists.newArrayList(table.getIndexes());\n+                indexes.add(table);\n+            } else {\n+                // for a data table, check all its indexes\n+                indexes = table.getIndexes();\n+            }\n+            // FIXME need handle views and indexes on views as well\n+            // if any index is disabled, we won't have all the data for a rebuild after compaction\n+            for (PTable index : indexes) {\n+                if (index.getIndexDisableTimestamp() != 0) {\n+                    try {\n+                        logger.info(\n+                            \"Major compaction running while index on table is disabled.  Clearing index disable timestamp: \"\n+                                    + index);\n+                        IndexUtil.updateIndexState(conn, index.getName().getString(),\n+                            PIndexState.DISABLE, Long.valueOf(0L));\n+                    } catch (SQLException e) {\n+                        logger.warn(\n+                            \"Unable to permanently disable index \" + index.getName().getString(),\n+                            e);\n+                    }\n+                }\n+            }\n+        } catch (Exception e) {\n+            if (e instanceof TableNotFoundException) {\n+                logger.debug(\"Ignoring HBase table that is not a Phoenix table: \" + fullTableName);\n+                // non-Phoenix HBase tables won't be found, do nothing\n+                return;\n+            }\n+            // If we can't reach the stats table, don't interrupt the normal\n+            // compaction operation, just log a warning.\n+            if (logger.isWarnEnabled()) {\n+                logger.warn(\"Unable to permanently disable indexes being partially rebuild for \"\n+                        + fullTableName,\n+                    e);\n+            }\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public void setCompactionConfig(Configuration compactionConfig) {\n+        this.compactionConfig = compactionConfig;\n+    }\n+\n     private static PTable deserializeTable(byte[] b) {\n         try {\n             PTableProtos.PTable ptableProto = PTableProtos.PTable.parseFrom(b);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java"}, {"additions": 0, "raw_url": "https://github.com/apache/phoenix/raw/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/Indexer.java", "blob_url": "https://github.com/apache/phoenix/blob/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/Indexer.java", "sha": "24eeab5ae34efd49ba1d1226eb2be32eb33d1a04", "changes": 52, "status": "modified", "deletions": 52, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/Indexer.java?ref=53910f9f88cd47f51f68691042306c89118b6ab3", "patch": "@@ -25,7 +25,6 @@\n \n import java.io.IOException;\n import java.security.PrivilegedExceptionAction;\n-import java.sql.SQLException;\n import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n@@ -63,8 +62,6 @@\n import org.apache.hadoop.hbase.regionserver.Region;\n import org.apache.hadoop.hbase.regionserver.ScanType;\n import org.apache.hadoop.hbase.regionserver.Store;\n-import org.apache.hadoop.hbase.regionserver.StoreFile;\n-import org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest;\n import org.apache.hadoop.hbase.regionserver.wal.HLogKey;\n import org.apache.hadoop.hbase.regionserver.wal.WALEdit;\n import org.apache.hadoop.hbase.security.User;\n@@ -90,18 +87,12 @@\n import org.apache.phoenix.hbase.index.write.RecoveryIndexWriter;\n import org.apache.phoenix.hbase.index.write.recovery.PerRegionIndexWriteCache;\n import org.apache.phoenix.hbase.index.write.recovery.StoreFailuresInCachePolicy;\n-import org.apache.phoenix.jdbc.PhoenixConnection;\n import org.apache.phoenix.query.QueryServices;\n import org.apache.phoenix.query.QueryServicesOptions;\n-import org.apache.phoenix.schema.PIndexState;\n-import org.apache.phoenix.schema.PTable;\n import org.apache.phoenix.trace.TracingUtils;\n import org.apache.phoenix.trace.util.NullSpan;\n import org.apache.phoenix.util.EnvironmentEdgeManager;\n-import org.apache.phoenix.util.IndexUtil;\n-import org.apache.phoenix.util.PhoenixRuntime;\n import org.apache.phoenix.util.PropertiesUtil;\n-import org.apache.phoenix.util.QueryUtil;\n import org.apache.phoenix.util.ServerUtil;\n \n import com.google.common.collect.Lists;\n@@ -840,48 +831,5 @@ public static void enableIndexing(HTableDescriptor desc, Class<? extends IndexBu\n     properties.put(Indexer.INDEX_BUILDER_CONF_KEY, builder.getName());\n     desc.addCoprocessor(Indexer.class.getName(), null, priority, properties);\n   }\n-  \n-  @Override\n-  public void postCompact(final ObserverContext<RegionCoprocessorEnvironment> c, final Store store,\n-          final StoreFile resultFile, CompactionRequest request) throws IOException {\n-      // If we're compacting all files, then delete markers are removed\n-      // and we must permanently disable an index that needs to be\n-      // partially rebuild because we're potentially losing the information\n-      // we need to successfully rebuilt it.\n-      if (request.isAllFiles() || request.isMajor()) {\n-          // Compaction and split upcalls run with the effective user context of the requesting user.\n-          // This will lead to failure of cross cluster RPC if the effective user is not\n-          // the login user. Switch to the login user context to ensure we have the expected\n-          // security context.\n-          User.runAsLoginUser(new PrivilegedExceptionAction<Void>() {\n-              @Override\n-              public Void run() throws Exception {\n-                  String fullTableName = c.getEnvironment().getRegion().getRegionInfo().getTable().getNameAsString();\n-                  try {\n-                      PhoenixConnection conn =  QueryUtil.getConnectionOnServer(compactionConfig).unwrap(PhoenixConnection.class);\n-                      PTable table = PhoenixRuntime.getTableNoCache(conn, fullTableName);\n-                      // FIXME: we may need to recurse into children of this table too\n-                      for (PTable index : table.getIndexes()) {\n-                          if (index.getIndexDisableTimestamp() != 0) {\n-                              try {\n-                                  LOG.info(\"Major compaction running while index on table is disabled.  Clearing index disable timestamp: \" + fullTableName);\n-                                  IndexUtil.updateIndexState(conn, index.getName().getString(), PIndexState.DISABLE, Long.valueOf(0L));\n-                              } catch (SQLException e) {\n-                                  LOG.warn(\"Unable to permanently disable index \" + index.getName().getString(), e);\n-                              }\n-                          }\n-                      }\n-                  } catch (Exception e) {\n-                      // If we can't reach the stats table, don't interrupt the normal\n-                      // compaction operation, just log a warning.\n-                      if (LOG.isWarnEnabled()) {\n-                          LOG.warn(\"Unable to permanently disable indexes being partially rebuild for \" + fullTableName, e);\n-                      }\n-                  }\n-                  return null;\n-              }\n-          });\n-      }\n-  }\n }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/hbase/index/Indexer.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "blob_url": "https://github.com/apache/phoenix/blob/53910f9f88cd47f51f68691042306c89118b6ab3/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "sha": "0ce424697aceb35740c4a898236d2a8c24ef1437", "changes": 3, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java?ref=53910f9f88cd47f51f68691042306c89118b6ab3", "patch": "@@ -602,6 +602,9 @@ private MetaDataMutationResult updateCache(PName origTenantId, String schemaName\n             }\n \n             if (SYSTEM_CATALOG_SCHEMA.equals(schemaName)) {\n+                if (result.getMutationCode() == MutationCode.TABLE_ALREADY_EXISTS && result.getTable() == null) {\n+                    result.setTable(table);\n+                }\n                 return result;\n             }\n             MutationCode code = result.getMutationCode();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/f51c0db9f2d2ee261e602a114d47dd63353bbba8", "parent": "https://github.com/apache/phoenix/commit/5b099014446865c12779f3882fd8b407496717ea", "message": "PHOENIX-3800 NPE when doing UPSERT SELECT into salted tables", "bug_id": "phoenix_16", "file": [{"additions": 16, "raw_url": "https://github.com/apache/phoenix/raw/f51c0db9f2d2ee261e602a114d47dd63353bbba8/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "blob_url": "https://github.com/apache/phoenix/blob/f51c0db9f2d2ee261e602a114d47dd63353bbba8/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "sha": "1c04acbb9f8107d258b560ca0b3f047541c5e78c", "changes": 21, "status": "modified", "deletions": 5, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=f51c0db9f2d2ee261e602a114d47dd63353bbba8", "patch": "@@ -78,20 +78,31 @@ public static void doSetup() throws Exception {\n     \n     @Test\n     public void testUpsertSelectWithNoIndex() throws Exception {\n-        testUpsertSelect(false);\n+        testUpsertSelect(false, false);\n     }\n     \n     @Test\n     public void testUpsertSelecWithIndex() throws Exception {\n-        testUpsertSelect(true);\n+        testUpsertSelect(true, false);\n     }\n     \n-    private void testUpsertSelect(boolean createIndex) throws Exception {\n+    @Test\n+    public void testUpsertSelecWithIndexWithSalt() throws Exception {\n+        testUpsertSelect(true, true);\n+    }\n+\n+    @Test\n+    public void testUpsertSelecWithNoIndexWithSalt() throws Exception {\n+        testUpsertSelect(false, true);\n+    }\n+\n+    private void testUpsertSelect(boolean createIndex, boolean saltTable) throws Exception {\n         long ts = nextTimestamp();\n         String tenantId = getOrganizationId();\n-        initATableValues(ATABLE_NAME, tenantId, getDefaultSplits(tenantId), null, ts-1, getUrl(), null);\n+        byte[][] splits = getDefaultSplits(tenantId);\n+        initATableValues(ATABLE_NAME, tenantId, saltTable ? null : splits, null, ts-1, getUrl(), saltTable ? \"salt_buckets = 2\" : null);\n \n-        ensureTableCreated(getUrl(), CUSTOM_ENTITY_DATA_FULL_NAME, CUSTOM_ENTITY_DATA_FULL_NAME, ts-1);\n+        ensureTableCreated(getUrl(), CUSTOM_ENTITY_DATA_FULL_NAME, CUSTOM_ENTITY_DATA_FULL_NAME, null, ts-1, saltTable ? \"salt_buckets = 2\" : null);\n         String indexName = \"IDX1\";\n         if (createIndex) {\n             Properties props = new Properties();", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/f51c0db9f2d2ee261e602a114d47dd63353bbba8/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/f51c0db9f2d2ee261e602a114d47dd63353bbba8/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "sha": "5559ad77ae5b168733322b74ea57b872bf92e6d0", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java?ref=f51c0db9f2d2ee261e602a114d47dd63353bbba8", "patch": "@@ -677,7 +677,7 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                     for (int i = 0 ; i < projectedExpressions.size(); i++) {\n                         // Must make new column if position has changed\n                         PColumn column = allColumns.get(allColumnsIndexes[i]);\n-                        projectedColumns.add(column.getPosition() == i + posOff ? column : new PColumnImpl(column, i));\n+                        projectedColumns.add(column.getPosition() == i + posOff ? column : new PColumnImpl(column, i + posOff));\n                     }\n                     // Build table from projectedColumns\n                     // Hack to add default column family to be used on server in case no value column is projected.", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/92b951e5387768e084ed09729884a59160cd81d3", "parent": "https://github.com/apache/phoenix/commit/90e32c015207b39330ed7496db7a73dbc7b634f4", "message": "PHOENIX-3759 Dropping a local index causes NPE", "bug_id": "phoenix_17", "file": [{"additions": 12, "raw_url": "https://github.com/apache/phoenix/raw/92b951e5387768e084ed09729884a59160cd81d3/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/92b951e5387768e084ed09729884a59160cd81d3/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java", "sha": "ea4780b40e2609763fb45cfb7a7f947124017e06", "changes": 15, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java?ref=92b951e5387768e084ed09729884a59160cd81d3", "patch": "@@ -599,21 +599,30 @@ public void testLocalIndexAutomaticRepair() throws Exception {\n             admin.disableTable(tableName);\n             copyLocalIndexHFiles(config, tableRegions.get(0), tableRegions.get(1), false);\n             copyLocalIndexHFiles(config, tableRegions.get(3), tableRegions.get(0), false);\n-\n             admin.enableTable(tableName);\n \n             int count=getCount(conn, tableName, \"L#0\");\n             assertTrue(count > 14);\n-            admin.majorCompact(tableName);\n+            admin.majorCompact(TableName.valueOf(tableName));\n             int tryCount = 5;// need to wait for rebuilding of corrupted local index region\n             while (tryCount-- > 0 && count != 14) {\n-                Thread.sleep(30000);\n+                Thread.sleep(15000);\n                 count = getCount(conn, tableName, \"L#0\");\n             }\n             assertEquals(14, count);\n             rs = statement.executeQuery(\"SELECT COUNT(*) FROM \" + indexName1);\n             assertTrue(rs.next());\n             assertEquals(7, rs.getLong(1));\n+            statement.execute(\"DROP INDEX \" + indexName1 + \" ON \" + tableName);\n+            admin.majorCompact(TableName.valueOf(tableName));\n+            statement.execute(\"DROP INDEX \" + indexName + \" ON \" + tableName);\n+            admin.majorCompact(TableName.valueOf(tableName));\n+            Thread.sleep(15000);\n+            admin.majorCompact(TableName.valueOf(tableName));\n+            Thread.sleep(15000);\n+            rs = statement.executeQuery(\"SELECT COUNT(*) FROM \" + tableName);\n+            assertTrue(rs.next());\n+            \n         }\n     }\n ", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/index/LocalIndexIT.java"}, {"additions": 7, "raw_url": "https://github.com/apache/phoenix/raw/92b951e5387768e084ed09729884a59160cd81d3/phoenix-core/src/main/java/org/apache/phoenix/util/RepairUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/92b951e5387768e084ed09729884a59160cd81d3/phoenix-core/src/main/java/org/apache/phoenix/util/RepairUtil.java", "sha": "ea14715b755831a6fa01966e05a151f66a53cbd4", "changes": 11, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/RepairUtil.java?ref=92b951e5387768e084ed09729884a59160cd81d3", "patch": "@@ -29,10 +29,13 @@ public static boolean isLocalIndexStoreFilesConsistent(RegionCoprocessorEnvironm\n         byte[] endKey = environment.getRegion().getRegionInfo().getEndKey();\n         byte[] indexKeyEmbedded = startKey.length == 0 ? new byte[endKey.length] : startKey;\n         for (StoreFile file : store.getStorefiles()) {\n-            byte[] fileFirstRowKey = KeyValue.createKeyValueFromKey(file.getReader().getFirstKey()).getRow();;\n-            if ((fileFirstRowKey != null && Bytes.compareTo(file.getReader().getFirstKey(), 0, indexKeyEmbedded.length,\n-                    indexKeyEmbedded, 0, indexKeyEmbedded.length) != 0)\n-                    /*|| (endKey.length > 0 && Bytes.compareTo(file.getLastKey(), endKey) < 0)*/) { return false; }\n+            if (file.getReader() != null && file.getReader().getFirstKey() != null) {\n+                byte[] fileFirstRowKey = KeyValue.createKeyValueFromKey(file.getReader().getFirstKey()).getRow();\n+                ;\n+                if ((fileFirstRowKey != null && Bytes.compareTo(file.getReader().getFirstKey(), 0,\n+                        indexKeyEmbedded.length, indexKeyEmbedded, 0, indexKeyEmbedded.length) != 0)\n+                /* || (endKey.length > 0 && Bytes.compareTo(file.getLastKey(), endKey) < 0) */) { return false; }\n+            }\n         }\n         return true;\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/RepairUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/e23634a358929516ce210fe06d668ce475eccccb", "parent": "https://github.com/apache/phoenix/commit/c5046047a78e0365d75bc696dff4870304c2b5b2", "message": "PHOENIX-3505 Avoid NPE on close() in OrderedResultIterator", "bug_id": "phoenix_18", "file": [{"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java", "blob_url": "https://github.com/apache/phoenix/blob/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java", "sha": "da75bb7bd7cb9e5f309a231c8618a04fff851b62", "changes": 5, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java?ref=e23634a358929516ce210fe06d668ce475eccccb", "patch": "@@ -279,7 +279,10 @@ public Tuple peek() throws SQLException {\n \n     @Override\n     public void close() throws SQLException {\n-        resultIterator.close();\n+        // Guard against resultIterator being null\n+        if (null != resultIterator) {\n+            resultIterator.close();\n+        }\n         resultIterator = PeekingResultIterator.EMPTY_ITERATOR;\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java"}, {"additions": 41, "raw_url": "https://github.com/apache/phoenix/raw/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java", "blob_url": "https://github.com/apache/phoenix/blob/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java", "sha": "50ed8e9df79907c35b0fcc1847732e05b3d6f8c0", "changes": 41, "status": "added", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java?ref=e23634a358929516ce210fe06d668ce475eccccb", "patch": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.iterate;\n+\n+import java.sql.SQLException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.phoenix.expression.OrderByExpression;\n+import org.junit.Test;\n+\n+/**\n+ * Test class for {@link OrderedResultIterator}.\n+ */\n+public class OrderedResultIteratorTest {\n+\n+  @Test\n+  public void testNullIteratorOnClose() throws SQLException {\n+      ResultIterator delegate =  ResultIterator.EMPTY_ITERATOR;\n+      List<OrderByExpression> orderByExpressions = Collections.singletonList(null);\n+      int thresholdBytes = Integer.MAX_VALUE;\n+      OrderedResultIterator iterator = new OrderedResultIterator(delegate, orderByExpressions, thresholdBytes);\n+      // Should not throw an exception\n+      iterator.close();\n+  }\n+\n+}", "filename": "phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/cd444d9a6a8e560889826bc491db7d71ad1960e5", "parent": "https://github.com/apache/phoenix/commit/92e728e09ace5dfac93cd04a747f3db8043569ee", "message": "PHOENIX-3765 NPE in IndexMaintainer when using old client and 4.10 server", "bug_id": "phoenix_19", "file": [{"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/cd444d9a6a8e560889826bc491db7d71ad1960e5/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java", "blob_url": "https://github.com/apache/phoenix/blob/cd444d9a6a8e560889826bc491db7d71ad1960e5/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java", "sha": "26c24217c1f50b5a677c05900a145c749b06edae", "changes": 3, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java?ref=cd444d9a6a8e560889826bc491db7d71ad1960e5", "patch": "@@ -1308,6 +1308,9 @@ public PDataType getDataType() {\n         int encodedEstimatedIndexRowKeyBytesAndImmutableRows = WritableUtils.readVInt(input);\n         this.immutableRows = encodedEstimatedIndexRowKeyBytesAndImmutableRows < 0;\n         this.estimatedIndexRowKeyBytes = Math.abs(encodedEstimatedIndexRowKeyBytesAndImmutableRows);\n+        // Needed for backward compatibility. Clients older than 4.10 will have non-encoded tables.\n+        this.immutableStorageScheme = ImmutableStorageScheme.ONE_CELL_PER_COLUMN;\n+        this.encodingScheme = QualifierEncodingScheme.NON_ENCODED_QUALIFIERS;\n         initCachedState();\n     }\n     ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/5f9cf15e272fc9d92a3165753ac2157396851bd6", "parent": "https://github.com/apache/phoenix/commit/2398f78441256ccfcb2b9e114486e91769510ff8", "message": "PHOENIX-3879 UNION ALL with subqueries that have aggregate functions on fixed length columns throw an NPE", "bug_id": "phoenix_20", "file": [{"additions": 55, "raw_url": "https://github.com/apache/phoenix/raw/5f9cf15e272fc9d92a3165753ac2157396851bd6/phoenix-core/src/it/java/org/apache/phoenix/end2end/NthValueFunctionIT.java", "blob_url": "https://github.com/apache/phoenix/blob/5f9cf15e272fc9d92a3165753ac2157396851bd6/phoenix-core/src/it/java/org/apache/phoenix/end2end/NthValueFunctionIT.java", "sha": "0f6bf256c05b2b5d5699afff7c5895654ec4171f", "changes": 55, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/NthValueFunctionIT.java?ref=5f9cf15e272fc9d92a3165753ac2157396851bd6", "patch": "@@ -487,5 +487,60 @@ private void assertInIntArray(int[] should, int actualValue) {\n         }\n         assertTrue(shouldList.contains(actualValue));\n     }\n+    \n+    @Test\n+    public void testUnionAll() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+\n+        String nthValue = generateUniqueName();\n+        String ddl = \"CREATE TABLE IF NOT EXISTS \" + nthValue + \" \"\n+                + \"(id INTEGER NOT NULL, feid UNSIGNED_LONG NOT NULL,\"\n+                + \" uid CHAR(1) NOT NULL, lrd INTEGER\"\n+                + \" CONSTRAINT PKVIEW PRIMARY KEY ( id, feid, uid))\";\n+        conn.createStatement().execute(ddl);\n+\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 8, '1', 7)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 8, '2', 9)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 8, '3', 4)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 8, '4', 2)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 9, '5', 1)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 9, '6', 3)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 9, '8', 5)\");\n+        conn.createStatement().execute(\n+            \"UPSERT INTO \" + nthValue + \" (id, feid, uid, lrd) VALUES (2, 9, '7', 8)\");\n+        conn.commit();\n+\n+        ResultSet rs = conn.createStatement().executeQuery(\n+            \"SELECT feid, NTH_VALUE(uid, 1) WITHIN GROUP (ORDER BY lrd DESC) as user_id, NTH_VALUE(lrd, 1) WITHIN GROUP (ORDER BY lrd DESC) as lrd FROM \" + nthValue\n+                + \" where id=2 and feid in (8, 9) GROUP BY feid\" \n+                + \" UNION ALL\" \n+                + \" SELECT feid, NTH_VALUE(uid, 2) WITHIN GROUP (ORDER BY lrd DESC) as user_id, NTH_VALUE(lrd, 2) WITHIN GROUP (ORDER BY lrd DESC) as lrd  FROM \" + nthValue\n+                + \" where id=2 and feid in (8, 9) GROUP BY feid\");\n+        \n+        assertTrue(rs.next());\n+        assertEquals(8, rs.getInt(1));\n+        assertEquals(\"2\", rs.getString(2));\n+        assertEquals(9, rs.getInt(3));\n+        assertTrue(rs.next());\n+        assertEquals(9, rs.getInt(1));\n+        assertEquals(\"7\", rs.getString(2));\n+        assertEquals(8, rs.getInt(3));\n+        assertTrue(rs.next());\n+        assertEquals(8, rs.getInt(1));\n+        assertEquals(\"1\", rs.getString(2));\n+        assertEquals(7, rs.getInt(3));\n+        assertTrue(rs.next());\n+        assertEquals(9, rs.getInt(1));\n+        assertEquals(\"8\", rs.getString(2));\n+        assertEquals(5, rs.getInt(3));\n+        assertFalse(rs.next());\n+    }\n \n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/NthValueFunctionIT.java"}, {"additions": 10, "raw_url": "https://github.com/apache/phoenix/raw/5f9cf15e272fc9d92a3165753ac2157396851bd6/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FirstLastValueBaseFunction.java", "blob_url": "https://github.com/apache/phoenix/blob/5f9cf15e272fc9d92a3165753ac2157396851bd6/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FirstLastValueBaseFunction.java", "sha": "61a196d4438b13c356b6cff743c8f13a77a43f7c", "changes": 10, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FirstLastValueBaseFunction.java?ref=5f9cf15e272fc9d92a3165753ac2157396851bd6", "patch": "@@ -53,4 +53,14 @@ public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n     public PDataType getDataType() {\n         return children.get(2).getDataType();\n     }\n+    \n+    @Override\n+    public Integer getMaxLength() {\n+        return children.get(2).getMaxLength();\n+    }\n+    \n+    @Override\n+    public Integer getScale() {\n+        return children.get(2).getScale();\n+    }\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/FirstLastValueBaseFunction.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/a9a9b24c904997b13fe966a9972793f1224a3564", "parent": "https://github.com/apache/phoenix/commit/c26cce5038971a01a4864e473ec249f78ebfa892", "message": "PHOENIX-2366 - Pherf NPE on Data loader", "bug_id": "phoenix_21", "file": [{"additions": 9, "raw_url": "https://github.com/apache/phoenix/raw/a9a9b24c904997b13fe966a9972793f1224a3564/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/PherfConstants.java", "blob_url": "https://github.com/apache/phoenix/blob/a9a9b24c904997b13fe966a9972793f1224a3564/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/PherfConstants.java", "sha": "3d504fd8ad114be03d47a7f3716c7388c059530b", "changes": 10, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/PherfConstants.java?ref=a9a9b24c904997b13fe966a9972793f1224a3564", "patch": "@@ -78,12 +78,20 @@ public static PherfConstants create() {\n         return instance;\n     }\n \n+    /**\n+     * Get a {@link Properties} object based on the file name\n+     * @param fileName      Name of the file\n+     * @param getDefault    True if you want to use the properties that may have been loaded into\n+     *                      the instance. use false if you want to reload the passed file.\n+     * @return {@link Properties}\n+     * @throws Exception\n+     */\n     public Properties getProperties(final String fileName, boolean getDefault) throws Exception {\n \n         if (instanceProperties == null) {\n             instanceProperties = loadProperties(fileName);\n         } else {\n-            return getDefault ? loadProperties(fileName) : instanceProperties;\n+            return getDefault ? instanceProperties : loadProperties(fileName);\n         }\n \n         return instanceProperties;", "filename": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/PherfConstants.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/a9a9b24c904997b13fe966a9972793f1224a3564/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/ResultUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/a9a9b24c904997b13fe966a9972793f1224a3564/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/ResultUtil.java", "sha": "d16a2f92af9d3b6787be3e9b1390402699c23eb5", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/ResultUtil.java?ref=a9a9b24c904997b13fe966a9972793f1224a3564", "patch": "@@ -51,8 +51,8 @@ public synchronized void write(DataLoadThreadTime dataLoadThreadTime) throws IOE\n         try {\n             if (!dataLoadThreadTime.getThreadTime().isEmpty()) {\n                 writer = new CSVFileResultHandler();\n-                writer.setResultFileName(\"Data_Load_Details\");\n                 writer.setResultFileDetails(ResultFileDetails.CSV);\n+                writer.setResultFileName(\"Data_Load_Details\");\n \n                 for (WriteThreadTime writeThreadTime : dataLoadThreadTime.getThreadTime()) {\n                     List<ResultValue> rowValues = new ArrayList<>();\n@@ -86,8 +86,8 @@ public synchronized void write(DataLoadTimeSummary dataLoadTime) throws IOExcept\n         ResultFileDetails resultFileDetails = ResultFileDetails.CSV_AGGREGATE_DATA_LOAD;\n         try {\n             writer = new CSVFileResultHandler();\n-            writer.setResultFileName(\"Data_Load_Summary\");\n             writer.setResultFileDetails(resultFileDetails);\n+            writer.setResultFileName(\"Data_Load_Summary\");\n \n             for (TableLoadTime loadTime : dataLoadTime.getTableLoadTime()) {\n                 List<ResultValue> rowValues = new ArrayList<>();", "filename": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/result/ResultUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/c584029b9face0acb0513d328d68ec42b25fc011", "parent": "https://github.com/apache/phoenix/commit/c2ee4f7fd7dc80b511ba23e0431a3b8ffeae26a3", "message": "PHOENIX-2600 NPE on immutable index creation over transactional table", "bug_id": "phoenix_22", "file": [{"additions": 9, "raw_url": "https://github.com/apache/phoenix/raw/c584029b9face0acb0513d328d68ec42b25fc011/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "blob_url": "https://github.com/apache/phoenix/blob/c584029b9face0acb0513d328d68ec42b25fc011/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "sha": "30de4de48166947c45a7831d8db8ce7290f074e5", "changes": 10, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=c584029b9face0acb0513d328d68ec42b25fc011", "patch": "@@ -1376,7 +1376,9 @@ public void testUpsertSelectWithFixedWidthNullByteSizeArray() throws Exception {\n \n     @Test\n     public void testParallelUpsertSelect() throws Exception {\n+        long ts = nextTimestamp();\n         Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));\n         props.setProperty(QueryServices.MUTATE_BATCH_SIZE_ATTRIB, Integer.toString(3));\n         props.setProperty(QueryServices.SCAN_CACHE_SIZE_ATTRIB, Integer.toString(3));\n         props.setProperty(QueryServices.SCAN_RESULT_CHUNK_SIZE, Integer.toString(3));\n@@ -1385,11 +1387,17 @@ public void testParallelUpsertSelect() throws Exception {\n         conn.createStatement().execute(\"CREATE SEQUENCE S1\");\n         conn.createStatement().execute(\"CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4\");\n         conn.createStatement().execute(\"CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER)\");\n-\n+        conn.close();\n+        \n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 10));\n+        conn = DriverManager.getConnection(getUrl(), props);\n         for (int i = 0; i < 100; i++) {\n             conn.createStatement().execute(\"UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, \" + (i%10) + \")\");\n         }\n         conn.commit();\n+        conn.close();\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 20));\n+        conn = DriverManager.getConnection(getUrl(), props);\n         conn.setAutoCommit(true);\n         int upsertCount = conn.createStatement().executeUpdate(\"UPSERT INTO T2 SELECT pk, val FROM SALTEDT1\");\n         assertEquals(100,upsertCount);", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/0f4f8eff727fb29d71285882f627d4aa92c2fe2c", "parent": "https://github.com/apache/phoenix/commit/87664bd3d0295b9d0aa6d4294c77c2fb757f4bdb", "message": "Fix NPE on startup", "bug_id": "phoenix_23", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java", "sha": "62cf8bf9af87cd626d4559e84ff8122a1d5a1fe6", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java?ref=0f4f8eff727fb29d71285882f627d4aa92c2fe2c", "patch": "@@ -601,7 +601,7 @@ private PTable getTable(RegionScanner scanner, long clientTimeStamp, long tableT\n         }\n         PName physicalTableName = physicalTables.isEmpty() ? PNameFactory.newName(SchemaUtil.getTableName(\n                 schemaName.getString(), tableName.getString())) : physicalTables.get(0);\n-        PTableStats stats = null;\n+        PTableStats stats = PTableStats.EMPTY_STATS;\n         if (tenantId == null) {\n             HTableInterface statsHTable = null;\n             try {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java", "sha": "d88325947b8d3b9f135fe36144968f34abfd7ed5", "changes": 3, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java?ref=0f4f8eff727fb29d71285882f627d4aa92c2fe2c", "patch": "@@ -65,6 +65,7 @@\n import com.google.common.collect.Lists;\n import com.google.common.collect.Maps;\n import com.google.protobuf.HBaseZeroCopyByteString;\n+import com.sun.istack.NotNull;\n \n /**\n  * \n@@ -225,7 +226,7 @@ public static PTableImpl makePTable(PName tenantId, PName schemaName, PName tabl\n             PIndexState state, long timeStamp, long sequenceNumber, PName pkName, Integer bucketNum,\n             List<PColumn> columns, PName dataTableName, List<PTable> indexes, boolean isImmutableRows,\n             List<PName> physicalNames, PName defaultFamilyName, String viewExpression, boolean disableWAL,\n-            boolean multiTenant, ViewType viewType, Short viewIndexId, IndexType indexType, PTableStats stats)\n+            boolean multiTenant, ViewType viewType, Short viewIndexId, IndexType indexType, @NotNull PTableStats stats)\n             throws SQLException {\n         return new PTableImpl(tenantId, schemaName, tableName, type, state, timeStamp, sequenceNumber, pkName,\n                 bucketNum, columns, dataTableName, indexes, isImmutableRows, physicalNames, defaultFamilyName,", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/schema/stats/PTableStatsImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/0f4f8eff727fb29d71285882f627d4aa92c2fe2c/phoenix-core/src/main/java/org/apache/phoenix/schema/stats/PTableStatsImpl.java", "sha": "e7114fedde2b44b84d4e25b4f3b1cb3462b80f49", "changes": 4, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/stats/PTableStatsImpl.java?ref=0f4f8eff727fb29d71285882f627d4aa92c2fe2c", "patch": "@@ -22,6 +22,8 @@\n import java.util.TreeMap;\n \n import org.apache.hadoop.hbase.util.Bytes;\n+\n+import com.sun.istack.NotNull;\n  \n  /**\n  * Implementation for PTableStats.\n@@ -33,7 +35,7 @@ public PTableStatsImpl() {\n         this(new TreeMap<byte[], List<byte[]>>(Bytes.BYTES_COMPARATOR));\n     }\n \n-    public PTableStatsImpl(SortedMap<byte[], List<byte[]>> guidePosts) {\n+    public PTableStatsImpl(@NotNull SortedMap<byte[], List<byte[]>> guidePosts) {\n         this.guidePosts = guidePosts;\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/stats/PTableStatsImpl.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/04504c34ffb2e39f38e1b37ee0d7f8f909537616", "parent": "https://github.com/apache/phoenix/commit/763a3566ed7ade82b7ffbd56cf90ff264cdbe20a", "message": "PHOENIX-2600 NPE on immutable index creation over transactional table", "bug_id": "phoenix_24", "file": [{"additions": 23, "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "sha": "364b4232c88bee9e4b0a87498bf944750c345100", "changes": 23, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616", "patch": "@@ -1373,6 +1373,29 @@ public void testUpsertSelectWithFixedWidthNullByteSizeArray() throws Exception {\n         assertEquals(\"[[128,0,0,54], [128,0,4,0]]\", rs.getArray(2).toString());\n     }\n \n+\n+    @Test\n+    public void testParallelUpsertSelect() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(QueryServices.MUTATE_BATCH_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_CACHE_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_RESULT_CHUNK_SIZE, Integer.toString(3));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.setAutoCommit(false);\n+        conn.createStatement().execute(\"CREATE SEQUENCE S1\");\n+        conn.createStatement().execute(\"CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4\");\n+        conn.createStatement().execute(\"CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER)\");\n+\n+        for (int i = 0; i < 100; i++) {\n+            conn.createStatement().execute(\"UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, \" + (i%10) + \")\");\n+        }\n+        conn.commit();\n+        conn.setAutoCommit(true);\n+        int upsertCount = conn.createStatement().executeUpdate(\"UPSERT INTO T2 SELECT pk, val FROM SALTEDT1\");\n+        assertEquals(100,upsertCount);\n+        conn.close();\n+    }\n+\n     private static Connection getConnection(long ts) throws SQLException {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java"}, {"additions": 232, "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java", "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java", "sha": "2794c477af4b0fd12e422b81999a2401a162eae6", "changes": 442, "status": "modified", "deletions": 210, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616", "patch": "@@ -36,6 +36,12 @@\n import java.util.Map;\n import java.util.Properties;\n \n+import co.cask.tephra.TransactionContext;\n+import co.cask.tephra.TransactionSystemClient;\n+import co.cask.tephra.TxConstants;\n+import co.cask.tephra.hbase11.TransactionAwareHTable;\n+import co.cask.tephra.hbase11.coprocessor.TransactionProcessor;\n+\n import org.apache.hadoop.hbase.HColumnDescriptor;\n import org.apache.hadoop.hbase.HTableDescriptor;\n import org.apache.hadoop.hbase.TableName;\n@@ -68,16 +74,10 @@\n import com.google.common.collect.Lists;\n import com.google.common.collect.Maps;\n \n-import co.cask.tephra.TransactionContext;\n-import co.cask.tephra.TransactionSystemClient;\n-import co.cask.tephra.TxConstants;\n-import co.cask.tephra.hbase11.TransactionAwareHTable;\n-import co.cask.tephra.hbase11.coprocessor.TransactionProcessor;\n-\n public class TransactionIT extends BaseHBaseManagedTimeIT {\n-\t\n-\tprivate static final String FULL_TABLE_NAME = INDEX_DATA_SCHEMA + QueryConstants.NAME_SEPARATOR + TRANSACTIONAL_DATA_TABLE;\n-\t\n+    \n+    private static final String FULL_TABLE_NAME = INDEX_DATA_SCHEMA + QueryConstants.NAME_SEPARATOR + TRANSACTIONAL_DATA_TABLE;\n+    \n     @Before\n     public void setUp() throws SQLException {\n         ensureTableCreated(getUrl(), TRANSACTIONAL_DATA_TABLE);\n@@ -90,73 +90,73 @@ public static void doSetup() throws Exception {\n         props.put(QueryServices.TRANSACTIONS_ENABLED, Boolean.toString(true));\n         setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n     }\n-\t\t\n-\t@Test\n-\tpublic void testReadOwnWrites() throws Exception {\n-\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 2);\n-\t\t\tstmt.execute();\n-\t        \n-\t        // verify rows can be read even though commit has not been called\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 1);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t        \n-\t        conn.commit();\n-\t        \n-\t        // verify rows can be read after commit\n-\t        rs = conn.createStatement().executeQuery(selectSql);\n-\t        TestUtil.validateRowKeyColumns(rs, 1);\n-\t        TestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t\t}\n-\t}\n-\t\n-\t@Test\n-\tpublic void testTxnClosedCorrecty() throws Exception {\n-\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 2);\n-\t\t\tstmt.execute();\n-\t        \n-\t        // verify rows can be read even though commit has not been called\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 1);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t        \n-\t        conn.close();\n-\t        // wait for any open txns to time out\n-\t        Thread.sleep(DEFAULT_TXN_TIMEOUT_SECONDS*1000+10000);\n-\t        assertTrue(\"There should be no invalid transactions\", txManager.getInvalidSize()==0);\n-\t\t}\n-\t}\n-\t\n+        \n+    @Test\n+    public void testReadOwnWrites() throws Exception {\n+        String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            TestUtil.setRowKeyColumns(stmt, 2);\n+            stmt.execute();\n+            \n+            // verify rows can be read even though commit has not been called\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+            \n+            conn.commit();\n+            \n+            // verify rows can be read after commit\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+        }\n+    }\n+    \n+    @Test\n+    public void testTxnClosedCorrecty() throws Exception {\n+        String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            TestUtil.setRowKeyColumns(stmt, 2);\n+            stmt.execute();\n+            \n+            // verify rows can be read even though commit has not been called\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+            \n+            conn.close();\n+            // wait for any open txns to time out\n+            Thread.sleep(DEFAULT_TXN_TIMEOUT_SECONDS*1000+10000);\n+            assertTrue(\"There should be no invalid transactions\", txManager.getInvalidSize()==0);\n+        }\n+    }\n+    \n     @Test\n     public void testDelete() throws Exception {\n         String selectSQL = \"SELECT * FROM \" + FULL_TABLE_NAME;\n         try (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n             conn1.setAutoCommit(false);\n             ResultSet rs = conn1.createStatement().executeQuery(selectSQL);\n             assertFalse(rs.next());\n@@ -188,107 +188,107 @@ public void testDelete() throws Exception {\n         }\n     }\n     \n-\t@Test\n-\tpublic void testAutoCommitQuerySingleTable() throws Exception {\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(true);\n-\t\t\t// verify no rows returned\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME);\n-\t\t\tassertFalse(rs.next());\n-\t\t}\n-\t}\n-\t\n+    @Test\n+    public void testAutoCommitQuerySingleTable() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(true);\n+            // verify no rows returned\n+            ResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME);\n+            assertFalse(rs.next());\n+        }\n+    }\n+    \n     @Test\n     public void testAutoCommitQueryMultiTables() throws Exception {\n-    \ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n             conn.setAutoCommit(true);\n             // verify no rows returned\n             ResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME + \" a JOIN \" + FULL_TABLE_NAME + \" b ON (a.long_pk = b.int_pk)\");\n             assertFalse(rs.next());\n         } \n     }\n     \n-\t@Test\n-\tpublic void testColConflicts() throws Exception {\n-\t\ttry (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tconn2.setAutoCommit(false);\n-\t\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tResultSet rs = conn1.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t\t\t// upsert row using conn1\n-\t\t\tString upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n-\t\t\tPreparedStatement stmt = conn1.prepareStatement(upsertSql);\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 10);\n-\t        stmt.execute();\n-\t        // upsert row using conn2\n- \t\t\tstmt = conn2.prepareStatement(upsertSql);\n- \t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 11);\n-\t        stmt.execute();\n- \t        \n- \t        conn1.commit();\n-\t        //second commit should fail\n- \t        try {\n- \t \t        conn2.commit();\n- \t \t        fail();\n- \t        }\t\n- \t        catch (SQLException e) {\n- \t        \tassertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n- \t        }\n-\t\t}\n-\t}\n-\t\n-\tprivate void testRowConflicts() throws Exception {\n-\t\ttry (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tconn2.setAutoCommit(false);\n-\t\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tResultSet rs = conn1.createStatement().executeQuery(selectSql);\n-\t\t\tboolean immutableRows = conn1.unwrap(PhoenixConnection.class).getTable(new PTableKey(null, FULL_TABLE_NAME)).isImmutableRows();\n-\t     \tassertFalse(rs.next());\n-\t\t\t// upsert row using conn1\n-\t\t\tString upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n-\t\t\tPreparedStatement stmt = conn1.prepareStatement(upsertSql);\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 10);\n-\t        stmt.execute();\n-\t        // upsert row using conn2\n-\t        upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, b.int_col2) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n- \t\t\tstmt = conn2.prepareStatement(upsertSql);\n- \t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 11);\n- \t        stmt.execute();\n- \t        \n- \t        conn1.commit();\n-\t        //second commit should fail\n- \t        try {\n- \t \t        conn2.commit();\n- \t \t        if (!immutableRows) fail();\n- \t        }\t\n- \t        catch (SQLException e) {\n- \t        \tif (immutableRows) fail();\n- \t        \tassertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n- \t        }\n-\t\t}\n-\t}\n-\t\n-\t@Test\n-\tpublic void testRowConflictDetected() throws Exception {\n-\t\ttestRowConflicts();\n-\t}\n-\t\n-\t@Test\n-\tpublic void testNoConflictDetectionForImmutableRows() throws Exception {\n-\t\tConnection conn = DriverManager.getConnection(getUrl());\n-\t\tconn.createStatement().execute(\"ALTER TABLE \" + FULL_TABLE_NAME + \" SET IMMUTABLE_ROWS=true\");\n-\t\ttestRowConflicts();\n-\t}\n+    @Test\n+    public void testColConflicts() throws Exception {\n+        try (Connection conn1 = DriverManager.getConnection(getUrl()); \n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n+            conn1.setAutoCommit(false);\n+            conn2.setAutoCommit(false);\n+            String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+            conn1.setAutoCommit(false);\n+            ResultSet rs = conn1.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            // upsert row using conn1\n+            String upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn1.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 10);\n+            stmt.execute();\n+            // upsert row using conn2\n+            stmt = conn2.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 11);\n+            stmt.execute();\n+            \n+            conn1.commit();\n+            //second commit should fail\n+            try {\n+                conn2.commit();\n+                fail();\n+            }   \n+            catch (SQLException e) {\n+                assertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n+            }\n+        }\n+    }\n+    \n+    private void testRowConflicts() throws Exception {\n+        try (Connection conn1 = DriverManager.getConnection(getUrl()); \n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n+            conn1.setAutoCommit(false);\n+            conn2.setAutoCommit(false);\n+            String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+            conn1.setAutoCommit(false);\n+            ResultSet rs = conn1.createStatement().executeQuery(selectSql);\n+            boolean immutableRows = conn1.unwrap(PhoenixConnection.class).getTable(new PTableKey(null, FULL_TABLE_NAME)).isImmutableRows();\n+            assertFalse(rs.next());\n+            // upsert row using conn1\n+            String upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn1.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 10);\n+            stmt.execute();\n+            // upsert row using conn2\n+            upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, b.int_col2) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            stmt = conn2.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 11);\n+            stmt.execute();\n+            \n+            conn1.commit();\n+            //second commit should fail\n+            try {\n+                conn2.commit();\n+                if (!immutableRows) fail();\n+            }   \n+            catch (SQLException e) {\n+                if (immutableRows) fail();\n+                assertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n+            }\n+        }\n+    }\n+    \n+    @Test\n+    public void testRowConflictDetected() throws Exception {\n+        testRowConflicts();\n+    }\n+    \n+    @Test\n+    public void testNoConflictDetectionForImmutableRows() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        conn.createStatement().execute(\"ALTER TABLE \" + FULL_TABLE_NAME + \" SET IMMUTABLE_ROWS=true\");\n+        testRowConflicts();\n+    }\n     \n     @Test\n     public void testNonTxToTxTable() throws Exception {\n@@ -514,33 +514,33 @@ public void testCreateTableToBeTransactional() throws Exception {\n     }\n \n     public void testCurrentDate() throws Exception {\n-\t\tString selectSql = \"SELECT current_date() FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tconn.commit();\n-\t\t\t\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tassertTrue(rs.next());\n-\t\t\tDate date1 = rs.getDate(1);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t     \tThread.sleep(1000);\n-\t     \t\n-\t     \trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tassertTrue(rs.next());\n-\t\t\tDate date2 = rs.getDate(1);\n-\t     \tassertFalse(rs.next());\n-\t     \tassertTrue(\"current_date() should change while executing multiple statements\", date2.getTime() > date1.getTime());\n-\t\t}\n-\t}\n+        String selectSql = \"SELECT current_date() FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            conn.commit();\n+            \n+            rs = conn.createStatement().executeQuery(selectSql);\n+            assertTrue(rs.next());\n+            Date date1 = rs.getDate(1);\n+            assertFalse(rs.next());\n+            \n+            Thread.sleep(1000);\n+            \n+            rs = conn.createStatement().executeQuery(selectSql);\n+            assertTrue(rs.next());\n+            Date date2 = rs.getDate(1);\n+            assertFalse(rs.next());\n+            assertTrue(\"current_date() should change while executing multiple statements\", date2.getTime() > date1.getTime());\n+        }\n+    }\n     \n     @Test\n     public void testReCreateTxnTableAfterDroppingExistingNonTxnTable() throws SQLException {\n@@ -558,32 +558,32 @@ public void testReCreateTxnTableAfterDroppingExistingNonTxnTable() throws SQLExc\n     \n     @Test\n     public void testRowTimestampDisabled() throws SQLException {\n-    \tProperties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n         try (Connection conn = DriverManager.getConnection(getUrl(), props)) {\n-\t        conn.setAutoCommit(false);\n-\t        Statement stmt = conn.createStatement();\n-\t        try {\n-\t        \tstmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP)) TRANSACTIONAL=true\");\n-\t        \tfail();\n-\t        }\n-        \tcatch(SQLException e) {\n-        \t\tassertEquals(SQLExceptionCode.CANNOT_CREATE_TXN_TABLE_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n-        \t}\n-\t        stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP))\");\n-\t        try {\n-\t        \tstmt.execute(\"ALTER TABLE DEMO SET TRANSACTIONAL=true\");\n-\t        \tfail();\n-\t        }\n-        \tcatch(SQLException e) {\n-        \t\tassertEquals(SQLExceptionCode.CANNOT_ALTER_TO_BE_TXN_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n-        \t}\n+            conn.setAutoCommit(false);\n+            Statement stmt = conn.createStatement();\n+            try {\n+                stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP)) TRANSACTIONAL=true\");\n+                fail();\n+            }\n+            catch(SQLException e) {\n+                assertEquals(SQLExceptionCode.CANNOT_CREATE_TXN_TABLE_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n+            }\n+            stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP))\");\n+            try {\n+                stmt.execute(\"ALTER TABLE DEMO SET TRANSACTIONAL=true\");\n+                fail();\n+            }\n+            catch(SQLException e) {\n+                assertEquals(SQLExceptionCode.CANNOT_ALTER_TO_BE_TXN_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n+            }\n         }\n     }\n     \n     @Test\n     public void testReadOnlyView() throws Exception {\n         Connection conn = DriverManager.getConnection(getUrl());\n-\t\tString ddl = \"CREATE TABLE t (k INTEGER NOT NULL PRIMARY KEY, v1 DATE) TRANSACTIONAL=true\";\n+        String ddl = \"CREATE TABLE t (k INTEGER NOT NULL PRIMARY KEY, v1 DATE) TRANSACTIONAL=true\";\n         conn.createStatement().execute(ddl);\n         ddl = \"CREATE VIEW v (v2 VARCHAR) AS SELECT * FROM t where k>4\";\n         conn.createStatement().execute(ddl);\n@@ -870,4 +870,26 @@ public void testInflightDeleteNotSeen() throws Exception {\n             assertFalse(rs.next());\n         }\n     }\n+\n+    @Test\n+    public void testParallelUpsertSelect() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(QueryServices.MUTATE_BATCH_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_CACHE_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_RESULT_CHUNK_SIZE, Integer.toString(3));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.setAutoCommit(false);\n+        conn.createStatement().execute(\"CREATE SEQUENCE S1\");\n+        conn.createStatement().execute(\"CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4,TRANSACTIONAL=true\");\n+        conn.createStatement().execute(\"CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER) TRANSACTIONAL=true\");\n+\n+        for (int i = 0; i < 100; i++) {\n+            conn.createStatement().execute(\"UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, \" + (i%10) + \")\");\n+        }\n+        conn.commit();\n+        conn.setAutoCommit(true);\n+        int upsertCount = conn.createStatement().executeUpdate(\"UPSERT INTO T2 SELECT pk, val FROM SALTEDT1\");\n+        assertEquals(100,upsertCount);\n+        conn.close();\n+    }\n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java"}, {"additions": 0, "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "sha": "4c41f82ca3d44238447d32a6c336baad6a08d613", "changes": 1, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616", "patch": "@@ -395,7 +395,6 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n             break;\n         }\n         final QueryPlan dataPlan = dataPlanToBe;\n-        final ColumnResolver resolver = resolverToBe;\n         final boolean hasImmutableIndexes = !immutableIndex.isEmpty();\n         // tableRefs is parallel with queryPlans\n         TableRef[] tableRefs = new TableRef[hasImmutableIndexes ? immutableIndex.size() : 1];", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java"}, {"additions": 25, "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java", "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java", "sha": "35a36e60141d6483a82bd9964eea85b7aae1dfa5", "changes": 40, "status": "modified", "deletions": 15, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616", "patch": "@@ -37,6 +37,18 @@\n import javax.annotation.Nonnull;\n import javax.annotation.concurrent.Immutable;\n \n+import co.cask.tephra.Transaction;\n+import co.cask.tephra.Transaction.VisibilityLevel;\n+import co.cask.tephra.TransactionAware;\n+import co.cask.tephra.TransactionCodec;\n+import co.cask.tephra.TransactionConflictException;\n+import co.cask.tephra.TransactionContext;\n+import co.cask.tephra.TransactionFailureException;\n+import co.cask.tephra.TransactionSystemClient;\n+import co.cask.tephra.hbase11.TransactionAwareHTable;\n+import co.cask.tephra.visibility.FenceWait;\n+import co.cask.tephra.visibility.VisibilityFence;\n+\n import org.apache.hadoop.hbase.HConstants;\n import org.apache.hadoop.hbase.client.Delete;\n import org.apache.hadoop.hbase.client.HTableInterface;\n@@ -98,18 +110,6 @@\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n \n-import co.cask.tephra.Transaction;\n-import co.cask.tephra.Transaction.VisibilityLevel;\n-import co.cask.tephra.TransactionAware;\n-import co.cask.tephra.TransactionCodec;\n-import co.cask.tephra.TransactionConflictException;\n-import co.cask.tephra.TransactionContext;\n-import co.cask.tephra.TransactionFailureException;\n-import co.cask.tephra.TransactionSystemClient;\n-import co.cask.tephra.hbase11.TransactionAwareHTable;\n-import co.cask.tephra.visibility.FenceWait;\n-import co.cask.tephra.visibility.VisibilityFence;\n-\n /**\n  * \n  * Tracks the uncommitted state\n@@ -242,7 +242,18 @@ public void commitWriteFence(PTable dataTable) throws SQLException {\n         }\n     }\n     \n-    private void addReadFence(PTable dataTable) throws SQLException {\n+    /**\n+     * Add an entry to the change set representing the DML operation that is starting.\n+     * These entries will not conflict with each other, but they will conflict with a\n+     * DDL operation of creating an index. See {@link #addReadFence(PTable)} and TEPHRA-157\n+     * for more information.\n+     * @param dataTable the table which is doing DML\n+     * @throws SQLException\n+     */\n+    public void addReadFence(PTable dataTable) throws SQLException {\n+        if (this.txContext == null) {\n+            throw new SQLExceptionInfo.Builder(SQLExceptionCode.NULL_TRANSACTION_CONTEXT).build().buildException();\n+        }\n         byte[] logicalKey = SchemaUtil.getTableKey(dataTable);\n         this.txContext.addTransactionAware(VisibilityFence.create(logicalKey));\n         byte[] physicalKey = dataTable.getPhysicalName().getBytes();\n@@ -848,8 +859,7 @@ private void send(Iterator<TableRef> tableRefIterator) throws SQLException {\n \t            final PTable table = tableRef.getTable();\n \t            // Track tables to which we've sent uncommitted data\n \t            if (isTransactional = table.isTransactional()) {\n-\t                addReadFence(table);\n-                    txTableRefs.add(tableRef);\n+\t                txTableRefs.add(tableRef);\n \t                uncommittedPhysicalNames.add(table.getPhysicalName().getString());\n \t            }\n \t            boolean isDataTable = true;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java", "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java", "sha": "6bb57224b260af6cb82e945abb6523a953a04ef8", "changes": 1, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616", "patch": "@@ -331,6 +331,7 @@ public Integer call() throws SQLException {\n                                 MutationPlan plan = stmt.compilePlan(PhoenixStatement.this, Sequence.ValueOp.VALIDATE_SEQUENCE);\n                                 if (plan.getTargetRef() != null && plan.getTargetRef().getTable() != null && plan.getTargetRef().getTable().isTransactional()) {\n                                     state.startTransaction();\n+                                    state.addReadFence(plan.getTargetRef().getTable());\n                                 }\n                                 Iterator<TableRef> tableRefs = plan.getSourceRefs().iterator();\n                                 state.sendUncommitted(tableRefs);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/71832b59ff8435067f9db3ac79f0a6360271fa75", "parent": "https://github.com/apache/phoenix/commit/6f16a6a629fdeca587f38fe6e1349a2b6f0fabd8", "message": "PHOENIX-1562 NPE in ServerCacheClient", "bug_id": "phoenix_25", "file": [{"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/71832b59ff8435067f9db3ac79f0a6360271fa75/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java", "blob_url": "https://github.com/apache/phoenix/blob/71832b59ff8435067f9db3ac79f0a6360271fa75/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java", "sha": "1233e1c806d11f97bd343cbcef18300df6702fc6", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java?ref=71832b59ff8435067f9db3ac79f0a6360271fa75", "patch": "@@ -24,12 +24,12 @@\n import java.sql.SQLException;\n import java.util.ArrayList;\n import java.util.Collections;\n-import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Random;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Future;\n import java.util.concurrent.TimeUnit;\n@@ -82,7 +82,7 @@\n     private static final Log LOG = LogFactory.getLog(ServerCacheClient.class);\n     private static final Random RANDOM = new Random();\n     private final PhoenixConnection connection;\n-    private final Map<Integer, TableRef> cacheUsingTableRefMap = new HashMap<Integer, TableRef>();\n+    private final Map<Integer, TableRef> cacheUsingTableRefMap = new ConcurrentHashMap<Integer, TableRef>();\n \n     /**\n      * Construct client used to create a serialized cached snapshot of a table and send it to each region server", "filename": "phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/e5a8dca90c369320ee12098e42f856626f2c9d69", "parent": "https://github.com/apache/phoenix/commit/e24b16a4df8d44e03dea47cbdb319be6485f22f2", "message": "PHOENIX-3021 Using local index during compaction is producing NPE(Sergey Soldatov)", "bug_id": "phoenix_26", "file": [{"additions": 61, "raw_url": "https://github.com/apache/phoenix/raw/e5a8dca90c369320ee12098e42f856626f2c9d69/phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/IndexHalfStoreFileReaderGenerator.java", "blob_url": "https://github.com/apache/phoenix/blob/e5a8dca90c369320ee12098e42f856626f2c9d69/phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/IndexHalfStoreFileReaderGenerator.java", "sha": "4a429841af8f8595b9ee60ca63aeb44422ce245f", "changes": 87, "status": "modified", "deletions": 26, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/IndexHalfStoreFileReaderGenerator.java?ref=e5a8dca90c369320ee12098e42f856626f2c9d69", "patch": "@@ -28,6 +28,7 @@\n \n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.Cell;\n import org.apache.hadoop.hbase.CellUtil;\n import org.apache.hadoop.hbase.HConstants;\n import org.apache.hadoop.hbase.HRegionInfo;\n@@ -246,36 +247,70 @@ public KeyValueScanner preStoreScannerOpen(final ObserverContext<RegionCoprocess\n         if (store.getFamily().getNameAsString()\n                 .startsWith(QueryConstants.LOCAL_INDEX_COLUMN_FAMILY_PREFIX)\n                 && store.hasReferences()) {\n-            long readPt = c.getEnvironment().getRegion().getReadpoint(scan.getIsolationLevel());\n-            boolean scanUsePread = c.getEnvironment().getConfiguration().getBoolean(\"hbase.storescanner.use.pread\", scan.isSmall());\n-            Collection<StoreFile> storeFiles = store.getStorefiles();\n-            List<StoreFile> nonReferenceStoreFiles = new ArrayList<StoreFile>(store.getStorefiles().size());\n-            List<StoreFile> referenceStoreFiles = new ArrayList<StoreFile>(store.getStorefiles().size());\n-            List<KeyValueScanner> keyValueScanners = new ArrayList<KeyValueScanner>(store.getStorefiles().size()+1);\n-            for(StoreFile storeFile : storeFiles) {\n-                if (storeFile.isReference()) {\n-                    referenceStoreFiles.add(storeFile);\n-                } else {\n-                    nonReferenceStoreFiles.add(storeFile);\n-                }\n-            } \n-            List<StoreFileScanner> scanners = StoreFileScanner.getScannersForStoreFiles(nonReferenceStoreFiles, scan.getCacheBlocks(), scanUsePread, readPt);\n-            keyValueScanners.addAll(scanners);\n-            for(StoreFile sf :  referenceStoreFiles) {\n-                if(sf.getReader() instanceof IndexHalfStoreFileReader) {\n-                    keyValueScanners.add(new LocalIndexStoreFileScanner(sf.getReader(), sf.getReader()\n+            final long readPt = c.getEnvironment().getRegion().getReadpoint(scan.getIsolationLevel\n+                    ());\n+            if (!scan.isReversed()) {\n+                return new StoreScanner(store, store.getScanInfo(), scan,\n+                        targetCols, readPt) {\n+\n+                    @Override\n+                    protected List<KeyValueScanner> getScannersNoCompaction() throws IOException {\n+                        if (store.hasReferences()) {\n+                            return getLocalIndexScanners(c, store, scan, readPt);\n+                        } else {\n+                            return super.getScannersNoCompaction();\n+                        }\n+                    }\n+                };\n+            } else {\n+                return new ReversedStoreScanner(store, store.getScanInfo(), scan,\n+                        targetCols, readPt) {\n+                    @Override\n+                    protected List<KeyValueScanner> getScannersNoCompaction() throws IOException {\n+                        if (store.hasReferences()) {\n+                            return getLocalIndexScanners(c, store, scan, readPt);\n+                        } else {\n+                            return super.getScannersNoCompaction();\n+                        }\n+                    }\n+                };\n+            }\n+        }\n+        return s;\n+    }\n+\n+    private List<KeyValueScanner> getLocalIndexScanners(final\n+                                                ObserverContext<RegionCoprocessorEnvironment> c,\n+                          final Store store, final Scan scan, final long readPt) throws IOException {\n+\n+        boolean scanUsePread = c.getEnvironment().getConfiguration().getBoolean(\"hbase.storescanner.use.pread\", scan.isSmall());\n+        Collection<StoreFile> storeFiles = store.getStorefiles();\n+        List<StoreFile> nonReferenceStoreFiles = new ArrayList<>(store.getStorefiles().size());\n+        List<StoreFile> referenceStoreFiles = new ArrayList<>(store.getStorefiles().size\n+                ());\n+        final List<KeyValueScanner> keyValueScanners = new ArrayList<>(store\n+                .getStorefiles().size() + 1);\n+        for (StoreFile storeFile : storeFiles) {\n+            if (storeFile.isReference()) {\n+                referenceStoreFiles.add(storeFile);\n+            } else {\n+                nonReferenceStoreFiles.add(storeFile);\n+            }\n+        }\n+        final List<StoreFileScanner> scanners = StoreFileScanner.getScannersForStoreFiles(nonReferenceStoreFiles, scan.getCacheBlocks(), scanUsePread, readPt);\n+        keyValueScanners.addAll(scanners);\n+        for (StoreFile sf : referenceStoreFiles) {\n+            if (sf.getReader() instanceof IndexHalfStoreFileReader) {\n+                keyValueScanners.add(new LocalIndexStoreFileScanner(sf.getReader(), sf.getReader()\n                         .getScanner(scan.getCacheBlocks(), scanUsePread, false), true, sf\n                         .getReader().getHFileReader().hasMVCCInfo(), readPt));\n-                } else {\n-                    keyValueScanners.add(new StoreFileScanner(sf.getReader(), sf.getReader()\n+            } else {\n+                keyValueScanners.add(new StoreFileScanner(sf.getReader(), sf.getReader()\n                         .getScanner(scan.getCacheBlocks(), scanUsePread, false), true, sf\n                         .getReader().getHFileReader().hasMVCCInfo(), readPt));\n-                }\n             }\n-            keyValueScanners.addAll(((HStore)store).memstore.getScanners(readPt));\n-            if(!scan.isReversed()) return new StoreScanner(scan, store.getScanInfo(), ScanType.USER_SCAN, targetCols, keyValueScanners);\n-            return new ReversedStoreScanner(scan, store.getScanInfo(), ScanType.USER_SCAN, targetCols, keyValueScanners);\n-        } \n-        return s;\n+        }\n+        keyValueScanners.addAll(((HStore) store).memstore.getScanners(readPt));\n+        return keyValueScanners;\n     }\n }", "filename": "phoenix-core/src/main/java/org/apache/hadoop/hbase/regionserver/IndexHalfStoreFileReaderGenerator.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/41c16a020fcd1cb143675ea17e2d9d3a56750a8a", "parent": "https://github.com/apache/phoenix/commit/c83d272b565447d39c42a4a8d3b0687bb2b5a16c", "message": "PHOENIX-3386 PhoenixStorageHandler throws NPE if local tasks executed via child\n\nSigned-off-by: Sergey Soldatov <ssa@apache.org>", "bug_id": "phoenix_27", "file": [{"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java", "sha": "2264acd54e1ecbf43d104eeb9640e8a7eef61295", "changes": 2, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a", "patch": "@@ -55,6 +55,8 @@\n public final class PhoenixConfigurationUtil {\n \n     private static final Log LOG = LogFactory.getLog(PhoenixInputFormat.class);\n+\n+    public static final String SESSION_ID = \"phoenix.sessionid\";\n     \n     public static final String UPSERT_STATEMENT = \"phoenix.upsert.stmt\";\n     ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java"}, {"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java", "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java", "sha": "bda2282e5f41d15b31b739876697537e3bd89b01", "changes": 4, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a", "patch": "@@ -31,6 +31,7 @@\n import org.apache.hadoop.hive.ql.metadata.InputEstimator;\n import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;\n import org.apache.hadoop.hive.ql.plan.TableDesc;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n import org.apache.hadoop.hive.serde2.Deserializer;\n import org.apache.hadoop.hive.serde2.SerDe;\n import org.apache.hadoop.mapred.InputFormat;\n@@ -142,7 +143,10 @@ protected void configureJobProperties(TableDesc tableDesc, Map<String, String> j\n             tableProperties.setProperty(PhoenixStorageHandlerConstants.PHOENIX_TABLE_NAME,\n                     tableName);\n         }\n+        SessionState sessionState = SessionState.get();\n \n+        String sessionId = sessionState.getSessionId();\n+        jobProperties.put(PhoenixConfigurationUtil.SESSION_ID, sessionId);\n         jobProperties.put(PhoenixConfigurationUtil.INPUT_TABLE_NAME, tableName);\n         jobProperties.put(PhoenixStorageHandlerConstants.ZOOKEEPER_QUORUM, tableProperties\n                 .getProperty(PhoenixStorageHandlerConstants.ZOOKEEPER_QUORUM,", "filename": "phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java", "sha": "1313fdb704309e5a6dcecc85a48184b273563a50", "changes": 5, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a", "patch": "@@ -33,6 +33,7 @@\n import org.apache.hadoop.net.DNS;\n import org.apache.phoenix.hive.constants.PhoenixStorageHandlerConstants;\n import org.apache.phoenix.hive.ql.index.IndexSearchCondition;\n+import org.apache.phoenix.mapreduce.util.PhoenixConfigurationUtil;\n \n import javax.naming.NamingException;\n import java.io.ByteArrayInputStream;\n@@ -182,10 +183,8 @@ private static String reverseDNS(InetAddress ipAddress) throws NamingException,\n     }\n \n     public static String getTableKeyOfSession(JobConf jobConf, String tableName) {\n-        SessionState sessionState = SessionState.get();\n-\n-        String sessionId = sessionState.getSessionId();\n \n+        String sessionId = jobConf.get(PhoenixConfigurationUtil.SESSION_ID);\n         return new StringBuilder(\"[\").append(sessionId).append(\"]-\").append(tableName).toString();\n     }\n ", "filename": "phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/b8f32aeaa735689f231268d7c790efbd6051d7f4", "parent": "https://github.com/apache/phoenix/commit/cf41cc63594ac7d8f3d831511215519fe43afea0", "message": "PHOENIX-1360: NPE in SpoolingResultIterator", "bug_id": "phoenix_28", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/b8f32aeaa735689f231268d7c790efbd6051d7f4/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java", "blob_url": "https://github.com/apache/phoenix/blob/b8f32aeaa735689f231268d7c790efbd6051d7f4/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java", "sha": "0ba6554077bb5a434ea84fef64cc1a4a1b16bd10", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java?ref=b8f32aeaa735689f231268d7c790efbd6051d7f4", "patch": "@@ -132,7 +132,7 @@ protected void thresholdReached() throws IOException {\n                 scanner.close();\n             } finally {\n                 try {\n-                    if (!usedOnDiskIterator) {\n+                    if (!usedOnDiskIterator && tempFile != null) {\n                         tempFile.delete();\n                     }\n                 } finally {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/5097982b00b36b74fb328afaab02159e81b21af0", "parent": "https://github.com/apache/phoenix/commit/4f6ee74c0a7b94282575300cfd698e78198685fb", "message": "PHOENIX-2276 Creating index on a global view on a multi-tenant table fails with NPE", "bug_id": "phoenix_29", "file": [{"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java", "sha": "0703e82aab2aedbe097613c3d0dd5eb139741d3a", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -140,9 +140,9 @@ private void createAndVerifyIndex(Connection conn, Integer saltBuckets, String t\n                             + \"CLIENT MERGE SORT\", QueryUtil.getExplainPlan(rs));\n         } else {\n             String expected = saltBuckets == null ? \n-                    \"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['\" + tenantId + \"',-32768,'\" + valuePrefix + \"v2-1']\\n\"\n+                    \"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32768,'\" + tenantId + \"','\" + valuePrefix + \"v2-1']\\n\"\n                             + \"    SERVER FILTER BY FIRST KEY ONLY\" :\n-                    \"CLIENT PARALLEL 3-WAY RANGE SCAN OVER _IDX_T [0,'\" + tenantId + \"',-32768,'\" + valuePrefix + \"v2-1']\\n\"\n+                    \"CLIENT PARALLEL 3-WAY RANGE SCAN OVER _IDX_T [0,-32768,'\" + tenantId + \"','\" + valuePrefix + \"v2-1']\\n\"\n                   + \"    SERVER FILTER BY FIRST KEY ONLY\\n\"\n                   + \"CLIENT MERGE SORT\";\n             assertEquals(expected, QueryUtil.getExplainPlan(rs));", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java", "sha": "f468d2003bf28bc79499c3d9e53a8676499d517a", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -206,7 +206,7 @@ private void createViewAndIndexesWithTenantId(String tableName,String baseViewNa\n             assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER \"\n                     + Bytes.toString(MetaDataUtil.getViewIndexPhysicalName(SchemaUtil\n                             .getPhysicalHBaseTableName(tableName, isNamespaceMapped, PTableType.TABLE).getBytes()))\n-                    + \" ['\" + tenantId + \"',-32768,'f']\\n\" + \"    SERVER FILTER BY FIRST KEY ONLY\",\n+                    + \" [-32768,'\" + tenantId + \"','f']\\n\" + \"    SERVER FILTER BY FIRST KEY ONLY\",\n                     QueryUtil.getExplainPlan(rs));\n         }\n ", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java"}, {"additions": 34, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java", "sha": "4da62de659fa9197452eb406626e0c35a1e1d32e", "changes": 34, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -22,6 +22,7 @@\n import static org.junit.Assert.assertTrue;\n \n import java.sql.Connection;\n+import java.sql.Date;\n import java.sql.DriverManager;\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n@@ -33,9 +34,11 @@\n \n import org.apache.hadoop.hbase.TableName;\n import org.apache.hadoop.hbase.client.HBaseAdmin;\n+import org.apache.phoenix.compile.QueryPlan;\n import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n import org.apache.phoenix.end2end.Shadower;\n import org.apache.phoenix.jdbc.PhoenixDatabaseMetaData;\n+import org.apache.phoenix.jdbc.PhoenixStatement;\n import org.apache.phoenix.query.QueryServices;\n import org.apache.phoenix.schema.PNameFactory;\n import org.apache.phoenix.util.MetaDataUtil;\n@@ -191,4 +194,35 @@ public void testMultiTenantViewLocalIndex() throws Exception {\n         assertTrue(rs.next());\n         assertFalse(rs.next());\n     }\n+    \n+    @Test\n+    public void testCreatingIndexOnGlobalView() throws Exception {\n+        String baseTable = \"testCreatingIndexOnGlobalView\".toUpperCase();\n+        String globalView = \"globalView\".toUpperCase();\n+        String globalViewIdx = \"globalView_idx\".toUpperCase();\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.createStatement().execute(\"CREATE TABLE \" + baseTable + \" (TENANT_ID CHAR(15) NOT NULL, PK2 DATE NOT NULL, PK3 INTEGER NOT NULL, KV1 VARCHAR, KV2 VARCHAR, KV3 CHAR(15) CONSTRAINT PK PRIMARY KEY(TENANT_ID, PK2 ROW_TIMESTAMP, PK3)) MULTI_TENANT=true\");\n+            conn.createStatement().execute(\"CREATE VIEW \" + globalView + \" AS SELECT * FROM \" + baseTable);\n+            conn.createStatement().execute(\"CREATE INDEX \" + globalViewIdx + \" ON \" + globalView + \" (PK3 DESC, KV3) INCLUDE (KV1)\");\n+            PreparedStatement stmt = conn.prepareStatement(\"UPSERT INTO  \" + globalView + \" (TENANT_ID, PK2, PK3, KV1, KV3) VALUES (?, ?, ?, ?, ?)\");\n+            stmt.setString(1, \"tenantId\");\n+            stmt.setDate(2, new Date(100));\n+            stmt.setInt(3, 1);\n+            stmt.setString(4, \"KV1\");\n+            stmt.setString(5, \"KV3\");\n+            stmt.executeUpdate();\n+            conn.commit();\n+            \n+            // Verify that query against the global view index works\n+            stmt = conn.prepareStatement(\"SELECT KV1 FROM  \" + globalView + \" WHERE PK3 = ? AND KV3 = ?\");\n+            stmt.setInt(1, 1);\n+            stmt.setString(2, \"KV3\");\n+            ResultSet rs = stmt.executeQuery();\n+            QueryPlan plan = stmt.unwrap(PhoenixStatement.class).getQueryPlan();\n+            assertTrue(plan.getTableRef().getTable().getName().getString().equals(globalViewIdx));\n+            assertTrue(rs.next());\n+            assertEquals(\"KV1\", rs.getString(1));\n+            assertFalse(rs.next());\n+        }\n+    }\n }\n\\ No newline at end of file", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java"}, {"additions": 24, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java", "sha": "d88b094644dc96c12bbb98594d2d2653d5080db7", "changes": 40, "status": "modified", "deletions": 16, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -195,18 +195,22 @@ public AddServerCacheResponse call(ServerCachingService instance) throws IOExcep\n                                                     BlockingRpcCallback<AddServerCacheResponse> rpcCallback =\n                                                             new BlockingRpcCallback<AddServerCacheResponse>();\n                                                     AddServerCacheRequest.Builder builder = AddServerCacheRequest.newBuilder();\n-                                                    if(connection.getTenantId() != null){\n+                                                    final byte[] tenantIdBytes;\n+                                                    if(cacheUsingTable.isMultiTenant()) {\n                                                         try {\n-                                                            byte[] tenantIdBytes =\n+                                                            tenantIdBytes = connection.getTenantId() == null ? null :\n                                                                     ScanUtil.getTenantIdBytes(\n                                                                             cacheUsingTable.getRowKeySchema(),\n-                                                                            cacheUsingTable.getBucketNum()!=null,\n-                                                                            connection.getTenantId(),\n-                                                                            cacheUsingTable.isMultiTenant());\n-                                                            builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                                                            cacheUsingTable.getBucketNum() != null,\n+                                                                            connection.getTenantId(), cacheUsingTable.getViewIndexId() != null);\n                                                         } catch (SQLException e) {\n-                                                            new IOException(e);\n+                                                            throw new IOException(e);\n                                                         }\n+                                                    } else {\n+                                                        tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n+                                                    }\n+                                                    if (tenantIdBytes != null) {\n+                                                        builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n                                                     }\n                                                     builder.setCacheId(ByteStringer.wrap(cacheId));\n                                                     builder.setCachePtr(org.apache.phoenix.protobuf.ProtobufUtil.toProto(cachePtr));\n@@ -325,20 +329,24 @@ public RemoveServerCacheResponse call(ServerCachingService instance) throws IOEx\n     \t\t\t\t\t\t\tBlockingRpcCallback<RemoveServerCacheResponse> rpcCallback =\n     \t\t\t\t\t\t\t\t\tnew BlockingRpcCallback<RemoveServerCacheResponse>();\n     \t\t\t\t\t\t\tRemoveServerCacheRequest.Builder builder = RemoveServerCacheRequest.newBuilder();\n-    \t\t\t\t\t\t\tif(connection.getTenantId() != null){\n+                                final byte[] tenantIdBytes;\n+                                if(cacheUsingTable.isMultiTenant()) {\n                                     try {\n-                                        byte[] tenantIdBytes =\n+                                        tenantIdBytes = connection.getTenantId() == null ? null :\n                                                 ScanUtil.getTenantIdBytes(\n                                                         cacheUsingTable.getRowKeySchema(),\n-                                                        cacheUsingTable.getBucketNum()!=null,\n-                                                        connection.getTenantId(),\n-                                                        cacheUsingTable.isMultiTenant());\n-                                        builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                                        cacheUsingTable.getBucketNum() != null,\n+                                                        connection.getTenantId(), cacheUsingTable.getViewIndexId() != null);\n                                     } catch (SQLException e) {\n-                                        new IOException(e);\n+                                        throw new IOException(e);\n                                     }\n-    \t\t\t\t\t\t\t}\n-    \t\t\t\t\t\t\tbuilder.setCacheId(ByteStringer.wrap(cacheId));\n+                                } else {\n+                                    tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n+                                }\n+                                if (tenantIdBytes != null) {\n+                                    builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                }\n+                                builder.setCacheId(ByteStringer.wrap(cacheId));\n     \t\t\t\t\t\t\tinstance.removeServerCache(controller, builder.build(), rpcCallback);\n     \t\t\t\t\t\t\tif(controller.getFailedOn() != null) {\n     \t\t\t\t\t\t\t\tthrow controller.getFailedOn();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java"}, {"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "sha": "504f9948675caa0e5db5937d4662884ca14b0f04", "changes": 8, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -107,7 +107,7 @@ private static MutationState deleteRows(StatementContext childContext, TableRef\n         PName tenantId = connection.getTenantId();\n         byte[] tenantIdBytes = null;\n         if (tenantId != null) {\n-            tenantIdBytes = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId);\n+            tenantIdBytes = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId, table.getViewIndexId() != null);\n         }\n         final boolean isAutoCommit = connection.getAutoCommit();\n         ConnectionQueryServices services = connection.getQueryServices();\n@@ -125,12 +125,12 @@ private static MutationState deleteRows(StatementContext childContext, TableRef\n         boolean isSharedViewIndex = table.getViewIndexId() != null;\n         int offset = (table.getBucketNum() == null ? 0 : 1);\n         byte[][] values = new byte[pkColumns.size()][];\n-        if (isMultiTenant) {\n-            values[offset++] = tenantIdBytes;\n-        }\n         if (isSharedViewIndex) {\n             values[offset++] = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n         }\n+        if (isMultiTenant) {\n+            values[offset++] = tenantIdBytes;\n+        }\n         try (PhoenixResultSet rs = new PhoenixResultSet(iterator, projector, childContext)) {\n             int rowCount = 0;\n             while (rs.next()) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java"}, {"additions": 20, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "sha": "be6499bf1702d805080fd6de74c9341d1f688775", "changes": 40, "status": "modified", "deletions": 20, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -334,18 +334,18 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                     targetColumns = Lists.newArrayListWithExpectedSize(columnIndexesToBe.length);\n                     targetColumns.addAll(Collections.<PColumn>nCopies(columnIndexesToBe.length, null));\n                     int minPKPos = 0;\n-                    if (isTenantSpecific) {\n-                        PColumn tenantColumn = table.getPKColumns().get(minPKPos);\n-                        columnIndexesToBe[minPKPos] = tenantColumn.getPosition();\n-                        targetColumns.set(minPKPos, tenantColumn);\n-                        minPKPos++;\n-                    }\n                     if (isSharedViewIndex) {\n                         PColumn indexIdColumn = table.getPKColumns().get(minPKPos);\n                         columnIndexesToBe[minPKPos] = indexIdColumn.getPosition();\n                         targetColumns.set(minPKPos, indexIdColumn);\n                         minPKPos++;\n                     }\n+                    if (isTenantSpecific) {\n+                        PColumn tenantColumn = table.getPKColumns().get(minPKPos);\n+                        columnIndexesToBe[minPKPos] = tenantColumn.getPosition();\n+                        targetColumns.set(minPKPos, tenantColumn);\n+                        minPKPos++;\n+                    }\n                     for (int i = posOffset, j = 0; i < allColumnsToBe.size(); i++) {\n                         PColumn column = allColumnsToBe.get(i);\n                         if (SchemaUtil.isPKColumn(column)) {\n@@ -375,6 +375,13 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                     Arrays.fill(pkSlotIndexesToBe, -1); // TODO: necessary? So we'll get an AIOB exception if it's not replaced\n                     BitSet pkColumnsSet = new BitSet(table.getPKColumns().size());\n                     int i = 0;\n+                    if (isSharedViewIndex) {\n+                        PColumn indexIdColumn = table.getPKColumns().get(i + posOffset);\n+                        columnIndexesToBe[i] = indexIdColumn.getPosition();\n+                        pkColumnsSet.set(pkSlotIndexesToBe[i] = i + posOffset);\n+                        targetColumns.set(i, indexIdColumn);\n+                        i++;\n+                    }\n                     // Add tenant column directly, as we don't want to resolve it as this will fail\n                     if (isTenantSpecific) {\n                         PColumn tenantColumn = table.getPKColumns().get(i + posOffset);\n@@ -383,13 +390,6 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                         targetColumns.set(i, tenantColumn);\n                         i++;\n                     }\n-                    if (isSharedViewIndex) {\n-                        PColumn indexIdColumn = table.getPKColumns().get(i + posOffset);\n-                        columnIndexesToBe[i] = indexIdColumn.getPosition();\n-                        pkColumnsSet.set(pkSlotIndexesToBe[i] = i + posOffset);\n-                        targetColumns.set(i, indexIdColumn);\n-                        i++;\n-                    }\n                     for (ColumnName colName : columnNodes) {\n                         ColumnRef ref = resolver.resolveColumn(null, colName.getFamilyName(), colName.getColumnName());\n                         PColumn column = ref.getColumn();\n@@ -820,13 +820,13 @@ public ExplainPlan getExplainPlan() throws SQLException {\n         /////////////////////////////////////////////////////////////////////\n         final byte[][] values = new byte[nValuesToSet][];\n         int nodeIndex = 0;\n-        if (isTenantSpecific) {\n-            PName tenantId = connection.getTenantId();\n-            values[nodeIndex++] = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId);\n-        }\n         if (isSharedViewIndex) {\n             values[nodeIndex++] = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n         }\n+        if (isTenantSpecific) {\n+            PName tenantId = connection.getTenantId();\n+            values[nodeIndex++] = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId, isSharedViewIndex);\n+        }\n         \n         final int nodeIndexOffset = nodeIndex;\n         // Allocate array based on size of all columns in table,\n@@ -1015,12 +1015,12 @@ private static SelectStatement prependTenantAndViewConstants(PTable table, Selec\n             return select;\n         }\n         List<AliasedNode> selectNodes = newArrayListWithCapacity(select.getSelect().size() + 1 + addViewColumns.size());\n-        if (table.isMultiTenant() && tenantId != null) {\n-            selectNodes.add(new AliasedNode(null, new LiteralParseNode(tenantId)));\n-        }\n         if (table.getViewIndexId() != null) {\n             selectNodes.add(new AliasedNode(null, new LiteralParseNode(table.getViewIndexId())));\n         }\n+        if (table.isMultiTenant() && tenantId != null) {\n+            selectNodes.add(new AliasedNode(null, new LiteralParseNode(tenantId)));\n+        }\n         selectNodes.addAll(select.getSelect());\n         for (PColumn column : addViewColumns) {\n             byte[] byteValue = column.getViewConstant();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java"}, {"additions": 16, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "sha": "8c2a216b59781593aaa26d017e3b3418165fac8f", "changes": 29, "status": "modified", "deletions": 13, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -114,8 +114,10 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n     \tboolean isSalted = nBuckets != null;\n     \tRowKeySchema schema = table.getRowKeySchema();\n     \tboolean isMultiTenant = tenantId != null && table.isMultiTenant();\n+    \tboolean isSharedIndex = table.getViewIndexId() != null;\n+    \t\n     \tif (isMultiTenant) {\n-            tenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId);\n+            tenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId, isSharedIndex);\n     \t}\n \n         if (whereClause == null && (tenantId == null || !table.isMultiTenant()) && table.getViewIndexId() == null) {\n@@ -187,6 +189,19 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             pkPos++;\n         }\n         \n+        // Add unique index ID for shared indexes on views. This ensures\n+        // that different indexes don't interleave.\n+        if (hasViewIndex) {\n+            byte[] viewIndexBytes = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n+            KeyRange indexIdKeyRange = KeyRange.getKeyRange(viewIndexBytes);\n+            cnf.add(singletonList(indexIdKeyRange));\n+            if (hasMinMaxRange) {\n+                System.arraycopy(viewIndexBytes, 0, minMaxRangePrefix, minMaxRangeOffset, viewIndexBytes.length);\n+                minMaxRangeOffset += viewIndexBytes.length;\n+            }\n+            pkPos++;\n+        }\n+        \n         // Add tenant data isolation for tenant-specific tables\n         if (isMultiTenant) {\n             KeyRange tenantIdKeyRange = KeyRange.getKeyRange(tenantIdBytes);\n@@ -202,18 +217,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             }\n             pkPos++;\n         }\n-        // Add unique index ID for shared indexes on views. This ensures\n-        // that different indexes don't interleave.\n-        if (hasViewIndex) {\n-            byte[] viewIndexBytes = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n-            KeyRange indexIdKeyRange = KeyRange.getKeyRange(viewIndexBytes);\n-            cnf.add(singletonList(indexIdKeyRange));\n-            if (hasMinMaxRange) {\n-                System.arraycopy(viewIndexBytes, 0, minMaxRangePrefix, minMaxRangeOffset, viewIndexBytes.length);\n-                minMaxRangeOffset += viewIndexBytes.length;\n-            }\n-            pkPos++;\n-        }\n         \n         // Prepend minMaxRange with fixed column values so we can properly intersect the\n         // range with the other range.", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java", "sha": "b940084a934d846ffd5645d4c059ad4a13b55c90", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -278,8 +278,8 @@ public final ResultIterator iterator(final List<? extends SQLCloseable> dependen\n             tenantIdBytes = connection.getTenantId() == null ? null :\n                     ScanUtil.getTenantIdBytes(\n                             table.getRowKeySchema(),\n-                            table.getBucketNum()!=null,\n-                            connection.getTenantId());\n+                            table.getBucketNum() != null,\n+                            connection.getTenantId(), table.getViewIndexId() != null);\n         } else {\n             tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n         }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java"}, {"additions": 10, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java", "sha": "db823deec60351db49f17d7ddc1b12b12289954c", "changes": 18, "status": "modified", "deletions": 8, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -476,6 +476,11 @@ private IndexMaintainer(PTable dataTable, PTable index, PhoenixConnection connec\n             // Skip data table salt byte\n             int maxRowKeyOffset = rowKeyPtr.getOffset() + rowKeyPtr.getLength();\n             dataRowKeySchema.iterator(rowKeyPtr, ptr, dataPosOffset);\n+            \n+            if (viewIndexId != null) {\n+                output.write(viewIndexId);\n+            }\n+            \n             if (isMultiTenant) {\n                 dataRowKeySchema.next(ptr, dataPosOffset, maxRowKeyOffset);\n                 output.write(ptr.get(), ptr.getOffset(), ptr.getLength());\n@@ -484,9 +489,6 @@ private IndexMaintainer(PTable dataTable, PTable index, PhoenixConnection connec\n                 }\n                 dataPosOffset++;\n             }\n-            if (viewIndexId != null) {\n-                output.write(viewIndexId);\n-            }\n             \n             // Write index row key\n             for (int i = dataPosOffset; i < dataRowKeySchema.getFieldCount(); i++) {\n@@ -714,11 +716,6 @@ private RowKeySchema generateIndexRowKeySchema() {\n             nIndexedColumns--;\n         }\n         int dataPosOffset = isDataTableSalted ? 1 : 0 ;\n-        if (isMultiTenant) {\n-            Field field = dataRowKeySchema.getField(dataPosOffset++);\n-            builder.addField(field, field.isNullable(), field.getSortOrder());\n-            nIndexedColumns--;\n-        }\n         if (viewIndexId != null) {\n             nIndexedColumns--;\n             builder.addField(new PDatum() {\n@@ -750,6 +747,11 @@ public SortOrder getSortOrder() {\n                 \n             }, false, SortOrder.getDefault());\n         }\n+        if (isMultiTenant) {\n+            Field field = dataRowKeySchema.getField(dataPosOffset++);\n+            builder.addField(field, field.isNullable(), field.getSortOrder());\n+            nIndexedColumns--;\n+        }\n         \n         Field[] indexFields = new Field[nIndexedColumns];\n         BitSet viewConstantColumnBitSet = this.rowKeyMetaData.getViewConstantColumnBitSet();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java"}, {"additions": 189, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java", "sha": "d1cbdfc2022797a1f47f7fb418f22aa10f806e67", "changes": 194, "status": "modified", "deletions": 5, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -21,7 +21,17 @@\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_MAJOR_VERSION;\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_MINOR_VERSION;\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_PATCH_NUMBER;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.COLUMN_FAMILY;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.COLUMN_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.DATA_TABLE_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.INDEX_TYPE;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.ORDINAL_POSITION;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME;\n import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME_BYTES;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TABLE_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TABLE_SCHEM;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TENANT_ID;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.VIEW_INDEX_ID;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_DROP_METADATA;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_RENEW_LEASE_ENABLED;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_RENEW_LEASE_THREAD_POOL_SIZE;\n@@ -31,6 +41,8 @@\n \n import java.io.IOException;\n import java.lang.ref.WeakReference;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n import java.sql.SQLException;\n import java.util.ArrayList;\n import java.util.Arrays;\n@@ -156,6 +168,7 @@\n import org.apache.phoenix.schema.PName;\n import org.apache.phoenix.schema.PNameFactory;\n import org.apache.phoenix.schema.PTable;\n+import org.apache.phoenix.schema.PTable.IndexType;\n import org.apache.phoenix.schema.PTableKey;\n import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.schema.ReadOnlyTableException;\n@@ -893,15 +906,15 @@ private void addCoprocessors(byte[] tableName, HTableDescriptor descriptor, PTab\n \n     private static interface RetriableOperation {\n         boolean checkForCompletion() throws TimeoutException, IOException;\n-        String getOperatioName();\n+        String getOperationName();\n     }\n \n     private void pollForUpdatedTableDescriptor(final HBaseAdmin admin, final HTableDescriptor newTableDescriptor,\n             final byte[] tableName) throws InterruptedException, TimeoutException {\n         checkAndRetry(new RetriableOperation() {\n \n             @Override\n-            public String getOperatioName() {\n+            public String getOperationName() {\n                 return \"UpdateOrNewTableDescriptor\";\n             }\n \n@@ -932,7 +945,7 @@ private void checkAndRetry(RetriableOperation op) throws InterruptedException, T\n                 // Else, we swallow the exception and retry till we reach maxRetries.\n                 if (numTries == 1 || numTries == maxRetries) {\n                     watch.stop();\n-                    TimeoutException toThrow = new TimeoutException(\"Operation \" + op.getOperatioName()\n+                    TimeoutException toThrow = new TimeoutException(\"Operation \" + op.getOperationName()\n                             + \" didn't complete because of exception. Time elapsed: \" + watch.elapsedMillis());\n                     toThrow.initCause(ex);\n                     throw toThrow;\n@@ -945,13 +958,13 @@ private void checkAndRetry(RetriableOperation op) throws InterruptedException, T\n         watch.stop();\n \n         if (!success) {\n-            throw new TimeoutException(\"Operation  \" + op.getOperatioName() + \" didn't complete within \"\n+            throw new TimeoutException(\"Operation  \" + op.getOperationName() + \" didn't complete within \"\n                     + watch.elapsedMillis() + \" ms \"\n                     + (numTries > 1 ? (\"after trying \" + numTries + (numTries > 1 ? \"times.\" : \"time.\")) : \"\"));\n         } else {\n             if (logger.isDebugEnabled()) {\n                 logger.debug(\"Operation \"\n-                        + op.getOperatioName()\n+                        + op.getOperationName()\n                         + \" completed within \"\n                         + watch.elapsedMillis()\n                         + \"ms \"\n@@ -2493,6 +2506,7 @@ public Void call() throws Exception {\n                                             MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP_4_8_0,\n                                             PhoenixDatabaseMetaData.APPEND_ONLY_SCHEMA + \" \"\n                                                     + PBoolean.INSTANCE.getSqlTypeName());\n+                                    metaConnection = disableViewIndexes(metaConnection);\n                                     ConnectionQueryServicesImpl.this.removeTable(null,\n                                             PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME, null,\n                                             MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP_4_8_0);\n@@ -2710,6 +2724,176 @@ private PhoenixConnection setImmutableTableIndexesImmutable(PhoenixConnection ol\n         }\n         return metaConnection;\n     }\n+    \n+    private PhoenixConnection disableViewIndexes(PhoenixConnection connParam) throws SQLException, IOException, InterruptedException, TimeoutException {\n+        Properties props = PropertiesUtil.deepCopy(connParam.getClientInfo());\n+        Long originalScn = null;\n+        String str = props.getProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB);\n+        if (str != null) {\n+            originalScn = Long.valueOf(str);\n+        }\n+        // don't use the passed timestamp as scn because we want to query all view indexes up to now.\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(HConstants.LATEST_TIMESTAMP));\n+        Set<String> physicalTables = new HashSet<>();\n+        SQLException sqlEx = null;\n+        PhoenixConnection globalConnection = null;\n+        PhoenixConnection toReturn = null;\n+        try {\n+            globalConnection = new PhoenixConnection(connParam, this, props);\n+            String tenantId = null;\n+            try (HBaseAdmin admin = getAdmin()) {\n+                String fetchViewIndexes = \"SELECT \" + TENANT_ID + \", \" + TABLE_SCHEM + \", \" + TABLE_NAME + \n+                        \", \" + DATA_TABLE_NAME + \" FROM \" + SYSTEM_CATALOG_NAME + \" WHERE \" + VIEW_INDEX_ID\n+                        + \" IS NOT NULL AND \" + INDEX_TYPE + \"<>\" + IndexType.LOCAL.getSerializedValue();\n+                String disableIndexDDL = \"ALTER INDEX %s ON %s DISABLE\"; \n+                try (ResultSet rs = globalConnection.createStatement().executeQuery(fetchViewIndexes)) {\n+                    while (rs.next()) {\n+                        tenantId = rs.getString(1);\n+                        String indexSchema = rs.getString(2);\n+                        String indexName = rs.getString(3);\n+                        String viewName = rs.getString(4);\n+                        String fullIndexName = SchemaUtil.getTableName(indexSchema, indexName);\n+                        PTable viewPTable = null;\n+                        // Disable the view index and truncate the underlying hbase table. \n+                        // Users would need to rebuild the view indexes. \n+                        if (tenantId != null && !tenantId.isEmpty()) {\n+                            Properties newProps = PropertiesUtil.deepCopy(globalConnection.getClientInfo());\n+                            newProps.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB, tenantId);\n+                            PTable indexPTable = null;\n+                            try (PhoenixConnection tenantConnection = new PhoenixConnection(globalConnection, this, newProps)) {\n+                                viewPTable = PhoenixRuntime.getTable(tenantConnection, viewName);\n+                                tenantConnection.createStatement().execute(String.format(disableIndexDDL, fullIndexName, viewName));\n+                                indexPTable = PhoenixRuntime.getTable(tenantConnection, fullIndexName);\n+                            }\n+\n+                            int offset = indexPTable.getBucketNum() != null ? 1 : 0;\n+                            int existingTenantIdPosition = ++offset; // positions are stored 1 based\n+                            int existingViewIdxIdPosition = ++offset;\n+                            int newTenantIdPosition = existingViewIdxIdPosition;\n+                            int newViewIdxPosition = existingTenantIdPosition;\n+                            String tenantIdColumn = indexPTable.getColumns().get(existingTenantIdPosition - 1).getName().getString();\n+                            int index = 0;\n+                            String updatePosition =\n+                                    \"UPSERT INTO \"\n+                                            + SYSTEM_CATALOG_NAME\n+                                            + \" ( \"\n+                                            + TENANT_ID\n+                                            + \",\"\n+                                            + TABLE_SCHEM\n+                                            + \",\"\n+                                            + TABLE_NAME\n+                                            + \",\"\n+                                            + COLUMN_NAME\n+                                            + \",\"\n+                                            + COLUMN_FAMILY\n+                                            + \",\"\n+                                            + ORDINAL_POSITION\n+                                            + \") SELECT \"\n+                                            + TENANT_ID\n+                                            + \",\"\n+                                            + TABLE_SCHEM\n+                                            + \",\"\n+                                            + TABLE_NAME\n+                                            + \",\"\n+                                            + COLUMN_NAME\n+                                            + \",\"\n+                                            + COLUMN_FAMILY\n+                                            + \",\"\n+                                            + \"?\"\n+                                            + \" FROM \"\n+                                            + SYSTEM_CATALOG_NAME\n+                                            + \" WHERE \"\n+                                            + TENANT_ID\n+                                            + \" = ? \"\n+                                            + \" AND \"\n+                                            + TABLE_NAME\n+                                            + \" = ? \"\n+                                            + \" AND \"\n+                                            + (indexSchema == null ? TABLE_SCHEM + \" IS NULL\" : TABLE_SCHEM + \" = ? \") \n+                                            + \" AND \"\n+                                            + COLUMN_NAME \n+                                            + \" = ? \";\n+                            // update view index position\n+                            try (PreparedStatement s = globalConnection.prepareStatement(updatePosition)) {\n+                                index = 0;\n+                                s.setInt(++index, newViewIdxPosition);\n+                                s.setString(++index, tenantId);\n+                                s.setString(++index, indexName);\n+                                if (indexSchema != null) {\n+                                    s.setString(++index, indexSchema);\n+                                }\n+                                s.setString(++index, MetaDataUtil.getViewIndexIdColumnName());\n+                                s.executeUpdate();\n+                            }\n+                            // update tenant id position\n+                            try (PreparedStatement s = globalConnection.prepareStatement(updatePosition)) {\n+                                index = 0;\n+                                s.setInt(++index, newTenantIdPosition);\n+                                s.setString(++index, tenantId);\n+                                s.setString(++index, indexName);\n+                                if (indexSchema != null) {\n+                                    s.setString(++index, indexSchema);\n+                                }\n+                                s.setString(++index, tenantIdColumn);\n+                                s.executeUpdate();\n+                            }\n+                            globalConnection.commit();\n+                        } else {\n+                            viewPTable = PhoenixRuntime.getTable(globalConnection, viewName);\n+                            globalConnection.createStatement().execute(String.format(disableIndexDDL, fullIndexName, viewName));\n+                        }\n+                        String indexPhysicalTableName = MetaDataUtil.getViewIndexTableName(viewPTable.getPhysicalName().getString());\n+                        if (physicalTables.add(indexPhysicalTableName)) {\n+                            final TableName tableName = TableName.valueOf(indexPhysicalTableName);\n+                            admin.disableTableAsync(tableName);\n+                            checkAndRetry(new RetriableOperation() {\n+                                @Override\n+                                public boolean checkForCompletion() throws TimeoutException,\n+                                IOException {\n+                                    return admin.isTableDisabled(tableName);\n+                                }\n+\n+                                @Override\n+                                public String getOperationName() {\n+                                    return \"Disable table: \" + tableName.getNameAsString();\n+                                }\n+\n+                            });\n+                            admin.truncateTable(tableName, false);\n+                        }\n+                    }\n+                }\n+            }\n+            if (originalScn != null) {\n+                props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(originalScn));\n+            }\n+            toReturn = new PhoenixConnection(globalConnection, this, props);\n+        } catch (SQLException e) {\n+            sqlEx = e;\n+        } finally {\n+            sqlEx = closeConnection(connParam, sqlEx);\n+            sqlEx = closeConnection(globalConnection, sqlEx);\n+            if (sqlEx != null) {\n+                throw sqlEx;\n+            }\n+        }\n+        return toReturn;\n+    }\n+    \n+    \n+    private static SQLException closeConnection(PhoenixConnection conn, SQLException sqlEx) {\n+        SQLException toReturn = sqlEx;\n+        try {\n+            conn.close();\n+        } catch (SQLException e) {\n+            if (toReturn != null) {\n+                toReturn.setNextException(e);\n+            } else {\n+                toReturn = e;\n+            }\n+        }\n+        return toReturn;\n+    }\n \n     /**\n      * Forces update of SYSTEM.CATALOG by setting column to existing value", "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java"}, {"additions": 10, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "sha": "3a4010bab3a93a4c5071b51b7a8fd1cdb5dd5198", "changes": 21, "status": "modified", "deletions": 11, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -1316,30 +1316,29 @@ public MutationState createIndex(CreateIndexStatement statement, byte[][] splits\n                 List<ColumnDefInPkConstraint> allPkColumns = Lists.newArrayListWithExpectedSize(unusedPkColumns.size());\n                 List<ColumnDef> columnDefs = Lists.newArrayListWithExpectedSize(includedColumns.size() + indexParseNodeAndSortOrderList.size());\n                 \n-                if (dataTable.isMultiTenant()) {\n-                    // Add tenant ID column as first column in index\n-                    PColumn col = dataTable.getPKColumns().get(posOffset);\n-                    RowKeyColumnExpression columnExpression = new RowKeyColumnExpression(col, new RowKeyValueAccessor(pkColumns, posOffset), col.getName().getString());\n-                    unusedPkColumns.remove(columnExpression);\n-                    PDataType dataType = IndexUtil.getIndexColumnDataType(col);\n-                    ColumnName colName = ColumnName.caseSensitiveColumnName(IndexUtil.getIndexColumnName(col));\n-                    allPkColumns.add(new ColumnDefInPkConstraint(colName, col.getSortOrder(), false));\n-                    columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), col.isNullable(), col.getMaxLength(), col.getScale(), false, SortOrder.getDefault(), col.getName().getString(), col.isRowTimestamp()));\n-                }\n                 /*\n                  * Allocate an index ID in two circumstances:\n                  * 1) for a local index, as all local indexes will reside in the same HBase table\n                  * 2) for a view on an index.\n                  */\n                 if (isLocalIndex || (dataTable.getType() == PTableType.VIEW && dataTable.getViewType() != ViewType.MAPPED)) {\n                     allocateIndexId = true;\n-                    // Next add index ID column\n                     PDataType dataType = MetaDataUtil.getViewIndexIdDataType();\n                     ColumnName colName = ColumnName.caseSensitiveColumnName(MetaDataUtil.getViewIndexIdColumnName());\n                     allPkColumns.add(new ColumnDefInPkConstraint(colName, SortOrder.getDefault(), false));\n                     columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), false, null, null, false, SortOrder.getDefault(), null, false));\n                 }\n                 \n+                if (dataTable.isMultiTenant()) {\n+                    PColumn col = dataTable.getPKColumns().get(posOffset);\n+                    RowKeyColumnExpression columnExpression = new RowKeyColumnExpression(col, new RowKeyValueAccessor(pkColumns, posOffset), col.getName().getString());\n+                    unusedPkColumns.remove(columnExpression);\n+                    PDataType dataType = IndexUtil.getIndexColumnDataType(col);\n+                    ColumnName colName = ColumnName.caseSensitiveColumnName(IndexUtil.getIndexColumnName(col));\n+                    allPkColumns.add(new ColumnDefInPkConstraint(colName, col.getSortOrder(), false));\n+                    columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), col.isNullable(), col.getMaxLength(), col.getScale(), false, SortOrder.getDefault(), col.getName().getString(), col.isRowTimestamp()));\n+                }\n+                \n                 PhoenixStatement phoenixStatment = new PhoenixStatement(connection);\n                 StatementContext context = new StatementContext(phoenixStatment, resolver);\n                 IndexExpressionCompiler expressionIndexCompiler = new IndexExpressionCompiler(context);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java", "sha": "ae81d378a11678ddb1f999d4524713b90e6f0ceb", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -93,7 +93,7 @@\n     public static final String VIEW_INDEX_SEQUENCE_PREFIX = \"_SEQ_\";\n     public static final String VIEW_INDEX_SEQUENCE_NAME_PREFIX = \"_ID_\";\n     public static final byte[] VIEW_INDEX_SEQUENCE_PREFIX_BYTES = Bytes.toBytes(VIEW_INDEX_SEQUENCE_PREFIX);\n-    public static final String VIEW_INDEX_ID_COLUMN_NAME = \"_INDEX_ID\";\n+    private static final String VIEW_INDEX_ID_COLUMN_NAME = \"_INDEX_ID\";\n     public static final String PARENT_TABLE_KEY = \"PARENT_TABLE\";\n     public static final byte[] PARENT_TABLE_KEY_BYTES = Bytes.toBytes(\"PARENT_TABLE\");\n     ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java", "sha": "e68c8d4078b4b459b15be79dcabe5d9ef871c056", "changes": 3, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -1056,7 +1056,8 @@ private static Expression getFirstPKColumnExpression(PTable table) throws SQLExc\n             throw new SQLFeatureNotSupportedException();\n         }\n         \n-        int pkPosition = table.getBucketNum() == null ? 0 : 1;\n+        // skip salt and viewIndexId columns.\n+        int pkPosition = table.getBucketNum() == null ? 0 : 1 + (table.getViewIndexId() == null ? 0 : 1);\n         List<PColumn> pkColumns = table.getPKColumns();\n         return new RowKeyColumnExpression(pkColumns.get(pkPosition), new RowKeyValueAccessor(pkColumns, pkPosition));\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java"}, {"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java", "sha": "7a3014ba2cf800fa9a6b159080a7f442c1f8b640", "changes": 8, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -766,16 +766,16 @@ private static boolean hasNonZeroLeadingBytes(byte[] key, int nBytesToCheck) {\n         return Bytes.compareTo(key, 0, nBytesToCheck, ZERO_BYTE_ARRAY, 0, nBytesToCheck) != 0;\n     }\n \n-    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isMultiTenantTable)\n+    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isMultiTenantTable, boolean isSharedIndex)\n             throws SQLException {\n         return isMultiTenantTable ?\n-                  getTenantIdBytes(schema, isSalted, tenantId)\n+                  getTenantIdBytes(schema, isSalted, tenantId, isSharedIndex)\n                 : tenantId.getBytes();\n     }\n \n-    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId)\n+    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isSharedIndex)\n             throws SQLException {\n-        int pkPos = isSalted ? 1 : 0;\n+        int pkPos = (isSalted ? 1 : 0) + (isSharedIndex ? 1 : 0); \n         Field field = schema.getField(pkPos);\n         PDataType dataType = field.getDataType();\n         byte[] convertedValue;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java", "sha": "27c30fc02f11dd0fc6fd989aa581e7a9bb9b50a2", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -50,7 +50,7 @@ public void testOrderByOptimizedOut() throws Exception {\n         conn.createStatement().execute(\"CREATE INDEX i1 ON v(v2) INCLUDE(v1)\");\n         \n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v1,v2 FROM v WHERE v2 > 'a' ORDER BY v2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32768,'a'] - ['me',-32768,*]\",\n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32768,'me','a'] - [-32768,'me',*]\",\n                 QueryUtil.getExplainPlan(rs));\n     }\n \n@@ -194,7 +194,7 @@ public void testViewConstantsOptimizedOut() throws Exception {\n         conn.createStatement().execute(\"CREATE INDEX i1 ON v(v2)\");\n         \n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v2 FROM v WHERE v2 > 'a' and k2 = 'a' ORDER BY v2,k2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32766,'a'] - ['me',-32766,*]\\n\" + \n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32766,'me','a'] - [-32766,'me',*]\\n\" + \n                 \"    SERVER FILTER BY FIRST KEY ONLY\",\n                 QueryUtil.getExplainPlan(rs));\n         \n@@ -227,7 +227,7 @@ public void testViewConstantsOptimizedOutOnReadOnlyView() throws Exception {\n         \n         // Confirm that a read-only view on an updatable view still optimizes out the read-only parts of the updatable view\n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v2 FROM v2 WHERE v3 > 'a' and k2 = 'a' ORDER BY v3,k2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32767,'a'] - ['me',-32767,*]\",\n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32767,'me','a'] - [-32767,'me',*]\",\n                 QueryUtil.getExplainPlan(rs));\n     }\n     ", "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java", "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java", "sha": "fb70d228796d6af48a0137b469cffe86359f8cb6", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java?ref=5097982b00b36b74fb328afaab02159e81b21af0", "patch": "@@ -61,7 +61,7 @@ public TenantIdByteConversionTest(\n     @Test\n     public void test() {\n         try {\n-            byte[] actualTenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId);\n+            byte[] actualTenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId, false);\n             assertArrayEquals(expectedTenantIdBytes, actualTenantIdBytes);\n         } catch (SQLException ex) {\n             fail(ex.getMessage());", "filename": "phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/5363c989a0f5b9876d3153355664760f164776a4", "parent": "https://github.com/apache/phoenix/commit/f379fdf2fc5354baca1f5a61b6935339dded31ad", "message": "PHOENIX-1449 Fix potential NPE in delete", "bug_id": "phoenix_30", "file": [{"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/5363c989a0f5b9876d3153355664760f164776a4/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/5363c989a0f5b9876d3153355664760f164776a4/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java", "sha": "92abd77ae7668a4600b5a11d5e0bb0454418add6", "changes": 4, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java?ref=5363c989a0f5b9876d3153355664760f164776a4", "patch": "@@ -166,7 +166,9 @@ private static MutationState deleteRows(PhoenixStatement statement, TableRef tar\n                     }\n                     connection.commit();\n                     mutations.clear();\n-                    indexMutations.clear();\n+                    if (indexMutations != null) {\n+                        indexMutations.clear();\n+                    }\n                 }\n             }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/0c21539cc331b8d6ca144604cf899068ad74fb25", "parent": "https://github.com/apache/phoenix/commit/18f7a69452eec7fd5fde38953510600c4a060151", "message": "PHOENIX-2658 When using QueryRunner API UNION ALL queries fail with NPE (Alicia Ying Shu)", "bug_id": "phoenix_31", "file": [{"additions": 48, "raw_url": "https://github.com/apache/phoenix/raw/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java", "blob_url": "https://github.com/apache/phoenix/blob/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java", "sha": "b391dcc1e3885ceca4ed9e83f578244ff4a39329", "changes": 49, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java?ref=0c21539cc331b8d6ca144604cf899068ad74fb25", "patch": "@@ -40,7 +40,6 @@\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n-\n public class UnionAllIT extends BaseOwnClusterHBaseManagedTimeIT {\n \n     @BeforeClass\n@@ -679,4 +678,52 @@ public void testBug2295() throws Exception {\n             conn.close();\n         }\n     }\n+\n+    @Test\n+    public void testParameterMetaDataNotNull() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+    \n+        String ddl = \"CREATE TABLE test_table \" +\n+                \"  (a_string varchar not null, col1 integer\" +\n+                \"  CONSTRAINT pk PRIMARY KEY (a_string))\\n\";\n+        createTestTable(getUrl(), ddl);\n+        String dml = \"UPSERT INTO test_table VALUES(?, ?)\";\n+        PreparedStatement stmt = conn.prepareStatement(dml);\n+        stmt.setString(1, \"a\");\n+        stmt.setInt(2, 10);\n+        stmt.execute();\n+        conn.commit();\n+\n+        ddl = \"CREATE TABLE b_table \" +\n+                \"  (a_string varchar not null, col1 integer\" +\n+                \"  CONSTRAINT pk PRIMARY KEY (a_string))\\n\";\n+        createTestTable(getUrl(), ddl);\n+        dml = \"UPSERT INTO b_table VALUES(?, ?)\";\n+        stmt = conn.prepareStatement(dml);\n+        stmt.setString(1, \"b\");\n+        stmt.setInt(2, 20);\n+        stmt.execute();\n+        conn.commit();\n+\n+        String query = \"select * from test_table union all select * from b_table\";\n+\n+        try{\n+            PreparedStatement pstmt = conn.prepareStatement(query);\n+            assertTrue(pstmt.getParameterMetaData() != null);\n+            ResultSet rs = pstmt.executeQuery();\n+            assertTrue(rs.next());\n+            assertEquals(\"a\",rs.getString(1));\n+            assertEquals(10,rs.getInt(2));\n+            assertTrue(rs.next());\n+            assertEquals(\"b\",rs.getString(1));\n+            assertEquals(20,rs.getInt(2));\n+            assertFalse(rs.next()); \n+        } catch (Exception ex) {\n+            ex.printStackTrace();\n+        } finally {\n+            conn.close();\n+        }\n+    } \n+\n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java", "sha": "9e756c8d009bae851d14a8c5a538b11deac009d6", "changes": 3, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java?ref=0c21539cc331b8d6ca144604cf899068ad74fb25", "patch": "@@ -182,7 +182,8 @@ public QueryPlan compileUnionAll(SelectStatement select) throws SQLException {\n         StatementContext context = new StatementContext(statement, resolver, scan, sequenceManager);\n \n         QueryPlan plan = compileSingleFlatQuery(context, select, statement.getParameters(), false, false, null, null, false);\n-        plan =  new UnionPlan(context, select, tableRef, plan.getProjector(), plan.getLimit(), plan.getOrderBy(), GroupBy.EMPTY_GROUP_BY, plans, null); \n+        plan =  new UnionPlan(context, select, tableRef, plan.getProjector(), plan.getLimit(), plan.getOrderBy(), GroupBy.EMPTY_GROUP_BY, \n+                plans, context.getBindManager().getParameterMetaData()); \n         return plan;\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/5c25a728e165cae8672522cb11ab2acbdbd72851", "parent": "https://github.com/apache/phoenix/commit/ea22dd5e00e1cf67cad2ac975c78f4aaa258d5e9", "message": "PHOENIX-2620 NPE in org.apache.phoenix.expression.util.regex.JavaPattern.matches(Nicolas Liochon)", "bug_id": "phoenix_32", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/5c25a728e165cae8672522cb11ab2acbdbd72851/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "blob_url": "https://github.com/apache/phoenix/blob/5c25a728e165cae8672522cb11ab2acbdbd72851/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "sha": "ccdb5af9812c2be40ed4bb97154d0b7282515434", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java?ref=5c25a728e165cae8672522cb11ab2acbdbd72851", "patch": "@@ -47,7 +47,7 @@ public JavaPattern(String patternString, int flags) {\n     public void matches(ImmutableBytesWritable srcPtr) {\n         Preconditions.checkNotNull(srcPtr);\n         String matcherSourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n-        if (srcPtr.get().length == 0 && matcherSourceStr == null) matcherSourceStr = \"\";\n+        if (srcPtr.getLength() == 0 && matcherSourceStr == null) matcherSourceStr = \"\";\n         boolean ret = pattern.matcher(matcherSourceStr).matches();\n         srcPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/c2a1f7445f3882464a58d07cb9fd15a914e13d36", "parent": "https://github.com/apache/phoenix/commit/bf06617754ac408279a1359cc660239fbab05ad5", "message": "PHOENIX-1949 NPE while inserting NULL in a VARCHAR array using UPSERT stmt\n(Ram)", "bug_id": "phoenix_33", "file": [{"additions": 27, "raw_url": "https://github.com/apache/phoenix/raw/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/it/java/org/apache/phoenix/end2end/ArrayIT.java", "blob_url": "https://github.com/apache/phoenix/blob/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/it/java/org/apache/phoenix/end2end/ArrayIT.java", "sha": "846507b4a9a0d51032a5f679cd3c730708ef9636", "changes": 27, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/ArrayIT.java?ref=c2a1f7445f3882464a58d07cb9fd15a914e13d36", "patch": "@@ -869,6 +869,33 @@ public void testArrayWithFloatArray() throws Exception {\n         conn.close();\n     }\n \n+    @Test\n+    public void testArrayWithVarCharArray() throws Exception {\n+        Connection conn;\n+        PreparedStatement stmt;\n+        ResultSet rs;\n+        long ts = nextTimestamp();\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 10));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\"CREATE TABLE t ( k VARCHAR PRIMARY KEY, a VARCHAR ARRAY[])\");\n+        conn.close();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 30));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        stmt = conn.prepareStatement(\"UPSERT INTO t VALUES('a',ARRAY['a',null])\");\n+        int res = stmt.executeUpdate();\n+        assertEquals(1, res);\n+        conn.commit();\n+        conn.close();\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 40));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        rs = conn.createStatement().executeQuery(\"SELECT ARRAY_ELEM(a,2) FROM t\");\n+        assertTrue(rs.next());\n+        assertEquals(null, rs.getString(1));\n+        conn.close();\n+    }\n+\n     @Test\n     public void testArraySelectSingleArrayElemWithCast() throws Exception {\n         Connection conn;", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/ArrayIT.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PChar.java", "blob_url": "https://github.com/apache/phoenix/blob/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PChar.java", "sha": "4170253da00ae52dd6afafe28c1fdb6b772f9271", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PChar.java?ref=c2a1f7445f3882464a58d07cb9fd15a914e13d36", "patch": "@@ -104,12 +104,12 @@ public int toBytes(Object object, byte[] bytes, int offset) {\n \n     @Override\n     public Object toObject(byte[] bytes, int offset, int length, PDataType actualType, SortOrder sortOrder, Integer maxLength, Integer scale) {\n-      if (!actualType.isCoercibleTo(this)) { // TODO: have isCoercibleTo that takes bytes, offset?\n-        throwConstraintViolationException(actualType,this);\n-      }\n       if (length == 0) {\n         return null;\n       }\n+      if (!actualType.isCoercibleTo(this)) {\n+        throwConstraintViolationException(actualType, this);\n+      }\n       length = StringUtil.getUnpaddedCharLength(bytes, offset, length, sortOrder);\n       if (sortOrder == SortOrder.DESC) {\n         bytes = SortOrder.invert(bytes, offset, length);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/types/PChar.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PVarchar.java", "blob_url": "https://github.com/apache/phoenix/blob/c2a1f7445f3882464a58d07cb9fd15a914e13d36/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PVarchar.java", "sha": "25751159b05ec77fcd61269303e01d6e0d0bbb60", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PVarchar.java?ref=c2a1f7445f3882464a58d07cb9fd15a914e13d36", "patch": "@@ -59,12 +59,12 @@ public int toBytes(Object object, byte[] bytes, int offset) {\n   @Override\n   public Object toObject(byte[] bytes, int offset, int length, PDataType actualType,\n       SortOrder sortOrder, Integer maxLength, Integer scale) {\n-    if (!actualType.isCoercibleTo(this)) {\n-      throwConstraintViolationException(actualType, this);\n-    }\n     if (length == 0) {\n       return null;\n     }\n+    if (!actualType.isCoercibleTo(this)) {\n+      throwConstraintViolationException(actualType, this);\n+    }\n     if (sortOrder == SortOrder.DESC) {\n       bytes = SortOrder.invert(bytes, offset, length);\n       offset = 0;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/types/PVarchar.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/00ee9415a95668c34e95b43003354fc898f6b4ea", "parent": "https://github.com/apache/phoenix/commit/49be33e71b592e330f1304cfa20bbffc8bd18637", "message": "PHOENIX-2402 NPE when using UPSERT SELECT with a char array (Julian Jaffe)", "bug_id": "phoenix_34", "file": [{"additions": 55, "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java", "sha": "689562af42c48c1050fc2d05fd849e59b52d57a8", "changes": 55, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea", "patch": "@@ -1318,6 +1318,61 @@ public void testDisallowNegativeValuesForRowTsColumn() throws Exception {\n         }\n     }\n     \n+    @Test\n+    public void testUpsertSelectWithFixedWidthNullByteSizeArray() throws Exception {\n+        long ts = nextTimestamp();\n+        Properties props = new Properties();\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"create table t1 (id bigint not null primary key, ca char(3)[])\");\n+        conn.close();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 10));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\"upsert into t1 values (1, ARRAY['aaa', 'bbb'])\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 15));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"upsert into t1(id, ca) select id, ARRAY['ccc', 'ddd'] from t1 WHERE id = 1\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 20));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        ResultSet rs = conn.createStatement().executeQuery(\"select * from t1\");\n+\n+        assertTrue(rs.next());\n+        assertEquals(1, rs.getLong(1));\n+        assertEquals(\"['ccc', 'ddd']\", rs.getArray(2).toString());\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 25));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"create table t2 (id bigint not null primary key, ba binary(4)[])\");\n+        conn.close();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 30));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\"upsert into t2 values (2, ARRAY[1, 27])\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 35));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"upsert into t2(id, ba) select id, ARRAY[54, 1024] from t2 WHERE id = 2\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 40));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        rs = conn.createStatement().executeQuery(\"select * from t2\");\n+\n+        assertTrue(rs.next());\n+        assertEquals(2, rs.getLong(1));\n+        assertEquals(\"[[128,0,0,54], [128,0,4,0]]\", rs.getArray(2).toString());\n+    }\n+\n     private static Connection getConnection(long ts) throws SQLException {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java", "sha": "7cc2e6638782e89bf6c346a8abbc93dcef155ea3", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea", "patch": "@@ -78,12 +78,12 @@\n import org.apache.phoenix.schema.PDatum;\n import org.apache.phoenix.schema.PName;\n import org.apache.phoenix.schema.PTable;\n-import org.apache.phoenix.schema.TableNotFoundException;\n import org.apache.phoenix.schema.PTable.IndexType;\n import org.apache.phoenix.schema.PTable.ViewType;\n import org.apache.phoenix.schema.PTableKey;\n import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.schema.RowKeySchema;\n+import org.apache.phoenix.schema.TableNotFoundException;\n import org.apache.phoenix.schema.TableRef;\n import org.apache.phoenix.schema.ValueBitSet;\n import org.apache.phoenix.schema.tuple.Tuple;\n@@ -323,7 +323,7 @@ private static Expression coerceIfNecessary(int index, List<? extends PDatum> ta\n                 if (expression.getDataType() != null && !expression.getDataType().isCastableTo(targetType)) {\n                     throw new ArgumentTypeMismatchException(targetType, expression.getDataType(), \"column: \" + targetColumn);\n                 }\n-                expression = CoerceExpression.create(expression, targetType);\n+                expression = CoerceExpression.create(expression, targetType, targetColumn.getSortOrder(), targetColumn.getMaxLength());\n             }\n         }\n         return expression;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java"}, {"additions": 7, "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java", "sha": "c31cb0a4df1cabbe1fdf7ae7aa27efd2d446771b", "changes": 8, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea", "patch": "@@ -50,8 +50,14 @@ public static Expression create(Expression expression, PDataType toType) throws\n         return new CoerceExpression(expression, toType);\n     }\n     \n+    public static Expression create(Expression expression, PDataType toType, SortOrder toSortOrder, Integer maxLength) throws SQLException {\n+        return create(expression, toType, toSortOrder, maxLength, true);\n+    }\n+    \n     public static Expression create(Expression expression, PDataType toType, SortOrder toSortOrder, Integer maxLength, boolean rowKeyOrderOptimizable) throws SQLException {\n-        if (toType == expression.getDataType() && toSortOrder == expression.getSortOrder()) {\n+        if (    toType == expression.getDataType() && \n+                toSortOrder == expression.getSortOrder() && \n+                (maxLength == null || maxLength.equals(expression.getMaxLength()))   ) {\n             return expression;\n         }\n         return new CoerceExpression(expression, toType, toSortOrder, maxLength, rowKeyOrderOptimizable);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/c0b617f554938ea31832a921b8caa579e87749aa", "parent": "https://github.com/apache/phoenix/commit/481d1bb878d08fc43fd1eb8f85c36244afdafe45", "message": "PHOENIX-1381 NPE in CellUtil.matchingFamily() for IndexedKeyValue (Jeffrey Zhong)", "bug_id": "phoenix_35", "file": [{"additions": 44, "raw_url": "https://github.com/apache/phoenix/raw/c0b617f554938ea31832a921b8caa579e87749aa/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/wal/IndexedKeyValue.java", "blob_url": "https://github.com/apache/phoenix/blob/c0b617f554938ea31832a921b8caa579e87749aa/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/wal/IndexedKeyValue.java", "sha": "0270de5530bf98491709d33ecb47a59d6f63fa64", "changes": 46, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/hbase/index/wal/IndexedKeyValue.java?ref=c0b617f554938ea31832a921b8caa579e87749aa", "patch": "@@ -34,7 +34,7 @@\n import org.apache.phoenix.hbase.index.util.ImmutableBytesPtr;\n \n public class IndexedKeyValue extends KeyValue {\n-    public static final byte [] COLUMN_FAMILY = Bytes.toBytes(\"INDEXEDKEYVALUE_FAKED_FAMILY\");\n+    public static final byte [] COLUMN_QUALIFIER = Bytes.toBytes(\"INDEXEDKEYVALUE_FAKED_COLUMN\");\n   \n     private static int calcHashCode(ImmutableBytesPtr indexTableName, Mutation mutation) {\n         final int prime = 31;\n@@ -71,9 +71,51 @@ public Mutation getMutation() {\n      */\n     @Override\n     public byte [] getFamily() {\n-      return COLUMN_FAMILY;\n+      return WALEdit.METAFAMILY;\n     }\n     \n+    @Override\n+    public byte[] getFamilyArray() {\n+        return WALEdit.METAFAMILY;\n+    }\n+\n+    /**\n+     * @return Family offset\n+     */\n+    @Override\n+    public int getFamilyOffset() {\n+        return 0;\n+    }\n+\n+    /**\n+     * @return Family length\n+     */\n+    @Override\n+    public byte getFamilyLength() {\n+        return (byte) WALEdit.METAFAMILY.length;\n+    }\n+\n+    @Override\n+    public byte[] getQualifierArray() {\n+        return COLUMN_QUALIFIER;\n+    }\n+\n+    /**\n+     * @return Qualifier offset\n+     */\n+    @Override\n+    public int getQualifierOffset() {\n+        return 0;\n+    }\n+\n+    /**\n+     * @return Qualifier length\n+     */\n+    @Override\n+    public int getQualifierLength() {\n+        return COLUMN_QUALIFIER.length;\n+    }\n+\n     /**\n      * This is a KeyValue that shouldn't actually be replayed/replicated, so we always mark it as \n      * an {@link WALEdit#METAFAMILY} so it isn't replayed/replicated via the normal replay mechanism", "filename": "phoenix-core/src/main/java/org/apache/phoenix/hbase/index/wal/IndexedKeyValue.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/21c12b11b1bc1b18ac667666dd715ed91d48ed4f", "parent": "https://github.com/apache/phoenix/commit/27a152eb03279cd30e6a633d5adbe06363c696a6", "message": "PHOENIX-2425 Invalid sql syntax produces NPE instead of meaningful error message", "bug_id": "phoenix_36", "file": [{"additions": 6, "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java", "sha": "e4770096d1deee70fc14fdfcdd1ea2ad6f281aea", "changes": 6, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f", "patch": "@@ -364,6 +364,9 @@ public static RowProjector compile(StatementContext context, SelectStatement sta\n                 if (statement.isAggregate()) {\n                     ExpressionCompiler.throwNonAggExpressionInAggException(node.toString());\n                 }\n+                if (tableRef == TableRef.EMPTY_TABLE_REF) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT).build().buildException();\n+                }\n                 isWildcard = true;\n                 if (tableRef.getTable().getType() == PTableType.INDEX && ((WildcardParseNode)node).isRewrite()) {\n                 \tprojectAllIndexColumns(context, tableRef, resolveColumn, projectedExpressions, projectedColumns, targetColumns);\n@@ -382,6 +385,9 @@ public static RowProjector compile(StatementContext context, SelectStatement sta\n                     projectAllTableColumns(context, tRef, true, projectedExpressions, projectedColumns, targetColumns);\n                 }                \n             } else if (node instanceof  FamilyWildcardParseNode){\n+                if (tableRef == TableRef.EMPTY_TABLE_REF) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT).build().buildException();\n+                }\n                 // Project everything for SELECT cf.*\n                 String cfName = ((FamilyWildcardParseNode) node).getName();\n                 // Delay projecting to scan, as when any other column in the column family gets", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java", "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java", "sha": "bb76ccb4dfcc34d68e1ea5e8ee5c017a12890cae", "changes": 1, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f", "patch": "@@ -226,6 +226,7 @@ public SQLException newException(SQLExceptionInfo info) {\n     AGGREGATE_WITH_NOT_GROUP_BY_COLUMN(1018, \"42Y27\", \"Aggregate may not contain columns not in GROUP BY.\"),\n     ONLY_AGGREGATE_IN_HAVING_CLAUSE(1019, \"42Y26\", \"Only aggregate maybe used in the HAVING clause.\"),\n     UPSERT_COLUMN_NUMBERS_MISMATCH(1020, \"42Y60\", \"Number of columns upserting must match number of values.\"),\n+    NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT(1057, \"42Y10\", \"No table specified for wildcard select.\"),\n     // Table properties exception.\n     INVALID_BUCKET_NUM(1021, \"42Y80\", \"Salt bucket numbers should be with 1 and 256.\"),\n     NO_SPLITS_ON_SALTED_TABLE(1022, \"42Y81\", \"Should not specify split points on salted table with default row key order.\"),", "filename": "phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java"}, {"additions": 21, "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java", "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java", "sha": "23eb147107c50dea9e169bc2fe5c5118b2100a12", "changes": 24, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f", "patch": "@@ -1985,9 +1985,27 @@ public void testNoFromClauseSelect() throws Exception {\n      public void testFailNoFromClauseSelect() throws Exception {\n          Connection conn = DriverManager.getConnection(getUrl());\n          try {\n-             conn.createStatement().executeQuery(\"SELECT foo, bar\");\n-             fail(\"Should have got ColumnNotFoundException\");\n-         } catch (ColumnNotFoundException e) {            \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT foo, bar\");\n+                 fail(\"Should have got ColumnNotFoundException\");\n+             } catch (ColumnNotFoundException e) {            \n+             }\n+             \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT *\");\n+                 fail(\"Should have got SQLException\");\n+             } catch (SQLException e) {\n+                 assertEquals(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT.getErrorCode(), e.getErrorCode());\n+             }\n+             \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT A.*\");\n+                 fail(\"Should have got SQLException\");\n+             } catch (SQLException e) {\n+                 assertEquals(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT.getErrorCode(), e.getErrorCode());\n+             }\n+         } finally {\n+             conn.close();\n          }\n      }\n ", "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/dc3083fec11720a3b92f3edf98a679406004550f", "parent": "https://github.com/apache/phoenix/commit/82df3b97a9ca88605f78b59e547819ff3bf9cd7a", "message": "PHOENIX-2016 Some Phoenix tests failed with NPE(Alicia Ying Shu)", "bug_id": "phoenix_37", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/dc3083fec11720a3b92f3edf98a679406004550f/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java", "blob_url": "https://github.com/apache/phoenix/blob/dc3083fec11720a3b92f3edf98a679406004550f/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java", "sha": "fa78656ae3f0f3ef9d5fe63c55cb45dacdaa4755", "changes": 1, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java?ref=dc3083fec11720a3b92f3edf98a679406004550f", "patch": "@@ -1627,6 +1627,7 @@ protected static void initJoinTableValues(String url, byte[][] splits, Long ts)\n      * Disable and drop all the tables except SYSTEM.CATALOG and SYSTEM.SEQUENCE\n      */\n     private static void disableAndDropNonSystemTables() throws Exception {\n+        if (driver == null) return;\n         HBaseAdmin admin = driver.getConnectionQueryServices(null, null).getAdmin();\n         try {\n             HTableDescriptor[] tables = admin.listTables();", "filename": "phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/3f294aa962dc9e31ffe19200f78623590eb68a36", "parent": "https://github.com/apache/phoenix/commit/5a63c6360e53ec0bb52fc41b4f1856f1cc757257", "message": "PHOENIX-1870 Fix NPE occurring during regex processing when joni library not used (Shuxiong Ye)", "bug_id": "phoenix_38", "file": [{"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java", "sha": "ec4aa3a538aaaa82c8074299d8002c5d548098d4", "changes": 8, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -236,10 +236,10 @@ private void init() {\n             LiteralExpression likeTypeExpression = (LiteralExpression)children.get(LIKE_TYPE_INDEX);\n             this.likeType = LikeType.valueOf((String)likeTypeExpression.getValue());\n         }\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n         Expression e = getPatternExpression();\n-        if (e instanceof LiteralExpression) {\n-            LiteralExpression patternExpression = (LiteralExpression)e;\n-            String value = (String)patternExpression.getValue();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, ptr)) {\n+            String value = (String) PVarchar.INSTANCE.toObject(ptr, e.getDataType(), e.getSortOrder());\n             pattern = compilePattern(value);\n         }\n     }\n@@ -294,7 +294,7 @@ public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n             value = (String) strDataType.toObject(ptr, strSortOrder);\n         }\n         strDataType.coerceBytes(ptr, strDataType, strSortOrder, SortOrder.ASC);\n-        pattern.matches(ptr, ptr);\n+        pattern.matches(ptr);\n         if (logger.isTraceEnabled()) {\n             boolean matched = ((Boolean) PBoolean.INSTANCE.toObject(ptr)).booleanValue();\n             logger.trace(\"LIKE(value='\" + value + \"'pattern='\" + pattern.pattern() + \"' is \" + matched);", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java"}, {"additions": 51, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java", "sha": "b5a3d39005063ca38e899c301110d073bc17562d", "changes": 74, "status": "modified", "deletions": 23, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -22,8 +22,8 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBasePattern;\n import org.apache.phoenix.parse.FunctionParseNode.Argument;\n import org.apache.phoenix.parse.FunctionParseNode.BuiltInFunction;\n@@ -57,9 +57,11 @@\n public abstract class RegexpReplaceFunction extends ScalarFunction {\n     public static final String NAME = \"REGEXP_REPLACE\";\n \n-    private boolean hasReplaceStr;\n+    private static final PVarchar TYPE = PVarchar.INSTANCE;\n+    private byte [] rStrBytes;\n+    private int rStrOffset, rStrLen;\n     private AbstractBasePattern pattern;\n-    \n+\n     public RegexpReplaceFunction() { }\n \n     // Expect 1 arguments, the pattern. \n@@ -71,44 +73,70 @@ public RegexpReplaceFunction(List<Expression> children) {\n     protected abstract AbstractBasePattern compilePatternSpec(String value);\n \n     private void init() {\n-        hasReplaceStr = ((LiteralExpression)getReplaceStrExpression()).getValue() != null;\n-        Object patternString = ((LiteralExpression)children.get(1)).getValue();\n-        if (patternString != null) {\n-            pattern = compilePatternSpec((String) patternString);\n+        ImmutableBytesWritable tmpPtr = new ImmutableBytesWritable();\n+        Expression e = getPatternStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, tmpPtr)) {\n+            String patternStr = (String) TYPE.toObject(tmpPtr, e.getDataType(), e.getSortOrder());\n+            if (patternStr != null) pattern = compilePatternSpec(patternStr);\n+        }\n+        e = getReplaceStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, tmpPtr)) {\n+            TYPE.coerceBytes(tmpPtr, TYPE, e.getSortOrder(), SortOrder.ASC);\n+            rStrBytes = tmpPtr.get();\n+            rStrOffset = tmpPtr.getOffset();\n+            rStrLen = tmpPtr.getLength();\n+        } else {\n+            rStrBytes = null;\n         }\n     }\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n-        // Can't parse if there is no replacement pattern.\n+        AbstractBasePattern pattern = this.pattern;\n         if (pattern == null) {\n-            return false;\n-        }\n-        Expression sourceStrExpression = getSourceStrExpression();\n-        if (!sourceStrExpression.evaluate(tuple, ptr)) {\n-            return false;\n+            Expression e = getPatternStrExpression();\n+            if (!e.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            String patternStr = (String) TYPE.toObject(ptr, e.getDataType(), e.getSortOrder());\n+            if (patternStr == null) {\n+                return false;\n+            } else {\n+                pattern = compilePatternSpec(patternStr);\n+            }\n         }\n-        if (ptr == null) return false;\n-        PVarchar type = PVarchar.INSTANCE;\n-        type.coerceBytes(ptr, type, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n-        ImmutableBytesWritable replacePtr = new ImmutableBytesWritable();\n-        if (hasReplaceStr) {\n+\n+        byte[] rStrBytes = this.rStrBytes;\n+        int rStrOffset = this.rStrOffset, rStrLen = this.rStrLen;\n+        if (rStrBytes == null) {\n             Expression replaceStrExpression = getReplaceStrExpression();\n-            if (!replaceStrExpression.evaluate(tuple, replacePtr)) {\n+            if (!replaceStrExpression.evaluate(tuple, ptr)) {\n                 return false;\n             }\n-            type.coerceBytes(replacePtr, type, replaceStrExpression.getSortOrder(), SortOrder.ASC);\n-        } else {\n-            replacePtr.set(type.toBytes(\"\"));\n+            TYPE.coerceBytes(ptr, TYPE, replaceStrExpression.getSortOrder(), SortOrder.ASC);\n+            rStrBytes = ptr.get();\n+            rStrOffset = ptr.getOffset();\n+            rStrLen = ptr.getLength();\n         }\n-        pattern.replaceAll(ptr, replacePtr, ptr);\n+\n+        Expression sourceStrExpression = getSourceStrExpression();\n+        if (!sourceStrExpression.evaluate(tuple, ptr)) {\n+            return false;\n+        }\n+        TYPE.coerceBytes(ptr, TYPE, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n+\n+        pattern.replaceAll(ptr, rStrBytes, rStrOffset, rStrLen);\n         return true;\n     }\n \n     private Expression getSourceStrExpression() {\n         return children.get(0);\n     }\n \n+    private Expression getPatternStrExpression() {\n+        return children.get(1);\n+    }\n+\n     private Expression getReplaceStrExpression() {\n         return children.get(2);\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java"}, {"additions": 34, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java", "sha": "c663188f62f26e51ddb353fa448ff161121b03a6", "changes": 59, "status": "modified", "deletions": 25, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -22,8 +22,8 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBaseSplitter;\n import org.apache.phoenix.parse.FunctionParseNode;\n import org.apache.phoenix.parse.RegexpSplitParseNode;\n@@ -53,6 +53,8 @@\n \n     public static final String NAME = \"REGEXP_SPLIT\";\n \n+    private static final PVarchar TYPE = PVarchar.INSTANCE;\n+\n     private AbstractBaseSplitter initializedSplitter = null;\n \n     public RegexpSplitFunction() {}\n@@ -63,11 +65,12 @@ public RegexpSplitFunction(List<Expression> children) {\n     }\n \n     private void init() {\n-        Expression patternExpression = children.get(1);\n-        if (patternExpression instanceof LiteralExpression) {\n-            Object patternValue = ((LiteralExpression) patternExpression).getValue();\n-            if (patternValue != null) {\n-                initializedSplitter = compilePatternSpec(patternValue.toString());\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n+        Expression e = getPatternStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, ptr)) {\n+            String pattern = (String) TYPE.toObject(ptr, TYPE, e.getSortOrder());\n+            if (pattern != null) {\n+                initializedSplitter = compilePatternSpec(pattern);\n             }\n         }\n     }\n@@ -87,31 +90,37 @@ public String getName() {\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n-        if (!children.get(0).evaluate(tuple, ptr)) {\n-            return false;\n-        }\n-\n-        Expression sourceStrExpression = children.get(0);\n-        PVarchar type = PVarchar.INSTANCE;\n-        type.coerceBytes(ptr, type, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n-\n         AbstractBaseSplitter splitter = initializedSplitter;\n         if (splitter == null) {\n-            ImmutableBytesWritable tmpPtr = new ImmutableBytesWritable();\n-            Expression patternExpression = children.get(1);\n-            if (!patternExpression.evaluate(tuple, tmpPtr)) {\n+            Expression e = getPatternStrExpression();\n+            if (e.evaluate(tuple, ptr)) {\n+                String pattern = (String) TYPE.toObject(ptr, TYPE, e.getSortOrder());\n+                if (pattern != null) {\n+                    splitter = compilePatternSpec(pattern);\n+                } else {\n+                    ptr.set(ByteUtil.EMPTY_BYTE_ARRAY); // set ptr to null\n+                    return true;\n+                }\n+            } else {\n                 return false;\n             }\n-            if (tmpPtr.getLength() == 0) {\n-                ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n-                return true; // set ptr to null\n-            }\n-            String patternStr =\n-                    (String) PVarchar.INSTANCE.toObject(tmpPtr, patternExpression.getSortOrder());\n-            splitter = compilePatternSpec(patternStr);\n         }\n \n-        return splitter.split(ptr, ptr);\n+        Expression e = getSourceStrExpression();\n+        if (!e.evaluate(tuple, ptr)) {\n+            return false;\n+        }\n+        TYPE.coerceBytes(ptr, TYPE, e.getSortOrder(), SortOrder.ASC);\n+\n+        return splitter.split(ptr);\n+    }\n+\n+    private Expression getSourceStrExpression() {\n+        return children.get(0);\n+    }\n+\n+    private Expression getPatternStrExpression() {\n+        return children.get(1);\n     }\n \n     @Override", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java", "sha": "922c7c94bcbe173e61c93e5a0cec3bb707830d6b", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -21,10 +21,10 @@\n \n public abstract class AbstractBasePattern {\n \n-    public abstract void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr);\n+    public abstract void matches(ImmutableBytesWritable srcPtr);\n \n-    public abstract void replaceAll(ImmutableBytesWritable srcPtr,\n-            ImmutableBytesWritable replacePtr, ImmutableBytesWritable outPtr);\n+    public abstract void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes,\n+            int rStrOffset, int rStrLen);\n \n     public abstract void substr(ImmutableBytesWritable srcPtr, int offsetInStr);\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java", "sha": "756533895e2aaa81bf9c44a2cfa79e8361ea0def", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -20,5 +20,5 @@\n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n \n public abstract interface AbstractBaseSplitter {\n-    public abstract boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr);\n+    public abstract boolean split(ImmutableBytesWritable srcPtr);\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java", "sha": "1f53526801585f33b024b802ea1ce2df2c367ba1", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -40,14 +40,14 @@ public GuavaSplitter(String patternString) {\n     }\n \n     @Override\n-    public boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public boolean split(ImmutableBytesWritable srcPtr) {\n         String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n         if (sourceStr == null) { // sourceStr evaluated to null\n-            outPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            srcPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n         } else {\n             List<String> splitStrings = Lists.newArrayList(splitter.split(sourceStr));\n             PhoenixArray splitArray = new PhoenixArray(PVarchar.INSTANCE, splitStrings.toArray());\n-            outPtr.set(PVarcharArray.INSTANCE.toBytes(splitArray));\n+            srcPtr.set(PVarcharArray.INSTANCE.toBytes(splitArray));\n         }\n         return true;\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java"}, {"additions": 10, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java", "sha": "69f9eaf0cd7554da2d4ce89739dd77c206693cb3", "changes": 22, "status": "modified", "deletions": 12, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -60,11 +60,10 @@ public JONIPattern(String patternString, int flags, Encoding coding) {\n     }\n \n     @Override\n-    public void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public void matches(ImmutableBytesWritable srcPtr) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n         boolean ret = matches(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength());\n-        outPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n+        srcPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n     }\n \n     private boolean matches(byte[] bytes, int offset, int len) {\n@@ -80,15 +79,14 @@ public String pattern() {\n     }\n \n     @Override\n-    public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable replacePtr,\n-            ImmutableBytesWritable replacedPtr) {\n+    public void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes, int rStrOffset,\n+            int rStrLen) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(replacePtr);\n-        Preconditions.checkNotNull(replacedPtr);\n+        Preconditions.checkNotNull(rStrBytes);\n         byte[] replacedBytes =\n-                replaceAll(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), replacePtr.get(),\n-                    replacePtr.getOffset(), replacePtr.getLength());\n-        replacedPtr.set(replacedBytes);\n+                replaceAll(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), rStrBytes,\n+                    rStrOffset, rStrLen);\n+        srcPtr.set(replacedBytes);\n     }\n \n     private byte[] replaceAll(byte[] srcBytes, int srcOffset, int srcLen, byte[] replaceBytes,\n@@ -154,8 +152,8 @@ private boolean substr(byte[] srcBytes, int offset, int range, ImmutableBytesWri\n     }\n \n     @Override\n-    public boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n-        return split(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), outPtr);\n+    public boolean split(ImmutableBytesWritable srcPtr) {\n+        return split(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), srcPtr);\n     }\n \n     private boolean", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java"}, {"additions": 9, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "sha": "707bced65e5ef919e00d0ee32d0fb0685693de23", "changes": 20, "status": "modified", "deletions": 11, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -44,13 +44,12 @@ public JavaPattern(String patternString, int flags) {\n     }\n \n     @Override\n-    public void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public void matches(ImmutableBytesWritable srcPtr) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n         String matcherSourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n         if (srcPtr.get().length == 0 && matcherSourceStr == null) matcherSourceStr = \"\";\n         boolean ret = pattern.matcher(matcherSourceStr).matches();\n-        outPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n+        srcPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n     }\n \n     @Override\n@@ -59,17 +58,16 @@ public String pattern() {\n     }\n \n     @Override\n-    public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable replacePtr,\n-            ImmutableBytesWritable replacedPtr) {\n+    public void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes, int rStrOffset,\n+            int rStrLen) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(replacePtr);\n-        Preconditions.checkNotNull(replacedPtr);\n+        Preconditions.checkNotNull(rStrBytes);\n         String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n-        String replaceStr = (String) PVarchar.INSTANCE.toObject(replacePtr);\n-        if (srcPtr.get().length == 0 && sourceStr == null) sourceStr = \"\";\n-        if (replacePtr.get().length == 0 && replaceStr == null) replaceStr = \"\";\n+        String replaceStr = (String) PVarchar.INSTANCE.toObject(rStrBytes, rStrOffset, rStrLen);\n+        if (srcPtr.getLength() == 0 && sourceStr == null) sourceStr = \"\";\n+        if (rStrLen == 0 && replaceStr == null) replaceStr = \"\";\n         String replacedStr = pattern.matcher(sourceStr).replaceAll(replaceStr);\n-        replacedPtr.set(PVarchar.INSTANCE.toBytes(replacedStr));\n+        srcPtr.set(PVarchar.INSTANCE.toBytes(replacedStr));\n     }\n \n     @Override", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java"}, {"additions": 10, "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java", "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java", "sha": "6722a71fb78aace3a3869f0e63dd021b2f3fac75", "changes": 13, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36", "patch": "@@ -63,7 +63,10 @@ private void testReplaceAll(ImmutableBytesWritable replacePtr, AbstractBasePatte\n             String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            pattern.replaceAll(dataPtr[i % 3], replacePtr, resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            pattern.replaceAll(resultPtr, replacePtr.get(), replacePtr.getOffset(),\n+                replacePtr.getLength());\n             if (ENABLE_ASSERT) {\n                 String result = (String) PVarchar.INSTANCE.toObject(resultPtr);\n                 assertTrue((i % 3 == 1 && \":\".equals(result))\n@@ -83,7 +86,9 @@ public void testReplaceAll() {\n     private void testLike(AbstractBasePattern pattern, String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            pattern.matches(dataPtr[i % 3], resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            pattern.matches(resultPtr);\n             if (ENABLE_ASSERT) {\n                 Boolean b = (Boolean) PBoolean.INSTANCE.toObject(resultPtr);\n                 assertTrue(i % 3 != 2 || b.booleanValue());\n@@ -120,7 +125,9 @@ public void testSubstr() {\n     private void testSplit(AbstractBaseSplitter pattern, String name) throws SQLException {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            boolean ret = pattern.split(dataPtr[i % 3], resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            boolean ret = pattern.split(resultPtr);\n             if (ENABLE_ASSERT) {\n                 PhoenixArray array = (PhoenixArray) PVarcharArray.INSTANCE.toObject(resultPtr);\n                 assertTrue(ret && (i % 3 != 1 || ((String[]) array.getArray()).length == 2));", "filename": "phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "parent": "https://github.com/apache/phoenix/commit/035e315794427e0914be6d0a84fb6bac5331d6a8", "message": "PHOENIX-1870 Fix NPE occurring during regex processing when joni library not used", "bug_id": "phoenix_39", "file": [{"additions": 61, "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java", "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java", "sha": "ea80b11fce372f8e9761aac96bfab5fc789ed295", "changes": 97, "status": "modified", "deletions": 36, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "patch": "@@ -22,15 +22,16 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBasePattern;\n import org.apache.phoenix.parse.FunctionParseNode.Argument;\n import org.apache.phoenix.parse.FunctionParseNode.BuiltInFunction;\n import org.apache.phoenix.parse.RegexpSubstrParseNode;\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.tuple.Tuple;\n import org.apache.phoenix.schema.types.PDataType;\n+import org.apache.phoenix.schema.types.PInteger;\n import org.apache.phoenix.schema.types.PLong;\n import org.apache.phoenix.schema.types.PVarchar;\n \n@@ -56,11 +57,11 @@\n     public static final String NAME = \"REGEXP_SUBSTR\";\n \n     private AbstractBasePattern pattern;\n-    private boolean isOffsetConstant;\n+    private Integer offset;\n     private Integer maxLength;\n \n     private static final PDataType TYPE = PVarchar.INSTANCE;\n-\n+    \n     public RegexpSubstrFunction() { }\n \n     public RegexpSubstrFunction(List<Expression> children) {\n@@ -71,51 +72,76 @@ public RegexpSubstrFunction(List<Expression> children) {\n     protected abstract AbstractBasePattern compilePatternSpec(String value);\n \n     private void init() {\n-        Object patternString = ((LiteralExpression)children.get(1)).getValue();\n-        if (patternString != null) {\n-            pattern = compilePatternSpec((String) patternString);\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n+        Expression patternExpr = getPatternExpression();\n+        if (patternExpr.isStateless() && patternExpr.getDeterminism() == Determinism.ALWAYS && patternExpr.evaluate(null, ptr)) {\n+            String patternStr = (String) patternExpr.getDataType().toObject(ptr, patternExpr.getSortOrder());\n+            if (patternStr != null) {\n+                pattern = compilePatternSpec(patternStr);\n+            }\n         }\n         // If the source string has a fixed width, then the max length would be the length \n         // of the source string minus the offset, or the absolute value of the offset if \n         // it's negative. Offset number is a required argument. However, if the source string\n         // is not fixed width, the maxLength would be null.\n-        isOffsetConstant = getOffsetExpression() instanceof LiteralExpression;\n-        Number offsetNumber = (Number)((LiteralExpression)getOffsetExpression()).getValue();\n-        if (offsetNumber != null) {\n-            int offset = offsetNumber.intValue();\n-            PDataType type = getSourceStrExpression().getDataType();\n-            if (type.isFixedWidth()) {\n-                if (offset >= 0) {\n-                    Integer maxLength = getSourceStrExpression().getMaxLength();\n-                    this.maxLength = maxLength - offset - (offset == 0 ? 0 : 1);\n-                } else {\n-                    this.maxLength = -offset;\n+        Expression offsetExpr = getOffsetExpression();\n+        if (offsetExpr.isStateless() && offsetExpr.getDeterminism() == Determinism.ALWAYS && offsetExpr.evaluate(null, ptr)) {\n+            offset = (Integer)PInteger.INSTANCE.toObject(ptr, offsetExpr.getDataType(), offsetExpr.getSortOrder());\n+            if (offset != null) {\n+                PDataType type = getSourceStrExpression().getDataType();\n+                if (type.isFixedWidth()) {\n+                    if (offset >= 0) {\n+                        Integer maxLength = getSourceStrExpression().getMaxLength();\n+                        this.maxLength = maxLength - offset - (offset == 0 ? 0 : 1);\n+                    } else {\n+                        this.maxLength = -offset;\n+                    }\n                 }\n             }\n         }\n     }\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n+        AbstractBasePattern pattern = this.pattern;\n         if (pattern == null) {\n-            return false;\n+            Expression patternExpr = getPatternExpression();\n+            if (!patternExpr.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            if (ptr.getLength() == 0) {\n+                return true;\n+            }\n+            pattern = compilePatternSpec((String) patternExpr.getDataType().toObject(ptr, patternExpr.getSortOrder()));\n         }\n-        ImmutableBytesWritable srcPtr = new ImmutableBytesWritable();\n-        if (!getSourceStrExpression().evaluate(tuple, srcPtr)) {\n-            return false;\n+        int offset;\n+        if (this.offset == null) {\n+            Expression offsetExpression = getOffsetExpression();\n+            if (!offsetExpression.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            if (ptr.getLength() == 0) {\n+                return true;\n+            }\n+            offset = offsetExpression.getDataType().getCodec().decodeInt(ptr, offsetExpression.getSortOrder());\n+        } else {\n+            offset = this.offset;\n         }\n-        TYPE.coerceBytes(srcPtr, TYPE, getSourceStrExpression().getSortOrder(), SortOrder.ASC);\n-\n-        Expression offsetExpression = getOffsetExpression();\n-        if (!offsetExpression.evaluate(tuple, ptr)) {\n+        Expression strExpression = getSourceStrExpression();\n+        if (!strExpression.evaluate(tuple, ptr)) {\n             return false;\n         }\n-        int offset = offsetExpression.getDataType().getCodec().decodeInt(ptr, offsetExpression.getSortOrder());\n+        if (ptr.get().length == 0) {\n+            return true;\n+        }\n+\n+        TYPE.coerceBytes(ptr, strExpression.getDataType(), strExpression.getSortOrder(), SortOrder.ASC);\n \n         // Account for 1 versus 0-based offset\n         offset = offset - (offset <= 0 ? 0 : 1);\n \n-        return pattern.substr(srcPtr, offset, ptr);\n+        pattern.substr(ptr, offset);\n+        return true;\n     }\n \n     @Override\n@@ -125,14 +151,9 @@ public Integer getMaxLength() {\n \n     @Override\n     public OrderPreserving preservesOrder() {\n-        if (isOffsetConstant) {\n-            LiteralExpression literal = (LiteralExpression) getOffsetExpression();\n-            Number offsetNumber = (Number) literal.getValue();\n-            if (offsetNumber != null) { \n-                int offset = offsetNumber.intValue();\n-                if (offset == 0 || offset == 1) {\n-                    return OrderPreserving.YES_IF_LAST;\n-                }\n+        if (offset != null) {\n+            if (offset == 0 || offset == 1) {\n+                return OrderPreserving.YES_IF_LAST;\n             }\n         }\n         return OrderPreserving.NO;\n@@ -153,6 +174,10 @@ private Expression getOffsetExpression() {\n         return children.get(2);\n     }\n \n+    private Expression getPatternExpression() {\n+        return children.get(1);\n+    }\n+\n     private Expression getSourceStrExpression() {\n         return children.get(0);\n     }\n@@ -161,7 +186,7 @@ private Expression getSourceStrExpression() {\n     public PDataType getDataType() {\n         // ALways VARCHAR since we do not know in advanced how long the \n         // matched string will be.\n-        return PVarchar.INSTANCE;\n+        return TYPE;\n     }\n \n     @Override", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java", "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java", "sha": "5287fd760f7c1e6a81d381e5613bb9ed0c836997", "changes": 3, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "patch": "@@ -26,8 +26,7 @@\n     public abstract void replaceAll(ImmutableBytesWritable srcPtr,\n             ImmutableBytesWritable replacePtr, ImmutableBytesWritable outPtr);\n \n-    public abstract boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr);\n+    public abstract void substr(ImmutableBytesWritable srcPtr, int offsetInStr);\n \n     public abstract String pattern();\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java"}, {"additions": 9, "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java", "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java", "sha": "b17e8a7446c87efba060457257fe5be4cd2b4169", "changes": 18, "status": "modified", "deletions": 9, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "patch": "@@ -130,15 +130,15 @@ public PairInt(int begin, int end) {\n     }\n \n     @Override\n-    public boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr) {\n-        Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n-        int offsetInBytes = StringUtil.calculateUTF8Offset(srcPtr.get(), srcPtr.getOffset(),\n-            srcPtr.getLength(), SortOrder.ASC, offsetInStr);\n-        if (offsetInBytes < 0) return false;\n-        substr(srcPtr.get(), offsetInBytes, srcPtr.getOffset() + srcPtr.getLength(), outPtr);\n-        return true;\n+    public void substr(ImmutableBytesWritable ptr, int offsetInStr) {\n+        Preconditions.checkNotNull(ptr);\n+        int offsetInBytes = StringUtil.calculateUTF8Offset(ptr.get(), ptr.getOffset(),\n+                ptr.getLength(), SortOrder.ASC, offsetInStr);\n+        if (offsetInBytes < 0) {\n+            ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+        } else {\n+            substr(ptr.get(), offsetInBytes, ptr.getOffset() + ptr.getLength(), ptr);\n+        }\n     }\n \n     private boolean substr(byte[] srcBytes, int offset, int range, ImmutableBytesWritable outPtr) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java"}, {"additions": 17, "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java", "sha": "f4bd239f6996be1352f3835bfae48e4f0ba9e28b", "changes": 31, "status": "modified", "deletions": 14, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "patch": "@@ -73,21 +73,24 @@ public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable rep\n     }\n \n     @Override\n-    public boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr) {\n-        Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n-        String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n-        if (srcPtr.get().length == 0 && sourceStr == null) sourceStr = \"\";\n-        if (offsetInStr < 0) offsetInStr += sourceStr.length();\n-        if (offsetInStr < 0 || offsetInStr >= sourceStr.length()) return false;\n-        Matcher matcher = pattern.matcher(sourceStr);\n-        boolean ret = matcher.find(offsetInStr);\n-        if (ret) {\n-            outPtr.set(PVarchar.INSTANCE.toBytes(matcher.group()));\n+    public void substr(ImmutableBytesWritable ptr, int offsetInStr) {\n+        Preconditions.checkNotNull(ptr);\n+        String sourceStr = (String) PVarchar.INSTANCE.toObject(ptr);\n+        if (sourceStr == null) {\n+            ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n         } else {\n-            outPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            if (offsetInStr < 0) offsetInStr += sourceStr.length();\n+            if (offsetInStr < 0 || offsetInStr >= sourceStr.length()) {\n+                ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            } else {\n+                Matcher matcher = pattern.matcher(sourceStr);\n+                boolean ret = matcher.find(offsetInStr);\n+                if (ret) {\n+                    ptr.set(PVarchar.INSTANCE.toBytes(matcher.group()));\n+                } else {\n+                    ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+                }\n+            }\n         }\n-        return true;\n     }\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java"}, {"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java", "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java", "sha": "4275687f0a09c336d4fa85bd0182ac90c1f7c99e", "changes": 7, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac", "patch": "@@ -101,10 +101,11 @@ public void testLike() {\n     private void testSubstr(AbstractBasePattern pattern, String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            boolean ret = pattern.substr(dataPtr[i % 3], 0, resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(),ptr.getOffset(),ptr.getLength());\n+            pattern.substr(resultPtr, 0);\n             if (ENABLE_ASSERT) {\n-                assertTrue(ret\n-                        && (i % 3 != 2 || \":THU\".equals(PVarchar.INSTANCE.toObject(resultPtr))));\n+                assertTrue((i % 3 != 2 || \":THU\".equals(PVarchar.INSTANCE.toObject(resultPtr))));\n             }\n         }\n         timer.printTime(name);", "filename": "phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee", "parent": "https://github.com/apache/phoenix/commit/0398178617cb2aeac3661510395635b9d00f814d", "message": "PHOENIX-1474 NPE when RVC between combined with key part comparison", "bug_id": "phoenix_40", "file": [{"additions": 15, "raw_url": "https://github.com/apache/phoenix/raw/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java", "blob_url": "https://github.com/apache/phoenix/blob/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java", "sha": "8d67fa41aaab932491017ca9e9de23d2fbee7489", "changes": 15, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java?ref=54b3ef98dd7a375c31e65873f8fb7eafc39f82ee", "patch": "@@ -1311,6 +1311,21 @@ public void testComparisonAgainstRVCCombinedWithOrAnd_1() throws Exception {\n         assertEquals(\"helo3\", rs.getString(1));\n         assertEquals(3, rs.getInt(2));\n         assertFalse(rs.next());\n+        \n+        stmt = conn.prepareStatement(\"select pk2, pk3 from RVC1 WHERE tenantId = ? AND (tenantId, pk2, pk3) BETWEEN (?, ?, ?) AND (?, ?, ?) LIMIT 100\");\n+        stmt.setString(1, \"ABC\");\n+        stmt.setString(2, \"ABC\");\n+        stmt.setString(3, \"helo2\");\n+        stmt.setInt(4, 2);\n+        stmt.setString(5, \"DEF\");\n+        stmt.setString(6, \"helo3\");\n+        stmt.setInt(7, 3);\n+        \n+        rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo2\", rs.getString(1));\n+        assertEquals(2, rs.getInt(2));\n+        assertFalse(rs.next());\n     }\n     \n     // query against tenant specific view. Salted base table.", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "blob_url": "https://github.com/apache/phoenix/blob/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "sha": "f70ba21eda1e6aa756baf1bbcdf3dd2cecdfede8", "changes": 4, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=54b3ef98dd7a375c31e65873f8fb7eafc39f82ee", "patch": "@@ -643,7 +643,9 @@ private KeySlots andKeySlots(AndExpression andExpression, List<KeySlots> childSl\n                     // with our minMaxRange, since it spans columns and this would mess up our skip scan.\n                     minMaxRange = minMaxRange.intersect(childSlot.getMinMaxRange());\n                     for (KeySlot slot : childSlot) {\n-                        minMaxExtractNodes.addAll(slot.getKeyPart().getExtractNodes());\n+                        if (slot != null) {\n+                    \t    minMaxExtractNodes.addAll(slot.getKeyPart().getExtractNodes());\n+                        }\n                     }\n                 } else {\n                     for (KeySlot slot : childSlot) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/31bd42301cad35f0e1f0b0e363dcf13726d84fd1", "parent": "https://github.com/apache/phoenix/commit/880fd9f9447da2bf435af2031c9468797558bb79", "message": "PHOENIX-1397 RVC combined with OR on first row key column results in NPE (Samarth Jain)", "bug_id": "phoenix_41", "file": [{"additions": 69, "raw_url": "https://github.com/apache/phoenix/raw/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java", "blob_url": "https://github.com/apache/phoenix/blob/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java", "sha": "9e3a5b07c9393efd0af2ce1ceb35f298e462fc27", "changes": 69, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java?ref=31bd42301cad35f0e1f0b0e363dcf13726d84fd1", "patch": "@@ -1280,5 +1280,74 @@ public void testForceSkipScan() throws Exception {\n             conn.close();\n         }\n     }\n+    \n+    // query against non-multitenant table. Salted - yes \n+    @Test\n+    public void testComparisonAgainstRVCCombinedWithOrAnd_1() throws Exception {\n+    \tString tableDDL = \"CREATE TABLE RVC1 (tenantId char(15) NOT NULL, pk2 char(15) NOT NULL, pk3 INTEGER NOT NULL, c1 INTEGER constraint pk primary key (tenantId,pk2,pk3)) SALT_BUCKETS = 4\";\n+        createTestTable(getUrl(), tableDDL, null, nextTimestamp());\n+\n+        Connection conn = nextConnection(getUrl());\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('ABC', 'helo1', 1, 1)\");\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('ABC', 'helo2', 2, 2)\");\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('DEF', 'helo3', 3, 3)\");\n+        conn.commit();\n+        conn.close();\n+\n+        conn = nextConnection(getUrl());\n+        PreparedStatement stmt = conn.prepareStatement(\"select pk2, pk3 from RVC1 WHERE (tenantId = ? OR tenantId = ?) AND (tenantId, pk2, pk3) > (?, ?, ?) LIMIT 100\");\n+        stmt.setString(1, \"ABC\");\n+        stmt.setString(2, \"DEF\");\n+        \n+        // give back all rows after row 1 - ABC|helo1|1\n+        stmt.setString(3, \"ABC\");\n+        stmt.setString(4, \"helo1\");\n+        stmt.setInt(5, 1);\n+        \n+        ResultSet rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo2\", rs.getString(1));\n+        assertEquals(2, rs.getInt(2));\n+        assertTrue(rs.next());\n+        assertEquals(\"helo3\", rs.getString(1));\n+        assertEquals(3, rs.getInt(2));\n+        assertFalse(rs.next());\n+    }\n+    \n+    // query against tenant specific view. Salted base table.\n+    @Test\n+    public void testComparisonAgainstRVCCombinedWithOrAnd_2() throws Exception {\n+        String tenantId = \"ABC\";\n+        String tenantSpecificUrl = getUrl() + \";\" + PhoenixRuntime.TENANT_ID_ATTRIB + '=' + tenantId;\n+        String baseTableDDL = \"CREATE TABLE RVC2 (tenant_id char(15) NOT NULL, pk2 char(15) NOT NULL, pk3 INTEGER NOT NULL, c1 INTEGER constraint pk primary key (tenant_id,pk2,pk3)) MULTI_TENANT=true, SALT_BUCKETS = 4\";\n+        createTestTable(getUrl(), baseTableDDL, null, nextTimestamp());\n+        String tenantTableDDL = \"CREATE VIEW t_view AS SELECT * FROM RVC2\";\n+        createTestTable(tenantSpecificUrl, tenantTableDDL, null, nextTimestamp());\n+\n+        Connection conn = nextConnection(tenantSpecificUrl);\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo1', 1, 1)\");\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo2', 2, 2)\");\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo3', 3, 3)\");\n+        conn.commit();\n+        conn.close();\n+\n+        conn = nextConnection(tenantSpecificUrl);\n+        PreparedStatement stmt = conn.prepareStatement(\"select pk2, pk3 from t_view WHERE (pk2 = ? OR pk2 = ?) AND (pk2, pk3) > (?, ?) LIMIT 100\");\n+        stmt.setString(1, \"helo1\");\n+        stmt.setString(2, \"helo3\");\n+        \n+        // return rows after helo1|1 \n+        stmt.setString(3, \"helo1\");\n+        stmt.setInt(4, 1);\n+\n+        ResultSet rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo3\", rs.getString(1));\n+        assertEquals(3, rs.getInt(2));\n+        assertFalse(rs.next());\n+        conn.close();\n+    }\n+\n+\n \n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java"}, {"additions": 13, "raw_url": "https://github.com/apache/phoenix/raw/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "blob_url": "https://github.com/apache/phoenix/blob/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java", "sha": "6a46a7b4a4fb0c87a6948b72267d58360214a0ee", "changes": 21, "status": "modified", "deletions": 8, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=31bd42301cad35f0e1f0b0e363dcf13726d84fd1", "patch": "@@ -105,6 +105,14 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             Expression whereClause, Set<Expression> extractNodes) {\n         PName tenantId = context.getConnection().getTenantId();\n         PTable table = context.getCurrentTable().getTable();\n+    \tInteger nBuckets = table.getBucketNum();\n+    \tboolean isSalted = nBuckets != null;\n+    \tRowKeySchema schema = table.getRowKeySchema();\n+    \tboolean isMultiTenant = tenantId != null && table.isMultiTenant();\n+    \tif (isMultiTenant) {\n+    \t\ttenantId = ScanUtil.padTenantIdIfNecessary(schema, isSalted, tenantId);\n+    \t}\n+\n         if (whereClause == null && (tenantId == null || !table.isMultiTenant()) && table.getViewIndexId() == null) {\n             context.setScanRanges(ScanRanges.EVERYTHING);\n             return whereClause;\n@@ -145,8 +153,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         int nPKColumns = table.getPKColumns().size();\n         int[] slotSpan = new int[nPKColumns];\n         List<Expression> removeFromExtractNodes = null;\n-        Integer nBuckets = table.getBucketNum();\n-        RowKeySchema schema = table.getRowKeySchema();\n         List<List<KeyRange>> cnf = Lists.newArrayListWithExpectedSize(schema.getMaxFields());\n         KeyRange minMaxRange = keySlots.getMinMaxRange();\n         if (minMaxRange == null) {\n@@ -155,8 +161,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         boolean hasMinMaxRange = (minMaxRange != KeyRange.EVERYTHING_RANGE);\n         int minMaxRangeOffset = 0;\n         byte[] minMaxRangePrefix = null;\n-        boolean isSalted = nBuckets != null;\n-        boolean isMultiTenant = tenantId != null && table.isMultiTenant();\n         boolean hasViewIndex = table.getViewIndexId() != null;\n         if (hasMinMaxRange) {\n             int minMaxRangeSize = (isSalted ? SaltingUtil.NUM_SALTING_BYTES : 0)\n@@ -181,7 +185,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         \n         // Add tenant data isolation for tenant-specific tables\n         if (isMultiTenant) {\n-            tenantId = ScanUtil.padTenantIdIfNecessary(schema, isSalted, tenantId);\n             byte[] tenantIdBytes = tenantId.getBytes();\n             KeyRange tenantIdKeyRange = KeyRange.getKeyRange(tenantIdBytes);\n             cnf.add(singletonList(tenantIdKeyRange));\n@@ -703,9 +706,11 @@ private KeySlots orKeySlots(OrExpression orExpression, List<KeySlots> childSlots\n                     minMaxRange = minMaxRange.union(childSlot.getMinMaxRange());\n                     thePosition = initialPos;\n                     for (KeySlot slot : childSlot) {\n-                        List<Expression> extractNodes = slot.getKeyPart().getExtractNodes();\n-                        extractAll &= !extractNodes.isEmpty();\n-                        slotExtractNodes.addAll(extractNodes);\n+                    \tif (slot != null) {\n+                    \t\tList<Expression> extractNodes = slot.getKeyPart().getExtractNodes();\n+                    \t\textractAll &= !extractNodes.isEmpty();\n+                    \t\tslotExtractNodes.addAll(extractNodes);\n+                    \t}\n                     }\n                 } else {\n                     // TODO: Do the same optimization that we do for IN if the childSlots specify a fully qualified row key", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "parent": "https://github.com/apache/phoenix/commit/c0b617f554938ea31832a921b8caa579e87749aa", "message": "PHOENIX-1385 Adding, dropping and adding columns fails with NPE (Samarth Jain, James Taylor)", "bug_id": "phoenix_42", "file": [{"additions": 21, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java", "sha": "5745bf03f1c17adbc1289cb0420a03e1acaafcaa", "changes": 22, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -892,4 +892,24 @@ public void alterTableFromDifferentClient() throws Exception {\n         pstmt2.close();\n         conn1.close();\n     }\n-}\n+    \n+    @Test\n+    public void testAddColumnsUsingNewConnection() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        String ddl = \"CREATE TABLE T (\\n\"\n+                +\"ID1 VARCHAR(15) NOT NULL,\\n\"\n+                +\"ID2 VARCHAR(15) NOT NULL,\\n\"\n+                +\"CREATED_DATE DATE,\\n\"\n+                +\"CREATION_TIME BIGINT,\\n\"\n+                +\"LAST_USED DATE,\\n\"\n+                +\"CONSTRAINT PK PRIMARY KEY (ID1, ID2))\";\n+        Connection conn1 = DriverManager.getConnection(getUrl(), props);\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T ADD STRING VARCHAR, STRING_DATA_TYPES VARCHAR\";\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T DROP COLUMN STRING, STRING_DATA_TYPES\";\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T ADD STRING_ARRAY1 VARCHAR[]\";\n+        conn1.createStatement().execute(ddl);\n+        conn1.close();\n+    }}", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java"}, {"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java", "sha": "4c57d0983b7a472b2fcc6aaf6475ab31fe05419a", "changes": 8, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -742,11 +742,11 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        metaData = metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        metaData = metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n         //Cascade through to connectionQueryServices too\n-        getQueryServices().removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+        getQueryServices().removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n         return metaData;\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java", "sha": "dbf786a17d2dc57eb6414d81b1e01e305b41f3da", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -512,12 +512,12 @@ public PMetaData removeTable(PName tenantId, final String tableName, String pare\n     }\n \n     @Override\n-    public PMetaData removeColumn(final PName tenantId, final String tableName, final String familyName, final String columnName, final long tableTimeStamp, final long tableSeqNum) throws SQLException {\n+    public PMetaData removeColumn(final PName tenantId, final String tableName, final List<PColumn> columnsToRemove, final long tableTimeStamp, final long tableSeqNum) throws SQLException {\n         return metaDataMutated(tenantId, tableName, tableSeqNum, new Mutator() {\n             @Override\n             public PMetaData mutate(PMetaData metaData) throws SQLException {\n                 try {\n-                    return metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+                    return metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n                 } catch (TableNotFoundException e) {\n                     // The DROP TABLE may have been processed first, so just ignore.\n                     return metaData;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java", "sha": "386050c6ebc049079ecdcf2147b79fec65bb85c9", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -152,9 +152,9 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        return metaData = metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        return metaData = metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n     }\n \n     ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java", "sha": "defad5b045372d3809d8b74be6d2b21ed932647a", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -88,9 +88,9 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        return getDelegate().removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        return getDelegate().removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n     }\n \n     @Override", "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java"}, {"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java", "sha": "cd4e2dedbfb4fb98d87563d23f910ecbb0131024", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -37,5 +37,5 @@\n     PMetaData addTable(PTable table) throws SQLException;\n     PMetaData removeTable(PName tenantId, String tableName, String parentTableName, long tableTimeStamp) throws SQLException;\n     PMetaData addColumn(PName tenantId, String tableName, List<PColumn> columns, long tableTimeStamp, long tableSeqNum, boolean isImmutableRows) throws SQLException;\n-    PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName, long tableTimeStamp, long tableSeqNum) throws SQLException;\n+    PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp, long tableSeqNum) throws SQLException;\n }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java", "sha": "afe21e866569ffba848acc3d2d373564631f8f61", "changes": 6, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -2308,10 +2308,8 @@ public MutationState dropColumn(DropColumnStatement statement) throws SQLExcepti\n                     // If we've done any index metadata updates, don't bother trying to update\n                     // client-side cache as it would be too painful. Just let it pull it over from\n                     // the server when needed.\n-                    if (columnsToDrop.size() > 0 && indexesToDrop.isEmpty()) {\n-                        for(PColumn columnToDrop : tableColumnsToDrop) {\n-                            connection.removeColumn(tenantId, SchemaUtil.getTableName(schemaName, tableName) , columnToDrop.getFamilyName().getString(), columnToDrop.getName().getString(), result.getMutationTime(), seqNum);\n-                        }\n+                    if (tableColumnsToDrop.size() > 0 && indexesToDrop.isEmpty()) {\n+                        connection.removeColumn(tenantId, SchemaUtil.getTableName(schemaName, tableName) , tableColumnsToDrop, result.getMutationTime(), seqNum);\n                     }\n                     // If we have a VIEW, then only delete the metadata, and leave the table data alone\n                     if (table.getType() != PTableType.VIEW) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java"}, {"additions": 28, "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java", "sha": "0d75aa29bcdc9e0ec11a97256a599d4c0dca678d", "changes": 53, "status": "modified", "deletions": 25, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50", "patch": "@@ -365,38 +365,41 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n     \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName, long tableTimeStamp, long tableSeqNum) throws SQLException {\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp, long tableSeqNum) throws SQLException {\n         PTableRef tableRef = metaData.get(new PTableKey(tenantId, tableName));\n         if (tableRef == null) {\n             return this;\n         }\n         PTable table = tableRef.table;\n         PTableCache tables = metaData.clone();\n-        PColumn column;\n-        if (familyName == null) {\n-            column = table.getPKColumn(columnName);\n-        } else {\n-            column = table.getColumnFamily(familyName).getColumn(columnName);\n-        }\n-        int positionOffset = 0;\n-        int position = column.getPosition();\n-        List<PColumn> oldColumns = table.getColumns();\n-        if (table.getBucketNum() != null) {\n-            position--;\n-            positionOffset = 1;\n-            oldColumns = oldColumns.subList(positionOffset, oldColumns.size());\n-        }\n-        List<PColumn> columns = Lists.newArrayListWithExpectedSize(oldColumns.size() - 1);\n-        columns.addAll(oldColumns.subList(0, position));\n-        // Update position of columns that follow removed column\n-        for (int i = position+1; i < oldColumns.size(); i++) {\n-            PColumn oldColumn = oldColumns.get(i);\n-            PColumn newColumn = new PColumnImpl(oldColumn.getName(), oldColumn.getFamilyName(), oldColumn.getDataType(), oldColumn.getMaxLength(), oldColumn.getScale(), oldColumn.isNullable(), i-1+positionOffset, oldColumn.getSortOrder(), oldColumn.getArraySize(), oldColumn.getViewConstant(), oldColumn.isViewReferenced());\n-            columns.add(newColumn);\n+        for (PColumn columnToRemove : columnsToRemove) {\n+            PColumn column;\n+            String familyName = columnToRemove.getFamilyName().getString();\n+            if (familyName == null) {\n+                column = table.getPKColumn(columnToRemove.getName().getString());\n+            } else {\n+                column = table.getColumnFamily(familyName).getColumn(columnToRemove.getName().getString());\n+            }\n+            int positionOffset = 0;\n+            int position = column.getPosition();\n+            List<PColumn> oldColumns = table.getColumns();\n+            if (table.getBucketNum() != null) {\n+                position--;\n+                positionOffset = 1;\n+                oldColumns = oldColumns.subList(positionOffset, oldColumns.size());\n+            }\n+            List<PColumn> columns = Lists.newArrayListWithExpectedSize(oldColumns.size() - 1);\n+            columns.addAll(oldColumns.subList(0, position));\n+            // Update position of columns that follow removed column\n+            for (int i = position+1; i < oldColumns.size(); i++) {\n+                PColumn oldColumn = oldColumns.get(i);\n+                PColumn newColumn = new PColumnImpl(oldColumn.getName(), oldColumn.getFamilyName(), oldColumn.getDataType(), oldColumn.getMaxLength(), oldColumn.getScale(), oldColumn.isNullable(), i-1+positionOffset, oldColumn.getSortOrder(), oldColumn.getArraySize(), oldColumn.getViewConstant(), oldColumn.isViewReferenced());\n+                columns.add(newColumn);\n+            }\n+            \n+            table = PTableImpl.makePTable(table, tableTimeStamp, tableSeqNum, columns);\n         }\n-        \n-        PTable newTable = PTableImpl.makePTable(table, tableTimeStamp, tableSeqNum, columns);\n-        tables.put(newTable.getKey(), newTable);\n+        tables.put(table.getKey(), table);\n         return new PMetaDataImpl(tables);\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/ea0a502ce133972b29c18a984063006d6dcd9691", "parent": "https://github.com/apache/phoenix/commit/faeab935554404a042285a01127e9b88b8e3a47c", "message": "PHOENIX-1305 create index throws NPE when dataTable has specified default column family (daniel meng)", "bug_id": "phoenix_43", "file": [{"additions": 50, "raw_url": "https://github.com/apache/phoenix/raw/ea0a502ce133972b29c18a984063006d6dcd9691/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/MutableIndexIT.java", "blob_url": "https://github.com/apache/phoenix/blob/ea0a502ce133972b29c18a984063006d6dcd9691/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/MutableIndexIT.java", "sha": "8c9256d23cf647755db33eaa70e4dc2935e6e790", "changes": 50, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/MutableIndexIT.java?ref=ea0a502ce133972b29c18a984063006d6dcd9691", "patch": "@@ -34,10 +34,16 @@\n import java.util.Properties;\n \n import org.apache.hadoop.hbase.HTableDescriptor;\n+import org.apache.phoenix.compile.ColumnResolver;\n+import org.apache.phoenix.compile.FromCompiler;\n import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n import org.apache.phoenix.end2end.HBaseManagedTimeTest;\n import org.apache.phoenix.end2end.Shadower;\n+import org.apache.phoenix.jdbc.PhoenixConnection;\n+import org.apache.phoenix.parse.NamedTableNode;\n+import org.apache.phoenix.parse.TableName;\n import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.schema.PTable;\n import org.apache.phoenix.util.MetaDataUtil;\n import org.apache.phoenix.util.PropertiesUtil;\n import org.apache.phoenix.util.QueryUtil;\n@@ -63,6 +69,50 @@ public static void doSetup() throws Exception {\n         props.put(QueryServices.DROP_METADATA_ATTRIB, Boolean.toString(true));\n         setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n     }\n+    \n+    @Test\n+    public void testIndexCreateWithoutOptions()  throws Exception {\n+        createIndexOnTableWithSpecifiedDefaultCF(false);\n+    }\n+    \n+    @Test\n+    public void testIndexCreateWithOptions()  throws Exception {\n+        createIndexOnTableWithSpecifiedDefaultCF(true);\n+    }\n+    \n+    private void createIndexOnTableWithSpecifiedDefaultCF(boolean hasOptions) throws Exception {\n+        String query;\n+        ResultSet rs;\n+\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"CREATE TABLE \" + DATA_TABLE_FULL_NAME + \" (k VARCHAR NOT NULL PRIMARY KEY, v1 VARCHAR, v2 VARCHAR) DEFAULT_COLUMN_FAMILY='A'\");\n+        query = \"SELECT * FROM \" + DATA_TABLE_FULL_NAME;\n+        rs = conn.createStatement().executeQuery(query);\n+        assertFalse(rs.next());\n+\n+        String options = hasOptions ? \"SALT_BUCKETS=10, MULTI_TENANT=true, IMMUTABLE_ROWS=true, DISABLE_WAL=true\" : \"\";\n+        conn.createStatement().execute(\n+                \"CREATE INDEX \" + INDEX_TABLE_NAME + \" ON \" + DATA_TABLE_FULL_NAME + \" (v1) INCLUDE (v2) \" + options);\n+        query = \"SELECT * FROM \" + INDEX_TABLE_FULL_NAME;\n+        rs = conn.createStatement().executeQuery(query);\n+        assertFalse(rs.next());\n+        \n+        //check options set correctly on index\n+        TableName indexName = TableName.create(SCHEMA_NAME, INDEX_TABLE_NAME);\n+        NamedTableNode indexNode = NamedTableNode.create(null, indexName, null);\n+        ColumnResolver resolver = FromCompiler.getResolver(indexNode, conn.unwrap(PhoenixConnection.class));\n+        PTable indexTable = resolver.getTables().get(0).getTable();\n+        // Can't set IMMUTABLE_ROWS, MULTI_TENANT or DEFAULT_COLUMN_FAMILY_NAME on an index\n+        assertNull(indexTable.getDefaultFamilyName());\n+        assertFalse(indexTable.isMultiTenant());\n+        assertFalse(indexTable.isImmutableRows());\n+        if(hasOptions) {\n+            assertEquals(10, indexTable.getBucketNum().intValue());\n+            assertTrue(indexTable.isWALDisabled());\n+        }\n+    }\n \n     @Test\n     public void testIndexWithNullableFixedWithCols() throws Exception {", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/index/MutableIndexIT.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/ea0a502ce133972b29c18a984063006d6dcd9691/phoenix-core/src/main/java/org/apache/phoenix/parse/CreateIndexStatement.java", "blob_url": "https://github.com/apache/phoenix/blob/ea0a502ce133972b29c18a984063006d6dcd9691/phoenix-core/src/main/java/org/apache/phoenix/parse/CreateIndexStatement.java", "sha": "669dc3f78ed078b76941a0fcb1e3e5dfa3ec7d37", "changes": 3, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/parse/CreateIndexStatement.java?ref=ea0a502ce133972b29c18a984063006d6dcd9691", "patch": "@@ -23,6 +23,7 @@\n import org.apache.hadoop.hbase.util.Pair;\n import org.apache.phoenix.schema.PTable.IndexType;\n \n+import com.google.common.collect.ArrayListMultimap;\n import com.google.common.collect.ListMultimap;\n \n \n@@ -43,7 +44,7 @@ public CreateIndexStatement(NamedNode indexTableName, NamedTableNode dataTable,\n         this.indexConstraint = indexConstraint == null ? PrimaryKeyConstraint.EMPTY : indexConstraint;\n         this.includeColumns = includeColumns == null ? Collections.<ColumnName>emptyList() : includeColumns;\n         this.splitNodes = splits == null ? Collections.<ParseNode>emptyList() : splits;\n-        this.props = props;\n+        this.props = props == null ? ArrayListMultimap.<String,Pair<String,Object>>create() : props;\n         this.ifNotExists = ifNotExists;\n         this.indexType = indexType;\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/parse/CreateIndexStatement.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113", "parent": "https://github.com/apache/phoenix/commit/eeac05afa257a7e733298a5680efede4abcd5355", "message": "PHOENIX-1131 Fix NPE in PhoenixRuntime.encodePk padding of row key values to max column length", "bug_id": "phoenix_44", "file": [{"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java", "blob_url": "https://github.com/apache/phoenix/blob/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java", "sha": "c2fcbf0006ba4537a65b9d6d1119f0fc029f9e09", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java?ref=dd97d44e779bc34c1edfb2bb3fd6dd91514d0113", "patch": "@@ -180,7 +180,7 @@ public String toStringLiteral(byte[] b, int offset, int length, Format formatter\n      */\n     CHAR(\"CHAR\", Types.CHAR, String.class, null) { // Delegate to VARCHAR\n         @Override\n-        public Object pad(Object object, int maxLength) {\n+        public Object pad(Object object, Integer maxLength) {\n             String s = (String) object;\n             if (s == null) {\n                 return s;\n@@ -3124,7 +3124,7 @@ public String toStringLiteral(byte[] b, int o, int length, Format formatter) {\n     },\n     BINARY(\"BINARY\", Types.BINARY, byte[].class, null) {\n         @Override\n-        public Object pad(Object object, int maxLength) {\n+        public Object pad(Object object, Integer maxLength) {\n             byte[] b = (byte[]) object;\n             if (b == null) {\n                 return null;\n@@ -7132,7 +7132,7 @@ public long getMillis(ImmutableBytesWritable ptr, SortOrder sortOrder) {\n         throw new UnsupportedOperationException(\"Operation not supported for type \" + this);\n     }\n \n-    public Object pad(Object object, int maxLength) {\n+    public Object pad(Object object, Integer maxLength) {\n         return object;\n     }\n     ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/8fb95998121d4f6e0330912ea5244dd9a8877045", "parent": "https://github.com/apache/phoenix/commit/675852ba974ab047dd0feca8e0dce5ff329b6e76", "message": "PHOENIX-875: NPE when running end2end tests against a live cluster", "bug_id": "phoenix_45", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/8fb95998121d4f6e0330912ea5244dd9a8877045/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/8fb95998121d4f6e0330912ea5244dd9a8877045/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java", "sha": "55c293bf3aa83e5f9feeaef6b7c74b8758a1e99a", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java?ref=8fb95998121d4f6e0330912ea5244dd9a8877045", "patch": "@@ -984,7 +984,7 @@ private MetaDataMutationResult doDropTable(byte[] key, byte[] tenantId, byte[] s\n                 }\n             } else {\n                 return new MetaDataMutationResult(MutationCode.NEWER_TABLE_FOUND,\n-                        EnvironmentEdgeManager.currentTimeMillis(), table);\n+                        EnvironmentEdgeManager.currentTimeMillis(), null);\n             }\n         }\n         if (table == null && buildDeletedTable(key, cacheKey, region, clientTimeStamp) != null) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/MetaDataEndpointImpl.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/0deb4881619b91a25f5b71baf88180597eba54c7", "parent": "https://github.com/apache/phoenix/commit/124bf461cdd2489389e1e05d881133b93d0ea16f", "message": "PHOENIX-841 Upserting into tenant-specific view with no where clause fails with an NPE (EliLevine)", "bug_id": "phoenix_46", "file": [{"additions": 16, "raw_url": "https://github.com/apache/phoenix/raw/0deb4881619b91a25f5b71baf88180597eba54c7/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificTablesDMLIT.java", "blob_url": "https://github.com/apache/phoenix/blob/0deb4881619b91a25f5b71baf88180597eba54c7/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificTablesDMLIT.java", "sha": "e32d84915b4ae9a4367c1d2eca435721fb369e86", "changes": 17, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificTablesDMLIT.java?ref=0deb4881619b91a25f5b71baf88180597eba54c7", "patch": "@@ -296,7 +296,7 @@ public void testUpsertSelectOnlyUpsertsTenantData() throws Exception {\n     @Test\n     public void testUpsertSelectOnlyUpsertsTenantDataWithDifferentTenantTable() throws Exception {\n         createTestTable(PHOENIX_JDBC_TENANT_SPECIFIC_URL, \"CREATE VIEW ANOTHER_TENANT_TABLE ( \" + \n-            \"tenant_col VARCHAR) AS SELECT * FROM PARENT_TABLE WHERE tenant_type_id = 'def'\", null, nextTimestamp(), false);\n+            \"tenant_col VARCHAR) AS SELECT * FROM \" + PARENT_TABLE_NAME + \" WHERE tenant_type_id = 'def'\", null, nextTimestamp(), false);\n         \n         Connection conn = nextConnection(getUrl());\n         try {\n@@ -384,4 +384,19 @@ public void testTenantTableCannotBeUsedInStatementsInNonMultitenantConnections()\n             conn.close();\n         }\n     }\n+    \n+    @Test\n+    public void testUpsertValuesUsingViewWithNoWhereClause() throws Exception {\n+        Connection conn = nextConnection(PHOENIX_JDBC_TENANT_SPECIFIC_URL);\n+        conn.setAutoCommit(true);\n+        conn.createStatement().executeUpdate(\"upsert into \" + TENANT_TABLE_NAME_NO_TENANT_TYPE_ID + \" (id) values (0)\");\n+        conn.close();\n+        \n+        conn = nextConnection(PHOENIX_JDBC_TENANT_SPECIFIC_URL);\n+        ResultSet rs = conn.createStatement().executeQuery(\"select id from \" + TENANT_TABLE_NAME_NO_TENANT_TYPE_ID);\n+        assertTrue(rs.next());\n+        assertEquals(0, rs.getInt(1));\n+        assertFalse(rs.next());\n+        conn.close();\n+    }\n }", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificTablesDMLIT.java"}, {"additions": 6, "raw_url": "https://github.com/apache/phoenix/raw/0deb4881619b91a25f5b71baf88180597eba54c7/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/0deb4881619b91a25f5b71baf88180597eba54c7/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java", "sha": "28dfda1d2b5f5ba8b7335a3bab6cc985788a42c5", "changes": 9, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java?ref=0deb4881619b91a25f5b71baf88180597eba54c7", "patch": "@@ -236,9 +236,12 @@ public MutationPlan compile(UpsertStatement upsert) throws SQLException {\n         if (table.getViewType() == ViewType.UPDATABLE) {\n             StatementContext context = new StatementContext(statement, resolver, new Scan());\n             ViewValuesMapBuilder builder = new ViewValuesMapBuilder(context);\n-            ParseNode viewNode = new SQLParser(table.getViewStatement()).parseQuery().getWhere();\n-            viewNode.accept(builder);\n-            addViewColumnsToBe = builder.getViewColumns();\n+            String viewStatement = table.getViewStatement();\n+            if (viewStatement != null) {\n+\t            ParseNode viewNode = new SQLParser(viewStatement).parseQuery().getWhere();\n+\t            viewNode.accept(builder);\n+\t            addViewColumnsToBe = builder.getViewColumns();\n+            }\n         }\n         // Allow full row upsert if no columns or only dynamic ones are specified and values count match\n         if (columnNodes.isEmpty() || columnNodes.size() == upsert.getTable().getDynamicColumns().size()) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/b355c2a08f92763f1d7272f2a2300e024e70d756", "parent": "https://github.com/apache/phoenix/commit/7b7ad1c1b8432c067754e94ff73d8ed2124999b8", "message": "PHOENIX-106 NPE when adding dynamic columns to a salted table (JamesTaylor)", "bug_id": "phoenix_47", "file": [{"additions": 5, "raw_url": "https://github.com/apache/phoenix/raw/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java", "sha": "a987798f2065b5483cdcb31d13ac2036f477f92f", "changes": 7, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java?ref=b355c2a08f92763f1d7272f2a2300e024e70d756", "patch": "@@ -312,8 +312,11 @@ protected PTable addDynamicColumns(List<ColumnDef> dynColumns, PTable theTable)\n                 throws SQLException {\n             if (!dynColumns.isEmpty()) {\n                 List<PColumn> allcolumns = new ArrayList<PColumn>();\n-                allcolumns.addAll(theTable.getColumns());\n-                int position = allcolumns.size();\n+                List<PColumn> existingColumns = theTable.getColumns();\n+                // Need to skip the salting column, as it's added in the makePTable call below\n+                allcolumns.addAll(theTable.getBucketNum() == null ? existingColumns : existingColumns.subList(1, existingColumns.size()));\n+                // Position still based on with the salting columns\n+                int position = existingColumns.size();\n                 PName defaultFamilyName = PNameFactory.newName(SchemaUtil.getEmptyColumnFamily(theTable));\n                 for (ColumnDef dynColumn : dynColumns) {\n                     PName familyName = defaultFamilyName;", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java"}, {"additions": 49, "raw_url": "https://github.com/apache/phoenix/raw/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java", "blob_url": "https://github.com/apache/phoenix/blob/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java", "sha": "ef68847e0f2bc257555f9f479b2efb1c9fa67a22", "changes": 49, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java?ref=b355c2a08f92763f1d7272f2a2300e024e70d756", "patch": "@@ -25,6 +25,7 @@\n import static org.junit.Assert.assertTrue;\n \n import java.sql.Connection;\n+import java.sql.Date;\n import java.sql.DriverManager;\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n@@ -83,4 +84,52 @@ public void testAutoCommitUpsertSelect() throws Exception {\n         assertFalse(rs.next());\n         \n     }\n+\n+    @Test\n+    public void testDynamicUpsertSelect() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        String cursorDDL = \" CREATE TABLE IF NOT EXISTS CURSOR (ORGANIZATION_ID VARCHAR(15) NOT NULL, \\n\"\n+                + \"QUERY_ID VARCHAR(15) NOT NULL, \\n\"\n+                + \"CURSOR_ORDER UNSIGNED_LONG NOT NULL, \\n\"\n+                + \"CONSTRAINT API_HBASE_CURSOR_STORAGE_PK PRIMARY KEY (ORGANIZATION_ID, QUERY_ID, CURSOR_ORDER))\\n\"\n+                + \"SALT_BUCKETS = 4\";\n+        conn.createStatement().execute(cursorDDL);\n+        \n+        String dataTableDDL = \"CREATE TABLE IF NOT EXISTS PLINYTEST\" +\n+                \"(\" +\n+                \"ORGANIZATION_ID CHAR(15) NOT NULL, \" +\n+                \"PLINY_ID CHAR(15) NOT NULL, \" +\n+                \"CREATED_DATE DATE NOT NULL, \" + \n+                \"TEXT VARCHAR, \" +\n+                \"CONSTRAINT PK PRIMARY KEY \" +\n+                \"(\" +\n+                \"ORGANIZATION_ID, \" +\n+                \"PLINY_ID, \"  +\n+                \"CREATED_DATE\" +\n+                \")\" +\n+                \")\";\n+        \n+        conn.createStatement().execute(dataTableDDL);\n+        PreparedStatement stmt = null;\n+        String upsert = \"UPSERT INTO PLINYTEST VALUES (?, ?, ?, ?)\";\n+        stmt = conn.prepareStatement(upsert);\n+        stmt.setString(1, getOrganizationId());\n+        stmt.setString(2, \"aaaaaaaaaaaaaaa\");\n+        stmt.setDate(3, new Date(System.currentTimeMillis()));\n+        stmt.setString(4, \"text\");\n+        stmt.executeUpdate();\n+        conn.commit();\n+        \n+        String upsertSelect = \"UPSERT INTO CURSOR (ORGANIZATION_ID, QUERY_ID, CURSOR_ORDER, PLINY_ID CHAR(15),CREATED_DATE DATE) SELECT ?, ?, ?, PLINY_ID, CREATED_DATE FROM PLINYTEST WHERE ORGANIZATION_ID = ?\";\n+        stmt = conn.prepareStatement(upsertSelect);\n+        String orgId = getOrganizationId();\n+        stmt.setString(1, orgId);\n+        stmt.setString(2, \"queryqueryquery\");\n+\n+        stmt.setInt(3, 1);\n+        stmt.setString(4, orgId);\n+        stmt.executeUpdate();\n+        conn.commit();\n+    }\n+    \n }", "filename": "phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/3fd64258a75701203f8848b294eb778e958796e4", "parent": "https://github.com/apache/phoenix/commit/2ab8f34d255fb0b92168fc63561ab335558d043d", "message": "PHOENIX-1001 Using NEXT VALUE FOR 'sequence' as an input to a function cause a NPE (Thomas D'Silva)", "bug_id": "phoenix_48", "file": [{"additions": 22, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/it/java/org/apache/phoenix/end2end/SequenceIT.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/it/java/org/apache/phoenix/end2end/SequenceIT.java", "sha": "84bfece501cf7d46a2799897b9041552819d2c7f", "changes": 22, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/SequenceIT.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -587,6 +587,28 @@ public void testExplainPlanValidatesSequences() throws Exception {\n         conn.close();\n     }\n     \n+    @Test\n+    public void testSelectNextValueAsInput() throws Exception {\n+        nextConnection();\n+        conn.createStatement().execute(\"CREATE SEQUENCE foo.bar START WITH 3 INCREMENT BY 2\");\n+        nextConnection();\n+        String query = \"SELECT COALESCE(NEXT VALUE FOR foo.bar,1) FROM SYSTEM.\\\"SEQUENCE\\\"\";\n+        ResultSet rs = conn.prepareStatement(query).executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(3, rs.getInt(1));\n+    }\n+    \n+    @Test\n+    public void testSelectNextValueInArithmetic() throws Exception {\n+        nextConnection();\n+        conn.createStatement().execute(\"CREATE SEQUENCE foo.bar START WITH 3 INCREMENT BY 2\");\n+        nextConnection();\n+        String query = \"SELECT NEXT VALUE FOR foo.bar+1 FROM SYSTEM.\\\"SEQUENCE\\\"\";\n+        ResultSet rs = conn.prepareStatement(query).executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(4, rs.getInt(1));\n+    }\n+    \n \tprivate void nextConnection() throws Exception {\n \t    if (conn != null) conn.close();\n \t    long ts = nextTimestamp();", "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/SequenceIT.java"}, {"additions": 18, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/compile/ExpressionCompiler.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/compile/ExpressionCompiler.java", "sha": "2d5e461bc7660873ff11d469b14afce1802b3c44", "changes": 48, "status": "modified", "deletions": 30, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ExpressionCompiler.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -99,6 +99,7 @@\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.TableRef;\n import org.apache.phoenix.schema.TypeMismatchException;\n+import org.apache.phoenix.util.ExpressionUtil;\n import org.apache.phoenix.util.IndexUtil;\n import org.apache.phoenix.util.SchemaUtil;\n \n@@ -272,7 +273,7 @@ private Expression wrapGroupByExpression(Expression expression) {\n     protected Expression addExpression(Expression expression) {\n         return context.getExpressionManager().addIfAbsent(expression);\n     }\n-\n+   \n     @Override\n     /**\n      * @param node a function expression node\n@@ -282,25 +283,18 @@ public Expression visitLeave(FunctionParseNode node, List<Expression> children)\n         children = node.validate(children, context);\n         Expression expression = node.create(children, context);\n         ImmutableBytesWritable ptr = context.getTempPtr();\n-        if (node.isStateless()) {\n-            Object value = null;\n-            PDataType type = expression.getDataType();\n-            if (expression.evaluate(null, ptr)) {\n-                value = type.toObject(ptr);\n-            }\n-            return LiteralExpression.newConstant(value, type, expression.isDeterministic());\n+        if (ExpressionUtil.isConstant(expression)) {\n+            return ExpressionUtil.getConstantExpression(expression, ptr);\n         }\n-        boolean isDeterministic = true;\n         BuiltInFunctionInfo info = node.getInfo();\n         for (int i = 0; i < info.getRequiredArgCount(); i++) { \n             // Optimization to catch cases where a required argument is null resulting in the function\n             // returning null. We have to wait until after we create the function expression so that\n             // we can get the proper type to use.\n             if (node.evalToNullIfParamIsNull(context, i)) {\n                 Expression child = children.get(i);\n-                isDeterministic &= child.isDeterministic();\n-                if (child.isStateless() && (!child.evaluate(null, ptr) || ptr.getLength() == 0)) {\n-                    return LiteralExpression.newConstant(null, expression.getDataType(), isDeterministic);\n+                if (ExpressionUtil.isNull(child, ptr)) {\n+                    return ExpressionUtil.getNullExpression(expression);\n                 }\n             }\n         }\n@@ -411,7 +405,7 @@ public Expression visitLeave(CaseParseNode node, List<Expression> l) throws SQLE\n                 context.getBindManager().addParamMetaData((BindParseNode)childNode, new DelegateDatum(caseExpression));\n             }\n         }\n-        if (node.isStateless()) {\n+        if (ExpressionUtil.isConstant(caseExpression)) {\n             ImmutableBytesWritable ptr = context.getTempPtr();\n             int index = caseExpression.evaluateIndexOf(null, ptr);\n             if (index < 0) {\n@@ -473,7 +467,7 @@ public Expression visitLeave(LikeParseNode node, List<Expression> children) thro\n             }\n         }\n         Expression expression = new LikeExpression(children);\n-        if (node.isStateless()) {\n+        if (ExpressionUtil.isConstant(expression)) {\n             ImmutableBytesWritable ptr = context.getTempPtr();\n             if (!expression.evaluate(null, ptr)) {\n                 return LiteralExpression.newConstant(null, expression.isDeterministic());\n@@ -658,12 +652,10 @@ private Expression visitLeave(ArithmeticParseNode node, List<Expression> childre\n         ImmutableBytesWritable ptr = context.getTempPtr();\n \n         // If all children are literals, just evaluate now\n-        if (expression.isStateless()) {\n-            if (!expression.evaluate(null,ptr) || ptr.getLength() == 0) {\n-                return LiteralExpression.newConstant(null, expression.getDataType(), expression.isDeterministic());\n-            }\n-            return LiteralExpression.newConstant(expression.getDataType().toObject(ptr), expression.getDataType(), expression.isDeterministic());\n-        } else if (isNull) {\n+        if (ExpressionUtil.isConstant(expression)) {\n+            return ExpressionUtil.getConstantExpression(expression, ptr); \n+        } \n+        else if (isNull) {\n             return LiteralExpression.newConstant(null, expression.getDataType(), expression.isDeterministic());\n         }\n         // Otherwise create and return the expression\n@@ -1065,11 +1057,8 @@ public Expression visitLeave(StringConcatParseNode node, List<Expression> childr\n             }\n         }\n         ImmutableBytesWritable ptr = context.getTempPtr();\n-        if (expression.isStateless()) {\n-            if (!expression.evaluate(null,ptr) || ptr.getLength() == 0) {\n-                return LiteralExpression.newConstant(null, expression.getDataType(), expression.isDeterministic());\n-            }\n-            return LiteralExpression.newConstant(expression.getDataType().toObject(ptr), expression.getDataType(), expression.isDeterministic());\n+        if (ExpressionUtil.isConstant(expression)) {\n+            return ExpressionUtil.getConstantExpression(expression, ptr);\n         }\n         return wrapGroupByExpression(expression);\n     }\n@@ -1147,21 +1136,20 @@ public PDataType getDataType() {\n         }\n         ImmutableBytesWritable ptr = context.getTempPtr();\n         Object[] elements = new Object[children.size()];\n-        if (node.isStateless()) {\n-            boolean isDeterministic = true;\n+        \n+        ArrayConstructorExpression arrayExpression = new ArrayConstructorExpression(children, arrayElemDataType);\n+        if (ExpressionUtil.isConstant(arrayExpression)) {\n             for (int i = 0; i < children.size(); i++) {\n                 Expression child = children.get(i);\n-                isDeterministic &= child.isDeterministic();\n                 child.evaluate(null, ptr);\n                 Object value = arrayElemDataType.toObject(ptr, child.getDataType(), child.getSortOrder());\n                 elements[i] = LiteralExpression.newConstant(value, child.getDataType(), child.isDeterministic()).getValue();\n             }\n             Object value = PArrayDataType.instantiatePhoenixArray(arrayElemDataType, elements);\n             return LiteralExpression.newConstant(value,\n-                    PDataType.fromTypeId(arrayElemDataType.getSqlType() + PDataType.ARRAY_TYPE_BASE), isDeterministic);\n+                    PDataType.fromTypeId(arrayElemDataType.getSqlType() + PDataType.ARRAY_TYPE_BASE), true);\n         }\n         \n-        ArrayConstructorExpression arrayExpression = new ArrayConstructorExpression(children, arrayElemDataType);\n         return wrapGroupByExpression(arrayExpression);\n     }\n ", "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ExpressionCompiler.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/BaseCompoundExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/BaseCompoundExpression.java", "sha": "03df653a0da19cf188685f8cb7bf4855c94673f5", "changes": 2, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/BaseCompoundExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -21,6 +21,7 @@\n import java.io.DataOutput;\n import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.List;\n \n import org.apache.hadoop.io.WritableUtils;\n@@ -37,6 +38,7 @@\n     private boolean requiresFinalEvaluation;\n    \n     public BaseCompoundExpression() {\n+        init(Collections.<Expression>emptyList());\n     }\n     \n     public BaseCompoundExpression(List<Expression> children) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/BaseCompoundExpression.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/ComparisonExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/ComparisonExpression.java", "sha": "008ae7bc2ed0181fd01ed672c88a81fd0488ab40", "changes": 5, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/ComparisonExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -35,6 +35,7 @@\n import org.apache.phoenix.schema.TypeMismatchException;\n import org.apache.phoenix.schema.tuple.Tuple;\n import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.util.ExpressionUtil;\n import org.apache.phoenix.util.StringUtil;\n \n import com.google.common.collect.Lists;\n@@ -59,8 +60,8 @@\n     }\n     \n     private static void addEqualityExpression(Expression lhs, Expression rhs, List<Expression> andNodes, ImmutableBytesWritable ptr) throws SQLException {\n-        boolean isLHSNull = lhs.isStateless() && (!lhs.evaluate(null, ptr) || ptr.getLength()==0);\n-        boolean isRHSNull = rhs.isStateless() && (!rhs.evaluate(null, ptr) || ptr.getLength()==0);\n+        boolean isLHSNull = ExpressionUtil.isNull(lhs, ptr);\n+        boolean isRHSNull = ExpressionUtil.isNull(rhs, ptr);\n         if (isLHSNull && isRHSNull) { // null == null will end up making the query degenerate\n             andNodes.add(LiteralExpression.newConstant(false, PDataType.BOOLEAN));\n         } else if (isLHSNull) { // AND rhs IS NULL", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/ComparisonExpression.java"}, {"additions": 3, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/InListExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/InListExpression.java", "sha": "979af0c0c142e17257090e7037b3ed832250fc87", "changes": 9, "status": "modified", "deletions": 6, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/InListExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -36,6 +36,7 @@\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.tuple.Tuple;\n import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.util.ExpressionUtil;\n \n import com.google.common.collect.Lists;\n import com.google.common.collect.Sets;\n@@ -93,12 +94,8 @@ public static Expression create (List<Expression> children, boolean isNegate, Im\n         if (isNegate) { \n             expression = NotExpression.create(expression, ptr);\n         }\n-        if (expression.isStateless()) {\n-            if (!expression.evaluate(null, ptr) || ptr.getLength() == 0) {\n-                return LiteralExpression.newConstant(null,expression.getDataType(), expression.isDeterministic());\n-            }\n-            Object value = expression.getDataType().toObject(ptr);\n-            return LiteralExpression.newConstant(value, expression.getDataType(), expression.isDeterministic());\n+        if (ExpressionUtil.isConstant(expression)) {\n+            return ExpressionUtil.getConstantExpression(expression, ptr);\n         }\n         return expression;\n     }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/InListExpression.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/IsNullExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/IsNullExpression.java", "sha": "4162dfce9378348ee15bac12df4aeb098edce107", "changes": 3, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/IsNullExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -27,6 +27,7 @@\n import org.apache.phoenix.expression.visitor.ExpressionVisitor;\n import org.apache.phoenix.schema.PDataType;\n import org.apache.phoenix.schema.tuple.Tuple;\n+import org.apache.phoenix.util.ExpressionUtil;\n \n \n /**\n@@ -43,7 +44,7 @@ public static Expression create(Expression child, boolean negate, ImmutableBytes\n         if (!child.isNullable()) {\n             return LiteralExpression.newConstant(negate, PDataType.BOOLEAN, child.isDeterministic());\n         }\n-        if (child.isStateless()) {\n+        if (ExpressionUtil.isConstant(child)) {\n             boolean evaluated = child.evaluate(null, ptr);\n             return LiteralExpression.newConstant(negate ^ (!evaluated || ptr.getLength() == 0), PDataType.BOOLEAN, child.isDeterministic());\n         }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/IsNullExpression.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/LiteralExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/LiteralExpression.java", "sha": "91a3125534e2b2e991484423cf1179209963e6fb", "changes": 4, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/LiteralExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -48,8 +48,8 @@\n  * @since 0.1\n  */\n public class LiteralExpression extends BaseTerminalExpression {\n-    public static final LiteralExpression NULL_EXPRESSION = new LiteralExpression(null, false);\n-    private static final LiteralExpression ND_NULL_EXPRESSION = new LiteralExpression(null, true);\n+    public static final LiteralExpression NULL_EXPRESSION = new LiteralExpression(null, true);\n+    private static final LiteralExpression ND_NULL_EXPRESSION = new LiteralExpression(null, false);\n     private static final LiteralExpression[] TYPED_NULL_EXPRESSIONS = new LiteralExpression[PDataType.values().length * 2];\n     static {\n         for (int i = 0; i < PDataType.values().length; i++) {", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/LiteralExpression.java"}, {"additions": 2, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FunctionExpression.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FunctionExpression.java", "sha": "45c3e15b20e8a011d325a060646ba41a02f45648", "changes": 2, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/FunctionExpression.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -59,6 +59,8 @@ public OrderPreserving preservesOrder() {\n     @Override\n     public final String toString() {\n         StringBuilder buf = new StringBuilder(getName() + \"(\");\n+        if (children.size()==0)\n+            return buf.append(\")\").toString();\n         for (int i = 0; i < children.size() - 1; i++) {\n             buf.append(children.get(i) + \", \");\n         }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/FunctionExpression.java"}, {"additions": 57, "raw_url": "https://github.com/apache/phoenix/raw/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/util/ExpressionUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/3fd64258a75701203f8848b294eb778e958796e4/phoenix-core/src/main/java/org/apache/phoenix/util/ExpressionUtil.java", "sha": "227a38531c78fff3f77d68b851b1081d737d9fa9", "changes": 57, "status": "added", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/ExpressionUtil.java?ref=3fd64258a75701203f8848b294eb778e958796e4", "patch": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE\n+ * file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the\n+ * License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by\n+ * applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language\n+ * governing permissions and limitations under the License.\n+ */\n+package org.apache.phoenix.util;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Expression;\n+import org.apache.phoenix.expression.LiteralExpression;\n+import org.apache.phoenix.expression.function.CurrentDateFunction;\n+import org.apache.phoenix.expression.function.CurrentTimeFunction;\n+import org.apache.phoenix.expression.function.FunctionExpression;\n+import org.apache.phoenix.schema.PDataType;\n+\n+import com.google.common.collect.Lists;\n+\n+public class ExpressionUtil {\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static final List<Class<? extends FunctionExpression>> OVERRIDE_LITERAL_FUNCTIONS = Lists\n+            .<Class<? extends FunctionExpression>> newArrayList(CurrentDateFunction.class, CurrentTimeFunction.class);\n+\n+    private ExpressionUtil() {}\n+\n+    public static boolean isConstant(Expression expression) {\n+        return (expression.isStateless() && expression.isDeterministic() || OVERRIDE_LITERAL_FUNCTIONS\n+                .contains(expression.getClass()));\n+    }\n+\n+    public static LiteralExpression getConstantExpression(Expression expression, ImmutableBytesWritable ptr)\n+            throws SQLException {\n+        Object value = null;\n+        PDataType type = expression.getDataType();\n+        if (expression.evaluate(null, ptr) && ptr.getLength() != 0) {\n+            value = type.toObject(ptr);\n+        }\n+        return LiteralExpression.newConstant(value, type, expression.isDeterministic());\n+    }\n+\n+    public static boolean isNull(Expression expression, ImmutableBytesWritable ptr) {\n+        return expression.isStateless() && expression.isDeterministic()\n+                && (!expression.evaluate(null, ptr) || ptr.getLength() == 0);\n+    }\n+\n+    public static LiteralExpression getNullExpression(Expression expression) throws SQLException {\n+        return LiteralExpression.newConstant(null, expression.getDataType(), expression.isDeterministic());\n+    }\n+\n+}", "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/ExpressionUtil.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/5d1fd559b27ea04d677b5a77fb26ab1d685053ee", "parent": "https://github.com/apache/phoenix/commit/a977a7529f5c5bce9b38610cc6b0c534ee3a88d0", "message": "PHOENIX-30 NPE on PTable.getColumn(String) if column with same name used in the PK and non PK (JamesTaylor)", "bug_id": "phoenix_49", "file": [{"additions": 4, "raw_url": "https://github.com/apache/phoenix/raw/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java", "blob_url": "https://github.com/apache/phoenix/blob/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java", "sha": "f2a3e7685e12f099b01de3954756c7ce0b98610e", "changes": 6, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java?ref=5d1fd559b27ea04d677b5a77fb26ab1d685053ee", "patch": "@@ -468,8 +468,10 @@ public PColumn getColumn(String name) throws ColumnNotFoundException, AmbiguousC\n         }\n         if (size > 1) {\n             for (PColumn column : columns) {\n-                if (QueryConstants.DEFAULT_COLUMN_FAMILY.equals(column.getFamilyName().getString())) {\n-                    // Allow ambiguity with default column, since a user would not know how to prefix it.\n+                if (column.getFamilyName() == null || QueryConstants.DEFAULT_COLUMN_FAMILY.equals(column.getFamilyName().getString())) {\n+                    // Allow ambiguity with PK column or column in the default column family,\n+                    // since a PK column cannot be prefixed and a user would not know how to\n+                    // prefix a column in the default column family.\n                     return column;\n                 }\n             }", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java"}, {"additions": 16, "raw_url": "https://github.com/apache/phoenix/raw/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java", "blob_url": "https://github.com/apache/phoenix/blob/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java", "sha": "e9c34e0005c09ffd59e2d0aa514ad6a13a9b448f", "changes": 17, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java?ref=5d1fd559b27ea04d677b5a77fb26ab1d685053ee", "patch": "@@ -23,10 +23,10 @@\n import static org.apache.phoenix.util.TestUtil.assertDegenerate;\n import static org.junit.Assert.assertArrayEquals;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertNotNull;\n import static org.junit.Assert.assertNull;\n import static org.junit.Assert.assertTrue;\n-import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.fail;\n \n import java.sql.Connection;\n@@ -45,12 +45,14 @@\n import org.apache.phoenix.expression.aggregator.CountAggregator;\n import org.apache.phoenix.expression.aggregator.ServerAggregators;\n import org.apache.phoenix.expression.function.TimeUnit;\n+import org.apache.phoenix.jdbc.PhoenixConnection;\n import org.apache.phoenix.jdbc.PhoenixPreparedStatement;\n import org.apache.phoenix.query.BaseConnectionlessQueryTest;\n import org.apache.phoenix.query.QueryConstants;\n import org.apache.phoenix.schema.AmbiguousColumnException;\n import org.apache.phoenix.schema.ColumnAlreadyExistsException;\n import org.apache.phoenix.schema.ColumnNotFoundException;\n+import org.apache.phoenix.schema.PColumn;\n import org.apache.phoenix.util.ByteUtil;\n import org.apache.phoenix.util.PhoenixRuntime;\n import org.apache.phoenix.util.SchemaUtil;\n@@ -138,6 +140,19 @@ public void testFamilyNameInPK() throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testSameColumnNameInPKAndNonPK() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        try {\n+            String query = \"CREATE TABLE t1 (k integer not null primary key, a.k decimal, b.k decimal)\";\n+            conn.createStatement().execute(query);\n+            PColumn c = conn.unwrap(PhoenixConnection.class).getPMetaData().getTable(\"T1\").getColumn(\"K\");\n+            assertTrue(SchemaUtil.isPKColumn(c));\n+        } finally {\n+            conn.close();\n+        }\n+    }\n+\n     @Test\n     public void testVarBinaryInMultipartPK() throws Exception {\n         Connection conn = DriverManager.getConnection(getUrl());", "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java"}], "repo": "phoenix"}, {"commit": "https://github.com/apache/phoenix/commit/fe18e96ae429cc0e4291075177d0e0c5f5e9a5b1", "parent": "https://github.com/apache/phoenix/commit/ae131f560987039142ea5d0ed468c19d4aca565d", "message": "Fix NPE introduced by my previous fix for Phoenix-32 - SortOrder was being passed in as null instead of ASC.\nhttps://issues.apache.org/jira/browse/PHOENIX-32", "bug_id": "phoenix_50", "file": [{"additions": 1, "raw_url": "https://github.com/apache/phoenix/raw/fe18e96ae429cc0e4291075177d0e0c5f5e9a5b1/phoenix-core/src/main/java/org/apache/phoenix/schema/SaltingUtil.java", "blob_url": "https://github.com/apache/phoenix/blob/fe18e96ae429cc0e4291075177d0e0c5f5e9a5b1/phoenix-core/src/main/java/org/apache/phoenix/schema/SaltingUtil.java", "sha": "f743f26aa3b1121dcc174e7aea2cec7a38ad88b4", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/SaltingUtil.java?ref=fe18e96ae429cc0e4291075177d0e0c5f5e9a5b1", "patch": "@@ -38,7 +38,7 @@\n     public static final String SALTING_COLUMN_NAME = \"_SALT\";\n     public static final String SALTED_ROW_KEY_NAME = \"_SALTED_KEY\";\n     public static final PColumnImpl SALTING_COLUMN = new PColumnImpl(\n-            PNameFactory.newName(SALTING_COLUMN_NAME), null, PDataType.BINARY, 1, 0, false, 0, null, 0);\n+            PNameFactory.newName(SALTING_COLUMN_NAME), null, PDataType.BINARY, 1, 0, false, 0, SortOrder.getDefault(), 0);\n     public static final RowKeySchema VAR_BINARY_SALTED_SCHEMA = new RowKeySchemaBuilder(1)\n         .addField(SALTING_COLUMN, false, SortOrder.getDefault())\n         .addField(SchemaUtil.VAR_BINARY_DATUM, false, SortOrder.getDefault()).build();", "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/SaltingUtil.java"}], "repo": "phoenix"}]
