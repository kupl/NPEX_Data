[
    {
        "commit": "https://github.com/apache/sentry/commit/13010b0b600c4f2e7a7ea7f0ec8dcae87632950a",
        "file": [
            {
                "patch": "@@ -878,7 +878,13 @@ void renameAuthzObject(String oldName, List<List<String>> oldPathElems,\n     if (!oldPathElements.equals(newPathElements)) {\n       Entry oldEntry = root.find(oldPathElements.toArray(new String[0]), false);\n       Entry newParent = root.createParent(newPathElements);\n-      oldEntry.moveTo(newParent, newPathElements.get(newPathElements.size() - 1));\n+\n+      if (oldEntry == null) {\n+        LOG.warn(String.format(\"%s Moving old paths for renameAuthzObject({%s, %s} -> {%s, %s}) is skipped. Cannot find entry for old name\",\n+            this, oldName, assemblePaths(oldPathElems), newName, assemblePaths(newPathElems)));\n+      } else {\n+        oldEntry.moveTo(newParent, newPathElements.get(newPathElements.size() - 1));\n+      }\n     }\n \n     // Re-write authObj from oldName to newName.",
                "additions": 7,
                "raw_url": "https://github.com/apache/sentry/raw/13010b0b600c4f2e7a7ea7f0ec8dcae87632950a/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/HMSPaths.java",
                "status": "modified",
                "changes": 8,
                "deletions": 1,
                "sha": "97a04d9eb5a1e0c5feb97b038b8fc0edec9b0d38",
                "blob_url": "https://github.com/apache/sentry/blob/13010b0b600c4f2e7a7ea7f0ec8dcae87632950a/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/HMSPaths.java",
                "filename": "sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/HMSPaths.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/HMSPaths.java?ref=13010b0b600c4f2e7a7ea7f0ec8dcae87632950a"
            },
            {
                "patch": "@@ -395,6 +395,34 @@ public void testRenameDiffPaths() {\n         paths.findAuthzObject(HMSPaths.getPathElements(partition2Path)));\n   }\n \n+  @Test\n+  public void testRenameExternalTableDiffPaths() {\n+    String[] prefixes = {\"/user/hive/warehouse\"};\n+    HMSPaths paths = new HMSPaths(prefixes);\n+    //Create old table and partition locations\n+    String table1Path = \"/user/external/warehouse/db1.db/table1\";\n+    String partition1Path = \"/user/external/warehouse/db1.db/table1/part1\";\n+    paths.addAuthzObject(\"db1.table1\",\n+        HMSPaths.getPathsElements(Arrays.asList(table1Path, partition1Path)));\n+\n+    //Create new table location\n+    String table2Path = \"/user/external/warehouse/db2.db/table2\";\n+    paths.renameAuthzObject(\"db1.table1\", HMSPaths.getPathsElements(Arrays.asList(table1Path)),\n+        \"db2.table2\", HMSPaths.getPathsElements(Arrays.asList(table2Path)));\n+\n+    //Assert that old path is not associated with a table\n+    Assert.assertEquals(null, paths.findAuthzObject(HMSPaths.getPathElements(table1Path)));\n+    Assert.assertEquals(null, paths.findAuthzObject(HMSPaths.getPathElements(partition1Path)));\n+\n+    //Assert that new path is not associated with new table because no entry is created for external path\n+    Assert.assertEquals(null, paths.findAuthzObject(HMSPaths.getPathElements(table2Path)));\n+\n+    //Assert that old path is not moved under new table\n+    String partition2Path = \"/user/external/warehouse/db2.db/table2/part1\";\n+    Assert.assertEquals(null,\n+        paths.findAuthzObject(HMSPaths.getPathElements(partition2Path)));\n+  }\n+\n   @Test\n   public void testRenameSamePaths() {\n     String[] prefixes = {\"/user/hive/warehouse\"};",
                "additions": 28,
                "raw_url": "https://github.com/apache/sentry/raw/13010b0b600c4f2e7a7ea7f0ec8dcae87632950a/sentry-hdfs/sentry-hdfs-common/src/test/java/org/apache/sentry/hdfs/TestHMSPaths.java",
                "status": "modified",
                "changes": 28,
                "deletions": 0,
                "sha": "fe2aa90663e210dd2a93bdb984ede74c26e484b0",
                "blob_url": "https://github.com/apache/sentry/blob/13010b0b600c4f2e7a7ea7f0ec8dcae87632950a/sentry-hdfs/sentry-hdfs-common/src/test/java/org/apache/sentry/hdfs/TestHMSPaths.java",
                "filename": "sentry-hdfs/sentry-hdfs-common/src/test/java/org/apache/sentry/hdfs/TestHMSPaths.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-common/src/test/java/org/apache/sentry/hdfs/TestHMSPaths.java?ref=13010b0b600c4f2e7a7ea7f0ec8dcae87632950a"
            }
        ],
        "bug_id": "sentry_1",
        "parent": "https://github.com/apache/sentry/commit/4d9665f60c240eba17356c6c91646c1c357a62d5",
        "message": "SENTRY-2299: NPE In Sentry HDFS Sync Plugin (Na Li, reviewed by Sergio Pena, Kalyan Kumar Kalvagadda, Arjun Mishra)",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/f0e1dfbd0c6eb21219993c84eff49d4ad3da0e5e",
        "file": [
            {
                "patch": "@@ -78,7 +78,8 @@ public static void main(String[] args)\n         log4jProperties.setProperty(\"log4j.category.DataNucleus.Query\", \"INFO\");\n \n         // Enable debug log for DataNucleus.Query only when log.threshold is TRACE\n-        if (log4jProperties.getProperty(\"log.threshold\").equalsIgnoreCase(\"TRACE\")) {\n+        String logThreshold = log4jProperties.getProperty(\"log.threshold\");\n+        if (logThreshold != null && logThreshold.equalsIgnoreCase(\"TRACE\")) {\n           log4jProperties.setProperty(\"log4j.category.DataNucleus.Query\", \"DEBUG\");\n         }\n       }",
                "additions": 2,
                "raw_url": "https://github.com/apache/sentry/raw/f0e1dfbd0c6eb21219993c84eff49d4ad3da0e5e/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "c1518ba3607ed7dd299ca75fd7869c40f805ccf3",
                "blob_url": "https://github.com/apache/sentry/blob/f0e1dfbd0c6eb21219993c84eff49d4ad3da0e5e/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "filename": "sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java?ref=f0e1dfbd0c6eb21219993c84eff49d4ad3da0e5e"
            }
        ],
        "bug_id": "sentry_2",
        "parent": "https://github.com/apache/sentry/commit/2fbaacc8e11dbd5a63922ec8051854b39857b85b",
        "message": "SENTRY-1504 - NPE in log4j.properties parsing",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/7138db63c7341f60b11e683022cd8a4ffc42a962",
        "file": [
            {
                "patch": "@@ -78,7 +78,8 @@ public static void main(String[] args)\n         log4jProperties.setProperty(\"log4j.category.DataNucleus.Query\", \"INFO\");\n \n         // Enable debug log for DataNucleus.Query only when log.threshold is TRACE\n-        if (log4jProperties.getProperty(\"log.threshold\").equalsIgnoreCase(\"TRACE\")) {\n+        String logThreshold = log4jProperties.getProperty(\"log.threshold\");\n+        if (logThreshold != null && logThreshold.equalsIgnoreCase(\"TRACE\")) {\n           log4jProperties.setProperty(\"log4j.category.DataNucleus.Query\", \"DEBUG\");\n         }\n       }",
                "additions": 2,
                "raw_url": "https://github.com/apache/sentry/raw/7138db63c7341f60b11e683022cd8a4ffc42a962/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "c1518ba3607ed7dd299ca75fd7869c40f805ccf3",
                "blob_url": "https://github.com/apache/sentry/blob/7138db63c7341f60b11e683022cd8a4ffc42a962/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "filename": "sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-core/sentry-core-common/src/main/java/org/apache/sentry/SentryMain.java?ref=7138db63c7341f60b11e683022cd8a4ffc42a962"
            }
        ],
        "bug_id": "sentry_3",
        "parent": "https://github.com/apache/sentry/commit/1e6ea0ea2b8a1294d28990c35be95bcbe064f463",
        "message": "SENTRY-1504 - NPE in log4j.properties parsing",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/924f0b038f351c26b1df72e21ad7e5dedbdb525e",
        "file": [
            {
                "patch": "@@ -63,7 +63,7 @@\n     AUTHZ_UDF_WHITELIST(\"sentry.hive.udf.whitelist\", HIVE_UDF_WHITE_LIST),\n     AUTHZ_ALLOW_HIVE_IMPERSONATION(\"sentry.hive.allow.hive.impersonation\", \"false\"),\n     AUTHZ_ONFAILURE_HOOKS(\"sentry.hive.failure.hooks\", \"\"),\n-    AUTHZ_METASTORE_SERVICE_USERS(\"sentry.metastore.service.users\", \"\"),\n+    AUTHZ_METASTORE_SERVICE_USERS(\"sentry.metastore.service.users\", null),\n     AUTHZ_SYNC_ALTER_WITH_POLICY_STORE(\"sentry.hive.sync.alter\", \"true\"),\n     AUTHZ_SYNC_CREATE_WITH_POLICY_STORE(\"sentry.hive.sync.create\", \"false\"),\n     AUTHZ_SYNC_DROP_WITH_POLICY_STORE(\"sentry.hive.sync.drop\", \"true\"),",
                "additions": 1,
                "raw_url": "https://github.com/apache/sentry/raw/924f0b038f351c26b1df72e21ad7e5dedbdb525e/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "3a83895bc000c416686abf6e99c8652bb4d56a5f",
                "blob_url": "https://github.com/apache/sentry/blob/924f0b038f351c26b1df72e21ad7e5dedbdb525e/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "filename": "sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java?ref=924f0b038f351c26b1df72e21ad7e5dedbdb525e"
            }
        ],
        "bug_id": "sentry_4",
        "parent": "https://github.com/apache/sentry/commit/6465503be6a4268f7ff4a2d787ecf4a4ad174988",
        "message": "SENTRY-337: When the parameter sentry.metastore.service.users isn't set or set empty, starting metastore will throw java.lang.NullPointerException (Guoquan Shen via Sravya Tirukkovalur)",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/a8c405a9ab6910fd6341588db76ccb78c5bcb535",
        "file": [
            {
                "patch": "@@ -53,6 +53,10 @@\n \n   private static final Logger LOGGER = LoggerFactory.getLogger(MetastorePlugin.class);\n \n+  private static final String initializationFailureMsg = \"Cache failed to initialize, cannot send path updates to Sentry.\" +\n+          \" Please review HMS error logs during startup for additional information. If the initialization failure is due\" +\n+          \" to SentryMalformedPathException, you will need to rectify the malformed path in HMS db and restart HMS\";\n+\n   class SyncTask implements Runnable {\n     @Override\n     public void run() {\n@@ -61,8 +65,7 @@ public void run() {\n         return;\n       }\n       if (MetastorePlugin.this.authzPaths == null) {\n-        LOGGER.info(\"#### Metastore Plugin cache has not finished\" +\n-                \"initialization.\");\n+        LOGGER.warn(initializationFailureMsg);\n         return;\n       }\n       try {\n@@ -316,13 +319,21 @@ protected void notifySentry(PathsUpdate update) {\n   protected void applyLocal(PathsUpdate update) {\n     final Timer.Context timerContext =\n         SentryHdfsMetricsUtil.getApplyLocalUpdateTimer.time();\n+    if(authzPaths == null) {\n+      LOGGER.error(initializationFailureMsg);\n+      return;\n+    }\n     authzPaths.updatePartial(Lists.newArrayList(update), new ReentrantReadWriteLock());\n     timerContext.stop();\n     SentryHdfsMetricsUtil.getApplyLocalUpdateHistogram.update(\n         update.getPathChanges().size());\n   }\n \n   private void notifySentryAndApplyLocal(PathsUpdate update) {\n+    if(authzPaths == null) {\n+      LOGGER.error(initializationFailureMsg);\n+      return;\n+    }\n     if (initComplete) {\n       processUpdate(update);\n     } else {",
                "additions": 13,
                "raw_url": "https://github.com/apache/sentry/raw/a8c405a9ab6910fd6341588db76ccb78c5bcb535/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "status": "modified",
                "changes": 15,
                "deletions": 2,
                "sha": "2df9f45b2ebb39d4e6bdec747141dee4c18c9e40",
                "blob_url": "https://github.com/apache/sentry/blob/a8c405a9ab6910fd6341588db76ccb78c5bcb535/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "filename": "sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java?ref=a8c405a9ab6910fd6341588db76ccb78c5bcb535"
            }
        ],
        "bug_id": "sentry_5",
        "parent": "https://github.com/apache/sentry/commit/caf924b5fe7862932443d445bdf46de1bedd2a61",
        "message": "SENTRY-1270: Improve error handling - Database with malformed URI causes NPE in HMS plugin during DDL (Sravya Tirukkovalur, Reviewed by: Lenni Kuff)\n\nChange-Id: I11da6179300ff50e892b7d7c0d290d4213be55a9",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/b8be26f84277644ddfd5d0e8512404857dc89ab1",
        "file": [
            {
                "patch": "@@ -53,6 +53,10 @@\n \n   private static final Logger LOGGER = LoggerFactory.getLogger(MetastorePlugin.class);\n \n+  private static final String initializationFailureMsg = \"Cache failed to initialize, cannot send path updates to Sentry.\" +\n+          \" Please review HMS error logs during startup for additional information. If the initialization failure is due\" +\n+          \" to SentryMalformedPathException, you will need to rectify the malformed path in HMS db and restart HMS\";\n+\n   class SyncTask implements Runnable {\n     @Override\n     public void run() {\n@@ -61,8 +65,7 @@ public void run() {\n         return;\n       }\n       if (MetastorePlugin.this.authzPaths == null) {\n-        LOGGER.info(\"#### Metastore Plugin cache has not finished\" +\n-                \"initialization.\");\n+        LOGGER.warn(initializationFailureMsg);\n         return;\n       }\n       try {\n@@ -316,13 +319,21 @@ protected void notifySentry(PathsUpdate update) {\n   protected void applyLocal(PathsUpdate update) {\n     final Timer.Context timerContext =\n         SentryHdfsMetricsUtil.getApplyLocalUpdateTimer.time();\n+    if(authzPaths == null) {\n+      LOGGER.error(initializationFailureMsg);\n+      return;\n+    }\n     authzPaths.updatePartial(Lists.newArrayList(update), new ReentrantReadWriteLock());\n     timerContext.stop();\n     SentryHdfsMetricsUtil.getApplyLocalUpdateHistogram.update(\n         update.getPathChanges().size());\n   }\n \n   private void notifySentryAndApplyLocal(PathsUpdate update) {\n+    if(authzPaths == null) {\n+      LOGGER.error(initializationFailureMsg);\n+      return;\n+    }\n     if (initComplete) {\n       processUpdate(update);\n     } else {",
                "additions": 13,
                "raw_url": "https://github.com/apache/sentry/raw/b8be26f84277644ddfd5d0e8512404857dc89ab1/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "status": "modified",
                "changes": 15,
                "deletions": 2,
                "sha": "2df9f45b2ebb39d4e6bdec747141dee4c18c9e40",
                "blob_url": "https://github.com/apache/sentry/blob/b8be26f84277644ddfd5d0e8512404857dc89ab1/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "filename": "sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-service/src/main/java/org/apache/sentry/hdfs/MetastorePlugin.java?ref=b8be26f84277644ddfd5d0e8512404857dc89ab1"
            }
        ],
        "bug_id": "sentry_6",
        "parent": "https://github.com/apache/sentry/commit/44dc1598e5e6a98137a84b51005cafac36ad3272",
        "message": "SENTRY-1270: Improve error handling - Database with malformed URI causes NPE in HMS plugin during DDL (Sravya Tirukkovalur, Reviewed by: Lenni Kuff)\n\nChange-Id: I11da6179300ff50e892b7d7c0d290d4213be55a9",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/71b889ad90a31ce992f587799f6f190a4a89bb3a",
        "file": [
            {
                "patch": "@@ -17,6 +17,7 @@\n  */\n package org.apache.sentry.hdfs;\n \n+import java.util.Collection;\n import java.util.HashMap;\n import java.util.LinkedList;\n import java.util.List;\n@@ -127,15 +128,21 @@ private void applyPrivilegeUpdates(PermissionsUpdate update) {\n         String newAuthzObj = pUpdate.getAddPrivileges().keySet().iterator().next();\n         String oldAuthzObj = pUpdate.getDelPrivileges().keySet().iterator().next();\n         PrivilegeInfo privilegeInfo = perms.getPrivilegeInfo(oldAuthzObj);\n-        Map<String, FsAction> allPermissions = privilegeInfo.getAllPermissions();\n-        perms.delPrivilegeInfo(oldAuthzObj);\n-        perms.removeParentChildMappings(oldAuthzObj);\n-        PrivilegeInfo newPrivilegeInfo = new PrivilegeInfo(newAuthzObj);\n-        for (Map.Entry<String, FsAction> e : allPermissions.entrySet()) {\n-          newPrivilegeInfo.setPermission(e.getKey(), e.getValue());\n+        // The privilegeInfo object can be null if no explicit Privileges\n+        // have been granted on the object. For eg. If grants have been applied on\n+        // Db, but no explicit grants on Table.. then the authzObject associated\n+        // with the table will never exist.\n+        if (privilegeInfo != null) {\n+          Map<String, FsAction> allPermissions = privilegeInfo.getAllPermissions();\n+          perms.delPrivilegeInfo(oldAuthzObj);\n+          perms.removeParentChildMappings(oldAuthzObj);\n+          PrivilegeInfo newPrivilegeInfo = new PrivilegeInfo(newAuthzObj);\n+          for (Map.Entry<String, FsAction> e : allPermissions.entrySet()) {\n+            newPrivilegeInfo.setPermission(e.getKey(), e.getValue());\n+          }\n+          perms.addPrivilegeInfo(newPrivilegeInfo);\n+          perms.addParentChildMappings(newAuthzObj);\n         }\n-        perms.addPrivilegeInfo(newPrivilegeInfo);\n-        perms.addParentChildMappings(newAuthzObj);\n         return;\n       }\n       if (pUpdate.getAuthzObj().equals(PermissionsUpdate.ALL_AUTHZ_OBJ)) {",
                "additions": 15,
                "raw_url": "https://github.com/apache/sentry/raw/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "status": "modified",
                "changes": 23,
                "deletions": 8,
                "sha": "c362115ce6757f6bf8b7c2372bf76579783252b6",
                "blob_url": "https://github.com/apache/sentry/blob/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "filename": "sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java?ref=71b889ad90a31ce992f587799f6f190a4a89bb3a"
            },
            {
                "patch": "@@ -655,6 +655,16 @@ public Void run() throws Exception {\n     verifyOnPath(\"/user/hive/warehouse\", FsAction.ALL, \"hbase\", true);\n     verifyOnAllSubDirs(\"/user/hive/warehouse/db1.db\", null, \"hbase\", false);\n \n+    // Verify table rename works\n+    stmt.execute(\"create table q1 (s string)\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q1\", FsAction.ALL, \"hbase\", true);\n+    stmt.execute(\"alter table q1 rename to q2\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q2\", FsAction.ALL, \"hbase\", true);\n+\n+    stmt.execute(\"create table q3 (s string)\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q3\", FsAction.ALL, \"hbase\", true);\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q2\", FsAction.ALL, \"hbase\", true);\n+\n     // Verify db privileges are propagated to tables\n     stmt.execute(\"grant select on database db1 to role p1_admin\");\n     verifyOnAllSubDirs(\"/user/hive/warehouse/db1.db/tbl1\", FsAction.READ_EXECUTE, \"hbase\", true);",
                "additions": 10,
                "raw_url": "https://github.com/apache/sentry/raw/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "status": "modified",
                "changes": 10,
                "deletions": 0,
                "sha": "ae7a9a210eeff33b10ab6abd6fd8732c6d5275ba",
                "blob_url": "https://github.com/apache/sentry/blob/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java?ref=71b889ad90a31ce992f587799f6f190a4a89bb3a"
            }
        ],
        "bug_id": "sentry_7",
        "parent": "https://github.com/apache/sentry/commit/2ad16d05577ccef77b509da75c77bf040ba9b234",
        "message": "SENTRY-573: Fix NPE caused when rename op is applied on authzObject with no explicit permissions",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465",
        "file": [
            {
                "patch": "@@ -100,30 +100,34 @@ UpdateableAuthzPermissions getAuthzPermissions() {\n     return authzPermissions;\n   }\n \n-  private void update() {\n+  private boolean update() {\n     SentryAuthzUpdate updates = updater.getUpdates();\n-    UpdateableAuthzPaths newAuthzPaths = processUpdates(\n-        updates.getPathUpdates(), authzPaths);\n-    UpdateableAuthzPermissions newAuthzPerms = processUpdates(\n-        updates.getPermUpdates(), authzPermissions);\n-    // If there were any FULL updates the returned instance would be\n-    // different\n-    if ((newAuthzPaths != authzPaths)||(newAuthzPerms != authzPermissions)) {\n-      lock.writeLock().lock();\n-      try {\n-        authzPaths = newAuthzPaths;\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"FULL Updated paths seq Num [\" + authzPaths.getLastUpdatedSeqNum() + \"]\");\n-        }\n-        authzPermissions = newAuthzPerms;\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"FULL Updated perms seq Num [\" + authzPermissions.getLastUpdatedSeqNum() + \"]\");\n+    // Updates can be null if Sentry Service is un-reachable\n+    if (updates != null) {\n+      UpdateableAuthzPaths newAuthzPaths = processUpdates(\n+          updates.getPathUpdates(), authzPaths);\n+      UpdateableAuthzPermissions newAuthzPerms = processUpdates(\n+          updates.getPermUpdates(), authzPermissions);\n+      // If there were any FULL updates the returned instance would be\n+      // different\n+      if ((newAuthzPaths != authzPaths)||(newAuthzPerms != authzPermissions)) {\n+        lock.writeLock().lock();\n+        try {\n+          authzPaths = newAuthzPaths;\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"FULL Updated paths seq Num [\" + authzPaths.getLastUpdatedSeqNum() + \"]\");\n+          }\n+          authzPermissions = newAuthzPerms;\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"FULL Updated perms seq Num [\" + authzPermissions.getLastUpdatedSeqNum() + \"]\");\n+          }\n+        } finally {\n+          lock.writeLock().unlock();\n         }\n-      } finally {\n-        lock.writeLock().unlock();\n       }\n+      return true;\n     }\n-\n+    return false;\n   }\n \n   private <K extends Update, V extends Updateable<K>> V processUpdates(List<K> updates,\n@@ -143,6 +147,7 @@ private void update() {\n   }\n \n   public void run() {\n+    boolean success = false;\n     try {\n       // In case of previous preUpdate failure, we sleep for a retry wait \n       // interval we can do this because we are using a singledthreadedexecutor\n@@ -151,24 +156,32 @@ public void run() {\n       if (waitUntil > currTime) {\n         Thread.sleep(waitUntil - currTime);\n       }\n-      update();\n-      // we reset lastUpdate only on successful pulling\n-      lastUpdate = System.currentTimeMillis();\n-      waitUntil = lastUpdate;\n+      success = update();\n     } catch (Exception ex) {\n+      success = false;\n       LOG.warn(\"Failed to update, will retry in [{}]ms, error: \", \n           new Object[]{ retryWaitMillisec, ex.getMessage(), ex});\n+    }\n+    if (success) {\n+      // we reset lastUpdate only on successful pulling\n+      lastUpdate = System.currentTimeMillis();\n+      waitUntil = lastUpdate;\n+    } else {\n       waitUntil = System.currentTimeMillis() + retryWaitMillisec;\n     }\n   }\n \n   public void start() {\n     if (authzPaths != null) {\n+      boolean success = false;\n       try {\n-        update();\n+        success = update();\n       } catch (Exception ex) {\n+        success = false;\n         LOG.warn(\"Failed to do initial update, will retry in [{}]ms, error: \",\n             new Object[]{retryWaitMillisec, ex.getMessage(), ex});\n+      }\n+      if (!success) {\n         waitUntil = System.currentTimeMillis() + retryWaitMillisec;\n       }\n       executor = Executors.newSingleThreadScheduledExecutor(",
                "additions": 38,
                "raw_url": "https://github.com/apache/sentry/raw/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "status": "modified",
                "changes": 63,
                "deletions": 25,
                "sha": "c0889f2851b159afe8482ed3ee5485cdf4ab9e3e",
                "blob_url": "https://github.com/apache/sentry/blob/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "filename": "sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java?ref=c5cc86a802ba5e17e78df9ee7671ca42bb1fe465"
            }
        ],
        "bug_id": "sentry_8",
        "parent": "https://github.com/apache/sentry/commit/3d3f96ca7939e687944f1426419db673f8797f3e",
        "message": "SENTRY-556: Remove NPE logging when Sentry Service is not reachable (Reviewed by: Lenni Kuff)",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/1e5826f85601319a2ef9c4bdab999ff1db697668",
        "file": [
            {
                "patch": "@@ -151,7 +151,6 @@ public ASTNode preAnalyze(HiveSemanticAnalyzerHookContext context, ASTNode ast)\n         break;\n       case HiveParser.TOK_DROPTABLE:\n       case HiveParser.TOK_DROPVIEW:\n-      case HiveParser.TOK_SHOW_TABLESTATUS:\n       case HiveParser.TOK_SHOW_CREATETABLE:\n       case HiveParser.TOK_ALTERTABLE_SERIALIZER:\n       case HiveParser.TOK_ALTERVIEW_ADDPARTS:\n@@ -166,6 +165,20 @@ public ASTNode preAnalyze(HiveSemanticAnalyzerHookContext context, ASTNode ast)\n       case HiveParser.TOK_ALTERINDEX_REBUILD:\n         currTab = extractTable((ASTNode)ast.getChild(0)); //type is not TOK_TABNAME\n         currDB = extractDatabase((ASTNode) ast.getChild(0));\n+      case HiveParser.TOK_SHOW_TABLESTATUS:\n+        currDB = extractDatabase((ASTNode)ast.getChild(0));\n+        int children = ast.getChildCount();\n+        for (int i = 1; i < children; i++) {\n+          ASTNode child = (ASTNode) ast.getChild(i);\n+          if (child.getToken().getType() == HiveParser.Identifier) {\n+            currDB = new Database(child.getText());\n+            break;\n+          }\n+        }\n+        //loosing the requested privileges for possible wildcard tables, since\n+        //further authorization will be done at the filter step and those unwanted will\n+        //eventually be filtered out from the output\n+        currTab = Table.ALL;\n         break;\n       case HiveParser.TOK_ALTERTABLE_RENAME:\n       case HiveParser.TOK_ALTERTABLE_PROPERTIES:",
                "additions": 14,
                "raw_url": "https://github.com/apache/sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "status": "modified",
                "changes": 15,
                "deletions": 1,
                "sha": "0546e6a68eb67aabfc8e3974a67deb4a5a64bf94",
                "blob_url": "https://github.com/apache/sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "filename": "sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668"
            },
            {
                "patch": "@@ -326,6 +326,7 @@ public void testSelectAndInsertOnTable() throws Exception {\n   6. Describe tb1 : HiveOperation.DESCTABLE5.\n   7. HiveOperation.SHOWPARTITIONS\n   8. TODO: show functions?\n+  9. HiveOperation.SHOW_TABLESTATUS\n    */\n   @Test\n   public void testSelectOnTable() throws Exception {\n@@ -347,6 +348,7 @@ public void testSelectOnTable() throws Exception {\n     statement.executeQuery(\"SHOW indexes on tb1\");\n     statement.executeQuery(\"SHOW COLUMNS from tb1\");\n     statement.executeQuery(\"SHOW functions '.*'\");\n+    statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n \n     statement.executeQuery(\"DESCRIBE tb1\");\n     statement.executeQuery(\"DESCRIBE tb1 PARTITION (b=1)\");\n@@ -355,6 +357,7 @@ public void testSelectOnTable() throws Exception {\n     connection.close();\n \n     //Negative case\n+    adminCreate(DB2, tableName);\n     policyFile\n         .addPermissionsToRole(\"insert_db1_tb1\", privileges.get(\"insert_db1_tb1\"))\n         .addRolesToGroup(USERGROUP3, \"insert_db1_tb1\");\n@@ -363,6 +366,8 @@ public void testSelectOnTable() throws Exception {\n     statement = context.createStatement(connection);\n     statement.execute(\"Use \" + DB1);\n     context.assertSentrySemanticException(statement, \"select * from tb1\", semanticException);\n+    context.assertSentrySemanticException(statement,\n+        \"SHOW TABLE EXTENDED IN \" + DB2 + \" LIKE 'tb*'\", semanticException);\n \n     statement.close();\n     connection.close();\n@@ -379,6 +384,7 @@ public void testSelectOnTable() throws Exception {\n   6. HiveOperation.SHOWPARTITIONS\n   7. TODO: show functions?\n   8. TODO: lock, unlock, Show locks\n+  9. HiveOperation.SHOW_TABLESTATUS\n    */\n   @Test\n   public void testInsertOnTable() throws Exception {\n@@ -401,6 +407,7 @@ public void testInsertOnTable() throws Exception {\n     statement.executeQuery(\"SHOW COLUMNS from tb1\");\n     statement.executeQuery(\"SHOW functions '.*'\");\n     //statement.executeQuery(\"SHOW LOCKS tb1\");\n+    statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n \n     //NoViableAltException\n     //statement.executeQuery(\"SHOW transactions\");",
                "additions": 7,
                "raw_url": "https://github.com/apache/sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "status": "modified",
                "changes": 7,
                "deletions": 0,
                "sha": "89d7b2ac84fbd152ef22c5ce0a46af8c2a752ab8",
                "blob_url": "https://github.com/apache/sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668"
            },
            {
                "patch": "@@ -250,6 +250,52 @@ public void testShowTables5() throws Exception {\n     statement.close();\n   }\n \n+  /**\n+   * Steps: 1. admin create db_1 and tb_1, tb_2, tb_3, tb_4 and table_5\n+   *        2. admin should see all tables except table_5 which does not match tb*\n+   *        3. user1 should only see the matched tables it has any level of privilege\n+   */\n+  @Test\n+  public void testShowTablesExtended() throws Exception {\n+    // tables visible to user1 (not access to tb_4\n+    String tableNames[] = {\"tb_1\", \"tb_2\", \"tb_3\", \"tb_4\", \"table_5\"};\n+    List<String> tableNamesValidation = new ArrayList<String>();\n+\n+    policyFile\n+        .addRolesToGroup(USERGROUP1, \"tab1_priv,tab2_priv,tab3_priv\")\n+        .addPermissionsToRole(\"tab1_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[0] + \"->action=select\")\n+        .addPermissionsToRole(\"tab2_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[1] + \"->action=insert\")\n+        .addPermissionsToRole(\"tab3_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[2] + \"->action=select\")\n+        .setUserGroupMapping(StaticUserGroup.getStaticMapping());\n+    writePolicyFile(policyFile);\n+\n+    String user1TableNames[] = {\"tb_1\", \"tb_2\", \"tb_3\"};\n+\n+    Connection connection = context.createConnection(ADMIN1);\n+    Statement statement = context.createStatement(connection);\n+    statement.execute(\"DROP DATABASE IF EXISTS \" + DB1 + \" CASCADE\");\n+    statement.execute(\"CREATE DATABASE \" + DB1);\n+    statement.execute(\"USE \" + DB1);\n+    createTabs(statement, DB1, tableNames);\n+    // Admin should see all tables except table_5, the one does not match the pattern\n+    ResultSet rs = statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n+    tableNamesValidation.addAll(Arrays.asList(tableNames).subList(0, 4));\n+    validateTablesInRs(rs, DB1, tableNamesValidation);\n+    statement.close();\n+\n+    connection = context.createConnection(USER1_1);\n+    statement = context.createStatement(connection);\n+    statement.execute(\"USE \" + DB1);\n+    // User1 should see tables with any level of access\n+    rs = statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n+    tableNamesValidation.addAll(Arrays.asList(user1TableNames));\n+    validateTablesInRs(rs, DB1, tableNamesValidation);\n+    statement.close();\n+  }\n+\n   /**\n    * Steps: 1. admin create few dbs\n    *        2. admin can do show databases\n@@ -359,4 +405,20 @@ private void validateTables(ResultSet rs, String dbName,\n     Assert.assertTrue(tableNames.toString(), tableNames.isEmpty());\n     rs.close();\n   }\n+\n+  // compare the tables in resultset with given array of table names\n+  // for some hive query like 'show table extended ...', the resultset does\n+  // not only contains tableName (See HIVE-8109)\n+  private void validateTablesInRs(ResultSet rs, String dbName,\n+      List<String> tableNames) throws SQLException {\n+    while (rs.next()) {\n+      String tableName = rs.getString(1);\n+      if (tableName.startsWith(\"tableName:\")) {\n+        Assert.assertTrue(\"Expected table \" + tableName.substring(10),\n+            tableNames.remove(tableName.substring(10).toLowerCase()));\n+      }\n+    }\n+    Assert.assertTrue(tableNames.toString(), tableNames.isEmpty());\n+    rs.close();\n+  }\n }",
                "additions": 62,
                "raw_url": "https://github.com/apache/sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "status": "modified",
                "changes": 62,
                "deletions": 0,
                "sha": "e103465ca8e7e71209383e4da696da4da6f2f59f",
                "blob_url": "https://github.com/apache/sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668"
            }
        ],
        "bug_id": "sentry_9",
        "parent": "https://github.com/apache/sentry/commit/fa5f81c7734f8af8e1bdc669d6cbe2e5951e2bac",
        "message": "SENTRY-423: Hive command \"SHOW TABLE EXTENDED LIKE... \" failed with NPE (Chaoyu Tang via Prasad Mujumdar)",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/370fab099b93d4265f25af01d1d864b7a829d86d",
        "file": [
            {
                "patch": "@@ -689,11 +689,12 @@ public TListSentryPrivilegesByAuthResponse list_sentry_privileges_by_authorizabl\n           requestedGroups = memberGroups;\n         }\n \n-        // Disallow non-admin to lookup roles that they are not part of\n+        Set<String> grantedRoles = toTrimmedLower(store.getRolesByGroups(request.getComponent(), requestedGroups));\n+\n+        // If activeRoleSet is not null, disallow non-admin to lookup roles that they are not part of.\n         if (activeRoleSet != null && !activeRoleSet.isAll()) {\n-          Set<String> grantedRoles = toTrimmedLower(store.getRolesByGroups(request.getComponent(), requestedGroups));\n-          Set<String> activeRoleNames = toTrimmedLower(activeRoleSet.getRoles());\n \n+          Set<String> activeRoleNames = toTrimmedLower(activeRoleSet.getRoles());\n           for (String activeRole : activeRoleNames) {\n             if (!grantedRoles.contains(activeRole)) {\n               throw new SentryAccessDeniedException(ACCESS_DENIAL_MESSAGE\n@@ -703,18 +704,30 @@ public TListSentryPrivilegesByAuthResponse list_sentry_privileges_by_authorizabl\n \n           // For non-admin, valid active roles are intersection of active roles and granted roles.\n           validActiveRoles.addAll(activeRoleSet.isAll() ? grantedRoles : Sets.intersection(activeRoleNames, grantedRoles));\n+        } else {\n+          // For non-admin, if activeRoleSet is null, valid active roles would be the granted roles.\n+          validActiveRoles.addAll(grantedRoles);\n         }\n       } else {\n         Set<String> allRoles = toTrimmedLower(store.getAllRoleNames());\n-        Set<String> activeRoleNames = toTrimmedLower(activeRoleSet.getRoles());\n+        Set<String> activeRoleNames = Sets.newHashSet();\n+        boolean isAllRoleSet = false;\n+\n+        // If activeRoleSet (which is optional) is null, valid active role will be all roles.\n+        if (activeRoleSet != null) {\n+          activeRoleNames = toTrimmedLower(activeRoleSet.getRoles());\n+          isAllRoleSet = activeRoleSet.isAll();\n+        } else {\n+          isAllRoleSet = true;\n+        }\n \n         // For admin, if requestedGroups are empty, valid active roles are intersection of active roles and all roles.\n         // Otherwise, valid active roles are intersection of active roles and the roles of requestedGroups.\n         if (requestedGroups == null || requestedGroups.isEmpty()) {\n-          validActiveRoles.addAll(activeRoleSet.isAll() ? allRoles : Sets.intersection(activeRoleNames, allRoles));\n+          validActiveRoles.addAll(isAllRoleSet ? allRoles : Sets.intersection(activeRoleNames, allRoles));\n         } else {\n           Set<String> requestedRoles = toTrimmedLower(store.getRolesByGroups(request.getComponent(), requestedGroups));\n-          validActiveRoles.addAll(activeRoleSet.isAll() ? allRoles : Sets.intersection(activeRoleNames, requestedRoles));\n+          validActiveRoles.addAll(isAllRoleSet ? allRoles : Sets.intersection(activeRoleNames, requestedRoles));\n         }\n       }\n ",
                "additions": 19,
                "raw_url": "https://github.com/apache/sentry/raw/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/main/java/org/apache/sentry/provider/db/generic/service/thrift/SentryGenericPolicyProcessor.java",
                "status": "modified",
                "changes": 25,
                "deletions": 6,
                "sha": "2a287e9b95e36b7d365de603d94208bad59966bc",
                "blob_url": "https://github.com/apache/sentry/blob/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/main/java/org/apache/sentry/provider/db/generic/service/thrift/SentryGenericPolicyProcessor.java",
                "filename": "sentry-provider/sentry-provider-db/src/main/java/org/apache/sentry/provider/db/generic/service/thrift/SentryGenericPolicyProcessor.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-provider/sentry-provider-db/src/main/java/org/apache/sentry/provider/db/generic/service/thrift/SentryGenericPolicyProcessor.java?ref=370fab099b93d4265f25af01d1d864b7a829d86d"
            },
            {
                "patch": "@@ -966,6 +966,8 @@ public void testGetPrivilegesByAuthorizable() throws Exception {\n \n     assertEquals(0, sentryStore.getPrivilegesByAuthorizable(SEARCH, service1, null,\n         Arrays.asList(new Collection(COLLECTION_NAME), new Field(FIELD_NAME))).size());\n+    assertEquals(1, sentryStore.getPrivilegesByAuthorizable(SEARCH, service1, Sets.newHashSet(roleName1),\n+    Arrays.asList(new Collection(COLLECTION_NAME), new Field(FIELD_NAME))).size());\n     assertEquals(2, sentryStore.getPrivilegesByAuthorizable(SEARCH, service1,\n         Sets.newHashSet(roleName1), null).size());\n     assertEquals(2, sentryStore.getPrivilegesByAuthorizable(SEARCH, service1,",
                "additions": 2,
                "raw_url": "https://github.com/apache/sentry/raw/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/persistent/TestPrivilegeOperatePersistence.java",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "deefefa72f665cae6159b70056ae8c3075e1f844",
                "blob_url": "https://github.com/apache/sentry/blob/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/persistent/TestPrivilegeOperatePersistence.java",
                "filename": "sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/persistent/TestPrivilegeOperatePersistence.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/persistent/TestPrivilegeOperatePersistence.java?ref=370fab099b93d4265f25af01d1d864b7a829d86d"
            },
            {
                "patch": "@@ -300,17 +300,27 @@ public void testGetRolesAndPrivileges() throws Exception {\n     assertEquals(Status.OK, fromTSentryStatus(response3.getStatus()));\n     assertEquals(2, response3.getPrivileges().size());\n \n+    // Optional parameters activeRoleSet and requested group name are both provided.\n     TListSentryPrivilegesByAuthRequest request4 = new TListSentryPrivilegesByAuthRequest();\n     request4.setGroups(Sets.newHashSet(groupName));\n     request4.setRoleSet(new TSentryActiveRoleSet(true, null));\n     request4.setRequestorUserName(ADMIN_USER);\n-\n     Set<String> authorizablesSet = Sets.newHashSet(\"Collection=c1->Field=f1\");\n     request4.setAuthorizablesSet(authorizablesSet);\n \n     TListSentryPrivilegesByAuthResponse response4 = processor.list_sentry_privileges_by_authorizable(request4);\n     assertEquals(Status.OK, fromTSentryStatus(response4.getStatus()));\n     assertEquals(1, response4.getPrivilegesMapByAuth().size());\n+\n+    // Optional parameters activeRoleSet and requested group name are both not provided.\n+    TListSentryPrivilegesByAuthRequest request5 = new TListSentryPrivilegesByAuthRequest();\n+    request5.setRequestorUserName(\"not_\" + ADMIN_USER);\n+    authorizablesSet = Sets.newHashSet(\"Collection=c1->Field=f2\");\n+    request5.setAuthorizablesSet(authorizablesSet);\n+\n+    TListSentryPrivilegesByAuthResponse response5 = processor.list_sentry_privileges_by_authorizable(request5);\n+    assertEquals(Status.OK, fromTSentryStatus(response5.getStatus()));\n+    assertEquals(1, response5.getPrivilegesMapByAuth().size());\n   }\n \n   @Test(expected=SentryConfigurationException.class)",
                "additions": 11,
                "raw_url": "https://github.com/apache/sentry/raw/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/thrift/TestSentryGenericPolicyProcessor.java",
                "status": "modified",
                "changes": 12,
                "deletions": 1,
                "sha": "cc0b28ecd1ffffb62d0416405de0656633e31482",
                "blob_url": "https://github.com/apache/sentry/blob/370fab099b93d4265f25af01d1d864b7a829d86d/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/thrift/TestSentryGenericPolicyProcessor.java",
                "filename": "sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/thrift/TestSentryGenericPolicyProcessor.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-provider/sentry-provider-db/src/test/java/org/apache/sentry/provider/db/generic/service/thrift/TestSentryGenericPolicyProcessor.java?ref=370fab099b93d4265f25af01d1d864b7a829d86d"
            }
        ],
        "bug_id": "sentry_10",
        "parent": "https://github.com/apache/sentry/commit/66b32afa87fab816af972d68b253f46c53ec7f58",
        "message": "SENTRY-1217: NPE for list_sentry_privileges_by_authorizable when activeRoleSet is not set (Hao Hao, Reviewed by: Lenni Kuff)\n\nChange-Id: I8a59320d737209234fe6105a7ba734fd1df45566",
        "repo": "sentry"
    },
    {
        "commit": "https://github.com/apache/sentry/commit/d96f95160fd3dfa30c27b82d09fb5cc2c348b483",
        "file": [
            {
                "patch": "@@ -23,13 +23,15 @@\n import java.util.LinkedList;\n import java.util.List;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n-\n import org.apache.sentry.hdfs.service.thrift.TPathChanges;\n import org.apache.sentry.hdfs.service.thrift.TPathsUpdate;\n import org.apache.commons.httpclient.util.URIUtil;\n import org.apache.commons.httpclient.URIException;\n import org.apache.commons.lang.StringUtils;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.conf.Configuration;\n \n import com.google.common.collect.Lists;\n \n@@ -42,7 +44,7 @@\n public class PathsUpdate implements Updateable.Update {\n \n   public static String ALL_PATHS = \"__ALL_PATHS__\";\n-\n+  private static final Configuration CONF = new Configuration();\n   private final TPathsUpdate tPathsUpdate;\n \n   public PathsUpdate() {\n@@ -89,6 +91,10 @@ public TPathsUpdate toThrift() {\n     return tPathsUpdate;\n   }\n \n+  @VisibleForTesting\n+  public static Configuration getConfiguration() {\n+    return CONF;\n+  }\n \n   /**\n    *\n@@ -106,9 +112,18 @@ public TPathsUpdate toThrift() {\n         return null;\n       }\n \n-      Preconditions.checkNotNull(uri.getScheme());\n+      String scheme = uri.getScheme();\n+      if (scheme == null) {\n+        // Use the default URI scheme only if the paths has no scheme.\n+        URI defaultUri = FileSystem.getDefaultUri(CONF);\n+        scheme = defaultUri.getScheme();\n+      }\n+\n+      // The paths without a scheme will be default to default scheme.\n+      Preconditions.checkNotNull(scheme);\n \n-      if(uri.getScheme().equalsIgnoreCase(\"hdfs\")) {\n+      // Non-HDFS paths will be skipped.\n+      if(scheme.equalsIgnoreCase(\"hdfs\")) {\n         return Lists.newArrayList(uri.getPath().split(\"^/\")[1]\n             .split(\"/\"));\n       } else {",
                "additions": 19,
                "raw_url": "https://github.com/apache/sentry/raw/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "status": "modified",
                "changes": 23,
                "deletions": 4,
                "sha": "50ef112ff9ea9674d3b0bbc4279620e7a82f2d95",
                "blob_url": "https://github.com/apache/sentry/blob/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "filename": "sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java?ref=d96f95160fd3dfa30c27b82d09fb5cc2c348b483"
            },
            {
                "patch": "@@ -51,13 +51,12 @@\n import org.apache.hadoop.fs.permission.AclStatus;\n import org.apache.hadoop.fs.permission.FsAction;\n import org.apache.hadoop.fs.permission.FsPermission;\n-import org.apache.hadoop.hdfs.DFSConfigKeys;\n-import org.apache.hadoop.hdfs.DFSTestUtil;\n-import org.apache.hadoop.hdfs.HdfsConfiguration;\n-import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.apache.hadoop.hdfs.*;\n import org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream;\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n import org.apache.hadoop.io.LongWritable;\n import org.apache.hadoop.io.Text;\n import org.apache.hadoop.mapred.FileInputFormat;\n@@ -76,6 +75,7 @@\n import org.apache.hadoop.security.UserGroupInformation;\n import org.apache.sentry.binding.hive.SentryHiveAuthorizationTaskFactoryImpl;\n import org.apache.sentry.binding.hive.conf.HiveAuthzConf;\n+import org.apache.sentry.hdfs.PathsUpdate;\n import org.apache.sentry.hdfs.SentryAuthorizationProvider;\n import org.apache.sentry.provider.db.SentryAlreadyExistsException;\n import org.apache.sentry.provider.db.SimpleDBProviderBackend;\n@@ -101,6 +101,7 @@\n import com.google.common.collect.Maps;\n import com.google.common.io.Files;\n import com.google.common.io.Resources;\n+import org.apache.hadoop.hive.metastore.api.Table;\n \n public class TestHDFSIntegration {\n   \n@@ -140,13 +141,15 @@ public void reduce(Text key, Iterator<Long> values,\n \n   private static final int NUM_RETRIES = 10;\n   private static final int RETRY_WAIT = 1000;\n+  private static final String EXTERNAL_SENTRY_SERVICE = \"sentry.e2etest.external.sentry\";\n   private static final String DFS_NAMENODE_AUTHORIZATION_PROVIDER_KEY =\n       \"dfs.namenode.authorization.provider.class\";\n \n   private static MiniDFSCluster miniDFS;\n   private MiniMRClientCluster miniMR;\n   private static InternalHiveServer hiveServer2;\n   private static InternalMetastoreServer metastore;\n+  private static HiveMetaStoreClient hmsClient;\n \n   private static int sentryPort = -1;\n   protected static SentrySrv sentryServer;\n@@ -304,6 +307,7 @@ public void run() {\n           }\n         }.start();\n \n+        hmsClient = new HiveMetaStoreClient(hiveConf);\n         startHiveServer2(retries, hiveConf);\n         return null;\n       }\n@@ -1266,7 +1270,7 @@ public void testAllColumn() throws Throwable {\n     conn = hiveServer2.createConnection(StaticUserGroup.ADMIN1, StaticUserGroup.ADMIN1);\n     stmt = conn.createStatement();\n     stmt.execute(\"create database \" + dbName);\n-    stmt.execute(\"use \"+ dbName);\n+    stmt.execute(\"use \" + dbName);\n     stmt.execute(\"create table p1 (c1 string, c2 string) partitioned by (month int, day int)\");\n     stmt.execute(\"alter table p1 add partition (month=1, day=1)\");\n     loadDataTwoCols(stmt);\n@@ -1591,6 +1595,70 @@ private void verifyQuery(Statement stmt, String table, int n, int retry) throws\n     }\n   }\n \n+  /**\n+   * SENTRY-1002:\n+   * Ensure the paths with no scheme will not cause NPE during paths update.\n+   */\n+   @Test\n+   public void testMissingScheme() throws Throwable {\n+\n+     // In the local test environment, EXTERNAL_SENTRY_SERVICE is false,\n+     // set the default URI scheme to be hdfs.\n+     boolean testConfOff = new Boolean(System.getProperty(EXTERNAL_SENTRY_SERVICE, \"false\"));\n+     if (!testConfOff) {\n+       PathsUpdate.getConfiguration().set(\"fs.defaultFS\", \"hdfs:///\");\n+     }\n+\n+     tmpHDFSDir = new Path(\"/tmp/external\");\n+     if (!miniDFS.getFileSystem().exists(tmpHDFSDir)) {\n+       miniDFS.getFileSystem().mkdirs(tmpHDFSDir);\n+     }\n+\n+     Path partitionDir = new Path(\"/tmp/external/p1\");\n+     if (!miniDFS.getFileSystem().exists(partitionDir)) {\n+       miniDFS.getFileSystem().mkdirs(partitionDir);\n+     }\n+\n+     String dbName = \"db1\";\n+     String tblName = \"tab1\";\n+     dbNames = new String[]{dbName};\n+     roles = new String[]{\"admin_role\"};\n+     admin = StaticUserGroup.ADMIN1;\n+\n+     Connection conn;\n+     Statement stmt;\n+\n+     conn = hiveServer2.createConnection(\"hive\", \"hive\");\n+     stmt = conn.createStatement();\n+     stmt.execute(\"create role admin_role\");\n+     stmt.execute(\"grant all on server server1 to role admin_role\");\n+     stmt.execute(\"grant role admin_role to group \" + StaticUserGroup.ADMINGROUP);\n+     stmt.close();\n+     conn.close();\n+\n+     conn = hiveServer2.createConnection(StaticUserGroup.ADMIN1, StaticUserGroup.ADMIN1);\n+     stmt = conn.createStatement();\n+     stmt.execute(\"create database \" + dbName);\n+     stmt.execute(\"create external table \" + dbName + \".\" + tblName + \"(s string) location '/tmp/external/p1'\");\n+\n+     // Deep copy of table tab1\n+     Table tbCopy = hmsClient.getTable(dbName, tblName);\n+\n+     // Change the location of the table to strip the scheme.\n+     StorageDescriptor sd = hmsClient.getTable(dbName, tblName).getSd();\n+     sd.setLocation(\"/tmp/external\");\n+     tbCopy.setSd(sd);\n+\n+     // Alter table tab1 to be tbCopy which is at scheme-less location.\n+     // And the corresponding path will be updated to sentry server.\n+     hmsClient.alter_table(dbName, \"tab1\", tbCopy);\n+     Assert.assertEquals(hmsClient.getTable(dbName, tblName).getSd().getLocation(), \"/tmp/external\");\n+     verifyOnPath(\"/tmp/external\", FsAction.ALL, StaticUserGroup.HIVE, true);\n+\n+     stmt.close();\n+     conn.close();\n+   }\n+\n   private void loadData(Statement stmt) throws IOException, SQLException {\n     FSDataOutputStream f1 = miniDFS.getFileSystem().create(new Path(\"/tmp/f1.txt\"));\n     f1.writeChars(\"m1d1_t1\\n\");",
                "additions": 73,
                "raw_url": "https://github.com/apache/sentry/raw/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "status": "modified",
                "changes": 78,
                "deletions": 5,
                "sha": "4d9e31cd9147511d6ee4becaf74e9c2a58d1f556",
                "blob_url": "https://github.com/apache/sentry/blob/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "contents_url": "https://api.github.com/repos/apache/sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java?ref=d96f95160fd3dfa30c27b82d09fb5cc2c348b483"
            }
        ],
        "bug_id": "sentry_11",
        "parent": "https://github.com/apache/sentry/commit/8529f8e121144d715986a485abb204aa036caa19",
        "message": "SENTRY-1002: PathsUpdate.parsePath(path) will throw an NPE when parsing relative paths (Hao Hao via Lenni Kuff)\n\nChange-Id: I8882078abeed37c17734b04d09f6fb2b298861b9",
        "repo": "sentry"
    }
]