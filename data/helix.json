{
    "helix_06a9350": {
        "bug_id": "helix_06a9350",
        "commit": "https://github.com/apache/helix/commit/06a9350f2392a9dc845e54282a29eccc8267bdf5",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/helix/blob/06a9350f2392a9dc845e54282a29eccc8267bdf5/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=06a9350f2392a9dc845e54282a29eccc8267bdf5",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "patch": "@@ -151,8 +151,10 @@ public long getDisabledInstancesGauge() {\n     }\n \n     // TODO : Get rid of this after old API removed.\n-    for (String instance : _oldDisabledPartitions.keySet()) {\n-      numDisabled += _oldDisabledPartitions.get(instance).size();\n+    for (List<String> partitions : _oldDisabledPartitions.values()) {\n+      if (partitions != null) {\n+        numDisabled += partitions.size();\n+      }\n     }\n \n     return numDisabled;",
                "raw_url": "https://github.com/apache/helix/raw/06a9350f2392a9dc845e54282a29eccc8267bdf5/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "sha": "e91f503fc8ef795291262298393ffba3fda42f16",
                "status": "modified"
            }
        ],
        "message": "Fix NPE in clusterstatusmonitor.\n\nShould check _oldDisabledPartitions for preventing null values.",
        "parent": "https://github.com/apache/helix/commit/edaf78e279e87f74a08355103b2ef1b427ae0012",
        "repo": "helix",
        "unit_tests": [
            "TestClusterStatusMonitor.java"
        ]
    },
    "helix_0ad8af4": {
        "bug_id": "helix_0ad8af4",
        "commit": "https://github.com/apache/helix/commit/0ad8af404908a54f7b98ee945bf2dda8e83f002f",
        "file": [
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "patch": "@@ -19,7 +19,6 @@\n  * under the License.\n  */\n \n-import com.google.common.base.Joiner;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -39,7 +38,6 @@\n import org.apache.helix.task.JobConfig;\n import org.apache.helix.task.JobContext;\n import org.apache.helix.task.RuntimeJobDag;\n-import org.apache.helix.task.Task;\n import org.apache.helix.task.TaskConstants;\n import org.apache.helix.task.WorkflowConfig;\n import org.apache.helix.task.WorkflowContext;\n@@ -128,6 +126,23 @@ public synchronized boolean refresh(HelixDataAccessor accessor,\n       if (!_jobConfigMap.containsKey(jobName) && newJobConfigs.get(jobName).getWorkflow() != null) {\n         workflowsUpdated.add(newJobConfigs.get(jobName).getWorkflow());\n       }\n+\n+      // Only for JobQueues when a new job is enqueued, there exists a race condition where only\n+      // JobConfig is updated and the RuntimeJobDag does not get updated because when the client\n+      // (TaskDriver) submits, it creates JobConfig ZNode first and modifies its parent JobDag next.\n+      // To ensure that they are both properly updated, check that workflow's DAG and existing\n+      // JobConfigs are consistent for JobQueues\n+      JobConfig jobConfig = newJobConfigs.get(jobName);\n+      if (_workflowConfigMap.containsKey(jobConfig.getWorkflow())) {\n+        WorkflowConfig workflowConfig = _workflowConfigMap.get(jobConfig.getWorkflow());\n+        // Check that the job's parent workflow's DAG contains this job\n+        if ((workflowConfig.isJobQueue() || !workflowConfig.isTerminable()) && !_runtimeJobDagMap\n+            .get(workflowConfig.getWorkflowId()).getAllNodes().contains(jobName)) {\n+          // Inconsistency between JobConfigs and DAGs found. Add the workflow to workflowsUpdated\n+          // to rebuild the RuntimeJobDag\n+          workflowsUpdated.add(jobConfig.getWorkflow());\n+        }\n+      }\n     }\n \n     // Removed jobs",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "sha": "5c29124e20096f62ac862dde55bb47c41904af02",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 3,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "patch": "@@ -259,9 +259,8 @@ private void scheduleWorkflows(Map<String, Resource> resourceMap, WorkflowContro\n             String quotaType = getQuotaType(cache.getWorkflowConfig(workflowId));\n             restOfResources.remove(workflowId);\n             if (assignableInstanceManager.hasGlobalCapacity(quotaType)) {\n-              _workflowDispatcher\n-                  .assignWorkflow(workflowId, cache.getWorkflowConfig(workflowId), context,\n-                      currentStateOutput, bestPossibleOutput, resourceMap);\n+              _workflowDispatcher.assignWorkflow(workflowId, cache.getWorkflowConfig(workflowId),\n+                  context, currentStateOutput, bestPossibleOutput);\n             } else {\n               LogUtil.logInfo(logger, _eventId, String.format(\n                   \"Fail to schedule new jobs assignment for Workflow %s due to quota %s is full\",",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "sha": "94af50dd119950bf0e2bb0496b36b04bce215ec1",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 1,
                "filename": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "patch": "@@ -1065,7 +1065,7 @@ private String getTaskId(JobConfig jobCfg, JobContext jobCtx, int partitionNum)\n    */\n   protected boolean isWorkflowStopped(WorkflowContext ctx, WorkflowConfig cfg) {\n     if (cfg.isRecurring()) {\n-      return cfg.getTargetState() == TargetState.START;\n+      return cfg.getTargetState() == TargetState.STOP;\n     }\n \n     for (String job : cfg.getJobDag().getAllNodes()) {",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "sha": "78a74195094b4f4913c7da62ec82428f4a8e6ce9",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 3,
                "filename": "helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "patch": "@@ -40,16 +40,22 @@ public ResourceAssignment computeBestPossiblePartitionState(\n       CurrentStateOutput currStateOutput) {\n     long startTime = System.currentTimeMillis();\n     final String jobName = resource.getResourceName();\n+    JobConfig jobConfig = clusterData.getJobConfig(jobName);\n+    if (jobConfig == null) {\n+      LOG.error(\n+          \"Job {}'s JobConfig is missing. This job might have been deleted or purged. Skipping status update and assignment!\",\n+          jobName);\n+      return buildEmptyAssignment(jobName, currStateOutput);\n+    }\n     LOG.debug(\"Computer Best Partition for job: \" + jobName);\n     if (_jobDispatcher == null) {\n       _jobDispatcher = new JobDispatcher();\n     }\n     _jobDispatcher.init(_manager);\n     _jobDispatcher.updateCache(clusterData);\n     _jobDispatcher.setClusterStatusMonitor(_clusterStatusMonitor);\n-    ResourceAssignment resourceAssignment = _jobDispatcher\n-        .processJobStatusUpdateAndAssignment(jobName, currStateOutput,\n-            clusterData.getWorkflowContext(clusterData.getJobConfig(jobName).getWorkflow()));\n+    ResourceAssignment resourceAssignment = _jobDispatcher.processJobStatusUpdateAndAssignment(\n+        jobName, currStateOutput, clusterData.getWorkflowContext(jobConfig.getWorkflow()));\n     LOG.debug(String.format(\"JobRebalancer computation takes %d ms for Job %s\",\n         System.currentTimeMillis() - startTime, jobName));\n     return resourceAssignment;",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "sha": "6d8022962eb7a35f2df7494ed686dbab48e0c4a7",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 8,
                "filename": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "patch": "@@ -20,26 +20,19 @@\n  */\n \n import java.util.ArrayDeque;\n-import java.util.Collections;\n import java.util.HashMap;\n-import java.util.LinkedList;\n import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.Queue;\n import java.util.Set;\n import java.util.HashSet;\n \n-import org.apache.helix.HelixException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-\n /**\n  * RuntimeJobDag is a job DAG that provides the job iterator functionality at runtime (when jobs are\n  * actually being assigned per job category). This is to support assignment of jobs based on their\n  * categories and quotas. RuntimeJobDag uses the list scheduling algorithm using ready-list and\n  * inflight-list to return jobs available for scheduling.\n- *\n  * NOTE: RuntimeJobDag is not thread-safe.\n  */\n public class RuntimeJobDag extends JobDag {\n@@ -125,11 +118,15 @@ public String getNextJob() {\n     }\n     // If list is empty, return null\n     if (_readyJobList.isEmpty()) {\n+\n       return null;\n     }\n     String nextJob = _readyJobList.poll();\n     _inflightJobList.add(nextJob);\n     _lastJob = nextJob;\n+\n+\n+\n     return nextJob;\n   }\n \n@@ -212,5 +209,4 @@ private void resetJobListAndDependencyMaps() {\n   public Set<String> getInflightJobList() {\n     return new HashSet<>(_inflightJobList);\n   }\n-\n }",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "sha": "c223a2947feb3a2cc96047849f969f23f9b4ce28",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 6,
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "patch": "@@ -654,7 +654,7 @@ private static boolean cleanupIdealStateExtView(final HelixDataAccessor accessor\n    * @return True if remove success, otherwise false\n    */\n   protected static boolean removeWorkflow(final HelixDataAccessor accessor,\n-      final HelixPropertyStore propertyStore, String workflow, Set<String> jobs) {\n+      final HelixPropertyStore<ZNRecord> propertyStore, String workflow, Set<String> jobs) {\n     // clean up all jobs\n     for (String job : jobs) {\n       if (!removeJob(accessor, propertyStore, job)) {\n@@ -724,9 +724,9 @@ protected static boolean removeJobsFromWorkflow(final HelixDataAccessor dataAcce\n    * @return\n    */\n   protected static Set<String> getExpiredJobs(HelixDataAccessor dataAccessor,\n-      HelixPropertyStore propertyStore, WorkflowConfig workflowConfig,\n+      HelixPropertyStore<ZNRecord> propertyStore, WorkflowConfig workflowConfig,\n       WorkflowContext workflowContext) {\n-    Set<String> expiredJobs = new HashSet<String>();\n+    Set<String> expiredJobs = new HashSet<>();\n \n     if (workflowContext != null) {\n       Map<String, TaskState> jobStates = workflowContext.getJobStates();\n@@ -742,7 +742,7 @@ protected static boolean removeJobsFromWorkflow(final HelixDataAccessor dataAcce\n           continue;\n         }\n         long expiry = jobConfig.getExpiry();\n-        if (expiry == workflowConfig.DEFAULT_EXPIRY || expiry < 0) {\n+        if (expiry == WorkflowConfig.DEFAULT_EXPIRY || expiry < 0) {\n           expiry = workflowConfig.getExpiry();\n         }\n         if (jobContext != null && jobStates.get(job) == TaskState.COMPLETED) {\n@@ -822,7 +822,7 @@ public ZNRecord update(ZNRecord currentData) {\n   /**\n    * update workflow's property to remove jobs from JOB_STATES if there are already started.\n    */\n-  protected static boolean removeJobsState(final HelixPropertyStore propertyStore,\n+  protected static boolean removeJobsState(final HelixPropertyStore<ZNRecord> propertyStore,\n       final String workflow, final Set<String> jobs) {\n     String contextPath =\n         Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, workflow, TaskUtil.CONTEXT_NODE);\n@@ -983,7 +983,6 @@ public static boolean isJobStarted(String job, WorkflowContext workflowContext)\n    * @param workflowConfig\n    * @param workflowContext\n    */\n-\n   public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConfig,\n       WorkflowContext workflowContext, HelixManager manager,\n       RebalanceScheduler rebalanceScheduler) {",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "sha": "5da9fc5f080672219ca22b7faacbd7dc5e14b419",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "patch": "@@ -174,7 +174,7 @@ public void updateWorkflowStatus(String workflow, WorkflowConfig workflowCfg, Wo\n \n   public void assignWorkflow(String workflow, WorkflowConfig workflowCfg,\n       WorkflowContext workflowCtx, CurrentStateOutput currentStateOutput,\n-      BestPossibleStateOutput bestPossibleOutput, Map<String, Resource> resourceMap) {\n+      BestPossibleStateOutput bestPossibleOutput) {\n     // Fetch workflow configuration and context\n     if (workflowCfg == null) {\n       // Already logged in status update.\n@@ -240,13 +240,13 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n     // Assign new jobs\n     while (nextJob != null) {\n       String job = nextJob;\n-      nextJob = jobDag.getNextJob();\n       TaskState jobState = workflowCtx.getJobState(job);\n       if (jobState != null && !jobState.equals(TaskState.NOT_STARTED)) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Job \" + job + \" is already started or completed.\");\n         }\n         processJob(job, currentStateOutput, bestPossibleOutput, workflowCtx);\n+        nextJob = jobDag.getNextJob();\n         continue;\n       }\n \n@@ -258,6 +258,9 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n         break;\n       }\n \n+      // TODO: Part of isJobReadyToSchedule() is already done by RuntimeJobDag. Because there is\n+      // some duplicate logic, consider refactoring. The check here and the ready-list in\n+      // RuntimeJobDag may cause conflicts.\n       // check ancestor job status\n       if (isJobReadyToSchedule(job, workflowCfg, workflowCtx, inCompleteAllJobCount, jobConfigMap,\n           clusterDataCache, clusterDataCache.getAssignableInstanceManager())) {\n@@ -288,6 +291,7 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n           scheduledJobs++;\n         }\n       }\n+      nextJob = jobDag.getNextJob();\n     }\n \n     long currentScheduledTime =",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "sha": "51b21ebaa197cfe54a3b66e2f33bec7768f58bf8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 1,
                "filename": "helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "patch": "@@ -54,7 +54,7 @@ public ResourceAssignment computeBestPossiblePartitionState(\n     _workflowDispatcher.updateWorkflowStatus(workflow, workflowCfg, workflowCtx, currStateOutput,\n         new BestPossibleStateOutput());\n     _workflowDispatcher.assignWorkflow(workflow, workflowCfg, workflowCtx, currStateOutput,\n-        new BestPossibleStateOutput(), new HashMap<String, Resource>());\n+        new BestPossibleStateOutput());\n \n     LOG.debug(String.format(\"WorkflowRebalancer computation takes %d ms for workflow %s\",\n         System.currentTimeMillis() - startTime, workflow));",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "sha": "2411b3901dcfad61c9fa5a1f6c0499906dacf4af",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 2,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "patch": "@@ -206,7 +206,7 @@ public static Date getDateFromStartTime(String startTime)\n   }\n \n   public static JobQueue.Builder buildRecurrentJobQueue(String jobQueueName, int delayStart,\n-      int recurrenInSeconds, TargetState targetState) {\n+      int recurrenceInSeconds, TargetState targetState) {\n     WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder(jobQueueName);\n     workflowCfgBuilder.setExpiry(120000);\n     if (targetState != null) {\n@@ -218,7 +218,7 @@ public static Date getDateFromStartTime(String startTime)\n     cal.set(Calendar.SECOND, cal.get(Calendar.SECOND) + delayStart % 60);\n     cal.set(Calendar.MILLISECOND, 0);\n     ScheduleConfig scheduleConfig =\n-        ScheduleConfig.recurringFromDate(cal.getTime(), TimeUnit.SECONDS, recurrenInSeconds);\n+        ScheduleConfig.recurringFromDate(cal.getTime(), TimeUnit.SECONDS, recurrenceInSeconds);\n     workflowCfgBuilder.setScheduleConfig(scheduleConfig);\n     return new JobQueue.Builder(jobQueueName).setWorkflowConfig(workflowCfgBuilder.build());\n   }",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "sha": "47b7cb8c52964c62105ac3b6666480da217afac8",
                "status": "modified"
            },
            {
                "additions": 99,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 0,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "patch": "@@ -0,0 +1,99 @@\n+package org.apache.helix.integration.task;\n+\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.task.Workflow;\n+import org.apache.helix.task.WorkflowConfig;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+public class TestEnqueueJobs extends TaskTestBase {\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception {\n+    setSingleTestEnvironment();\n+    super.beforeClass();\n+  }\n+\n+  @Test\n+  public void testJobQueueAddingJobsOneByOne() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder().setWorkflowId(queueName).setParallelJobs(1);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    _driver.enqueueJob(queueName, \"JOB0\", jobBuilder);\n+    for (int i = 1; i < 5; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + (i - 1)),\n+          10000L, TaskState.COMPLETED);\n+      _driver.waitToStop(queueName, 5000L);\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+      _driver.resume(queueName);\n+    }\n+\n+    _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + 4),\n+        TaskState.COMPLETED);\n+  }\n+\n+  @Test\n+  public void testJobQueueAddingJobsAtSametime() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder =\n+        new WorkflowConfig.Builder().setWorkflowId(queueName).setParallelJobs(1);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+\n+    // Adding jobs\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    _driver.waitToStop(queueName, 5000L);\n+    for (int i = 0; i < 5; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+    _driver.resume(queueName);\n+\n+    _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + 4),\n+        TaskState.COMPLETED);\n+  }\n+\n+  @Test\n+  public void testJobSubmitGenericWorkflows() throws InterruptedException {\n+    String workflowName = TestHelper.getTestMethodName();\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    Workflow.Builder builder = new Workflow.Builder(workflowName);\n+    for (int i = 0; i < 5; i++) {\n+      builder.addJob(\"JOB\" + i, jobBuilder);\n+    }\n+\n+    /**\n+     * Dependency visualization\n+     *               JOB0\n+     *\n+     *             /   |    \\\n+     *\n+     *         JOB1 <-JOB2   JOB4\n+     *\n+     *                 |     /\n+     *\n+     *                JOB3\n+     */\n+\n+    builder.addParentChildDependency(\"JOB0\", \"JOB1\");\n+    builder.addParentChildDependency(\"JOB0\", \"JOB2\");\n+    builder.addParentChildDependency(\"JOB0\", \"JOB4\");\n+    builder.addParentChildDependency(\"JOB1\", \"JOB2\");\n+    builder.addParentChildDependency(\"JOB2\", \"JOB3\");\n+    builder.addParentChildDependency(\"JOB4\", \"JOB3\");\n+    _driver.start(builder.build());\n+\n+    _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n+  }\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "sha": "28ee51d19c7a063189a45c8b190495fed6899430",
                "status": "added"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 1,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "patch": "@@ -274,12 +274,15 @@ public void testDeletingRecurrentQueueWithHistory() throws Exception {\n \n     // Record all scheduled workflows\n     wCtx = TaskTestUtil.pollForWorkflowContext(_driver, queueName);\n-    List<String> scheduledWorkflows = new ArrayList<String>(wCtx.getScheduledWorkflows());\n+    List<String> scheduledWorkflows = new ArrayList<>(wCtx.getScheduledWorkflows());\n     final String lastScheduledWorkflow = wCtx.getLastScheduledSingleWorkflow();\n \n     // Delete recurrent workflow\n     _driver.delete(queueName);\n \n+    // Try to delete again to make sure things are cleaned up\n+    _driver.delete(queueName);\n+\n     // Wait until recurrent workflow and the last scheduled workflow are cleaned up\n     boolean result = TestHelper.verify(new TestHelper.Verifier() {\n       @Override public boolean verify() throws Exception {",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "sha": "6d05d3848c91083ae807cfe9c3b974a9fa248221",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 6,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "patch": "@@ -231,12 +231,16 @@ public void stopDeleteJobAndResumeNamedQueue() throws Exception {\n     currentJobNames.remove(deletedJob2);\n \n     // add job 3 back\n-    JobConfig.Builder job =\n-        new JobConfig.Builder().setCommand(MockTask.TASK_COMMAND)\n-            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(Sets.newHashSet(\"SLAVE\"));\n-    LOG.info(\"Enqueuing job: \" + deletedJob2);\n-    _driver.enqueueJob(queueName, deletedJob2, job);\n-    currentJobNames.add(deletedJob2);\n+    JobConfig.Builder job = new JobConfig.Builder().setCommand(MockTask.TASK_COMMAND)\n+        .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+        .setTargetPartitionStates(Sets.newHashSet(\"SLAVE\"));\n+\n+    // the name here MUST be unique in order to avoid conflicts with the old job cached in\n+    // RuntimeJobDag\n+    String newJob = deletedJob2 + \"_second\";\n+    LOG.info(\"Enqueuing job: \" + newJob);\n+    _driver.enqueueJob(queueName, newJob, job);\n+    currentJobNames.add(newJob);\n \n     // Ensure the jobs left are successful completed in the correct order\n     long preJobFinish = 0;",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "sha": "5f5c6a3c052570d9ab1f72cad5d053ee3151f6ff",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "deletions": 1,
                "filename": "helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "patch": "@@ -60,8 +60,8 @@ public void testGetLastScheduledTaskExecInfo() throws InterruptedException {\n     List<Long> startTimesFastTasks = setupTasks(\"TestWorkflow_3\", 4, 10);\n     // API call needs to return the most recent timestamp (value at last index)\n     lastScheduledTaskTs = _driver.getLastScheduledTaskTimestamp(\"TestWorkflow_3\");\n-    execInfo = _driver.getLastScheduledTaskExecutionInfo(\"TestWorkflow_3\");\n     Thread.sleep(200); // Let the tasks run\n+    execInfo = _driver.getLastScheduledTaskExecutionInfo(\"TestWorkflow_3\");\n \n     Assert.assertEquals(startTimesFastTasks.get(startTimesFastTasks.size() - 1), lastScheduledTaskTs);\n     Assert.assertEquals(execInfo.getJobName(), \"TestWorkflow_3_job_0\");",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "sha": "a73f02d02009d3cd4258edf77aeadc8b5ffd72ac",
                "status": "modified"
            }
        ],
        "message": "TASK2.0: Job scheduling core pipeline fixes\n\nTask Framework 2.0 had stability issues and race conditions that weren't being handled correctly. Also, integration with RuntimeJobDag had some loopholes that needed to be fixed. This diff includes such fixes and improvements that makes it really show performance gains and cuts down on redundant computation.\nChangelist:\n1. Race condition when a job is enqueued, only the new JobConfig is updated and not the DAG\n    Add a two-way selective update which ensures consistency between JobConfigs and parent DAGs\n2. Moved where getNextJob() is called in scheduleJobs() in WorkflowDispatcher\n    This ensures that once a RuntimeJobDag is rebuilt, update for jobs happens in one pipeline run, which removes any extra delay or slowness\n3. Race condition where the job you got from getNextJob is for some reason not schedulable\n    This is due to deleting and enqueuing a job of the same name\n    RuntimeJobDag has the old job name, which conflicts with the dependency in the new DAG\n    This fixes the test: TestTaskRebalancerStopResume so that it does not enqueue a job of the same name\n4. JobRebalancer was throwing an NPE when calling processJobStatusUpdateAndAssignment()\n    This was sometimes making the Controller hang\n    Added a null check for JobConfig (job could have been deleted/purged)\n5. Fix bug with isWorkflowStopped\n    TargetState comparison was done in the opposite way\n    This fixes the test: TestRecurringJobQueue's testDeletingRecurrentQueueWithHistory()\n    Sometimes contexts do not get deleted cleanly but this does not affect correctness\n6. Add TestEnqueueJobs\n7. Fix unstable TestGetLastScheduledTaskExecInfo\n8. Other minor style fixes",
        "parent": "https://github.com/apache/helix/commit/8ba4c9c19981fffe3c958c6851e2b8b8bf90bfbb",
        "repo": "helix",
        "unit_tests": [
            "TestRuntimeJobDag.java"
        ]
    },
    "helix_10114cd": {
        "bug_id": "helix_10114cd",
        "commit": "https://github.com/apache/helix/commit/10114cd0a201344c58bd9b1e51311d69011c5198",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=10114cd0a201344c58bd9b1e51311d69011c5198",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "patch": "@@ -881,6 +881,8 @@ public void handleNewSession() throws Exception {\n       throw new HelixException(\"Cluster structure is not set up for cluster: \" + _clusterName);\n     }\n \n+    _sessionStartTime = System.currentTimeMillis();\n+\n     switch (_instanceType) {\n     case PARTICIPANT:\n       handleNewSessionAsParticipant();\n@@ -898,8 +900,6 @@ public void handleNewSession() throws Exception {\n       break;\n     }\n \n-    _sessionStartTime = System.currentTimeMillis();\n-\n     startTimerTasks();\n \n     /**",
                "raw_url": "https://github.com/apache/helix/raw/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "sha": "cded08603f8869b5142e68b5428f85fd0f25cf0d",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=10114cd0a201344c58bd9b1e51311d69011c5198",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "patch": "@@ -881,16 +881,16 @@ public MessageHandler createMessageHandler(Message message, NotificationContext\n     String msgType = message.getMsgType().toString();\n \n     MsgHandlerFactoryRegistryItem item = _hdlrFtyRegistry.get(msgType);\n-    MessageHandlerFactory handlerFactory = item.factory();\n \n     // Fail to find a MessageHandlerFactory for the message\n     // we will keep the message and the message will be handled when\n     // the corresponding MessageHandlerFactory is registered\n-    if (handlerFactory == null) {\n+    if (item == null) {\n       LOG.warn(\"Fail to find message handler factory for type: \" + msgType + \" msgId: \"\n           + message.getMsgId());\n       return null;\n     }\n+    MessageHandlerFactory handlerFactory = item.factory();\n \n     // pass the executor to msg-handler since batch-msg-handler needs task-executor to schedule\n     // sub-msgs",
                "raw_url": "https://github.com/apache/helix/raw/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "sha": "717bbcf63345bcc5ceb5865768235573821b29b3",
                "status": "modified"
            }
        ],
        "message": "Bug fix\n\n(1) HelixTaskExecutor checks whether MsgHandlerFactoryRegistryItem\nexists.\n(2) ZkHelixManager, onMessage callback might occur before\nsessionStartTime is set, which will cause NPE. Set the time first before\nregistering the message listener.",
        "parent": "https://github.com/apache/helix/commit/826d6c00832851124219f9d72da430e751e07300",
        "repo": "helix",
        "unit_tests": [
            "TestHelixTaskExecutor.java"
        ]
    },
    "helix_1c78fef": {
        "bug_id": "helix_1c78fef",
        "commit": "https://github.com/apache/helix/commit/1c78fef91e48345876ccdb038aa4ca1099a3bacd",
        "file": [
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/helix/blob/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java?ref=1c78fef91e48345876ccdb038aa4ca1099a3bacd",
                "deletions": 5,
                "filename": "helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "patch": "@@ -60,7 +60,7 @@\n   private final HelixManager _helixManager;\n   private final RouterUpdater _routerUpdater;\n   private final PropertyType _sourceDataType;\n-  private final Map<RoutingTableChangeListener, Object> _routingTableChangeListenerMap;\n+  private final Map<RoutingTableChangeListener, ListenerContext> _routingTableChangeListenerMap;\n \n   public RoutingTableProvider() {\n     this(null);\n@@ -173,7 +173,7 @@ public RoutingTableSnapshot getRoutingTableSnapshot() {\n    */\n   public void addRoutingTableChangeListener(final RoutingTableChangeListener routingTableChangeListener,\n       Object context) {\n-    _routingTableChangeListenerMap.put(routingTableChangeListener, context);\n+    _routingTableChangeListenerMap.put(routingTableChangeListener, new ListenerContext(context));\n   }\n \n   /**\n@@ -494,10 +494,10 @@ protected void refresh(Map<String, Map<String, Map<String, CurrentState>>> curre\n   }\n \n   private void notifyRoutingTableChange() {\n-    for (Map.Entry<RoutingTableChangeListener, Object> entry : _routingTableChangeListenerMap\n+    for (Map.Entry<RoutingTableChangeListener, ListenerContext> entry : _routingTableChangeListenerMap\n         .entrySet()) {\n-      entry.getKey()\n-          .onRoutingTableChange(new RoutingTableSnapshot(_routingTableRef.get()), entry.getValue());\n+      entry.getKey().onRoutingTableChange(new RoutingTableSnapshot(_routingTableRef.get()),\n+          entry.getValue().getContext());\n     }\n   }\n \n@@ -561,4 +561,16 @@ public void queueEvent(NotificationContext context, ClusterEventType eventType,\n       queueEvent(event);\n     }\n   }\n+\n+  private class ListenerContext {\n+    private Object _context;\n+\n+    public ListenerContext(Object context) {\n+      _context = context;\n+    }\n+\n+    public Object getContext() {\n+      return _context;\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/helix/raw/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "sha": "89079220cde88de4d81b0afaada68ded002a569b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java?ref=1c78fef91e48345876ccdb038aa4ca1099a3bacd",
                "deletions": 1,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "patch": "@@ -164,7 +164,7 @@ public void testRoutingTableListener() throws InterruptedException {\n     context.put(\"MASTER\", Sets.newSet(_instances.get(0)));\n     context.put(\"SLAVE\", Sets.newSet(_instances.get(1), _instances.get(2)));\n     _routingTableProvider.addRoutingTableChangeListener(routingTableChangeListener, context);\n-\n+    _routingTableProvider.addRoutingTableChangeListener(new MockRoutingTableChangeListener(), null);\n     // reenable the master instance to cause change\n     String prevMasterInstance = _instances.get(0);\n     _gSetupTool.getClusterManagementTool().enableInstance(CLUSTER_NAME, prevMasterInstance, true);",
                "raw_url": "https://github.com/apache/helix/raw/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "sha": "ff35dbd9cc657435d3508285e9cc7422f969a14e",
                "status": "modified"
            }
        ],
        "message": "Fix NPE for RoutingTableProvider listener",
        "parent": "https://github.com/apache/helix/commit/90730bff49120fc1ca0103e8be2cbab90e6ceced",
        "repo": "helix",
        "unit_tests": [
            "TestRoutingTableProvider.java"
        ]
    },
    "helix_516faa0": {
        "bug_id": "helix_516faa0",
        "commit": "https://github.com/apache/helix/commit/516faa0c504c807bbc9133694998f227e8e0d114",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/helix/blob/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java?ref=516faa0c504c807bbc9133694998f227e8e0d114",
                "deletions": 4,
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "patch": "@@ -61,6 +61,7 @@\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.Partition;\n import org.apache.helix.model.Resource;\n+import org.apache.helix.task.TaskConstants;\n import org.apache.helix.util.ZKClientPool;\n import org.apache.log4j.Logger;\n \n@@ -255,15 +256,22 @@ static boolean verifyBestPossAndExtView(HelixDataAccessor accessor,\n       cache.refresh(accessor);\n \n       Map<String, IdealState> idealStates = cache.getIdealStates();\n-      if (idealStates == null) // || idealStates.isEmpty())\n-      {\n+      if (idealStates == null) {\n         // ideal state is null because ideal state is dropped\n         idealStates = Collections.emptyMap();\n       }\n \n+      // filter out all resources that use Task state model\n+      Iterator it = idealStates.entrySet().iterator();\n+      while (it.hasNext()) {\n+        Map.Entry<String, IdealState> pair = (Map.Entry<String, IdealState>)it.next();\n+        if (pair.getValue().getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)) {\n+          it.remove();\n+        }\n+      }\n+\n       Map<String, ExternalView> extViews = accessor.getChildValuesMap(keyBuilder.externalViews());\n-      if (extViews == null) // || extViews.isEmpty())\n-      {\n+      if (extViews == null) {\n         extViews = Collections.emptyMap();\n       }\n ",
                "raw_url": "https://github.com/apache/helix/raw/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "sha": "473a4df1f0070584309b27be11fc687b4229fc1d",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/helix/blob/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=516faa0c504c807bbc9133694998f227e8e0d114",
                "deletions": 4,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "patch": "@@ -373,8 +373,7 @@ private JobQueue buildRecurrentJobQueue(String jobQueueName)\n   {\n     Map<String, String> cfgMap = new HashMap<String, String>();\n     cfgMap.put(WorkflowConfig.EXPIRY, String.valueOf(50000));\n-    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.getDefaultDateFormat().format(\n-        Calendar.getInstance().getTime()));\n+    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.getDefaultDateFormat().format(Calendar.getInstance().getTime()));\n     cfgMap.put(WorkflowConfig.RECURRENCE_INTERVAL, String.valueOf(60));\n     cfgMap.put(WorkflowConfig.RECURRENCE_UNIT, \"SECONDS\");\n     return (new JobQueue.Builder(jobQueueName).fromMap(cfgMap)).build();\n@@ -503,12 +502,19 @@ public void stopAndDeleteQueue() throws Exception {\n     String namespacedJob2 = String.format(\"%s_%s\", queueName,  job2Name);\n     TestUtil.pollForJobState(_manager, queueName, namespacedJob2, TaskState.COMPLETED);\n \n-    // Stop and delete queue\n+    // Stop queue\n     _driver.stop(queueName);\n+\n+    boolean result =\n+        ClusterStateVerifier.verifyByPolling(new ClusterStateVerifier.BestPossAndExtViewZkVerifier(\n+            ZK_ADDR, CLUSTER_NAME));\n+    Assert.assertTrue(result);\n+\n+    // Delete queue\n     _driver.delete(queueName);\n \n     // Wait until all status are cleaned up\n-    boolean result = TestHelper.verify(new TestHelper.Verifier() {\n+    result = TestHelper.verify(new TestHelper.Verifier() {\n       @Override public boolean verify() throws Exception {\n         HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n         PropertyKey.Builder keyBuilder = accessor.keyBuilder();",
                "raw_url": "https://github.com/apache/helix/raw/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "sha": "aed40884a04f24d09985e52d76a4640ef36eaa21",
                "status": "modified"
            }
        ],
        "message": "[HELIX-587] Fix NPE in ClusterStateVerifier, rb=32344",
        "parent": "https://github.com/apache/helix/commit/e924a4c4ee1f1c52dcf6b478bbc88d3050e9d0f8",
        "repo": "helix",
        "unit_tests": [
            "TestClusterStateVerifier.java"
        ]
    },
    "helix_5359861": {
        "bug_id": "helix_5359861",
        "commit": "https://github.com/apache/helix/commit/535986137b557f836c712e14c83f9fe923af4258",
        "file": [
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "deletions": 4,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "patch": "@@ -72,6 +72,10 @@ public IdealState computeNewIdealState(String resourceName,\n \n     if (resourceConfig != null) {\n       userDefinedPreferenceList = resourceConfig.getPreferenceLists();\n+      if (!userDefinedPreferenceList.isEmpty()) {\n+        LOG.info(\"Using user defined preference list for partitions: \" + userDefinedPreferenceList\n+            .keySet());\n+      }\n     }\n \n     Set<String> liveEnabledNodes;\n@@ -100,7 +104,7 @@ public IdealState computeNewIdealState(String resourceName,\n           clusterData.getInstanceOfflineTimeMap(), clusterData.getLiveInstances().keySet(),\n           clusterData.getInstanceConfigMap(), delay, clusterConfig);\n \n-      Set<String> offlineOrDisabledInstances = new HashSet<String>(activeNodes);\n+      Set<String> offlineOrDisabledInstances = new HashSet<>(activeNodes);\n       offlineOrDisabledInstances.removeAll(liveEnabledNodes);\n       setRebalanceScheduler(currentIdealState, offlineOrDisabledInstances,\n           clusterData.getInstanceOfflineTimeMap(), clusterData.getLiveInstances().keySet(),\n@@ -169,7 +173,7 @@ public IdealState computeNewIdealState(String resourceName,\n       LOG.debug(\"currentMapping: \" + currentMapping);\n       LOG.debug(\"stateCountMap: \" + stateCountMap);\n       LOG.debug(\"liveEnabledNodes: \" + liveEnabledNodes);\n-      LOG.debug(\"ActiveNodes: \" + activeNodes);\n+      LOG.debug(\"activeNodes: \" + activeNodes);\n       LOG.debug(\"allNodes: \" + allNodes);\n       LOG.debug(\"maxPartition: \" + maxPartition);\n       LOG.debug(\"newIdealMapping: \" + newIdealMapping);\n@@ -305,11 +309,11 @@ private ZNRecord getFinalDelayedMapping(IdealState idealState, ZNRecord newIdeal\n       return newIdealMapping;\n     }\n     ZNRecord finalMapping = new ZNRecord(idealState.getResourceName());\n-    for (String partition : idealState.getPartitionSet()) {\n+    for (String partition : newIdealMapping.getListFields().keySet()) {\n       List<String> idealList = newIdealMapping.getListField(partition);\n       List<String> activeList = newActiveMapping.getListField(partition);\n \n-      List<String> liveList = new ArrayList<String>();\n+      List<String> liveList = new ArrayList<>();\n       int activeReplica = 0;\n       for (String ins : activeList) {\n         if (liveInstances.contains(ins)) {\n@@ -385,6 +389,12 @@ public ResourceAssignment computeBestPossiblePartitionState(ClusterDataCache cac\n \n       partitionMapping.addReplicaMap(partition, bestStateForPartition);\n     }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Best possible mapping for resource  \" + resource.getResourceName() + \": \"\n+          + partitionMapping);\n+    }\n+\n     return partitionMapping;\n   }\n ",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "sha": "bbbdda08cafccbddd12f1ddce3740e20185fde4d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "patch": "@@ -240,7 +240,6 @@ private void chargePendingTransition(Resource resource, CurrentStateOutput curre\n       StateTransitionThrottleController throttleController, Set<Partition> partitionsNeedRecovery,\n       Set<Partition> partitionsNeedLoadbalance) {\n     String resourceName = resource.getResourceName();\n-    logger.info(\"Processing resource:\" + resourceName);\n \n     // check and charge pending transitions\n     for (Partition partition : resource.getPartitions()) {\n@@ -308,7 +307,7 @@ public int compare(Partition o1, Partition o2) {\n           intermediatePartitionStateMap, RebalanceType.RECOVERY_BALANCE);\n     }\n \n-    logger.info(String\n+    logger.debug(String\n         .format(\"needRecovery: %d, recoverybalanceThrottled: %d\", partitionsNeedRecovery.size(),\n             partitionRecoveryBalanceThrottled.size()));\n     return partitionRecoveryBalanceThrottled.size();",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "sha": "52b7b288a8ac36b7f13335fb8c89e3242b8678a4",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "deletions": 2,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "patch": "@@ -73,8 +73,8 @@ public void beforeSuite() throws Exception {\n \n     _gZkClient = new ZkClient(ZK_ADDR);\n     _gZkClient.setZkSerializer(new ZNRecordSerializer());\n-    _gSetupTool = new ClusterSetup(ZK_ADDR);\n-    _baseAccessor = new ZkBaseDataAccessor<ZNRecord>(_gZkClient);\n+    _gSetupTool = new ClusterSetup(_gZkClient);\n+    _baseAccessor = new ZkBaseDataAccessor<>(_gZkClient);\n   }\n \n   @AfterSuite",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "sha": "c3b4942dbd97d555d8bcb40aa0276aa78aeb4036",
                "status": "modified"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "changes": 47,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "deletions": 18,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "patch": "@@ -25,11 +25,14 @@\n import java.util.List;\n import java.util.Map;\n import org.apache.helix.ConfigAccessor;\n+import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.controller.rebalancer.strategy.CrushRebalanceStrategy;\n import org.apache.helix.controller.rebalancer.strategy.MultiRoundCrushRebalanceStrategy;\n+import org.apache.helix.controller.rebalancer.util.RebalanceScheduler;\n import org.apache.helix.integration.common.ZkIntegrationTestBase;\n import org.apache.helix.integration.manager.ClusterControllerManager;\n import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n import org.apache.helix.model.BuiltInStateModelDefinitions;\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.ResourceConfig;\n@@ -51,12 +54,11 @@\n   private final String CLUSTER_NAME = CLUSTER_PREFIX + \"_\" + CLASS_NAME;\n   private ClusterControllerManager _controller;\n \n-  private ClusterSetup _setupTool = null;\n   private List<MockParticipantManager> _participants = new ArrayList<>();\n   private int _replica = 3;\n   private HelixClusterVerifier _clusterVerifier;\n-  private List<String> _testDBs = new ArrayList<>();\n   private ConfigAccessor _configAccessor;\n+  private HelixDataAccessor _dataAccessor;\n \n   @BeforeClass\n   public void beforeClass() throws Exception {\n@@ -66,12 +68,11 @@ public void beforeClass() throws Exception {\n     if (_gZkClient.exists(namespace)) {\n       _gZkClient.deleteRecursive(namespace);\n     }\n-    _setupTool = new ClusterSetup(_gZkClient);\n-    _setupTool.addCluster(CLUSTER_NAME, true);\n+    _gSetupTool.addCluster(CLUSTER_NAME, true);\n \n     for (int i = 0; i < NUM_NODE; i++) {\n       String storageNodeName = PARTICIPANT_PREFIX + \"_\" + (START_PORT + i);\n-      _setupTool.addInstanceToCluster(CLUSTER_NAME, storageNodeName);\n+      _gSetupTool.addInstanceToCluster(CLUSTER_NAME, storageNodeName);\n \n       // start dummy participants\n       MockParticipantManager participant =\n@@ -91,24 +92,33 @@ public void beforeClass() throws Exception {\n     enablePersistBestPossibleAssignment(_gZkClient, CLUSTER_NAME, true);\n \n     _configAccessor = new ConfigAccessor(_gZkClient);\n+    _dataAccessor = new ZKHelixDataAccessor(CLUSTER_NAME, _baseAccessor);\n   }\n \n   @DataProvider(name = \"stateModels\")\n-  public static String [][] stateModels() {\n-    return new String[][] { {BuiltInStateModelDefinitions.MasterSlave.name()},\n-        {BuiltInStateModelDefinitions.OnlineOffline.name()},\n-        {BuiltInStateModelDefinitions.LeaderStandby.name()}\n+  public static Object [][] stateModels() {\n+    return new Object[][] { {BuiltInStateModelDefinitions.MasterSlave.name(), true},\n+        {BuiltInStateModelDefinitions.OnlineOffline.name(), true},\n+        {BuiltInStateModelDefinitions.LeaderStandby.name(), true},\n+        {BuiltInStateModelDefinitions.MasterSlave.name(), false},\n+        {BuiltInStateModelDefinitions.OnlineOffline.name(), false},\n+        {BuiltInStateModelDefinitions.LeaderStandby.name(), false},\n     };\n   }\n \n   @Test(dataProvider = \"stateModels\")\n-  public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n-      throws Exception {\n+  public void testUserDefinedPreferenceListsInFullAuto(\n+      String stateModel, boolean delayEnabled) throws Exception {\n     String db = \"Test-DB-\" + stateModel;\n-    createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n-        _replica, 0, CrushRebalanceStrategy.class.getName());\n+    if (delayEnabled) {\n+      createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n+          _replica - 1, 200, CrushRebalanceStrategy.class.getName());\n+    } else {\n+      createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n+          _replica, 0, CrushRebalanceStrategy.class.getName());\n+    }\n     IdealState idealState =\n-        _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n+        _gSetupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n     Map<String, List<String>> userDefinedPreferenceLists = idealState.getPreferenceLists();\n     List<String> userDefinedPartitions = new ArrayList<>();\n     for (String partition : userDefinedPreferenceLists.keySet()) {\n@@ -125,6 +135,9 @@ public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n         new ResourceConfig.Builder(db).setPreferenceLists(userDefinedPreferenceLists).build();\n     _configAccessor.setResourceConfig(CLUSTER_NAME, db, resourceConfig);\n \n+    //TODO: Trigger rebalancer, remove this once Helix controller is listening on resource config changes.\n+    RebalanceScheduler.invokeRebalance(_dataAccessor, db);\n+\n     while (userDefinedPartitions.size() > 0) {\n       Thread.sleep(100);\n       Assert.assertTrue(_clusterVerifier.verify());\n@@ -136,7 +149,7 @@ public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n   private void verifyUserDefinedPreferenceLists(String db,\n       Map<String, List<String>> userDefinedPreferenceLists, List<String> userDefinedPartitions)\n       throws InterruptedException {\n-    IdealState is = _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n+    IdealState is = _gSetupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n     for (String p : userDefinedPreferenceLists.keySet()) {\n       List<String> userDefined = userDefinedPreferenceLists.get(p);\n       List<String> preferenceListInIs = is.getPreferenceList(p);\n@@ -163,9 +176,7 @@ private void removePartitionFromUserDefinedList(String db, List<String> userDefi\n     _configAccessor.setResourceConfig(CLUSTER_NAME, db, resourceConfig);\n \n     //TODO: Touch IS, remove this once Helix controller is listening on resource config changes.\n-    IdealState idealState =\n-        _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n-    _setupTool.getClusterManagementTool().setResourceIdealState(CLUSTER_NAME, db, idealState);\n+    RebalanceScheduler.invokeRebalance(_dataAccessor, db);\n   }\n \n   @AfterClass",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "sha": "fafd78c87a64b5aebefe9ba0bacbe383998ac018",
                "status": "modified"
            }
        ],
        "message": "Fix a NPE in DelayedAutoRebalancer, adding more debug logs.",
        "parent": "https://github.com/apache/helix/commit/69f43016f231e428fc741988542e688865fa27f5",
        "repo": "helix",
        "unit_tests": [
            "TestIntermediateStateCalcStage.java"
        ]
    },
    "helix_590f65c": {
        "bug_id": "helix_590f65c",
        "commit": "https://github.com/apache/helix/commit/590f65cf9538435c89dfd71922479b281a159e60",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/pom.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/pom.xml?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 0,
                "filename": "helix-core/pom.xml",
                "patch": "@@ -124,6 +124,11 @@ under the License.\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.mockito</groupId>\n+      <artifactId>mockito-all</artifactId>\n+      <scope>test</scope>\n+    </dependency>\n     <dependency>\n       <groupId>org.apache.commons</groupId>\n       <artifactId>commons-math</artifactId>",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/pom.xml",
                "sha": "67b28973bebcd2715011a32a986f0a1bc841c4b8",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/PropertyKey.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "patch": "@@ -408,6 +408,15 @@ public PropertyKey stateTransitionStatus(String instanceName, String sessionId)\n           sessionId);\n     }\n \n+    /**\n+     * Get a property key associated with {@link StatusUpdate} of an instance\n+     * @param instanceName\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey stateTransitionStatus(String instanceName) {\n+      return new PropertyKey(STATUSUPDATES, StatusUpdate.class, _clusterName, instanceName);\n+    }\n+\n     /**\n      * Used to get status update for a NON STATE TRANSITION type\n      * @param instanceName\n@@ -451,6 +460,16 @@ public PropertyKey stateTransitionErrors(String instanceName, String sessionId,\n           resourceName);\n     }\n \n+    /**\n+     * Get a property key associated with {@link Error} of an instance, session, and\n+     * resource\n+     * @param instanceName\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey stateTransitionErrors(String instanceName) {\n+      return new PropertyKey(ERRORS, Error.class, _clusterName, instanceName);\n+    }\n+\n     /**\n      * Used to get status update for a NON STATE TRANSITION type\n      * @param instanceName\n@@ -525,6 +544,14 @@ public PropertyKey controllerTaskStatus(String subPath, String recordName) {\n           recordName);\n     }\n \n+    /**\n+     * Get a property key associated with {@link StatusUpdate} of controller status updates\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey controllerTaskStatuses() {\n+      return new PropertyKey(STATUSUPDATES_CONTROLLER, StatusUpdate.class, _clusterName);\n+    }\n+\n     /**\n      * Get a property key associated with all {@link Message}s for the controller\n      * @return {@link PropertyKey}",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "sha": "f4e47a0e286e9ecc7a05a7b0feb95a86c7921523",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 7,
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "patch": "@@ -131,11 +131,9 @@\n    */\n   static class StatusDumpTask extends HelixTimerTask {\n     Timer _timer = null;\n-    final ZkClient zkclient;\n     final HelixManager helixController;\n \n-    public StatusDumpTask(ZkClient zkclient, HelixManager helixController) {\n-      this.zkclient = zkclient;\n+    public StatusDumpTask(HelixManager helixController) {\n       this.helixController = helixController;\n     }\n \n@@ -148,8 +146,8 @@ public void start() {\n       if (_timer == null) {\n         LOG.info(\"Start StatusDumpTask\");\n         _timer = new Timer(\"StatusDumpTimerTask\", true);\n-        _timer.scheduleAtFixedRate(new ZKPathDataDumpTask(helixController, zkclient,\n-            timeThresholdNoChange), initialDelay, period);\n+        _timer.scheduleAtFixedRate(new ZKPathDataDumpTask(helixController, timeThresholdNoChange),\n+            initialDelay, period);\n       }\n     }\n \n@@ -216,12 +214,12 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n       break;\n     case CONTROLLER:\n       _stateMachineEngine = null;\n-      _controllerTimerTasks.add(new StatusDumpTask(_zkclient, this));\n+      _controllerTimerTasks.add(new StatusDumpTask(this));\n \n       break;\n     case CONTROLLER_PARTICIPANT:\n       _stateMachineEngine = new HelixStateMachineEngine(this);\n-      _controllerTimerTasks.add(new StatusDumpTask(_zkclient, this));\n+      _controllerTimerTasks.add(new StatusDumpTask(this));\n       break;\n     case ADMINISTRATOR:\n     case SPECTATOR:",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "sha": "01bbaf3ead19afd0971831004f84c7a86e7f443c",
                "status": "modified"
            },
            {
                "additions": 90,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "changes": 173,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 83,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "patch": "@@ -19,36 +19,35 @@\n  * under the License.\n  */\n \n-import java.io.StringWriter;\n-import java.util.Date;\n import java.util.List;\n import java.util.TimerTask;\n \n+import org.apache.helix.BaseDataAccessor;\n import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n import org.apache.helix.PropertyType;\n import org.apache.helix.ZNRecord;\n import org.apache.helix.PropertyKey.Builder;\n import org.apache.helix.manager.zk.ZNRecordSerializer;\n-import org.apache.helix.manager.zk.ZkClient;\n import org.apache.helix.util.HelixUtil;\n import org.apache.log4j.Logger;\n import org.apache.zookeeper.data.Stat;\n-import org.codehaus.jackson.map.ObjectMapper;\n-import org.codehaus.jackson.map.SerializationConfig;\n+\n+import com.google.common.collect.Lists;\n \n public class ZKPathDataDumpTask extends TimerTask {\n-  static Logger logger = Logger.getLogger(ZKPathDataDumpTask.class);\n+  static Logger LOG = Logger.getLogger(ZKPathDataDumpTask.class);\n \n   private final int _thresholdNoChangeInMs;\n   private final HelixManager _manager;\n-  private final ZkClient _zkClient;\n+  private final ZNRecordSerializer _jsonSerializer;\n+\n+  public ZKPathDataDumpTask(HelixManager manager, int thresholdNoChangeInMs) {\n+    LOG.info(\"Init ZKPathDataDumpTask for cluster: \" + manager.getClusterName()\n+        + \", thresholdNoChangeInMs: \" + thresholdNoChangeInMs);\n \n-  public ZKPathDataDumpTask(HelixManager manager, ZkClient zkClient, int thresholdNoChangeInMs) {\n     _manager = manager;\n-    _zkClient = zkClient;\n-    logger.info(\"Scanning cluster statusUpdate \" + manager.getClusterName()\n-        + \" thresholdNoChangeInMs: \" + thresholdNoChangeInMs);\n+    _jsonSerializer = new ZNRecordSerializer();\n     _thresholdNoChangeInMs = thresholdNoChangeInMs;\n   }\n \n@@ -59,88 +58,96 @@ public void run() {\n     // We need to think if we should create per-instance log files that contains\n     // per-instance statusUpdates\n     // and errors\n-    logger.info(\"Scanning status updates ...\");\n-    try {\n-      HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n-      Builder keyBuilder = accessor.keyBuilder();\n-\n-      List<String> instances = accessor.getChildNames(keyBuilder.instanceConfigs());\n-      for (String instanceName : instances) {\n-        scanPath(HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instanceName,\n-            PropertyType.STATUSUPDATES), _thresholdNoChangeInMs);\n-        scanPath(HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instanceName,\n-            PropertyType.ERRORS), _thresholdNoChangeInMs * 3);\n-      }\n-      scanPath(HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n-          PropertyType.STATUSUPDATES_CONTROLLER), _thresholdNoChangeInMs);\n+    LOG.info(\"Scan statusUpdates and errors for cluster: \" + _manager.getClusterName()\n+        + \", by controller: \" + _manager);\n+    HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n+    Builder keyBuilder = accessor.keyBuilder();\n+    BaseDataAccessor<ZNRecord> baseAccessor = accessor.getBaseDataAccessor();\n+\n+    List<String> instances = accessor.getChildNames(keyBuilder.instanceConfigs());\n+    for (String instance : instances) {\n+      // dump participant status updates\n+      String statusUpdatePath =\n+          HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instance,\n+              PropertyType.STATUSUPDATES);\n+      dump(baseAccessor, statusUpdatePath, _thresholdNoChangeInMs);\n \n-      scanPath(HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n-          PropertyType.ERRORS_CONTROLLER), _thresholdNoChangeInMs * 3);\n-    } catch (Exception e) {\n-      logger.error(e);\n+      // dump participant errors\n+      String errorPath =\n+          HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instance,\n+              PropertyType.ERRORS);\n+      dump(baseAccessor, errorPath, _thresholdNoChangeInMs * 3);\n     }\n+    // dump controller status updates\n+    String controllerStatusUpdatePath =\n+        HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n+            PropertyType.STATUSUPDATES_CONTROLLER);\n+    dump(baseAccessor, controllerStatusUpdatePath, _thresholdNoChangeInMs);\n+\n+    // dump controller errors\n+    String controllerErrorPath =\n+        HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n+            PropertyType.ERRORS_CONTROLLER);\n+    dump(baseAccessor, controllerErrorPath, _thresholdNoChangeInMs);\n   }\n \n-  void scanPath(String path, int thresholdNoChangeInMs) {\n-    logger.info(\"Scanning path \" + path);\n-    List<String> subPaths = _zkClient.getChildren(path);\n-    for (String subPath : subPaths) {\n-      try {\n-        String nextPath = path + \"/\" + subPath;\n-        List<String> subSubPaths = _zkClient.getChildren(nextPath);\n-        for (String subsubPath : subSubPaths) {\n-          try {\n-            checkAndDump(nextPath + \"/\" + subsubPath, thresholdNoChangeInMs);\n-          } catch (Exception e) {\n-            logger.error(e);\n-          }\n-        }\n-      } catch (Exception e) {\n-        logger.error(e);\n+  /**\n+   * Find paths of all leaf nodes under an ancestor path (exclusive)\n+   * @param accessor\n+   * @param ancestorPath\n+   * @return a list of paths\n+   */\n+  static List<String> scanPath(BaseDataAccessor<ZNRecord> accessor, String ancestorPath) {\n+    List<String> queue = Lists.newLinkedList();\n+    queue.add(ancestorPath);\n+\n+    // BFS\n+    List<String> leafPaths = Lists.newArrayList();\n+    while (!queue.isEmpty()) {\n+      String path = queue.remove(0);\n+      List<String> childNames = accessor.getChildNames(path, 0);\n+      if (childNames == null) {\n+        // path doesn't exist\n+        continue;\n+      }\n+      if (childNames.isEmpty() && !path.equals(ancestorPath)) {\n+        // leaf node, excluding ancestorPath\n+        leafPaths.add(path);\n+      }\n+      for (String childName : childNames) {\n+        String subPath = String.format(\"%s/%s\", path, childName);\n+        queue.add(subPath);\n       }\n     }\n+    return leafPaths;\n   }\n \n-  void checkAndDump(String path, int thresholdNoChangeInMs) {\n-    List<String> subPaths = _zkClient.getChildren(path);\n-    if (subPaths.size() == 0) {\n-      subPaths.add(\"\");\n+  void dump(BaseDataAccessor<ZNRecord> accessor, String ancestorPath, int threshold) {\n+    List<String> leafPaths = scanPath(accessor, ancestorPath);\n+    if (leafPaths.isEmpty()) {\n+      return;\n+    }\n+\n+    Stat[] stats = accessor.getStats(leafPaths, 0);\n+    List<String> dumpPaths = Lists.newArrayList();\n+    long now = System.currentTimeMillis();\n+    for (int i = 0; i < stats.length; i++) {\n+      Stat stat = stats[i];\n+      if ((now - stat.getMtime()) > threshold) {\n+        dumpPaths.add(leafPaths.get(i));\n+      }\n     }\n-    for (String subPath : subPaths) {\n-      String fullPath = subPath.length() > 0 ? path + \"/\" + subPath : path;\n-      Stat pathStat = _zkClient.getStat(fullPath);\n-\n-      long lastModifiedTimeInMs = pathStat.getMtime();\n-      long nowInMs = new Date().getTime();\n-      // logger.info(nowInMs + \" \" + lastModifiedTimeInMs + \" \" + fullPath);\n-\n-      // Check the last modified time\n-      if (nowInMs > lastModifiedTimeInMs) {\n-        long timeDiff = nowInMs - lastModifiedTimeInMs;\n-        if (timeDiff > thresholdNoChangeInMs) {\n-          logger.info(\"Dumping status update path \" + fullPath + \" \" + timeDiff + \"MS has passed\");\n-          _zkClient.setZkSerializer(new ZNRecordSerializer());\n-          ZNRecord record = _zkClient.readData(fullPath);\n-\n-          // dump the node content into log file\n-          ObjectMapper mapper = new ObjectMapper();\n-          SerializationConfig serializationConfig = mapper.getSerializationConfig();\n-          serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n-\n-          StringWriter sw = new StringWriter();\n-          try {\n-            mapper.writeValue(sw, record);\n-            logger.info(sw.toString());\n-          } catch (Exception e) {\n-            logger\n-                .warn(\n-                    \"Exception during serialization in ZKPathDataDumpTask.checkAndDump. This can mostly be ignored\",\n-                    e);\n-          }\n-          // Delete the leaf data\n-          _zkClient.deleteRecursive(fullPath);\n-        }\n+\n+    // dump\n+    LOG.info(\"Dump statusUpdates and errors records for pahts: \" + dumpPaths);\n+    List<ZNRecord> dumpRecords = accessor.get(dumpPaths, null, 0);\n+    for (ZNRecord record : dumpRecords) {\n+      if (record != null) {\n+        LOG.info(new String(_jsonSerializer.serialize(record)));\n       }\n     }\n+\n+    // clean up\n+    accessor.remove(dumpPaths, 0);\n   }\n }",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "sha": "a0190d2be24a3b9ee5992310023c38987c958524",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 27,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "patch": "@@ -21,6 +21,7 @@\n \n import java.util.Date;\n \n+import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n import org.apache.helix.NotificationContext;\n import org.apache.helix.TestHelper;\n@@ -32,7 +33,6 @@\n import org.apache.helix.integration.manager.MockParticipantManager;\n import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n-import org.apache.helix.mock.participant.MockJobIntf;\n import org.apache.helix.model.LiveInstance;\n import org.apache.helix.participant.CustomCodeCallbackHandler;\n import org.apache.helix.participant.HelixCustomCodeRunner;\n@@ -62,30 +62,20 @@ public void onCallback(NotificationContext context) {\n \n   }\n \n-  class MockJob implements MockJobIntf {\n-    @Override\n-    public void doPreConnectJob(HelixManager manager) {\n-      try {\n-        // delay the start of the 1st participant\n-        // so there will be a leadership transfer from localhost_12919 to 12918\n-        if (manager.getInstanceName().equals(\"localhost_12918\")) {\n-          Thread.sleep(2000);\n-        }\n-\n-        HelixCustomCodeRunner customCodeRunner = new HelixCustomCodeRunner(manager, ZK_ADDR);\n-        customCodeRunner.invoke(_callback).on(ChangeType.LIVE_INSTANCE)\n-            .usingLeaderStandbyModel(\"TestParticLeader\").start();\n-      } catch (Exception e) {\n-        LOG.error(\"Exception do pre-connect job\", e);\n+  private void registerCustomCodeRunner(HelixManager manager) {\n+    try {\n+      // delay the start of the 1st participant\n+      // so there will be a leadership transfer from localhost_12919 to 12918\n+      if (manager.getInstanceName().equals(\"localhost_12918\")) {\n+        Thread.sleep(2000);\n       }\n-    }\n-\n-    @Override\n-    public void doPostConnectJob(HelixManager manager) {\n-      // TODO Auto-generated method stub\n \n+      HelixCustomCodeRunner customCodeRunner = new HelixCustomCodeRunner(manager, ZK_ADDR);\n+      customCodeRunner.invoke(_callback).on(ChangeType.LIVE_INSTANCE)\n+          .usingLeaderStandbyModel(\"TestParticLeader\").start();\n+    } catch (Exception e) {\n+      LOG.error(\"Exception do pre-connect job\", e);\n     }\n-\n   }\n \n   @Test\n@@ -109,10 +99,9 @@ public void testCustomCodeRunner() throws Exception {\n     for (int i = 0; i < _nodeNb; i++) {\n       String instanceName = \"localhost_\" + (_startPort + i);\n \n-      MockJob job = new MockJob();\n       participants[i] = new MockParticipantManager(ZK_ADDR, _clusterName, instanceName);\n \n-      job.doPreConnectJob(participants[i]);\n+      registerCustomCodeRunner(participants[i]);\n       participants[i].syncStart();\n     }\n     boolean result =\n@@ -125,9 +114,7 @@ public void testCustomCodeRunner() throws Exception {\n     _callback._isCallbackInvoked = false;\n \n     // add a new live instance\n-    // ZkClient zkClient = new ZkClient(ZK_ADDR);\n-    // zkClient.setZkSerializer(new ZNRecordSerializer());\n-    ZKHelixDataAccessor accessor =\n+    HelixDataAccessor accessor =\n         new ZKHelixDataAccessor(_clusterName, new ZkBaseDataAccessor<ZNRecord>(_gZkClient));\n     Builder keyBuilder = accessor.keyBuilder();\n ",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "sha": "93ceedb0d425e26012f2b55707faa4100749555e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 1,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "patch": "@@ -393,7 +393,7 @@ public void testSchedulerMsg() throws Exception {\n       }\n     }\n     Thread.sleep(3000);\n-    ZKPathDataDumpTask dumpTask = new ZKPathDataDumpTask(manager, _gZkClient, 0);\n+    ZKPathDataDumpTask dumpTask = new ZKPathDataDumpTask(manager, 0);\n     dumpTask.run();\n \n     subPaths = _gZkClient.getChildren(controllerStatusPath);",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "sha": "cb6e186f9157aeb209efbb0e49f0209eb2dec70b",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 1,
                "filename": "helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "patch": "@@ -28,7 +28,6 @@\n import org.apache.helix.manager.zk.ZkClient;\n import org.apache.helix.mock.participant.DummyProcess.DummyLeaderStandbyStateModelFactory;\n import org.apache.helix.mock.participant.DummyProcess.DummyOnlineOfflineStateModelFactory;\n-import org.apache.helix.mock.participant.MockJobIntf;\n import org.apache.helix.mock.participant.MockMSModelFactory;\n import org.apache.helix.mock.participant.MockSchemataModelFactory;\n import org.apache.helix.mock.participant.MockTransition;",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "sha": "917be1741a266f099729f1dc7f355d9738a58098",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/helix/blob/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java?ref=8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5",
                "deletions": 28,
                "filename": "helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "patch": "@@ -1,28 +0,0 @@\n-package org.apache.helix.mock.participant;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-import org.apache.helix.HelixManager;\n-\n-public interface MockJobIntf {\n-  public void doPreConnectJob(HelixManager manager);\n-\n-  public void doPostConnectJob(HelixManager manager);\n-}",
                "raw_url": "https://github.com/apache/helix/raw/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "sha": "4b637a6abe322d2f26e782b4162a52cf314548e5",
                "status": "removed"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 4,
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "patch": "@@ -96,10 +96,8 @@ public void onMBeanUnRegistered(MBeanServerConnection server,\n     }\n   }\n \n-  @Test(groups = {\n-    \"unitTest\"\n-  })\n-  public void TestReportData() throws InstanceNotFoundException, MalformedObjectNameException,\n+  @Test()\n+  public void testReportData() throws InstanceNotFoundException, MalformedObjectNameException,\n       NullPointerException, IOException, InterruptedException {\n     System.out.println(\"START TestParticipantMonitor\");\n     ParticipantMonitor monitor = new ParticipantMonitor();",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "sha": "5f44b364e439fd8ceb1c14c4cd695eec83355056",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 4,
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "patch": "@@ -23,10 +23,8 @@\n import org.testng.annotations.Test;\n \n public class TestStatCollector {\n-  @Test(groups = {\n-    \"unitTest\"\n-  })\n-  public void TestCollectData() {\n+  @Test()\n+  public void testCollectData() {\n     StatCollector collector = new StatCollector();\n \n     int nPoints = 100;",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "sha": "7a4a941851b34a4476901beb92729588baff0feb",
                "status": "modified"
            },
            {
                "additions": 113,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "changes": 113,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 0,
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "patch": "@@ -0,0 +1,113 @@\n+package org.apache.helix.monitoring;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.Date;\n+\n+import org.apache.helix.BaseDataAccessor;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.ZkUnitTestBase;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n+import org.apache.helix.model.StatusUpdate;\n+import org.apache.helix.model.Error;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestZKPathDataDumpTask extends ZkUnitTestBase {\n+\n+  @Test\n+  public void test() throws Exception {\n+    String className = TestHelper.getTestClassName();\n+    String methodName = TestHelper.getTestMethodName();\n+    String clusterName = className + \"_\" + methodName;\n+    int n = 1;\n+\n+    System.out.println(\"START \" + clusterName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+    TestHelper.setupCluster(clusterName, ZK_ADDR, 12918, // participant port\n+        \"localhost\", // participant name prefix\n+        \"TestDB\", // resource name prefix\n+        1, // resources\n+        2, // partitions per resource\n+        n, // number of nodes\n+        1, // replicas\n+        \"MasterSlave\", true); // do rebalance\n+\n+    HelixDataAccessor accessor =\n+        new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor<ZNRecord>(_gZkClient));\n+    PropertyKey.Builder keyBuilder = accessor.keyBuilder();\n+    BaseDataAccessor<ZNRecord> baseAccessor = accessor.getBaseDataAccessor();\n+\n+    HelixManager manager = mock(HelixManager.class);\n+    when(manager.getHelixDataAccessor()).thenReturn(accessor);\n+    when(manager.getClusterName()).thenReturn(clusterName);\n+\n+    // run dump task without statusUpdates and errors, should not remove any existing statusUpdate/error paths\n+    ZKPathDataDumpTask task = new ZKPathDataDumpTask(manager, 0);\n+    task.run();\n+    PropertyKey controllerStatusUpdateKey = keyBuilder.controllerTaskStatuses();\n+    Assert.assertTrue(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    PropertyKey controllerErrorKey = keyBuilder.controllerTaskErrors();\n+    Assert.assertTrue(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    PropertyKey statusUpdateKey = keyBuilder.stateTransitionStatus(\"localhost_12918\");\n+    Assert.assertTrue(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    PropertyKey errorKey = keyBuilder.stateTransitionErrors(\"localhost_12918\");\n+\n+    // add participant status updates and errors\n+    statusUpdateKey =\n+        keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_0\", \"TestDB0\", \"TestDB0_0\");\n+    accessor.setProperty(statusUpdateKey, new StatusUpdate(new ZNRecord(\"statusUpdate\")));\n+    errorKey =\n+        keyBuilder.stateTransitionError(\"localhost_12918\", \"session_0\", \"TestDB0\", \"TestDB0_0\");\n+    accessor.setProperty(errorKey, new Error(new ZNRecord(\"error\")));\n+\n+    // add controller status updates and errors\n+    controllerStatusUpdateKey = keyBuilder.controllerTaskStatus(\"session_0\", \"TestDB\");\n+    accessor.setProperty(controllerStatusUpdateKey, new StatusUpdate(new ZNRecord(\"controllerStatusUpdate\")));\n+    controllerErrorKey = keyBuilder.controllerTaskError(\"TestDB_error\");\n+    accessor.setProperty(controllerErrorKey, new Error(new ZNRecord(\"controllerError\")));\n+\n+    // run dump task, should remove existing statusUpdate/error paths\n+    task.run();\n+    Assert.assertFalse(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(errorKey.getPath(), 0));\n+\n+    controllerStatusUpdateKey = keyBuilder.controllerTaskStatuses();\n+    Assert.assertTrue(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    controllerErrorKey = keyBuilder.controllerTaskErrors();\n+    Assert.assertTrue(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    statusUpdateKey = keyBuilder.stateTransitionStatus(\"localhost_12918\");\n+    Assert.assertTrue(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    errorKey = keyBuilder.stateTransitionErrors(\"localhost_12918\");\n+\n+    System.out.println(\"END \" + clusterName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "sha": "a3d8ae346fe78e712db34b6098e66dae5b0d87e4",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/pom.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/pom.xml?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "deletions": 0,
                "filename": "pom.xml",
                "patch": "@@ -284,6 +284,11 @@ under the License.\n         <artifactId>testng</artifactId>\n         <version>6.0.1</version>\n       </dependency>\n+      <dependency>\n+        <groupId>org.mockito</groupId>\n+        <artifactId>mockito-all</artifactId>\n+        <version>1.9.5</version>\n+      </dependency>\n     </dependencies>\n   </dependencyManagement>\n ",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/pom.xml",
                "sha": "1f6369d90a73c9ee71a89e3540ae72ff10e5198e",
                "status": "modified"
            }
        ],
        "message": "[HELIX-445] NPE in ZkPathDataDumpTask, rb=21504",
        "parent": "https://github.com/apache/helix/commit/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5",
        "repo": "helix",
        "unit_tests": [
            "TestZKPathDataDumpTask.java"
        ]
    },
    "helix_79301ad": {
        "bug_id": "helix_79301ad",
        "commit": "https://github.com/apache/helix/commit/79301ad19871b1acb179436277b7f34683872b9c",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/helix/blob/79301ad19871b1acb179436277b7f34683872b9c/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java?ref=79301ad19871b1acb179436277b7f34683872b9c",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "patch": "@@ -178,6 +178,9 @@ public void updateResource(ExternalView externalView, IdealState idealState, Sta\n       Map<String, String> idealRecord = idealState.getInstanceStateMap(partition);\n       Map<String, String> externalViewRecord = externalView.getStateMap(partition);\n \n+      if (idealRecord == null) {\n+        idealRecord = Collections.emptyMap();\n+      }\n       if (externalViewRecord == null) {\n         externalViewRecord = Collections.emptyMap();\n       }",
                "raw_url": "https://github.com/apache/helix/raw/79301ad19871b1acb179436277b7f34683872b9c/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "sha": "41c73ed71f50ac069f65961a2ab7f3a1d5227878",
                "status": "modified"
            }
        ],
        "message": "Adding check to avoid possible NPE when recording resource status.",
        "parent": "https://github.com/apache/helix/commit/8b7632ecec3e447bef5201bc1218e1dea2d45938",
        "repo": "helix",
        "unit_tests": [
            "TestResourceMonitor.java"
        ]
    },
    "helix_7b28011": {
        "bug_id": "helix_7b28011",
        "commit": "https://github.com/apache/helix/commit/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 2,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "patch": "@@ -45,6 +45,7 @@\n import com.linkedin.clustermanager.messaging.handling.MessageHandlerFactory;\n import com.linkedin.clustermanager.model.CurrentState;\n import com.linkedin.clustermanager.model.LiveInstance;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n import com.linkedin.clustermanager.monitoring.ZKPathDataDumpTask;\n import com.linkedin.clustermanager.participant.DistClusterControllerElection;\n import com.linkedin.clustermanager.store.PropertyStore;\n@@ -464,7 +465,7 @@ private CallbackHandler createCallBackHandler(String path, Object listener,\n \n   /**\n    * This will be invoked when ever a new session is created<br/>\n-   * \n+   *\n    * case 1: the cluster manager was a participant carry over current state, add\n    * live instance, and invoke message listener; case 2: the cluster manager was\n    * controller and was a leader before do leader election, and if it becomes\n@@ -644,10 +645,13 @@ private void carryOverPreviousCurrentState()\n           logger.info(\"Carrying over old session:\" + previousSessionId\n               + \" resource \" + previousCurrentState.getId()\n               + \" to new session:\" + _sessionId);\n+          String stateModelDefRef = previousCurrentState.getStateModelDefRef();\n+          StateModelDefinition stateModel = _accessor.getProperty(StateModelDefinition.class, PropertyType.STATEMODELDEFS, stateModelDefRef);\n           for (String resourceKey : previousCurrentState\n               .getResourceKeyStateMap().keySet())\n           {\n-            previousCurrentState.setState(resourceKey, \"OFFLINE\");\n+\n+            previousCurrentState.setState(resourceKey, stateModel.getInitialState());\n           }\n           previousCurrentState.setSessionId(_sessionId);\n           _accessor.setProperty(PropertyType.CURRENTSTATES,",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "sha": "be34f93d4c27a5ccac814e31619bd32921b07bc8",
                "status": "modified"
            },
            {
                "additions": 87,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "changes": 103,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 16,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "patch": "@@ -91,23 +91,26 @@ private BestPossibleStateOutput compute(ClusterDataCache cache,\n             currentStateOutput.getCurrentStateMap(resourceGroupName, resource);\n \n         Map<String, String> bestStateForResource;\n+        Set<String> disabledInstancesForResource\n+          = cache.getDisabledInstancesForResource(resource.toString());\n+\n         if (idealState.getIdealStateMode() == IdealStateModeProperty.CUSTOMIZED)\n         {\n-          // TODO add computerBestStateForResourceInCustomizedMode()\n-          //  e.g. exclude non-alive instance\n-          bestStateForResource = idealState.getInstanceStateMap(resource.getResourceKeyName());\n+          Map<String, String> idealStateMap = idealState.getInstanceStateMap(resource.getResourceKeyName());\n+          bestStateForResource = computeCustomizedBestStateForResource(cache, stateModelDef,\n+                                                                       idealStateMap,\n+                                                                       currentStateMap,\n+                                                                       disabledInstancesForResource);\n         }\n         else\n         {\n           List<String> instancePreferenceList\n             = getPreferenceList(cache, resource, idealState, stateModelDef);\n-          Set<String> disabledInstancesForResource\n-            = cache.getDisabledInstancesForResource(resource.toString());\n           bestStateForResource =\n-              computeBestStateForResource(cache, stateModelDef,\n-                                          instancePreferenceList,\n-                                          currentStateMap,\n-                                          disabledInstancesForResource);\n+              computeAutoBestStateForResource(cache, stateModelDef,\n+                                              instancePreferenceList,\n+                                              currentStateMap,\n+                                              disabledInstancesForResource);\n         }\n \n         output.setState(resourceGroupName, resource, bestStateForResource);\n@@ -116,11 +119,20 @@ private BestPossibleStateOutput compute(ClusterDataCache cache,\n     return output;\n   }\n \n-  private Map<String, String> computeBestStateForResource(ClusterDataCache cache,\n-  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  StateModelDefinition stateModelDef,\n-                                                          List<String> instancePreferenceList,\n-                                                          Map<String, String> currentStateMap,\n-                                                          Set<String> disabledInstancesForResource)\n+  /**\n+   * compute best state for resource in AUTO ideal state mode\n+   * @param cache\n+   * @param stateModelDef\n+   * @param instancePreferenceList\n+   * @param currentStateMap\n+   * @param disabledInstancesForResource\n+   * @return\n+   */\n+  private Map<String, String> computeAutoBestStateForResource(ClusterDataCache cache,\n+                                                              StateModelDefinition stateModelDef,\n+                                                              List<String> instancePreferenceList,\n+                                                              Map<String, String> currentStateMap,\n+                                                              Set<String> disabledInstancesForResource)\n   {\n     Map<String, String> instanceStateMap = new HashMap<String, String>();\n \n@@ -143,7 +155,7 @@ else if (disabledInstancesForResource.contains(instance))\n       }\n     }\n \n-    // ideal state is deleted or use customized ideal states\n+    // ideal state is deleted\n     if (instancePreferenceList == null)\n     {\n       return instanceStateMap;\n@@ -207,6 +219,65 @@ else if (\"R\".equals(num))\n     return instanceStateMap;\n   }\n \n+\n+  /**\n+   * compute best state for resource in CUSTOMIZED ideal state mode\n+   * @param cache\n+   * @param stateModelDef\n+   * @param idealStateMap\n+   * @param currentStateMap\n+   * @param disabledInstancesForResource\n+   * @return\n+   */\n+  private Map<String, String> computeCustomizedBestStateForResource(ClusterDataCache cache,\n+                                                                    StateModelDefinition stateModelDef,\n+                                                                    Map<String, String> idealStateMap,\n+                                                                    Map<String, String> currentStateMap,\n+                                                                    Set<String> disabledInstancesForResource)\n+  {\n+    Map<String, String> instanceStateMap = new HashMap<String, String>();\n+\n+    // if the ideal state is deleted, idealStateMap will be null/empty and\n+    // we should drop all resources.\n+    if (currentStateMap != null)\n+    {\n+      for (String instance : currentStateMap.keySet())\n+      {\n+        if (idealStateMap == null || !idealStateMap.containsKey(instance))\n+        {\n+          instanceStateMap.put(instance, \"DROPPED\");\n+        }\n+        else if (disabledInstancesForResource.contains(instance))\n+        {\n+          // if a node is disabled, put it into initial state (OFFLINE)\n+          instanceStateMap.put(instance, stateModelDef.getInitialState());\n+        }\n+      }\n+    }\n+\n+    // ideal state is deleted\n+    if (idealStateMap == null)\n+    {\n+      return instanceStateMap;\n+    }\n+\n+    Map<String, LiveInstance> liveInstancesMap = cache.getLiveInstances();\n+    for (String instance : idealStateMap.keySet())\n+    {\n+      boolean notInErrorState =\n+          currentStateMap == null || !\"ERROR\".equals(currentStateMap.get(instance));\n+\n+      if (liveInstancesMap.containsKey(instance) && notInErrorState\n+          && !disabledInstancesForResource.contains(instance))\n+      {\n+        instanceStateMap.put(instance, idealStateMap.get(instance));\n+      }\n+    }\n+\n+    return instanceStateMap;\n+  }\n+\n+\n   private List<String> getPreferenceList(ClusterDataCache cache, ResourceKey resource,\n                                          IdealState idealState,\n                                          StateModelDefinition stateModelDef)\n@@ -223,8 +294,8 @@ else if (\"R\".equals(num))\n     \t  list.add(instanceName);\n       }\n       return list;\n-\n     }\n+\n     return listField;\n   }\n }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "sha": "9dba454a4ec89b3bdfee8d88ff641f3b03af5400",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 12,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "patch": "@@ -21,10 +21,10 @@\n   public void process(ClusterEvent event) throws Exception\n   {\n     ClusterDataCache cache = event.getAttribute(\"ClusterDataCache\");\n-    Map<String, ResourceGroup> resourceGroupMap = event\n-        .getAttribute(AttributeName.RESOURCE_GROUPS.toString());\n-    MessageGenerationOutput messageGenOutput = event\n-        .getAttribute(AttributeName.MESSAGES_ALL.toString());\n+    Map<String, ResourceGroup> resourceGroupMap =\n+        event.getAttribute(AttributeName.RESOURCE_GROUPS.toString());\n+    MessageGenerationOutput messageGenOutput =\n+        event.getAttribute(AttributeName.MESSAGES_ALL.toString());\n     if (cache == null || resourceGroupMap == null || messageGenOutput == null)\n     {\n       throw new StageException(\"Missing attributes in event:\" + event\n@@ -36,11 +36,12 @@ public void process(ClusterEvent event) throws Exception\n     for (String resourceGroupName : resourceGroupMap.keySet())\n     {\n       ResourceGroup resourceGroup = resourceGroupMap.get(resourceGroupName);\n-      StateModelDefinition stateModelDef = cache.getStateModelDef(resourceGroup.getStateModelDefRef());\n+      StateModelDefinition stateModelDef =\n+          cache.getStateModelDef(resourceGroup.getStateModelDefRef());\n       for (ResourceKey resource : resourceGroup.getResourceKeys())\n       {\n-        List<Message> messages = messageGenOutput.getMessages(\n-            resourceGroupName, resource);\n+        List<Message> messages =\n+            messageGenOutput.getMessages(resourceGroupName, resource);\n         List<Message> selectedMessages = selectMessages(messages, stateModelDef);\n         output.addMessages(resourceGroupName, resource, selectedMessages);\n       }\n@@ -49,22 +50,26 @@ public void process(ClusterEvent event) throws Exception\n   }\n \n   protected List<Message> selectMessages(List<Message> messages,\n-      StateModelDefinition stateModelDef)\n+                                         StateModelDefinition stateModelDef)\n   {\n     if (messages == null || messages.size() == 0)\n     {\n       return Collections.emptyList();\n     }\n-\n+    List<String> stateTransitionPriorityList =\n+        stateModelDef.getStateTransitionPriorityList();\n+    //todo change this and add validation logic so that state model constraints are not violated.\n+    if (stateTransitionPriorityList == null || stateTransitionPriorityList.isEmpty())\n+    {\n+      return messages;\n+    }\n     Set<String> possibleTransitions = new HashSet<String>();\n     for (Message message : messages)\n     {\n       String transition = message.getFromState() + \"-\" + message.getToState();\n       possibleTransitions.add(transition.toUpperCase());\n     }\n     String preferredTransition = null;\n-    List<String> stateTransitionPriorityList = stateModelDef\n-        .getStateTransitionPriorityList();\n \n     for (String transition : stateTransitionPriorityList)\n     {\n@@ -90,5 +95,4 @@ public void process(ClusterEvent event) throws Exception\n     return Collections.emptyList();\n   }\n \n-\n }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "sha": "4e93dea8237b8c9a68a17a533c24067ada64042d",
                "status": "modified"
            },
            {
                "additions": 121,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "changes": 224,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 103,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "patch": "@@ -27,8 +27,7 @@\n \n public class CMStateTransitionHandler implements MessageHandler\n {\n-  private static Logger logger = Logger\n-      .getLogger(CMStateTransitionHandler.class);\n+  private static Logger logger = Logger.getLogger(CMStateTransitionHandler.class);\n   private final StateModel _stateModel;\n   StatusUpdateUtil _statusUpdateUtil;\n   private final StateModelParser _transitionMethodFinder;\n@@ -48,26 +47,28 @@ private boolean isNullOrEmpty(String data)\n \n   private boolean validateMessage(Message message)\n   {\n-    boolean isValid = isNullOrEmpty(message.getFromState())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getStateUnitKey())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getStateModelDef());\n+    boolean isValid =\n+        isNullOrEmpty(message.getFromState()) || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getStateUnitKey())\n+            || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getStateModelDef());\n     return !isValid;\n   }\n \n-  private void prepareMessageExecution(ClusterManager manager, Message message)\n-      throws ClusterManagerException\n+  private void prepareMessageExecution(ClusterManager manager, Message message) throws ClusterManagerException\n   {\n     if (!validateMessage(message))\n     {\n-      String errorMessage = \"Invalid Message, ensure that message: \" + message\n-          + \" has all the required fields: \"\n-          + Arrays.toString(Message.Attributes.values());\n-\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, manager.getDataAccessor());\n+      String errorMessage =\n+          \"Invalid Message, ensure that message: \" + message\n+              + \" has all the required fields: \"\n+              + Arrays.toString(Message.Attributes.values());\n+\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 manager.getDataAccessor());\n       logger.error(errorMessage);\n       throw new ClusterManagerException(errorMessage);\n     }\n@@ -79,26 +80,24 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n     String fromState = message.getFromState();\n     String toState = message.getToState();\n \n-    List<StateModelDefinition> stateModelDefs = accessor.getChildValues(StateModelDefinition.class,\n-                                                                        PropertyType.STATEMODELDEFS);\n+    List<StateModelDefinition> stateModelDefs =\n+        accessor.getChildValues(StateModelDefinition.class, PropertyType.STATEMODELDEFS);\n \n-    String initStateValue = \"OFFLINE\";\n-    if (stateModelDefs != null)\n-    {\n-      StateModelDefinition stateModelDef = lookupStateModel(\n-          message.getStateModelDef(), stateModelDefs);\n+    StateModelDefinition stateModelDef =\n+        lookupStateModel(message.getStateModelDef(), stateModelDefs);\n \n-      if (stateModelDef != null)\n-      {\n-        initStateValue = stateModelDef.getInitialState();\n-      }\n+    String initStateValue;\n+    if (stateModelDef == null)\n+    {\n+      throw new ClusterManagerException(\"No State Model Defined for \"+ message.getStateModelDef());\n     }\n-\n-    CurrentState currentState = accessor.getProperty(CurrentState.class,\n-                                                     PropertyType.CURRENTSTATES,\n-                                                     instanceName,\n-                                                     manager.getSessionId(),\n-                                                     stateUnitGroup);\n+    initStateValue = stateModelDef.getInitialState();\n+    CurrentState currentState =\n+        accessor.getProperty(CurrentState.class,\n+                             PropertyType.CURRENTSTATES,\n+                             instanceName,\n+                             manager.getSessionId(),\n+                             stateUnitGroup);\n \n     // Set an empty current state record if it is null\n     if (currentState == null)\n@@ -113,10 +112,9 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n     }\n \n     /**\n-     * For resource unit that does not have a state, initialize it to OFFLINE\n-     * If current state does not have a state model def, set it.\n-     * Do the two updates together, otherwise controller may view a current state\n-     * with a NULL state model def\n+     * For resource unit that does not have a state, initialize it to OFFLINE If current\n+     * state does not have a state model def, set it. Do the two updates together,\n+     * otherwise controller may view a current state with a NULL state model def\n      */\n \n     CurrentState currentStateDelta = new CurrentState(stateUnitGroup);\n@@ -125,8 +123,8 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n       currentStateDelta.setState(stateUnitKey, initStateValue);\n       currentState.setState(stateUnitKey, initStateValue);\n \n-      logger.info(\"Setting initial state for partition: \" + stateUnitKey\n-          + \" to \" + initStateValue);\n+      logger.info(\"Setting initial state for partition: \" + stateUnitKey + \" to \"\n+          + initStateValue);\n     }\n \n     // Set the state model def to current state\n@@ -136,7 +134,7 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n       if (message.getStateModelDef() != null)\n       {\n         logger.info(\"Setting state model def on current state: \"\n-                   + message.getStateModelDef());\n+            + message.getStateModelDef());\n         currentStateDelta.setStateModelDefRef(message.getStateModelDef());\n       }\n     }\n@@ -148,29 +146,29 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n \n     // Verify the fromState and current state of the stateModel\n     String state = currentState.getState(stateUnitKey);\n-    if (!fromState.equals(\"*\") && (fromState == null || !fromState.equalsIgnoreCase(state)))\n+    if (!fromState.equals(\"*\")\n+        && (fromState == null || !fromState.equalsIgnoreCase(state)))\n     {\n-      String errorMessage = \"Current state of stateModel does not match the fromState in Message\"\n-          + \", Current State:\"\n-          + state\n-          + \", message expected:\"\n-          + fromState\n-          + \", partition: \"\n-          + message.getStateUnitKey()\n-          + \", from: \"\n-          + message.getMsgSrc()\n-          + \", to: \" + message.getTgtName();\n-\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, accessor);\n+      String errorMessage =\n+          \"Current state of stateModel does not match the fromState in Message\"\n+              + \", Current State:\" + state + \", message expected:\" + fromState\n+              + \", partition: \" + message.getStateUnitKey() + \", from: \"\n+              + message.getMsgSrc() + \", to: \" + message.getTgtName();\n+\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 accessor);\n       logger.error(errorMessage);\n       throw new ClusterManagerException(errorMessage);\n     }\n   }\n \n-  void postExecutionMessage(ClusterManager manager, Message message,\n-      NotificationContext context, CMTaskResult taskResult, Exception exception)\n-      throws InterruptedException\n+  void postExecutionMessage(ClusterManager manager,\n+                            Message message,\n+                            NotificationContext context,\n+                            CMTaskResult taskResult,\n+                            Exception exception) throws InterruptedException\n   {\n     ClusterDataAccessor accessor = manager.getDataAccessor();\n     try\n@@ -181,20 +179,20 @@ void postExecutionMessage(ClusterManager manager, Message message,\n \n       String fromState = message.getFromState();\n       String toState = message.getToState();\n-      CurrentState currentState = accessor.getProperty(CurrentState.class,\n-                                                       PropertyType.CURRENTSTATES,\n-                                                       instanceName,\n-                                                       manager.getSessionId(),\n-                                                       stateUnitGroup);\n+      CurrentState currentState =\n+          accessor.getProperty(CurrentState.class,\n+                               PropertyType.CURRENTSTATES,\n+                               instanceName,\n+                               manager.getSessionId(),\n+                               stateUnitGroup);\n \n       if (currentState != null)\n       {\n-//        map = currentState.getMapField(stateUnitKey);\n+        // map = currentState.getMapField(stateUnitKey);\n       }\n       else\n       {\n-        logger\n-            .warn(\"currentState is null. Storage node should be working with file based cluster manager.\");\n+        logger.warn(\"currentState is null. Storage node should be working with file based cluster manager.\");\n       }\n \n       // TODO verify that fromState is same as currentState this task\n@@ -213,22 +211,22 @@ void postExecutionMessage(ClusterManager manager, Message message,\n       }\n       else\n       {\n-        StateTransitionError error = new StateTransitionError(\n-            StateTransitionError.ErrorCode.INTERNAL, exception);\n+        StateTransitionError error =\n+            new StateTransitionError(StateTransitionError.ErrorCode.INTERNAL, exception);\n         _stateModel.rollbackOnError(message, context, error);\n         currentStateDelta.setState(stateUnitKey, \"ERROR\");\n         _stateModel.updateState(\"ERROR\");\n       }\n \n       currentStateDelta.setResourceGroup(stateUnitKey, message.getStateUnitGroup());\n \n-\n       if (taskResult.isSucess() && toState.equals(\"DROPPED\"))\n       {\n         // for \"OnOfflineToDROPPED\" message, we need to remove the resource key\n         // record from\n         // the current state of the instance because the resource key is dropped.\n-        ZNRecordDelta delta = new ZNRecordDelta(currentStateDelta.getRecord(), MERGEOPERATION.SUBSTRACT);\n+        ZNRecordDelta delta =\n+            new ZNRecordDelta(currentStateDelta.getRecord(), MERGEOPERATION.SUBSTRACT);\n         List<ZNRecordDelta> deltaList = new ArrayList<ZNRecordDelta>();\n         deltaList.add(delta);\n         CurrentState currentStateUpdate = new CurrentState(stateUnitGroup);\n@@ -248,22 +246,25 @@ void postExecutionMessage(ClusterManager manager, Message message,\n                                 manager.getSessionId(),\n                                 stateUnitGroup);\n       }\n-    } catch (Exception e)\n+    }\n+    catch (Exception e)\n     {\n       logger.error(\"Error when updating the state \", e);\n-      StateTransitionError error = new StateTransitionError(\n-          StateTransitionError.ErrorCode.FRAMEWORK, e);\n+      StateTransitionError error =\n+          new StateTransitionError(StateTransitionError.ErrorCode.FRAMEWORK, e);\n       _stateModel.rollbackOnError(message, context, error);\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class, e,\n-          \"Error when update the state \", accessor);\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 e,\n+                                 \"Error when update the state \",\n+                                 accessor);\n     }\n   }\n \n   // TODO: decide if handleMessage() should return a value CMTaskResult; this\n   // part need to integrate with\n   // send reply message\n-  public CMTaskResult handleMessageInternal(Message message,\n-      NotificationContext context)\n+  public CMTaskResult handleMessageInternal(Message message, NotificationContext context)\n   {\n     synchronized (_stateModel)\n     {\n@@ -273,13 +274,16 @@ public CMTaskResult handleMessageInternal(Message message,\n       String instanceName = manager.getInstanceName();\n       try\n       {\n-        _statusUpdateUtil.logInfo(message, CMStateTransitionHandler.class,\n-            \"Message handling task begin execute\", accessor);\n+        _statusUpdateUtil.logInfo(message,\n+                                  CMStateTransitionHandler.class,\n+                                  \"Message handling task begin execute\",\n+                                  accessor);\n         message.setExecuteStartTimeStamp(new Date().getTime());\n         try\n         {\n           prepareMessageExecution(manager, message);\n-        } catch (ClusterManagerException e)\n+        }\n+        catch (ClusterManagerException e)\n         {\n           taskResult.setSuccess(false);\n           taskResult.setMessage(e.getMessage());\n@@ -294,11 +298,11 @@ public CMTaskResult handleMessageInternal(Message message,\n         }\n         catch (Exception e)\n         {\n-          String errorMessage = \"Exception while executing a state transition task. \"\n-              + e;\n+          String errorMessage = \"Exception while executing a state transition task. \" + e;\n \n           // Hack: avoid throwing mock exception for testing code\n-          if (e instanceof InvocationTargetException && e.getCause().getMessage().startsWith(\"IGNORABLE\"))\n+          if (e instanceof InvocationTargetException\n+              && e.getCause().getMessage().startsWith(\"IGNORABLE\"))\n           {\n             logger.error(errorMessage + \". Cause:\" + e.getCause().getMessage());\n           }\n@@ -322,51 +326,64 @@ public CMTaskResult handleMessageInternal(Message message,\n       }\n       catch (InterruptedException e)\n       {\n-        _statusUpdateUtil.logError(message, CMStateTransitionHandler.class, e,\n-            \"State transition interrupted\", accessor);\n+        _statusUpdateUtil.logError(message,\n+                                   CMStateTransitionHandler.class,\n+                                   e,\n+                                   \"State transition interrupted\",\n+                                   accessor);\n         logger.info(\"Message \" + message.getMsgId() + \" is interrupted\");\n \n-        StateTransitionError error = new StateTransitionError(\n-            StateTransitionError.ErrorCode.FRAMEWORK, e);\n+        StateTransitionError error =\n+            new StateTransitionError(StateTransitionError.ErrorCode.FRAMEWORK, e);\n         _stateModel.rollbackOnError(message, context, error);\n         return taskResult;\n       }\n     }\n   }\n \n   private void invoke(ClusterDataAccessor accessor,\n-      NotificationContext context, CMTaskResult taskResult, Message message)\n-      throws IllegalAccessException, InvocationTargetException,\n+                      NotificationContext context,\n+                      CMTaskResult taskResult,\n+                      Message message) throws IllegalAccessException,\n+      InvocationTargetException,\n       InterruptedException\n   {\n     Method methodToInvoke = null;\n     String fromState = message.getFromState();\n     String toState = message.getToState();\n-    methodToInvoke = _transitionMethodFinder.getMethodForTransition(\n-        _stateModel.getClass(), fromState, toState, new Class[]\n-        { Message.class, NotificationContext.class });\n-    _statusUpdateUtil.logInfo(message, CMStateTransitionHandler.class,\n-        \"Message handling invoking\", accessor);\n+    methodToInvoke =\n+        _transitionMethodFinder.getMethodForTransition(_stateModel.getClass(),\n+                                                       fromState,\n+                                                       toState,\n+                                                       new Class[] { Message.class,\n+                                                           NotificationContext.class });\n+    _statusUpdateUtil.logInfo(message,\n+                              CMStateTransitionHandler.class,\n+                              \"Message handling invoking\",\n+                              accessor);\n     if (methodToInvoke != null)\n     {\n-      methodToInvoke.invoke(_stateModel, new Object[]\n-      { message, context });\n+      methodToInvoke.invoke(_stateModel, new Object[] { message, context });\n       taskResult.setSuccess(true);\n-    } else\n+    }\n+    else\n     {\n-      String errorMessage = \"Unable to find method for transition from \"\n-          + fromState + \" to \" + toState + \"in \" + _stateModel.getClass();\n+      String errorMessage =\n+          \"Unable to find method for transition from \" + fromState + \" to \" + toState\n+              + \"in \" + _stateModel.getClass();\n       logger.error(errorMessage);\n       taskResult.setSuccess(false);\n \n       System.out.println(errorMessage);\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, accessor);\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 accessor);\n     }\n   }\n \n   private StateModelDefinition lookupStateModel(String stateModelDefRef,\n-      List<StateModelDefinition> stateModelDefs)\n+                                                List<StateModelDefinition> stateModelDefs)\n   {\n     for (StateModelDefinition def : stateModelDefs)\n     {\n@@ -379,8 +396,9 @@ private StateModelDefinition lookupStateModel(String stateModelDefRef,\n   }\n \n   @Override\n-  public void handleMessage(Message message, NotificationContext context,\n-      Map<String, String> resultMap) throws InterruptedException\n+  public void handleMessage(Message message,\n+                            NotificationContext context,\n+                            Map<String, String> resultMap) throws InterruptedException\n   {\n     handleMessageInternal(message, context);\n ",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "sha": "f17bd2b00cbfb5539cbba733a33b32d26cac8e1d",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 6,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "patch": "@@ -6,7 +6,6 @@\n \n import org.apache.log4j.Logger;\n \n-import com.linkedin.clustermanager.ClusterManagerException;\n import com.linkedin.clustermanager.ZNRecord;\n import com.linkedin.clustermanager.ZNRecordDecorator;\n \n@@ -117,11 +116,13 @@ public boolean isValid()\n       _logger.error(\"CurrentState does not contain StatesPriorityList, state model : \" + _record.getId());\n       return false;\n     }\n-    if(_record.getListField(StateModelDefinitionProperty.STATE_TRANSITION_PRIORITYLIST.toString()) == null)\n-    {\n-      _logger.error(\"CurrentState does not contain StateTransitionPriorityList, state model : \" + _record.getId());\n-      return false;\n-    }\n+\n+    // STATE_TRANSITION_PRIORITYLIST is optional\n+//    if(_record.getListField(StateModelDefinitionProperty.STATE_TRANSITION_PRIORITYLIST.toString()) == null)\n+//    {\n+//      _logger.error(\"CurrentState does not contain StateTransitionPriorityList, state model : \" + _record.getId());\n+//      return false;\n+//    }\n     return true;\n   }\n }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "sha": "0e43b79f6443013fa0427eed8c2bf0f5bbceafb8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 2,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "patch": "@@ -1,6 +1,5 @@\n package com.linkedin.clustermanager.tools;\n \n-import java.io.IOException;\n import java.io.InputStream;\n import java.util.Properties;\n \n@@ -21,7 +20,7 @@ public PropertiesReader(String propertyFileName)\n           .getResourceAsStream(propertyFileName);\n       _properties.load(stream);\n     }\n-    catch (IOException e)\n+    catch (Exception e)\n     {\n       String errMsg = \"could not open properties file:\" + propertyFileName;\n       // LOG.error(errMsg, e);",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "sha": "e3941c367302c29fb1dc610957e8c6d3f28ffb7b",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 3,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "patch": "@@ -839,7 +839,7 @@ else if (_command._commandType == CommandType.VERIFY)\n             }\n             else\n             {\n-//              logger.debug(\"result:\" + result + \", diff:\" + diff);\n+//              logger.error(\"result:\" + result + \", diff:\" + diff);\n             }\n           }\n           else if (_command._commandType == CommandType.START)\n@@ -848,6 +848,7 @@ else if (_command._commandType == CommandType.START)\n             Thread thread = _command._nodeOpArg._thread;\n             thread.start();\n \n+            result = true;\n             _command._finishTimestamp = System.currentTimeMillis();\n             logger.info(\"result:\" + result + \", \" + _command.toString());\n             _testResults.put(_command, true);\n@@ -862,15 +863,16 @@ else if (_command._commandType == CommandType.STOP)\n             thread.interrupt();\n \n             // System.err.println(\"stop \" + _command._nodeOpArg._manager.getInstanceName());\n+            result = true;\n             _command._finishTimestamp = System.currentTimeMillis();\n             logger.info(\"result:\" + result + \", \" + _command.toString());\n             _testResults.put(_command, true);\n             break;\n           }\n           else\n           {\n-            logger.error(\"unsupport command\");\n-            break;\n+            throw new IllegalArgumentException(\"Unsupport command type (was \"\n+                                             + _command._commandType + \")\");\n           }\n \n           Thread.sleep(SLEEP_TIME);\n@@ -885,6 +887,11 @@ else if (_command._commandType == CommandType.STOP)\n       }\n       finally\n       {\n+        if (result == false)\n+        {\n+          _command._finishTimestamp = System.currentTimeMillis();\n+          logger.error(\"result:\" + result + \", diff: \" + diff);\n+        }\n         _countDown.countDown();\n       }\n     }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "sha": "60303ba3434f8732446f06635d39466b062fa687",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 2,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "patch": "@@ -10,6 +10,8 @@\n import com.linkedin.clustermanager.messaging.handling.CMStateTransitionHandler;\n import com.linkedin.clustermanager.model.Message;\n import com.linkedin.clustermanager.model.Message.MessageType;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n+import com.linkedin.clustermanager.tools.StateModelConfigGenerator;\n \n public class TestCMTaskExecutor\n {\n@@ -36,8 +38,13 @@ public void testCMTaskExecutor() throws Exception\n     NotificationContext context;\n     executor.registerMessageHandlerFactory(\n         MessageType.TASK_REPLY.toString(), new AsyncCallbackService());\n-    String clusterName =\" testcluster\";\n-    context = new NotificationContext(new MockManager(clusterName));\n+    MockManager manager = new MockManager(\"testcluster\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMStateTransitionHandler handler = new CMStateTransitionHandler(stateModel);\n     executor.scheduleTask(message, handler, context);\n     while (!executor.isDone(msgId))",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "sha": "2d54ef74a4b27296919389993d64bf944d97002c",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "changes": 38,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 11,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "patch": "@@ -1,5 +1,7 @@\n package com.linkedin.clustermanager;\n \n+import java.util.Date;\n+\n import org.testng.AssertJUnit;\n import org.testng.annotations.Test;\n \n@@ -10,14 +12,16 @@\n import com.linkedin.clustermanager.messaging.handling.CMTask;\n import com.linkedin.clustermanager.model.Message;\n import com.linkedin.clustermanager.model.Message.MessageType;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n+import com.linkedin.clustermanager.tools.StateModelConfigGenerator;\n \n public class TestCMTaskHandler\n {\n-  @Test ()\n+  @Test()\n   public void testInvocation() throws Exception\n   {\n-    System.out.println(\"START TestCMTaskHandler.testInvocation()\");\n-    Message message = new Message(MessageType.STATE_TRANSITION,\"Some unique id\");\n+    System.out.println(\"START TestCMTaskHandler.testInvocation() at \"+ new Date(System.currentTimeMillis()));\n+    Message message = new Message(MessageType.STATE_TRANSITION, \"Some unique id\");\n     message.setSrcName(\"cm-instance-0\");\n     message.setTgtSessionId(\"1234\");\n     message.setFromState(\"Offline\");\n@@ -30,20 +34,25 @@ public void testInvocation() throws Exception\n     MockStateModel stateModel = new MockStateModel();\n     NotificationContext context;\n     CMStateTransitionHandler stHandler = new CMStateTransitionHandler(stateModel);\n-    String clusterName=\"clusterName\";\n-    context = new NotificationContext(new MockManager(clusterName));\n+    MockManager manager = new MockManager(\"clusterName\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMTask handler;\n     handler = new CMTask(message, context, stHandler, null);\n     handler.call();\n     AssertJUnit.assertTrue(stateModel.stateModelInvoked);\n-    System.out.println(\"END TestCMTaskHandler.testInvocation()\");\n+    System.out.println(\"END TestCMTaskHandler.testInvocation() at \" + new Date(System.currentTimeMillis()));\n   }\n \n-  @Test ()\n+  @Test()\n   public void testInvocationAnnotated() throws Exception\n   {\n-    System.out.println(\"START TestCMTaskHandler.testInvocationAnnotated()\");\n-    Message message = new Message(MessageType.STATE_TRANSITION,\"Some unique id\");\n+    System.out.println(\"START TestCMTaskHandler.testInvocationAnnotated() at \" + new Date(System.currentTimeMillis()));\n+    Message message = new Message(MessageType.STATE_TRANSITION, \"Some unique id\");\n     message.setSrcName(\"cm-instance-0\");\n     message.setTgtSessionId(\"1234\");\n     message.setFromState(\"Offline\");\n@@ -55,14 +64,21 @@ public void testInvocationAnnotated() throws Exception\n     message.setStateModelDef(\"MasterSlave\");\n     MockStateModelAnnotated stateModel = new MockStateModelAnnotated();\n     NotificationContext context;\n-    context = new NotificationContext(new MockManager());\n+\n+    MockManager manager = new MockManager(\"clusterName\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMTask handler;\n     CMStateTransitionHandler stHandler = new CMStateTransitionHandler(stateModel);\n \n     handler = new CMTask(message, context, stHandler, null);\n     handler.call();\n     AssertJUnit.assertTrue(stateModel.stateModelInvoked);\n-    System.out.println(\"END TestCMTaskHandler.testInvocationAnnotated()\");\n+    System.out.println(\"END TestCMTaskHandler.testInvocationAnnotated() at \"+ new Date(System.currentTimeMillis()));\n   }\n \n }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "sha": "59054b715fba37cffe05d2b0782bbfc71b7499b5",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 3,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "patch": "@@ -378,19 +378,25 @@ else if (map1 != null && map2 == null)\n     return set;\n   }\n \n+  public static void verifyWithTimeout(String verifierName, Object... args)\n+  {\n+    verifyWithTimeout(verifierName, 30 * 1000, args);\n+  }\n+\n   /**\n    * generic method for verification with a timeout\n    * @param verifierName\n    * @param args\n    */\n-  public static void verifyWithTimeout(String verifierName, Object... args)\n+  public static void verifyWithTimeout(String verifierName, long timeout, Object... args)\n   {\n     final long sleepInterval = 1000;  // in ms\n+    final int loop = (int) (timeout / sleepInterval) + 1;\n     try\n     {\n       boolean result = false;\n       int i = 0;\n-      for (; i < 30; i++)\n+      for (; i < loop; i++)\n       {\n         Thread.sleep(sleepInterval);\n         // verifier should be static method\n@@ -483,7 +489,7 @@ public static boolean verifyBestPossAndExtViewExtended(String resourceGroupName,\n       }\n \n       BestPossibleStateOutput bestPossOutput =\n-        calcBestPossState(resourceGroupName, partitions, stateModelName, clusterName, accessor);\n+        TestHelper.calcBestPossState(resourceGroupName, partitions, stateModelName, clusterName, accessor);\n \n //      System.out.println(\"extView:\" + extView.getMapFields());\n //      System.out.println(\"BestPoss:\" + bestPossOutput);",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "sha": "af5e541f3c846826d4260f7bc5ca152e0e96e228",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 2,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "patch": "@@ -30,7 +30,7 @@ public void afterClass()\n   \t_zkClient.close();\n   }\n \n-  @Test (groups = {\"integrationTest\"})\n+  @Test ()\n   public void testCMUsingDifferentParams() throws Exception\n   {\n     System.out.println(\"START \" + getShortClassName() + \" at \"\n@@ -62,7 +62,7 @@ public void testCMUsingDifferentParams() throws Exception\n             }\n \n             TestDriver.startController(uniqTestName);\n-            TestDriver.verifyCluster(uniqTestName);\n+            TestDriver.verifyCluster(uniqTestName, 1000);\n             TestDriver.stopCluster(uniqTestName);\n \n             System.out.println(\"END \" + uniqTestName + \" at \"",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "sha": "ecfbe64c661e94153c7ed872ae6fd0e27068c239",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 8,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "patch": "@@ -13,28 +13,29 @@\n public class TestCMWithFailParticipant extends ZkIntegrationTestBase\n {\n   ZkClient _zkClient;\n-  @BeforeClass (groups = {\"integrationTest\"})\n+\n+  @BeforeClass ()\n   public void beforeClass() throws Exception\n   {\n   \t_zkClient = new ZkClient(ZK_ADDR);\n   \t_zkClient.setZkSerializer(new ZNRecordSerializer());\n   }\n-  \n-  \n+\n+\n \t@AfterClass\n   public void afterClass()\n   {\n   \t_zkClient.close();\n   }\n-\t\n-  @Test (groups = {\"integrationTest\"})\n+\n+  @Test ()\n   public void testCMWithFailParticipant() throws Exception\n   {\n     int numDb = 1;\n     int numPartitionsPerDb = 10;\n     int numNode = 5;\n     int replica = 3;\n-    \n+\n     String uniqTestName = \"TestFail_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n         + numNode + \"_r\" + replica;\n     System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n@@ -46,9 +47,9 @@ public void testCMWithFailParticipant() throws Exception\n       TestDriver.startDummyParticipant(uniqTestName, i);\n     }\n     TestDriver.startController(uniqTestName);\n-    \n+\n     TestDriver.stopDummyParticipant(uniqTestName, 2000, 0);\n-    TestDriver.verifyCluster(uniqTestName);\n+    TestDriver.verifyCluster(uniqTestName, 3000);\n     TestDriver.stopCluster(uniqTestName);\n \n     System.out.println(\"END \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "sha": "aa944df8e312ceb67148c36022cf5286e4bc4583",
                "status": "modified"
            },
            {
                "additions": 42,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "changes": 46,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 4,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "patch": "@@ -23,15 +23,14 @@ public void beforeClass() throws Exception\n   \t_zkClient.setZkSerializer(new ZNRecordSerializer());\n   }\n \n-\n \t@AfterClass\n   public void afterClass()\n   {\n   \t_zkClient.close();\n   }\n \n   @Test\n-  public void testCustomIdealState() throws Exception\n+  public void testBasic() throws Exception\n   {\n \n     int numDb = 2;\n@@ -40,7 +39,7 @@ public void testCustomIdealState() throws Exception\n     int replica = 3;\n \n     String uniqTestName = \"TestCustomIS_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n-        + numNode + \"_r\" + replica;\n+        + numNode + \"_r\" + replica + \"_basic\";\n     System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n \n     TestDriver.setupClusterWithoutRebalance(uniqTestName, _zkClient, numDb, numPartitionsPerDb, numNode, replica);\n@@ -52,12 +51,51 @@ public void testCustomIdealState() throws Exception\n     TestDriver.startController(uniqTestName);\n \n     TestDriver.setIdealState(uniqTestName, 2000, 50);\n+    TestDriver.verifyCluster(uniqTestName, 3000);\n \n-    TestDriver.verifyCluster(uniqTestName);\n     TestDriver.stopCluster(uniqTestName);\n \n+    System.out.println(\"STOP \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+  }\n+\n+  @Test\n+  public void testNonAliveInstances() throws Exception\n+  {\n+    int numDb = 2;\n+    int numPartitionsPerDb = 50;\n+    int numNode = 5;\n+    int replica = 3;\n+\n+    String uniqTestName = \"TestCustomIS_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n+        + numNode + \"_r\" + replica + \"_nonalive\";\n+    System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+    TestDriver.setupClusterWithoutRebalance(uniqTestName, _zkClient, numDb, numPartitionsPerDb, numNode, replica);\n+\n+    for (int i = 0; i < numNode/2; i++)\n+    {\n+      TestDriver.startDummyParticipant(uniqTestName, i);\n+    }\n+\n+    TestDriver.startController(uniqTestName);\n+    TestDriver.setIdealState(uniqTestName, 0, 100);\n+\n+    // wait some time for customized ideal state being populated\n+    Thread.sleep(1000);\n+\n+    // start the rest of participants after ideal state is set\n+    for (int i = numNode/2; i < numNode; i++)\n+    {\n+      TestDriver.startDummyParticipant(uniqTestName, i);\n+    }\n+\n+    TestDriver.verifyCluster(uniqTestName, 4000);\n+\n+    TestDriver.stopCluster(uniqTestName);\n \n     System.out.println(\"STOP \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+\n   }\n \n+  // TODO add a test case that verify (in case of node failure) best possible state is a subset of ideal state\n }",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "sha": "fd244d826967d02d88fa7444f544b6ce4b35979e",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "changes": 81,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "deletions": 65,
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "patch": "@@ -10,7 +10,6 @@\n import java.util.concurrent.ConcurrentHashMap;\n \n import org.apache.log4j.Logger;\n-import org.testng.AssertJUnit;\n \n import com.linkedin.clustermanager.ClusterManager;\n import com.linkedin.clustermanager.PropertyType;\n@@ -36,11 +35,7 @@\n public class TestDriver\n {\n   private static Logger LOG = Logger.getLogger(TestDriver.class);\n-  private static final String ZK_ADDR = ZkIntegrationTestBase.ZK_ADDR; // \"localhost:2183\";\n-  // private static final int DEFAULT_SESSION_TIMEOUT = 30000;\n-  // private static final int DEFAULT_CONNECTION_TIMEOUT = Integer.MAX_VALUE;\n-  // private static final ZkClient _zkClient = new ZkClient(ZK_ADDR, DEFAULT_SESSION_TIMEOUT,\n-  //    DEFAULT_CONNECTION_TIMEOUT, new ZNRecordSerializer());\n+  private static final String ZK_ADDR = ZkIntegrationTestBase.ZK_ADDR;\n \n   private static final String CLUSTER_PREFIX = \"TestDriver\";\n   private static final String STATE_MODEL = \"MasterSlave\";\n@@ -219,8 +214,10 @@ public static void startController(String uniqTestName, int[] nodeIds) throws Ex\n     }\n   }\n \n-  public static void verifyCluster(String uniqTestName) throws Exception\n+  public static void verifyCluster(String uniqTestName, long at) throws Exception\n   {\n+    Thread.sleep(at);\n+\n     if (!_testInfoMap.containsKey(uniqTestName))\n     {\n       String errMsg = \"test cluster hasn't been setup:\" + uniqTestName;\n@@ -231,47 +228,21 @@ public static void verifyCluster(String uniqTestName) throws Exception\n     String clusterName = testInfo._clusterName;\n     ZkClient zkClient = testInfo._zkClient;\n \n-    // verify external view\n-    String liveInstancePath = \"/\" + clusterName + \"/\"\n-        + PropertyType.LIVEINSTANCES.toString();\n-    List<String> liveInstances = zkClient.getChildren(liveInstancePath);\n-    String configInstancePath = \"/\" + clusterName + \"/\" + PropertyType.CONFIGS.toString();\n-    List<String> failInstances = zkClient.getChildren(configInstancePath);\n-    failInstances.removeAll(liveInstances);\n-\n-    List<TestCommand> commandList = new ArrayList<TestCommand>();\n \n     for (int i = 0; i < testInfo._numDb; i++)\n     {\n-      // String idealStatePath = \"/\" + clusterName + \"/\" + PropertyType.IDEALSTATES.toString()\n-      //    + \"/\" + TEST_DB_PREFIX + i;\n-      // ZNRecord idealState = _zkClient.<ZNRecord> readData(idealStatePath);\n       String dbName = TEST_DB_PREFIX + i;\n-      ZNRecord idealState = testInfo._idealStateMap.get(dbName);\n-\n-      ZNRecord externalView = calculateExternalViewFromIdealState(idealState, failInstances);\n-\n-      String externalViewPath = \"/\" + clusterName + \"/\"\n-          + PropertyType.EXTERNALVIEW.toString() + \"/\" + TEST_DB_PREFIX + i;\n-\n-      ZnodeOpArg arg = new ZnodeOpArg(externalViewPath, ZnodePropertyType.ZNODE, \"==\");\n-      TestCommand command = new TestCommand(CommandType.VERIFY, new TestTrigger(1000, 60 * 1000,\n-          externalView), arg);\n-      commandList.add(command);\n-    }\n-\n-    Map<TestCommand, Boolean> results = TestExecutor.executeTest(commandList, ZK_ADDR);\n-    for (Map.Entry<TestCommand, Boolean> entry : results.entrySet())\n-    {\n-      System.out.println(entry.getValue() + \":\" + entry.getKey());\n-      // LOG.info(entry.getValue() + \":\" + entry.getKey());\n-      AssertJUnit.assertTrue(entry.getValue());\n+      TestHelper.verifyWithTimeout(\"verifyBestPossAndExtViewExtended\",\n+                                   60 * 1000,\n+                                   dbName,\n+                                   testInfo._numPartitionsPerDb,\n+                                   \"MasterSlave\",\n+                                   TestHelper.<String>setOf(clusterName),\n+                                   zkClient,\n+                                   null,\n+                                   null,\n+                                   null);\n     }\n-\n-    // LOG.info(\"verify cluster:\" + clusterName + \", result:\" + result);\n-    // System.err.println(\"verify cluster:\" + clusterName + \", result:\" +\n-    // result);\n-    // TODO verify other states\n   }\n \n   public static void stopCluster(String uniqTestName) throws Exception\n@@ -331,7 +302,8 @@ public static void stopDummyParticipant(String uniqTestName, long at, int nodeId\n     {\n       String errMsg = \"Dummy participant:\" + failHost + \" seems not running\";\n       LOG.error(errMsg);\n-    } else\n+    }\n+    else\n     {\n       // System.err.println(\"try to stop participant: \" + result._manager.getInstanceName());\n       NodeOpArg arg = new NodeOpArg(result._manager, result._thread);\n@@ -342,7 +314,6 @@ public static void stopDummyParticipant(String uniqTestName, long at, int nodeId\n     }\n   }\n \n-\n   public static void setIdealState(String uniqTestName, long at, int percentage)\n   throws Exception\n   {\n@@ -400,26 +371,6 @@ public static void setIdealState(String uniqTestName, long at, int percentage)\n \n   }\n \n-  private static ZNRecord calculateExternalViewFromIdealState(ZNRecord idealState,\n-      List<String> failInstances)\n-  {\n-    ZNRecord externalView = new ZNRecord(idealState.getId());\n-\n-    // externalView.setId();\n-\n-    for (Map.Entry<String, Map<String, String>> mapEntry : idealState.getMapFields().entrySet())\n-    {\n-\n-      for (String failInstance : failInstances)\n-      {\n-        mapEntry.getValue().remove(failInstance);\n-      }\n-      externalView.setMapField(mapEntry.getKey(), mapEntry.getValue());\n-    }\n-\n-    return externalView;\n-  }\n-\n   private static List<String[]> findAllUnfinishPairs(ZNRecord cur, ZNRecord dest)\n   {\n     // find all (host, resource) pairs that haven't reached destination state",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "sha": "9ba90455e7c59dc851bf2153a3b66ec4cd99e06d",
                "status": "modified"
            }
        ],
        "message": "Fixed the following issues:\nDDS-2251: State transition priority list must be optional.\nDDS-2252: Initial State not honored; assumed to be OFFLINE always\nDDS-2248: customized ideal state doesn't honor non-alive/disabled instances and disabled resources (partitions), which in turn creates messages with null TgtSessionId and cause NPE on participant side\nDDS-2249: ideal state customized mode is broken\nAdded a new test case for customized ideal state",
        "parent": "https://github.com/apache/helix/commit/08e5beced616e83400a1b3eab1f989343bded2b0",
        "repo": "helix",
        "unit_tests": [
            "TestBestPossibleStateCalcStage.java"
        ]
    },
    "helix_895cd9c": {
        "bug_id": "helix_895cd9c",
        "commit": "https://github.com/apache/helix/commit/895cd9c14f071a62af59a7cc4d2627455a9eb9d1",
        "file": [
            {
                "additions": 228,
                "blob_url": "https://github.com/apache/helix/blob/895cd9c14f071a62af59a7cc4d2627455a9eb9d1/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "changes": 488,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java?ref=895cd9c14f071a62af59a7cc4d2627455a9eb9d1",
                "deletions": 260,
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "patch": "@@ -12,7 +12,6 @@\n import org.apache.commons.cli.HelpFormatter;\n import org.apache.commons.cli.Option;\n import org.apache.commons.cli.OptionBuilder;\n-import org.apache.commons.cli.OptionGroup;\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.log4j.Logger;\n@@ -33,42 +32,35 @@\n \n public class ClusterSetup\n {\n-  private static Logger logger = Logger.getLogger(ClusterSetup.class);\n-  public static final String zkServerAddress = \"zkSvr\";\n+  private static Logger      logger                = Logger.getLogger(ClusterSetup.class);\n+  public static final String zkServerAddress       = \"zkSvr\";\n \n   // List info about the cluster / DB/ Instances\n-  public static final String listClusters = \"listClusters\";\n-  public static final String listResourceGroups = \"listResourceGroups\";\n-  public static final String listInstances = \"listInstances\";\n+  public static final String listClusters          = \"listClusters\";\n+  public static final String listResourceGroups    = \"listResourceGroups\";\n+  public static final String listInstances         = \"listInstances\";\n \n   // Add and rebalance\n-  public static final String addCluster = \"addCluster\";\n-  public static final String addInstance = \"addNode\";\n-  public static final String addResourceGroup = \"addResourceGroup\";\n-  public static final String addStateModelDef = \"addStateModelDef\";\n-  public static final String addIdealState = \"addIdealState\";\n-  public static final String rebalance = \"rebalance\";\n+  public static final String addCluster            = \"addCluster\";\n+  public static final String addInstance           = \"addNode\";\n+  public static final String addResourceGroup      = \"addResourceGroup\";\n+  public static final String addStateModelDef      = \"addStateModelDef\";\n+  public static final String addIdealState         = \"addIdealState\";\n+  public static final String rebalance             = \"rebalance\";\n \n   // Query info (TBD in V2)\n-  public static final String listClusterInfo = \"listClusterInfo\";\n-  public static final String listInstanceInfo = \"listInstanceInfo\";\n+  public static final String listClusterInfo       = \"listClusterInfo\";\n+  public static final String listInstanceInfo      = \"listInstanceInfo\";\n   public static final String listResourceGroupInfo = \"listResourceGroupInfo\";\n-  public static final String listResourceInfo = \"listResourceInfo\";\n-  public static final String listStateModels = \"listStateModels\";\n-  public static final String listStateModel = \"listStateModel\";\n-  \n-\n-  // TODO: refactor\n-  // setup for file-based cluster manager\n-  // public static final String configFile = \"configFile\";\n+  public static final String listResourceInfo      = \"listResourceInfo\";\n+  public static final String listStateModels       = \"listStateModels\";\n+  public static final String listStateModel        = \"listStateModel\";\n \n   // enable / disable Instances\n-  public static final String enableInstance = \"enableInstance\";\n-\n-  public static final String help = \"help\";\n-\n-  static Logger _logger = Logger.getLogger(ClusterSetup.class);\n-  String _zkServerAddress;\n+  public static final String enableInstance        = \"enableInstance\";\n+  public static final String help                  = \"help\";\n+  static Logger              _logger               = Logger.getLogger(ClusterSetup.class);\n+  String                     _zkServerAddress;\n \n   public ClusterSetup(String zkServerAddress)\n   {\n@@ -78,23 +70,21 @@ public ClusterSetup(String zkServerAddress)\n   public void addCluster(String clusterName, boolean overwritePrevious)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n-    \n+\n     managementTool.addCluster(clusterName, overwritePrevious);\n     StateModelConfigGenerator generator = new StateModelConfigGenerator();\n-    addStateModelDef(clusterName, \"MasterSlave\",\n-        generator.generateConfigForMasterSlave());\n-    \n-    addStateModelDef(clusterName, \"LeaderStandby\",\n-        generator.generateConfigForLeaderStandby());\n-    \n-    addStateModelDef(clusterName, \"StorageSchemata\",\n-        generator.generateConfigForStorageSchemata());\n-    \n-    addStateModelDef(clusterName, \"OnlineOffline\",\n-        generator.generateConfigForOnlineOffline());\n+    addStateModelDef(clusterName, \"MasterSlave\", generator.generateConfigForMasterSlave());\n+\n+    addStateModelDef(clusterName, \"LeaderStandby\", generator.generateConfigForLeaderStandby());\n+\n+    addStateModelDef(clusterName, \"StorageSchemata\", generator.generateConfigForStorageSchemata());\n+\n+    addStateModelDef(clusterName, \"OnlineOffline\", generator.generateConfigForOnlineOffline());\n   }\n-  \n-  public void addCluster(String clusterName, boolean overwritePrevious, String stateModDefName, \n+\n+  public void addCluster(String clusterName,\n+                         boolean overwritePrevious,\n+                         String stateModDefName,\n                          ZNRecord stateModDef)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n@@ -138,10 +128,8 @@ public void addInstanceToCluster(String clusterName, String host, int port)\n     String InstanceId = host + \"_\" + port;\n     InstanceConfig.setId(InstanceId);\n     InstanceConfig.setSimpleField(InstanceConfigProperty.HOST.toString(), host);\n-    InstanceConfig\n-        .setSimpleField(InstanceConfigProperty.PORT.toString(), \"\" + port);\n-    InstanceConfig.setSimpleField(InstanceConfigProperty.ENABLED.toString(),\n-        true + \"\");\n+    InstanceConfig.setSimpleField(InstanceConfigProperty.PORT.toString(), \"\" + port);\n+    InstanceConfig.setSimpleField(InstanceConfigProperty.ENABLED.toString(), true + \"\");\n \n     managementTool.addInstance(clusterName, InstanceConfig);\n   }\n@@ -152,119 +140,124 @@ public ClusterManagementService getClusterManagementTool()\n     return new ZKClusterManagementTool(zkClient);\n   }\n \n-  public void addStateModelDef(String clusterName, String stateModelDef,\n-      ZNRecord record)\n+  public void addStateModelDef(String clusterName, String stateModelDef, ZNRecord record)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n     managementTool.addStateModelDef(clusterName, stateModelDef, record);\n   }\n \n   public void addResourceGroupToCluster(String clusterName,\n-      String resourceGroup, int numResources, String stateModelRef)\n+                                        String resourceGroup,\n+                                        int numResources,\n+                                        String stateModelRef)\n   {\n-    /*\n-    ClusterManagementService managementTool = getClusterManagementTool();\n-    managementTool.addResourceGroup(clusterName, resourceGroup, numResources,\n-        stateModelRef);\n-    */\n-    addResourceGroupToCluster(clusterName, resourceGroup, numResources, stateModelRef, \n+    addResourceGroupToCluster(clusterName,\n+                              resourceGroup,\n+                              numResources,\n+                              stateModelRef,\n                               IdealStateConfigProperty.AUTO.toString());\n   }\n-  \n+\n   public void addResourceGroupToCluster(String clusterName,\n-      String resourceGroup, int numResources, String stateModelRef, String idealStateMode)\n+                                        String resourceGroup,\n+                                        int numResources,\n+                                        String stateModelRef,\n+                                        String idealStateMode)\n   {\n     if (!idealStateMode.equalsIgnoreCase(IdealStateConfigProperty.CUSTOMIZED.toString()))\n     {\n       logger.info(\"ideal state mode is configured to auto mode\");\n       idealStateMode = IdealStateConfigProperty.AUTO.toString();\n     }\n     ClusterManagementService managementTool = getClusterManagementTool();\n-    managementTool.addResourceGroup(clusterName, resourceGroup, numResources,\n-        stateModelRef, idealStateMode);\n+    managementTool.addResourceGroup(clusterName,\n+                                    resourceGroup,\n+                                    numResources,\n+                                    stateModelRef,\n+                                    idealStateMode);\n   }\n-  \n-  public void dropResourceGroupToCluster(String clusterName,\n-      String resourceGroup)\n+\n+  public void dropResourceGroupToCluster(String clusterName, String resourceGroup)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n     managementTool.dropResourceGroup(clusterName, resourceGroup);\n   }\n \n-  public void rebalanceStorageCluster(String clusterName,\n-      String resourceGroupName, int replica)\n+  public void rebalanceStorageCluster(String clusterName, String resourceGroupName, int replica)\n   {\n-    replica --;\n+    replica--;\n     ClusterManagementService managementTool = getClusterManagementTool();\n     List<String> InstanceNames = managementTool.getInstancesInCluster(clusterName);\n \n-    ZNRecord dbIdealState = managementTool.getResourceGroupIdealState(\n-        clusterName, resourceGroupName);\n-    int partitions = Integer\n-        .parseInt(dbIdealState.getSimpleField(\"partitions\"));\n+    ZNRecord dbIdealState =\n+        managementTool.getResourceGroupIdealState(clusterName, resourceGroupName);\n+    int partitions = Integer.parseInt(dbIdealState.getSimpleField(\"partitions\"));\n \n     ZkClient zkClient = ZKClientPool.getZkClient(_zkServerAddress);\n     String idealStatePath = CMUtil.getIdealStatePath(clusterName, resourceGroupName);\n-    ZNRecord idealState = zkClient.<ZNRecord>readData(idealStatePath);\n+    ZNRecord idealState = zkClient.<ZNRecord> readData(idealStatePath);\n     String stateModelName = idealState.getSimpleField(\"state_model_def_ref\");\n     ZNRecord stateModDef = managementTool.getStateModelDef(clusterName, stateModelName);\n- \n+\n     if (stateModDef == null)\n     {\n       throw new ClusterManagerException(\"cannot find state model \" + stateModelName);\n     }\n     StateModelDefinition def = new StateModelDefinition(stateModDef);\n-    \n+\n     List<String> statePriorityList = def.getStatesPriorityList();\n-    \n+\n     String masterStateValue = null;\n     String slaveStateValue = null;\n-    \n-    for(String state : statePriorityList)\n+\n+    for (String state : statePriorityList)\n     {\n       String count = def.getNumInstancesPerState(state);\n-      if(count.equals(\"1\"))\n+      if (count.equals(\"1\"))\n       {\n-        if(masterStateValue != null)\n+        if (masterStateValue != null)\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         masterStateValue = state;\n       }\n-      else if(count.equalsIgnoreCase(\"R\"))\n+      else if (count.equalsIgnoreCase(\"R\"))\n       {\n-        if(slaveStateValue != null)\n+        if (slaveStateValue != null)\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         slaveStateValue = state;\n       }\n-      else if(count.equalsIgnoreCase(\"N\"))\n+      else if (count.equalsIgnoreCase(\"N\"))\n       {\n-        if(!(masterStateValue == null && slaveStateValue == null))\n+        if (!(masterStateValue == null && slaveStateValue == null))\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         replica = InstanceNames.size() - 1;\n         masterStateValue = slaveStateValue = state;\n       }\n     }\n-    if(masterStateValue == null && slaveStateValue == null)\n+    if (masterStateValue == null && slaveStateValue == null)\n     {\n       throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n     }\n-    \n-    if(masterStateValue == null)\n+\n+    if (masterStateValue == null)\n     {\n       masterStateValue = slaveStateValue;\n     }\n-    \n-    idealState = IdealStateCalculatorForStorageNode\n-        .calculateIdealState(InstanceNames, partitions, replica, resourceGroupName,\n-                             masterStateValue, slaveStateValue);\n+\n+    idealState =\n+        IdealStateCalculatorForStorageNode.calculateIdealState(InstanceNames,\n+                                                               partitions,\n+                                                               replica,\n+                                                               resourceGroupName,\n+                                                               masterStateValue,\n+                                                               slaveStateValue);\n     idealState.setSimpleFields(dbIdealState.getSimpleFields());\n-    managementTool.setResourceGroupIdealState(clusterName, resourceGroupName,\n-        idealState);\n+    managementTool.setResourceGroupIdealState(clusterName, resourceGroupName, idealState);\n   }\n \n   /**\n@@ -295,131 +288,145 @@ public static void printUsage(Options cliOptions)\n   @SuppressWarnings(\"static-access\")\n   private static Options constructCommandLineOptions()\n   {\n-    Option helpOption = OptionBuilder.withLongOpt(help)\n-        .withDescription(\"Prints command-line options info\").create();\n-\n-    Option zkServerOption = OptionBuilder.withLongOpt(zkServerAddress)\n-        .withDescription(\"Provide zookeeper address\").create();\n+    Option helpOption =\n+        OptionBuilder.withLongOpt(help)\n+                     .withDescription(\"Prints command-line options info\")\n+                     .create();\n+\n+    Option zkServerOption =\n+        OptionBuilder.withLongOpt(zkServerAddress)\n+                     .withDescription(\"Provide zookeeper address\")\n+                     .create();\n     zkServerOption.setArgs(1);\n     zkServerOption.setRequired(true);\n     zkServerOption.setArgName(\"ZookeeperServerAddress(Required)\");\n \n-    Option listClustersOption = OptionBuilder.withLongOpt(listClusters)\n-        .withDescription(\"List existing clusters\").create();\n+    Option listClustersOption =\n+        OptionBuilder.withLongOpt(listClusters).withDescription(\"List existing clusters\").create();\n     listClustersOption.setArgs(0);\n     listClustersOption.setRequired(false);\n \n-    Option listResourceGroupOption = OptionBuilder\n-        .withLongOpt(listResourceGroups)\n-        .withDescription(\"List resourceGroups hosted in a cluster\").create();\n+    Option listResourceGroupOption =\n+        OptionBuilder.withLongOpt(listResourceGroups)\n+                     .withDescription(\"List resourceGroups hosted in a cluster\")\n+                     .create();\n     listResourceGroupOption.setArgs(1);\n     listResourceGroupOption.setRequired(false);\n     listResourceGroupOption.setArgName(\"clusterName\");\n \n-    Option listInstancesOption = OptionBuilder.withLongOpt(listInstances)\n-        .withDescription(\"List Instances in a cluster\").create();\n+    Option listInstancesOption =\n+        OptionBuilder.withLongOpt(listInstances)\n+                     .withDescription(\"List Instances in a cluster\")\n+                     .create();\n     listInstancesOption.setArgs(1);\n     listInstancesOption.setRequired(false);\n     listInstancesOption.setArgName(\"clusterName\");\n \n-    Option addClusterOption = OptionBuilder.withLongOpt(addCluster)\n-        .withDescription(\"Add a new cluster\").create();\n+    Option addClusterOption =\n+        OptionBuilder.withLongOpt(addCluster).withDescription(\"Add a new cluster\").create();\n     addClusterOption.setArgs(1);\n     addClusterOption.setRequired(false);\n     addClusterOption.setArgName(\"clusterName\");\n \n-    Option addInstanceOption = OptionBuilder.withLongOpt(addInstance)\n-        .withDescription(\"Add a new Instance to a cluster\").create();\n+    Option addInstanceOption =\n+        OptionBuilder.withLongOpt(addInstance)\n+                     .withDescription(\"Add a new Instance to a cluster\")\n+                     .create();\n     addInstanceOption.setArgs(2);\n     addInstanceOption.setRequired(false);\n     addInstanceOption.setArgName(\"clusterName InstanceAddress(host:port)\");\n \n-    Option addResourceGroupOption = OptionBuilder.withLongOpt(addResourceGroup)\n-        .withDescription(\"Add a resourceGroup to a cluster\").create();\n+    Option addResourceGroupOption =\n+        OptionBuilder.withLongOpt(addResourceGroup)\n+                     .withDescription(\"Add a resourceGroup to a cluster\")\n+                     .create();\n     addResourceGroupOption.setArgs(4);\n     addResourceGroupOption.setRequired(false);\n-    addResourceGroupOption\n-        .setArgName(\"clusterName resourceGroupName partitionNo stateModelRef\");\n+    addResourceGroupOption.setArgName(\"clusterName resourceGroupName partitionNo stateModelRef\");\n \n-    Option addStateModelDefOption = OptionBuilder\n-        .withLongOpt(addStateModelDef)\n-        .withDescription(\"Add a State model to a cluster\").create();\n+    Option addStateModelDefOption =\n+        OptionBuilder.withLongOpt(addStateModelDef)\n+                     .withDescription(\"Add a State model to a cluster\")\n+                     .create();\n     addStateModelDefOption.setArgs(2);\n     addStateModelDefOption.setRequired(false);\n     addStateModelDefOption.setArgName(\"clusterName <filename>\");\n-    \n-    Option addIdealStateOption = OptionBuilder\n-        .withLongOpt(addIdealState)\n-        .withDescription(\"Add a State model to a cluster\").create();\n+\n+    Option addIdealStateOption =\n+        OptionBuilder.withLongOpt(addIdealState)\n+                     .withDescription(\"Add a State model to a cluster\")\n+                     .create();\n     addIdealStateOption.setArgs(3);\n     addIdealStateOption.setRequired(false);\n     addIdealStateOption.setArgName(\"clusterName reourceGroupName <filename>\");\n \n-    Option rebalanceOption = OptionBuilder.withLongOpt(rebalance)\n-        .withDescription(\"Rebalance a resourceGroup in a cluster\").create();\n+    Option rebalanceOption =\n+        OptionBuilder.withLongOpt(rebalance)\n+                     .withDescription(\"Rebalance a resourceGroup in a cluster\")\n+                     .create();\n     rebalanceOption.setArgs(3);\n     rebalanceOption.setRequired(false);\n     rebalanceOption.setArgName(\"clusterName resourceGroupName replicationNo\");\n \n-    Option InstanceInfoOption = OptionBuilder.withLongOpt(listInstanceInfo)\n-        .withDescription(\"Query info of a Instance in a cluster\").create();\n+    Option InstanceInfoOption =\n+        OptionBuilder.withLongOpt(listInstanceInfo)\n+                     .withDescription(\"Query info of a Instance in a cluster\")\n+                     .create();\n     InstanceInfoOption.setArgs(2);\n     InstanceInfoOption.setRequired(false);\n     InstanceInfoOption.setArgName(\"clusterName InstanceName\");\n \n-    Option clusterInfoOption = OptionBuilder.withLongOpt(listClusterInfo)\n-        .withDescription(\"Query info of a cluster\").create();\n+    Option clusterInfoOption =\n+        OptionBuilder.withLongOpt(listClusterInfo)\n+                     .withDescription(\"Query info of a cluster\")\n+                     .create();\n     clusterInfoOption.setArgs(1);\n     clusterInfoOption.setRequired(false);\n     clusterInfoOption.setArgName(\"clusterName\");\n \n-    Option resourceGroupInfoOption = OptionBuilder\n-        .withLongOpt(listResourceGroupInfo)\n-        .withDescription(\"Query info of a resourceGroup\").create();\n+    Option resourceGroupInfoOption =\n+        OptionBuilder.withLongOpt(listResourceGroupInfo)\n+                     .withDescription(\"Query info of a resourceGroup\")\n+                     .create();\n     resourceGroupInfoOption.setArgs(2);\n     resourceGroupInfoOption.setRequired(false);\n     resourceGroupInfoOption.setArgName(\"clusterName resourceGroupName\");\n \n-    Option partitionInfoOption = OptionBuilder.withLongOpt(listResourceInfo)\n-        .withDescription(\"Query info of a partition\").create();\n+    Option partitionInfoOption =\n+        OptionBuilder.withLongOpt(listResourceInfo)\n+                     .withDescription(\"Query info of a partition\")\n+                     .create();\n     partitionInfoOption.setArgs(2);\n     partitionInfoOption.setRequired(false);\n     partitionInfoOption.setArgName(\"clusterName partitionName\");\n \n-    Option enableInstanceOption = OptionBuilder.withLongOpt(enableInstance)\n-        .withDescription(\"Enable / disable a Instance\").create();\n+    Option enableInstanceOption =\n+        OptionBuilder.withLongOpt(enableInstance)\n+                     .withDescription(\"Enable / disable a Instance\")\n+                     .create();\n     enableInstanceOption.setArgs(3);\n     enableInstanceOption.setRequired(false);\n     enableInstanceOption.setArgName(\"clusterName InstanceName true/false\");\n-    \n-    Option listStateModelsOption = OptionBuilder.withLongOpt(listStateModels)\n-      .withDescription(\"Query info of state models in a cluster\").create();\n+\n+    Option listStateModelsOption =\n+        OptionBuilder.withLongOpt(listStateModels)\n+                     .withDescription(\"Query info of state models in a cluster\")\n+                     .create();\n     listStateModelsOption.setArgs(1);\n     listStateModelsOption.setRequired(false);\n     listStateModelsOption.setArgName(\"clusterName\");\n \n-    Option listStateModelOption = OptionBuilder.withLongOpt(listStateModel)\n-      .withDescription(\"Query info of a state model in a cluster\").create();\n+    Option listStateModelOption =\n+        OptionBuilder.withLongOpt(listStateModel)\n+                     .withDescription(\"Query info of a state model in a cluster\")\n+                     .create();\n     listStateModelOption.setArgs(2);\n     listStateModelOption.setRequired(false);\n     listStateModelOption.setArgName(\"clusterName stateModelName\");\n \n-\n-    // add an option group including either --zkSvr or --configFile\n-    /**\n-    Option fileOption = OptionBuilder.withLongOpt(configFile)\n-        .withDescription(\"Provide file to write states/messages\").create();\n-    fileOption.setArgs(1);\n-    fileOption.setRequired(true);\n-    fileOption.setArgName(\"File to write states/messages (Optional)\");\n-     **/\n-    OptionGroup optionGroup = new OptionGroup();\n-    optionGroup.addOption(zkServerOption);\n-    // optionGroup.addOption(fileOption);\n-\n     Options options = new Options();\n     options.addOption(helpOption);\n-    // options.addOption(zkServerOption);\n+    options.addOption(zkServerOption);\n     options.addOption(rebalanceOption);\n     options.addOption(addResourceGroupOption);\n     options.addOption(addClusterOption);\n@@ -438,26 +445,25 @@ private static Options constructCommandLineOptions()\n     options.addOption(listStateModelsOption);\n     options.addOption(listStateModelOption);\n \n-    options.addOptionGroup(optionGroup);\n-\n     return options;\n   }\n+\n   private static byte[] readFile(String filePath) throws IOException\n   {\n-    File file = new File(filePath); \n+    File file = new File(filePath);\n \n-    int size = (int)file.length(); \n-    byte[] bytes = new byte[size]; \n-    DataInputStream dis = new DataInputStream(new FileInputStream(file)); \n+    int size = (int) file.length();\n+    byte[] bytes = new byte[size];\n+    DataInputStream dis = new DataInputStream(new FileInputStream(file));\n     int read = 0;\n     int numRead = 0;\n-    while (read < bytes.length && \n-        (numRead = dis.read(bytes, read, bytes.length-read)) >= 0) \n+    while (read < bytes.length && (numRead = dis.read(bytes, read, bytes.length - read)) >= 0)\n     {\n       read = read + numRead;\n     }\n     return bytes;\n   }\n+\n   public static int processCommandLineArgs(String[] cliArgs) throws Exception\n   {\n     CommandLineParser cliParser = new GnuParser();\n@@ -467,54 +473,16 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     try\n     {\n       cmd = cliParser.parse(cliOptions, cliArgs);\n-    } catch (ParseException pe)\n+    }\n+    catch (ParseException pe)\n     {\n-      System.err\n-          .println(\"CommandLineClient: failed to parse command-line options: \"\n-              + pe.toString());\n+      System.err.println(\"CommandLineClient: failed to parse command-line options: \"\n+          + pe.toString());\n       printUsage(cliOptions);\n       System.exit(1);\n     }\n \n-    /**\n-    if (cmd.hasOption(configFile))\n-    {\n-      String file = cmd.getOptionValue(configFile);\n-\n-      // for temporary test only, will move to command line\n-      // create fake db names\n-      List<FileBasedClusterManager.DBParam> dbParams = new ArrayList<FileBasedClusterManager.DBParam>();\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"BizFollow\", 1));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"BizProfile\", 1));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"EspressoDB\", 10));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"MailboxDB\", 128));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"MyDB\", 8));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"schemata\", 1));\n-      String[] InstancesInfo =\n-      { \"localhost:8900\" };\n-\n-      // ClusterViewSerializer serializer = new ClusterViewSerializer(file);\n-      int replica = 0;\n-      ClusterView view = FileBasedClusterManager\n-          .generateStaticConfigClusterView(InstancesInfo, dbParams, replica);\n-\n-      // byte[] bytes;\n-      ClusterViewSerializer.serialize(view, new File(file));\n-      // System.out.println(new String(bytes));\n-\n-      ClusterView restoredView = ClusterViewSerializer.deserialize(new File(\n-          file));\n-      // System.out.println(restoredView);\n-\n-      byte[] bytes = ClusterViewSerializer.serialize(restoredView);\n-      // System.out.println(new String(bytes));\n-\n-      return 0;\n-    }\n-    **/\n-    \n-    ClusterSetup setupTool = new ClusterSetup(\n-        cmd.getOptionValue(zkServerAddress));\n+    ClusterSetup setupTool = new ClusterSetup(cmd.getOptionValue(zkServerAddress));\n \n     if (cmd.hasOption(addCluster))\n     {\n@@ -536,11 +504,9 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     {\n       String clusterName = cmd.getOptionValues(addResourceGroup)[0];\n       String resourceGroupName = cmd.getOptionValues(addResourceGroup)[1];\n-      int partitions = Integer\n-          .parseInt(cmd.getOptionValues(addResourceGroup)[2]);\n+      int partitions = Integer.parseInt(cmd.getOptionValues(addResourceGroup)[2]);\n       String stateModelRef = cmd.getOptionValues(addResourceGroup)[3];\n-      setupTool.addResourceGroupToCluster(clusterName, resourceGroupName,\n-          partitions, stateModelRef);\n+      setupTool.addResourceGroupToCluster(clusterName, resourceGroupName, partitions, stateModelRef);\n       return 0;\n     }\n \n@@ -549,15 +515,13 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n       String clusterName = cmd.getOptionValues(rebalance)[0];\n       String resourceGroupName = cmd.getOptionValues(rebalance)[1];\n       int replicas = Integer.parseInt(cmd.getOptionValues(rebalance)[2]);\n-      setupTool.rebalanceStorageCluster(clusterName, resourceGroupName,\n-          replicas);\n+      setupTool.rebalanceStorageCluster(clusterName, resourceGroupName, replicas);\n       return 0;\n     }\n \n     if (cmd.hasOption(listClusters))\n     {\n-      List<String> clusters = setupTool.getClusterManagementTool()\n-          .getClusters();\n+      List<String> clusters = setupTool.getClusterManagementTool().getClusters();\n \n       System.out.println(\"Existing clusters:\");\n       for (String cluster : clusters)\n@@ -570,30 +534,30 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     if (cmd.hasOption(listResourceGroups))\n     {\n       String clusterName = cmd.getOptionValue(listResourceGroups);\n-      List<String> resourceGroupNames = setupTool.getClusterManagementTool()\n-          .getResourceGroupsInCluster(clusterName);\n+      List<String> resourceGroupNames =\n+          setupTool.getClusterManagementTool().getResourceGroupsInCluster(clusterName);\n \n       System.out.println(\"Existing resources in cluster \" + clusterName + \":\");\n       for (String resourceGroupName : resourceGroupNames)\n       {\n         System.out.println(resourceGroupName);\n       }\n       return 0;\n-    } \n-    else if(cmd.hasOption(listClusterInfo))\n+    }\n+    else if (cmd.hasOption(listClusterInfo))\n     {\n       String clusterName = cmd.getOptionValue(listClusterInfo);\n-      List<String> resourceGroupNames = setupTool.getClusterManagementTool()\n-          .getResourceGroupsInCluster(clusterName);\n-      List<String> Instances = setupTool.getClusterManagementTool()\n-        .getInstancesInCluster(clusterName);\n-      \n+      List<String> resourceGroupNames =\n+          setupTool.getClusterManagementTool().getResourceGroupsInCluster(clusterName);\n+      List<String> Instances =\n+          setupTool.getClusterManagementTool().getInstancesInCluster(clusterName);\n+\n       System.out.println(\"Existing resources in cluster \" + clusterName + \":\");\n       for (String resourceGroupName : resourceGroupNames)\n       {\n         System.out.println(resourceGroupName);\n       }\n-      \n+\n       System.out.println(\"Instances in cluster \" + clusterName + \":\");\n       for (String InstanceName : Instances)\n       {\n@@ -604,8 +568,8 @@ else if(cmd.hasOption(listClusterInfo))\n     else if (cmd.hasOption(listInstances))\n     {\n       String clusterName = cmd.getOptionValue(listInstances);\n-      List<String> Instances = setupTool.getClusterManagementTool()\n-          .getInstancesInCluster(clusterName);\n+      List<String> Instances =\n+          setupTool.getClusterManagementTool().getInstancesInCluster(clusterName);\n \n       System.out.println(\"Instances in cluster \" + clusterName + \":\");\n       for (String InstanceName : Instances)\n@@ -618,53 +582,54 @@ else if (cmd.hasOption(listInstanceInfo))\n     {\n       String clusterName = cmd.getOptionValues(listInstanceInfo)[0];\n       String instanceName = cmd.getOptionValues(listInstanceInfo)[1];\n-      ZNRecord record = setupTool.getClusterManagementTool().getInstanceConfig(clusterName, instanceName);\n-      \n+      ZNRecord record =\n+          setupTool.getClusterManagementTool().getInstanceConfig(clusterName, instanceName);\n+\n       String result = new String(new ZNRecordSerializer().serialize(record));\n       System.out.println(result);\n       return 0;\n-      \n-      // print out current states and\n-    } \n+    }\n     else if (cmd.hasOption(listResourceGroupInfo))\n     {\n       // print out partition number, db name and replication number\n       // Also the ideal states and current states\n       String clusterName = cmd.getOptionValues(listResourceGroupInfo)[0];\n       String resourceGroupName = cmd.getOptionValues(listResourceGroupInfo)[1];\n-      ZNRecord idealState = setupTool.getClusterManagementTool().getResourceGroupIdealState(clusterName, resourceGroupName);\n-      ZNRecord externalView = setupTool.getClusterManagementTool().getResourceGroupExternalView(clusterName, resourceGroupName);\n-      \n-      System.out.println(\"IdealState for \"+resourceGroupName+\":\");\n+      ZNRecord idealState =\n+          setupTool.getClusterManagementTool().getResourceGroupIdealState(clusterName,\n+                                                                          resourceGroupName);\n+      ZNRecord externalView =\n+          setupTool.getClusterManagementTool().getResourceGroupExternalView(clusterName,\n+                                                                            resourceGroupName);\n+\n+      System.out.println(\"IdealState for \" + resourceGroupName + \":\");\n       System.out.println(new String(new ZNRecordSerializer().serialize(idealState)));\n-      \n+\n       System.out.println();\n-      System.out.println(\"External view for \"+resourceGroupName+\":\");\n+      System.out.println(\"External view for \" + resourceGroupName + \":\");\n       System.out.println(new String(new ZNRecordSerializer().serialize(externalView)));\n       return 0;\n-      \n-    } \n+\n+    }\n     else if (cmd.hasOption(listResourceInfo))\n     {\n       // print out where the partition master / slaves locates\n-    } \n+    }\n     else if (cmd.hasOption(enableInstance))\n     {\n       String clusterName = cmd.getOptionValues(enableInstance)[0];\n       String instanceName = cmd.getOptionValues(enableInstance)[1];\n-      boolean enabled = Boolean.parseBoolean(cmd.getOptionValues(enableInstance)[1]\n-          .toLowerCase());\n+      boolean enabled = Boolean.parseBoolean(cmd.getOptionValues(enableInstance)[1].toLowerCase());\n \n-      setupTool.getClusterManagementTool().enableInstance(clusterName,\n-          instanceName, enabled);\n+      setupTool.getClusterManagementTool().enableInstance(clusterName, instanceName, enabled);\n       return 0;\n-    } \n-    else if(cmd.hasOption(listStateModels))\n+    }\n+    else if (cmd.hasOption(listStateModels))\n     {\n       String clusterName = cmd.getOptionValues(listStateModels)[0];\n-      \n-      List<String> stateModels =  setupTool.getClusterManagementTool()\n-      .getStateModelDefs(clusterName);\n+\n+      List<String> stateModels =\n+          setupTool.getClusterManagementTool().getStateModelDefs(clusterName);\n \n       System.out.println(\"Existing state models:\");\n       for (String stateModel : stateModels)\n@@ -677,36 +642,43 @@ else if (cmd.hasOption(listStateModel))\n     {\n       String clusterName = cmd.getOptionValues(listStateModel)[0];\n       String stateModel = cmd.getOptionValues(listStateModel)[1];\n-      ZNRecord record = setupTool.getClusterManagementTool().getStateModelDef(clusterName, stateModel);\n+      ZNRecord record =\n+          setupTool.getClusterManagementTool().getStateModelDef(clusterName, stateModel);\n       String result = new String(new ZNRecordSerializer().serialize(record));\n       System.out.println(result);\n       return 0;\n     }\n-    else if(cmd.hasOption(addStateModelDef))\n+    else if (cmd.hasOption(addStateModelDef))\n     {\n       String clusterName = cmd.getOptionValues(addStateModelDef)[0];\n       String stateModelFile = cmd.getOptionValues(addStateModelDef)[1];\n-      \n-      ZNRecord stateModelRecord = (ZNRecord)(new ZNRecordSerializer().deserialize(readFile(stateModelFile)));\n-      if(stateModelRecord.getId() == null || stateModelRecord.getId().length() == 0)\n+\n+      ZNRecord stateModelRecord =\n+          (ZNRecord) (new ZNRecordSerializer().deserialize(readFile(stateModelFile)));\n+      if (stateModelRecord.getId() == null || stateModelRecord.getId().length() == 0)\n       {\n         throw new IllegalArgumentException(\"ZNRecord for state model definition must have an id\");\n       }\n-      setupTool.getClusterManagementTool().addStateModelDef(clusterName, stateModelRecord.getId(), stateModelRecord);\n+      setupTool.getClusterManagementTool().addStateModelDef(clusterName,\n+                                                            stateModelRecord.getId(),\n+                                                            stateModelRecord);\n       return 0;\n     }\n-    else if(cmd.hasOption(addIdealState))\n+    else if (cmd.hasOption(addIdealState))\n     {\n       String clusterName = cmd.getOptionValues(addIdealState)[0];\n       String resourceGroupName = cmd.getOptionValues(addIdealState)[1];\n       String idealStateFile = cmd.getOptionValues(addIdealState)[2];\n-      \n-      ZNRecord idealStateRecord = (ZNRecord)(new ZNRecordSerializer().deserialize(readFile(idealStateFile)));\n-      if(idealStateRecord.getId() == null || !idealStateRecord.getId().equals(resourceGroupName))\n+\n+      ZNRecord idealStateRecord =\n+          (ZNRecord) (new ZNRecordSerializer().deserialize(readFile(idealStateFile)));\n+      if (idealStateRecord.getId() == null || !idealStateRecord.getId().equals(resourceGroupName))\n       {\n         throw new IllegalArgumentException(\"ideal state must have same id as resourceGroup name\");\n       }\n-      setupTool.getClusterManagementTool().setResourceGroupIdealState(clusterName, resourceGroupName, idealStateRecord);\n+      setupTool.getClusterManagementTool().setResourceGroupIdealState(clusterName,\n+                                                                      resourceGroupName,\n+                                                                      idealStateRecord);\n       return 0;\n     }\n     else if (cmd.hasOption(help))\n@@ -725,14 +697,10 @@ else if (cmd.hasOption(help))\n    */\n   public static void main(String[] args) throws Exception\n   {\n-    // For temporary test only, remove later\n-    // Logger.getRootLogger().setLevel(Level.ERROR);\n     if (args.length == 0)\n     {\n-      new ClusterSetup(\"localhost:2181\")\n-          .setupTestCluster(\"storage-integration-cluster\");\n-      new ClusterSetup(\"localhost:2181\")\n-          .setupTestCluster(\"relay-integration-cluster\");\n+      new ClusterSetup(\"localhost:2181\").setupTestCluster(\"storage-integration-cluster\");\n+      new ClusterSetup(\"localhost:2181\").setupTestCluster(\"relay-integration-cluster\");\n       System.exit(0);\n     }\n ",
                "raw_url": "https://github.com/apache/helix/raw/895cd9c14f071a62af59a7cc4d2627455a9eb9d1/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "sha": "5d56a3eebbb2cca27e50ed595353fd18df15d397",
                "status": "modified"
            }
        ],
        "message": "fix NPE in ClusterSetup.main()",
        "parent": "https://github.com/apache/helix/commit/49cb4ff8e08ef02b84378365cf4230c33371a3a7",
        "repo": "helix",
        "unit_tests": [
            "TestClusterSetup.java"
        ]
    },
    "helix_90ef589": {
        "bug_id": "helix_90ef589",
        "commit": "https://github.com/apache/helix/commit/90ef589aa47ef1726356ce5ea37e12d27372b342",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/helix/blob/90ef589aa47ef1726356ce5ea37e12d27372b342/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java?ref=90ef589aa47ef1726356ce5ea37e12d27372b342",
                "deletions": 11,
                "filename": "helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "patch": "@@ -464,23 +464,18 @@ boolean containsState(String state) {\n   private static Comparator<InstanceConfig> INSTANCE_CONFIG_COMPARATOR =\n       new Comparator<InstanceConfig>() {\n         @Override\n-        public int compare(InstanceConfig o1, InstanceConfig o2) {\n-          if (o1 == o2) {\n+        public int compare(InstanceConfig config1, InstanceConfig config2) {\n+          if (config1 == config2) {\n             return 0;\n           }\n-          if (o1 == null) {\n+          if (config1 == null) {\n             return -1;\n           }\n-          if (o2 == null) {\n+          if (config2 == null) {\n             return 1;\n           }\n-\n-          int compareTo = o1.getHostName().compareTo(o2.getHostName());\n-          if (compareTo == 0) {\n-            return o1.getPort().compareTo(o2.getPort());\n-          }\n-\n-          return compareTo;\n+          // IDs for InstanceConfigs are a concatenation of instance name, host, and port.\n+          return config1.getId().compareTo(config2.getId());\n         }\n       };\n }",
                "raw_url": "https://github.com/apache/helix/raw/90ef589aa47ef1726356ce5ea37e12d27372b342/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "sha": "46cf4711a48c0fff5ef26ab66218eee134db8d04",
                "status": "modified"
            }
        ],
        "message": "[HELIX-699] Compare InstanceConfigs using their IDs in RoutingTable\n\nA possible race condition was causing a NPE on InstanceConfig.getHostName(). Instead of comparing hostnames and ports, we compare IDs, which are supposed to be concatenation of instance name, hostname, and port anyways and should always be set.",
        "parent": "https://github.com/apache/helix/commit/0e4163f18c1274c0f77320698e9dfbf42314810d",
        "repo": "helix",
        "unit_tests": [
            "TestRoutingTable.java"
        ]
    },
    "helix_959966e": {
        "bug_id": "helix_959966e",
        "commit": "https://github.com/apache/helix/commit/959966effa11f7cce0e054b6189c5e97130ae039",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/helix/blob/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java?ref=959966effa11f7cce0e054b6189c5e97130ae039",
                "deletions": 1,
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "patch": "@@ -185,7 +185,9 @@ public void close() throws ZkInterruptedException {\n       }\n     } finally {\n       getEventLock().unlock();\n-      _monitor.unregister();\n+      if (_monitor != null) {\n+        _monitor.unregister();\n+      }\n       LOG.info(\"Closed zkclient\");\n     }\n   }",
                "raw_url": "https://github.com/apache/helix/raw/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "sha": "aa1a0738cc3415f53719043b81209c97d6402c55",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java?ref=959966effa11f7cce0e054b6189c5e97130ae039",
                "deletions": 4,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "patch": "@@ -22,6 +22,7 @@\n import java.lang.management.ManagementFactory;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import javax.management.JMException;\n import javax.management.MBeanServer;\n import javax.management.ObjectName;\n@@ -62,10 +63,10 @@ public boolean match(String path) {\n   private long _writeCounter;\n   private long _readBytesCounter;\n   private long _writeBytesCounter;\n-  private Map<PredefinedPath, Long> _readCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _writeCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _readBytesCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _writBytesCounterMap = new HashMap<PredefinedPath, Long>();\n+  private Map<PredefinedPath, Long> _readCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _writeCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _readBytesCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _writBytesCounterMap = new ConcurrentHashMap<>();\n \n   public ZkClientMonitor(String tag) throws JMException {\n     tag = tag == null ? DEFAULT_TAG : tag;",
                "raw_url": "https://github.com/apache/helix/raw/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "sha": "5811d7ec316fc62a23c17649d7b8f2bdca761d21",
                "status": "modified"
            }
        ],
        "message": "Fix ZkClientMonitor bugs\n\nNPE check and thread-safe map for counter maps.",
        "parent": "https://github.com/apache/helix/commit/3768fc11cfe3be87131ce1743ea335e578c3d55e",
        "repo": "helix",
        "unit_tests": [
            "TestZkClientMonitor.java"
        ]
    },
    "helix_b0c3bfd": {
        "bug_id": "helix_b0c3bfd",
        "commit": "https://github.com/apache/helix/commit/b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "patch": "@@ -267,6 +267,15 @@ private void generateMessage(final Resource resource, final ClusterDataCache cac\n       for (String state : statesPriorityList) {\n         if (messageMap.containsKey(state)) {\n           for (Message message : messageMap.get(state)) {\n+            // This is for a bug where a message's target session id is null\n+            if (!message.isValid()) {\n+              LogUtil.logError(logger, _eventId, String.format(\n+                  \"An invalid message was generated! Discarding this message. sessionIdMap: %s, CurrentStateMap: %s, InstanceStateMap: %s, AllInstances: %s, LiveInstances: %s, Message: %s\",\n+                  sessionIdMap, currentStateOutput.getCurrentStateMap(resourceName, partition),\n+                  instanceStateMap, cache.getAllInstances(), cache.getLiveInstances().keySet(),\n+                  message));\n+              continue; // Do not add this message\n+            }\n             output.addMessage(resourceName, partition, message);\n           }\n         }",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "sha": "4c693a639900236a6c2c27ab406c85440fe9c6d7",
                "status": "modified"
            },
            {
                "additions": 70,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "changes": 132,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "deletions": 62,
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "patch": "@@ -779,78 +779,86 @@ public void onMessage(String instanceName, List<Message> messages,\n     Set<String> createCurStateNames = new HashSet<>();\n \n     for (Message message : messages) {\n-      // nop messages are simply removed. It is used to trigger onMessage() in\n-      // situations such as register a new message handler factory\n-      if (message.getMsgType().equalsIgnoreCase(MessageType.NO_OP.toString())) {\n-        LOG.info(\n-            \"Dropping NO-OP message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc());\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        continue;\n-      }\n+      try {\n+        // nop messages are simply removed. It is used to trigger onMessage() in\n+        // situations such as register a new message handler factory\n+        if (message.getMsgType().equalsIgnoreCase(MessageType.NO_OP.toString())) {\n+          LOG.info(\n+              \"Dropping NO-OP message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc());\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n+          continue;\n+        }\n \n-      String tgtSessionId = message.getTgtSessionId();\n-      // sessionId mismatch normally means message comes from expired session, just remove it\n-      if (!sessionId.equals(tgtSessionId) && !tgtSessionId.equals(\"*\")) {\n-        String warningMessage =\n-            \"SessionId does NOT match. expected sessionId: \" + sessionId\n-                + \", tgtSessionId in message: \" + tgtSessionId + \", messageId: \"\n-                + message.getMsgId();\n-        LOG.warn(warningMessage);\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        _statusUpdateUtil.logWarning(message, HelixStateMachineEngine.class, warningMessage, manager);\n-\n-        // Proactively send a session sync message from participant to controller\n-        // upon session mismatch after a new session is established\n-        if (manager.getInstanceType() == InstanceType.PARTICIPANT\n-            || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT) {\n-          if (message.getCreateTimeStamp() > manager.getSessionStartTime()) {\n-            syncSessionToController(manager);\n+        String tgtSessionId = message.getTgtSessionId();\n+        // sessionId mismatch normally means message comes from expired session, just remove it\n+        if (!sessionId.equals(tgtSessionId) && !tgtSessionId.equals(\"*\")) {\n+          String warningMessage =\n+              \"SessionId does NOT match. expected sessionId: \" + sessionId\n+                  + \", tgtSessionId in message: \" + tgtSessionId + \", messageId: \"\n+                  + message.getMsgId();\n+          LOG.warn(warningMessage);\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n+          _statusUpdateUtil.logWarning(message, HelixStateMachineEngine.class, warningMessage, manager);\n+\n+          // Proactively send a session sync message from participant to controller\n+          // upon session mismatch after a new session is established\n+          if (manager.getInstanceType() == InstanceType.PARTICIPANT\n+              || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT) {\n+            if (message.getCreateTimeStamp() > manager.getSessionStartTime()) {\n+              syncSessionToController(manager);\n+            }\n           }\n+          continue;\n         }\n-        continue;\n-      }\n-\n-      if ((manager.getInstanceType() == InstanceType.CONTROLLER\n-          || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT)\n-          && MessageType.PARTICIPANT_SESSION_CHANGE.name().equals(message.getMsgType())) {\n-        LOG.info(String.format(\"Controller received PARTICIPANT_SESSION_CHANGE msg from src: %s\",\n-            message.getMsgSrc()));\n-        PropertyKey key = new Builder(manager.getClusterName()).liveInstances();\n-        List<LiveInstance> liveInstances = manager.getHelixDataAccessor().getChildValues(key);\n-        _controller.onLiveInstanceChange(liveInstances, changeContext);\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.COMPLETED);\n-        continue;\n-      }\n \n-      // don't process message that is of READ or UNPROCESSABLE state\n-      if (MessageState.NEW != message.getMsgState()) {\n-        // It happens because we don't delete message right after\n-        // read. Instead we keep it until the current state is updated.\n-        // We will read the message again if there is a new message but we\n-        // check for the status and ignore if its already read\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"Message already read. msgId: \" + message.getMsgId());\n+        if ((manager.getInstanceType() == InstanceType.CONTROLLER\n+            || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT)\n+            && MessageType.PARTICIPANT_SESSION_CHANGE.name().equals(message.getMsgType())) {\n+          LOG.info(String.format(\"Controller received PARTICIPANT_SESSION_CHANGE msg from src: %s\",\n+              message.getMsgSrc()));\n+          PropertyKey key = new Builder(manager.getClusterName()).liveInstances();\n+          List<LiveInstance> liveInstances = manager.getHelixDataAccessor().getChildValues(key);\n+          _controller.onLiveInstanceChange(liveInstances, changeContext);\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.COMPLETED);\n+          continue;\n         }\n-        continue;\n-      }\n \n-      if (message.isExpired()) {\n-        LOG.info(\n-            \"Dropping expired message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc()\n-                + \" relayed from: \" + message.getRelaySrcHost());\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        continue;\n-      }\n+        // don't process message that is of READ or UNPROCESSABLE state\n+        if (MessageState.NEW != message.getMsgState()) {\n+          // It happens because we don't delete message right after\n+          // read. Instead we keep it until the current state is updated.\n+          // We will read the message again if there is a new message but we\n+          // check for the status and ignore if its already read\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Message already read. msgId: \" + message.getMsgId());\n+          }\n+          continue;\n+        }\n \n-      // State Transition Cancellation\n-      if (message.getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n-        boolean success = cancelNotStartedStateTransition(message, stateTransitionHandlers, accessor, instanceName);\n-        if (success) {\n+        if (message.isExpired()) {\n+          LOG.info(\n+              \"Dropping expired message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc()\n+                  + \" relayed from: \" + message.getRelaySrcHost());\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n           continue;\n         }\n-      }\n \n-      _monitor.reportReceivedMessage(message);\n+        // State Transition Cancellation\n+        if (message.getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n+          boolean success = cancelNotStartedStateTransition(message, stateTransitionHandlers, accessor, instanceName);\n+          if (success) {\n+            continue;\n+          }\n+        }\n+\n+        _monitor.reportReceivedMessage(message);\n+      } catch (Exception e) {\n+        LOG.error(\"Failed to process the message {}. Deleting the message from ZK. Exception: {}\",\n+            message, e);\n+        removeMessageFromTaskAndFutureMap(message);\n+        removeMessageFromZK(accessor, message, instanceName);\n+        continue;\n+      }\n \n       // create message handlers, if handlers not found, leave its state as NEW\n       NotificationContext msgWorkingContext = changeContext.clone();",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "sha": "a0481e327d5eb520faffe253a49430a3239ae18c",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/model/Message.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/Message.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "deletions": 7,
                "filename": "helix-core/src/main/java/org/apache/helix/model/Message.java",
                "patch": "@@ -905,16 +905,15 @@ public boolean isValid() {\n     // TODO: refactor message to state transition message and task-message and\n     // implement this function separately\n \n-    if (getMsgType().equals(MessageType.STATE_TRANSITION.name())) {\n-      boolean isNotValid =\n-          isNullOrEmpty(getTgtName()) || isNullOrEmpty(getPartitionName())\n-              || isNullOrEmpty(getResourceName()) || isNullOrEmpty(getStateModelDef())\n-              || isNullOrEmpty(getToState()) || isNullOrEmpty(getStateModelFactoryName())\n-              || isNullOrEmpty(getFromState());\n+    if (getMsgType().equals(MessageType.STATE_TRANSITION.name())\n+        || getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n+      boolean isNotValid = isNullOrEmpty(getTgtName()) || isNullOrEmpty(getPartitionName())\n+          || isNullOrEmpty(getResourceName()) || isNullOrEmpty(getStateModelDef())\n+          || isNullOrEmpty(getToState()) || isNullOrEmpty(getFromState())\n+          || isNullOrEmpty(getTgtSessionId());\n \n       return !isNotValid;\n     }\n-\n     return true;\n   }\n }",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/model/Message.java",
                "sha": "4177b441489e7c5ed566b163e50a01f7c1ada77a",
                "status": "modified"
            }
        ],
        "message": "HELIX: Fix null tgtSessionId message bug\n\nIt has been reported that the Controller sometimes sends a message with a null tgtSessionId, which was causing an NPE on the Participant.\nChangelist:\n    1. Controller side fix\n    2. Participant side fix with a try-catch\n    3. Modify isValid for messages",
        "parent": "https://github.com/apache/helix/commit/5fb6563da5fe4ab89274fa1b982452ec11774550",
        "repo": "helix",
        "unit_tests": [
            "TestHelixTaskExecutor.java"
        ]
    },
    "helix_b429d48": {
        "bug_id": "helix_b429d48",
        "commit": "https://github.com/apache/helix/commit/b429d4815f5314bdb0c67ca7ed31d17270a4b878",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/helix/blob/b429d4815f5314bdb0c67ca7ed31d17270a4b878/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java?ref=b429d4815f5314bdb0c67ca7ed31d17270a4b878",
                "deletions": 13,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "patch": "@@ -250,6 +250,13 @@ private boolean computeResourceBestPossibleState(ClusterEvent event, ResourceCon\n         // The next release will support rebalancers that compute the mapping from start to finish\n         partitionStateAssignment = mappingCalculator\n             .computeBestPossiblePartitionState(cache, idealState, resource, currentStateOutput);\n+\n+        if (partitionStateAssignment == null) {\n+          LogUtil.logWarn(logger, _eventId,\n+              \"PartitionStateAssignment is null, resource: \" + resourceName);\n+          return false;\n+        }\n+\n         for (Partition partition : resource.getPartitions()) {\n           Map<String, String> newStateMap = partitionStateAssignment.getReplicaMap(partition);\n           output.setState(resourceName, partition, newStateMap);\n@@ -263,19 +270,6 @@ private boolean computeResourceBestPossibleState(ClusterEvent event, ResourceCon\n       } catch (Exception e) {\n         LogUtil.logError(logger, _eventId,\n             \"Error computing assignment for resource \" + resourceName + \". Skipping.\");\n-        // TODO : remove this part after debugging NPE\n-        StringBuilder sb = new StringBuilder();\n-\n-        sb.append(String\n-            .format(\"HelixManager is null : %s\\n\", event.getAttribute(\"helixmanager\") == null));\n-        sb.append(String.format(\"Rebalancer is null : %s\\n\", rebalancer == null));\n-        sb.append(String.format(\"Calculated idealState is null : %s\\n\", idealState == null));\n-        sb.append(String.format(\"MappingCaculator is null : %s\\n\", mappingCalculator == null));\n-        sb.append(\n-            String.format(\"PartitionAssignment is null : %s\\n\", partitionStateAssignment == null));\n-        sb.append(String.format(\"Output is null : %s\\n\", output == null));\n-\n-        LogUtil.logError(logger, _eventId, sb.toString());\n       }\n     }\n     // Exception or rebalancer is not found",
                "raw_url": "https://github.com/apache/helix/raw/b429d4815f5314bdb0c67ca7ed31d17270a4b878/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "sha": "85a4add52dfe2edec42c03c3d36e083873ce3993",
                "status": "modified"
            }
        ],
        "message": "Remove TODO NPE log for computeResourceBestPossibleState\n\nThe logs related to NPE in computeResourceBestPossibleState is not needed anymore.\n\nThis commit fixes issue #351.",
        "parent": "https://github.com/apache/helix/commit/c9300968690024765fe9d66ca1ac248720cd0af8",
        "repo": "helix",
        "unit_tests": [
            "TestBestPossibleStateCalcStage.java"
        ]
    },
    "helix_c0bef9a": {
        "bug_id": "helix_c0bef9a",
        "commit": "https://github.com/apache/helix/commit/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61",
        "file": [
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/helix/blob/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java?ref=c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61",
                "deletions": 13,
                "filename": "helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "patch": "@@ -271,8 +271,9 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n   public List<String> getDisabledPartitions() {\n     List<String> oldDisabled =\n         _record.getListField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n-    if (!_record.getMapFields().containsKey(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        && oldDisabled == null) {\n+    Map<String, String> newDisabledMap =\n+        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n+    if (newDisabledMap == null && oldDisabled == null) {\n       return null;\n     }\n \n@@ -281,11 +282,11 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n       disabledPartitions.addAll(oldDisabled);\n     }\n \n-    for (String perResource : _record\n-        .getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name()).values()) {\n-      disabledPartitions.addAll(HelixUtil.deserializeByComma(perResource));\n+    if (newDisabledMap != null) {\n+      for (String perResource : newDisabledMap.values()) {\n+        disabledPartitions.addAll(HelixUtil.deserializeByComma(perResource));\n+      }\n     }\n-\n     return new ArrayList<String>(disabledPartitions);\n   }\n \n@@ -298,9 +299,10 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n     // TODO: Remove this logic getting data from list field when getDisabledParition() removed.\n     List<String> oldDisabled =\n         _record.getListField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n-    if ((!_record.getMapFields().containsKey(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        || !_record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        .containsKey(resourceName)) && oldDisabled == null) {\n+    Map<String, String> newDisabledMap =\n+        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n+    if ((newDisabledMap == null || !newDisabledMap.containsKey(resourceName))\n+        && oldDisabled == null) {\n       return null;\n     }\n \n@@ -309,10 +311,9 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n       disabledPartitions.addAll(oldDisabled);\n     }\n \n-    disabledPartitions.addAll(HelixUtil.deserializeByComma(\n-        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-            .get(resourceName)));\n-\n+    if (newDisabledMap != null) {\n+      disabledPartitions.addAll(HelixUtil.deserializeByComma(newDisabledMap.get(resourceName)));\n+    }\n     return new ArrayList<String>(disabledPartitions);\n   }\n ",
                "raw_url": "https://github.com/apache/helix/raw/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "sha": "0d540596080362f6b584fee4918094e877f4ba0b",
                "status": "modified"
            }
        ],
        "message": "Fix NPE for get disabled partitions",
        "parent": "https://github.com/apache/helix/commit/04281faf0302fa7cfdbe81ec86325c043627489f",
        "repo": "helix",
        "unit_tests": [
            "TestInstanceConfig.java"
        ]
    },
    "helix_cf010f9": {
        "bug_id": "helix_cf010f9",
        "commit": "https://github.com/apache/helix/commit/cf010f90426003dab7e713945c2c9daa23ffed13",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/helix/blob/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java?ref=cf010f90426003dab7e713945c2c9daa23ffed13",
                "deletions": 4,
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "patch": "@@ -267,12 +267,13 @@ private PartitionStateMap computeIntermediatePartitionState(ClusterDataCache cac\n       // logic doesn't need to check for more details.\n       boolean isRebalanceNeeded = false;\n \n+      // Check whether partition has any ERROR state replicas\n+      if (currentStateMap.values().contains(HelixDefinedState.ERROR.name())) {\n+        partitionsWithErrorStateReplica.add(partition);\n+      }\n+\n       // Number of states required by StateModelDefinition are not satisfied, need recovery\n       if (rebalanceType.equals(RebalanceType.RECOVERY_BALANCE)) {\n-        // Check whether partition is in ERROR state\n-        if (currentStateMap.values().contains(HelixDefinedState.ERROR.name())) {\n-          partitionsWithErrorStateReplica.add(partition);\n-        }\n         // Check if recovery is needed for this partition\n         if (!currentStateMap.equals(bestPossibleMap)) {\n           partitionsNeedRecovery.add(partition);\n@@ -284,6 +285,7 @@ private PartitionStateMap computeIntermediatePartitionState(ClusterDataCache cac\n         partitionsNeedLoadBalance.add(partition);\n         isRebalanceNeeded = true;\n       }\n+\n       // Currently at BestPossibleState, no further action necessary\n       if (!isRebalanceNeeded) {\n         Map<String, String> intermediateMap = new HashMap<>(bestPossibleMap);\n@@ -388,6 +390,12 @@ private boolean isLoadBalanceDownwardForAllReplicas(Map<String, String> currentS\n       if (bestPossibleState != null) {\n         // Compare priority values and return if an upward transition is found\n         // Note that lower integer value implies higher priority\n+        if (!statePriorityMap.containsKey(currentState)\n+            || !statePriorityMap.containsKey(bestPossibleState)) {\n+          // If the state is not found in statePriorityMap, consider it not strictly downward by\n+          // default because we can't determine whether it is downward\n+          return false;\n+        }\n         if (statePriorityMap.get(currentState) > statePriorityMap.get(bestPossibleState)) {\n           return false;\n         }",
                "raw_url": "https://github.com/apache/helix/raw/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "sha": "c156c066f9c2f4eb7bb5ff1147e42d382811b332",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/helix/blob/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java?ref=cf010f90426003dab7e713945c2c9daa23ffed13",
                "deletions": 2,
                "filename": "helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "patch": "@@ -70,7 +70,7 @@\n \n   private final List<String> _stateTransitionPriorityList;\n \n-  Map<String, Integer> _statesPriorityMap = new HashMap<String, Integer>();\n+  private Map<String, Integer> _statesPriorityMap = new HashMap<>();\n \n   /**\n    * StateTransition which is used to find the nextState given StartState and\n@@ -112,9 +112,17 @@ public StateModelDefinition(ZNRecord record) {\n       }\n     }\n \n+    // add HelixDefinedStates to statesPriorityMap in case it hasn't been added already\n+    for (HelixDefinedState state : HelixDefinedState.values()) {\n+      if (!_statesPriorityMap.containsKey(state.name())) {\n+        // Make it the lowest priority\n+        _statesPriorityMap.put(state.name(), Integer.MAX_VALUE);\n+      }\n+    }\n+\n     // add transitions for helix-defined states\n     for (HelixDefinedState state : HelixDefinedState.values()) {\n-      if (!_statesPriorityList.contains(state.toString())) {\n+      if (_statesPriorityList == null || !_statesPriorityList.contains(state.toString())) {\n         _statesCountMap.put(state.toString(), \"-1\");\n       }\n     }",
                "raw_url": "https://github.com/apache/helix/raw/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "sha": "ae5952225ec40c6b1ffce1176fb7877a6831d2e2",
                "status": "modified"
            }
        ],
        "message": "[HELIX-770] HELIX: Fix a possible NPE in loadBalance in IntermediateStateCalcStage\n\nIn isLoadBalanceDownwardForAllReplicas() in IntermediateStateCalcStage, statePriorityMap was throwing a NPE because the partition contained a replica in ERROR state, and the map did not have an entry for it. To amend the issue, Venice added the ERROR state in the state model with a priority, and Helix added checks to prevent NPEs.\nChangelist:\n1. Add containsKey checks in isLoadBalanceDownwardForAllReplicas()\n2. Make the Controller correctly log all partitions with ERROR state replicas\n3. Add HelixDefinedStates in statePriorityList if not already added",
        "parent": "https://github.com/apache/helix/commit/7bb55742e2fe2b61c634dd559cf86a71da50fcdf",
        "repo": "helix",
        "unit_tests": [
            "TestIntermediateStateCalcStage.java"
        ]
    },
    "helix_d9ac96e": {
        "bug_id": "helix_d9ac96e",
        "commit": "https://github.com/apache/helix/commit/d9ac96eb842d2025168bce5a87268c5bc5bd3a77",
        "file": [
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/helix/blob/d9ac96eb842d2025168bce5a87268c5bc5bd3a77/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=d9ac96eb842d2025168bce5a87268c5bc5bd3a77",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "patch": "@@ -132,6 +132,8 @@ MessageHandlerFactory factory() {\n   // timer for schedule timeout tasks\n   final Timer _timer;\n \n+  private boolean _isShuttingDown;\n+\n   public HelixTaskExecutor() {\n     this(new ParticipantStatusMonitor(false, null));\n   }\n@@ -157,6 +159,8 @@ public HelixTaskExecutor(ParticipantStatusMonitor participantStatusMonitor) {\n \n     _timer = new Timer(true); // created as a daemon timer thread to handle task timeout\n \n+    _isShuttingDown = false;\n+\n     startMonitorThread();\n   }\n \n@@ -173,6 +177,8 @@ public void registerMessageHandlerFactory(String type, MessageHandlerFactory fac\n           + factory.getMessageTypes());\n     }\n \n+    _isShuttingDown = false;\n+\n     MsgHandlerFactoryRegistryItem newItem =\n         new MsgHandlerFactoryRegistryItem(factory, threadpoolSize);\n     MsgHandlerFactoryRegistryItem prevItem = _hdlrFtyRegistry.putIfAbsent(type, newItem);\n@@ -386,6 +392,13 @@ public boolean scheduleTask(MessageTask task) {\n         if (!_taskMap.containsKey(taskId)) {\n           ExecutorService exeSvc = findExecutorServiceForMsg(message);\n \n+          if (exeSvc == null) {\n+            LOG.warn(String\n+                .format(\"Threadpool is null for type %s of message %s\", message.getMsgType(),\n+                    message.getMsgId()));\n+            return false;\n+          }\n+\n           LOG.info(\"Submit task: \" + taskId + \" to pool: \" + exeSvc);\n           Future<HelixTaskResult> future = exeSvc.submit(task);\n \n@@ -586,6 +599,8 @@ void init() {\n       _messageQueueMonitor.init();\n     }\n \n+    _isShuttingDown = false;\n+\n     // Re-init all existing factories\n     for (String msgType : _hdlrFtyRegistry.keySet()) {\n       MsgHandlerFactoryRegistryItem item = _hdlrFtyRegistry.get(msgType);\n@@ -649,6 +664,16 @@ public void onMessage(String instanceName, List<Message> messages,\n       // continue to process messages\n     }\n \n+    if (_isShuttingDown) {\n+      StringBuilder sb = new StringBuilder();\n+      for (Message message : messages) {\n+        sb.append(message.getMsgId() + \",\");\n+      }\n+      LOG.info(\n+          \"Helix task executor is shutting down, discard unprocessed messages : \" + sb.toString());\n+      return;\n+    }\n+\n     if (messages == null || messages.size() == 0) {\n       LOG.info(\"No Messages to process\");\n       return;\n@@ -953,6 +978,7 @@ private void removeMessageFromZk(HelixDataAccessor accessor, Message message,\n   @Override\n   public void shutdown() {\n     LOG.info(\"Shutting down HelixTaskExecutor\");\n+    _isShuttingDown = true;\n     _timer.cancel();\n \n     reset();",
                "raw_url": "https://github.com/apache/helix/raw/d9ac96eb842d2025168bce5a87268c5bc5bd3a77/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "sha": "ad4a2767687a5a1634879c706cd4c5d6e767464e",
                "status": "modified"
            }
        ],
        "message": "Fix NPEs for HelixTask Executors\n\nHelixTaskExecutors has some NPEs when participant disconnects from ZK. Fix those NPEs by protective checks and shut downs signals.\nx",
        "parent": "https://github.com/apache/helix/commit/9178f035569db3288590ae505c2b692aaf27700a",
        "repo": "helix",
        "unit_tests": [
            "TestHelixTaskExecutor.java"
        ]
    },
    "helix_dca1ed0": {
        "bug_id": "helix_dca1ed0",
        "commit": "https://github.com/apache/helix/commit/dca1ed05bfccce69814fdb59b095d734d1c82de0",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/dca1ed05bfccce69814fdb59b095d734d1c82de0/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=dca1ed05bfccce69814fdb59b095d734d1c82de0",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "patch": "@@ -463,6 +463,11 @@ public void updateJobCounters(JobConfig jobConfig, TaskState to) {\n   }\n \n   private void updateJobGauges(JobConfig jobConfig, TaskState current) {\n+    // When first time for WorkflowRebalancer call, jobconfig may not ready.\n+    // Thus only check it for gauge.\n+    if (jobConfig == null) {\n+      return;\n+    }\n     String jobType = jobConfig.getJobType();\n     jobType = preProcessJobMonitor(jobType);\n     _perTypeJobMonitorMap.get(jobType).updateJobGauge(current);",
                "raw_url": "https://github.com/apache/helix/raw/dca1ed05bfccce69814fdb59b095d734d1c82de0/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "sha": "7f996c5a2896276675fb2be68ee1afc41bfe7fcb",
                "status": "modified"
            }
        ],
        "message": "Fix NPE when first time call WorkflowRebalancer",
        "parent": "https://github.com/apache/helix/commit/f5705dc9201716543c72427c004f1f64211e304e",
        "repo": "helix",
        "unit_tests": [
            "TestClusterStatusMonitor.java"
        ]
    },
    "helix_fe5062f": {
        "bug_id": "helix_fe5062f",
        "commit": "https://github.com/apache/helix/commit/fe5062f5d7f230c41524d0d0ac66a955f4c3661f",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/helix/blob/fe5062f5d7f230c41524d0d0ac66a955f4c3661f/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=fe5062f5d7f230c41524d0d0ac66a955f4c3661f",
                "deletions": 0,
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "patch": "@@ -493,6 +493,11 @@ public void updateJobCounters(JobConfig jobConfig, TaskState to) {\n   }\n \n   private void updateJobGauges(JobConfig jobConfig, TaskState current) {\n+    // When first time for WorkflowRebalancer call, jobconfig may not ready.\n+    // Thus only check it for gauge.\n+    if (jobConfig == null) {\n+      return;\n+    }\n     String jobType = jobConfig.getJobType();\n     jobType = preProcessJobMonitor(jobType);\n     _perTypeJobMonitorMap.get(jobType).updateJobGauge(current);",
                "raw_url": "https://github.com/apache/helix/raw/fe5062f5d7f230c41524d0d0ac66a955f4c3661f/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "sha": "95ee43f2ad84e999f8c2b17bbf4c0f1f98e44cd5",
                "status": "modified"
            }
        ],
        "message": "Fix NPE when first time call WorkflowRebalancer",
        "parent": "https://github.com/apache/helix/commit/f117e24522b0da3dc983f27faa3a427b156124a2",
        "repo": "helix",
        "unit_tests": [
            "TestClusterStatusMonitor.java"
        ]
    }
}