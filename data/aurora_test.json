{
    "aurora_0e12155": {
        "bug_id": "aurora_0e12155",
        "commit": "https://github.com/apache/aurora/commit/0e1215538c485f1a8f23cff0ba8b0be29c31793e",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/aurora/blob/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java?ref=0e1215538c485f1a8f23cff0ba8b0be29c31793e",
                "deletions": 1,
                "filename": "src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "patch": "@@ -207,7 +207,12 @@ private void killAndMaybeReserve(\n         IJobUpdateInstructions instructions) throws UpdateStateException {\n \n       if (status == ROLLING_FORWARD) {\n-        return Optional.ofNullable(instructions.getDesiredState().getTask().getSlaPolicy());\n+        // It is possible that an update only removes instances. In this case, there is no desired\n+        // state. Otherwise, get the task associated (this should never be null) and return an\n+        // optional of the SlaPolicy of the task (or empty if null).\n+        return Optional\n+            .ofNullable(instructions.getDesiredState())\n+            .map(desiredState -> desiredState.getTask().getSlaPolicy());\n       } else if (status == ROLLING_BACK) {\n         return getConfig(instance.getInstanceId(), instructions.getInitialState())\n             .map(ITaskConfig::getSlaPolicy);",
                "raw_url": "https://github.com/apache/aurora/raw/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "sha": "97906b5a0306aeac0930276deb950d825e52d778",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/aurora/blob/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora?ref=0e1215538c485f1a8f23cff0ba8b0be29c31793e",
                "deletions": 1,
                "filename": "src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "patch": "@@ -18,6 +18,7 @@ class DefaultProfile(Struct):\n   role=Default(String, getpass.getuser())\n   cmd=Default(String, 'cp /vagrant/src/test/sh/org/apache/aurora/e2e/http_example.py .')\n   gpu=Default(Integer, 0)\n+  instances=Default(Integer, 1)\n \n \n ContainerProfile = DefaultProfile(\n@@ -115,7 +116,7 @@ shell_health_check_config = HealthCheckConfig(\n \n job = Service(\n   cluster = 'devcluster',\n-  instances = 1,\n+  instances = '{{profile.instances}}',\n   update_config = update_config,\n   health_check_config = health_check_config,\n   task = test_task,",
                "raw_url": "https://github.com/apache/aurora/raw/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "sha": "bd4d4a17f2f60fbaa7736c1684f8e956a7e6984a",
                "status": "modified"
            },
            {
                "additions": 59,
                "blob_url": "https://github.com/apache/aurora/blob/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "changes": 76,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh?ref=0e1215538c485f1a8f23cff0ba8b0be29c31793e",
                "deletions": 17,
                "filename": "src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "patch": "@@ -213,7 +213,7 @@ test_restart() {\n   aurora job restart --batch-size=2 --watch-secs=10 $_jobkey\n }\n \n-assert_update_state() {\n+assert_active_update_state() {\n   local _jobkey=$1 _expected_state=$2\n \n   local _state=$(aurora update list $_jobkey --status active | tail -n +2 | awk '{print $3}')\n@@ -223,6 +223,17 @@ assert_update_state() {\n   fi\n }\n \n+assert_update_state_by_id() {\n+  # Assert that a given update ID is in an expected state\n+  local _jobkey=$1 _update_id=$2 _expected_state=$3\n+\n+  local _state=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n+  if [[ $_state != $_expected_state ]]; then\n+    echo \"Update should have completed in $_expected_state state, but found $_state\"\n+    exit 1\n+  fi\n+}\n+\n assert_task_status() {\n   local _jobkey=$1 _id=$2 _expected_state=$3\n \n@@ -294,30 +305,64 @@ wait_until_task_counts() {\n   fi\n }\n \n+test_update_add_only_kill_only() {\n+  # Tests update functionality where we only add or kill instances\n+  local _jobkey=$1 _config=$2 _cluster=$3\n+  shift 3\n+  local _extra_args=\"${@}\"\n+\n+  # Create the initial update with 3 instances\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=3\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_state_by_id $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 3 0\n+\n+  # Update and kill 2 instances only\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=1\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_state_by_id $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 1 0\n+\n+  # Update and add 2 instances only\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=3\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_state_by_id $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 3 0\n+\n+  # Clean up\n+  aurora job killall $_jobkey\n+}\n+\n test_update() {\n+  # Tests generic update functionality like pausing and resuming\n   local _jobkey=$1 _config=$2 _cluster=$3\n   shift 3\n   local _extra_args=\"${@}\"\n \n   aurora update start $_jobkey $_config $_extra_args\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n       | tail -n +2 | awk '{print $2}')\n   aurora_admin scheduler_snapshot devcluster\n   sudo systemctl restart aurora-scheduler\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   aurora update pause $_jobkey --message='hello'\n-  assert_update_state $_jobkey 'ROLL_FORWARD_PAUSED'\n+  assert_active_update_state $_jobkey 'ROLL_FORWARD_PAUSED'\n   aurora update resume $_jobkey\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   aurora update wait $_jobkey $_update_id\n \n   # Check that the update ended in ROLLED_FORWARD state.  Assumes the status is the last column.\n-  local status=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n-  if [[ $status != \"ROLLED_FORWARD\" ]]; then\n-    echo \"Update should have completed in ROLLED_FORWARD state\"\n-    exit 1\n-  fi\n+  assert_update_state_by_id $_jobkey $_update_id 'ROLLED_FORWARD'\n }\n \n test_update_fail() {\n@@ -327,7 +372,7 @@ test_update_fail() {\n \n   # Make sure our updates works.\n   aurora update start $_jobkey $_config $_extra_args\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n       | tail -n +2 | awk '{print $2}')\n   # Need to wait until udpate finishes before we can start one that we want to fail.\n@@ -339,12 +384,8 @@ test_update_fail() {\n       | tail -n +2 | awk '{print $2}')\n   # || is so that we don't return an EXIT so that `trap collect_result` doesn't get triggered.\n   aurora update wait $_jobkey $_update_id || echo $?\n-  # Making sure we rolled back.\n-  local status=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n-  if [[ $status != \"ROLLED_BACK\" ]]; then\n-    echo \"Update should have completed in ROLLED_BACK state due to failed healthcheck.\"\n-    exit 1\n-  fi\n+  # Making sure we rolled back due to a failed health check\n+  assert_update_state_by_id $_jobkey $_update_id 'ROLLED_BACK'\n }\n \n test_partition_awareness() {\n@@ -665,6 +706,7 @@ test_http_example() {\n   test_thermos_profile $_jobkey\n   test_file_mount $_cluster $_role $_env $_job\n   test_restart $_jobkey\n+  test_update_add_only_kill_only $_jobkey $_base_config $_cluster $_bind_parameters\n   test_update $_jobkey $_updated_config $_cluster $_bind_parameters\n   test_update_fail $_jobkey $_base_config  $_cluster $_bad_healthcheck_config $_bind_parameters\n   # Running test_update second time to change state to success.",
                "raw_url": "https://github.com/apache/aurora/raw/0e1215538c485f1a8f23cff0ba8b0be29c31793e/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "sha": "7c68679871533e206ee1af817f0705b710e8883e",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #33 from jordanly/jly/fix-npe-in-sla-aware-updates\n\nFix possible NullPointerException in InstanceActionHandler",
        "parent": "https://github.com/apache/aurora/commit/d46a8d91aa69ab9cf1ebc2b13552f8093d366fe9",
        "patched_files": [
            "http_example.java",
            "InstanceActionHandler.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "test_end_to_end.java"
        ]
    },
    "aurora_10ed36a": {
        "bug_id": "aurora_10ed36a",
        "commit": "https://github.com/apache/aurora/commit/10ed36a7477282b5dac35ca9ba82732eddf47a2f",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/aurora/blob/10ed36a7477282b5dac35ca9ba82732eddf47a2f/src/java/com/twitter/mesos/scheduler/SchedulerCoreImpl.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/java/com/twitter/mesos/scheduler/SchedulerCoreImpl.java?ref=10ed36a7477282b5dac35ca9ba82732eddf47a2f",
                "deletions": 0,
                "filename": "src/java/com/twitter/mesos/scheduler/SchedulerCoreImpl.java",
                "patch": "@@ -30,6 +30,7 @@\n import com.twitter.mesos.ExecutorKey;\n import com.twitter.mesos.Tasks;\n import com.twitter.mesos.gen.AssignedTask;\n+import com.twitter.mesos.gen.Constraint;\n import com.twitter.mesos.gen.Identity;\n import com.twitter.mesos.gen.JobConfiguration;\n import com.twitter.mesos.gen.Quota;\n@@ -274,6 +275,7 @@ private static TwitterTaskInfo makeBootstrapTask() {\n         .setRamMb(1)\n         .setShardId(0)\n         .setRequestedPorts(ImmutableSet.<String>of())\n+        .setConstraints(ImmutableSet.<Constraint>of())\n         .setStartCommand(\"echo \\\"Bootstrapping\\\"\");\n   }\n ",
                "raw_url": "https://github.com/apache/aurora/raw/10ed36a7477282b5dac35ca9ba82732eddf47a2f/src/java/com/twitter/mesos/scheduler/SchedulerCoreImpl.java",
                "sha": "d594050cf67c85d0123d911703dab82e993b3b8a",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/aurora/blob/10ed36a7477282b5dac35ca9ba82732eddf47a2f/src/java/com/twitter/mesos/scheduler/configuration/ConfigurationManager.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/java/com/twitter/mesos/scheduler/configuration/ConfigurationManager.java?ref=10ed36a7477282b5dac35ca9ba82732eddf47a2f",
                "deletions": 3,
                "filename": "src/java/com/twitter/mesos/scheduler/configuration/ConfigurationManager.java",
                "patch": "@@ -46,7 +46,7 @@\n   private static final Logger LOG = Logger.getLogger(ConfigurationManager.class.getName());\n \n   private static final Pattern GOOD_IDENTIFIER_PATTERN = Pattern.compile(\"[\\\\w\\\\-\\\\.]+\");\n-  private static final String HOST_CONSTRAINT = \"host\";\n+  @VisibleForTesting public static final String HOST_CONSTRAINT = \"host\";\n   private static final int MAX_IDENTIFIED_LENGTH = 255;\n \n   @VisibleForTesting\n@@ -341,8 +341,7 @@ public static void resetStartCommand(TwitterTaskInfo task) {\n             LOG.info(\"Task configuration uses deprecated max_per_host.\");\n \n             // TODO(wfarner): Remove this once the mesos client is updated to supply it.\n-            task.addToConstraints(new Constraint(HOST_CONSTRAINT,\n-                TaskConstraint.limit(new LimitConstraint(value))));\n+            task.addToConstraints(hostLimitConstraint(1));\n           }\n         }\n       })\n@@ -360,6 +359,11 @@ public static void resetStartCommand(TwitterTaskInfo task) {\n       })\n       .build();\n \n+  @VisibleForTesting\n+  public static Constraint hostLimitConstraint(int limit) {\n+    return new Constraint(HOST_CONSTRAINT, TaskConstraint.limit(new LimitConstraint(limit)));\n+  }\n+\n   private static Predicate<Constraint> hasName(final String name) {\n     MorePreconditions.checkNotBlank(name);\n     return new Predicate<Constraint>() {",
                "raw_url": "https://github.com/apache/aurora/raw/10ed36a7477282b5dac35ca9ba82732eddf47a2f/src/java/com/twitter/mesos/scheduler/configuration/ConfigurationManager.java",
                "sha": "92a6e615a8c152dc747d93203a606ad19915fd02",
                "status": "modified"
            },
            {
                "additions": 70,
                "blob_url": "https://github.com/apache/aurora/blob/10ed36a7477282b5dac35ca9ba82732eddf47a2f/tests/java/com/twitter/mesos/scheduler/BaseSchedulerCoreImplTest.java",
                "changes": 140,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/tests/java/com/twitter/mesos/scheduler/BaseSchedulerCoreImplTest.java?ref=10ed36a7477282b5dac35ca9ba82732eddf47a2f",
                "deletions": 70,
                "filename": "tests/java/com/twitter/mesos/scheduler/BaseSchedulerCoreImplTest.java",
                "patch": "@@ -9,6 +9,9 @@\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.logging.Level;\n+import java.util.logging.LogManager;\n+import java.util.logging.Logger;\n \n import javax.annotation.Nullable;\n \n@@ -25,6 +28,7 @@\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n \n+import org.apache.mesos.Protos.Attribute;\n import org.apache.mesos.Protos.ExecutorID;\n import org.apache.mesos.Protos.FrameworkID;\n import org.apache.mesos.Protos.Offer;\n@@ -34,6 +38,7 @@\n import org.apache.mesos.Protos.Value.Range;\n import org.apache.mesos.Protos.Value.Ranges;\n import org.apache.mesos.Protos.Value.Scalar;\n+import org.apache.mesos.Protos.Value.Text;\n import org.apache.mesos.Protos.Value.Type;\n import org.easymock.EasyMock;\n import org.easymock.IAnswer;\n@@ -48,6 +53,7 @@\n import com.twitter.common.util.testing.FakeClock;\n import com.twitter.mesos.ExecutorKey;\n import com.twitter.mesos.Tasks;\n+import com.twitter.mesos.executor.Task;\n import com.twitter.mesos.gen.AssignedTask;\n import com.twitter.mesos.gen.Constraint;\n import com.twitter.mesos.gen.CronCollisionPolicy;\n@@ -114,7 +120,9 @@\n   private static final Identity OWNER_A = new Identity(\"Test_Role_A\", \"Test_User_A\");\n   private static final String JOB_A = \"Test_Job_A\";\n   private static final String JOB_A_KEY = Tasks.jobKey(OWNER_A, JOB_A);\n-  private static final Quota DEFAULT_TASK_QUOTA = new Quota(1.0, 1024, 1024);\n+  private static final int ONE_GB = 1024;\n+  private static final int FOUR_GB = 4096;\n+  private static final Quota DEFAULT_TASK_QUOTA = new Quota(1.0, ONE_GB, ONE_GB);\n   private static final int DEFAULT_TASKS_IN_QUOTA = 10;\n \n   private static final Identity OWNER_B = new Identity(\"Test_Role_B\", \"Test_User_B\");\n@@ -129,6 +137,7 @@\n \n   private static final OfferID OFFER_ID = OfferID.newBuilder().setValue(\"OfferId\").build();\n \n+\n   private SchedulingFilter schedulingFilter;\n   private Driver driver;\n   private StateManager stateManager;\n@@ -140,7 +149,6 @@\n \n   @Before\n   public void setUp() throws Exception {\n-    schedulingFilter = createMock(SchedulingFilter.class);\n     driver = createMock(Driver.class);\n     executorPulseMonitor = createMock(new Clazz<PulseMonitor<ExecutorKey>>() {});\n     clock = new FakeClock();\n@@ -171,6 +179,7 @@ private void buildScheduler(Storage storage) throws Exception {\n     cron = new CronJobManager(storage, new TearDownRegistry(this));\n     stateManager = new StateManager(storage, clock, new MutableState(), driver);\n     quotaManager = new QuotaManagerImpl(storage);\n+    schedulingFilter = new SchedulingFilterImpl(ImmutableMap.<String, String>of(), storage);\n     scheduler = new SchedulerCoreImpl(cron, immediateManager, stateManager, schedulingFilter,\n         executorPulseMonitor, quotaManager);\n     cron.schedulerCore = scheduler;\n@@ -280,7 +289,7 @@ public void testCreateJob() throws Exception {\n   public void testLoadTasksFromStorage() throws Exception {\n     final String storedTaskId = \"task_on_disk\";\n \n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n     control.replay();\n \n@@ -292,7 +301,7 @@ public void testLoadTasksFromStorage() throws Exception {\n         .setOwner(OWNER_A)\n         .setJobName(JOB_A)\n         .setNumCpus(1.0)\n-        .setRamMb(1024)\n+        .setRamMb(ONE_GB)\n         .setDiskMb(500)\n         .setShardId(0)\n         .setStartCommand(\"ls\")\n@@ -316,7 +325,7 @@ public void testLoadTasksFromStorage() throws Exception {\n     // Check that the missing event was synthesized.\n     assertThat(Iterables.getLast(getTask(storedTaskId).getTaskEvents()).getStatus(), is(PENDING));\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB);\n     TwitterTask launchedTask = scheduler.offer(offer, EXECUTOR_ID);\n \n     // Since task fields are backfilled with defaults, the production flag and thermos config\n@@ -338,17 +347,18 @@ public void testShardUniquenessCorrection() throws Exception {\n     final AtomicInteger taskId = new AtomicInteger();\n \n     JobConfiguration job = makeJob(OWNER_A, JOB_A, 10);\n-    final Set<ScheduledTask> badTasks = ImmutableSet.copyOf(Iterables.transform(job.getTaskConfigs(),\n-        new Function<TwitterTaskInfo, ScheduledTask>() {\n-          @Override public ScheduledTask apply(TwitterTaskInfo task) {\n-            return new ScheduledTask()\n-                .setStatus(RUNNING)\n-                .setAssignedTask(\n-                    new AssignedTask()\n-                      .setTaskId(\"task-\" + taskId.incrementAndGet())\n-                      .setTask(task.setShardId(0)));\n-          }\n-        }));\n+    final Set<ScheduledTask> badTasks = ImmutableSet.copyOf(Iterables\n+        .transform(job.getTaskConfigs(),\n+            new Function<TwitterTaskInfo, ScheduledTask>() {\n+              @Override public ScheduledTask apply(TwitterTaskInfo task) {\n+                return new ScheduledTask()\n+                    .setStatus(RUNNING)\n+                    .setAssignedTask(\n+                        new AssignedTask()\n+                            .setTaskId(\"task-\" + taskId.incrementAndGet())\n+                            .setTask(task.setShardId(0)));\n+              }\n+            }));\n \n     storage.doInTransaction(new NoResult.Quiet() {\n       @Override protected void execute(Storage.StoreProvider storeProvider) {\n@@ -366,7 +376,7 @@ public void testShardUniquenessCorrection() throws Exception {\n   public void testBackfillRequestedPorts() throws Exception {\n     final String storedTaskId = \"task_on_disk\";\n \n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n     control.replay();\n \n@@ -378,7 +388,7 @@ public void testBackfillRequestedPorts() throws Exception {\n         .setOwner(OWNER_A)\n         .setJobName(JOB_A)\n         .setNumCpus(1.0)\n-        .setRamMb(1024)\n+        .setRamMb(ONE_GB)\n         .setDiskMb(500)\n         .setShardId(0)\n         .setStartCommand(\"ls %port:foo%\")\n@@ -397,7 +407,8 @@ public void testBackfillRequestedPorts() throws Exception {\n \n     buildScheduler(storage);\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096, ImmutableSet.of(Pair.of(80, 81)));\n+    Offer offer =\n+        createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB, ImmutableSet.of(Pair.of(80, 81)));\n     TwitterTask launchedTask = scheduler.offer(offer, EXECUTOR_ID);\n \n     assertEquals(ImmutableSet.of(\"foo\"), launchedTask.task.getTask().getRequestedPorts());\n@@ -416,7 +427,7 @@ public void testBackfillRequestedPortsForCronJob() throws Exception {\n         .setOwner(OWNER_A)\n         .setJobName(JOB_A)\n         .setNumCpus(1.0)\n-        .setRamMb(1024)\n+        .setRamMb(ONE_GB)\n         .setDiskMb(500)\n         .setShardId(0)\n         .setStartCommand(\"ls %port:foo%\")\n@@ -425,7 +436,8 @@ public void testBackfillRequestedPortsForCronJob() throws Exception {\n     storage.doInTransaction(new NoResult.Quiet() {\n       @Override protected void execute(Storage.StoreProvider storeProvider) {\n         storeProvider.getJobStore().saveAcceptedJob(\n-            CronJobManager.MANAGER_KEY, makeJob(OWNER_A, JOB_A, storedTask, 1).setCronSchedule(\"1 1 1 1 1\"));\n+            CronJobManager.MANAGER_KEY, makeJob(OWNER_A, JOB_A, storedTask, 1)\n+            .setCronSchedule(\"1 1 1 1 1\"));\n       }\n     });\n \n@@ -435,8 +447,8 @@ public void testBackfillRequestedPortsForCronJob() throws Exception {\n \n     scheduler.startCronJob(OWNER_A.getRole(), JOB_A);\n \n-    assertEquals(\n-        ImmutableSet.of(\"foo\"), getOnlyTask(queryJob(OWNER_A, JOB_A)).getAssignedTask().getTask().getRequestedPorts());\n+    assertEquals(ImmutableSet.of(\"foo\"),\n+        getOnlyTask(queryJob(OWNER_A, JOB_A)).getAssignedTask().getTask().getRequestedPorts());\n   }\n \n   @Test\n@@ -686,7 +698,6 @@ public void testCreateJobShardIdHole() throws Exception {\n   @Test\n   public void testHonorsScheduleFilter() throws Exception {\n     expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n-    expectFiltering(true).anyTimes();\n     expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n     expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n@@ -697,7 +708,7 @@ public void testHonorsScheduleFilter() throws Exception {\n \n     assertTaskCount(10);\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, 1);\n \n     assertNull(scheduler.offer(offer, EXECUTOR_ID));\n     assertNull(scheduler.offer(offer, EXECUTOR_ID));\n@@ -1169,23 +1180,26 @@ private void sendOffer(Offer offer, String taskId, SlaveID slave, String slaveHo\n   public void testExecutorBootstrap() throws Exception {\n     expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(false);\n     executorPulseMonitor.pulse(EasyMock.<ExecutorKey>anyObject());\n-    expectFiltering(false);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 3, 4096);\n-    final Resources offerResources = Resources.from(offer);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 3, FOUR_GB, ONE_GB);\n \n     control.replay();\n \n     buildScheduler();\n     TwitterTask scheduledTask =  scheduler.offer(offer, EXECUTOR_ID);\n     assertNotNull(scheduledTask);\n     assertEquals(scheduledTask.task.getTask().getJobName(), \"executor_bootstrap\");\n+\n+    // Force the task to be rescheduled.  This should help weed out bugs where ConfigurationManager\n+    // populates fields in normal tasks that are not present in the bootstrap task.\n+    changeStatus(scheduledTask.taskId, LOST);\n+    assertNotNull(scheduler.offer(offer, EXECUTOR_ID));\n   }\n \n   @Test\n   public void testSlaveDeletesTasks() throws Exception {\n-    expectOffer(true);\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true).times(2);\n \n     control.replay();\n     buildScheduler();\n@@ -1195,7 +1209,7 @@ public void testSlaveDeletesTasks() throws Exception {\n     String taskId1 = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 0)));\n     String taskId2 = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 1)));\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB);\n     sendOffer(offer, taskId1, SLAVE_ID, SLAVE_HOST_1);\n     sendOffer(offer, taskId2, SLAVE_ID, SLAVE_HOST_1);\n \n@@ -1218,12 +1232,7 @@ public void testSlaveDeletesTasks() throws Exception {\n \n   @Test\n   public void testSchedulingOrder() throws Exception {\n-    expectOffer(true);\n-    expectOffer(true);\n-    expectOffer(true);\n-    expectOffer(true);\n-    expectOffer(true);\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true).times(6);\n \n     control.replay();\n     buildScheduler();\n@@ -1243,7 +1252,7 @@ public void testSchedulingOrder() throws Exception {\n     String taskId3a = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_B), 0)));\n     String taskId3b = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_B), 1)));\n \n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB);\n     sendOffer(offer, taskId2a, SLAVE_ID, SLAVE_HOST_1);\n     sendOffer(offer, taskId2b, SLAVE_ID, SLAVE_HOST_1);\n     sendOffer(offer, taskId1a, SLAVE_ID, SLAVE_HOST_1);\n@@ -1705,7 +1714,7 @@ public void testDecreaseShardsRollback() throws Exception {\n \n   @Test\n   public void testTaskIdExpansion() throws Exception {\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n     control.replay();\n     buildScheduler();\n@@ -1715,7 +1724,7 @@ public void testTaskIdExpansion() throws Exception {\n     scheduler.createJob(makeJob(OWNER_A, JOB_A, config, 1));\n \n     String taskId = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 0)));\n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB);\n     sendOffer(offer, taskId, SLAVE_ID, SLAVE_HOST_1);\n \n     AssignedTask task = getTask(taskId).getAssignedTask();\n@@ -1724,7 +1733,7 @@ public void testTaskIdExpansion() throws Exception {\n \n   @Test\n   public void testShardIdExpansion() throws Exception {\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n \n     control.replay();\n     buildScheduler();\n@@ -1734,7 +1743,7 @@ public void testShardIdExpansion() throws Exception {\n     scheduler.createJob(makeJob(OWNER_A, JOB_A, config, 1));\n \n     String taskId = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 0)));\n-    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096);\n+    Offer offer = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB);\n     sendOffer(offer, taskId, SLAVE_ID, SLAVE_HOST_1);\n \n     AssignedTask task = getTask(taskId).getAssignedTask();\n@@ -1743,7 +1752,7 @@ public void testShardIdExpansion() throws Exception {\n \n   @Test\n   public void testPortResource() throws Exception {\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true);\n     control.replay();\n     buildScheduler();\n \n@@ -1755,7 +1764,7 @@ public void testPortResource() throws Exception {\n     String taskId = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 0)));\n \n     Set<Integer> assignedPorts = ImmutableSet.of(80, 81, 82);\n-    Offer threePorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096,\n+    Offer threePorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB,\n         ImmutableSet.of(Pair.of(80, 82)));\n     sendOffer(threePorts, taskId, SLAVE_ID, SLAVE_HOST_1,\n         ImmutableSet.of(\"one\", \"two\", \"three\"), assignedPorts);\n@@ -1768,8 +1777,7 @@ public void testPortResource() throws Exception {\n \n   @Test\n   public void testPortResourceResetAfterReschedule() throws Exception {\n-    expectOffer(true);\n-    expectOffer(true);\n+    expect(executorPulseMonitor.isAlive(SLAVE_HOST_1_KEY)).andReturn(true).times(2);\n \n     control.replay();\n     buildScheduler();\n@@ -1782,7 +1790,7 @@ public void testPortResourceResetAfterReschedule() throws Exception {\n     String taskId = Tasks.id(getOnlyTask(Query.liveShard(Tasks.jobKey(OWNER_A, JOB_A), 0)));\n \n     Set<Integer> assignedPorts = ImmutableSet.of(80);\n-    Offer threePorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096,\n+    Offer threePorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB,\n         ImmutableSet.of(Pair.of(80, 80)));\n     sendOffer(threePorts, taskId, SLAVE_ID, SLAVE_HOST_1, ImmutableSet.of(\"one\"), assignedPorts);\n \n@@ -1796,7 +1804,7 @@ public void testPortResourceResetAfterReschedule() throws Exception {\n     assertThat(getTask(newTaskId).getAssignedTask().getTask().getStartCommand(), is(\"%port:one%\"));\n \n     assignedPorts = ImmutableSet.of(86);\n-    Offer threeOtherPorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, 4096,\n+    Offer threeOtherPorts = createOffer(SLAVE_ID, SLAVE_HOST_1, 4, FOUR_GB, ONE_GB,\n         ImmutableSet.of(Pair.of(86, 86)));\n     sendOffer(threeOtherPorts, newTaskId, SLAVE_ID, SLAVE_HOST_1, ImmutableSet.of(\"one\"),\n         assignedPorts);\n@@ -1931,12 +1939,13 @@ private static JobConfiguration makeJob(Identity owner, String jobName,\n   }\n \n   private static Offer createOffer(SlaveID slave, String slaveHost, double cpu,\n-      double ramMb) {\n-    return createOffer(slave, slaveHost, cpu, ramMb, ImmutableSet.<Pair<Integer, Integer>>of());\n+      double ramMb, double diskMb) {\n+    return createOffer(slave, slaveHost, cpu, ramMb, diskMb,\n+        ImmutableSet.<Pair<Integer, Integer>>of());\n   }\n \n   private static Offer createOffer(SlaveID slave, String slaveHost, double cpu,\n-      double ramMb, Set<Pair<Integer, Integer>> ports) {\n+      double ramMb, double diskMb, Set<Pair<Integer, Integer>> ports) {\n \n     Ranges portRanges = Ranges.newBuilder()\n         .addAllRange(Iterables.transform(ports, new Function<Pair<Integer, Integer>, Range>() {\n@@ -1951,8 +1960,13 @@ private static Offer createOffer(SlaveID slave, String slaveHost, double cpu,\n             .setScalar(Scalar.newBuilder().setValue(cpu)))\n         .addResources(Resource.newBuilder().setType(Type.SCALAR).setName(Resources.RAM_MB)\n             .setScalar(Scalar.newBuilder().setValue(ramMb)))\n+        .addResources(Resource.newBuilder().setType(Type.SCALAR).setName(Resources.DISK_MB)\n+            .setScalar(Scalar.newBuilder().setValue(diskMb)))\n         .addResources(Resource.newBuilder().setType(Type.RANGES).setName(Resources.PORTS)\n             .setRanges(portRanges))\n+        .addAttributes(Attribute.newBuilder().setType(Type.TEXT)\n+            .setName(ConfigurationManager.HOST_CONSTRAINT)\n+            .setText(Text.newBuilder().setValue(slaveHost)))\n         .setSlaveId(slave)\n         .setHostname(slaveHost)\n         .setFrameworkId(FrameworkID.newBuilder().setValue(FRAMEWORK_ID).build())\n@@ -1977,7 +1991,11 @@ private static TwitterTaskInfo defaultTask(boolean production, String... additio\n       params.put(additionalParams[i], additionalParams[i + 1]);\n     }\n \n-    return new TwitterTaskInfo().setConfiguration(ImmutableMap.copyOf(params));\n+    TwitterTaskInfo task = new TwitterTaskInfo().setConfiguration(ImmutableMap.copyOf(params));\n+\n+    // Avoid hitting per-host scheduling constraints.\n+    task.addToConstraints(ConfigurationManager.hostLimitConstraint(100));\n+    return task;\n   }\n \n   private static TwitterTaskInfo productionTask(String... additionalParams) {\n@@ -2059,22 +2077,4 @@ public void changeStatus(String taskId, ScheduleStatus status, @Nullable String\n   private static final ImmutableSet<Veto> ALWAYS_VETO = ImmutableSet.of(new Veto(\"Fake veto\"));\n \n   private static final ImmutableSet<Veto> NO_VETO = ImmutableSet.of();\n-\n-  private void expectOffer(boolean passFilter) {\n-    expect(executorPulseMonitor.isAlive(EasyMock.<ExecutorKey>anyObject())).andReturn(true);\n-    expect(schedulingFilter.filter(EasyMock.<Resources>anyObject(), EasyMock.<Optional<String>>anyObject(), EasyMock.<TwitterTaskInfo>anyObject())).\n-        andReturn(passFilter ? NO_VETO : ALWAYS_VETO);\n-  }\n-\n-  private IExpectationSetters<Set<Veto>> expectFiltering(final boolean filter) {\n-    return expect(schedulingFilter.filter(EasyMock.<Resources>anyObject(),\n-        EasyMock.<Optional<String>>anyObject(),\n-        EasyMock.<TwitterTaskInfo>anyObject())).andAnswer(\n-        new IAnswer<Set<Veto>>() {\n-          @Override public Set<Veto> answer() {\n-            return filter? ALWAYS_VETO : NO_VETO;\n-          }\n-        }\n-    );\n-  }\n }",
                "raw_url": "https://github.com/apache/aurora/raw/10ed36a7477282b5dac35ca9ba82732eddf47a2f/tests/java/com/twitter/mesos/scheduler/BaseSchedulerCoreImplTest.java",
                "sha": "72e2bdb22b6e3d2bd222c058f1004149fd744669",
                "status": "modified"
            }
        ],
        "message": "Reproduced SchedulingFilter NPE in test and fixed.",
        "parent": "https://github.com/apache/aurora/commit/372f50c28a1dd5e8adb2d25149a04b0f995b1177",
        "patched_files": [
            "SchedulerCoreImpl.java",
            "ConfigurationManager.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "BaseSchedulerCoreImplTest.java"
        ]
    },
    "aurora_3665b4a": {
        "bug_id": "aurora_3665b4a",
        "commit": "https://github.com/apache/aurora/commit/3665b4a7ddcdcf7845d4cc2f652fa9f6febda9fc",
        "file": [
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/aurora/blob/3665b4a7ddcdcf7845d4cc2f652fa9f6febda9fc/src/java/com/twitter/mesos/updater/UpdateLogic.java",
                "changes": 52,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/java/com/twitter/mesos/updater/UpdateLogic.java?ref=3665b4a7ddcdcf7845d4cc2f652fa9f6febda9fc",
                "deletions": 8,
                "filename": "src/java/com/twitter/mesos/updater/UpdateLogic.java",
                "patch": "@@ -8,6 +8,7 @@\n import com.twitter.common.util.StateMachine;\n import com.twitter.mesos.gen.UpdateConfig;\n \n+import java.util.Collection;\n import java.util.PriorityQueue;\n import java.util.Set;\n import java.util.logging.Level;\n@@ -17,7 +18,13 @@\n import static com.twitter.common.base.MorePreconditions.checkNotBlank;\n import static com.twitter.mesos.updater.UpdateCommand.Type.ROLLBACK_TASK;\n import static com.twitter.mesos.updater.UpdateCommand.Type.UPDATE_TASK;\n-import static com.twitter.mesos.updater.UpdateLogic.State.*;\n+import static com.twitter.mesos.updater.UpdateLogic.State.CANARY;\n+import static com.twitter.mesos.updater.UpdateLogic.State.COMPLETE_FAILED;\n+import static com.twitter.mesos.updater.UpdateLogic.State.COMPLETE_SUCCESS;\n+import static com.twitter.mesos.updater.UpdateLogic.State.INIT;\n+import static com.twitter.mesos.updater.UpdateLogic.State.PREPARE_ROLLBACK;\n+import static com.twitter.mesos.updater.UpdateLogic.State.ROLLBACK_BATCH;\n+import static com.twitter.mesos.updater.UpdateLogic.State.UPDATE_BATCH;\n \n /**\n  * Abstract logic for the mesos updater.\n@@ -75,9 +82,38 @@ public boolean run() throws InterruptedException {\n     return stateMachine.getState() == COMPLETE_SUCCESS;\n   }\n \n+\n+  private static class ConsumableSortedIds {\n+    private final Collection<Integer> sortedIds;\n+    private final Iterable<Integer> consumingIds;\n+\n+    private ConsumableSortedIds(final Set<Integer> ids) {\n+      sortedIds = new PriorityQueue<Integer>(ids);\n+      consumingIds = Iterables.consumingIterable(sortedIds);\n+    }\n+\n+    /**\n+     * Returns an iterable over sorted ids that will consume ids as they are iterated over.  When\n+     * all ids have been iterated over once, {@link #isEmpty()} will return {@code true}.\n+     *\n+     * @return an consuming {@code Iterable} over the sorted shard ids\n+     */\n+    public Iterable<Integer> get() {\n+      return consumingIds;\n+    }\n+\n+    /**\n+     * @return {@code true} iff the Iterable returned by {@link #get()} has been fully iterated.\n+     */\n+    public boolean isEmpty() {\n+      return sortedIds.isEmpty();\n+    }\n+  }\n+\n+\n   // An iterable that will consume from a queue of shards being operated on in the current stage.\n   // Be careful when reading from this, since the objects are removed.\n-  Iterable<Integer> consumingIds;\n+  private ConsumableSortedIds consumingIds;\n \n   int totalFailures = 0;\n \n@@ -86,7 +122,7 @@ private void step(StateMachine<State> stateMachine) throws InterruptedException\n       switch (stateMachine.getState()) {\n         case INIT:\n           LOG.info(\"Initiating update.\");\n-          consumingIds = Iterables.consumingIterable(new PriorityQueue<Integer>(newShards));\n+          consumingIds = new ConsumableSortedIds(newShards);\n           stateMachine.transition(CANARY);\n           break;\n \n@@ -102,7 +138,7 @@ private void step(StateMachine<State> stateMachine) throws InterruptedException\n           break;\n \n         case UPDATE_BATCH:\n-          if (Iterables.isEmpty(consumingIds)) {\n+          if (consumingIds.isEmpty()) {\n             stateMachine.transition(COMPLETE_SUCCESS);\n           } else {\n             restartShards(UPDATE_TASK, config.getUpdateBatchSize(),\n@@ -116,13 +152,13 @@ private void step(StateMachine<State> stateMachine) throws InterruptedException\n \n         case PREPARE_ROLLBACK:\n           LOG.info(\"Preparing for rollback.\");\n-          consumingIds = Iterables.consumingIterable(new PriorityQueue<Integer>(\n-              Sets.difference(oldShards, ImmutableSet.copyOf(consumingIds))));\n+          consumingIds = new ConsumableSortedIds(Sets.difference(oldShards,\n+              ImmutableSet.copyOf(consumingIds.get())));\n           stateMachine.transition(ROLLBACK_BATCH);\n           break;\n \n         case ROLLBACK_BATCH:\n-          if (Iterables.isEmpty(consumingIds)) {\n+          if (consumingIds.isEmpty()) {\n             stateMachine.transition(COMPLETE_FAILED);\n           } else {\n             // TODO(wfarner): Can/should we do anything if this fails?\n@@ -154,7 +190,7 @@ private int restartShards(UpdateCommand.Type type, int numShards, int toleratedF\n       int updateWatchDurationSecs) throws UpdateException {\n     Preconditions.checkArgument(numShards > 0, \"Restart of zero shards does not make sense.\");\n \n-    Set<Integer> ids = ImmutableSet.copyOf(Iterables.limit(consumingIds, numShards));\n+    Set<Integer> ids = ImmutableSet.copyOf(Iterables.limit(consumingIds.get(), numShards));\n     LOG.info(String.format(\"Issuing %s on shards %s\", type, ids));\n \n     int newFailures = commandRunner.apply(new UpdateCommand(type, ids,",
                "raw_url": "https://github.com/apache/aurora/raw/3665b4a7ddcdcf7845d4cc2f652fa9f6febda9fc/src/java/com/twitter/mesos/updater/UpdateLogic.java",
                "sha": "1437cc40a6209bb4fc9b48cb2259a46c0814fcd3",
                "status": "modified"
            }
        ],
        "message": "Upgrade to guava_r08\n+ fix UpdateLogic/UpdateLogicTest - can no longer get away with Iterables.isEmpty(consumingIterable)\n+ fix NameClassifier -> NPE in NameClassifierTest",
        "parent": "https://github.com/apache/aurora/commit/850d28673b70d8266a5aa6bd3c9d4c0ba5ed91ec",
        "patched_files": [
            "UpdateLogic.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "UpdateLogicTest.java"
        ]
    },
    "aurora_86675fc": {
        "bug_id": "aurora_86675fc",
        "commit": "https://github.com/apache/aurora/commit/86675fc48d63f04c8ed4e658b2980fe675cec923",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/aurora/blob/86675fc48d63f04c8ed4e658b2980fe675cec923/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java?ref=86675fc48d63f04c8ed4e658b2980fe675cec923",
                "deletions": 1,
                "filename": "src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "patch": "@@ -207,7 +207,12 @@ private void killAndMaybeReserve(\n         IJobUpdateInstructions instructions) throws UpdateStateException {\n \n       if (status == ROLLING_FORWARD) {\n-        return Optional.ofNullable(instructions.getDesiredState().getTask().getSlaPolicy());\n+        // It is possible that an update only removes instances. In this case, there is no desired\n+        // state. Otherwise, get the task associated (this should never be null) and return an\n+        // optional of the SlaPolicy of the task (or empty if null).\n+        return Optional\n+            .ofNullable(instructions.getDesiredState())\n+            .map(desiredState -> desiredState.getTask().getSlaPolicy());\n       } else if (status == ROLLING_BACK) {\n         return getConfig(instance.getInstanceId(), instructions.getInitialState())\n             .map(ITaskConfig::getSlaPolicy);",
                "raw_url": "https://github.com/apache/aurora/raw/86675fc48d63f04c8ed4e658b2980fe675cec923/src/main/java/org/apache/aurora/scheduler/updater/InstanceActionHandler.java",
                "sha": "97906b5a0306aeac0930276deb950d825e52d778",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/aurora/blob/86675fc48d63f04c8ed4e658b2980fe675cec923/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora?ref=86675fc48d63f04c8ed4e658b2980fe675cec923",
                "deletions": 1,
                "filename": "src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "patch": "@@ -18,6 +18,7 @@ class DefaultProfile(Struct):\n   role=Default(String, getpass.getuser())\n   cmd=Default(String, 'cp /vagrant/src/test/sh/org/apache/aurora/e2e/http_example.py .')\n   gpu=Default(Integer, 0)\n+  instances=Default(Integer, 1)\n \n \n ContainerProfile = DefaultProfile(\n@@ -115,7 +116,7 @@ shell_health_check_config = HealthCheckConfig(\n \n job = Service(\n   cluster = 'devcluster',\n-  instances = 1,\n+  instances = '{{profile.instances}}',\n   update_config = update_config,\n   health_check_config = health_check_config,\n   task = test_task,",
                "raw_url": "https://github.com/apache/aurora/raw/86675fc48d63f04c8ed4e658b2980fe675cec923/src/test/sh/org/apache/aurora/e2e/http/http_example.aurora",
                "sha": "bd4d4a17f2f60fbaa7736c1684f8e956a7e6984a",
                "status": "modified"
            },
            {
                "additions": 59,
                "blob_url": "https://github.com/apache/aurora/blob/86675fc48d63f04c8ed4e658b2980fe675cec923/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "changes": 76,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh?ref=86675fc48d63f04c8ed4e658b2980fe675cec923",
                "deletions": 17,
                "filename": "src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "patch": "@@ -213,7 +213,7 @@ test_restart() {\n   aurora job restart --batch-size=2 --watch-secs=10 $_jobkey\n }\n \n-assert_update_state() {\n+assert_active_update_state() {\n   local _jobkey=$1 _expected_state=$2\n \n   local _state=$(aurora update list $_jobkey --status active | tail -n +2 | awk '{print $3}')\n@@ -223,6 +223,17 @@ assert_update_state() {\n   fi\n }\n \n+assert_update_id_state() {\n+  # Assert that a given update ID is in an expected state\n+  local _jobkey=$1 _update_id=$2 _expected_state=$3\n+\n+  local _state=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n+  if [[ $_state != $_expected_state ]]; then\n+    echo \"Update should have completed in $_expected_state state, but found $_state\"\n+    exit 1\n+  fi\n+}\n+\n assert_task_status() {\n   local _jobkey=$1 _id=$2 _expected_state=$3\n \n@@ -294,30 +305,64 @@ wait_until_task_counts() {\n   fi\n }\n \n+test_update_add_only_kill_only() {\n+  # Tests update functionality where we only add or kill instances\n+  local _jobkey=$1 _config=$2 _cluster=$3\n+  shift 3\n+  local _extra_args=\"${@}\"\n+\n+  # Create the initial update with 3 instances\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=3\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_id_state $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 3 0\n+\n+  # Update and kill 2 instances only\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=1\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_id_state $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 1 0\n+\n+  # Update and add 2 instances only\n+  aurora update start $_jobkey $_config $_extra_args --bind profile.instances=3\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n+  local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n+      | tail -n +2 | awk '{print $2}')\n+  aurora update wait $_jobkey $_update_id\n+  assert_update_id_state $_jobkey $_update_id 'ROLLED_FORWARD'\n+  wait_until_task_counts $_jobkey 3 0\n+\n+  # Clean up\n+  aurora job killall $_jobkey\n+}\n+\n test_update() {\n+  # Tests generic update functionality like pausing and resuming\n   local _jobkey=$1 _config=$2 _cluster=$3\n   shift 3\n   local _extra_args=\"${@}\"\n \n   aurora update start $_jobkey $_config $_extra_args\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n       | tail -n +2 | awk '{print $2}')\n   aurora_admin scheduler_snapshot devcluster\n   sudo systemctl restart aurora-scheduler\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   aurora update pause $_jobkey --message='hello'\n-  assert_update_state $_jobkey 'ROLL_FORWARD_PAUSED'\n+  assert_active_update_state $_jobkey 'ROLL_FORWARD_PAUSED'\n   aurora update resume $_jobkey\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   aurora update wait $_jobkey $_update_id\n \n   # Check that the update ended in ROLLED_FORWARD state.  Assumes the status is the last column.\n-  local status=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n-  if [[ $status != \"ROLLED_FORWARD\" ]]; then\n-    echo \"Update should have completed in ROLLED_FORWARD state\"\n-    exit 1\n-  fi\n+  assert_update_id_state $_jobkey $_update_id 'ROLLED_FORWARD'\n }\n \n test_update_fail() {\n@@ -327,7 +372,7 @@ test_update_fail() {\n \n   # Make sure our updates works.\n   aurora update start $_jobkey $_config $_extra_args\n-  assert_update_state $_jobkey 'ROLLING_FORWARD'\n+  assert_active_update_state $_jobkey 'ROLLING_FORWARD'\n   local _update_id=$(aurora update list $_jobkey --status ROLLING_FORWARD \\\n       | tail -n +2 | awk '{print $2}')\n   # Need to wait until udpate finishes before we can start one that we want to fail.\n@@ -339,12 +384,8 @@ test_update_fail() {\n       | tail -n +2 | awk '{print $2}')\n   # || is so that we don't return an EXIT so that `trap collect_result` doesn't get triggered.\n   aurora update wait $_jobkey $_update_id || echo $?\n-  # Making sure we rolled back.\n-  local status=$(aurora update info $_jobkey $_update_id | grep 'Current status' | awk '{print $NF}')\n-  if [[ $status != \"ROLLED_BACK\" ]]; then\n-    echo \"Update should have completed in ROLLED_BACK state due to failed healthcheck.\"\n-    exit 1\n-  fi\n+  # Making sure we rolled back due to a failed health check\n+  assert_update_id_state $_jobkey $_update_id 'ROLLED_BACK'\n }\n \n test_partition_awareness() {\n@@ -665,6 +706,7 @@ test_http_example() {\n   test_thermos_profile $_jobkey\n   test_file_mount $_cluster $_role $_env $_job\n   test_restart $_jobkey\n+  test_update_add_only_kill_only $_jobkey $_base_config $_cluster $_bind_parameters\n   test_update $_jobkey $_updated_config $_cluster $_bind_parameters\n   test_update_fail $_jobkey $_base_config  $_cluster $_bad_healthcheck_config $_bind_parameters\n   # Running test_update second time to change state to success.",
                "raw_url": "https://github.com/apache/aurora/raw/86675fc48d63f04c8ed4e658b2980fe675cec923/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh",
                "sha": "89959ab5cf4aae9d56c94c7ab25bd0437b2c9a29",
                "status": "modified"
            }
        ],
        "message": "Fix possible NullPointerException in InstanceActionHandler, add e2e tests around feature",
        "parent": "https://github.com/apache/aurora/commit/d46a8d91aa69ab9cf1ebc2b13552f8093d366fe9",
        "patched_files": [
            "http_example.java",
            "InstanceActionHandler.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "test_end_to_end.java"
        ]
    },
    "aurora_91ddb07": {
        "bug_id": "aurora_91ddb07",
        "commit": "https://github.com/apache/aurora/commit/91ddb075cf37cc15cee9c2b15cff0f71a950d551",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/aurora/blob/91ddb075cf37cc15cee9c2b15cff0f71a950d551/src/main/java/org/apache/aurora/scheduler/cron/quartz/AuroraCronJob.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/main/java/org/apache/aurora/scheduler/cron/quartz/AuroraCronJob.java?ref=91ddb075cf37cc15cee9c2b15cff0f71a950d551",
                "deletions": 2,
                "filename": "src/main/java/org/apache/aurora/scheduler/cron/quartz/AuroraCronJob.java",
                "patch": "@@ -154,9 +154,9 @@ void doExecute(JobExecutionContext context) throws JobExecutionException {\n       if (killFollowups.contains(key)) {\n         context.getJobDetail().getJobDataMap().remove(path);\n         killFollowups.remove(key);\n-        LOG.info(\"Resetting job context for cron \" + path);\n+        LOG.info(\"Resetting job context for cron {}\", path);\n       } else {\n-        LOG.info(\"Ignoring trigger as another concurrent run is active for cron \" + path);\n+        LOG.info(\"Ignoring trigger as another concurrent run is active for cron {}\", path);\n         return;\n       }\n     }",
                "raw_url": "https://github.com/apache/aurora/raw/91ddb075cf37cc15cee9c2b15cff0f71a950d551/src/main/java/org/apache/aurora/scheduler/cron/quartz/AuroraCronJob.java",
                "sha": "5873983479c39a011eb363f7fd442867f0794b17",
                "status": "modified"
            }
        ],
        "message": "Fix invalid logging that was causing pmd to NPE.\n\nReviewed at https://reviews.apache.org/r/54428/",
        "parent": "https://github.com/apache/aurora/commit/4bc5246149f296b14dc520bedd71747fdb2578fb",
        "patched_files": [
            "AuroraCronJob.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "AuroraCronJobTest.java"
        ]
    },
    "aurora_cbe99f5": {
        "bug_id": "aurora_cbe99f5",
        "commit": "https://github.com/apache/aurora/commit/cbe99f547c562a56ae800991105fb2060387776e",
        "file": [
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/aurora/blob/cbe99f547c562a56ae800991105fb2060387776e/src/test/java/org/apache/aurora/scheduler/preemptor/PendingTaskProcessorTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/aurora/contents/src/test/java/org/apache/aurora/scheduler/preemptor/PendingTaskProcessorTest.java?ref=cbe99f547c562a56ae800991105fb2060387776e",
                "deletions": 2,
                "filename": "src/test/java/org/apache/aurora/scheduler/preemptor/PendingTaskProcessorTest.java",
                "patch": "@@ -224,8 +224,6 @@ public void testMultipleTaskGroups() throws Exception {\n     // evaluated first.\n     assertTrue(ImmutableSet.of(0L, 2L).contains(\n         statsProvider.getLongValue(slotSearchStatName(false, true))));\n-    assertTrue(ImmutableSet.of(0L, 2L).contains(\n-        statsProvider.getLongValue(slotSearchByJobStatName(false, JOB_A))));\n     assertEquals(1L, statsProvider.getLongValue(UNMATCHED_TASKS));\n     assertEquals(2L, statsProvider.getLongValue(CACHE_SIZE_STAT_NAME));\n   }",
                "raw_url": "https://github.com/apache/aurora/raw/cbe99f547c562a56ae800991105fb2060387776e/src/test/java/org/apache/aurora/scheduler/preemptor/PendingTaskProcessorTest.java",
                "sha": "82b7aee5d620edcfb844254edf3b1660f7571bdc",
                "status": "modified"
            }
        ],
        "message": "Remove flaky test/assertion in PendingTaskProcessorTest\n\nI realized I added a flaky assertion in `PendingTaskProcessorTest` in\nhttps://reviews.apache.org/r/66536/\n\nI got extremely unlucky and every time I ran the tests it passed until after\nI merged :( The stat `preemptor_slot_search_[success|failed]_for_[name]` will\nnot appear unless the job slot search actually succeeds or fails (i.e. it\ncannot be 0 since it is dynamically generated). We were getting lucky where the\ntest would search for JOB_A slots first and create the stat. However, when\nJOB_B gets searched first, the JOB_A stat is never created because there are no\nslaves to search through anymore.\n\nI removed the assertion because there is a sufficient assertion directly above,\nand the stat is tested in multiple other tests.\n\nThe assertion would result in a `NullPointerException`.\n\nReviewed at https://reviews.apache.org/r/66570/",
        "parent": "https://github.com/apache/aurora/commit/c05632b219346abd483937933c04a2ad92bca3d2",
        "patched_files": [
            "PendingTaskProcessor.java"
        ],
        "repo": "aurora",
        "unit_tests": [
            "PendingTaskProcessorTest.java"
        ]
    }
}