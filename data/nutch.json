{
    "nutch_04df178": {
        "bug_id": "nutch_04df178",
        "commit": "https://github.com/apache/nutch/commit/04df178b376eaae7bf5a7fbcf044a13369a17b82",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/nutch/blob/04df178b376eaae7bf5a7fbcf044a13369a17b82/src/plugin/lib-http/src/java/org/apache/nutch/protocol/http/api/RobotRulesParser.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/lib-http/src/java/org/apache/nutch/protocol/http/api/RobotRulesParser.java?ref=04df178b376eaae7bf5a7fbcf044a13369a17b82",
                "deletions": 2,
                "filename": "src/plugin/lib-http/src/java/org/apache/nutch/protocol/http/api/RobotRulesParser.java",
                "patch": "@@ -70,8 +70,8 @@\n    * file, and can test paths against those rules.\n    */\n   public static class RobotRuleSet {\n-    ArrayList tmpEntries;\n-    RobotsEntry[] entries;\n+    ArrayList tmpEntries = new ArrayList();\n+    RobotsEntry[] entries = null;\n     long expireTime;\n \n     /**",
                "raw_url": "https://github.com/apache/nutch/raw/04df178b376eaae7bf5a7fbcf044a13369a17b82/src/plugin/lib-http/src/java/org/apache/nutch/protocol/http/api/RobotRulesParser.java",
                "sha": "a8f9072dd29edde1eaca4cf2062fd4c5c816eefc",
                "status": "modified"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/nutch/blob/04df178b376eaae7bf5a7fbcf044a13369a17b82/src/plugin/lib-http/src/test/org/apache/nutch/protocol/http/api/TestRobotRulesParser.java",
                "changes": 47,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/lib-http/src/test/org/apache/nutch/protocol/http/api/TestRobotRulesParser.java?ref=04df178b376eaae7bf5a7fbcf044a13369a17b82",
                "deletions": 3,
                "filename": "src/plugin/lib-http/src/test/org/apache/nutch/protocol/http/api/TestRobotRulesParser.java",
                "patch": "@@ -25,7 +25,29 @@\n   private static final String CR= \"\\r\";\n   private static final String CRLF= \"\\r\\n\";\n   \n-\n+  private static final boolean[] ACCEPT_ALL = {\n+    true,   // \"/a\",\t      \n+    true,   // \"/a/\",\t      \n+    true,   // \"/a/bloh/foo.html\"\n+    true,   // \"/b\",\t      \n+    true,   // \"/b/a\",\t      \n+    true,   // \"/b/a/index.html\",\n+    true,   // \"/b/b/foo.html\",  \n+    true,   // \"/c\",\t      \n+    true,   // \"/c/a\",\t      \n+    true,   // \"/c/a/index.html\",\n+    true,   // \"/c/b/foo.html\",  \n+    true,   // \"/d\",\t      \n+    true,   // \"/d/a\",\t      \n+    true,   // \"/e/a/index.html\",\n+    true,   // \"/e/d\",\t      \n+    true,   // \"/e/d/foo.html\",  \n+    true,   // \"/e/doh.html\",    \n+    true,   // \"/f/index.html\",  \n+    true,   // \"/foo/bar.html\",  \n+    true,   // \"/f/\",\n+  };\n+  \n   private static final String[] ROBOTS_STRINGS= new String[] {\n     \"User-Agent: Agent1 #foo\" + CR \n     + \"Disallow: /a\" + CR \n@@ -40,6 +62,7 @@\n     + \"\" + CR \n     + \"User-Agent: *\" + CR \n     + \"Disallow: /foo/bar/\" + CR,\n+    null  // Used to test EMPTY_RULES\n   };\n \n   private static final String[] AGENT_STRINGS= new String[] {\n@@ -57,7 +80,14 @@\n       false,\n       false,\n       true,\n-    }\n+    },\n+    { \n+      false, \n+      false,\n+      false,\n+      false,\n+      true,\n+    }    \n   };\n \n   private static final String[] TEST_PATHS= new String[] {\n@@ -195,6 +225,13 @@\n \tfalse,  // \"/foo/bar.html\",  \n \ttrue,   // \"/f/\",  \n       }\n+    },\n+    { // ROBOTS_STRINGS[1]\n+      ACCEPT_ALL, // Agent 1\n+      ACCEPT_ALL, // Agent 2\n+      ACCEPT_ALL, // Agent 3\n+      ACCEPT_ALL, // Agent 4\n+      ACCEPT_ALL, // Agent 5\n     }\n   };\n  \n@@ -233,7 +270,9 @@ public void testRobots(int robotsString, String[] agents, String[] paths,\n     for (int i= 1; i < agents.length; i++)\n       agentsString= agentsString + \",\" + agents[i];\n     RobotRulesParser p= new RobotRulesParser(agents);\n-    RobotRuleSet rules= p.parseRules(ROBOTS_STRINGS[robotsString].getBytes());\n+    RobotRuleSet rules= p.parseRules(ROBOTS_STRINGS[robotsString] != null\n+                                     ? ROBOTS_STRINGS[robotsString].getBytes()\n+                                     : null);\n     for (int i= 0; i < paths.length; i++) {\n       assertTrue(\"testing robots file \"+robotsString+\", on agents (\"\n \t\t + agentsString + \"), and path \" + TEST_PATHS[i] + \"; got \" \n@@ -243,4 +282,6 @@ public void testRobots(int robotsString, String[] agents, String[] paths,\n     }\n   }\n \n+\n+  \n }",
                "raw_url": "https://github.com/apache/nutch/raw/04df178b376eaae7bf5a7fbcf044a13369a17b82/src/plugin/lib-http/src/test/org/apache/nutch/protocol/http/api/TestRobotRulesParser.java",
                "sha": "4040a45a455254184346b78b6f7b6b58a74349da",
                "status": "modified"
            }
        ],
        "message": "NUTCH-298 : No more NPE if a 404 for a robots.txt + some unit tests\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@411926 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/7b6abacf81e063ddbe0b4cffce176c158137ed8b",
        "repo": "nutch",
        "unit_tests": [
            "TestRobotRulesParser.java"
        ]
    },
    "nutch_138bc89": {
        "bug_id": "nutch_138bc89",
        "commit": "https://github.com/apache/nutch/commit/138bc89f01bfada8d800a41670d36a863c83ef21",
        "file": [
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/nutch/blob/138bc89f01bfada8d800a41670d36a863c83ef21/src/java/org/apache/nutch/crawl/Injector.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/crawl/Injector.java?ref=138bc89f01bfada8d800a41670d36a863c83ef21",
                "deletions": 3,
                "filename": "src/java/org/apache/nutch/crawl/Injector.java",
                "patch": "@@ -18,6 +18,7 @@\n package org.apache.nutch.crawl;\n \n import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.io.FloatWritable;\n@@ -41,6 +42,7 @@\n import org.apache.nutch.scoring.ScoringFilterException;\n import org.apache.nutch.scoring.ScoringFilters;\n import org.apache.nutch.service.NutchServer;\n+import org.apache.nutch.util.LockUtil;\n import org.apache.nutch.util.NutchConfiguration;\n import org.apache.nutch.util.NutchJob;\n import org.apache.nutch.util.NutchTool;\n@@ -409,7 +411,24 @@ public void inject(Path crawlDb, Path urlDir, boolean overwrite,\n \n     // set input and output paths of the job\n     MultipleInputs.addInputPath(job, current, SequenceFileInputFormat.class);\n-    MultipleInputs.addInputPath(job, urlDir, KeyValueTextInputFormat.class);\n+    FileStatus[] seedFiles = urlDir.getFileSystem(getConf()).listStatus(urlDir);\n+    int numSeedFiles = 0;\n+    for (FileStatus seedFile : seedFiles) {\n+      if (seedFile.isFile()) {\n+        MultipleInputs.addInputPath(job, seedFile.getPath(),\n+            KeyValueTextInputFormat.class);\n+        numSeedFiles++;\n+        LOG.info(\"Injecting seed URL file {}\", seedFile.getPath());\n+      } else {\n+        LOG.warn(\"Skipped non-file input in {}: {}\", urlDir,\n+            seedFile.getPath());\n+      }\n+    }\n+    if (numSeedFiles == 0) {\n+      LOG.error(\"No seed files to inject found in {}\", urlDir);\n+      LockUtil.removeLockFile(fs, lock);\n+      return;\n+    }\n     FileOutputFormat.setOutputPath(job, tempCrawlDb);\n \n     try {\n@@ -461,8 +480,8 @@ public void inject(Path crawlDb, Path urlDir, boolean overwrite,\n         LOG.info(\"Injector: finished at \" + sdf.format(end) + \", elapsed: \"\n             + TimingUtil.elapsedTime(start, end));\n       }\n-    } catch (IOException | InterruptedException | ClassNotFoundException e) {\n-      LOG.error(\"Injector job failed\", e);\n+    } catch (IOException | InterruptedException | ClassNotFoundException | NullPointerException e) {\n+      LOG.error(\"Injector job failed: {}\", e.getMessage());\n       NutchJob.cleanupAfterFailure(tempCrawlDb, lock, fs);\n       throw e;\n     }",
                "raw_url": "https://github.com/apache/nutch/raw/138bc89f01bfada8d800a41670d36a863c83ef21/src/java/org/apache/nutch/crawl/Injector.java",
                "sha": "1f30989052d57db6ed8e57abcc7719698a33e536",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #313 from sebastian-nagel/NUTCH-2533-npe-inject-urldir-with-non-files\n\nNUTCH-2533 Injector: NullPointerException if seed URL dir contains non-file entries",
        "parent": "https://github.com/apache/nutch/commit/929fc9c89afb9267e3116cdca874dbcf9e511430",
        "repo": "nutch",
        "unit_tests": [
            "TestInjector.java"
        ]
    },
    "nutch_1a718e0": {
        "bug_id": "nutch_1a718e0",
        "commit": "https://github.com/apache/nutch/commit/1a718e0cc9a0c3811111e40f4bf8351e26f73522",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/nutch/blob/1a718e0cc9a0c3811111e40f4bf8351e26f73522/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java?ref=1a718e0cc9a0c3811111e40f4bf8351e26f73522",
                "deletions": 1,
                "filename": "src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "patch": "@@ -111,7 +111,7 @@ public String normalize(String urlString, String scope)\n     if (\"http\".equals(protocol) || \"https\".equals(protocol)\n         || \"ftp\".equals(protocol)) {\n \n-      if (host != null) {\n+      if (host != null && url.getAuthority() != null) {\n         String newHost = host.toLowerCase(Locale.ROOT); // lowercase host\n         if (!host.equals(newHost)) {\n           host = newHost;\n@@ -121,6 +121,9 @@ public String normalize(String urlString, String scope)\n           // etc.) which will likely cause a change if left away\n           changed = true;\n         }\n+      } else {\n+        // no host or authority: recompose the URL from components\n+        changed = true;\n       }\n \n       if (port == url.getDefaultPort()) { // uses default port",
                "raw_url": "https://github.com/apache/nutch/raw/1a718e0cc9a0c3811111e40f4bf8351e26f73522/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "sha": "5c056364b5cfa9d9834dad7375a647edd953b2e6",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/nutch/blob/1a718e0cc9a0c3811111e40f4bf8351e26f73522/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java?ref=1a718e0cc9a0c3811111e40f4bf8351e26f73522",
                "deletions": 0,
                "filename": "src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "patch": "@@ -164,6 +164,12 @@ public void testNormalizer() throws Exception {\n         \"http://foo.com/aa/bb/foo.html\");\n     normalizeTest(\"http://foo.com/aa?referer=http://bar.com\",\n         \"http://foo.com/aa?referer=http://bar.com\");\n+    // check for NPEs when normalizing URLs without host (authority)\n+    normalizeTest(\"file:///foo/bar.txt\", \"file:///foo/bar.txt\");\n+    normalizeTest(\"ftp:/\", \"ftp:/\");\n+    normalizeTest(\"http:\", \"http:/\");\n+    normalizeTest(\"http:////\", \"http:/\");\n+    normalizeTest(\"http:///////\", \"http:/\");\n   }\n \n   private void normalizeTest(String weird, String normal) throws Exception {",
                "raw_url": "https://github.com/apache/nutch/raw/1a718e0cc9a0c3811111e40f4bf8351e26f73522/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "sha": "2625ea3e4a3e895c7f55c42c92bb7ea7e084565e",
                "status": "modified"
            }
        ],
        "message": "NUTCH-2349 urlnormalizer-basic: NPE for URLs without authority\n- check whether URL.getAuthority() returns null\n- recompose URLs without authority with empty authority/host",
        "parent": "https://github.com/apache/nutch/commit/f351790d7f496561aeae5e214d1b33975ca34cf2",
        "repo": "nutch",
        "unit_tests": [
            "TestBasicURLNormalizer.java"
        ]
    },
    "nutch_58d355c": {
        "bug_id": "nutch_58d355c",
        "commit": "https://github.com/apache/nutch/commit/58d355cfa035ae850682efe9019d070d1dae827d",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/nutch/blob/58d355cfa035ae850682efe9019d070d1dae827d/src/plugin/parse-html/src/java/org/apache/nutch/parse/html/HtmlParser.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/parse-html/src/java/org/apache/nutch/parse/html/HtmlParser.java?ref=58d355cfa035ae850682efe9019d070d1dae827d",
                "deletions": 3,
                "filename": "src/plugin/parse-html/src/java/org/apache/nutch/parse/html/HtmlParser.java",
                "patch": "@@ -269,9 +269,11 @@ public static void main(String[] args) throws Exception {\n     byte[] bytes = new byte[(int)file.length()];\n     DataInputStream in = new DataInputStream(new FileInputStream(file));\n     in.readFully(bytes);\n-    Parse parse = new HtmlParser().getParse(\n-            new Content(url, url, bytes, \"text/html\", new Metadata(),\n-                        NutchConfiguration.create()));\n+    Configuration conf = NutchConfiguration.create();\n+    HtmlParser parser = new HtmlParser();\n+    parser.setConf(conf);\n+    Parse parse = parser.getParse(\n+            new Content(url, url, bytes, \"text/html\", new Metadata(), conf));\n     System.out.println(\"data: \"+parse.getData());\n \n     System.out.println(\"text: \"+parse.getText());",
                "raw_url": "https://github.com/apache/nutch/raw/58d355cfa035ae850682efe9019d070d1dae827d/src/plugin/parse-html/src/java/org/apache/nutch/parse/html/HtmlParser.java",
                "sha": "502d37fbcca6bc04c2457ec6bb8350ccbf334b89",
                "status": "modified"
            }
        ],
        "message": "Set the configuration of the parser used in the main method to fix NPEs\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@388293 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/37c5ffe04361630c20e287b93f741a0af22e0cb5",
        "repo": "nutch",
        "unit_tests": [
            "TestHtmlParser.java"
        ]
    },
    "nutch_615b20e": {
        "bug_id": "nutch_615b20e",
        "commit": "https://github.com/apache/nutch/commit/615b20eafe947bf75abee836ddd3a9b67706c49f",
        "file": [
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/nutch/blob/615b20eafe947bf75abee836ddd3a9b67706c49f/src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/util/PrefixStringMatcher.java?ref=615b20eafe947bf75abee836ddd3a9b67706c49f",
                "deletions": 2,
                "filename": "src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "patch": "@@ -16,8 +16,11 @@\n  */\n package org.apache.nutch.util;\n \n+import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.Iterator;\n+import java.util.List;\n \n /**\n  * A class for efficiently matching <code>String</code>s against a set of\n@@ -102,8 +105,9 @@ public String longestMatch(String input) {\n   }\n \n   public static final void main(String[] argv) {\n-    PrefixStringMatcher matcher = new PrefixStringMatcher(new String[] {\n-        \"abcd\", \"abc\", \"aac\", \"baz\", \"foo\", \"foobar\" });\n+    String[] prefixes = new String[] { \"abcd\", \"abc\", \"aac\", \"baz\", \"foo\",\n+        \"foobar\" };\n+    PrefixStringMatcher matcher = new PrefixStringMatcher(prefixes);\n \n     String[] tests = { \"a\", \"ab\", \"abc\", \"abcdefg\", \"apple\", \"aa\", \"aac\",\n         \"aaccca\", \"abaz\", \"baz\", \"bazooka\", \"fo\", \"foobar\", \"kite\", };\n@@ -114,5 +118,23 @@ public static final void main(String[] argv) {\n       System.out.println(\"  shortest: \" + matcher.shortestMatch(tests[i]));\n       System.out.println(\"   longest: \" + matcher.longestMatch(tests[i]));\n     }\n+\n+    int iterations = 1000;\n+    System.out.println(\"Testing thread-safety (NUTCH-2585) with \" + iterations\n+        + \" iterations:\");\n+    List<String> testsList = Arrays.asList(tests);\n+    for (int i = 0; i < iterations; i++) {\n+      matcher = new PrefixStringMatcher(prefixes);\n+      Collections.shuffle(testsList);\n+      try {\n+        long count = testsList.parallelStream().filter(matcher::matches).count();\n+        System.out.print(String.format(\"Cycle %4d : %d matches\\r\", i, count));\n+      } catch (Exception e) {\n+        // flush output\n+        System.out.println(\"\");\n+        throw e;\n+      }\n+    }\n+    System.out.println(\"\");\n   }\n }",
                "raw_url": "https://github.com/apache/nutch/raw/615b20eafe947bf75abee836ddd3a9b67706c49f/src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "sha": "3be0fd71a0f3d1a30851c60967f2aab4d6e403cb",
                "status": "modified"
            }
        ],
        "message": "NUTCH-2585 NPE in TrieStringMatcher\n- add test for thread-safety to main() method of PrefixStringMatcher\n  using parallel streams calling the match method",
        "parent": "https://github.com/apache/nutch/commit/7765bb3afdc6f43e8bac0a4a4f4de248657e3a76",
        "repo": "nutch",
        "unit_tests": [
            "TestPrefixStringMatcher.java"
        ]
    },
    "nutch_63037c7": {
        "bug_id": "nutch_63037c7",
        "commit": "https://github.com/apache/nutch/commit/63037c71370cad1eba4152668f33b184c686d092",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/java/org/apache/nutch/crawl/URLPartitioner.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/crawl/URLPartitioner.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 5,
                "filename": "src/java/org/apache/nutch/crawl/URLPartitioner.java",
                "patch": "@@ -63,23 +63,27 @@ public void configure(JobConf job) {\n   public void close() {\n   }\n \n-  /** Hash by domain name. */\n+  /** Hash by host or domain name or IP address. */\n   public int getPartition(Text key, Writable value, int numReduceTasks) {\n     String urlString = key.toString();\n     URL url = null;\n-    int hashCode = urlString.hashCode();\n+    int hashCode;\n     try {\n       urlString = normalizers.normalize(urlString,\n           URLNormalizers.SCOPE_PARTITION);\n       url = new URL(urlString);\n-      hashCode = url.getHost().hashCode();\n     } catch (MalformedURLException e) {\n       LOG.warn(\"Malformed URL: '\" + urlString + \"'\");\n     }\n \n-    if (mode.equals(PARTITION_MODE_DOMAIN) && url != null)\n+    if (url == null) {\n+      // failed to parse URL, must take URL string as fall-back\n+      hashCode = urlString.hashCode();\n+    } else if (mode.equals(PARTITION_MODE_HOST)) {\n+      hashCode = url.getHost().hashCode();\n+    } else if (mode.equals(PARTITION_MODE_DOMAIN)) {\n       hashCode = URLUtil.getDomainName(url).hashCode();\n-    else if (mode.equals(PARTITION_MODE_IP)) {\n+    } else if (mode.equals(PARTITION_MODE_IP)) {\n       try {\n         InetAddress address = InetAddress.getByName(url.getHost());\n         hashCode = address.getHostAddress().hashCode();",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/java/org/apache/nutch/crawl/URLPartitioner.java",
                "sha": "23a3eb08030a77548ba7b257a469cacfc9248fa9",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/java/org/apache/nutch/tools/CommonCrawlDataDumper.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/tools/CommonCrawlDataDumper.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/java/org/apache/nutch/tools/CommonCrawlDataDumper.java",
                "patch": "@@ -38,6 +38,7 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.regex.Pattern;\n \n import org.apache.commons.cli.CommandLine;\n import org.apache.commons.cli.CommandLineParser;\n@@ -342,7 +343,8 @@ public void dump(File outputDir, File segmentRootDir, File linkdb, boolean gzip,\n                   .createFileName(md5Ofurl, baseName, extensionName);\n               outputFullPath = String.format(\"%s/%s\", fullDir, filename);\n \n-              String[] fullPathLevels = fullDir.split(File.separator);\n+              String[] fullPathLevels = fullDir\n+                  .split(Pattern.quote(File.separator));\n               String firstLevelDirName = fullPathLevels[fullPathLevels.length\n                   - 2];\n               String secondLevelDirName = fullPathLevels[fullPathLevels.length",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/java/org/apache/nutch/tools/CommonCrawlDataDumper.java",
                "sha": "107ec1c5250be5d7f1c98efa93edd4dadc5d16e5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/plugin/index-more/src/java/org/apache/nutch/indexer/more/MoreIndexingFilter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/index-more/src/java/org/apache/nutch/indexer/more/MoreIndexingFilter.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/plugin/index-more/src/java/org/apache/nutch/indexer/more/MoreIndexingFilter.java",
                "patch": "@@ -324,7 +324,7 @@ private void readConfiguration() throws IOException {\n \n     while ((line = reader.readLine()) != null) {\n       if (StringUtils.isNotBlank(line) && !line.startsWith(\"#\")) {\n-        line.trim();\n+        line = line.trim();\n         parts = line.split(\"\\t\");\n \n         // Must be at least two parts",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/plugin/index-more/src/java/org/apache/nutch/indexer/more/MoreIndexingFilter.java",
                "sha": "26a7df2c65c93cad9e128e013853ac75c7dbeebb",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/plugin/indexer-elastic/src/java/org/apache/nutch/indexwriter/elastic/ElasticIndexWriter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/indexer-elastic/src/java/org/apache/nutch/indexwriter/elastic/ElasticIndexWriter.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/plugin/indexer-elastic/src/java/org/apache/nutch/indexwriter/elastic/ElasticIndexWriter.java",
                "patch": "@@ -114,7 +114,7 @@ protected Client makeClient(Configuration conf) throws IOException {\n     String parts[];\n     while ((line = reader.readLine()) != null) {\n       if (StringUtils.isNotBlank(line) && !line.startsWith(\"#\")) {\n-        line.trim();\n+        line = line.trim();\n         parts = line.split(\"=\");\n \n         if (parts.length == 2) {",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/plugin/indexer-elastic/src/java/org/apache/nutch/indexwriter/elastic/ElasticIndexWriter.java",
                "sha": "6cb9cf8d1f6e296f8cf766b65bf57fbe32282065",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-host/src/java/org/apache/nutch/net/urlnormalizer/host/HostURLNormalizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-host/src/java/org/apache/nutch/net/urlnormalizer/host/HostURLNormalizer.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/plugin/urlnormalizer-host/src/java/org/apache/nutch/net/urlnormalizer/host/HostURLNormalizer.java",
                "patch": "@@ -76,7 +76,7 @@ private synchronized void readConfiguration(Reader configReader)\n \n     while ((line = reader.readLine()) != null) {\n       if (StringUtils.isNotBlank(line) && !line.startsWith(\"#\")) {\n-        line.trim();\n+        line = line.trim();\n         delimiterIndex = line.indexOf(\" \");\n \n         host = line.substring(0, delimiterIndex);",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-host/src/java/org/apache/nutch/net/urlnormalizer/host/HostURLNormalizer.java",
                "sha": "86f58e4ac86ef545ce2b42ace0418d11afb0b361",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-protocol/src/java/org/apache/nutch/net/urlnormalizer/protocol/ProtocolURLNormalizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-protocol/src/java/org/apache/nutch/net/urlnormalizer/protocol/ProtocolURLNormalizer.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/plugin/urlnormalizer-protocol/src/java/org/apache/nutch/net/urlnormalizer/protocol/ProtocolURLNormalizer.java",
                "patch": "@@ -75,7 +75,7 @@ private synchronized void readConfiguration(Reader configReader) throws IOExcept\n \n     while ((line = reader.readLine()) != null) {\n       if (StringUtils.isNotBlank(line) && !line.startsWith(\"#\")) {\n-        line.trim();\n+        line = line.trim();\n         delimiterIndex = line.indexOf(\" \");\n         // try tabulator\n         if (delimiterIndex == -1) {",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-protocol/src/java/org/apache/nutch/net/urlnormalizer/protocol/ProtocolURLNormalizer.java",
                "sha": "73067462d7bc96237bfb52f4d8d6812e6d252d5a",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-slash/src/java/org/apache/nutch/net/urlnormalizer/slash/SlashURLNormalizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-slash/src/java/org/apache/nutch/net/urlnormalizer/slash/SlashURLNormalizer.java?ref=63037c71370cad1eba4152668f33b184c686d092",
                "deletions": 1,
                "filename": "src/plugin/urlnormalizer-slash/src/java/org/apache/nutch/net/urlnormalizer/slash/SlashURLNormalizer.java",
                "patch": "@@ -77,7 +77,7 @@ private synchronized void readConfiguration(Reader configReader) throws IOExcept\n \n     while ((line = reader.readLine()) != null) {\n       if (StringUtils.isNotBlank(line) && !line.startsWith(\"#\")) {\n-        line.trim();\n+        line = line.trim();\n         delimiterIndex = line.indexOf(\" \");\n         // try tabulator\n         if (delimiterIndex == -1) {",
                "raw_url": "https://github.com/apache/nutch/raw/63037c71370cad1eba4152668f33b184c686d092/src/plugin/urlnormalizer-slash/src/java/org/apache/nutch/net/urlnormalizer/slash/SlashURLNormalizer.java",
                "sha": "c4f68ef20c337453f4ca92239310028a67e4769d",
                "status": "modified"
            }
        ],
        "message": "NUTCH-2394 Fix of bugs detected by static code analysis\n- String.trim() without assignment\n- avoid strings to fail as regex.Pattern\n- possible NPE in URLPartitioner: reworked code",
        "parent": "https://github.com/apache/nutch/commit/4cfec6e327702704527ef9162c9e4823041ee5d1",
        "repo": "nutch",
        "unit_tests": [
            "TestCommonCrawlDataDumper.java",
            "TestMoreIndexingFilter.java",
            "TestHostURLNormalizer.java",
            "TestProtocolURLNormalizer.java",
            "TestSlashURLNormalizer.java"
        ]
    },
    "nutch_76aedcb": {
        "bug_id": "nutch_76aedcb",
        "commit": "https://github.com/apache/nutch/commit/76aedcb780c88344966f47536274ecb001682291",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/nutch/blob/76aedcb780c88344966f47536274ecb001682291/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java?ref=76aedcb780c88344966f47536274ecb001682291",
                "deletions": 1,
                "filename": "src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "patch": "@@ -112,7 +112,7 @@ public String normalize(String urlString, String scope)\n     if (\"http\".equals(protocol) || \"https\".equals(protocol)\n         || \"ftp\".equals(protocol)) {\n \n-      if (host != null) {\n+      if (host != null && url.getAuthority() != null) {\n         String newHost = host.toLowerCase(Locale.ROOT); // lowercase host\n         if (!host.equals(newHost)) {\n           host = newHost;\n@@ -122,6 +122,9 @@ public String normalize(String urlString, String scope)\n           // etc.) which will likely cause a change if left away\n           changed = true;\n         }\n+      } else {\n+        // no host or authority: recompose the URL from components\n+        changed = true;\n       }\n \n       if (port == url.getDefaultPort()) { // uses default port",
                "raw_url": "https://github.com/apache/nutch/raw/76aedcb780c88344966f47536274ecb001682291/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java",
                "sha": "ffd22cee0eadd5f5d3fafb6148ba48b1f523f035",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/nutch/blob/76aedcb780c88344966f47536274ecb001682291/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java?ref=76aedcb780c88344966f47536274ecb001682291",
                "deletions": 0,
                "filename": "src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "patch": "@@ -164,6 +164,12 @@ public void testNormalizer() throws Exception {\n         \"http://foo.com/aa/bb/foo.html\");\n     normalizeTest(\"http://foo.com/aa?referer=http://bar.com\",\n         \"http://foo.com/aa?referer=http://bar.com\");\n+    // check for NPEs when normalizing URLs without host (authority)\n+    normalizeTest(\"file:///foo/bar.txt\", \"file:///foo/bar.txt\");\n+    normalizeTest(\"ftp:/\", \"ftp:/\");\n+    normalizeTest(\"http:\", \"http:/\");\n+    normalizeTest(\"http:////\", \"http:/\");\n+    normalizeTest(\"http:///////\", \"http:/\");\n   }\n \n   private void normalizeTest(String weird, String normal) throws Exception {",
                "raw_url": "https://github.com/apache/nutch/raw/76aedcb780c88344966f47536274ecb001682291/src/plugin/urlnormalizer-basic/src/test/org/apache/nutch/net/urlnormalizer/basic/TestBasicURLNormalizer.java",
                "sha": "2625ea3e4a3e895c7f55c42c92bb7ea7e084565e",
                "status": "modified"
            }
        ],
        "message": "NUTCH-2349 urlnormalizer-basic: NPE for URLs without authority\nMerge branch 'NUTCH-2349-basic-url-normalizer-npe' of https://github.com/sebastian-nagel/nutch, this closes #169",
        "parent": "https://github.com/apache/nutch/commit/2b93a66f0472e93223c69053d5482dcbef26de6d",
        "repo": "nutch",
        "unit_tests": [
            "TestBasicURLNormalizer.java"
        ]
    },
    "nutch_78106e3": {
        "bug_id": "nutch_78106e3",
        "commit": "https://github.com/apache/nutch/commit/78106e3663b696dc175ee0cece299b40ca1116de",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/nutch/blob/78106e3663b696dc175ee0cece299b40ca1116de/src/java/org/apache/nutch/crawl/Crawl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/crawl/Crawl.java?ref=78106e3663b696dc175ee0cece299b40ca1116de",
                "deletions": 0,
                "filename": "src/java/org/apache/nutch/crawl/Crawl.java",
                "patch": "@@ -117,6 +117,10 @@ public static void main(String args[]) throws Exception {\n     for (int i = 0; i < depth; i++) {             // generate new segment\n       Path segment = generator.generate(crawlDb, segments, -1, topN, System\n           .currentTimeMillis(), false, false);\n+      if (segment == null) {\n+        LOG.info(\"Stopping at depth=\" + i + \" - no more URLs to fetch.\");\n+        break;\n+      }\n       fetcher.fetch(segment, threads);  // fetch it\n       if (!Fetcher.isParsing(job)) {\n         parseSegment.parse(segment);    // parse it, if needed",
                "raw_url": "https://github.com/apache/nutch/raw/78106e3663b696dc175ee0cece299b40ca1116de/src/java/org/apache/nutch/crawl/Crawl.java",
                "sha": "9f4fc8ddc2a8efa09052ad75b09f68d405078da7",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/nutch/blob/78106e3663b696dc175ee0cece299b40ca1116de/src/java/org/apache/nutch/fetcher/Fetcher.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/fetcher/Fetcher.java?ref=78106e3663b696dc175ee0cece299b40ca1116de",
                "deletions": 2,
                "filename": "src/java/org/apache/nutch/fetcher/Fetcher.java",
                "patch": "@@ -157,6 +157,8 @@ public void run() {\n                   newUrl = normalizers.normalize(newUrl, URLNormalizers.SCOPE_FETCHER);\n                   newUrl = this.urlFilters.filter(newUrl);\n                   if (newUrl != null && !newUrl.equals(url.toString())) {\n+                    // record that we were redirected\n+                    output(url, datum, null, status, CrawlDatum.STATUS_FETCH_REDIR_PERM);\n                     url = new Text(newUrl);\n                     if (maxRedirect > 0) {\n                       redirecting = true;\n@@ -165,7 +167,7 @@ public void run() {\n                         LOG.debug(\" - content redirect to \" + url + \" (fetching now)\");\n                       }\n                     } else {\n-                      output(url, new CrawlDatum(), null, null, CrawlDatum.STATUS_FETCH_REDIR_TEMP);\n+                      output(url, new CrawlDatum(), null, null, CrawlDatum.STATUS_LINKED);\n                       if (LOG.isDebugEnabled()) {\n                         LOG.debug(\" - content redirect to \" + url + \" (fetching later)\");\n                       }\n@@ -198,7 +200,7 @@ public void run() {\n                       LOG.debug(\" - protocol redirect to \" + url + \" (fetching now)\");\n                     }\n                   } else {\n-                    output(url, new CrawlDatum(), null, null, code);\n+                    output(url, new CrawlDatum(), null, null, CrawlDatum.STATUS_LINKED);\n                     if (LOG.isDebugEnabled()) {\n                       LOG.debug(\" - protocol redirect to \" + url + \" (fetching later)\");\n                     }",
                "raw_url": "https://github.com/apache/nutch/raw/78106e3663b696dc175ee0cece299b40ca1116de/src/java/org/apache/nutch/fetcher/Fetcher.java",
                "sha": "9e681bf8b122f0d102b231f066b2243dd1a495d9",
                "status": "modified"
            }
        ],
        "message": "Use different status code when recording a redirected terget URL without\nfetching. Fix also an NPE in Crawl when Generator doesn't produce any\nnew segment. Reported by Meghna Kukreja.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@492525 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/93475d193a633589643c684359c99b3cbcf0e143",
        "repo": "nutch",
        "unit_tests": [
            "TestFetcher.java"
        ]
    },
    "nutch_8168861": {
        "bug_id": "nutch_8168861",
        "commit": "https://github.com/apache/nutch/commit/8168861dd1acd0d632050aad45d7dcf358d95e15",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/nutch/blob/8168861dd1acd0d632050aad45d7dcf358d95e15/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/CHANGES.txt?ref=8168861dd1acd0d632050aad45d7dcf358d95e15",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -2,6 +2,8 @@ Nutch Change Log\n \n Release 2.0 - Current Development\n \n+* NUTCH-950 DomainURLFilter throws NPE on bogus urls (Alexis Detreglode via jnioche)\n+\n * NUTCH-935 basicurlnormalizer removes unnecessary /./ in URLs\n \n * NUTCH-912 MoreIndexingFilter does not parse docx and xlsx date formats (Markus Jelsma, jnioche)",
                "raw_url": "https://github.com/apache/nutch/raw/8168861dd1acd0d632050aad45d7dcf358d95e15/CHANGES.txt",
                "sha": "008deed39d281fe0e18c4b0aa7e6230b8dd38e2e",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/nutch/blob/8168861dd1acd0d632050aad45d7dcf358d95e15/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java?ref=8168861dd1acd0d632050aad45d7dcf358d95e15",
                "deletions": 1,
                "filename": "src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "patch": "@@ -32,6 +32,7 @@\n import org.apache.nutch.plugin.Extension;\n import org.apache.nutch.plugin.PluginRepository;\n import org.apache.nutch.util.URLUtil;\n+import org.apache.nutch.util.domain.DomainSuffix;\n \n /**\n  * <p>Filters URLs based on a file containing domain suffixes, domain names, and\n@@ -174,9 +175,14 @@ public String filter(String url) {\n \n       // match for suffix, domain, and host in that order.  more general will\n       // override more specific\n-      String suffix = URLUtil.getDomainSuffix(url).getDomain();\n       String domain = URLUtil.getDomainName(url).toLowerCase().trim();\n       String host = URLUtil.getHost(url);\n+      String suffix = null;\n+      DomainSuffix domainSuffix = URLUtil.getDomainSuffix(url);\n+      if (domainSuffix != null) {\n+        suffix = domainSuffix.getDomain();\n+      }\n+      \n       if (domainSet.contains(suffix) || domainSet.contains(domain)\n         || domainSet.contains(host)) {\n         return url;",
                "raw_url": "https://github.com/apache/nutch/raw/8168861dd1acd0d632050aad45d7dcf358d95e15/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "sha": "f1f76a791281f033ae7ac9a42ad44526180fe181",
                "status": "modified"
            }
        ],
        "message": "NUTCH-950 DomainURLFilter throws NPE on bogus urls\n\ngit-svn-id: https://svn.apache.org/repos/asf/nutch/trunk@1055608 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/02e18a5f7e77d040ccb8cda3b2eef1739fef0024",
        "repo": "nutch",
        "unit_tests": [
            "TestDomainURLFilter.java"
        ]
    },
    "nutch_8b23273": {
        "bug_id": "nutch_8b23273",
        "commit": "https://github.com/apache/nutch/commit/8b232735884acedb3df5976a05d8b66c65430b16",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/nutch/blob/8b232735884acedb3df5976a05d8b66c65430b16/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/CHANGES.txt?ref=8b232735884acedb3df5976a05d8b66c65430b16",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -2,6 +2,8 @@ Nutch Change Log\n \n Release 1.3 - Current Development\n \n+* NUTCH-950 DomainURLFilter throws NPE on bogus urls (Alexis Detreglode via jnioche)\n+\n * NUTCH-935 basicurlnormalizer removes unnecessary /./ in URLs\n \n * NUTCH-912 MoreIndexingFilter does not parse docx and xlsx date formats (Markus Jelsma, jnioche)",
                "raw_url": "https://github.com/apache/nutch/raw/8b232735884acedb3df5976a05d8b66c65430b16/CHANGES.txt",
                "sha": "fdd47f7e236c656ab79f21a3fb5283d86e5fd1cf",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/nutch/blob/8b232735884acedb3df5976a05d8b66c65430b16/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java?ref=8b232735884acedb3df5976a05d8b66c65430b16",
                "deletions": 1,
                "filename": "src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "patch": "@@ -31,6 +31,7 @@\n import org.apache.nutch.plugin.Extension;\n import org.apache.nutch.plugin.PluginRepository;\n import org.apache.nutch.util.URLUtil;\n+import org.apache.nutch.util.domain.DomainSuffix;\n \n /**\n  * <p>Filters URLs based on a file containing domain suffixes, domain names, and\n@@ -170,9 +171,14 @@ public String filter(String url) {\n \n       // match for suffix, domain, and host in that order.  more general will\n       // override more specific\n-      String suffix = URLUtil.getDomainSuffix(url).getDomain();\n       String domain = URLUtil.getDomainName(url).toLowerCase().trim();\n       String host = URLUtil.getHost(url);\n+      String suffix = null;\n+      DomainSuffix domainSuffix = URLUtil.getDomainSuffix(url);\n+      if (domainSuffix != null) {\n+        suffix = domainSuffix.getDomain();\n+      }\n+      \n       if (domainSet.contains(suffix) || domainSet.contains(domain)\n         || domainSet.contains(host)) {\n         return url;",
                "raw_url": "https://github.com/apache/nutch/raw/8b232735884acedb3df5976a05d8b66c65430b16/src/plugin/urlfilter-domain/src/java/org/apache/nutch/urlfilter/domain/DomainURLFilter.java",
                "sha": "70e6dd5e945c060d12d527f56bf02317d53e6f80",
                "status": "modified"
            }
        ],
        "message": "NUTCH-950 DomainURLFilter throws NPE on bogus urls\n\ngit-svn-id: https://svn.apache.org/repos/asf/nutch/branches/branch-1.3@1055604 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/372dfb29da0b2c2d0ec54b71b1dfee191b8e62c7",
        "repo": "nutch",
        "unit_tests": [
            "TestDomainURLFilter.java"
        ]
    },
    "nutch_b92daca": {
        "bug_id": "nutch_b92daca",
        "commit": "https://github.com/apache/nutch/commit/b92dacafad2cb0e23fe2ecf3e592e8f136074cb7",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/b92dacafad2cb0e23fe2ecf3e592e8f136074cb7/src/java/org/apache/nutch/protocol/ProtocolFactory.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/protocol/ProtocolFactory.java?ref=b92dacafad2cb0e23fe2ecf3e592e8f136074cb7",
                "deletions": 1,
                "filename": "src/java/org/apache/nutch/protocol/ProtocolFactory.java",
                "patch": "@@ -75,7 +75,7 @@ private static Extension getExtension(String name)\n     \n     Extension extension = findExtension(name);\n     \n-    CACHE.put(name, extension);\n+    if (extension != null) CACHE.put(name, extension);\n     \n     return extension;\n   }",
                "raw_url": "https://github.com/apache/nutch/raw/b92dacafad2cb0e23fe2ecf3e592e8f136074cb7/src/java/org/apache/nutch/protocol/ProtocolFactory.java",
                "sha": "5ba3acaab4e5e388914bd0dd31639e07dfb0ef8e",
                "status": "modified"
            }
        ],
        "message": "Fix NPE when protocol not found. Reported by Dawid Weiss.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@232840 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/f2503012087b4b6d56707e902965f82c3ae5dae9",
        "repo": "nutch",
        "unit_tests": [
            "TestProtocolFactory.java"
        ]
    },
    "nutch_d124af4": {
        "bug_id": "nutch_d124af4",
        "commit": "https://github.com/apache/nutch/commit/d124af49f1574e14facf17cb85efadcd7b4121b6",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/nutch/blob/d124af49f1574e14facf17cb85efadcd7b4121b6/src/java/org/apache/nutch/fetcher/Fetcher.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/fetcher/Fetcher.java?ref=d124af49f1574e14facf17cb85efadcd7b4121b6",
                "deletions": 2,
                "filename": "src/java/org/apache/nutch/fetcher/Fetcher.java",
                "patch": "@@ -152,7 +152,7 @@ public void run() {\n                     LOG.fine(\" - content redirect to \" + url);\n                   } else {\n                     LOG.fine(\" - content redirect skipped: \" +\n-                             (url.equals(newUrl.toString()) ? \"to same url\" : \"filtered\"));\n+                             (newUrl != null ? \"to same url\" : \"filtered\"));\n                   }\n                 }\n                 break;\n@@ -169,7 +169,7 @@ public void run() {\n                   LOG.fine(\" - protocol redirect to \" + url);\n                 } else {\n                   LOG.fine(\" - protocol redirect skipped: \" +\n-                           (url.equals(newUrl.toString()) ? \"to same url\" : \"filtered\"));\n+                           (newUrl != null ? \"to same url\" : \"filtered\"));\n                 }\n                 break;\n ",
                "raw_url": "https://github.com/apache/nutch/raw/d124af49f1574e14facf17cb85efadcd7b4121b6/src/java/org/apache/nutch/fetcher/Fetcher.java",
                "sha": "32303149d9cf3b12d74bd4a248f11713234db9ba",
                "status": "modified"
            }
        ],
        "message": "Fix an NPE, and simplify the logic (NUTCH-254).\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@396708 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/40c0f4b44aa08f0f4db6e79cb4f0bace3a53caf1",
        "repo": "nutch",
        "unit_tests": [
            "TestFetcher.java"
        ]
    },
    "nutch_db27c64": {
        "bug_id": "nutch_db27c64",
        "commit": "https://github.com/apache/nutch/commit/db27c6473b8733b63ef025c221baccd3a7756417",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/nutch/blob/db27c6473b8733b63ef025c221baccd3a7756417/src/java/org/apache/nutch/crawl/Generator.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/crawl/Generator.java?ref=db27c6473b8733b63ef025c221baccd3a7756417",
                "deletions": 3,
                "filename": "src/java/org/apache/nutch/crawl/Generator.java",
                "patch": "@@ -243,7 +243,7 @@ public Path generate(Path dbDir, Path segments,\n                \"/generate-temp-\"+\n                Integer.toString(new Random().nextInt(Integer.MAX_VALUE)));\n \n-    Path segment = new Path(segments, getDate());\n+    Path segment = new Path(segments, generateSegmentName());\n     Path output = new Path(segment, CrawlDatum.GENERATE_DIR_NAME);\n \n     LOG.info(\"Generator: starting\");\n@@ -305,9 +305,14 @@ public Path generate(Path dbDir, Path segments,\n \n     return segment;\n   }\n+  \n+  private static SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMddHHmmss\");\n \n-  private static String getDate() {\n-    return new SimpleDateFormat(\"yyyyMMddHHmmss\").format\n+  public static synchronized String generateSegmentName() {\n+    try {\n+      Thread.sleep(1000);\n+    } catch (Throwable t) {};\n+    return sdf.format\n       (new Date(System.currentTimeMillis()));\n   }\n ",
                "raw_url": "https://github.com/apache/nutch/raw/db27c6473b8733b63ef025c221baccd3a7756417/src/java/org/apache/nutch/crawl/Generator.java",
                "sha": "11189fd1028a7a83c0e9545ff825849f35f278cc",
                "status": "modified"
            },
            {
                "additions": 55,
                "blob_url": "https://github.com/apache/nutch/blob/db27c6473b8733b63ef025c221baccd3a7756417/src/java/org/apache/nutch/segment/SegmentMerger.java",
                "changes": 93,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/segment/SegmentMerger.java?ref=db27c6473b8733b63ef025c221baccd3a7756417",
                "deletions": 38,
                "filename": "src/java/org/apache/nutch/segment/SegmentMerger.java",
                "patch": "@@ -16,17 +16,19 @@\n \n package org.apache.nutch.segment;\n \n-import java.io.File;\n-import java.io.FileFilter;\n import java.io.IOException;\n import java.util.*;\n import java.util.logging.Logger;\n \n import org.apache.hadoop.conf.*;\n import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n import org.apache.hadoop.io.*;\n import org.apache.hadoop.mapred.*;\n import org.apache.nutch.crawl.CrawlDatum;\n+import org.apache.nutch.crawl.Generator;\n+import org.apache.nutch.fetcher.Fetcher;\n import org.apache.nutch.metadata.Metadata;\n import org.apache.nutch.net.URLFilters;\n import org.apache.nutch.parse.ParseData;\n@@ -104,7 +106,7 @@ public RecordReader getRecordReader(FileSystem fs, FileSplit split, JobConf job,\n \n       reporter.setStatus(split.toString());\n       // find part name\n-      String dir = split.getFile().toString().replace('\\\\', '/');\n+      String dir = split.getPath().toString().replace('\\\\', '/');\n       int idx = dir.lastIndexOf(\"/part-\");\n       if (idx == -1) {\n         throw new IOException(\"Cannot determine segment part: \" + dir);\n@@ -173,6 +175,7 @@ public RecordWriter getRecordWriter(final FileSystem fs, final JobConf job, fina\n         SequenceFile.Writer g_out = null;\n         SequenceFile.Writer p_out = null;\n         HashMap sliceWriters = new HashMap();\n+        String segmentName = job.get(\"segment.merger.segmentName\");\n         \n         public void write(WritableComparable key, Writable value) throws IOException {\n           // unwrap\n@@ -205,12 +208,24 @@ public void write(WritableComparable key, Writable value) throws IOException {\n             slice = ((Content)o).getMetadata().get(sliceMarker);\n             ((Content)o).getMetadata().remove(sliceMarker);\n             ((Content)o).getMetadata().remove(nameMarker);\n+            // update the segment name inside metadata\n+            if (slice == null) {\n+              ((Content)o).getMetadata().set(Fetcher.SEGMENT_NAME_KEY, segmentName);\n+            } else {\n+              ((Content)o).getMetadata().set(Fetcher.SEGMENT_NAME_KEY, segmentName + \"-\" + slice);\n+            }\n             c_out = ensureMapFile(slice, Content.DIR_NAME, Content.class);\n             c_out.append(key, o);\n           } else if (o instanceof ParseData) {\n             slice = ((ParseData)o).getParseMeta().get(sliceMarker);\n             ((ParseData)o).getParseMeta().remove(sliceMarker);\n             ((ParseData)o).getParseMeta().remove(nameMarker);\n+            // update the segment name inside contentMeta - required by Indexer\n+            if (slice == null) {\n+              ((ParseData)o).getContentMeta().set(Fetcher.SEGMENT_NAME_KEY, segmentName);\n+            } else {\n+              ((ParseData)o).getContentMeta().set(Fetcher.SEGMENT_NAME_KEY, segmentName + \"-\" + slice);\n+            }\n             pd_out = ensureMapFile(slice, ParseData.DIR_NAME, ParseData.class);\n             pd_out.append(key, o);\n           } else if (o instanceof ParseText) {\n@@ -243,11 +258,11 @@ public void write(WritableComparable key, Writable value) throws IOException {\n           if (slice == null) slice = DEFAULT_SLICE;\n           SequenceFile.Writer res = (SequenceFile.Writer)sliceWriters.get(slice + dirName);\n           if (res != null) return res;\n-          String wname;\n+          Path wname;\n           if (slice == DEFAULT_SLICE) {\n-            wname = new File(new File(job.getOutputDir(), dirName), name).toString();\n+            wname = new Path(new Path(new Path(job.getOutputPath(), segmentName), dirName), name);\n           } else {\n-            wname = new File(new File(new File(job.getOutputDir(), slice), dirName), name).toString();\n+            wname = new Path(new Path(new Path(job.getOutputPath(), segmentName + \"-\" + slice), dirName), name);\n           }\n           res = new SequenceFile.Writer(fs, wname, UTF8.class, CrawlDatum.class);\n           sliceWriters.put(slice + dirName, res);\n@@ -259,13 +274,13 @@ public void write(WritableComparable key, Writable value) throws IOException {\n           if (slice == null) slice = DEFAULT_SLICE;\n           MapFile.Writer res = (MapFile.Writer)sliceWriters.get(slice + dirName);\n           if (res != null) return res;\n-          String wname;\n+          Path wname;\n           if (slice == DEFAULT_SLICE) {\n-            wname = new File(new File(job.getOutputDir(), dirName), name).toString();\n+            wname = new Path(new Path(new Path(job.getOutputPath(), segmentName), dirName), name);\n           } else {\n-            wname = new File(new File(new File(job.getOutputDir(), slice), dirName), name).toString();\n+            wname = new Path(new Path(new Path(job.getOutputPath(), segmentName + \"-\" + slice), dirName), name);\n           }\n-          res = new MapFile.Writer(fs, wname, UTF8.class, clazz);\n+          res = new MapFile.Writer(fs, wname.toString(), UTF8.class, clazz);\n           sliceWriters.put(slice + dirName, res);\n           return res;\n         }\n@@ -512,12 +527,14 @@ public void reduce(WritableComparable key, Iterator values, OutputCollector outp\n     }\n   }\n \n-  public void merge(File out, File[] segs, boolean filter, long slice) throws Exception {\n-    LOG.info(\"Merging \" + segs.length + \" segments to \" + out);\n+  public void merge(Path out, Path[] segs, boolean filter, long slice) throws Exception {\n+    String segmentName = Generator.generateSegmentName();\n     JobConf job = new JobConf(getConf());\n-    job.setJobName(\"mergesegs \" + out);\n+    job.setJobName(\"mergesegs \" + out + \"/\" + segmentName);\n+    LOG.info(\"Merging \" + segs.length + \" segments to \" + out + \"/\" + segmentName);\n     job.setBoolean(\"segment.merger.filter\", filter);\n     job.setLong(\"segment.merger.slice\", slice);\n+    job.set(\"segment.merger.segmentName\", segmentName);\n     FileSystem fs = FileSystem.get(getConf());\n     // prepare the minimal common set of input dirs\n     boolean g = true;\n@@ -533,12 +550,12 @@ public void merge(File out, File[] segs, boolean filter, long slice) throws Exce\n         continue;\n       }\n       LOG.info(\"SegmentMerger:   adding \" + segs[i]);\n-      File cDir = new File(segs[i], Content.DIR_NAME);\n-      File gDir = new File(segs[i], CrawlDatum.GENERATE_DIR_NAME);\n-      File fDir = new File(segs[i], CrawlDatum.FETCH_DIR_NAME);\n-      File pDir = new File(segs[i], CrawlDatum.PARSE_DIR_NAME);\n-      File pdDir = new File(segs[i], ParseData.DIR_NAME);\n-      File ptDir = new File(segs[i], ParseText.DIR_NAME);\n+      Path cDir = new Path(segs[i], Content.DIR_NAME);\n+      Path gDir = new Path(segs[i], CrawlDatum.GENERATE_DIR_NAME);\n+      Path fDir = new Path(segs[i], CrawlDatum.FETCH_DIR_NAME);\n+      Path pDir = new Path(segs[i], CrawlDatum.PARSE_DIR_NAME);\n+      Path pdDir = new Path(segs[i], ParseData.DIR_NAME);\n+      Path ptDir = new Path(segs[i], ParseText.DIR_NAME);\n       c = c && fs.exists(cDir);\n       g = g && fs.exists(gDir);\n       f = f && fs.exists(fDir);\n@@ -557,36 +574,36 @@ public void merge(File out, File[] segs, boolean filter, long slice) throws Exce\n     for (int i = 0; i < segs.length; i++) {\n       if (segs[i] == null) continue;\n       if (g) {\n-        File gDir = new File(segs[i], CrawlDatum.GENERATE_DIR_NAME);\n-        job.addInputDir(gDir);\n+        Path gDir = new Path(segs[i], CrawlDatum.GENERATE_DIR_NAME);\n+        job.addInputPath(gDir);\n       }\n       if (c) {\n-        File cDir = new File(segs[i], Content.DIR_NAME);\n-        job.addInputDir(cDir);\n+        Path cDir = new Path(segs[i], Content.DIR_NAME);\n+        job.addInputPath(cDir);\n       }\n       if (f) {\n-        File fDir = new File(segs[i], CrawlDatum.FETCH_DIR_NAME);\n-        job.addInputDir(fDir);\n+        Path fDir = new Path(segs[i], CrawlDatum.FETCH_DIR_NAME);\n+        job.addInputPath(fDir);\n       }\n       if (p) {\n-        File pDir = new File(segs[i], CrawlDatum.PARSE_DIR_NAME);\n-        job.addInputDir(pDir);\n+        Path pDir = new Path(segs[i], CrawlDatum.PARSE_DIR_NAME);\n+        job.addInputPath(pDir);\n       }\n       if (pd) {\n-        File pdDir = new File(segs[i], ParseData.DIR_NAME);\n-        job.addInputDir(pdDir);\n+        Path pdDir = new Path(segs[i], ParseData.DIR_NAME);\n+        job.addInputPath(pdDir);\n       }\n       if (pt) {\n-        File ptDir = new File(segs[i], ParseText.DIR_NAME);\n-        job.addInputDir(ptDir);\n+        Path ptDir = new Path(segs[i], ParseText.DIR_NAME);\n+        job.addInputPath(ptDir);\n       }\n     }\n     job.setInputFormat(ObjectInputFormat.class);\n     job.setInputKeyClass(UTF8.class);\n     job.setInputValueClass(ObjectWritable.class);\n     job.setMapperClass(SegmentMerger.class);\n     job.setReducerClass(SegmentMerger.class);\n-    job.setOutputDir(out);\n+    job.setOutputPath(out);\n     job.setOutputKeyClass(UTF8.class);\n     job.setOutputValueClass(ObjectWritable.class);\n     job.setOutputFormat(SegmentOutputFormat.class);\n@@ -602,7 +619,7 @@ public void merge(File out, File[] segs, boolean filter, long slice) throws Exce\n   public static void main(String[] args) throws Exception {\n     if (args.length < 2) {\n       System.err.println(\"SegmentMerger output_dir (-dir segments | seg1 seg2 ...) [-filter] [-slice NNNN]\");\n-      System.err.println(\"\\toutput_dir\\tname of the resulting segment, or the parent dir of segment slices\");\n+      System.err.println(\"\\toutput_dir\\tname of the parent dir for output segment slice(s)\");\n       System.err.println(\"\\t-dir segments\\tparent dir containing several segments\");\n       System.err.println(\"\\tseg1 seg2 ...\\tlist of segment dirs\");\n       System.err.println(\"\\t-filter\\t\\tfilter out URL-s prohibited by current URLFilters\");\n@@ -611,14 +628,14 @@ public static void main(String[] args) throws Exception {\n     }\n     Configuration conf = NutchConfiguration.create();\n     final FileSystem fs = FileSystem.get(conf);\n-    File out = new File(args[0]);\n+    Path out = new Path(args[0]);\n     ArrayList segs = new ArrayList();\n     long sliceSize = 0;\n     boolean filter = false;\n     for (int i = 1; i < args.length; i++) {\n       if (args[i].equals(\"-dir\")) {\n-        File[] files = fs.listFiles(new File(args[++i]), new FileFilter() {\n-          public boolean accept(File f) {\n+        Path[] files = fs.listPaths(new Path(args[++i]), new PathFilter() {\n+          public boolean accept(Path f) {\n             try {\n               if (fs.isDirectory(f)) return true;\n             } catch (IOException e) {}\n@@ -633,15 +650,15 @@ public boolean accept(File f) {\n       } else if (args[i].equals(\"-slice\")) {\n         sliceSize = Long.parseLong(args[++i]);\n       } else {\n-        segs.add(new File(args[i]));\n+        segs.add(new Path(args[i]));\n       }\n     }\n     if (segs.size() == 0) {\n       System.err.println(\"ERROR: No input segments.\");\n       return;\n     }\n     SegmentMerger merger = new SegmentMerger(conf);\n-    merger.merge(out, (File[]) segs.toArray(new File[segs.size()]), filter, sliceSize);\n+    merger.merge(out, (Path[]) segs.toArray(new Path[segs.size()]), filter, sliceSize);\n   }\n \n }",
                "raw_url": "https://github.com/apache/nutch/raw/db27c6473b8733b63ef025c221baccd3a7756417/src/java/org/apache/nutch/segment/SegmentMerger.java",
                "sha": "5ee4031e1eb3f8bb415b102884fc5f1ce4eabda6",
                "status": "modified"
            }
        ],
        "message": "SegmentMerger bug-fixes and improvements:\n\n* replace deprecated use of java.io.File with Hadoop's Path.\n\n* old segment name from Content.metadata needs to be replaced with\n  the new segment name. This was causing NPE-s when getting hit\n  summaries.\n\n* SegmentMerger will now always create its output in a subdirectory\n  of the output_dir argument. All newly created segments will follow\n  the same naming convention as other segments (i.e. yyyyMMddHHmmss),\n  and use sequential suffixes for sliced segments (yyyyMMddHHmmss-NN).\n\nRename Generator.getDate() to Generator.generateSegmentName(), and\nmake it public. Additionally, this method now will try to ensure that\nunique segment names are created.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@410377 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/db5d2865c2204cade87600cb89a0dcd88d372077",
        "repo": "nutch",
        "unit_tests": [
            "TestGenerator.java",
            "TestSegmentMerger.java"
        ]
    },
    "nutch_ed601a6": {
        "bug_id": "nutch_ed601a6",
        "commit": "https://github.com/apache/nutch/commit/ed601a677692595902ea96b2ae90d35e81abb7b1",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/nutch/blob/ed601a677692595902ea96b2ae90d35e81abb7b1/src/java/org/apache/nutch/crawl/Generator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/crawl/Generator.java?ref=ed601a677692595902ea96b2ae90d35e81abb7b1",
                "deletions": 1,
                "filename": "src/java/org/apache/nutch/crawl/Generator.java",
                "patch": "@@ -480,7 +480,7 @@ public Generator(Configuration conf) {\n       LOG.info(\"Generator: topN: \" + topN);\n     }\n     \n-    if (getConf().get(GENERATE_MAX_PER_HOST_BY_IP).equals(\"true\")){\n+    if (\"true\".equals(getConf().get(GENERATE_MAX_PER_HOST_BY_IP))){\n       LOG.info(\"Generator: GENERATE_MAX_PER_HOST_BY_IP will be ignored, use partition.url.mode instead\");\n     }\n ",
                "raw_url": "https://github.com/apache/nutch/raw/ed601a677692595902ea96b2ae90d35e81abb7b1/src/java/org/apache/nutch/crawl/Generator.java",
                "sha": "60bf6e4523c991302271c67345adcbdb26bfcd8e",
                "status": "modified"
            }
        ],
        "message": "fixed NPE introduced in NUTCH-762\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@926163 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/nutch/commit/133cc0696d588d373f4657ea5d334105513f2976",
        "repo": "nutch",
        "unit_tests": [
            "TestGenerator.java"
        ]
    },
    "nutch_fd203d8": {
        "bug_id": "nutch_fd203d8",
        "commit": "https://github.com/apache/nutch/commit/fd203d8f7d6376fc5348c80e4ee34d0164af31da",
        "file": [
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/nutch/blob/fd203d8f7d6376fc5348c80e4ee34d0164af31da/src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/util/PrefixStringMatcher.java?ref=fd203d8f7d6376fc5348c80e4ee34d0164af31da",
                "deletions": 2,
                "filename": "src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "patch": "@@ -16,8 +16,11 @@\n  */\n package org.apache.nutch.util;\n \n+import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.Iterator;\n+import java.util.List;\n \n /**\n  * A class for efficiently matching <code>String</code>s against a set of\n@@ -102,8 +105,9 @@ public String longestMatch(String input) {\n   }\n \n   public static final void main(String[] argv) {\n-    PrefixStringMatcher matcher = new PrefixStringMatcher(new String[] {\n-        \"abcd\", \"abc\", \"aac\", \"baz\", \"foo\", \"foobar\" });\n+    String[] prefixes = new String[] { \"abcd\", \"abc\", \"aac\", \"baz\", \"foo\",\n+        \"foobar\" };\n+    PrefixStringMatcher matcher = new PrefixStringMatcher(prefixes);\n \n     String[] tests = { \"a\", \"ab\", \"abc\", \"abcdefg\", \"apple\", \"aa\", \"aac\",\n         \"aaccca\", \"abaz\", \"baz\", \"bazooka\", \"fo\", \"foobar\", \"kite\", };\n@@ -114,5 +118,23 @@ public static final void main(String[] argv) {\n       System.out.println(\"  shortest: \" + matcher.shortestMatch(tests[i]));\n       System.out.println(\"   longest: \" + matcher.longestMatch(tests[i]));\n     }\n+\n+    int iterations = 1000;\n+    System.out.println(\"Testing thread-safety (NUTCH-2585) with \" + iterations\n+        + \" iterations:\");\n+    List<String> testsList = Arrays.asList(tests);\n+    for (int i = 0; i < iterations; i++) {\n+      matcher = new PrefixStringMatcher(prefixes);\n+      Collections.shuffle(testsList);\n+      try {\n+        long count = testsList.parallelStream().filter(matcher::matches).count();\n+        System.out.print(String.format(\"Cycle %4d : %d matches\\r\", i, count));\n+      } catch (Exception e) {\n+        // flush output\n+        System.out.println(\"\");\n+        throw e;\n+      }\n+    }\n+    System.out.println(\"\");\n   }\n }",
                "raw_url": "https://github.com/apache/nutch/raw/fd203d8f7d6376fc5348c80e4ee34d0164af31da/src/java/org/apache/nutch/util/PrefixStringMatcher.java",
                "sha": "3be0fd71a0f3d1a30851c60967f2aab4d6e403cb",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/nutch/blob/fd203d8f7d6376fc5348c80e4ee34d0164af31da/src/java/org/apache/nutch/util/TrieStringMatcher.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/nutch/contents/src/java/org/apache/nutch/util/TrieStringMatcher.java?ref=fd203d8f7d6376fc5348c80e4ee34d0164af31da",
                "deletions": 3,
                "filename": "src/java/org/apache/nutch/util/TrieStringMatcher.java",
                "patch": "@@ -23,6 +23,8 @@\n /**\n  * TrieStringMatcher is a base class for simple tree-based string matching.\n  * \n+ * This class is thread-safe during string matching but not when adding strings\n+ * to the trie.\n  */\n public abstract class TrieStringMatcher {\n   protected TrieNode root;\n@@ -103,9 +105,7 @@ TrieNode getChildAddIfNotPresent(char nextChar, boolean isTerminal) {\n      */\n     TrieNode getChild(char nextChar) {\n       if (children == null) {\n-        children = childrenList.toArray(new TrieNode[childrenList.size()]);\n-        childrenList = null;\n-        Arrays.sort(children);\n+        compile();\n       }\n \n       int min = 0;\n@@ -137,6 +137,18 @@ public int compareTo(TrieNode other) {\n       // if (this.nodeChar > other.nodeChar)\n       return 1;\n     }\n+\n+    /**\n+     * Prepare node for matching. Note: this method is synchronized because it\n+     * may be called concurrently when the trie is used for matching.\n+     */\n+    synchronized void compile() {\n+      if (childrenList != null) {\n+        children = childrenList.toArray(new TrieNode[childrenList.size()]);\n+        childrenList = null;\n+        Arrays.sort(children);\n+      }\n+    }\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/nutch/raw/fd203d8f7d6376fc5348c80e4ee34d0164af31da/src/java/org/apache/nutch/util/TrieStringMatcher.java",
                "sha": "d974ecbc1cae7c55f120a025a2b869c6424c50c1",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #452 from sebastian-nagel/NUTCH-2585-trie-string-matcher\n\nNUTCH-2585 NPE in trie string matcher",
        "parent": "https://github.com/apache/nutch/commit/7765bb3afdc6f43e8bac0a4a4f4de248657e3a76",
        "repo": "nutch",
        "unit_tests": [
            "TestPrefixStringMatcher.java"
        ]
    }
}