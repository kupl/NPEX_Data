{
    "flume_199684b": {
        "bug_id": "flume_199684b",
        "commit": "https://github.com/apache/flume/commit/199684b62ec983b8f922b1d6d706479032a18e64",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/199684b62ec983b8f922b1d6d706479032a18e64/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java?ref=199684b62ec983b8f922b1d6d706479032a18e64",
                "deletions": 1,
                "filename": "flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "patch": "@@ -102,7 +102,9 @@ public Status process() throws EventDeliveryException {\n           headers.put(KafkaSourceConstants.TIMESTAMP,\n                   String.valueOf(System.currentTimeMillis()));\n           headers.put(KafkaSourceConstants.TOPIC, topic);\n-          headers.put(KafkaSourceConstants.KEY, new String(kafkaKey));\n+          if (kafkaKey != null) {\n+            headers.put(KafkaSourceConstants.KEY, new String(kafkaKey));\n+          }\n           if (log.isDebugEnabled()) {\n             log.debug(\"Message: {}\", new String(kafkaMessage));\n           }",
                "raw_url": "https://github.com/apache/flume/raw/199684b62ec983b8f922b1d6d706479032a18e64/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "sha": "00a81c666985a8ce4f071fe075aea49235860226",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/flume/blob/199684b62ec983b8f922b1d6d706479032a18e64/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java?ref=199684b62ec983b8f922b1d6d706479032a18e64",
                "deletions": 2,
                "filename": "flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "patch": "@@ -105,8 +105,6 @@ public void testProcessItNotEmpty() throws EventDeliveryException,\n \n     Assert.assertEquals(\"hello, world\", new String(events.get(0).getBody(),\n             Charsets.UTF_8));\n-\n-\n   }\n \n   @SuppressWarnings(\"unchecked\")\n@@ -301,6 +299,29 @@ public void testTwoBatchesWithAutocommit() throws InterruptedException,\n \n   }\n \n+  @SuppressWarnings(\"unchecked\")\n+  @Test\n+  public void testNullKey() throws EventDeliveryException,\n+      SecurityException, NoSuchFieldException, IllegalArgumentException,\n+      IllegalAccessException, InterruptedException {\n+    context.put(KafkaSourceConstants.BATCH_SIZE,\"1\");\n+    kafkaSource.configure(context);\n+    kafkaSource.start();\n+\n+    Thread.sleep(500L);\n+\n+    kafkaServer.produce(topicName, null , \"hello, world\");\n+\n+    Thread.sleep(500L);\n+\n+    Assert.assertEquals(Status.READY, kafkaSource.process());\n+    Assert.assertEquals(Status.BACKOFF, kafkaSource.process());\n+    Assert.assertEquals(1, events.size());\n+\n+    Assert.assertEquals(\"hello, world\", new String(events.get(0).getBody(),\n+        Charsets.UTF_8));\n+  }\n+\n   ChannelProcessor createGoodChannel() {\n \n     ChannelProcessor channelProcessor = mock(ChannelProcessor.class);",
                "raw_url": "https://github.com/apache/flume/raw/199684b62ec983b8f922b1d6d706479032a18e64/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "sha": "8ec14cccf555ab38449b1bcb1e41a6ecbd19fe7c",
                "status": "modified"
            }
        ],
        "message": "FLUME-2578. Kafka source throws NPE if Kafka record has null key\n\n(Gwen Shapira via Hari)",
        "parent": "https://github.com/apache/flume/commit/84465664c21ed0a1261f015a010b94a98153c8d7",
        "patched_files": [
            "KafkaSource.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestKafkaSource.java"
        ]
    },
    "flume_1e69fc7": {
        "bug_id": "flume_1e69fc7",
        "commit": "https://github.com/apache/flume/commit/1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flume/blob/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java?ref=1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
                "deletions": 2,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "patch": "@@ -82,8 +82,11 @@ void writeProtos(OutputStream out) throws IOException {\n       for (String key : headers.keySet()) {\n         String value = headers.get(key);\n         headerBuilder.clear();\n-        eventBuilder.addHeaders(headerBuilder.setKey(key)\n-            .setValue(value).build());\n+        headerBuilder.setKey(key);\n+        if (value != null) {\n+          headerBuilder.setValue(value);\n+        }\n+        eventBuilder.addHeaders(headerBuilder.build());\n       }\n     }\n     eventBuilder.setBody(ByteString.copyFrom(event.getBody()));",
                "raw_url": "https://github.com/apache/flume/raw/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "sha": "c5ea290c8bfe00e6c82b03f4bdd4fada4657e2a0",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/flume/blob/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/proto/ProtosFactory.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/proto/ProtosFactory.java?ref=1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
                "deletions": 24,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/proto/ProtosFactory.java",
                "patch": "@@ -6831,17 +6831,17 @@ public Builder clearBody() {\n     com.google.protobuf.ByteString\n         getKeyBytes();\n \n-    // required string value = 2;\n+    // optional string value = 2;\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     boolean hasValue();\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     java.lang.String getValue();\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     com.google.protobuf.ByteString\n         getValueBytes();\n@@ -6990,17 +6990,17 @@ public boolean hasKey() {\n       }\n     }\n \n-    // required string value = 2;\n+    // optional string value = 2;\n     public static final int VALUE_FIELD_NUMBER = 2;\n     private java.lang.Object value_;\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     public boolean hasValue() {\n       return ((bitField0_ & 0x00000002) == 0x00000002);\n     }\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     public java.lang.String getValue() {\n       java.lang.Object ref = value_;\n@@ -7017,7 +7017,7 @@ public boolean hasValue() {\n       }\n     }\n     /**\n-     * <code>required string value = 2;</code>\n+     * <code>optional string value = 2;</code>\n      */\n     public com.google.protobuf.ByteString\n         getValueBytes() {\n@@ -7046,10 +7046,6 @@ public final boolean isInitialized() {\n         memoizedIsInitialized = 0;\n         return false;\n       }\n-      if (!hasValue()) {\n-        memoizedIsInitialized = 0;\n-        return false;\n-      }\n       memoizedIsInitialized = 1;\n       return true;\n     }\n@@ -7271,10 +7267,6 @@ public final boolean isInitialized() {\n           \n           return false;\n         }\n-        if (!hasValue()) {\n-          \n-          return false;\n-        }\n         return true;\n       }\n \n@@ -7371,16 +7363,16 @@ public Builder setKeyBytes(\n         return this;\n       }\n \n-      // required string value = 2;\n+      // optional string value = 2;\n       private java.lang.Object value_ = \"\";\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public boolean hasValue() {\n         return ((bitField0_ & 0x00000002) == 0x00000002);\n       }\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public java.lang.String getValue() {\n         java.lang.Object ref = value_;\n@@ -7394,7 +7386,7 @@ public boolean hasValue() {\n         }\n       }\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public com.google.protobuf.ByteString\n           getValueBytes() {\n@@ -7410,7 +7402,7 @@ public boolean hasValue() {\n         }\n       }\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public Builder setValue(\n           java.lang.String value) {\n@@ -7423,7 +7415,7 @@ public Builder setValue(\n         return this;\n       }\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public Builder clearValue() {\n         bitField0_ = (bitField0_ & ~0x00000002);\n@@ -7432,7 +7424,7 @@ public Builder clearValue() {\n         return this;\n       }\n       /**\n-       * <code>required string value = 2;</code>\n+       * <code>optional string value = 2;</code>\n        */\n       public Builder setValueBytes(\n           com.google.protobuf.ByteString value) {\n@@ -7546,7 +7538,7 @@ public Builder setValueBytes(\n       \"ansactionEventFooter\\\">\\n\\nFlumeEvent\\022\\\"\\n\\007he\" +\n       \"aders\\030\\001 \\003(\\0132\\021.FlumeEventHeader\\022\\014\\n\\004body\\030\\002\",\n       \" \\002(\\014\\\".\\n\\020FlumeEventHeader\\022\\013\\n\\003key\\030\\001 \\002(\\t\\022\\r\\n\" +\n-      \"\\005value\\030\\002 \\002(\\tB4\\n#org.apache.flume.channel\" +\n+      \"\\005value\\030\\002 \\001(\\tB4\\n#org.apache.flume.channel\" +\n       \".file.protoB\\rProtosFactory\"\n     };\n     com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =",
                "raw_url": "https://github.com/apache/flume/raw/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/proto/ProtosFactory.java",
                "sha": "202f33d006c786988062547505e5e30a1f7f78ba",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/proto/filechannel.proto",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/proto/filechannel.proto?ref=1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/proto/filechannel.proto",
                "patch": "@@ -83,5 +83,5 @@ message FlumeEvent {\n \n message FlumeEventHeader {\n   required string key = 1;\n-  required string value = 2;\n+  optional string value = 2;\n }",
                "raw_url": "https://github.com/apache/flume/raw/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/main/proto/filechannel.proto",
                "sha": "929b41df1e61370b6b4f22e046599a11854df24b",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/flume/blob/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestFileChannel.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestFileChannel.java?ref=1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
                "deletions": 0,
                "filename": "flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestFileChannel.java",
                "patch": "@@ -18,6 +18,7 @@\n  */\n package org.apache.flume.channel.file;\n \n+import com.google.common.base.Charsets;\n import com.google.common.base.Throwables;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n@@ -69,6 +70,7 @@\n \n   private static final Logger LOG = LoggerFactory\n           .getLogger(TestFileChannel.class);\n+  public static final String TEST_KEY = \"test_key\";\n \n   @Before\n   public void setup() throws Exception {\n@@ -233,6 +235,28 @@ public void testPut() throws Exception {\n     compareInputAndOut(expected, actual);\n   }\n \n+  @Test\n+  public void testPutConvertsNullValueToEmptyStrInHeader() throws Exception {\n+    channel.start();\n+\n+    Event event = EventBuilder.withBody(\"test body\".getBytes(Charsets.UTF_8),\n+        Collections.<String, String>singletonMap(TEST_KEY, null));\n+\n+    Transaction txPut = channel.getTransaction();\n+    txPut.begin();\n+    channel.put(event);\n+    txPut.commit();\n+    txPut.close();\n+\n+    Transaction txTake = channel.getTransaction();\n+    txTake.begin();\n+    Event eventTaken = channel.take();\n+    Assert.assertArrayEquals(event.getBody(), eventTaken.getBody());\n+    Assert.assertEquals(\"\", eventTaken.getHeaders().get(TEST_KEY));\n+    txTake.commit();\n+    txTake.close();\n+  }\n+\n   @Test\n   public void testCommitAfterNoPutTake() throws Exception {\n     channel.start();",
                "raw_url": "https://github.com/apache/flume/raw/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestFileChannel.java",
                "sha": "a3d27f7de98bc10f7c0076b5421a2ea4ca0696fa",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/flume/blob/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java?ref=1e69fc7c29f104a2117a62de11cba9b2a2c740e1",
                "deletions": 0,
                "filename": "flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "patch": "@@ -19,6 +19,7 @@\n \n package org.apache.flume.channel;\n \n+import com.google.common.base.Charsets;\n import com.google.common.collect.ImmutableMap;\n import org.apache.flume.ChannelException;\n import org.apache.flume.Context;\n@@ -32,6 +33,7 @@\n import org.junit.Before;\n import org.junit.Test;\n \n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.concurrent.LinkedBlockingDeque;\n@@ -71,6 +73,26 @@ public void testPutTake() throws InterruptedException, EventDeliveryException {\n     transaction.commit();\n   }\n \n+  @Test\n+  public void testPutAcceptsNullValueInHeader() {\n+    Configurables.configure(channel, new Context());\n+\n+    Event event = EventBuilder.withBody(\"test body\".getBytes(Charsets.UTF_8),\n+        Collections.<String, String>singletonMap(\"test_key\", null));\n+\n+    Transaction txPut = channel.getTransaction();\n+    txPut.begin();\n+    channel.put(event);\n+    txPut.commit();\n+    txPut.close();\n+\n+    Transaction txTake = channel.getTransaction();\n+    txTake.begin();\n+    Event eventTaken = channel.take();\n+    Assert.assertEquals(event, eventTaken);\n+    txTake.commit();\n+  }\n+\n   @Test\n   public void testChannelResize() {\n     Context context = new Context();",
                "raw_url": "https://github.com/apache/flume/raw/1e69fc7c29f104a2117a62de11cba9b2a2c740e1/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "sha": "f7e43eb01b4581b227d491e4c3008612b48a3b7a",
                "status": "modified"
            }
        ],
        "message": "FLUME-2620. File Channel to support empty values in headers\n\nFlume user guide does not specify whether a value in event header could be null or not.\nGiven an external system generating events which header values can be null and a user configures\nFlume with Memory Channel then he will have no trouble.\nLater on when the user changes Memory Channel to File Channel then Flume will fail with NPE.\nIt is because FC is serializing events with protocol buffer and header values are defined as\nrequired in the proto file.\nIn this patch I have changed the value field to optional. However protocol buffer does not have\na notation for null and setting a field to null raises NPE again. Added a null check before\nserialization to prevent this.\nThere is on caveat: When an optional field is not set, at deserialization it will be set to a\ndefault value: in this case it will be empty string.\n\nReviewers: Miklos Csanady\n\n(Marcell Hegedus via Denes Arvay)",
        "parent": "https://github.com/apache/flume/commit/c570a51b3c53e4899d16dd623e19a0d939518dd2",
        "patched_files": [
            "MemoryChannel.java",
            "FileChannel.java",
            "Put.java",
            "ProtosFactory.java",
            "filechannel.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestMemoryChannel.java",
            "TestFileChannel.java"
        ]
    },
    "flume_250c457": {
        "bug_id": "flume_250c457",
        "commit": "https://github.com/apache/flume/commit/250c4579033b36f2ea2e66a581e1c0834c627732",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flume/blob/250c4579033b36f2ea2e66a581e1c0834c627732/flume-ng-core/src/main/java/org/apache/flume/channel/MemoryChannel.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/channel/MemoryChannel.java?ref=250c4579033b36f2ea2e66a581e1c0834c627732",
                "deletions": 1,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/channel/MemoryChannel.java",
                "patch": "@@ -330,6 +330,11 @@ protected BasicTransactionSemantics createTransaction() {\n \n   private long estimateEventSize(Event event)\n   {\n-    return event.getBody().length;\n+    byte[] body = event.getBody();\n+    if(body != null && body.length != 0) {\n+      return body.length;\n+    }\n+    //Each event occupies at least 1 slot, so return 1.\n+    return 1;\n   }\n }",
                "raw_url": "https://github.com/apache/flume/raw/250c4579033b36f2ea2e66a581e1c0834c627732/flume-ng-core/src/main/java/org/apache/flume/channel/MemoryChannel.java",
                "sha": "06c90d9e7fa09f5066a56076509a5ba2960377fb",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/flume/blob/250c4579033b36f2ea2e66a581e1c0834c627732/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java?ref=250c4579033b36f2ea2e66a581e1c0834c627732",
                "deletions": 0,
                "filename": "flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "patch": "@@ -411,4 +411,32 @@ public void testByteCapacityBufferChangeConfig() {\n       //success\n     }\n   }\n+\n+  /*\n+   * This would cause a NPE without FLUME-1622.\n+   */\n+  @Test\n+  public void testNullEmptyEvent() {\n+    Context context = new Context();\n+    Map<String, String> parms = new HashMap<String, String>();\n+    parms.put(\"byteCapacity\", \"2000\");\n+    parms.put(\"byteCapacityBufferPercentage\", \"20\");\n+    context.putAll(parms);\n+    Configurables.configure(channel,  context);\n+\n+    Transaction tx = channel.getTransaction();\n+    tx.begin();\n+    //This line would cause a NPE without FLUME-1622.\n+    channel.put(EventBuilder.withBody(null));\n+    tx.commit();\n+    tx.close();\n+\n+    tx = channel.getTransaction();\n+    tx.begin();\n+    channel.put(EventBuilder.withBody(new byte[0]));\n+    tx.commit();\n+    tx.close();\n+\n+\n+  }\n }",
                "raw_url": "https://github.com/apache/flume/raw/250c4579033b36f2ea2e66a581e1c0834c627732/flume-ng-core/src/test/java/org/apache/flume/channel/TestMemoryChannel.java",
                "sha": "e1a61c2fcae8dfb987d5995f8050389c8bf04fe5",
                "status": "modified"
            }
        ],
        "message": "FLUME-1622: MemoryChannel throws NPE if the event has no body\n\n(Hari Shreedharan via Brock Noland)",
        "parent": "https://github.com/apache/flume/commit/bad9e9ab822068806c85c8857eca154d024a52db",
        "patched_files": [
            "MemoryChannel.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestMemoryChannel.java"
        ]
    },
    "flume_296fc9f": {
        "bug_id": "flume_296fc9f",
        "commit": "https://github.com/apache/flume/commit/296fc9f92b51bbe9c674cede560ab7be8a03e161",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/flume/blob/296fc9f92b51bbe9c674cede560ab7be8a03e161/flume-ng-core/src/main/java/org/apache/flume/source/ThriftSource.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/source/ThriftSource.java?ref=296fc9f92b51bbe9c674cede560ab7be8a03e161",
                "deletions": 7,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/source/ThriftSource.java",
                "patch": "@@ -153,14 +153,16 @@ public void stop() {\n     if(server != null && server.isServing()) {\n       server.stop();\n     }\n-    servingExecutor.shutdown();\n-    try {\n-      if(!servingExecutor.awaitTermination(5, TimeUnit.SECONDS)) {\n-        servingExecutor.shutdownNow();\n+    if (servingExecutor != null) {\n+      servingExecutor.shutdown();\n+      try {\n+        if (!servingExecutor.awaitTermination(5, TimeUnit.SECONDS)) {\n+          servingExecutor.shutdownNow();\n+        }\n+      } catch (InterruptedException e) {\n+        throw new FlumeException(\"Interrupted while waiting for server to be \" +\n+          \"shutdown.\");\n       }\n-    } catch (InterruptedException e) {\n-      throw new FlumeException(\"Interrupted while waiting for server to be \" +\n-        \"shutdown.\");\n     }\n     sourceCounter.stop();\n     super.stop();",
                "raw_url": "https://github.com/apache/flume/raw/296fc9f92b51bbe9c674cede560ab7be8a03e161/flume-ng-core/src/main/java/org/apache/flume/source/ThriftSource.java",
                "sha": "68a632a5a4916f757830e175aa76ed870833c96d",
                "status": "modified"
            }
        ],
        "message": "FLUME-2025. ThriftSource throws NPE in stop() if start() failed because socket open failed or if thrift server instance creation threw.\n\n(Hari Shreedharan via Mike Percy)",
        "parent": "https://github.com/apache/flume/commit/337e5fc3768af2d26a9a9dbfaa1e5afa30ae26bf",
        "patched_files": [
            "ThriftSource.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestThriftSource.java"
        ]
    },
    "flume_3ddf4d7": {
        "bug_id": "flume_3ddf4d7",
        "commit": "https://github.com/apache/flume/commit/3ddf4d783e582e168eaa7e36740d8b3fe98ba881",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flume/blob/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/pom.xml",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/pom.xml?ref=3ddf4d783e582e168eaa7e36740d8b3fe98ba881",
                "deletions": 0,
                "filename": "flume-ng-core/pom.xml",
                "patch": "@@ -164,6 +164,12 @@ limitations under the License.\n       <artifactId>servlet-api</artifactId>\n     </dependency>\n \n+    <dependency>\n+      <groupId>org.mockito</groupId>\n+      <artifactId>mockito-all</artifactId>\n+      <scope>test</scope>\n+    </dependency>\n+\n   </dependencies>\n \n </project>",
                "raw_url": "https://github.com/apache/flume/raw/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/pom.xml",
                "sha": "8dd0d3e24a023d09ea1f5e1d07fd622bf4830eeb",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/main/java/org/apache/flume/channel/ChannelProcessor.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/channel/ChannelProcessor.java?ref=3ddf4d783e582e168eaa7e36740d8b3fe98ba881",
                "deletions": 4,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/channel/ChannelProcessor.java",
                "patch": "@@ -173,9 +173,9 @@ public void processEventBatch(List<Event> events) {\n \n     // Process required channels\n     for (Channel reqChannel : reqChannelQueue.keySet()) {\n-      Transaction tx = null;\n+      Transaction tx = reqChannel.getTransaction();\n+      Preconditions.checkNotNull(tx, \"Transaction object must not be null\");\n       try {\n-        tx = reqChannel.getTransaction();\n         tx.begin();\n \n         List<Event> batch = reqChannelQueue.get(reqChannel);\n@@ -204,9 +204,9 @@ public void processEventBatch(List<Event> events) {\n \n     // Process optional channels\n     for (Channel optChannel : optChannelQueue.keySet()) {\n-      Transaction tx = null;\n+      Transaction tx = optChannel.getTransaction();\n+      Preconditions.checkNotNull(tx, \"Transaction object must not be null\");\n       try {\n-        tx = optChannel.getTransaction();\n         tx.begin();\n \n         List<Event> batch = optChannelQueue.get(optChannel);",
                "raw_url": "https://github.com/apache/flume/raw/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/main/java/org/apache/flume/channel/ChannelProcessor.java",
                "sha": "53bfac1c8e9b629f54d917a593e0552b218084c6",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flume/blob/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/main/java/org/apache/flume/source/AvroSource.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/source/AvroSource.java?ref=3ddf4d783e582e168eaa7e36740d8b3fe98ba881",
                "deletions": 2,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/source/AvroSource.java",
                "patch": "@@ -235,9 +235,12 @@ public Status appendBatch(List<AvroFlumeEvent> events) {\n \n     try {\n       getChannelProcessor().processEventBatch(batch);\n-    } catch (ChannelException ex) {\n+    } catch (Throwable t) {\n       logger.error(\"Avro source \" + getName() + \": Unable to process event \" +\n-          \"batch. Exception follows.\", ex);\n+          \"batch. Exception follows.\", t);\n+      if (t instanceof Error) {\n+        throw (Error) t;\n+      }\n       return Status.FAILED;\n     }\n ",
                "raw_url": "https://github.com/apache/flume/raw/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/main/java/org/apache/flume/source/AvroSource.java",
                "sha": "e91af9e346d804126e5aee1d227b38f0161f07cb",
                "status": "modified"
            },
            {
                "additions": 82,
                "blob_url": "https://github.com/apache/flume/blob/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/test/java/org/apache/flume/channel/TestChannelProcessor.java",
                "changes": 82,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/test/java/org/apache/flume/channel/TestChannelProcessor.java?ref=3ddf4d783e582e168eaa7e36740d8b3fe98ba881",
                "deletions": 0,
                "filename": "flume-ng-core/src/test/java/org/apache/flume/channel/TestChannelProcessor.java",
                "patch": "@@ -0,0 +1,82 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flume.channel;\n+\n+import com.google.common.base.Charsets;\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.flume.Channel;\n+import org.apache.flume.ChannelException;\n+import org.apache.flume.ChannelSelector;\n+import org.apache.flume.Event;\n+import org.apache.flume.event.EventBuilder;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import static org.mockito.Mockito.*;\n+\n+public class TestChannelProcessor {\n+\n+  /**\n+   * Ensure that we bubble up any specific exception thrown from getTransaction\n+   * instead of another exception masking it such as an NPE\n+   */\n+  @Test(expected = ChannelException.class)\n+  public void testExceptionFromGetTransaction() {\n+    // create a channel which unexpectedly throws a ChEx on getTransaction()\n+    Channel ch = mock(Channel.class);\n+    when(ch.getTransaction()).thenThrow(new ChannelException(\"doh!\"));\n+\n+    ChannelSelector sel = new ReplicatingChannelSelector();\n+    sel.setChannels(Lists.newArrayList(ch));\n+    ChannelProcessor proc = new ChannelProcessor(sel);\n+\n+    List<Event> events = Lists.newArrayList();\n+    events.add(EventBuilder.withBody(\"event 1\", Charsets.UTF_8));\n+\n+    proc.processEventBatch(events);\n+  }\n+\n+  /**\n+   * Ensure that we see the original NPE from the PreConditions check instead\n+   * of an auto-generated NPE, which could be masking something else.\n+   */\n+  @Test\n+  public void testNullFromGetTransaction() {\n+    // channel which returns null from getTransaction()\n+    Channel ch = mock(Channel.class);\n+    when(ch.getTransaction()).thenReturn(null);\n+\n+    ChannelSelector sel = new ReplicatingChannelSelector();\n+    sel.setChannels(Lists.newArrayList(ch));\n+    ChannelProcessor proc = new ChannelProcessor(sel);\n+\n+    List<Event> events = Lists.newArrayList();\n+    events.add(EventBuilder.withBody(\"event 1\", Charsets.UTF_8));\n+\n+    boolean threw = false;\n+    try {\n+      proc.processEventBatch(events);\n+    } catch (NullPointerException ex) {\n+      threw = true;\n+      Assert.assertNotNull(\"NPE must be manually thrown\", ex.getMessage());\n+    }\n+    Assert.assertTrue(\"Must throw NPE\", threw);\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/flume/raw/3ddf4d783e582e168eaa7e36740d8b3fe98ba881/flume-ng-core/src/test/java/org/apache/flume/channel/TestChannelProcessor.java",
                "sha": "06565962862c1ff1db874430562e12ff04938ae6",
                "status": "added"
            }
        ],
        "message": "FLUME-1377. ChannelProcessor should not throw NPE if channel.getTransaction throws.\n\n(Mike Percy via Hari Shreedharan)\n\ngit-svn-id: https://svn.apache.org/repos/asf/flume/trunk@1362809 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/5c22b171d65e236636f01b5c8d5d7a1b9b49a14a",
        "patched_files": [
            "ChannelProcessor.java",
            "pom.java",
            "AvroSource.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestChannelProcessor.java",
            "TestAvroSource.java"
        ]
    },
    "flume_5293eba": {
        "bug_id": "flume_5293eba",
        "commit": "https://github.com/apache/flume/commit/5293eba9a418180b42b3138c0c0b5aac38361f7f",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/5293eba9a418180b42b3138c0c0b5aac38361f7f/flume-ng-sinks/flume-ng-hbase-sink/src/main/java/org/apache/flume/sink/hbase/AsyncHBaseSink.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sinks/flume-ng-hbase-sink/src/main/java/org/apache/flume/sink/hbase/AsyncHBaseSink.java?ref=5293eba9a418180b42b3138c0c0b5aac38361f7f",
                "deletions": 2,
                "filename": "flume-ng-sinks/flume-ng-hbase-sink/src/main/java/org/apache/flume/sink/hbase/AsyncHBaseSink.java",
                "patch": "@@ -204,10 +204,11 @@ public Status process() throws EventDeliveryException {\n \n     Status status = Status.READY;\n     Channel channel = getChannel();\n+    txn = channel.getTransaction();\n+    txn.begin();\n+\n     int i = 0;\n     try {\n-      txn = channel.getTransaction();\n-      txn.begin();\n       for (; i < batchSize; i++) {\n         Event event = channel.take();\n         if (event == null) {",
                "raw_url": "https://github.com/apache/flume/raw/5293eba9a418180b42b3138c0c0b5aac38361f7f/flume-ng-sinks/flume-ng-hbase-sink/src/main/java/org/apache/flume/sink/hbase/AsyncHBaseSink.java",
                "sha": "c1ff0c41eb57b0b4c77754cb4b8714c0b13a6c8b",
                "status": "modified"
            }
        ],
        "message": "FLUME-2897: AsyncHBase sink NPE when Channel.getTransaction() fails\n\n(Mike Percy via Jarek Jarcec Cecho)",
        "parent": "https://github.com/apache/flume/commit/caa64a1a6d4bc97be5993cb468516e9ffe862794",
        "patched_files": [
            "AsyncHBaseSink.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestAsyncHBaseSink.java"
        ]
    },
    "flume_591b138": {
        "bug_id": "flume_591b138",
        "commit": "https://github.com/apache/flume/commit/591b138321280cea1e7d61efcaf625a67202cb3d",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/591b138321280cea1e7d61efcaf625a67202cb3d/flume-ng-sources/flume-jms-source/src/main/java/org/apache/flume/source/jms/DefaultJMSMessageConverter.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-jms-source/src/main/java/org/apache/flume/source/jms/DefaultJMSMessageConverter.java?ref=591b138321280cea1e7d61efcaf625a67202cb3d",
                "deletions": 1,
                "filename": "flume-ng-sources/flume-jms-source/src/main/java/org/apache/flume/source/jms/DefaultJMSMessageConverter.java",
                "patch": "@@ -100,7 +100,10 @@ public JMSMessageConverter build(Context context) {\n       }\n     } else if (message instanceof TextMessage) {\n       TextMessage textMessage = (TextMessage)message;\n-      event.setBody(textMessage.getText().getBytes(charset));\n+      String text = textMessage.getText();\n+      if (text != null) {\n+        event.setBody(text.getBytes(charset));\n+      }\n     } else if (message instanceof ObjectMessage) {\n       ObjectMessage objectMessage = (ObjectMessage)message;\n       Object object = objectMessage.getObject();",
                "raw_url": "https://github.com/apache/flume/raw/591b138321280cea1e7d61efcaf625a67202cb3d/flume-ng-sources/flume-jms-source/src/main/java/org/apache/flume/source/jms/DefaultJMSMessageConverter.java",
                "sha": "003f591fd53ef122dbf1c0fac1c3fe911fdd4588",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/flume/blob/591b138321280cea1e7d61efcaf625a67202cb3d/flume-ng-sources/flume-jms-source/src/test/java/org/apache/flume/source/jms/TestDefaultJMSMessageConverter.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-jms-source/src/test/java/org/apache/flume/source/jms/TestDefaultJMSMessageConverter.java?ref=591b138321280cea1e7d61efcaf625a67202cb3d",
                "deletions": 0,
                "filename": "flume-ng-sources/flume-jms-source/src/test/java/org/apache/flume/source/jms/TestDefaultJMSMessageConverter.java",
                "patch": "@@ -66,6 +66,13 @@ void createTextMessage() throws Exception {\n     when(message.getText()).thenReturn(TEXT);\n     this.message = message;\n   }\n+\n+  void createNullTextMessage() throws Exception {\n+    TextMessage message = mock(TextMessage.class);\n+    when(message.getText()).thenReturn(null);\n+    this.message = message;\n+  }\n+\n   void createBytesMessage() throws Exception {\n     BytesMessage message = mock(BytesMessage.class);\n     when(message.getBodyLength()).thenReturn((long)BYTES.length);\n@@ -117,6 +124,20 @@ public void testTextMessage() throws Exception {\n     assertEquals(headers, event.getHeaders());\n     assertEquals(TEXT, new String(event.getBody(), Charsets.UTF_8));\n   }\n+\n+  @Test\n+  public void testNullTextMessage() throws Exception {\n+    createNullTextMessage();\n+    headers.put(\"key1\", \"value1\");\n+    headers.put(\"key2\", \"value2\");\n+    createHeaders();\n+    Event event = converter.convert(message).iterator().next();\n+    assertEquals(headers, event.getHeaders());\n+    // In case of a null text message, the event's body will be empty due to\n+    // SimpleEvent's body not updated with a valid text message.\n+    assertEquals(event.getBody().length, 0);\n+  }\n+\n   @Test\n   public void testBytesMessage() throws Exception {\n     createBytesMessage();",
                "raw_url": "https://github.com/apache/flume/raw/591b138321280cea1e7d61efcaf625a67202cb3d/flume-ng-sources/flume-jms-source/src/test/java/org/apache/flume/source/jms/TestDefaultJMSMessageConverter.java",
                "sha": "f0e46ca3ac2f6eba5d2c711083bd959736acb0c1",
                "status": "modified"
            }
        ],
        "message": "FLUME-2966. Fix NPE in JMS Source\n\nJMS Source does not check for null text in a TextMessage. This can lead to NullPointerException.\nThis commit fixes that problem by checking for nullity of textMessage.getText().\n\nReviewers: Denes Arvay, Attila Simon, Mike Percy, Bessenyei Bal\u00e1zs Don\u00e1t\n\n(Siddharth Ahuja via Bessenyei Bal\u00e1zs Don\u00e1t)",
        "parent": "https://github.com/apache/flume/commit/d9c9a7dd9a6889ecf6b9dc88fb8e02ccc1cd5167",
        "patched_files": [
            "DefaultJMSMessageConverter.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestDefaultJMSMessageConverter.java"
        ]
    },
    "flume_606eabb": {
        "bug_id": "flume_606eabb",
        "commit": "https://github.com/apache/flume/commit/606eabb09997fa939735b5600f526a99895c350c",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/pom.xml",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-kafka-channel/pom.xml?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-kafka-channel/pom.xml",
                "patch": "@@ -71,7 +71,11 @@ limitations under the License.\n       <artifactId>mockito-all</artifactId>\n       <scope>test</scope>\n     </dependency>\n-\n+    <dependency>\n+      <groupId>org.apache.logging.log4j</groupId>\n+      <artifactId>log4j-slf4j-impl</artifactId>\n+      <scope>test</scope>\n+    </dependency>\n   </dependencies>\n \n </project>",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/pom.xml",
                "sha": "9bf1e27d2addafa96682882078926ae4edb38937",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 7,
                "filename": "flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "patch": "@@ -318,6 +318,10 @@ private void migrateOffsets() {\n             Time.SYSTEM, \"kafka.server\", \"SessionExpireListener\");\n          KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(consumerProps)) {\n       Map<TopicPartition, OffsetAndMetadata> kafkaOffsets = getKafkaOffsets(consumer);\n+      if (kafkaOffsets == null) {\n+        logger.warn(\"Topic \" + topicStr + \" not found in Kafka. Offset migration will be skipped.\");\n+        return;\n+      }\n       if (!kafkaOffsets.isEmpty()) {\n         logger.info(\"Found Kafka offsets for topic {}. Will not migrate from zookeeper\", topicStr);\n         logger.debug(\"Offsets found: {}\", kafkaOffsets);\n@@ -338,7 +342,8 @@ private void migrateOffsets() {\n       // Read the offsets to verify they were committed\n       Map<TopicPartition, OffsetAndMetadata> newKafkaOffsets = getKafkaOffsets(consumer);\n       logger.debug(\"Offsets committed: {}\", newKafkaOffsets);\n-      if (!newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {\n+      if (newKafkaOffsets == null\n+          || !newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {\n         throw new FlumeException(\"Offsets could not be committed\");\n       }\n     }\n@@ -347,13 +352,16 @@ private void migrateOffsets() {\n \n   private Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(\n       KafkaConsumer<String, byte[]> client) {\n-    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\n+    Map<TopicPartition, OffsetAndMetadata> offsets = null;\n     List<PartitionInfo> partitions = client.partitionsFor(topicStr);\n-    for (PartitionInfo partition : partitions) {\n-      TopicPartition key = new TopicPartition(topicStr, partition.partition());\n-      OffsetAndMetadata offsetAndMetadata = client.committed(key);\n-      if (offsetAndMetadata != null) {\n-        offsets.put(key, offsetAndMetadata);\n+    if (partitions != null) {\n+      offsets = new HashMap<>();\n+      for (PartitionInfo partition : partitions) {\n+        TopicPartition key = new TopicPartition(topicStr, partition.partition());\n+        OffsetAndMetadata offsetAndMetadata = client.committed(key);\n+        if (offsetAndMetadata != null) {\n+          offsets.put(key, offsetAndMetadata);\n+        }\n       }\n     }\n     return offsets;",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "sha": "852b4bd58669cb757e6c6b7e51408f5d51174d66",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/test/java/org/apache/flume/channel/kafka/TestOffsetsAndMigration.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-kafka-channel/src/test/java/org/apache/flume/channel/kafka/TestOffsetsAndMigration.java?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 0,
                "filename": "flume-ng-channels/flume-kafka-channel/src/test/java/org/apache/flume/channel/kafka/TestOffsetsAndMigration.java",
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.flume.Context;\n import org.apache.flume.Event;\n import org.apache.flume.Transaction;\n+import org.apache.flume.lifecycle.LifecycleState;\n import org.apache.kafka.clients.consumer.KafkaConsumer;\n import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n import org.apache.kafka.clients.producer.KafkaProducer;\n@@ -190,4 +191,20 @@ private void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean\n       Assert.assertTrue(\"Channel should read the 11th message\", finals.contains(11));\n     }\n   }\n+\n+  @Test\n+  public void testMigrateZookeeperOffsetsWhenTopicNotExists() throws Exception {\n+    topic = findUnusedTopic();\n+\n+    Context context = prepareDefaultContext(false);\n+    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, testUtil.getZkUrl());\n+    context.put(GROUP_ID_FLUME, \"testMigrateOffsets-nonExistingTopic\");\n+    KafkaChannel channel = createChannel(context);\n+\n+    channel.start();\n+\n+    Assert.assertEquals(LifecycleState.START, channel.getLifecycleState());\n+\n+    channel.stop();\n+  }\n }",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/test/java/org/apache/flume/channel/kafka/TestOffsetsAndMigration.java",
                "sha": "7657aa6518383cd12a087584a96f01a2f6ff42cf",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/test/resources/kafka-server.properties",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-kafka-channel/src/test/resources/kafka-server.properties?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-kafka-channel/src/test/resources/kafka-server.properties",
                "patch": "@@ -1,5 +1,4 @@\n # Licensed to the Apache Software Foundation (ASF) under one or more\n-# Licensed to the Apache Software Foundation (ASF) under one or more\n # contributor license agreements.  See the NOTICE file distributed with\n # this work for additional information regarding copyright ownership.\n # The ASF licenses this file to You under the Apache License, Version 2.0\n@@ -118,3 +117,5 @@ zookeeper.connect=localhost:2181\n zookeeper.connection.timeout.ms=1000000\n \n offsets.topic.replication.factor=1\n+\n+auto.create.topics.enable=false",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-channels/flume-kafka-channel/src/test/resources/kafka-server.properties",
                "sha": "55fa20d379866dd5457e55e6ae780da214abfed6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sinks/flume-ng-kafka-sink/src/test/resources/kafka-server.properties",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sinks/flume-ng-kafka-sink/src/test/resources/kafka-server.properties?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 1,
                "filename": "flume-ng-sinks/flume-ng-kafka-sink/src/test/resources/kafka-server.properties",
                "patch": "@@ -1,5 +1,4 @@\n # Licensed to the Apache Software Foundation (ASF) under one or more\n-# Licensed to the Apache Software Foundation (ASF) under one or more\n # contributor license agreements.  See the NOTICE file distributed with\n # this work for additional information regarding copyright ownership.\n # The ASF licenses this file to You under the Apache License, Version 2.0",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sinks/flume-ng-kafka-sink/src/test/resources/kafka-server.properties",
                "sha": "b6e1207705d8c918e8e9acf31c22782a2d5311b6",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/pom.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/pom.xml?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 0,
                "filename": "flume-ng-sources/flume-kafka-source/pom.xml",
                "patch": "@@ -76,5 +76,10 @@\n       <classifier>test</classifier>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.logging.log4j</groupId>\n+      <artifactId>log4j-slf4j-impl</artifactId>\n+      <scope>test</scope>\n+    </dependency>\n   </dependencies>\n </project>",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/pom.xml",
                "sha": "affc999438a2b6b07d34961187703581cc20f996",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 7,
                "filename": "flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "patch": "@@ -567,6 +567,10 @@ private void migrateOffsets(String topicStr) {\n          KafkaConsumer<String, byte[]> consumer = new KafkaConsumer<>(kafkaProps)) {\n       Map<TopicPartition, OffsetAndMetadata> kafkaOffsets =\n           getKafkaOffsets(consumer, topicStr);\n+      if (kafkaOffsets == null) {\n+        log.warn(\"Topic \" + topicStr + \" not found in Kafka. Offset migration will be skipped.\");\n+        return;\n+      }\n       if (!kafkaOffsets.isEmpty()) {\n         log.info(\"Found Kafka offsets for topic \" + topicStr +\n             \". Will not migrate from zookeeper\");\n@@ -589,21 +593,25 @@ private void migrateOffsets(String topicStr) {\n       Map<TopicPartition, OffsetAndMetadata> newKafkaOffsets =\n           getKafkaOffsets(consumer, topicStr);\n       log.debug(\"Offsets committed: {}\", newKafkaOffsets);\n-      if (!newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {\n+      if (newKafkaOffsets == null\n+          || !newKafkaOffsets.keySet().containsAll(zookeeperOffsets.keySet())) {\n         throw new FlumeException(\"Offsets could not be committed\");\n       }\n     }\n   }\n \n   private Map<TopicPartition, OffsetAndMetadata> getKafkaOffsets(\n       KafkaConsumer<String, byte[]> client, String topicStr) {\n-    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\n+    Map<TopicPartition, OffsetAndMetadata> offsets = null;\n     List<PartitionInfo> partitions = client.partitionsFor(topicStr);\n-    for (PartitionInfo partition : partitions) {\n-      TopicPartition key = new TopicPartition(topicStr, partition.partition());\n-      OffsetAndMetadata offsetAndMetadata = client.committed(key);\n-      if (offsetAndMetadata != null) {\n-        offsets.put(key, offsetAndMetadata);\n+    if (partitions != null) {\n+      offsets = new HashMap<>();\n+      for (PartitionInfo partition : partitions) {\n+        TopicPartition key = new TopicPartition(topicStr, partition.partition());\n+        OffsetAndMetadata offsetAndMetadata = client.committed(key);\n+        if (offsetAndMetadata != null) {\n+          offsets.put(key, offsetAndMetadata);\n+        }\n       }\n     }\n     return offsets;",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/main/java/org/apache/flume/source/kafka/KafkaSource.java",
                "sha": "b02285d91324607e00919060e66747a838dab772",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/KafkaSourceEmbeddedKafka.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/KafkaSourceEmbeddedKafka.java?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 0,
                "filename": "flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/KafkaSourceEmbeddedKafka.java",
                "patch": "@@ -76,6 +76,7 @@ public KafkaSourceEmbeddedKafka(Properties properties) {\n     props.put(\"port\", String.valueOf(serverPort));\n     props.put(\"log.dir\", dir.getAbsolutePath());\n     props.put(\"offsets.topic.replication.factor\", \"1\");\n+    props.put(\"auto.create.topics.enable\", \"false\");\n     if (properties != null) {\n       props.putAll(properties);\n     }",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/KafkaSourceEmbeddedKafka.java",
                "sha": "56a582a188a267417e43776abddb365824b458ef",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/flume/blob/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java?ref=606eabb09997fa939735b5600f526a99895c350c",
                "deletions": 1,
                "filename": "flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "patch": "@@ -34,6 +34,7 @@\n import org.apache.flume.PollableSource.Status;\n import org.apache.flume.channel.ChannelProcessor;\n import org.apache.flume.instrumentation.SourceCounter;\n+import org.apache.flume.lifecycle.LifecycleState;\n import org.apache.flume.source.avro.AvroFlumeEvent;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.clients.consumer.ConsumerRecords;\n@@ -340,6 +341,8 @@ public void testNonExistingTopic() throws EventDeliveryException,\n     startKafkaSource();\n     Thread.sleep(500L);\n \n+    assertEquals(LifecycleState.START, kafkaSource.getLifecycleState());\n+\n     Status status = kafkaSource.process();\n     assertEquals(Status.BACKOFF, status);\n   }\n@@ -845,7 +848,7 @@ public void testTopicCustomHeaderNotSet() throws InterruptedException, EventDeli\n     kafkaSource.stop();\n   }\n \n-  public void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean hasKafkaOffsets,\n+  private void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean hasKafkaOffsets,\n                                             String group) throws Exception {\n     // create a topic with 1 partition for simplicity\n     String topic = findUnusedTopic();\n@@ -928,6 +931,27 @@ public void doTestMigrateZookeeperOffsets(boolean hasZookeeperOffsets, boolean h\n     }\n   }\n \n+  @Test\n+  public void testMigrateZookeeperOffsetsWhenTopicNotExists() throws Exception {\n+    String topic = findUnusedTopic();\n+\n+    Context context = prepareDefaultContext(\"testMigrateOffsets-nonExistingTopic\");\n+    context.put(ZOOKEEPER_CONNECT_FLUME_KEY, kafkaServer.getZkConnectString());\n+    context.put(TOPIC, topic);\n+    KafkaSource source = new KafkaSource();\n+    source.doConfigure(context);\n+\n+    source.setChannelProcessor(createGoodChannel());\n+    source.start();\n+\n+    assertEquals(LifecycleState.START, source.getLifecycleState());\n+\n+    Status status = source.process();\n+    assertEquals(Status.BACKOFF, status);\n+\n+    source.stop();\n+  }\n+\n   ChannelProcessor createGoodChannel() {\n \n     ChannelProcessor channelProcessor = mock(ChannelProcessor.class);",
                "raw_url": "https://github.com/apache/flume/raw/606eabb09997fa939735b5600f526a99895c350c/flume-ng-sources/flume-kafka-source/src/test/java/org/apache/flume/source/kafka/TestKafkaSource.java",
                "sha": "d866c98ed54c4f625a58f41e6d599b689e6f7f7a",
                "status": "modified"
            }
        ],
        "message": "FLUME-3314 Fixed NPE in Kafka source/channel during offset migration (#276)\n\n* FLUME-3314 Fixed NPE in Kafka source/channel during offset migration\r\n\r\nKafka source/channel threw NPE when migrateOffsets() was called\r\non nonexistent topics.\r\nIt has been fixed by adding null check and logging a warning message\r\n(topic not found, skipping offset migration).\r\n\r\nAfter skipping the offset migration, the source/channel works the same way\r\nas the \"non offset migration\" case:\r\n- starts and prints warning messages about the non-existing topic periodically\r\n- can recover if the topic is created later\r\n\r\n* FLUME-3314 Additional null checks.\r\n\r\nReviewers: Ferenc Szabo\r\n\r\n(Peter Turcsanyi via Ferenc Szabo)",
        "parent": "https://github.com/apache/flume/commit/41902ebc998ca31de4ddc0fb89136a2e70b236f9",
        "patched_files": [
            "KafkaChannel.java",
            "KafkaSource.java",
            "pom.java",
            "KafkaSourceEmbeddedKafka.java",
            "kafka-server.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestOffsetsAndMigration.java",
            "TestKafkaSource.java"
        ]
    },
    "flume_67189ca": {
        "bug_id": "flume_67189ca",
        "commit": "https://github.com/apache/flume/commit/67189ca84d24154150fa2ca4194b3b8d79400bda",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/67189ca84d24154150fa2ca4194b3b8d79400bda/flume-ng-core/src/main/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounter.java?ref=67189ca84d24154150fa2ca4194b3b8d79400bda",
                "deletions": 1,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounter.java",
                "patch": "@@ -31,7 +31,7 @@\n       \"source.kafka.empty.count\";\n \n   private static final String[] ATTRIBUTES =\n-      {TIMER_KAFKA_COMMIT, TIMER_KAFKA_EVENT_GET};\n+      {TIMER_KAFKA_COMMIT, TIMER_KAFKA_EVENT_GET, COUNTER_KAFKA_EMPTY};\n \n   public KafkaSourceCounter(String name) {\n     super(name, ATTRIBUTES);",
                "raw_url": "https://github.com/apache/flume/raw/67189ca84d24154150fa2ca4194b3b8d79400bda/flume-ng-core/src/main/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounter.java",
                "sha": "ad0ba2cf10490c23308a20516409d232a428c057",
                "status": "modified"
            },
            {
                "additions": 63,
                "blob_url": "https://github.com/apache/flume/blob/67189ca84d24154150fa2ca4194b3b8d79400bda/flume-ng-core/src/test/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounterTest.java",
                "changes": 63,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/test/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounterTest.java?ref=67189ca84d24154150fa2ca4194b3b8d79400bda",
                "deletions": 0,
                "filename": "flume-ng-core/src/test/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounterTest.java",
                "patch": "@@ -0,0 +1,63 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.flume.instrumentation.kafka;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class KafkaSourceCounterTest {\n+\n+    KafkaSourceCounter counter;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        counter = new KafkaSourceCounter(\"test\");\n+    }\n+\n+    @Test\n+    public void testAddToKafkaEventGetTimer() throws Exception {\n+        Assert.assertEquals(1L, counter.addToKafkaEventGetTimer(1L));\n+    }\n+\n+    @Test\n+    public void testAddToKafkaCommitTimer() throws Exception {\n+        Assert.assertEquals(1L, counter.addToKafkaCommitTimer(1L));\n+    }\n+\n+    @Test\n+    public void testIncrementKafkaEmptyCount() throws Exception {\n+        Assert.assertEquals(1L, counter.incrementKafkaEmptyCount());\n+    }\n+\n+    @Test\n+    public void testGetKafkaCommitTimer() throws Exception {\n+        Assert.assertEquals(0, counter.getKafkaCommitTimer());\n+    }\n+\n+    @Test\n+    public void testGetKafkaEventGetTimer() throws Exception {\n+        Assert.assertEquals(0, counter.getKafkaEventGetTimer());\n+    }\n+\n+    @Test\n+    public void testGetKafkaEmptyCount() throws Exception {\n+        Assert.assertEquals(0, counter.getKafkaEmptyCount());\n+    }\n+\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/flume/raw/67189ca84d24154150fa2ca4194b3b8d79400bda/flume-ng-core/src/test/java/org/apache/flume/instrumentation/kafka/KafkaSourceCounterTest.java",
                "sha": "4a712656dcfa58bd348a31d79e7152df1b4eafbc",
                "status": "added"
            }
        ],
        "message": "FLUME-2672. NPE in KafkaSourceCounter\n\n(Rigo MacTaggart via Johny Rufus)",
        "parent": "https://github.com/apache/flume/commit/318da208844d02ed7554724ae526cefe94dd894c",
        "patched_files": [
            "KafkaSourceCounter.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "KafkaSourceCounterTest.java"
        ]
    },
    "flume_6d43583": {
        "bug_id": "flume_6d43583",
        "commit": "https://github.com/apache/flume/commit/6d435838c9285021dcd2d57fa0b906d5014d5232",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/conf/FlumeSpecGen.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/java/com/cloudera/flume/conf/FlumeSpecGen.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 0,
                "filename": "src/java/com/cloudera/flume/conf/FlumeSpecGen.java",
                "patch": "@@ -100,6 +100,9 @@ public static String genEventSource(CommonTree t) throws FlumeSpecException {\n \n   @SuppressWarnings(\"unchecked\")\n   public static String genEventSink(CommonTree t) throws FlumeSpecException {\n+    if (t == null) {\n+      throw new FlumeSpecException(\"Tree is null\");\n+    }\n     ASTNODE type = ASTNODE.valueOf(t.getText()); // convert to enum\n     switch (type) {\n     case SINK:",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/conf/FlumeSpecGen.java",
                "sha": "27987b5f2557338ec5c0ac942bd13343c4a61a69",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/master/TranslatingConfigurationManager.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/java/com/cloudera/flume/master/TranslatingConfigurationManager.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 2,
                "filename": "src/java/com/cloudera/flume/master/TranslatingConfigurationManager.java",
                "patch": "@@ -150,7 +150,7 @@ synchronized public ReportEvent getReport() {\n             + \"<th>Node</th><th>Version</th><th>Source</th><th>Sink</th>\"\n             + \"<th>Translated Version</th><th>Translated Source</th><th>Translated Sink</th>\"\n             + \"</tr>\");\n-    \n+\n     Map<String, FlumeConfigData> cfgs = new TreeMap<String, FlumeConfigData>(\n         parentMan.getAllConfigs());\n     Map<String, FlumeConfigData> xcfgs = new TreeMap<String, FlumeConfigData>(\n@@ -348,7 +348,7 @@ synchronized public void setBulkConfig(Map<String, FlumeConfigData> configs)\n       }\n     }\n     parentMan.setBulkConfig(updates);\n-    selfMan.setBulkConfig(selfupdates);\n+    updateAll();\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/master/TranslatingConfigurationManager.java",
                "sha": "16d05c9992c269489d1521553deeb3fab3adbd64",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/master/failover/FailoverConfigurationManager.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/java/com/cloudera/flume/master/failover/FailoverConfigurationManager.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 1,
                "filename": "src/java/com/cloudera/flume/master/failover/FailoverConfigurationManager.java",
                "patch": "@@ -179,6 +179,12 @@ static CommonTree substDFOChains(String sink, List<String> collectors)\n       CommonTree dfoFailChain = buildFailChainAST(\n           \"{ lazyOpen => { stubbornAppend => logicalSink(\\\"%s\\\") } }  \",\n           collectors);\n+\n+      // Check if dfo is null\n+      if (dfoFailChain == null) {\n+        dfoFailChain = FlumeBuilder.parseSink(\"fail(\\\"no collectors\\\")\");\n+      }\n+\n       String dfo = \"let primary := \" + FlumeSpecGen.genEventSink(dfoFailChain)\n           + \" in \"\n           + \"< primary ? {diskFailover => { insistentOpen =>  primary} } >\";\n@@ -192,7 +198,7 @@ static CommonTree substDFOChains(String sink, List<String> collectors)\n       } else {\n         parent.replaceChildren(idx, idx, newDfoTree);\n       }\n-      // patern match again.\n+      // pattern match again.\n       dfoMatches = dfoPat.match(sinkTree);\n     }\n     return sinkTree;",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/java/com/cloudera/flume/master/failover/FailoverConfigurationManager.java",
                "sha": "7bb923c3369e3b4e3c6ed31daa3b77dee74cd89a",
                "status": "modified"
            },
            {
                "additions": 188,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestFlumeConfigTranslation.java",
                "changes": 188,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/javatest/com/cloudera/flume/master/TestFlumeConfigTranslation.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 0,
                "filename": "src/javatest/com/cloudera/flume/master/TestFlumeConfigTranslation.java",
                "patch": "@@ -0,0 +1,188 @@\n+/**\n+ * Licensed to Cloudera, Inc. under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  Cloudera, Inc. licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.cloudera.flume.master;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+\n+import org.apache.log4j.Level;\n+import org.apache.log4j.Logger;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+import org.junit.runners.Parameterized.Parameters;\n+\n+import com.cloudera.flume.conf.FlumeConfiguration;\n+import com.cloudera.util.FileUtil;\n+\n+/**\n+ * Verify translation of a number of sources/sink combinations\n+ */\n+@RunWith(Parameterized.class)\n+public class TestFlumeConfigTranslation {\n+  public static Logger LOG = Logger.getLogger(TestFlumeConfigTranslation.class);\n+\n+  private FlumeMaster fm;\n+\n+  private File tmpdir = null;\n+  private FlumeConfiguration cfg = FlumeConfiguration\n+      .createTestableConfiguration();\n+  private CmdList cmds;\n+\n+  public TestFlumeConfigTranslation(CmdList cmds) {\n+    this.cmds = cmds;\n+  }\n+\n+  private static class Cmd {\n+    public Cmd(String name, String src, String snk) {\n+      this.name = name;\n+      this.src = src;\n+      this.snk = snk;\n+    }\n+\n+    String name;\n+    String src;\n+    String snk;\n+\n+    public String[] asArray() {\n+      return new String[] { name, src, snk };\n+    }\n+  }\n+\n+  private static class CmdList extends ArrayList<Cmd> {\n+    private static final long serialVersionUID = 1L;\n+  }\n+\n+  @Parameters\n+  public static Collection<Object[]> configs() {\n+    ArrayList<Object[]> data = new ArrayList<Object[]>();\n+\n+    CmdList cl;\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"node\", \"null\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentSink(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentDFOSink(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentE2ESink(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentBESink(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentDFOChain(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentE2EChain(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"agentBEChain(\\\"localhost\\\",73737)\"));\n+    cl.add(new Cmd(\"B\", \"collectorSource(73737)\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"autoDFOChain\"));\n+    cl.add(new Cmd(\"B\", \"autoCollectorSource\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"autoE2EChain\"));\n+    cl.add(new Cmd(\"B\", \"autoCollectorSource\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    cl = new CmdList();\n+    cl.add(new Cmd(\"A\", \"null\", \"autoBEChain\"));\n+    cl.add(new Cmd(\"B\", \"autoCollectorSource\", \"null\"));\n+    data.add(new Object[] { cl });\n+\n+    return data;\n+  }\n+\n+  /**\n+   * Use the same master for all these tests - faster\n+   * \n+   * @throws IOException\n+   */\n+  @Before\n+  public void setConfiguration() throws IOException {\n+    // Set directory of webapps to build-specific dir\n+    cfg.set(FlumeConfiguration.WEBAPPS_PATH, \"build/webapps\");\n+    // Give ZK a temporary directory, otherwise it's possible we'll reload some\n+    // old configs\n+    tmpdir = FileUtil.mktempdir();\n+    cfg.set(FlumeConfiguration.MASTER_ZK_LOGDIR, tmpdir.getAbsolutePath());\n+\n+    Logger.getRootLogger().setLevel(Level.DEBUG);\n+\n+    // would rather do this once for the whole test but unmapAll is unreliable\n+    // in some cases after the test failed unmapAll would fail and cause all\n+    // subsequent tests to fail\n+    fm = new FlumeMaster(cfg, false);\n+    fm.serve();\n+  }\n+\n+  @After\n+  public void deleteConfigDir() throws IOException {\n+    fm.shutdown();\n+\n+    if (tmpdir != null) {\n+      FileUtil.rmr(tmpdir);\n+      tmpdir = null;\n+    }\n+  }\n+\n+  /**\n+   * Verify translation.\n+   */\n+  @Test\n+  public void testTranslateConfigString() throws Exception {\n+    Execable cfg = ConfigCommand.buildExecable();\n+\n+    for (Cmd cmd : cmds) {\n+      cfg.exec(cmd.asArray());\n+    }\n+\n+    assertEquals(cmds.size(), fm.getSpecMan().getAllConfigs().size());\n+    assertEquals(cmds.size(), fm.getSpecMan().getTranslatedConfigs().size());\n+  }\n+}",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestFlumeConfigTranslation.java",
                "sha": "edebd234a44a74da94bf79d460e001b193052151",
                "status": "added"
            },
            {
                "additions": 342,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesDFO.java",
                "changes": 342,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesDFO.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 0,
                "filename": "src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesDFO.java",
                "patch": "@@ -0,0 +1,342 @@\n+/**\n+ * Licensed to Cloudera, Inc. under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  Cloudera, Inc. licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.cloudera.flume.master;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import org.apache.log4j.Logger;\n+import org.apache.thrift.transport.TTransportException;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.cloudera.flume.conf.FlumeConfiguration;\n+import com.cloudera.flume.conf.FlumeSpecException;\n+import com.cloudera.flume.conf.thrift.FlumeConfigData;\n+import com.cloudera.flume.master.StatusManager.NodeState;\n+import com.cloudera.flume.master.availability.ConsistentHashFailoverChainManager;\n+import com.cloudera.flume.master.availability.FailoverChainManager;\n+import com.cloudera.flume.master.failover.FailoverConfigurationManager;\n+import com.cloudera.flume.master.logical.LogicalConfigurationManager;\n+import com.cloudera.util.Clock;\n+import com.cloudera.util.FileUtil;\n+import com.cloudera.util.NetUtils;\n+\n+/**\n+ * This tests all kinds of auto update scenarios where a user or new machine\n+ * update causes an incremental update to some machine configurations. This\n+ * specifically tests the DFO.\n+ * \n+ */\n+public class TestMasterAutoUpdatesDFO {\n+  final public static Logger LOG = Logger\n+      .getLogger(TestMasterAutoUpdatesDFO.class);\n+\n+  // /////////\n+\n+  protected FlumeMaster flumeMaster = null;\n+  private File tmpdir = null;\n+  protected ConfigManager cfgMan;\n+\n+  /**\n+   * This creates an environment where we have configurations set and then\n+   * serving starts. This simulates a zk configstore load and then the serve\n+   * call being run.\n+   * \n+   * Ideally we'd create a SetupTranslatingZKMasterTestEnv, but there is an\n+   * issue when trying to start/shutdown and start a new master in the same\n+   * process/jvm.\n+   * */\n+  @Before\n+  public void setCfgAndStartMaster() throws TTransportException, IOException,\n+      FlumeSpecException {\n+    // Give ZK a temporary directory, otherwise it's possible we'll reload some\n+    // old configs\n+    tmpdir = FileUtil.mktempdir();\n+    FlumeConfiguration.createTestableConfiguration();\n+    FlumeConfiguration.get().set(FlumeConfiguration.MASTER_STORE, \"memory\");\n+\n+    buildMaster();\n+\n+    // Instead of loading from a ZK Store, we just see the config in the \"deep\"\n+    // config manager. Any translations will not occur.\n+    ConfigurationManager loaded = cfgMan;\n+    loaded.setConfig(\"node1\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node2\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node3\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node4\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"agent\", \"flow\", \"null\", \"autoDFOChain\");\n+\n+    // this is the outer configman, should have no translation.\n+    ConfigurationManager cfgman1 = flumeMaster.getSpecMan();\n+    Map<String, FlumeConfigData> cfgs1 = cfgman1.getTranslatedConfigs();\n+    assertEquals(0, cfgs1.size()); // no translations happened\n+\n+    // start the master (which should trigger an update and translation\n+    flumeMaster.serve();\n+  }\n+\n+  /**\n+   * Build but do not start a master.\n+   * \n+   * This exposes a hook to the deepest cfgMan which would ideally be a saved ZK\n+   * backed version being reloaded from a restarted master.\n+   */\n+  void buildMaster() throws IOException {\n+    cfgMan = new ConfigManager(FlumeMaster.createConfigStore(FlumeConfiguration\n+        .get()));\n+    FailoverChainManager fcMan = new ConsistentHashFailoverChainManager(3);\n+    ConfigurationManager self2 = new ConfigManager();\n+    ConfigurationManager failover = new FailoverConfigurationManager(cfgMan,\n+        self2, fcMan);\n+\n+    StatusManager statman = new StatusManager();\n+    ConfigurationManager self = new ConfigManager();\n+    ConfigurationManager logical = new LogicalConfigurationManager(failover,\n+        self, statman);\n+    flumeMaster = new FlumeMaster(new CommandManager(), logical, statman,\n+        new MasterAckManager(), FlumeConfiguration.get());\n+\n+  }\n+\n+  @After\n+  public void stopMaster() throws IOException {\n+    if (flumeMaster != null) {\n+      flumeMaster.shutdown();\n+      flumeMaster = null;\n+    }\n+\n+    if (tmpdir != null) {\n+      FileUtil.rmr(tmpdir);\n+      tmpdir = null;\n+    }\n+  }\n+\n+  // /////// end stuff that should be refactored\n+\n+  /**\n+   * Ideally, start a master (calling serve), set a configuration, kill the\n+   * master, and then reload it. We make sure that there was an attempt to\n+   * translate the configuration. This simulates a ZK-backed master going down\n+   * and coming back up with the previously specfied configuration.\n+   */\n+  @Test\n+  public void testReloadRefresh() throws IOException, InterruptedException,\n+      FlumeSpecException {\n+\n+    ConfigurationManager cfgman2 = flumeMaster.getSpecMan();\n+    Map<String, FlumeConfigData> cfgs2 = cfgman2.getTranslatedConfigs();\n+    assertEquals(5, cfgs2.size());\n+  }\n+\n+  /**\n+   * The configuration here has no live nodes. It translates the failchains but\n+   * fail on logicalSink translations. This is the base case for most of the\n+   * subsequent tests.\n+   */\n+  @Test\n+  public void testMasterNoNode() {\n+    Map<String, FlumeConfigData> xcfgs = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd = xcfgs.get(\"agent\");\n+    String ans1 = \"let primary := < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(agentFcd.sinkConfig, ans1);\n+  }\n+\n+  /**\n+   * A user triggered reconfigure of a collector to a non collector should cause\n+   * a configuration that depends on the removed configuration to be removed.\n+   */\n+  @Test\n+  public void testCollectorReconfigAutoUpdate() throws IOException,\n+      FlumeSpecException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().setConfig(\"node2\", \"flow\", \"null\", \"null\");\n+\n+    // Look, no explicit updates!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"let primary := < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node3\\\\\\\" )\\\" ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+  }\n+\n+  /**\n+   * A user triggered decommission should cause a configuration that depends on\n+   * the removed configuration to be removed.\n+   */\n+  @Test\n+  public void testDecommission() throws IOException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().removeLogicalNode(\"node2\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    // This is wrong -- there should be a different logicalSink replacing node2\n+    String ans2 = \"let primary := < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node3\\\\\\\" )\\\" ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+  }\n+\n+  /**\n+   * Add a new collectorSource node, and make sure the agent's configuration is\n+   * updated.\n+   */\n+  @Test\n+  public void testMasterNodeNewCollectorAutoUpdate() throws IOException,\n+      FlumeSpecException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().setConfig(\"nodeNew\", \"flow\",\n+        \"autoCollectorSource\", \"null\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"let primary := < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"nodeNew\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+\n+  }\n+\n+  /**\n+   * Test that an autoUpdate happens when a physical node information\n+   * (heartbeat) shows up and allows for a logicalSink/Source translation\n+   * \n+   * This condition is assumed in the following test --\n+   * testMasterNodeUnmapAutoUpdate()\n+   */\n+\n+  @Test\n+  public void testMasterNodeAutoUpdate() throws IOException, FlumeSpecException {\n+\n+    // First, heart beats\n+    String host = NetUtils.localhost();\n+    long ver = Clock.unixTime();\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node1\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node2\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node3\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node4\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"agent\",\n+        NodeState.IDLE, ver);\n+\n+    // Next spawn so that all are mapped onto a node and now gets a physical\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node1\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node2\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node3\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node4\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"agent\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    // This is wrong -- there should be a different logicalSink replacing node2\n+    String ans2 = \"let primary := < { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35856 ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35854 ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35853 ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(ans2, agentFcd2.sinkConfig);\n+  }\n+\n+  /**\n+   * This heartbeats to provide physical node info and allows the translators to\n+   * build fully physical configurations.\n+   */\n+  @Test\n+  public void testMasterNodeUnmapAutoUpdate() throws IOException {\n+\n+    // First, heart beats\n+    String host = NetUtils.localhost();\n+    long ver = Clock.unixTime();\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node1\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node2\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node3\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node4\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"agent\",\n+        NodeState.IDLE, ver);\n+\n+    // First, spawn so that all are mapped onto a node and now gets a physical\n+    // node info\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node1\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node2\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node3\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node4\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"agent\");\n+\n+    // Now do a user initiated unmap should make the config go back to a failing\n+    // version with logicalSinks\n+    flumeMaster.getSpecMan().unmapAllLogicalNodes();\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"let primary := < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } > > in\"\n+        + \" < primary ? { diskFailover => { insistentOpen => primary } } >\";\n+    assertEquals(ans2, agentFcd2.sinkConfig);\n+\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesDFO.java",
                "sha": "13a22b9e244c3c6a5c3780299c9db0ac41d6710a",
                "status": "added"
            },
            {
                "additions": 337,
                "blob_url": "https://github.com/apache/flume/blob/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesE2E.java",
                "changes": 337,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesE2E.java?ref=6d435838c9285021dcd2d57fa0b906d5014d5232",
                "deletions": 0,
                "filename": "src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesE2E.java",
                "patch": "@@ -0,0 +1,337 @@\n+/**\n+ * Licensed to Cloudera, Inc. under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  Cloudera, Inc. licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.cloudera.flume.master;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import org.apache.log4j.Logger;\n+import org.apache.thrift.transport.TTransportException;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.cloudera.flume.conf.FlumeConfiguration;\n+import com.cloudera.flume.conf.FlumeSpecException;\n+import com.cloudera.flume.conf.thrift.FlumeConfigData;\n+import com.cloudera.flume.master.StatusManager.NodeState;\n+import com.cloudera.flume.master.availability.ConsistentHashFailoverChainManager;\n+import com.cloudera.flume.master.availability.FailoverChainManager;\n+import com.cloudera.flume.master.failover.FailoverConfigurationManager;\n+import com.cloudera.flume.master.logical.LogicalConfigurationManager;\n+import com.cloudera.util.Clock;\n+import com.cloudera.util.FileUtil;\n+import com.cloudera.util.NetUtils;\n+\n+/**\n+ * This tests all kinds of auto update scenarios where a user or new machine\n+ * update causes an incremental update to some machine configurations. This\n+ * specifically tests the DFO.\n+ * \n+ */\n+public class TestMasterAutoUpdatesE2E {\n+  final public static Logger LOG = Logger\n+      .getLogger(TestMasterAutoUpdatesE2E.class);\n+\n+  // /////////\n+\n+  protected FlumeMaster flumeMaster = null;\n+  private File tmpdir = null;\n+  protected ConfigManager cfgMan;\n+\n+  /**\n+   * This creates an environment where we have configurations set and then\n+   * serving starts. This simulates a zk configstore load and then the serve\n+   * call being run.\n+   * \n+   * Ideally we'd create a SetupTranslatingZKMasterTestEnv, but there is an\n+   * issue when trying to start/shutdown and start a new master in the same\n+   * process/jvm.\n+   * */\n+  @Before\n+  public void setCfgAndStartMaster() throws TTransportException, IOException,\n+      FlumeSpecException {\n+    // Give ZK a temporary directory, otherwise it's possible we'll reload some\n+    // old configs\n+    tmpdir = FileUtil.mktempdir();\n+    FlumeConfiguration.createTestableConfiguration();\n+    FlumeConfiguration.get().set(FlumeConfiguration.MASTER_STORE, \"memory\");\n+\n+    buildMaster();\n+\n+    // Instead of loading from a ZK Store, we just see the config in the \"deep\"\n+    // config manager. Any translations will not occur.\n+    ConfigurationManager loaded = cfgMan;\n+    loaded.setConfig(\"node1\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node2\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node3\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"node4\", \"flow\", \"autoCollectorSource\", \"null\");\n+    loaded.setConfig(\"agent\", \"flow\", \"null\", \"autoE2EChain\");\n+\n+    // this is the outer configman, should have no translation.\n+    ConfigurationManager cfgman1 = flumeMaster.getSpecMan();\n+    Map<String, FlumeConfigData> cfgs1 = cfgman1.getTranslatedConfigs();\n+    assertEquals(0, cfgs1.size()); // no translations happened\n+\n+    // start the master (which should trigger an update and translation\n+    flumeMaster.serve();\n+  }\n+\n+  /**\n+   * Build but do not start a master.\n+   * \n+   * This exposes a hook to the deepest cfgMan which would ideally be a saved ZK\n+   * backed version being reloaded from a restarted master.\n+   */\n+  void buildMaster() throws IOException {\n+    cfgMan = new ConfigManager(FlumeMaster.createConfigStore(FlumeConfiguration\n+        .get()));\n+    FailoverChainManager fcMan = new ConsistentHashFailoverChainManager(3);\n+    ConfigurationManager self2 = new ConfigManager();\n+    ConfigurationManager failover = new FailoverConfigurationManager(cfgMan,\n+        self2, fcMan);\n+\n+    StatusManager statman = new StatusManager();\n+    ConfigurationManager self = new ConfigManager();\n+    ConfigurationManager logical = new LogicalConfigurationManager(failover,\n+        self, statman);\n+    flumeMaster = new FlumeMaster(new CommandManager(), logical, statman,\n+        new MasterAckManager(), FlumeConfiguration.get());\n+\n+  }\n+\n+  @After\n+  public void stopMaster() throws IOException {\n+    if (flumeMaster != null) {\n+      flumeMaster.shutdown();\n+      flumeMaster = null;\n+    }\n+\n+    if (tmpdir != null) {\n+      FileUtil.rmr(tmpdir);\n+      tmpdir = null;\n+    }\n+  }\n+\n+  // /////// end stuff that should be refactored\n+\n+  /**\n+   * Ideally, start a master (calling serve), set a configuration, kill the\n+   * master, and then reload it. We make sure that there was an attempt to\n+   * translate the configuration. This simulates a ZK-backed master going down\n+   * and coming back up with the previously specfied configuration.\n+   */\n+  @Test\n+  public void testReloadRefresh() throws IOException, InterruptedException,\n+      FlumeSpecException {\n+\n+    ConfigurationManager cfgman2 = flumeMaster.getSpecMan();\n+    Map<String, FlumeConfigData> cfgs2 = cfgman2.getTranslatedConfigs();\n+    assertEquals(5, cfgs2.size());\n+  }\n+\n+  /**\n+   * The configuration here has no live nodes. It translates the failchains but\n+   * fail on logicalSink translations. This is the base case for most of the\n+   * subsequent tests.\n+   */\n+  @Test\n+  public void testMasterNoNode() {\n+    Map<String, FlumeConfigData> xcfgs = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd = xcfgs.get(\"agent\");\n+    String ans1 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } > > }\";\n+    assertEquals(agentFcd.sinkConfig, ans1);\n+  }\n+\n+  /**\n+   * A user triggered reconfigure of a collector to a non collector should cause\n+   * a configuration that depends on the removed configuration to be removed.\n+   */\n+  @Test\n+  public void testCollectorReconfigAutoUpdate() throws IOException,\n+      FlumeSpecException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().setConfig(\"node2\", \"flow\", \"null\", \"null\");\n+\n+    // Look, no explicit updates!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node3\\\\\\\" )\\\" ) } } > > }\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+  }\n+\n+  /**\n+   * A user triggered decommission should cause a configuration that depends on\n+   * the removed configuration to be removed.\n+   */\n+  @Test\n+  public void testDecommission() throws IOException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().removeLogicalNode(\"node2\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    // This is wrong -- there should be a different logicalSink replacing node2\n+    String ans2 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node3\\\\\\\" )\\\" ) } } > > }\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+  }\n+\n+  /**\n+   * Add a new collectorSource node, and make sure the agent's configuration is\n+   * updated.\n+   */\n+  @Test\n+  public void testMasterNodeNewCollectorAutoUpdate() throws IOException,\n+      FlumeSpecException {\n+\n+    // a user initiated removal of a node would cause the config to change.\n+    flumeMaster.getSpecMan().setConfig(\"nodeNew\", \"flow\",\n+        \"autoCollectorSource\", \"null\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"nodeNew\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } > > }\";\n+    assertEquals(agentFcd2.sinkConfig, ans2);\n+\n+  }\n+\n+  /**\n+   * Test that an autoUpdate happens when a physical node information\n+   * (heartbeat) shows up and allows for a logicalSink/Source translation\n+   * \n+   * This condition is assumed in the following test --\n+   * testMasterNodeUnmapAutoUpdate()\n+   */\n+\n+  @Test\n+  public void testMasterNodeAutoUpdate() throws IOException, FlumeSpecException {\n+\n+    // First, heart beats\n+    String host = NetUtils.localhost();\n+    long ver = Clock.unixTime();\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node1\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node2\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node3\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node4\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"agent\",\n+        NodeState.IDLE, ver);\n+\n+    // Next spawn so that all are mapped onto a node and now gets a physical\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node1\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node2\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node3\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"node4\");\n+    flumeMaster.getSpecMan().addLogicalNode(host, \"agent\");\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    // This is wrong -- there should be a different logicalSink replacing node2\n+    String ans2 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35856 ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35854 ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => rpcSink( \\\"\"\n+        + host\n+        + \"\\\", 35853 ) } } > > }\";\n+    assertEquals(ans2, agentFcd2.sinkConfig);\n+  }\n+\n+  /**\n+   * This heartbeats to provide physical node info and allows the translators to\n+   * build fully physical configurations.\n+   */\n+  @Test\n+  public void testMasterNodeUnmapAutoUpdate() throws IOException {\n+\n+    // First, heart beats\n+    String host = NetUtils.localhost();\n+    long ver = Clock.unixTime();\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node1\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node2\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node3\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"node4\",\n+        NodeState.IDLE, ver);\n+    flumeMaster.getStatMan().updateHeartbeatStatus(host, \"physnode\", \"agent\",\n+        NodeState.IDLE, ver);\n+\n+    // First, spawn so that all are mapped onto a node and now gets a physical\n+    // node info\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node1\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node2\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node3\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"node4\");\n+    flumeMaster.getSpecMan().addLogicalNode(\"host\", \"agent\");\n+\n+    // Now do a user initiated unmap should make the config go back to a failing\n+    // version with logicalSinks\n+    flumeMaster.getSpecMan().unmapAllLogicalNodes();\n+\n+    // Look, no explicit update call!\n+\n+    // check new config\n+    Map<String, FlumeConfigData> xcfgs2 = flumeMaster.getSpecMan()\n+        .getTranslatedConfigs();\n+    FlumeConfigData agentFcd2 = xcfgs2.get(\"agent\");\n+    String ans2 = \"{ ackedWriteAhead => < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node4\\\\\\\" )\\\" ) } } ?\"\n+        + \" < { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node2\\\\\\\" )\\\" ) } } ?\"\n+        + \" { lazyOpen => { stubbornAppend => fail( \\\"logicalSink( \\\\\\\"node1\\\\\\\" )\\\" ) } } > > }\";\n+\n+    assertEquals(ans2, agentFcd2.sinkConfig);\n+\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/flume/raw/6d435838c9285021dcd2d57fa0b906d5014d5232/src/javatest/com/cloudera/flume/master/TestMasterAutoUpdatesE2E.java",
                "sha": "5ba04e447bf09e3bbb0d7ddc710d5934c6ce67f4",
                "status": "added"
            }
        ],
        "message": "CDH-1475: Fix flume spec NPE on DFO autogen and no collectors\n- tests for NPE for DFO collector transform\n- parameterized system-style NPE test\n\nFrom: Jonathan Hsieh <jon@cloudera.com>\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/flume/trunk@1155596 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/13fb7b577228ddbdf34350ff35ee20c3de07fa9c",
        "patched_files": [
            "TranslatingConfigurationManager.java",
            "FailoverConfigurationManager.java",
            "FlumeSpecGen.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestMasterAutoUpdatesDFO.java",
            "TestTranslatingConfigurationManager.java",
            "TestFlumeConfigTranslation.java",
            "TestFlumeSpecGen.java",
            "TestMasterAutoUpdatesE2E.java"
        ]
    },
    "flume_9040e49": {
        "bug_id": "flume_9040e49",
        "commit": "https://github.com/apache/flume/commit/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/CheckpointRebuilder.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/CheckpointRebuilder.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/CheckpointRebuilder.java",
                "patch": "@@ -23,6 +23,8 @@\n import com.google.common.collect.Lists;\n import com.google.common.collect.SetMultimap;\n import com.google.common.collect.Sets;\n+\n+import java.io.EOFException;\n import java.io.File;\n import java.io.IOException;\n import java.util.Arrays;\n@@ -62,7 +64,11 @@ public boolean rebuild() throws IOException, Exception {\n     LOG.info(\"Attempting to fast replay the log files.\");\n     List<LogFile.SequentialReader> logReaders = Lists.newArrayList();\n     for (File logFile : logFiles) {\n-      logReaders.add(LogFileFactory.getSequentialReader(logFile, null));\n+      try {\n+        logReaders.add(LogFileFactory.getSequentialReader(logFile, null));\n+      } catch(EOFException e) {\n+        LOG.warn(\"Ignoring \" + logFile + \" due to EOF\", e);\n+      }\n     }\n     long transactionIDSeed = 0;\n     long writeOrderIDSeed = 0;",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/CheckpointRebuilder.java",
                "sha": "6e64003e10d2ea1f032ed4e0b964d47895e52203",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Commit.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Commit.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Commit.java",
                "patch": "@@ -26,6 +26,8 @@\n \n import org.apache.flume.channel.file.proto.ProtosFactory;\n \n+import com.google.common.base.Preconditions;\n+\n /**\n  * Represents a Commit on disk\n  */\n@@ -55,7 +57,8 @@ void writeProtos(OutputStream out) throws IOException {\n   }\n   @Override\n   void readProtos(InputStream in) throws IOException {\n-    ProtosFactory.Commit commit = ProtosFactory.Commit.parseDelimitedFrom(in);\n+    ProtosFactory.Commit commit = Preconditions.checkNotNull(ProtosFactory.\n+        Commit.parseDelimitedFrom(in), \"Commit cannot be null\");\n     type = (short) commit.getType();\n   }\n ",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Commit.java",
                "sha": "366324486b8b56dc3c8822d70f24b40bc2a3869d",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileFactory.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileFactory.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 0,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileFactory.java",
                "patch": "@@ -18,6 +18,7 @@\n  */\n package org.apache.flume.channel.file;\n \n+import java.io.EOFException;\n import java.io.File;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n@@ -148,6 +149,15 @@ private LogFileFactory() {}\n         if(tempMetadataFile.exists()) {\n           tempMetadataFile.delete();\n         }\n+        if(metaDataFile.length() == 0L) {\n+          if(file.length() != 0L) {\n+            String msg = String.format(\"MetaData file %s is empty, but log %s\" +\n+                \" is of size %d\", metaDataFile, file, file.length());\n+            throw new IllegalStateException(msg);\n+          }\n+          throw new EOFException(String.format(\"MetaData file %s is empty\",\n+              metaDataFile));\n+        }\n         return new LogFileV3.SequentialReader(file, encryptionKeyProvider);\n       }\n       logFile = new RandomAccessFile(file, \"r\");",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileFactory.java",
                "sha": "1fe219a2450460e5ebdcb3dac761fbf7cb6124fd",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileV3.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileV3.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 5,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileV3.java",
                "patch": "@@ -100,8 +100,9 @@ protected MetaDataReader(File logFile, int logFileID) throws IOException {\n     ProtosFactory.LogFileMetaData read() throws IOException {\n       FileInputStream inputStream = new FileInputStream(metaDataFile);\n       try {\n-        ProtosFactory.LogFileMetaData metaData =\n-            ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream);\n+        ProtosFactory.LogFileMetaData metaData = Preconditions.checkNotNull(\n+            ProtosFactory.LogFileMetaData.\n+            parseDelimitedFrom(inputStream), \"Metadata cannot be null\");\n         if (metaData.getLogFileID() != logFileID) {\n           throw new IOException(\"The file id of log file: \"\n               + logFile + \" is different from expected \"\n@@ -216,7 +217,8 @@ private void initialize() throws IOException {\n       FileInputStream inputStream = new FileInputStream(metaDataFile);\n       try {\n         ProtosFactory.LogFileMetaData metaData =\n-            ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream);\n+            Preconditions.checkNotNull(ProtosFactory.LogFileMetaData.\n+                parseDelimitedFrom(inputStream), \"MetaData cannot be null\");\n         int version = metaData.getVersion();\n         if(version != getVersion()) {\n           throw new IOException(\"Version is \" + Integer.toHexString(version) +\n@@ -295,8 +297,9 @@ protected TransactionEventRecord doGet(RandomAccessFile fileHandle)\n       File metaDataFile = Serialization.getMetaDataFile(file);\n       FileInputStream inputStream = new FileInputStream(metaDataFile);\n       try {\n-        ProtosFactory.LogFileMetaData metaData =\n-            ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream);\n+        ProtosFactory.LogFileMetaData metaData = Preconditions.checkNotNull(\n+            ProtosFactory.LogFileMetaData.parseDelimitedFrom(inputStream),\n+            \"MetaData cannot be null\");\n         int version = metaData.getVersion();\n         if(version != getVersion()) {\n           throw new IOException(\"Version is \" + Integer.toHexString(version) +",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/LogFileV3.java",
                "sha": "aac7805cf51f699a1d0dc033bc6d3fbf69a5db59",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "patch": "@@ -27,6 +27,7 @@\n \n import org.apache.flume.channel.file.proto.ProtosFactory;\n \n+import com.google.common.base.Preconditions;\n import com.google.common.collect.Maps;\n import com.google.protobuf.ByteString;\n \n@@ -82,7 +83,8 @@ void writeProtos(OutputStream out) throws IOException {\n   }\n   @Override\n   void readProtos(InputStream in) throws IOException {\n-    ProtosFactory.Put put = ProtosFactory.Put.parseDelimitedFrom(in);\n+    ProtosFactory.Put put = Preconditions.checkNotNull(ProtosFactory.\n+        Put.parseDelimitedFrom(in), \"Put cannot be null\");\n     Map<String, String> headers = Maps.newHashMap();\n     ProtosFactory.FlumeEvent protosEvent = put.getEvent();\n     for(ProtosFactory.FlumeEventHeader header : protosEvent.getHeadersList()) {",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Put.java",
                "sha": "4235a79132dea10aaea8a66ca3cdd1425fb670e7",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Rollback.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Rollback.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 2,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Rollback.java",
                "patch": "@@ -26,6 +26,8 @@\n \n import org.apache.flume.channel.file.proto.ProtosFactory;\n \n+import com.google.common.base.Preconditions;\n+\n /**\n  * Represents a Rollback on disk\n  */\n@@ -51,8 +53,8 @@ void writeProtos(OutputStream out) throws IOException {\n   @Override\n   void readProtos(InputStream in) throws IOException {\n     @SuppressWarnings(\"unused\")\n-    ProtosFactory.Rollback rollback =\n-      ProtosFactory.Rollback.parseDelimitedFrom(in);\n+    ProtosFactory.Rollback rollback = Preconditions.checkNotNull(ProtosFactory.\n+        Rollback.parseDelimitedFrom(in), \"Rollback cannot be null\");\n   }\n   @Override\n   short getRecordType() {",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Rollback.java",
                "sha": "335ad0bd4a94bbf9a2b080cc5424f5a145702268",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Take.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Take.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Take.java",
                "patch": "@@ -26,6 +26,8 @@\n \n import org.apache.flume.channel.file.proto.ProtosFactory;\n \n+import com.google.common.base.Preconditions;\n+\n /**\n  * Represents a Take on disk\n  */\n@@ -70,7 +72,8 @@ void writeProtos(OutputStream out) throws IOException {\n   }\n   @Override\n   void readProtos(InputStream in) throws IOException {\n-    ProtosFactory.Take take = ProtosFactory.Take.parseDelimitedFrom(in);\n+    ProtosFactory.Take take = Preconditions.checkNotNull(ProtosFactory.\n+        Take.parseDelimitedFrom(in), \"Take cannot be null\");\n     fileID = take.getFileID();\n     offset = take.getOffset();\n   }",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Take.java",
                "sha": "143143a546cb3e3e1cb1cc9d9b643ede323e46a6",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/TransactionEventRecord.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/TransactionEventRecord.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 4,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/TransactionEventRecord.java",
                "patch": "@@ -190,17 +190,19 @@ static TransactionEventRecord fromByteArray(byte[] buffer)\n       throws IOException {\n     ByteArrayInputStream in = new ByteArrayInputStream(buffer);\n     try {\n-      ProtosFactory.TransactionEventHeader header =\n-          ProtosFactory.TransactionEventHeader.parseDelimitedFrom(in);\n+      ProtosFactory.TransactionEventHeader header = Preconditions.\n+          checkNotNull(ProtosFactory.TransactionEventHeader.\n+              parseDelimitedFrom(in), \"Header cannot be null\");\n       short type = (short)header.getType();\n       long transactionID = header.getTransactionID();\n       long writeOrderID = header.getWriteOrderID();\n       TransactionEventRecord transactionEvent =\n           newRecordForType(type, transactionID, writeOrderID);\n       transactionEvent.readProtos(in);\n       @SuppressWarnings(\"unused\")\n-      ProtosFactory.TransactionEventFooter footer =\n-          ProtosFactory.TransactionEventFooter.parseDelimitedFrom(in);\n+      ProtosFactory.TransactionEventFooter footer = Preconditions.checkNotNull(\n+          ProtosFactory.TransactionEventFooter.\n+          parseDelimitedFrom(in), \"Footer cannot be null\");\n       return transactionEvent;\n     } finally {\n       try {",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/TransactionEventRecord.java",
                "sha": "073042f5426ba7a4edb1491e53fda0b62713a0e2",
                "status": "modified"
            },
            {
                "additions": 99,
                "blob_url": "https://github.com/apache/flume/blob/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestLog.java",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestLog.java?ref=9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443",
                "deletions": 0,
                "filename": "flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestLog.java",
                "patch": "@@ -337,6 +337,105 @@ public void testGetLogs() throws IOException {\n     LogUtils.sort(expected);\n     Assert.assertEquals(expected, actual);\n   }\n+  @Test\n+  public void testReplayFailsWithAllEmptyLogMetaDataNormalReplay()\n+      throws IOException, InterruptedException {\n+    doTestReplayFailsWithAllEmptyLogMetaData(false);\n+  }\n+  @Test\n+  public void testReplayFailsWithAllEmptyLogMetaDataFastReplay()\n+      throws IOException, InterruptedException {\n+    doTestReplayFailsWithAllEmptyLogMetaData(true);\n+  }\n+  public void doTestReplayFailsWithAllEmptyLogMetaData(boolean useFastReplay)\n+      throws IOException, InterruptedException {\n+    // setup log with correct fast replay parameter\n+    log.close();\n+    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(\n+        MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(\n+            checkpointDir).setLogDirs(dataDirs)\n+            .setChannelName(\"testlog\").setUseFastReplay(useFastReplay).build();\n+    log.replay();\n+    FlumeEvent eventIn = TestUtils.newPersistableEvent();\n+    long transactionID = ++this.transactionID;\n+    log.put(transactionID, eventIn);\n+    log.commitPut(transactionID);\n+    log.close();\n+    if(useFastReplay) {\n+      FileUtils.deleteQuietly(checkpointDir);\n+      Assert.assertTrue(checkpointDir.mkdir());\n+    }\n+    List<File> logFiles = Lists.newArrayList();\n+    for (int i = 0; i < dataDirs.length; i++) {\n+      logFiles.addAll(LogUtils.getLogs(dataDirs[i]));\n+    }\n+    Assert.assertTrue(logFiles.size() > 0);\n+    for(File logFile : logFiles) {\n+      File logFileMeta = Serialization.getMetaDataFile(logFile);\n+      Assert.assertTrue(logFileMeta.delete());\n+      Assert.assertTrue(logFileMeta.createNewFile());\n+    }\n+    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(\n+        MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(\n+            checkpointDir).setLogDirs(dataDirs)\n+            .setChannelName(\"testlog\").setUseFastReplay(useFastReplay).build();\n+    try {\n+      log.replay();\n+      Assert.fail();\n+    } catch(IllegalStateException expected) {\n+      String msg = expected.getMessage();\n+      Assert.assertNotNull(msg);\n+      Assert.assertTrue(msg, msg.contains(\".meta is empty, but log\"));\n+    }\n+  }\n+  @Test\n+  public void testReplaySucceedsWithUnusedEmptyLogMetaDataNormalReplay()\n+      throws IOException, InterruptedException {\n+    FlumeEvent eventIn = TestUtils.newPersistableEvent();\n+    long transactionID = ++this.transactionID;\n+    FlumeEventPointer eventPointer = log.put(transactionID, eventIn);\n+    log.commitPut(transactionID); // this is not required since\n+    log.close();\n+    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(\n+        MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(\n+            checkpointDir).setLogDirs(dataDirs)\n+            .setChannelName(\"testlog\").build();\n+    doTestReplaySucceedsWithUnusedEmptyLogMetaData(eventIn, eventPointer);\n+  }\n+  @Test\n+  public void testReplaySucceedsWithUnusedEmptyLogMetaDataFastReplay()\n+      throws IOException, InterruptedException {\n+    FlumeEvent eventIn = TestUtils.newPersistableEvent();\n+    long transactionID = ++this.transactionID;\n+    FlumeEventPointer eventPointer = log.put(transactionID, eventIn);\n+    log.commitPut(transactionID); // this is not required since\n+    log.close();\n+    FileUtils.deleteDirectory(checkpointDir);\n+    Assert.assertTrue(checkpointDir.mkdir());\n+    log = new Log.Builder().setCheckpointInterval(1L).setMaxFileSize(\n+        MAX_FILE_SIZE).setQueueSize(CAPACITY).setCheckpointDir(\n+            checkpointDir).setLogDirs(dataDirs)\n+            .setChannelName(\"testlog\").setUseFastReplay(true).build();\n+    doTestReplaySucceedsWithUnusedEmptyLogMetaData(eventIn, eventPointer);\n+  }\n+  public void doTestReplaySucceedsWithUnusedEmptyLogMetaData(FlumeEvent eventIn,\n+      FlumeEventPointer eventPointer) throws IOException,\n+      InterruptedException {\n+    for (int i = 0; i < dataDirs.length; i++) {\n+      for(File logFile : LogUtils.getLogs(dataDirs[i])) {\n+        if(logFile.length() == 0L) {\n+          File logFileMeta = Serialization.getMetaDataFile(logFile);\n+          Assert.assertTrue(logFileMeta.delete());\n+          Assert.assertTrue(logFileMeta.createNewFile());\n+        }\n+      }\n+    }\n+    log.replay();\n+    FlumeEvent eventOut = log.get(eventPointer);\n+    Assert.assertNotNull(eventOut);\n+    Assert.assertEquals(eventIn.getHeaders(), eventOut.getHeaders());\n+    Assert.assertArrayEquals(eventIn.getBody(), eventOut.getBody());\n+  }\n   private void takeAndVerify(FlumeEventPointer eventPointerIn,\n       FlumeEvent eventIn) throws IOException, InterruptedException {\n     FlumeEventQueue queue = log.getFlumeEventQueue();",
                "raw_url": "https://github.com/apache/flume/raw/9040e49c0c95b66f3ff3a0c879d3a6ea0bf11443/flume-ng-channels/flume-file-channel/src/test/java/org/apache/flume/channel/file/TestLog.java",
                "sha": "f9dbba5a0b7beb1cacaa9ef5b664313293d4721e",
                "status": "modified"
            }
        ],
        "message": "FLUME-1761. FileChannel can NPE when log metadata file is empty\n\n(Brock Noland via Hari Shreedharan)",
        "parent": "https://github.com/apache/flume/commit/3369b34320175fc9b1132ef3e1ac8551ae55492a",
        "patched_files": [
            "LogFileV3.java",
            "CheckpointRebuilder.java",
            "Log.java",
            "LogFileFactory.java",
            "Put.java",
            "TransactionEventRecord.java",
            "Take.java",
            "Commit.java",
            "Rollback.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestCheckpointRebuilder.java",
            "TestLog.java"
        ]
    },
    "flume_adc7fee": {
        "bug_id": "flume_adc7fee",
        "commit": "https://github.com/apache/flume/commit/adc7fee32ea3243d9b38714cd56fca81a9dca135",
        "file": [
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/flume/blob/adc7fee32ea3243d9b38714cd56fca81a9dca135/flume-ng-core/src/main/java/org/apache/flume/Context.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-core/src/main/java/org/apache/flume/Context.java?ref=adc7fee32ea3243d9b38714cd56fca81a9dca135",
                "deletions": 0,
                "filename": "flume-ng-core/src/main/java/org/apache/flume/Context.java",
                "patch": "@@ -119,6 +119,14 @@ public Boolean getBoolean(String key, Boolean defaultValue) {\n   }\n   /**\n    * Gets value mapped to key, returning null if unmapped.\n+   * <p>\n+   * Note that this method returns an object as opposed to a\n+   * primitive. The configuration key requested may not be mapped\n+   * to a value and by returning the primitive object wrapper we can\n+   * return null. If the key does not exist the return value of\n+   * this method is assigned directly to a primitive, a\n+   * {@link NullPointerException} will be thrown.\n+   * </p>\n    * @param key to be found\n    * @return value associated with key or null if unmapped\n    */\n@@ -140,6 +148,14 @@ public Integer getInteger(String key, Integer defaultValue) {\n   }\n   /**\n    * Gets value mapped to key, returning null if unmapped.\n+   * <p>\n+   * Note that this method returns an object as opposed to a\n+   * primitive. The configuration key requested may not be mapped\n+   * to a value and by returning the primitive object wrapper we can\n+   * return null. If the key does not exist the return value of\n+   * this method is assigned directly to a primitive, a\n+   * {@link NullPointerException} will be thrown.\n+   * </p>\n    * @param key to be found\n    * @return value associated with key or null if unmapped\n    */\n@@ -161,6 +177,14 @@ public Long getLong(String key, Long defaultValue) {\n   }\n   /**\n    * Gets value mapped to key, returning null if unmapped.\n+   * <p>\n+   * Note that this method returns an object as opposed to a\n+   * primitive. The configuration key requested may not be mapped\n+   * to a value and by returning the primitive object wrapper we can\n+   * return null. If the key does not exist the return value of\n+   * this method is assigned directly to a primitive, a\n+   * {@link NullPointerException} will be thrown.\n+   * </p>\n    * @param key to be found\n    * @return value associated with key or null if unmapped\n    */",
                "raw_url": "https://github.com/apache/flume/raw/adc7fee32ea3243d9b38714cd56fca81a9dca135/flume-ng-core/src/main/java/org/apache/flume/Context.java",
                "sha": "5294e312ca3042bb87c63f82781f623345f21fd8",
                "status": "modified"
            }
        ],
        "message": "FLUME-1018. Context can cause NullPointerException.\n\n(Brock Noland via Arvind Prabhakar)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/flume/trunk@1299708 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/fc6c76799f5dbf17f7e2529231c0cc0134fc3e1a",
        "patched_files": [
            "Context.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestContext.java"
        ]
    },
    "flume_c718dae": {
        "bug_id": "flume_c718dae",
        "commit": "https://github.com/apache/flume/commit/c718dae09d10db640cb9eb59f8abb11bd385a799",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/c718dae09d10db640cb9eb59f8abb11bd385a799/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java?ref=c718dae09d10db640cb9eb59f8abb11bd385a799",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "patch": "@@ -756,8 +756,10 @@ public void onCompletion(RecordMetadata metadata, Exception exception) {\n     }\n     if (log.isDebugEnabled()) {\n       long batchElapsedTime = System.currentTimeMillis() - startTime;\n-      log.debug(\"Acked message_no \" + index + \": \" + metadata.topic() + \"-\" +\n+      if (metadata != null) {\n+        log.debug(\"Acked message_no \" + index + \": \" + metadata.topic() + \"-\" +\n                 metadata.partition() + \"-\" + metadata.offset() + \"-\" + batchElapsedTime);\n+      }\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/flume/raw/c718dae09d10db640cb9eb59f8abb11bd385a799/flume-ng-channels/flume-kafka-channel/src/main/java/org/apache/flume/channel/kafka/KafkaChannel.java",
                "sha": "5bd9be0eebcc26be019e0e3415a0906d9007ab8a",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flume/blob/c718dae09d10db640cb9eb59f8abb11bd385a799/flume-ng-sinks/flume-ng-kafka-sink/src/main/java/org/apache/flume/sink/kafka/KafkaSink.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sinks/flume-ng-kafka-sink/src/main/java/org/apache/flume/sink/kafka/KafkaSink.java?ref=c718dae09d10db640cb9eb59f8abb11bd385a799",
                "deletions": 1,
                "filename": "flume-ng-sinks/flume-ng-kafka-sink/src/main/java/org/apache/flume/sink/kafka/KafkaSink.java",
                "patch": "@@ -453,7 +453,10 @@ public void onCompletion(RecordMetadata metadata, Exception exception) {\n \n     if (logger.isDebugEnabled()) {\n       long eventElapsedTime = System.currentTimeMillis() - startTime;\n-      logger.debug(\"Acked message partition:{} ofset:{}\",  metadata.partition(), metadata.offset());\n+      if (metadata != null) {\n+        logger.debug(\"Acked message partition:{} ofset:{}\", metadata.partition(),\n+                metadata.offset());\n+      }\n       logger.debug(\"Elapsed time for send: {}\", eventElapsedTime);\n     }\n   }",
                "raw_url": "https://github.com/apache/flume/raw/c718dae09d10db640cb9eb59f8abb11bd385a799/flume-ng-sinks/flume-ng-kafka-sink/src/main/java/org/apache/flume/sink/kafka/KafkaSink.java",
                "sha": "68866c36194b58ed6138a50baec26dcf834df57d",
                "status": "modified"
            }
        ],
        "message": "FLUME-3043. Fix NPE in Kafka Sink and Channel\n\nWhen logging level is set to DEBUG, Kafka Sink and Kafka Channel may throw a NullPointerException.\n\nThis patch ensures that `metadata` is not null to avoid the exception.\n\nThis closes #125\n\nReviewers: Denes Arvay, Bessenyei Bal\u00e1zs Don\u00e1t\n\n(loleek via Bessenyei Bal\u00e1zs Don\u00e1t)",
        "parent": "https://github.com/apache/flume/commit/03c8357dfeff9615d1590a5c980eb4cfe035f3be",
        "patched_files": [
            "KafkaSink.java",
            "KafkaChannel.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestKafkaSink.java",
            "TestKafkaChannel.java"
        ]
    },
    "flume_ca04449": {
        "bug_id": "flume_ca04449",
        "commit": "https://github.com/apache/flume/commit/ca04449e395dac56202463dea77e3e387be0ca78",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/ca04449e395dac56202463dea77e3e387be0ca78/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/FileChannel.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/FileChannel.java?ref=ca04449e395dac56202463dea77e3e387be0ca78",
                "deletions": 1,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/FileChannel.java",
                "patch": "@@ -79,7 +79,7 @@\n   private Log log;\n   private boolean shutdownHookAdded;\n   private Thread shutdownHook;\n-  private volatile boolean open;\n+\tprivate volatile boolean open;\n   private Semaphore queueRemaining;\n   private final ThreadLocal<FileBackedTransaction> transactions =\n       new ThreadLocal<FileBackedTransaction>();",
                "raw_url": "https://github.com/apache/flume/raw/ca04449e395dac56202463dea77e3e387be0ca78/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/FileChannel.java",
                "sha": "741f9f4c0b8aa88cf8142ab27e0419df83ada972",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flume/blob/ca04449e395dac56202463dea77e3e387be0ca78/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Log.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Log.java?ref=ca04449e395dac56202463dea77e3e387be0ca78",
                "deletions": 12,
                "filename": "flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Log.java",
                "patch": "@@ -123,8 +123,6 @@\n    */\n   synchronized void replay() throws IOException {\n     Preconditions.checkState(!open, \"Cannot replay after Log as been opened\");\n-    open = true;\n-    boolean error = true;\n     try {\n       /*\n        * First we are going to look through the data directories\n@@ -161,7 +159,7 @@ synchronized void replay() throws IOException {\n        */\n       checkpointA = new Checkpoint(new File(checkpointDir, \"chkpt-A\"),\n           queueSize);\n-      checkpointB = new Checkpoint(new File(checkpointDir, \"chkpt-B\"), \n+      checkpointB = new Checkpoint(new File(checkpointDir, \"chkpt-B\"),\n           queueSize);\n       if (checkpointA.getTimestamp() > checkpointB.getTimestamp()) {\n         try {\n@@ -213,11 +211,9 @@ synchronized void replay() throws IOException {\n        * Now that we have replayed, write the current queue to disk\n        */\n       writeCheckpoint();\n-      error = false;\n-    } finally {\n-      if (error) {\n-        open = false;\n-      }\n+      open = true;\n+    } catch (Exception ex) {\n+      LOGGER.error(\"Failed to initialize Log\", ex);\n     }\n   }\n \n@@ -396,7 +392,7 @@ synchronized void close() {\n         if(reader != null) {\n           reader.close();\n         }\n-      }      \n+      }\n     }\n     try {\n       unlock(checkpointDir);\n@@ -478,7 +474,6 @@ private void roll(int index) throws IOException {\n    */\n   private synchronized void roll(int index, ByteBuffer buffer)\n       throws IOException {\n-    Preconditions.checkState(open, \"Log is closed\");\n     LogFile.Writer oldLogFile = logFiles.get(index);\n     // check to make sure a roll is actually required due to\n     // the possibility of multiple writes waiting on lock\n@@ -510,7 +505,6 @@ private synchronized void roll(int index, ByteBuffer buffer)\n    * @throws IOException if we are unable to write the checkpoint out to disk\n    */\n   private synchronized void writeCheckpoint() throws IOException {\n-    Preconditions.checkState(open, \"Log is closed\");\n     synchronized (queue) {\n       checkpoint.get().write(queue);\n       if (!checkpoint.compareAndSet(checkpointA, checkpointB)) {\n@@ -672,4 +666,4 @@ public void run() {\n       }\n     }\n   }\n-}\n\\ No newline at end of file\n+}",
                "raw_url": "https://github.com/apache/flume/raw/ca04449e395dac56202463dea77e3e387be0ca78/flume-ng-channels/flume-file-channel/src/main/java/org/apache/flume/channel/file/Log.java",
                "sha": "c4e5ea785a72f35e0c003d4f3279c1f95913837d",
                "status": "modified"
            }
        ],
        "message": "FLUME-1205: NPE related to checkpointing when using FileChannel\n\n(Arvind Prabhakar via Brock Noland)\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/flume/trunk@1342462 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/897b33befa1fdee8631dab23877cc04048dca988",
        "patched_files": [
            "FileChannel.java",
            "Log.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestLog.java",
            "TestFileChannel.java"
        ]
    },
    "flume_d06c3c3": {
        "bug_id": "flume_d06c3c3",
        "commit": "https://github.com/apache/flume/commit/d06c3c3a9ce9e053e2803550f98ed214c7b5e85b",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flume/blob/d06c3c3a9ce9e053e2803550f98ed214c7b5e85b/flume-ng-node/src/main/java/org/apache/flume/conf/properties/PropertiesFileConfigurationProvider.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-node/src/main/java/org/apache/flume/conf/properties/PropertiesFileConfigurationProvider.java?ref=d06c3c3a9ce9e053e2803550f98ed214c7b5e85b",
                "deletions": 1,
                "filename": "flume-ng-node/src/main/java/org/apache/flume/conf/properties/PropertiesFileConfigurationProvider.java",
                "patch": "@@ -262,7 +262,12 @@ private void loadSinks(AgentConfiguration agentConf, NodeConfiguration conf)\n     for (ComponentConfiguration comp : agentConf.getSinks()) {\n       Context context = new Context();\n \n-      Sink sink = getSinkFactory().create(comp.getConfiguration().get(\"type\"));\n+      String type = comp.getConfiguration().get(\"type\");\n+      Sink sink = getSinkFactory().create(type);\n+      if(sink == null) {\n+        throw new InstantiationException(\"Can't instantiate sink with type \" + type + \" (it's probably \" +\n+          \"unknown type)\");\n+      }\n \n       for (Entry<String, String> entry : comp.getConfiguration().entrySet()) {\n         context.put(entry.getKey(), entry.getValue());",
                "raw_url": "https://github.com/apache/flume/raw/d06c3c3a9ce9e053e2803550f98ed214c7b5e85b/flume-ng-node/src/main/java/org/apache/flume/conf/properties/PropertiesFileConfigurationProvider.java",
                "sha": "12ea8094c4aabfb5f601d985dd3fd726112f28f5",
                "status": "modified"
            }
        ],
        "message": "FLUME-863: Use of unknown sink type leads to NullPointerException\nadd condition for testing null returned from calling getSinkFactory() and rising exception in case that it's really null.\n\n(Jarek Jarcec Cecho via Prasad Mujumdar)\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/flume/branches/flume-728@1220918 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/b23d35255ab58ff6d6614be641f736ea91fda9c7",
        "patched_files": [
            "PropertiesFileConfigurationProvider.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestPropertiesFileConfigurationProvider.java"
        ]
    },
    "flume_e6ace37": {
        "bug_id": "flume_e6ace37",
        "commit": "https://github.com/apache/flume/commit/e6ace378fbd33cf6c127a1870f488588be532777",
        "file": [
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/flume/blob/e6ace378fbd33cf6c127a1870f488588be532777/src/java/com/cloudera/flume/handlers/hdfs/CustomDfsSink.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/java/com/cloudera/flume/handlers/hdfs/CustomDfsSink.java?ref=e6ace378fbd33cf6c127a1870f488588be532777",
                "deletions": 1,
                "filename": "src/java/com/cloudera/flume/handlers/hdfs/CustomDfsSink.java",
                "patch": "@@ -23,6 +23,7 @@\n import java.util.List;\n import java.util.concurrent.atomic.AtomicLong;\n \n+import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.io.compress.CompressionCodec;\n@@ -87,6 +88,15 @@ public void close() throws IOException {\n     writer = null;\n   }\n \n+  /**\n+   * Hadoop Compression Codecs that use Native libs require\n+   * an instance of a Configuration Object. They require this\n+   * due to some check against knowing weather or not the native libs \n+   * have been loaded. GzipCodec, LzoCodec, LzopCodec are all codecs that\n+   * require Native libs. GZipCodec has a slight exception that if native libs\n+   * are not accessible it will use Pure Java. This results in no errors just\n+   * notices. BZip2Codec is an example codec that doesn't use native libs.\n+   */\n   @Override\n   public void open() throws IOException {\n     FlumeConfiguration conf = FlumeConfiguration.get();\n@@ -100,6 +110,11 @@ public void open() throws IOException {\n           + FlumeConfiguration.COLLECTOR_DFS_COMPRESS_CODEC\n           + \" set to GzipCodec instead\");\n       CompressionCodec gzipC = new GzipCodec();\n+      \n+      //See Below for comments on this\n+      if(gzipC instanceof Configurable){\n+        ((Configurable)gzipC).setConf(conf);\n+      }\n       Compressor gzCmp = gzipC.createCompressor();\n       dstPath = new Path(path + gzipC.getDefaultExtension());\n       hdfs = dstPath.getFileSystem(conf);\n@@ -112,6 +127,7 @@ public void open() throws IOException {\n     String codecName = conf.getCollectorDfsCompressCodec();\n     List<Class<? extends CompressionCodec>> codecs = CompressionCodecFactory\n         .getCodecClasses(FlumeConfiguration.get());\n+    //Wish we could base this on DefaultCodec but appears not all codec's extend DefaultCodec(Lzo)\n     CompressionCodec codec = null;\n     ArrayList<String> codecStrs = new ArrayList<String>();\n     codecStrs.add(\"None\");\n@@ -140,7 +156,11 @@ public void open() throws IOException {\n       LOG.info(\"Creating HDFS file: \" + dstPath.toString());\n       return;\n     }\n-\n+    //Must check instanceof codec as BZip2Codec doesn't inherit Configurable\n+    if(codec instanceof Configurable){\n+      //Must set the configuration for Configurable objects that may or do use native libs\n+      ((Configurable)codec).setConf(conf);\n+    }\n     Compressor cmp = codec.createCompressor();\n     dstPath = new Path(path + codec.getDefaultExtension());\n     hdfs = dstPath.getFileSystem(conf);",
                "raw_url": "https://github.com/apache/flume/raw/e6ace378fbd33cf6c127a1870f488588be532777/src/java/com/cloudera/flume/handlers/hdfs/CustomDfsSink.java",
                "sha": "27bf9151bfd4787a6691d0a2aeb26f7cec97083d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flume/blob/e6ace378fbd33cf6c127a1870f488588be532777/src/javatest/com/cloudera/flume/handlers/hdfs/TestEscapedCustomOutputDfs.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/src/javatest/com/cloudera/flume/handlers/hdfs/TestEscapedCustomOutputDfs.java?ref=e6ace378fbd33cf6c127a1870f488588be532777",
                "deletions": 1,
                "filename": "src/javatest/com/cloudera/flume/handlers/hdfs/TestEscapedCustomOutputDfs.java",
                "patch": "@@ -153,7 +153,9 @@ public void testLog4jOutputFormat() throws IOException, InterruptedException {\n \n   /**\n    * Test to write few log lines, compress using gzip, write to disk, read back\n-   * the compressed file and verify the written lines.\n+   * the compressed file and verify the written lines. This test alone doesn't\n+   * test GZipCodec with its Native Libs. java.library.path must contain the path to the\n+   * hadoop native libs for this to happen.\n    * \n    * @throws IOException\n    * @throws InterruptedException",
                "raw_url": "https://github.com/apache/flume/raw/e6ace378fbd33cf6c127a1870f488588be532777/src/javatest/com/cloudera/flume/handlers/hdfs/TestEscapedCustomOutputDfs.java",
                "sha": "a19385aacec7de4a414f58e282516511200a5b3b",
                "status": "modified"
            }
        ],
        "message": "FLUME-482: Compression producing NullPointerException\n\nFrom: NerdyNick <nerdynick@gmail.com>\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/flume/trunk@1155872 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/flume/commit/6763dddb12c7eb58a5e20ce43c0dc6b82c6acca3",
        "patched_files": [
            "CustomDfsSink.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestEscapedCustomOutputDfs.java"
        ]
    },
    "flume_f32e8cd": {
        "bug_id": "flume_f32e8cd",
        "commit": "https://github.com/apache/flume/commit/f32e8cd4c529b1b334d8adf0282647eac3472294",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/f32e8cd4c529b1b334d8adf0282647eac3472294/flume-ng-configuration/src/main/java/org/apache/flume/conf/source/SourceConfiguration.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-configuration/src/main/java/org/apache/flume/conf/source/SourceConfiguration.java?ref=f32e8cd4c529b1b334d8adf0282647eac3472294",
                "deletions": 0,
                "filename": "flume-ng-configuration/src/main/java/org/apache/flume/conf/source/SourceConfiguration.java",
                "patch": "@@ -40,6 +40,7 @@\n \n   public SourceConfiguration(String componentName) {\n     super(componentName);\n+    channels = new HashSet<String>();\n   }\n \n   public Set<String> getChannels() {",
                "raw_url": "https://github.com/apache/flume/raw/f32e8cd4c529b1b334d8adf0282647eac3472294/flume-ng-configuration/src/main/java/org/apache/flume/conf/source/SourceConfiguration.java",
                "sha": "3312b04922177e5e6c2a910590cf1be468aa4331",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/flume/blob/f32e8cd4c529b1b334d8adf0282647eac3472294/flume-ng-configuration/src/test/java/org/apache/flume/conf/source/TestSourceConfiguration.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-configuration/src/test/java/org/apache/flume/conf/source/TestSourceConfiguration.java?ref=f32e8cd4c529b1b334d8adf0282647eac3472294",
                "deletions": 0,
                "filename": "flume-ng-configuration/src/test/java/org/apache/flume/conf/source/TestSourceConfiguration.java",
                "patch": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.flume.conf.source;\n+\n+import org.apache.flume.Context;\n+import org.apache.flume.conf.ConfigurationException;\n+import org.junit.Test;\n+\n+public class TestSourceConfiguration {\n+\n+  /**\n+   * Test fails without FLUME-1847\n+   */\n+  @Test(expected = ConfigurationException.class)\n+  public void testFLUME1847() throws Exception {\n+    Context context = new Context();\n+    context.put(\"type\", \"something\");\n+    SourceConfiguration sourceConfig = new SourceConfiguration(\"src\");\n+    sourceConfig.configure(context);\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/flume/raw/f32e8cd4c529b1b334d8adf0282647eac3472294/flume-ng-configuration/src/test/java/org/apache/flume/conf/source/TestSourceConfiguration.java",
                "sha": "1d04158115dc7e90ac7549a42b2e91557d19f68f",
                "status": "added"
            }
        ],
        "message": "FLUME-1847. NPE in SourceConfiguration\n\n(Brock Noland via Hari Shreedharan)",
        "parent": "https://github.com/apache/flume/commit/001d4860e16e690d8135f63bf864200c24b04ee8",
        "patched_files": [
            "SourceConfiguration.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestSourceConfiguration.java"
        ]
    },
    "flume_fa3fb3d": {
        "bug_id": "flume_fa3fb3d",
        "commit": "https://github.com/apache/flume/commit/fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flume/blob/fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1/flume-ng-sinks/flume-irc-sink/src/main/java/org/apache/flume/sink/irc/IRCSink.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sinks/flume-irc-sink/src/main/java/org/apache/flume/sink/irc/IRCSink.java?ref=fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1",
                "deletions": 1,
                "filename": "flume-ng-sinks/flume-irc-sink/src/main/java/org/apache/flume/sink/irc/IRCSink.java",
                "patch": "@@ -132,7 +132,7 @@ public void configure(Context context) {\n     user = context.getString(\"user\");\n     name = context.getString(\"name\");\n     chan = context.getString(\"chan\");\n-    splitLines = context.getBoolean(\"splitlines\");\n+    splitLines = context.getBoolean(\"splitlines\", false);\n     splitChars = context.getString(\"splitchars\");\n \n     if (portStr != null) {",
                "raw_url": "https://github.com/apache/flume/raw/fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1/flume-ng-sinks/flume-irc-sink/src/main/java/org/apache/flume/sink/irc/IRCSink.java",
                "sha": "40657b40b37f3b6c9690de9027faf6ff82eee2c2",
                "status": "modified"
            },
            {
                "additions": 159,
                "blob_url": "https://github.com/apache/flume/blob/fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1/flume-ng-sinks/flume-irc-sink/src/test/java/org/apache/flume/sink/irc/TestIRCSink.java",
                "changes": 159,
                "contents_url": "https://api.github.com/repos/apache/flume/contents/flume-ng-sinks/flume-irc-sink/src/test/java/org/apache/flume/sink/irc/TestIRCSink.java?ref=fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1",
                "deletions": 0,
                "filename": "flume-ng-sinks/flume-irc-sink/src/test/java/org/apache/flume/sink/irc/TestIRCSink.java",
                "patch": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.flume.sink.irc;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.flume.*;\n+import org.apache.flume.channel.MemoryChannel;\n+import org.apache.flume.conf.Configurables;\n+import org.apache.flume.event.EventBuilder;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.net.ServerSocket;\n+import java.net.Socket;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.junit.Assert.fail;\n+\n+public class TestIRCSink {\n+\n+  private File eventFile;\n+  int ircServerPort;\n+  DumbIRCServer dumbIRCServer;\n+  @Rule\n+  public TemporaryFolder folder = new TemporaryFolder();\n+\n+  private static int findFreePort() throws IOException {\n+    ServerSocket socket = new ServerSocket(0);\n+    int port = socket.getLocalPort();\n+    socket.close();\n+    return port;\n+  }\n+\n+  @Before\n+  public void setUp() throws IOException {\n+    ircServerPort = findFreePort();\n+    dumbIRCServer = new DumbIRCServer(ircServerPort);\n+    dumbIRCServer.start();\n+    eventFile = folder.newFile(\"eventFile.txt\");\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    dumbIRCServer.shutdownServer();\n+  }\n+\n+  @Test\n+  public void testIRCSinkMissingSplitLineProperty() {\n+    Sink ircSink = new IRCSink();\n+    ircSink.setName(\"IRC Sink - \" + UUID.randomUUID().toString());\n+    Context context = new Context();\n+    context.put(\"hostname\", \"localhost\");\n+    context.put(\"port\", String.valueOf(ircServerPort));\n+    context.put(\"nick\", \"flume\");\n+    context.put(\"password\", \"flume\");\n+    context.put(\"user\", \"flume\");\n+    context.put(\"name\", \"flume-dev\");\n+    context.put(\"chan\", \"flume\");\n+    context.put(\"splitchars\", \"false\");\n+    Configurables.configure(ircSink, context);\n+    Channel memoryChannel = new MemoryChannel();\n+    Configurables.configure(memoryChannel, context);\n+    ircSink.setChannel(memoryChannel);\n+    ircSink.start();\n+    Transaction txn = memoryChannel.getTransaction();\n+    txn.begin();\n+    Event event = EventBuilder.withBody(\"Dummy Event\".getBytes());\n+    memoryChannel.put(event);\n+    txn.commit();\n+    txn.close();\n+    try {\n+      Sink.Status status = ircSink.process();\n+      if (status == Sink.Status.BACKOFF) {\n+        fail(\"Error occured\");\n+      }\n+    } catch (EventDeliveryException eDelExcp) {\n+      // noop\n+    }\n+  }\n+\n+  class DumbIRCServer extends Thread {\n+    int port;\n+    ServerSocket ss;\n+\n+    public DumbIRCServer(int port) {\n+      this.port = port;\n+    }\n+\n+    public void run() {\n+      try {\n+        ss = new ServerSocket(port);\n+        while (true) {\n+          try {\n+            Socket socket = ss.accept();\n+            process(socket);\n+          } catch (Exception ex) {/* noop */ }\n+        }\n+      } catch (IOException e) {\n+        // noop\n+      }\n+    }\n+\n+    public void shutdownServer() throws Exception {\n+      ss.close();\n+    }\n+\n+    /**\n+     * Process the incoming request from IRC client\n+     *\n+     * @param socket  IRC client connection socket\n+     * @throws IOException\n+     */\n+    private void process(Socket socket) throws IOException {\n+      FileOutputStream fileOutputStream = FileUtils.openOutputStream(eventFile);\n+      List<String> input = IOUtils.readLines(socket.getInputStream());\n+      for (String next : input) {\n+        if (isPrivMessage(next)) {\n+          fileOutputStream.write(next.getBytes());\n+          fileOutputStream.write(\"\\n\".getBytes());\n+        }\n+      }\n+      fileOutputStream.close();\n+      socket.close();\n+    }\n+\n+    /**\n+     * Checks if the message is Priv message\n+     *\n+     * @param input command received from IRC client\n+     * @return true, if command received is PrivMessage\n+     */\n+    private boolean isPrivMessage(String input) {\n+      return input.startsWith(\"PRIVMSG\");\n+    }\n+  }\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/flume/raw/fa3fb3deaa1045d0c6ebbd18630fa268f5db7fc1/flume-ng-sinks/flume-irc-sink/src/test/java/org/apache/flume/sink/irc/TestIRCSink.java",
                "sha": "e6c065ee0db5b62844d5eb0cbb16e4adf9856b63",
                "status": "added"
            }
        ],
        "message": "FLUME-1892. Fix NullPointerException in IRC Sink.\n\n(Ashish Paliwal via Hari Shreedharan)",
        "parent": "https://github.com/apache/flume/commit/492cd8d08cab347e02e43805b47435413d16937c",
        "patched_files": [
            "IRCSink.java"
        ],
        "repo": "flume",
        "unit_tests": [
            "TestIRCSink.java"
        ]
    }
}