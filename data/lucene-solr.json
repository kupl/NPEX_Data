{
    "lucene-solr_0051410": {
        "bug_id": "lucene-solr_0051410",
        "commit": "https://github.com/apache/lucene-solr/commit/005141020b10bec772ee0e280938e2a30d629c53",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/005141020b10bec772ee0e280938e2a30d629c53/solr/CHANGES.txt",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=005141020b10bec772ee0e280938e2a30d629c53",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -75,6 +75,12 @@ New Features\n * SOLR-5308: A new 'migrate' collection API to split all documents with a\n   route key into another collection (shalin)\n \n+Bug Fixes\n+----------------------\n+\n+* SOLR-5438: DebugComponent throws NPE when used with grouping.\n+  (Tom\u00e1s Fern\u00e1ndez L\u00f6bbe via shalin)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/005141020b10bec772ee0e280938e2a30d629c53/solr/CHANGES.txt",
                "sha": "a3066eebabc39207d6465da515d4f9fdd2871b10",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java?ref=005141020b10bec772ee0e280938e2a30d629c53",
                "deletions": 12,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "patch": "@@ -19,26 +19,20 @@\n \n import static org.apache.solr.common.params.CommonParams.FQ;\n \n+import org.apache.solr.common.SolrDocumentList;\n+import org.apache.solr.common.params.CommonParams;\n+\n import java.io.IOException;\n import java.net.URL;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.TreeMap;\n+import java.util.*;\n import java.util.concurrent.atomic.AtomicLong;\n \n import org.apache.lucene.search.Query;\n-import org.apache.solr.common.SolrDocumentList;\n-import org.apache.solr.common.params.CommonParams;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.common.util.SimpleOrderedMap;\n import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.search.DocList;\n import org.apache.solr.search.QueryParsing;\n import org.apache.solr.util.SolrPluginUtils;\n \n@@ -87,8 +81,14 @@ public void prepare(ResponseBuilder rb) throws IOException\n   public void process(ResponseBuilder rb) throws IOException\n   {\n     if( rb.isDebug() ) {\n+      DocList results = null;\n+      //some internal grouping requests won't have results value set\n+      if(rb.getResults() != null) {\n+        results = rb.getResults().docList;\n+      }\n+\n       NamedList stdinfo = SolrPluginUtils.doStandardDebug( rb.req,\n-          rb.getQueryString(), rb.getQuery(), rb.getResults().docList, rb.isDebugQuery(), rb.isDebugResults());\n+          rb.getQueryString(), rb.getQuery(), results, rb.isDebugQuery(), rb.isDebugResults());\n       \n       NamedList info = rb.getDebugInfo();\n       if( info == null ) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "sha": "5a35a0356eee4ddc58443b7bd00777bf1f92ee5e",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java?ref=005141020b10bec772ee0e280938e2a30d629c53",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "patch": "@@ -326,10 +326,13 @@ public static void doStandardResultsDebug(\n       IndexSchema schema = searcher.getSchema();\n       boolean explainStruct = req.getParams().getBool(CommonParams.EXPLAIN_STRUCT, false);\n \n-      NamedList<Explanation> explain = getExplanations(query, results, searcher, schema);\n-      dbg.add(\"explain\", explainStruct\n-              ? explanationsToNamedLists(explain)\n-              : explanationsToStrings(explain));\n+      if (results != null) {\n+        NamedList<Explanation> explain = getExplanations(query, results, searcher, schema);\n+        dbg.add(\"explain\", explainStruct\n+            ? explanationsToNamedLists(explain)\n+            : explanationsToStrings(explain));\n+      }\n+\n       String otherQueryS = req.getParams().get(CommonParams.EXPLAIN_OTHER);\n       if (otherQueryS != null && otherQueryS.length() > 0) {\n         DocList otherResults = doSimpleQuery(otherQueryS, req, 0, 10);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "sha": "8e9e405f404d870102bf0f2b4c2ad929d9cd1b25",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java?ref=005141020b10bec772ee0e280938e2a30d629c53",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/TestDistributedGrouping.java",
                "patch": "@@ -261,6 +261,9 @@ public void doTest() throws Exception {\n \n     // Can't validate the response, but can check if no errors occur.\n     simpleQuery(\"q\", \"*:*\", \"rows\", 100, \"fl\", \"id,\" + i1, \"group\", \"true\", \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\", \"group.limit\", 10, \"sort\", i1 + \" asc, id asc\", CommonParams.TIME_ALLOWED, 1);\n+    \n+    //Debug\n+    simpleQuery(\"q\", \"*:*\", \"rows\", 10, \"fl\", \"id,\" + i1, \"group\", \"true\", \"group.field\", i1, \"debug\", \"true\");\n   }\n \n   private void simpleQuery(Object... queryParams) throws SolrServerException {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java",
                "sha": "3eccde1760ff9b870260c790bbc751a5a0fedc0e",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/test/org/apache/solr/handler/component/DebugComponentTest.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DebugComponentTest.java?ref=005141020b10bec772ee0e280938e2a30d629c53",
                "deletions": 4,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DebugComponentTest.java",
                "patch": "@@ -40,9 +40,9 @@\n   @BeforeClass\n   public static void beforeClass() throws Exception {\n     initCore(\"solrconfig.xml\", \"schema.xml\");\n-    assertU(adoc(\"id\", \"1\", \"title\", \"this is a title.\"));\n-    assertU(adoc(\"id\", \"2\", \"title\", \"this is another title.\"));\n-    assertU(adoc(\"id\", \"3\", \"title\", \"Mary had a little lamb.\"));\n+    assertU(adoc(\"id\", \"1\", \"title\", \"this is a title.\", \"inStock_b1\", \"true\"));\n+    assertU(adoc(\"id\", \"2\", \"title\", \"this is another title.\", \"inStock_b1\", \"true\"));\n+    assertU(adoc(\"id\", \"3\", \"title\", \"Mary had a little lamb.\", \"inStock_b1\", \"false\"));\n     assertU(commit());\n \n   }\n@@ -147,7 +147,15 @@ public void testPerItemInterface() throws Exception {\n \n             \"count(//lst[@name='timing']/*)=0\"\n     );\n-\n+    \n+    //Grouping\n+    assertQ(req(\"q\", \"*:*\", \"debug\", CommonParams.RESULTS,\n+        \"group\", CommonParams.TRUE,\n+        \"group.field\", \"inStock_b1\",\n+        \"debug\", CommonParams.TRUE), \n+        \"//str[@name='rawquerystring']='*:*'\",\n+        \"count(//lst[@name='explain']/*)=2\"\n+    );\n   }\n   \n   @Test",
                "raw_url": "https://github.com/apache/lucene-solr/raw/005141020b10bec772ee0e280938e2a30d629c53/solr/core/src/test/org/apache/solr/handler/component/DebugComponentTest.java",
                "sha": "521cd05707c7006e3d911961e930afeca3a437af",
                "status": "modified"
            }
        ],
        "message": "SOLR-5438: DebugComponent throws NPE when used with grouping\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1541849 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/5d2d0e70f37d7bd83477046065b3e40dcb883e43",
        "repo": "lucene-solr",
        "unit_tests": [
            "DebugComponentTest.java",
            "SolrPluginUtilsTest.java"
        ]
    },
    "lucene-solr_07a615f": {
        "bug_id": "lucene-solr_07a615f",
        "commit": "https://github.com/apache/lucene-solr/commit/07a615fd6552132fe0787a3cbb51918fb7e1d051",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=07a615fd6552132fe0787a3cbb51918fb7e1d051",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -227,6 +227,9 @@ Bug Fixes\n * SOLR-7705: CoreAdminHandler Unload no longer handles null core name and throws NPE\n   instead of a bad request error. (John Call, Edward Ribeiro via shalin)\n \n+* SOLR-7529: CoreAdminHandler Reload throws NPE on null core name instead of a bad\n+  request error. (Jellyfrog, Edward Ribeiro via shalin)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/CHANGES.txt",
                "sha": "bf5e3da7eacdbe3f909fac6d4a081b41c7440e3d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java?ref=07a615fd6552132fe0787a3cbb51918fb7e1d051",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "patch": "@@ -766,7 +766,7 @@ protected void handleReloadAction(SolrQueryRequest req, SolrQueryResponse rsp) {\n     SolrParams params = req.getParams();\n     String cname = params.get(CoreAdminParams.CORE);\n \n-    if(!coreContainer.getCoreNames().contains(cname)) {\n+    if (cname == null || !coreContainer.getCoreNames().contains(cname)) {\n       throw new SolrException(ErrorCode.BAD_REQUEST, \"Core with core name [\" + cname + \"] does not exist.\");\n     }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "sha": "09f81ae67d32060d98135d8151c28261ecb71eee",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java?ref=07a615fd6552132fe0787a3cbb51918fb7e1d051",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java",
                "patch": "@@ -243,5 +243,21 @@ public void testNonexistentCoreReload() throws Exception {\n     } catch (Exception e) {\n       assertEquals(\"Expected error message for non-existent core.\", \"Core with core name [non-existent-core] does not exist.\", e.getMessage());\n     }\n+\n+    // test null core\n+    try {\n+      admin.handleRequestBody(\n+          req(CoreAdminParams.ACTION,\n+              CoreAdminParams.CoreAdminAction.RELOAD.toString())\n+          , resp);\n+      fail(\"Was able to successfully reload null core\");\n+    }\n+    catch (Exception e) {\n+      if (!(e instanceof SolrException)) {\n+        fail(\"Expected SolrException but got \" + e);\n+      }\n+      assertEquals(\"Expected error message for non-existent core.\", \"Core with core name [null] does not exist.\", e.getMessage());\n+    }\n+\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a615fd6552132fe0787a3cbb51918fb7e1d051/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java",
                "sha": "6d8b1049b0d193c39ec2456ebdd522574f10dcee",
                "status": "modified"
            }
        ],
        "message": "SOLR-7529: CoreAdminHandler Reload throws NPE on null core name instead of a bad request error\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1690426 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/2c64848c78d0bf235cf3e7d4e2ee9d770ebd05e1",
        "repo": "lucene-solr",
        "unit_tests": [
            "CoreAdminHandlerTest.java"
        ]
    },
    "lucene-solr_07a632c": {
        "bug_id": "lucene-solr_07a632c",
        "commit": "https://github.com/apache/lucene-solr/commit/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/IndexFileDeleter.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 0,
                "filename": "src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "patch": "@@ -84,6 +84,8 @@ void findDeletableFiles() throws IOException {\n     IndexFileNameFilter filter = IndexFileNameFilter.getFilter();\n \n     String[] files = directory.list();\n+    if (files == null)\n+      throw new IOException(\"cannot read directory \" + directory + \": list() returned null\");\n \n     for (int i = 0; i < files.length; i++) {\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "sha": "7cb2fe4237783ad95dc67f9b5f4358caf33edb56",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/SegmentInfo.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/SegmentInfo.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 0,
                "filename": "src/java/org/apache/lucene/index/SegmentInfo.java",
                "patch": "@@ -236,6 +236,9 @@ boolean hasSeparateNorms()\n         // code.  So we must fallback to the original\n         // directory list check:\n         String[] result = dir.list();\n+        if (result == null)\n+          throw new IOException(\"cannot read directory \" + dir + \": list() returned null\");\n+        \n         String pattern;\n         pattern = name + \".s\";\n         int patternLength = pattern.length();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/SegmentInfo.java",
                "sha": "22f9d077686543050cfae120a52ad1dbe334017d",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/SegmentInfos.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/SegmentInfos.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 5,
                "filename": "src/java/org/apache/lucene/index/SegmentInfos.java",
                "patch": "@@ -113,7 +113,7 @@ public static long getCurrentSegmentGeneration(String[] files) {\n   public static long getCurrentSegmentGeneration(Directory directory) throws IOException {\n     String[] files = directory.list();\n     if (files == null)\n-      throw new IOException(\"Cannot read directory \" + directory);\n+      throw new IOException(\"cannot read directory \" + directory + \": list() returned null\");\n     return getCurrentSegmentGeneration(files);\n   }\n \n@@ -477,12 +477,12 @@ public Object run() throws CorruptIndexException, IOException {\n         if (0 == method) {\n           if (directory != null) {\n             files = directory.list();\n+            if (files == null)\n+              throw new FileNotFoundException(\"cannot read directory \" + directory + \": list() returned null\");\n           } else {\n             files = fileDirectory.list();\n-          }\n-\n-          if (files == null) {\n-            throw new FileNotFoundException(\"no segments* file found in directory \" + directory + \": list() returned null\");\n+            if (files == null)\n+              throw new FileNotFoundException(\"cannot read directory \" + fileDirectory + \": list() returned null\");\n           }\n \n           gen = getCurrentSegmentGeneration(files);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/index/SegmentInfos.java",
                "sha": "41a8799c3b7d5d2a4e200007fa73a7c718024267",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/store/Directory.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/store/Directory.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/store/Directory.java",
                "patch": "@@ -42,7 +42,11 @@\n    * this Directory instance). */\n   protected LockFactory lockFactory;\n \n-  /** Returns an array of strings, one for each file in the directory. */\n+  /** Returns an array of strings, one for each file in the\n+   * directory.  This method may return null (for example for\n+   * {@link FSDirectory} if the underlying directory doesn't\n+   * exist in the filesystem or there are permissions\n+   * problems).*/\n   public abstract String[] list()\n        throws IOException;\n \n@@ -154,6 +158,10 @@ public String getLockID() {\n    */\n   public static void copy(Directory src, Directory dest, boolean closeDirSrc) throws IOException {\n       final String[] files = src.list();\n+\n+      if (files == null)\n+        throw new IOException(\"cannot read directory \" + src + \": list() returned null\");\n+\n       byte[] buf = new byte[BufferedIndexOutput.BUFFER_SIZE];\n       for (int i = 0; i < files.length; i++) {\n         IndexOutput os = null;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/store/Directory.java",
                "sha": "3cc441387dcc58ca0c29d99cfe71b21421e089ab",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/store/FSDirectory.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/store/FSDirectory.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/store/FSDirectory.java",
                "patch": "@@ -239,7 +239,7 @@ private void create() throws IOException {\n     if (directory.exists()) {\n       String[] files = directory.list(IndexFileNameFilter.getFilter());            // clear old files\n       if (files == null)\n-        throw new IOException(\"Cannot read directory \" + directory.getAbsolutePath());\n+        throw new IOException(\"cannot read directory \" + directory.getAbsolutePath() + \": list() returned null\");\n       for (int i = 0; i < files.length; i++) {\n         File file = new File(directory, files[i]);\n         if (!file.delete())",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/java/org/apache/lucene/store/FSDirectory.java",
                "sha": "881450de43721ede361b2a2709868eacd6c80602",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/test/org/apache/lucene/index/TestIndexReader.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/index/TestIndexReader.java?ref=07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22",
                "deletions": 2,
                "filename": "src/test/org/apache/lucene/index/TestIndexReader.java",
                "patch": "@@ -980,7 +980,7 @@ public void testOpenReaderAfterDelete() throws IOException {\n       Directory dir = FSDirectory.getDirectory(dirFile);\n       try {\n         IndexReader reader = IndexReader.open(dir);\n-        fail(\"expected CorruptIndexException\");\n+        fail(\"expected FileNotFoundException\");\n       } catch (FileNotFoundException e) {\n         // expected\n       }\n@@ -990,7 +990,7 @@ public void testOpenReaderAfterDelete() throws IOException {\n       // Make sure we still get a CorruptIndexException (not NPE):\n       try {\n         IndexReader reader = IndexReader.open(dir);\n-        fail(\"expected CorruptIndexException\");\n+        fail(\"expected FileNotFoundException\");\n       } catch (FileNotFoundException e) {\n         // expected\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/07a632c0e995c1a3d45e4a1c2bc642ffc9f22a22/src/test/org/apache/lucene/index/TestIndexReader.java",
                "sha": "118e89dc584bc38a37e42b8d183b72619c4cbaa3",
                "status": "modified"
            }
        ],
        "message": "LUCENE-825: detect null returned from Directory.list() and throw IOException not NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@516120 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/57cf17d188e5172548f38bfb1a098e7410626e2f",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestIndexFileDeleter.java",
            "TestSegmentInfos.java",
            "TestDirectory.java"
        ]
    },
    "lucene-solr_0a4f6c5": {
        "bug_id": "lucene-solr_0a4f6c5",
        "commit": "https://github.com/apache/lucene-solr/commit/0a4f6c566e450f89745439f07d4c22119cf977b9",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=0a4f6c566e450f89745439f07d4c22119cf977b9",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -136,6 +136,8 @@ Bug Fixes\n * SOLR-12393: Compute score if requested even when expanded docs not sorted by score in ExpandComponent.\n   (David Smiley, Munendra S N)\n \n+* SOLR-13877: Fix NPE in expand component when matched docs have fewer unique values. (Munendra S N)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/CHANGES.txt",
                "sha": "a41d2ea394c91150913aaa34fd359821de22c34a",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java?ref=0a4f6c566e450f89745439f07d4c22119cf977b9",
                "deletions": 12,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "patch": "@@ -327,11 +327,7 @@ public void process(ResponseBuilder rb) throws IOException {\n       }\n \n       if(count > 0 && count < 200) {\n-        try {\n-          groupQuery = getGroupQuery(field, count, ordBytes);\n-        } catch(Exception e) {\n-          throw new IOException(e);\n-        }\n+        groupQuery = getGroupQuery(field, count, ordBytes);\n       }\n     } else {\n       groupSet = new LongHashSet(docList.size());\n@@ -689,16 +685,15 @@ private Query getGroupQuery(String fname,\n                            int size,\n                            LongHashSet groupSet) {\n \n-    BytesRef[] bytesRefs = new BytesRef[size];\n+    List<BytesRef> bytesRefs = new ArrayList<>(size);\n     BytesRefBuilder term = new BytesRefBuilder();\n     Iterator<LongCursor> it = groupSet.iterator();\n-    int index = -1;\n \n     while (it.hasNext()) {\n       LongCursor cursor = it.next();\n       String stringVal = numericToString(ft, cursor.value);\n       ft.readableToIndexed(stringVal, term);\n-      bytesRefs[++index] = term.toBytesRef();\n+      bytesRefs.add(term.toBytesRef());\n     }\n \n     return new TermInSetQuery(fname, bytesRefs);\n@@ -738,13 +733,12 @@ private String numericToString(FieldType fieldType, long val) {\n \n   private Query getGroupQuery(String fname,\n                               int size,\n-                              IntObjectHashMap<BytesRef> ordBytes) throws Exception {\n-    BytesRef[] bytesRefs = new BytesRef[size];\n-    int index = -1;\n+                              IntObjectHashMap<BytesRef> ordBytes) {\n+    List<BytesRef> bytesRefs = new ArrayList<>(size);\n     Iterator<IntObjectCursor<BytesRef>>it = ordBytes.iterator();\n     while (it.hasNext()) {\n       IntObjectCursor<BytesRef> cursor = it.next();\n-      bytesRefs[++index] = cursor.value;\n+      bytesRefs.add(cursor.value);\n     }\n     return new TermInSetQuery(fname, bytesRefs);\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "sha": "2a58248bfa92e7eea29a7bcf306a3803ac8b33d5",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/lucene-solr/blob/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "changes": 53,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java?ref=0a4f6c566e450f89745439f07d4c22119cf977b9",
                "deletions": 21,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "patch": "@@ -91,17 +91,7 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n         {\"id\",\"7\", \"term_s\", \"YYYY\", group, \"1\"+floatAppend, \"test_i\", \"1\", \"test_l\", \"100000\", \"test_f\", \"2000\", \"type_s\", \"child\"},\n         {\"id\",\"8\", \"term_s\",\"YYYY\", group, \"2\"+floatAppend, \"test_i\", \"2\", \"test_l\",  \"100000\", \"test_f\", \"200\", \"type_s\", \"child\"}\n     };\n-    // randomize addition of docs into bunch of segments\n-    // TODO there ought to be a test utility to do this; even add in batches\n-    Collections.shuffle(Arrays.asList(docs), random());\n-    for (String[] doc : docs) {\n-      assertU(adoc(doc));\n-      if (random().nextBoolean()) {\n-        assertU(commit());\n-      }\n-    }\n-\n-    assertU(commit());\n+    createIndex(docs);\n \n     ModifiableSolrParams params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n@@ -165,7 +155,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n \n \n     //Test override expand.q\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"type_s:parent\");\n     params.add(\"defType\", \"edismax\");\n@@ -186,7 +175,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n \n \n     //Test override expand.fq\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n     params.add(\"fq\", \"type_s:parent\");\n@@ -207,7 +195,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test override expand.fq and expand.q\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n     params.add(\"fq\", \"type_s:parent\");\n@@ -229,7 +216,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test expand.rows\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n     params.add(\"fq\", \"{!collapse field=\"+group+hint+\"}\");\n@@ -250,7 +236,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n \n \n     //Test no group results\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"test_i:5\");\n     params.add(\"fq\", \"{!collapse field=\"+group+hint+\"}\");\n@@ -264,7 +249,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test zero results\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"test_i:5532535\");\n     params.add(\"fq\", \"{!collapse field=\"+group+hint+\"}\");\n@@ -278,7 +262,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test key-only fl\n-\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n     params.add(\"fq\", \"{!collapse field=\"+group+hint+\"}\");\n@@ -299,7 +282,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test key-only fl with score but no sorting\n-\n     assertQ(req(params, \"fl\", \"id,score\"), \"*[count(/response/result/doc)=2]\",\n         \"*[count(/response/lst[@name='expanded']/result)=2]\",\n         \"/response/result/doc[1]/str[@name='id'][.='2']\",\n@@ -326,7 +308,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test fl with score, sort by non-score\n-\n     assertQ(req(params, \"expand.sort\", \"test_l desc\", \"fl\", \"id,test_i,score\"),\n         \"*[count(/response/result/doc)=2]\",\n         \"count(/response/lst[@name='expanded']/result)=2\",\n@@ -342,7 +323,6 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n     );\n \n     //Test fl with score with multi-sort\n-\n     assertQ(req(params, \"expand.sort\", \"test_l desc, score asc\", \"fl\", \"id,test_i,score\"),\n         \"*[count(/response/result/doc)=2]\",\n         \"count(/response/lst[@name='expanded']/result)=2\",\n@@ -356,6 +336,22 @@ private void _testExpand(String group, String floatAppend, String hint) throws E\n         \"count(//*[@name='score' and .='NaN'])=0\",\n         \"count(/response/lst[@name='expanded']/result/doc[number(*/@name='score')!=number(*/@name='test_i')])=0\"\n     );\n+\n+    // Test for expand with collapse\n+    // when matched docs have fewer unique values\n+    params = params(\"q\", \"*:*\", \"sort\", \"id asc\", \"fl\", \"id\", \"rows\", \"6\", \"expand\", \"true\", \"expand.sort\", \"id asc\");\n+    assertQ(req(params, \"expand.field\", \"term_s\"),\n+        \"*[count(/response/result/doc)=6]\",\n+        \"/response/lst[@name='expanded']/result[@name='YYYY']/doc[1]/str[@name='id'][.='7']\",\n+        \"/response/lst[@name='expanded']/result[@name='YYYY']/doc[2]/str[@name='id'][.='8']\",\n+        \"count(//*[@name='score'])=0\"\n+    );\n+    assertQ(req(params, \"expand.field\", \"test_f\"),\n+        \"*[count(/response/result/doc)=6]\",\n+        \"/response/lst[@name='expanded']/result[@name='200.0']/doc[1]/str[@name='id'][.='8']\",\n+        \"/response/lst[@name='expanded']/result[@name='2000.0']/doc[1]/str[@name='id'][.='7']\",\n+        \"count(//*[@name='score'])=0\"\n+    );\n   }\n \n   @Test\n@@ -416,4 +412,19 @@ public void testErrorCases() {\n \n     resetExceptionIgnores();\n   }\n+\n+  /**\n+   * randomize addition of docs into bunch of segments\n+   * TODO: there ought to be a test utility to do this; even add in batches\n+   */\n+  private void createIndex(String[][] docs) {\n+    Collections.shuffle(Arrays.asList(docs), random());\n+    for (String[] doc : docs) {\n+      assertU(adoc(doc));\n+      if (random().nextBoolean()) {\n+        assertU(commit());\n+      }\n+    }\n+    assertU(commit());\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/0a4f6c566e450f89745439f07d4c22119cf977b9/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "sha": "336d608a32cdaf6fbf30d80cd521eafcc4507b30",
                "status": "modified"
            }
        ],
        "message": "SOLR-13877: fix NPE in expand component\n\n* This could happen when expand component is not used with collapse\n  and matched docs have fewer unique values",
        "parent": "https://github.com/apache/lucene-solr/commit/d53e877152851a3dc91c7c56f01544a43ffe7397",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestExpandComponent.java"
        ]
    },
    "lucene-solr_0d5a475": {
        "bug_id": "lucene-solr_0d5a475",
        "commit": "https://github.com/apache/lucene-solr/commit/0d5a4755c9844380ffd4d5bdf5e0c87c0ae281b9",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/0d5a4755c9844380ffd4d5bdf5e0c87c0ae281b9/src/java/org/apache/lucene/store/BufferedIndexInput.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/store/BufferedIndexInput.java?ref=0d5a4755c9844380ffd4d5bdf5e0c87c0ae281b9",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/store/BufferedIndexInput.java",
                "patch": "@@ -49,7 +49,7 @@ public BufferedIndexInput(int bufferSize) {\n \n   /** Change the buffer size used by this IndexInput */\n   public void setBufferSize(int newSize) {\n-    assert bufferSize == buffer.length;\n+    assert buffer == null || bufferSize == buffer.length;\n     if (newSize != bufferSize) {\n       checkBufferSize(newSize);\n       bufferSize = newSize;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/0d5a4755c9844380ffd4d5bdf5e0c87c0ae281b9/src/java/org/apache/lucene/store/BufferedIndexInput.java",
                "sha": "20f9a284e05d087184b92f58bf4e9bec77f4bda2",
                "status": "modified"
            }
        ],
        "message": "LUCENE-888: fix possible NPE in assert statement\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@542667 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/3e09257c09a6ef0c8495938f6e99ab0fcc62c305",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestBufferedIndexInput.java"
        ]
    },
    "lucene-solr_1182376": {
        "bug_id": "lucene-solr_1182376",
        "commit": "https://github.com/apache/lucene-solr/commit/1182376282c7ed248a5cac9b3d5f981ab93bdf26",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/1182376282c7ed248a5cac9b3d5f981ab93bdf26/src/java/org/apache/solr/handler/ReplicationHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/handler/ReplicationHandler.java?ref=1182376282c7ed248a5cac9b3d5f981ab93bdf26",
                "deletions": 1,
                "filename": "src/java/org/apache/solr/handler/ReplicationHandler.java",
                "patch": "@@ -153,7 +153,7 @@ public void run() {\n     for (IndexCommit c : commits.values()) {\n       try {\n         NamedList nl = new NamedList();\n-        nl.add(CMD_INDEX_VERSION, c.getVersion());\n+        nl.add(\"indexVersion\", c.getVersion());\n         nl.add(GENERATION, c.getGeneration());\n         nl.add(CMD_GET_FILE_LIST, c.getFileNames().toString());\n         l.add(nl);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/1182376282c7ed248a5cac9b3d5f981ab93bdf26/src/java/org/apache/solr/handler/ReplicationHandler.java",
                "sha": "90f8cf15816c1e0b1eb92000ff898b0021be3b65",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/1182376282c7ed248a5cac9b3d5f981ab93bdf26/src/webapp/web/admin/replication/index.jsp",
                "changes": 39,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/webapp/web/admin/replication/index.jsp?ref=1182376282c7ed248a5cac9b3d5f981ab93bdf26",
                "deletions": 23,
                "filename": "src/webapp/web/admin/replication/index.jsp",
                "patch": "@@ -1,5 +1,5 @@\n <%@ page contentType=\"text/html; charset=utf-8\" pageEncoding=\"UTF-8\" %>\n-<%-- \n+<%--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n@@ -40,48 +40,41 @@ if (detailsMap != null)\n     <strong>Master</strong>\n   </td>\n   <td>\n+    <%=slave.get(\"masterUrl\")%>\n     <%\n-      out.println((String) slave.get(\"masterUrl\"));\n+    NamedList nl = (NamedList) slave.get(\"masterDetails\");\n+    if(nl == null)\n+    \tout.print(\" - <b>Unreachable</b>\");\n     %>\n   </td>\n </tr>\n-\n-<tr>\n-  <%\n-    NamedList nl = (NamedList) slave.get(\"masterDetails\");\n-    if (nl != null) {\n-      long masterVersion = (Long) nl.get(\"indexVersion\");\n-      long masterGeneration = (Long) nl.get(\"generation\");\n-      long replicatableMasterVer = 0, replicatableMasterGen = 0;\n+<%\n+    if (nl != null) {         \n+      Object replicatableMasterVer = null, replicatableMasterGen = null;\n       nl = (NamedList) nl.get(\"master\");\n-      if(nl != null){\n-      \tif (nl.get(\"replicatableindexversion\") != null)\n-        \treplicatableMasterVer = (Long) nl.get(\"replicatableindexversion\");\n-      \tif (nl.get(\"replicatablegeneration\") != null)\n-        \treplicatableMasterGen = (Long) nl.get(\"replicatablegeneration\");\n-      }\n+      if(nl != null){      \n   %>\n+<tr>  \n   <td>\n   </td>\n-  <td>Latest Index Version:<%=masterVersion%>, Generation: <%=masterGeneration%>\n+  <td>Latest Index Version:<%=nl.get(\"indexVersion\")%>, Generation: <%=nl.get(\"generation\")%>\n   </td>\n </tr>\n-\n <tr>\n   <td></td>\n-  <td>Replicatable Index Version:<%=replicatableMasterVer%>, Generation: <%=replicatableMasterGen%>\n+  <td>Replicatable Index Version:<%=nl.get(\"replicatableIndexVersion\")%>, Generation: <%=nl.get(\"replicatableGeneration\")%>\n   </td>\n </tr>\n-<%}%>\n+<%\n+}\n+}%>\n \n <tr>\n   <td>\n     <strong>Poll Interval</strong>\n   </td>\n   <td>\n-    <%\n-      out.println((String) slave.get(\"pollInterval\"));\n-    %>\n+    <%=slave.get(\"pollInterval\")%>\n   </td>\n </tr>\n <%}%>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/1182376282c7ed248a5cac9b3d5f981ab93bdf26/src/webapp/web/admin/replication/index.jsp",
                "sha": "c2731be384daa5ee46eac4be5668a4b47c294843",
                "status": "modified"
            }
        ],
        "message": "SOLR-1050 -- NPE thrown in replication admin page due to unhandled casting of null values\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@751374 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/ab7106f35f8fd3744b9b4137f2127cb8549d65f9",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestReplicationHandler.java"
        ]
    },
    "lucene-solr_1389f64": {
        "bug_id": "lucene-solr_1389f64",
        "commit": "https://github.com/apache/lucene-solr/commit/1389f64fbe6f68552b44b380ae8d770fd5075c8c",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/1389f64fbe6f68552b44b380ae8d770fd5075c8c/solr/core/src/java/org/apache/solr/update/UpdateHandler.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/UpdateHandler.java?ref=1389f64fbe6f68552b44b380ae8d770fd5075c8c",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/update/UpdateHandler.java",
                "patch": "@@ -85,7 +85,8 @@ private void initLog(PluginInfo ulogPluginInfo) {\n \n   // not thread safe - for startup\n   private void clearLog(PluginInfo ulogPluginInfo) {\n-    File tlogDir = UpdateLog.getTlogDir(ulogPluginInfo);\n+    if (ulogPluginInfo == null) return;\n+    File tlogDir = UpdateLog.getTlogDir(core, ulogPluginInfo);\n     if (tlogDir.exists()) {\n       String[] files = UpdateLog.getLogList(tlogDir);\n       for (String file : files) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/1389f64fbe6f68552b44b380ae8d770fd5075c8c/solr/core/src/java/org/apache/solr/update/UpdateHandler.java",
                "sha": "5f343658087dfc1e5f0f88f2f46526e82c88d114",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/1389f64fbe6f68552b44b380ae8d770fd5075c8c/solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/UpdateLog.java?ref=1389f64fbe6f68552b44b380ae8d770fd5075c8c",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "patch": "@@ -1395,8 +1395,18 @@ public static void deleteFile(File file) {\n     }\n   }\n   \n-  public static File getTlogDir(PluginInfo info) {\n-    String dataDir = (String)info.initArgs.get(\"dir\");\n+  public static File getTlogDir(SolrCore core, PluginInfo info) {\n+    String dataDir = (String) info.initArgs.get(\"dir\");\n+    if (dataDir == null) {\n+      String ulogDir = core.getCoreDescriptor().getUlogDir();\n+      if (ulogDir != null) {\n+        dataDir = ulogDir;\n+      }\n+      \n+      if (dataDir == null || dataDir.length() == 0) {\n+        dataDir = core.getDataDir();\n+      }\n+    }\n     return new File(dataDir, TLOG_NAME);\n   }\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/1389f64fbe6f68552b44b380ae8d770fd5075c8c/solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "sha": "bc761ea41f6e4389be0f52859e0ca5daa44b4856",
                "status": "modified"
            }
        ],
        "message": "SOLR-4203: whoops - fix npe\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1423625 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/bef4454e2f28ce884dbda8542377e357f64e6192",
        "repo": "lucene-solr",
        "unit_tests": [
            "UpdateLogTest.java"
        ]
    },
    "lucene-solr_148d99c": {
        "bug_id": "lucene-solr_148d99c",
        "commit": "https://github.com/apache/lucene-solr/commit/148d99cbbc1201c1812ea0b7d63604355f55ff8b",
        "file": [
            {
                "additions": 51,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/build.xml",
                "changes": 67,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/build.xml?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 16,
                "filename": "build.xml",
                "patch": "@@ -176,22 +176,57 @@\n     </subant>\n   </target>\n \n-  <target name=\"jar-checksums\" depends=\"resolve\" description=\"Recompute SHA1 checksums for all JAR files.\">\n-    <delete>\n-      <fileset dir=\"${basedir}\">\n-        <include name=\"**/*.jar.sha1\"/>\n-      </fileset>\n-    </delete>\n-\n-    <checksum algorithm=\"SHA1\" fileext=\".sha1\">\n-      <fileset dir=\"${basedir}\">\n-        <include name=\"**/*.jar\"/>\n-      </fileset>\n-    </checksum>\n+  <target name=\"jar-checksums\" description=\"Recompute SHA1 checksums for all JAR files.\">\n+    <sequential>\n+      <subant target=\"jar-checksums\" inheritall=\"false\" failonerror=\"true\">\n+        <fileset dir=\"lucene\" includes=\"build.xml\" />\n+        <fileset dir=\"solr\" includes=\"build.xml\" />\n+      </subant>\n+    </sequential>\n+  </target>\n \n-    <fixcrlf \n-      srcdir=\"${basedir}\"\n-      includes=\"**/*.jar.sha1\"\n-      eol=\"lf\" fixlast=\"true\" encoding=\"US-ASCII\" />\n+  <property name=\"python32.exe\" value=\"python3.2\" />\n+  <property name=\"JAVA6_HOME\" value=\"/usr/local/jdk1.6.0_27\"/>\n+  <property name=\"JAVA7_HOME\" value=\"/usr/local/jdk1.7.0_01\"/>\n+  <property name=\"fakeRelease\" value=\"lucene/build/fakeRelease\"/>\n+  <property name=\"fakeReleaseTmp\" value=\"lucene/build/fakeReleaseTmp\"/>\n+  <property name=\"fakeReleaseVersion\" value=\"5.0\"/> <!-- *not* -SNAPSHOT, the real version -->\n+\n+  <target name=\"nightly-smoke\" description=\"Builds an unsigned release and smoke tests it.\" depends=\"clean\">\n+   <sequential>\n+     <subant target=\"prepare-release-no-sign\" inheritall=\"false\" failonerror=\"true\">\n+       <fileset dir=\"lucene\" includes=\"build.xml\" />\n+       <fileset dir=\"solr\" includes=\"build.xml\" />\n+       <property name=\"version\" value=\"${fakeReleaseVersion}\" />\n+     </subant>\n+     <delete dir=\"${fakeRelease}\"/>\n+     <delete dir=\"${fakeReleaseTmp}\"/>\n+     <mkdir dir=\"${fakeRelease}\"/>\n+     <copy todir=\"${fakeRelease}/lucene\">\n+       <fileset dir=\"lucene/dist\"/>\n+     </copy>\n+     <copy todir=\"${fakeRelease}/lucene/changes\">\n+       <fileset dir=\"lucene/build/docs/changes\"/>\n+     </copy>\n+     <get src=\"http://people.apache.org/keys/group/lucene.asc\" \n+          dest=\"${fakeRelease}/lucene/KEYS\"/>\n+     <copy todir=\"${fakeRelease}/solr\">\n+       <fileset dir=\"solr/package\"/>\n+     </copy>\n+     <copy file=\"${fakeRelease}/lucene/KEYS\" todir=\"${fakeRelease}/solr\"/>\n+     <makeurl file=\"${fakeRelease}\" validate=\"false\" property=\"fakeRelease.uri\"/>\n+     <exec executable=\"${python32.exe}\" failonerror=\"true\">\n+       <arg value=\"-u\"/>\n+       <arg value=\"dev-tools/scripts/smokeTestRelease.py\"/>\n+       <arg value=\"${fakeRelease.uri}\"/>\n+       <arg value=\"${fakeReleaseVersion}\"/>\n+       <arg value=\"${fakeReleaseTmp}\"/>\n+       <arg value=\"false\"/>\n+       <env key=\"JAVA6_HOME\" value=\"${JAVA6_HOME}\"/>\n+       <env key=\"JAVA7_HOME\" value=\"${JAVA7_HOME}\"/>\n+     </exec>\n+     <delete dir=\"${fakeRelease}\"/>\n+     <delete dir=\"${fakeReleaseTmp}\"/>\n+   </sequential>\n   </target>\n </project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/build.xml",
                "sha": "4dbcf68efcec148f2a02fd80fac2fe0197d1ff82",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/eclipse/dot.classpath",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/eclipse/dot.classpath?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 11,
                "filename": "dev-tools/eclipse/dot.classpath",
                "patch": "@@ -15,30 +15,30 @@\n \t<classpathentry kind=\"src\" path=\"lucene/sandbox/src/java\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/sandbox/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/test-framework/src/java\"/>\n-  <classpathentry kind=\"src\" output=\"bin.tests-framework\" path=\"lucene/test-framework/src/resources\"/>\n+  <classpathentry kind=\"src\" output=\"bin/tests-framework\" path=\"lucene/test-framework/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/common/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-common\"  path=\"lucene/analysis/common/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-common\"  path=\"lucene/analysis/common/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/common/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/icu/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-icu\" path=\"lucene/analysis/icu/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-icu\" path=\"lucene/analysis/icu/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/icu/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/kuromoji/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-kuromoji\" path=\"lucene/analysis/kuromoji/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-kuromoji\" path=\"lucene/analysis/kuromoji/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/kuromoji/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/phonetic/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-phonetic\" path=\"lucene/analysis/phonetic/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-phonetic\" path=\"lucene/analysis/phonetic/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/phonetic/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/smartcn/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-smartcn\" path=\"lucene/analysis/smartcn/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-smartcn\" path=\"lucene/analysis/smartcn/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/smartcn/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/stempel/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-stempel\" path=\"lucene/analysis/stempel/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-stempel\" path=\"lucene/analysis/stempel/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/stempel/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/morfologik/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-morfologik\" path=\"lucene/analysis/morfologik/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-morfologik\" path=\"lucene/analysis/morfologik/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/morfologik/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/uima/src/java\"/>\n-\t<classpathentry kind=\"src\" output=\"bin.analysis-uima\" path=\"lucene/analysis/uima/src/resources\"/>\n+\t<classpathentry kind=\"src\" output=\"bin/analysis-uima\" path=\"lucene/analysis/uima/src/resources\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/analysis/uima/src/test\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/benchmark/src/java\"/>\n \t<classpathentry kind=\"src\" path=\"lucene/benchmark/src/test\"/>\n@@ -120,7 +120,7 @@\n \t<classpathentry kind=\"lib\" path=\"solr/lib/slf4j-api-1.6.4.jar\"/>\n \t<classpathentry kind=\"lib\" path=\"solr/lib/slf4j-jdk14-1.6.4.jar\"/>\n \t<classpathentry kind=\"lib\" path=\"solr/lib/wstx-asl-3.2.7.jar\"/>\n-\t<classpathentry kind=\"lib\" path=\"solr/lib/zookeeper-3.3.5.jar\"/>\n+\t<classpathentry kind=\"lib\" path=\"solr/lib/zookeeper-3.3.6.jar\"/>\n   <classpathentry kind=\"lib\" path=\"solr/example/lib/jetty-continuation-8.1.2.v20120308.jar\"/>\n   <classpathentry kind=\"lib\" path=\"solr/example/lib/jetty-deploy-8.1.2.v20120308.jar\"/>\n   <classpathentry kind=\"lib\" path=\"solr/example/lib/jetty-http-8.1.2.v20120308.jar\"/>\n@@ -175,5 +175,5 @@\n   <classpathentry kind=\"lib\" path=\"solr/contrib/velocity/lib/commons-collections-3.2.1.jar\"/>\n \t<classpathentry kind=\"con\" path=\"org.eclipse.jdt.launching.JRE_CONTAINER\"/>\n \t<classpathentry kind=\"lib\" path=\"lucene/test-framework/lib/randomizedtesting-runner-1.6.0.jar\"/>\n-\t<classpathentry kind=\"output\" path=\"bin\"/>\n+\t<classpathentry kind=\"output\" path=\"bin/other\"/>\n </classpath>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/eclipse/dot.classpath",
                "sha": "66e7bbc031283c13390223ca748ff253966d2c69",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/README.maven",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/README.maven?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 12,
                "filename": "dev-tools/maven/README.maven",
                "patch": "@@ -36,27 +36,25 @@ A. How to use nightly Jenkins-built Lucene/Solr Maven artifacts\n \n B. How to generate Lucene/Solr Maven artifacts\n \n-   Prerequisites: JDK 1.6+ and Ant 1.7.X\n+   Prerequisites: JDK 1.6+ and Ant 1.8.2+\n \n    Run 'ant generate-maven-artifacts' to create an internal Maven\n    repository, including POMs, binary .jars, source .jars, and javadoc\n    .jars.\n \n-   You can run the above command in four possible places: the top-level\n-   directory; under lucene/; under solr/; or under modules/.  From the\n-   top-level directory, from lucene/, or from modules/, the internal\n-   repository will be located at dist/maven/.  From solr/, the internal\n-   repository will be located at package/maven/.\n+   You can run the above command in three possible places: the top-level\n+   directory; under lucene/; or under solr/.  From the top-level directory\n+   or from lucene/, the internal repository will be located at dist/maven/.\n+   From solr/, the internal repository will be located at package/maven/.\n \n \n C. How to deploy Maven artifacts to a repository\n \n-   Prerequisites: JDK 1.6+ and Ant 1.7.X\n+   Prerequisites: JDK 1.6+ and Ant 1.8.2+\n \n-   You can deploy targets for all of Lucene/Solr, only Lucene, only Solr,\n-   or only modules/, as in B. above.  To deploy to a Maven repository, the\n-   command is the same as in B. above, with the addition of two system\n-   properties:\n+   You can deploy targets for all of Lucene/Solr, only Lucene, or only Solr,\n+   as in B. above.  To deploy to a Maven repository, the command is the same\n+   as in B. above, with the addition of two system properties:\n \n       ant -Dm2.repository.id=my-repo-id \\\n           -Dm2.repository.url=http://example.org/my/repo \\\n@@ -101,7 +99,7 @@ D. How to use Maven to build Lucene/Solr\n       the default, you can supply an alternate version on the command line\n       with the above command, e.g.:\n \n-         ant -Dversion=5.0-my-special-version get-maven-poms\n+         ant -Dversion=my-special-version get-maven-poms\n \n       Note: if you change the version in the POMs, there is one test method\n       that will fail under maven-surefire-plugin:",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/README.maven",
                "sha": "9f728ed1a5f1b2be5a0477865b8a4d84426b7bea",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/common/pom.xml.template",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/common/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 37,
                "filename": "dev-tools/maven/lucene/analysis/common/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -77,33 +71,5 @@\n         </excludes>\n       </testResource>\n     </testResources>\n-    <plugins>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.lucene.analysis.charfilter.HtmlStripCharFilter</mainClass>\n-              <name>HtmlStripCharFilter</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.analysis.en.PorterStemmer</mainClass>\n-              <name>EnglishPorterStemmer</name>\n-            </program>\n-            <program>\n-              <mainClass>org.tartarus.snowball.TestApp</mainClass>\n-              <name>SnowballTestApp</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n-    </plugins>\n   </build>\n </project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/common/pom.xml.template",
                "sha": "2ea7940ea5491651f377350949a9ab4282367cbf",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/icu/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/icu/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/icu/pom.xml.template",
                "patch": "@@ -40,15 +40,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/icu/pom.xml.template",
                "sha": "c1281c79d6a9b92d948b34351426b649c55c3c2c",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/kuromoji/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/kuromoji/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/kuromoji/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/kuromoji/pom.xml.template",
                "sha": "1447a915c0e209c88185f8063ff29c0cea24d412",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/morfologik/pom.xml.template",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/morfologik/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/morfologik/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -75,6 +69,11 @@\n   <build>\n     <sourceDirectory>${module-path}/src/java</sourceDirectory>\n     <testSourceDirectory>${module-path}/src/test</testSourceDirectory>\n+    <resources>\n+      <resource>\n+        <directory>${module-path}/src/resources</directory>\n+      </resource>\n+    </resources>\n     <testResources>\n       <testResource>\n         <directory>${project.build.testSourceDirectory}</directory>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/morfologik/pom.xml.template",
                "sha": "b520b3e12230c170a0c331af6a0e246364a0061b",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/phonetic/pom.xml.template",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/phonetic/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/phonetic/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -75,6 +69,11 @@\n   <build>\n     <sourceDirectory>${module-path}/src/java</sourceDirectory>\n     <testSourceDirectory>${module-path}/src/test</testSourceDirectory>\n+    <resources>\n+      <resource>\n+        <directory>${module-path}/src/resources</directory>\n+      </resource>\n+    </resources>\n     <testResources>\n       <testResource>\n         <directory>${project.build.testSourceDirectory}</directory>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/phonetic/pom.xml.template",
                "sha": "b7498afcb8104529fa4d1dc2c08e00034f65231d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/smartcn/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/smartcn/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/smartcn/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/smartcn/pom.xml.template",
                "sha": "e045921cbf1bd6291f2997b898cadbd985d18328",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/stempel/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/stempel/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/stempel/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/stempel/pom.xml.template",
                "sha": "d10c0933ee3fb853e67f85542bda684379a7f0c0",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/uima/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/analysis/uima/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/analysis/uima/pom.xml.template",
                "patch": "@@ -41,15 +41,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/analysis/uima/pom.xml.template",
                "sha": "81dbac36e4accb20c27f07b3cf372ff11b327776",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/benchmark/pom.xml.template",
                "changes": 48,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/benchmark/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 45,
                "filename": "dev-tools/maven/lucene/benchmark/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -120,41 +114,5 @@\n         </includes>\n       </testResource>\n     </testResources>\n-    <plugins>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.lucene.benchmark.byTask.Benchmark</mainClass>\n-              <name>Benchmark</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.benchmark.quality.trec.QueryDriver</mainClass>\n-              <name>QueryDriver</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.benchmark.quality.utils.QualityQueriesFinder</mainClass>\n-              <name>QualityQueriesFinder</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.benchmark.utils.ExtractReuters</mainClass>\n-              <name>ExtractReuters</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.benchmark.utils.ExtractWikipedia</mainClass>\n-              <name>ExtractWikipedia</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n-    </plugins>\n   </build>\n </project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/benchmark/pom.xml.template",
                "sha": "c52a3a170205982307ca604427470a166b96f8c5",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/core/pom.xml.template",
                "changes": 46,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/core/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 43,
                "filename": "dev-tools/maven/lucene/core/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>\n@@ -104,40 +98,6 @@\n           </systemPropertyVariables>\n         </configuration>\n       </plugin>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.lucene.index.CheckIndex</mainClass>\n-              <name>CheckIndex</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.index.IndexReader</mainClass>\n-              <name>IndexReader</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.store.LockStressTest</mainClass>\n-              <name>LockStressTest</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.store.LockVerifyServer</mainClass>\n-              <name>LockVerifyServer</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.util.English</mainClass>\n-              <name>English</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n       <plugin>\n         <groupId>org.codehaus.mojo</groupId>\n         <artifactId>build-helper-maven-plugin</artifactId>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/core/pom.xml.template",
                "sha": "35197d45e133b17f86ae88f3660a57a4cd36852e",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/demo/pom.xml.template",
                "changes": 37,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/demo/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 34,
                "filename": "dev-tools/maven/lucene/demo/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -87,30 +81,5 @@\n         </excludes>\n       </testResource>\n     </testResources>\n-    <plugins>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <assembleDirectory>${build-directory}</assembleDirectory>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.lucene.demo.IndexFiles</mainClass>\n-              <name>IndexFiles</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.demo.SearchFiles</mainClass>\n-              <name>SearchFiles</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n-    </plugins>\n   </build>\n </project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/demo/pom.xml.template",
                "sha": "5e24dd85875cc1a102e409f3f7b3c67983847b52",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/facet/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/facet/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/facet/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/facet/pom.xml.template",
                "sha": "c68a88af720684a73071a622dca37f6c642f4d8f",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/grouping/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/grouping/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/grouping/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/grouping/pom.xml.template",
                "sha": "2b004bf321ef9c0135c5887ea37453a4146b41e8",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/highlighter/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/highlighter/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/highlighter/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/highlighter/pom.xml.template",
                "sha": "0d5ef3a58049871dd417c0112445520be072504a",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/join/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/join/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/join/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/join/pom.xml.template",
                "sha": "4ff18bdf23dffcf973adb234c0b258730a4f0d7d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/memory/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/memory/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/memory/pom.xml.template",
                "patch": "@@ -39,15 +39,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/memory/pom.xml.template",
                "sha": "53de59948210d771d0954f194dafe3d7966f4e9c",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/misc/pom.xml.template",
                "changes": 56,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/misc/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 53,
                "filename": "dev-tools/maven/lucene/misc/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> \n@@ -72,49 +66,5 @@\n         </excludes>\n       </testResource>\n     </testResources>\n-    <plugins>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.lucene.index.FieldNormModifier</mainClass>\n-              <name>FieldNormModifier</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.index.IndexSplitter</mainClass>\n-              <name>IndexSplitter</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.index.MultiPassIndexSplitter</mainClass>\n-              <name>MultiPassIndexSplitter</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.misc.GetTermInfo</mainClass>\n-              <name>GetTermInfo</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.misc.HighFreqTerms</mainClass>\n-              <name>HighFreqTerms</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.misc.IndexMergeTool</mainClass>\n-              <name>IndexMergeTool</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.lucene.misc.LengthNormModifier</mainClass>\n-              <name>LengthNormModifier</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n-    </plugins>\n   </build>\n </project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/misc/pom.xml.template",
                "sha": "12a60f0f1c8ed53c01ef9cd098d501b848bf1118",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/pom.xml.template",
                "patch": "@@ -35,15 +35,9 @@\n     <module-directory>lucene</module-directory>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <modules>\n     <module>core</module>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/pom.xml.template",
                "sha": "9883aa2024d7e0e9d4fd138f20dfdd105ef79640",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/queries/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/queries/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/queries/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/queries/pom.xml.template",
                "sha": "864c0b9237e2caa77a652d6be5c3768dbf1c71c8",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/queryparser/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/queryparser/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/queryparser/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/queryparser/pom.xml.template",
                "sha": "b14ffcea6cd4e644b7d6b704a9414696154577c9",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/sandbox/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/sandbox/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/sandbox/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/sandbox/pom.xml.template",
                "sha": "508975f497f4438559cb6845cc5aa0857bb6660d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/suggest/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/suggest/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/suggest/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency> ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/suggest/pom.xml.template",
                "sha": "42ecf7da9e03d46f6a26d55a3350725dded07cd2",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/test-framework/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/lucene/test-framework/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/lucene/test-framework/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/lucene/test-framework/pom.xml.template",
                "sha": "f454c523c1034103266ad3dd4880e94e1633663a",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/pom.xml.template",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 21,
                "filename": "dev-tools/maven/pom.xml.template",
                "patch": "@@ -31,15 +31,18 @@\n   <version>@version@</version>\n   <packaging>pom</packaging>\n   <name>Grandparent POM for Apache Lucene Core and Apache Solr</name>\n-  <description>Parent POM for Apache Lucene Core and Apache Solr</description>\n-  <url>http://lucene.apache.org/java</url>\n+  <description>Grandparent POM for Apache Lucene Core and Apache Solr</description>\n+  <url>http://lucene.apache.org</url>\n   <modules>\n     <module>lucene</module>\n     <module>solr</module>\n   </modules>\n   <properties>\n     <top-level>..</top-level>\n-    <base.specification.version>4.0.0</base.specification.version>\n+    <vc-anonymous-base-url>http://svn.apache.org/repos/asf/lucene/dev/trunk</vc-anonymous-base-url>\n+    <vc-dev-base-url>https://svn.apache.org/repos/asf/lucene/dev/trunk</vc-dev-base-url>\n+    <vc-browse-base-url>http://svn.apache.org/viewvc/lucene/dev/trunk</vc-browse-base-url>\n+    <base.specification.version>5.0.0</base.specification.version>\n     <maven.build.timestamp.format>yyyy-MM-dd HH:mm:ss</maven.build.timestamp.format>\n     <java.compat.version>1.6</java.compat.version>\n     <jetty.version>8.1.2.v20120308</jetty.version>\n@@ -69,11 +72,11 @@\n   </properties>\n   <issueManagement>\n     <system>JIRA</system>\n-    <url>http://issues.apache.org/jira/browse/LUCENE</url>\n+    <url>https://issues.apache.org/jira/browse/LUCENE</url>\n   </issueManagement>\n   <ciManagement>\n-    <system>Hudson</system>\n-    <url>http://lucene.zones.apache.org:8080/hudson/job/Lucene-Nightly/</url>\n+    <system>Jenkins</system>\n+    <url>https://builds.apache.org/computer/lucene/</url>\n   </ciManagement>\n   <mailingLists>\n     <mailingList>\n@@ -109,15 +112,9 @@\n   </mailingLists>\n   <inceptionYear>2000</inceptionYear>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}</developerConnection>\n+    <url>${vc-browse-base-url}</url>\n   </scm>\n   <licenses>\n     <license>\n@@ -298,7 +295,7 @@\n       <dependency>\n         <groupId>org.apache.zookeeper</groupId>\n         <artifactId>zookeeper</artifactId>\n-        <version>3.3.5</version>\n+        <version>3.3.6</version>\n       </dependency>\n       <dependency>\n         <groupId>org.carrot2</groupId>\n@@ -549,11 +546,6 @@\n             </archive>\n           </configuration>\n         </plugin>\n-        <plugin>\n-          <groupId>org.codehaus.mojo</groupId>\n-          <artifactId>appassembler-maven-plugin</artifactId>\n-          <version>1.2.1</version>\n-        </plugin>\n         <plugin>\n           <groupId>org.codehaus.mojo</groupId>\n           <artifactId>build-helper-maven-plugin</artifactId>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/pom.xml.template",
                "sha": "0ed4cfc8f6bc0f013973edf05a15dbe5d192bd29",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/analysis-extras/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/analysis-extras/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/analysis-extras/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/analysis-extras/pom.xml.template",
                "sha": "4084e4e6497c6803c8a07ce6dccffa5232befd7f",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/clustering/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/clustering/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/clustering/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/clustering/pom.xml.template",
                "sha": "5fa0ebb669092fc5522794e2f53e297f821aa6c0",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/dataimporthandler-extras/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/dataimporthandler-extras/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/dataimporthandler-extras/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/dataimporthandler-extras/pom.xml.template",
                "sha": "79f505891086685843213115a25923a1b4193da0",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/dataimporthandler/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/dataimporthandler/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/dataimporthandler/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/dataimporthandler/pom.xml.template",
                "sha": "e1a7894936b456789c03d1b54a7242ebf57e3c33",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/extraction/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/extraction/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/extraction/pom.xml.template",
                "patch": "@@ -41,15 +41,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/extraction/pom.xml.template",
                "sha": "5b235868601cc9f15c93557fdfebb682b507f8ee",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/langid/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/langid/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/langid/pom.xml.template",
                "patch": "@@ -42,15 +42,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/langid/pom.xml.template",
                "sha": "cf4dd8a874fbec44f7c453007133ce43ef2cae98",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/uima/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/uima/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/uima/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/uima/pom.xml.template",
                "sha": "b671ec9f8d54c8deaecd012ad9314244d446e8cb",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/velocity/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/contrib/velocity/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/contrib/velocity/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/contrib/velocity/pom.xml.template",
                "sha": "51ff782366561bbff0255d37b93857a738ea5509",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/core/pom.xml.template",
                "changes": 43,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/core/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 40,
                "filename": "dev-tools/maven/solr/core/pom.xml.template",
                "patch": "@@ -38,15 +38,9 @@\n     <surefire-top-level>${top-level}/../..</surefire-top-level>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>\n@@ -254,37 +248,6 @@\n           </systemPropertyVariables>\n         </configuration>\n       </plugin>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>appassembler-maven-plugin</artifactId>\n-        <configuration>\n-          <extraJvmArguments>-Xmx128M</extraJvmArguments>\n-          <repositoryLayout>flat</repositoryLayout>\n-          <platforms>\n-            <platform>windows</platform>\n-            <platform>unix</platform>\n-          </platforms>\n-          <programs>\n-            <program>\n-              <mainClass>org.apache.solr.client.solrj.embedded.JettySolrRunner</mainClass>\n-              <name>JettySolrRunner</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.solr.util.BitSetPerf</mainClass>\n-              <name>BitSetPerf</name>\n-              <extraJvmArguments>-Xms128m -Xbatch</extraJvmArguments>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.solr.util.SimplePostTool</mainClass>\n-              <name>SimplePostTool</name>\n-            </program>\n-            <program>\n-              <mainClass>org.apache.solr.util.SuggestMissingFactories</mainClass>\n-              <name>SuggestMissingFactories</name>\n-            </program>\n-          </programs>\n-        </configuration>\n-      </plugin>\n       <plugin>\n         <groupId>org.codehaus.mojo</groupId>\n         <artifactId>build-helper-maven-plugin</artifactId>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/core/pom.xml.template",
                "sha": "22f4cd23d018bd5584cb56ef4b10a62f15143831",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/pom.xml.template",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 16,
                "filename": "dev-tools/maven/solr/pom.xml.template",
                "patch": "@@ -43,26 +43,14 @@\n     <module-directory>solr</module-directory>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <issueManagement>\n     <system>JIRA</system>\n-    <url>http://issues.apache.org/jira/browse/SOLR</url>\n+    <url>https://issues.apache.org/jira/browse/SOLR</url>\n   </issueManagement>\n-  <ciManagement>\n-    <system>Hudson</system>\n-    <url>\n-      http://lucene.zones.apache.org:8080/hudson/job/Solr-Nightly/\n-    </url>\n-  </ciManagement>\n   <mailingLists>\n     <mailingList>\n       <name>Solr User List</name>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/pom.xml.template",
                "sha": "6c546006a702b63fd4440f8980693f6f5251be9d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/solrj/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/solrj/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/solrj/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/solrj/pom.xml.template",
                "sha": "68904112e8ce137a9e5222deaa0be7e06c0dd728",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/test-framework/pom.xml.template",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/test-framework/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 13,
                "filename": "dev-tools/maven/solr/test-framework/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <!-- These dependencies are compile scope because this is a test framework. -->\n@@ -60,20 +54,27 @@\n       <artifactId>solr-core</artifactId>\n       <version>${project.version}</version>\n     </dependency>\n+    <dependency>\n+      <groupId>javax.servlet</groupId>\n+      <artifactId>servlet-api</artifactId>\n+    </dependency>\n     <dependency>\n       <groupId>junit</groupId>\n       <artifactId>junit</artifactId>\n     </dependency>\n-    <!-- If your tests don't use BaseDistributedSearchTestCase or SolrJettyTestBase,\n-         you can exclude the three Jetty dependencies below. -->\n     <dependency>\n       <groupId>org.eclipse.jetty</groupId>\n-      <artifactId>jetty-server</artifactId>\n-      <scope>runtime</scope>\n+      <artifactId>jetty-servlet</artifactId>\n     </dependency>\n     <dependency>\n       <groupId>org.eclipse.jetty</groupId>\n       <artifactId>jetty-util</artifactId>\n+    </dependency>\n+    <!-- If your tests don't use BaseDistributedSearchTestCase or SolrJettyTestBase,\n+         you can exclude the two Jetty dependencies below. -->\n+    <dependency>\n+      <groupId>org.eclipse.jetty</groupId>\n+      <artifactId>jetty-server</artifactId>\n       <scope>runtime</scope>\n     </dependency>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/test-framework/pom.xml.template",
                "sha": "5735f54f5e831782be51e313e331fb77905f1897",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/webapp/pom.xml.template",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/maven/solr/webapp/pom.xml.template?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 9,
                "filename": "dev-tools/maven/solr/webapp/pom.xml.template",
                "patch": "@@ -37,15 +37,9 @@\n     <module-path>${top-level}/${module-directory}</module-path>\n   </properties>\n   <scm>\n-    <connection>\n-      scm:svn:http://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </connection>\n-    <developerConnection>\n-      scm:svn:https://svn.apache.org/repos/asf/lucene/dev/trunk/${module-directory}\n-    </developerConnection>\n-    <url>\n-      http://svn.apache.org/viewvc/lucene/dev/trunk/${module-directory}\n-    </url>\n+    <connection>scm:svn:${vc-anonymous-base-url}/${module-directory}</connection>\n+    <developerConnection>scm:svn:${vc-dev-base-url}/${module-directory}</developerConnection>\n+    <url>${vc-browse-base-url}/${module-directory}</url>\n   </scm>\n   <dependencies>\n     <dependency>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/maven/solr/webapp/pom.xml.template",
                "sha": "ce20f26b761a2f57b891840a313b983b0781d6b3",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/scripts/checkJavaDocs.py",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/scripts/checkJavaDocs.py?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 17,
                "filename": "dev-tools/scripts/checkJavaDocs.py",
                "patch": "@@ -23,7 +23,7 @@\n \n def checkSummary(fullPath):\n   printed = False\n-  f = open(fullPath)\n+  f = open(fullPath, encoding='UTF-8')\n   anyMissing = False\n   sawPackage = False\n   desc = []\n@@ -41,28 +41,28 @@ def checkSummary(fullPath):\n           desc = desc.strip()\n           if desc == '':\n             if not printed:\n-              print\n-              print fullPath\n+              print()\n+              print(fullPath)\n               printed = True\n-            print '  no package description (missing package.html in src?)'\n+            print('  no package description (missing package.html in src?)')\n             anyMissing = True\n           desc = None\n         else:\n           desc.append(lineLower)\n       \n     if lineLower in ('<td>&nbsp;</td>', '<td></td>', '<td class=\"collast\">&nbsp;</td>'):\n       if not printed:\n-        print\n-        print fullPath\n+        print()\n+        print(fullPath)\n         printed = True\n-      print '  missing: %s' % unescapeHTML(lastHREF)\n+      print('  missing: %s' % unescapeHTML(lastHREF))\n       anyMissing = True\n     elif lineLower.find('licensed to the apache software foundation') != -1 or lineLower.find('copyright 2004 the apache software foundation') != -1:\n       if not printed:\n-        print\n-        print fullPath\n+        print()\n+        print(fullPath)\n         printed = True\n-      print '  license-is-javadoc: %s' % unescapeHTML(lastHREF)\n+      print('  license-is-javadoc: %s' % unescapeHTML(lastHREF))\n       anyMissing = True\n     m = reHREF.search(line)\n     if m is not None:\n@@ -85,17 +85,17 @@ def checkPackageSummaries(root, level='class'):\n   \"\"\"\n \n   if level != 'class' and level != 'package':\n-    print 'unsupported level: %s, must be \"class\" or \"package\"' % level\n+    print('unsupported level: %s, must be \"class\" or \"package\"' % level)\n     sys.exit(1)\n   \n   #for dirPath, dirNames, fileNames in os.walk('%s/lucene/build/docs/api' % root):\n \n   if False:\n     os.chdir(root)\n-    print\n-    print 'Run \"ant javadocs\" > javadocs.log...'\n+    print()\n+    print('Run \"ant javadocs\" > javadocs.log...')\n     if os.system('ant javadocs > javadocs.log 2>&1'):\n-      print '  FAILED'\n+      print('  FAILED')\n       sys.exit(1)\n     \n   anyMissing = False\n@@ -116,14 +116,14 @@ def checkPackageSummaries(root, level='class'):\n \n if __name__ == '__main__':\n   if len(sys.argv) < 2 or len(sys.argv) > 3:\n-    print 'usage: %s <dir> [class|package]' % sys.argv[0]\n+    print('usage: %s <dir> [class|package]' % sys.argv[0])\n     sys.exit(1)\n   if len(sys.argv) == 2:\n     level = 'class'\n   else:\n     level = sys.argv[2]\n   if checkPackageSummaries(sys.argv[1], level):\n-    print\n-    print 'Missing javadocs were found!'\n+    print()\n+    print('Missing javadocs were found!')\n     sys.exit(1)\n   sys.exit(0)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/scripts/checkJavaDocs.py",
                "sha": "459341b54402fb4870f21b6f5d5907f5c4edf059",
                "status": "modified"
            },
            {
                "additions": 129,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/scripts/smokeTestRelease.py",
                "changes": 243,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/dev-tools/scripts/smokeTestRelease.py?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 114,
                "filename": "dev-tools/scripts/smokeTestRelease.py",
                "patch": "@@ -20,12 +20,12 @@\n import signal\n import shutil\n import hashlib\n-import httplib\n+import http.client\n import re\n-import urllib2\n-import urlparse\n+import urllib.request, urllib.error, urllib.parse\n+import urllib.parse\n import sys\n-import HTMLParser\n+import html.parser\n from collections import defaultdict\n import xml.etree.ElementTree as ET\n import filecmp\n@@ -38,9 +38,9 @@\n # tested on Linux and on Cygwin under Windows 7.\n \n def unshortenURL(url):\n-  parsed = urlparse.urlparse(url)\n+  parsed = urllib.parse.urlparse(url)\n   if parsed[0] in ('http', 'https'):\n-    h = httplib.HTTPConnection(parsed.netloc)\n+    h = http.client.HTTPConnection(parsed.netloc)\n     h.request('HEAD', parsed.path)\n     response = h.getresponse()\n     if response.status/100 == 3 and response.getheader('Location'):\n@@ -101,8 +101,8 @@ def getHREFs(urlString):\n \n   # Deref any redirects\n   while True:\n-    url = urlparse.urlparse(urlString)\n-    h = httplib.HTTPConnection(url.netloc)\n+    url = urllib.parse.urlparse(urlString)\n+    h = http.client.HTTPConnection(url.netloc)\n     h.request('GET', url.path)\n     r = h.getresponse()\n     newLoc = r.getheader('location')\n@@ -112,24 +112,24 @@ def getHREFs(urlString):\n       break\n \n   links = []\n-  for subUrl, text in reHREF.findall(urllib2.urlopen(urlString).read()):\n-    fullURL = urlparse.urljoin(urlString, subUrl)\n+  for subUrl, text in reHREF.findall(urllib.request.urlopen(urlString).read().decode('UTF-8')):\n+    fullURL = urllib.parse.urljoin(urlString, subUrl)\n     links.append((text, fullURL))\n   return links\n \n def download(name, urlString, tmpDir, quiet=False):\n   fileName = '%s/%s' % (tmpDir, name)\n   if DEBUG and os.path.exists(fileName):\n     if not quiet and fileName.find('.asc') == -1:\n-      print '    already done: %.1f MB' % (os.path.getsize(fileName)/1024./1024.)\n+      print('    already done: %.1f MB' % (os.path.getsize(fileName)/1024./1024.))\n     return\n-  fIn = urllib2.urlopen(urlString)\n+  fIn = urllib.request.urlopen(urlString)\n   fOut = open(fileName, 'wb')\n   success = False\n   try:\n     while True:\n       s = fIn.read(65536)\n-      if s == '':\n+      if s == b'':\n         break\n       fOut.write(s)\n     fOut.close()\n@@ -141,14 +141,14 @@ def download(name, urlString, tmpDir, quiet=False):\n     if not success:\n       os.remove(fileName)\n   if not quiet and fileName.find('.asc') == -1:\n-    print '    %.1f MB' % (os.path.getsize(fileName)/1024./1024.)\n+    print('    %.1f MB' % (os.path.getsize(fileName)/1024./1024.))\n     \n def load(urlString):\n-  return urllib2.urlopen(urlString).read()\n+  return urllib.request.urlopen(urlString).read().decode('utf-8')\n   \n def checkSigs(project, urlString, version, tmpDir, isSigned):\n \n-  print '  test basics...'\n+  print('  test basics...')\n   ents = getDirEntries(urlString)\n   artifact = None\n   keysURL = None\n@@ -210,7 +210,7 @@ def checkSigs(project, urlString, version, tmpDir, isSigned):\n   if keysURL is None:\n     raise RuntimeError('%s is missing KEYS' % project)\n \n-  print '  get KEYS'\n+  print('  get KEYS')\n   download('%s.KEYS' % project, keysURL, tmpDir)\n \n   keysFile = '%s/%s.KEYS' % (tmpDir, project)\n@@ -219,7 +219,7 @@ def checkSigs(project, urlString, version, tmpDir, isSigned):\n   gpgHomeDir = '%s/%s.gpg' % (tmpDir, project)\n   if os.path.exists(gpgHomeDir):\n     shutil.rmtree(gpgHomeDir)\n-  os.makedirs(gpgHomeDir, 0700)\n+  os.makedirs(gpgHomeDir, 0o700)\n   run('gpg --homedir %s --import %s' % (gpgHomeDir, keysFile),\n       '%s/%s.gpg.import.log 2>&1' % (tmpDir, project))\n \n@@ -232,12 +232,12 @@ def checkSigs(project, urlString, version, tmpDir, isSigned):\n     testChanges(project, version, changesURL)\n \n   for artifact, urlString in artifacts:\n-    print '  download %s...' % artifact\n+    print('  download %s...' % artifact)\n     download(artifact, urlString, tmpDir)\n     verifyDigests(artifact, urlString, tmpDir)\n \n     if isSigned:\n-      print '    verify sig'\n+      print('    verify sig')\n       # Test sig (this is done with a clean brand-new GPG world)\n       download(artifact + '.asc', urlString + '.asc', tmpDir)\n       sigFile = '%s/%s.asc' % (tmpDir, artifact)\n@@ -246,28 +246,28 @@ def checkSigs(project, urlString, version, tmpDir, isSigned):\n       run('gpg --homedir %s --verify %s %s' % (gpgHomeDir, sigFile, artifactFile),\n           logFile)\n       # Forward any GPG warnings, except the expected one (since its a clean world)\n-      f = open(logFile, 'rb')\n+      f = open(logFile, encoding='UTF-8')\n       for line in f.readlines():\n         if line.lower().find('warning') != -1 \\\n         and line.find('WARNING: This key is not certified with a trusted signature') == -1:\n-          print '      GPG: %s' % line.strip()\n+          print('      GPG: %s' % line.strip())\n       f.close()\n \n       # Test trust (this is done with the real users config)\n       run('gpg --import %s' % (keysFile),\n           '%s/%s.gpg.trust.import.log 2>&1' % (tmpDir, project))\n-      print '    verify trust'\n+      print('    verify trust')\n       logFile = '%s/%s.%s.gpg.trust.log' % (tmpDir, project, artifact)\n       run('gpg --verify %s %s' % (sigFile, artifactFile), logFile)\n       # Forward any GPG warnings:\n-      f = open(logFile, 'rb')\n+      f = open(logFile, encoding='UTF-8')\n       for line in f.readlines():\n         if line.lower().find('warning') != -1:\n-          print '      GPG: %s' % line.strip()\n+          print('      GPG: %s' % line.strip())\n       f.close()\n \n def testChanges(project, version, changesURLString):\n-  print '  check changes HTML...'\n+  print('  check changes HTML...')\n   changesURL = None\n   for text, subURL in getDirEntries(changesURLString):\n     if text == 'Changes.html':\n@@ -287,7 +287,7 @@ def testChangesText(dir, version, project):\n     if 'CHANGES.txt' in files:\n       fullPath = '%s/CHANGES.txt' % root\n       #print 'CHECK %s' % fullPath\n-      checkChangesContent(open(fullPath).read(), version, fullPath, project, False)\n+      checkChangesContent(open(fullPath, encoding='UTF-8').read(), version, fullPath, project, False)\n       \n def checkChangesContent(s, version, name, project, isHTML):\n \n@@ -336,7 +336,7 @@ def run(command, logFile):\n     raise RuntimeError('command \"%s\" failed; see log file %s' % (command, logPath))\n     \n def verifyDigests(artifact, urlString, tmpDir):\n-  print '    verify md5/sha1 digests'\n+  print('    verify md5/sha1 digests')\n   md5Expected, t = load(urlString + '.md5').strip().split()\n   if t != '*'+artifact:\n     raise RuntimeError('MD5 %s.md5 lists artifact %s but expected *%s' % (urlString, t, artifact))\n@@ -347,10 +347,10 @@ def verifyDigests(artifact, urlString, tmpDir):\n   \n   m = hashlib.md5()\n   s = hashlib.sha1()\n-  f = open('%s/%s' % (tmpDir, artifact))\n+  f = open('%s/%s' % (tmpDir, artifact), 'rb')\n   while True:\n     x = f.read(65536)\n-    if x == '':\n+    if len(x) == 0:\n       break\n     m.update(x)\n     s.update(x)\n@@ -363,6 +363,10 @@ def verifyDigests(artifact, urlString, tmpDir):\n     raise RuntimeError('SHA1 digest mismatch for %s: expected %s but got %s' % (artifact, sha1Expected, sha1Actual))\n \n def getDirEntries(urlString):\n+  if urlString.startswith('file:/') and not urlString.startswith('file://'):\n+    # stupid bogus ant URI\n+    urlString = \"file:///\" + urlString[6:]\n+\n   if urlString.startswith('file://'):\n     path = urlString[7:]\n     if path.endswith('/'):\n@@ -388,7 +392,7 @@ def unpack(project, tmpDir, artifact, version):\n     shutil.rmtree(destDir)\n   os.makedirs(destDir)\n   os.chdir(destDir)\n-  print '    unpack %s...' % artifact\n+  print('    unpack %s...' % artifact)\n   unpackLogFile = '%s/%s-unpack-%s.log' % (tmpDir, project, artifact)\n   if artifact.endswith('.tar.gz') or artifact.endswith('.tgz'):\n     run('tar xzf %s/%s' % (tmpDir, artifact), unpackLogFile)\n@@ -437,12 +441,14 @@ def verifyUnpacked(project, artifact, unpackPath, version, tmpDir):\n \n   if project == 'lucene':\n     # TODO: clean this up to not be a list of modules that we must maintain\n-    extras = ('analysis', 'benchmark', 'core', 'demo', 'docs', 'facet', 'grouping', 'highlighter', 'join', 'memory', 'misc', 'queries', 'queryparser', 'sandbox', 'spatial', 'suggest', 'test-framework')\n+    extras = ('analysis', 'benchmark', 'core', 'demo', 'docs', 'facet', 'grouping', 'highlighter', 'join', 'memory', 'misc', 'queries', 'queryparser', 'sandbox', 'spatial', 'suggest', 'test-framework', 'licenses')\n     if isSrc:\n       extras += ('build.xml', 'common-build.xml', 'module-build.xml', 'ivy-settings.xml', 'backwards', 'tools', 'site')\n   else:\n     extras = ()\n \n+  # TODO: if solr, verify lucene/licenses, solr/licenses are present\n+\n   for e in extras:\n     if e not in l:\n       raise RuntimeError('%s: %s missing from artifact %s' % (project, e, artifact))\n@@ -453,81 +459,81 @@ def verifyUnpacked(project, artifact, unpackPath, version, tmpDir):\n       raise RuntimeError('%s: unexpected files/dirs in artifact %s: %s' % (project, artifact, l))\n \n   if isSrc:\n-    print '    make sure no JARs/WARs in src dist...'\n+    print('    make sure no JARs/WARs in src dist...')\n     lines = os.popen('find . -name \\\\*.jar').readlines()\n     if len(lines) != 0:\n-      print '    FAILED:'\n+      print('    FAILED:')\n       for line in lines:\n-        print '      %s' % line.strip()\n+        print('      %s' % line.strip())\n       raise RuntimeError('source release has JARs...')\n     lines = os.popen('find . -name \\\\*.war').readlines()\n     if len(lines) != 0:\n-      print '    FAILED:'\n+      print('    FAILED:')\n       for line in lines:\n-        print '      %s' % line.strip()\n+        print('      %s' % line.strip())\n       raise RuntimeError('source release has WARs...')\n \n-    print '    run \"ant validate\"'\n+    print('    run \"ant validate\"')\n     run('%s; ant validate' % javaExe('1.7'), '%s/validate.log' % unpackPath)\n \n     if project == 'lucene':\n-      print '    run tests w/ Java 6...'\n+      print('    run tests w/ Java 6...')\n       run('%s; ant test' % javaExe('1.6'), '%s/test.log' % unpackPath)\n       run('%s; ant jar' % javaExe('1.6'), '%s/compile.log' % unpackPath)\n       testDemo(isSrc, version)\n       # test javadocs\n-      print '    generate javadocs w/ Java 6...'\n+      print('    generate javadocs w/ Java 6...')\n       run('%s; ant javadocs' % javaExe('1.6'), '%s/javadocs.log' % unpackPath)\n       checkJavadocpath('%s/build/docs' % unpackPath)\n     else:\n-      print '    run tests w/ Java 6...'\n+      print('    run tests w/ Java 6...')\n       run('%s; ant test' % javaExe('1.6'), '%s/test.log' % unpackPath)\n \n       # test javadocs\n-      print '    generate javadocs w/ Java 6...'\n+      print('    generate javadocs w/ Java 6...')\n       run('%s; ant javadocs' % javaExe('1.6'), '%s/javadocs.log' % unpackPath)\n       checkJavadocpath('%s/build/docs' % unpackPath)\n \n-      print '    run tests w/ Java 7...'\n+      print('    run tests w/ Java 7...')\n       run('%s; ant test' % javaExe('1.7'), '%s/test.log' % unpackPath)\n  \n       # test javadocs\n-      print '    generate javadocs w/ Java 7...'\n+      print('    generate javadocs w/ Java 7...')\n       run('%s; ant javadocs' % javaExe('1.7'), '%s/javadocs.log' % unpackPath)\n       checkJavadocpath('%s/build/docs' % unpackPath)\n \n       os.chdir('solr')\n-      print '    test solr example w/ Java 6...'\n+      print('    test solr example w/ Java 6...')\n       run('%s; ant clean example' % javaExe('1.6'), '%s/antexample.log' % unpackPath)\n       testSolrExample(unpackPath, JAVA6_HOME, True)\n \n-      print '    test solr example w/ Java 7...'\n+      print('    test solr example w/ Java 7...')\n       run('%s; ant clean example' % javaExe('1.7'), '%s/antexample.log' % unpackPath)\n       testSolrExample(unpackPath, JAVA7_HOME, True)\n       os.chdir('..')\n \n-      print '    check NOTICE'\n+      print('    check NOTICE')\n       testNotice(unpackPath)\n \n   else:\n     if project == 'lucene':\n       testDemo(isSrc, version)\n     else:\n-      print '    test solr example w/ Java 6...'\n+      print('    test solr example w/ Java 6...')\n       testSolrExample(unpackPath, JAVA6_HOME, False)\n \n-      print '    test solr example w/ Java 7...'\n+      print('    test solr example w/ Java 7...')\n       testSolrExample(unpackPath, JAVA7_HOME, False)\n \n   testChangesText('.', version, project)\n \n   if project == 'lucene' and not isSrc:\n-    print '    check Lucene\\'s javadoc JAR'\n+    print('    check Lucene\\'s javadoc JAR')\n     checkJavadocpath('%s/docs' % unpackPath)\n \n def testNotice(unpackPath):\n-  solrNotice = open('%s/NOTICE.txt' % unpackPath).read()\n-  luceneNotice = open('%s/lucene/NOTICE.txt' % unpackPath).read()\n+  solrNotice = open('%s/NOTICE.txt' % unpackPath, encoding='UTF-8').read()\n+  luceneNotice = open('%s/lucene/NOTICE.txt' % unpackPath, encoding='UTF-8').read()\n \n   expected = \"\"\"\n =========================================================================\n@@ -545,20 +551,20 @@ def readSolrOutput(p, startupEvent, logFile):\n   try:\n     while True:\n       line = p.readline()\n-      if line == '':\n+      if len(line) == 0:\n         break\n       f.write(line)\n       f.flush()\n       # print 'SOLR: %s' % line.strip()\n-      if line.find('Started SocketConnector@0.0.0.0:8983') != -1:\n+      if line.decode('UTF-8').find('Started SocketConnector@0.0.0.0:8983') != -1:\n         startupEvent.set()\n   finally:\n     f.close()\n     \n def testSolrExample(unpackPath, javaPath, isSrc):\n   logFile = '%s/solr-example.log' % unpackPath\n   os.chdir('example')\n-  print '      start Solr instance (log=%s)...' % logFile\n+  print('      start Solr instance (log=%s)...' % logFile)\n   env = {}\n   env.update(os.environ)\n   env['JAVA_HOME'] = javaPath\n@@ -572,36 +578,36 @@ def testSolrExample(unpackPath, javaPath, isSrc):\n \n   # Make sure Solr finishes startup:\n   startupEvent.wait()\n-  print '      startup done'\n+  print('      startup done')\n   \n   try:\n-    print '      test utf8...'\n+    print('      test utf8...')\n     run('sh ./exampledocs/test_utf8.sh', 'utf8.log')\n-    print '      index example docs...'\n+    print('      index example docs...')\n     run('sh ./exampledocs/post.sh ./exampledocs/*.xml', 'post-example-docs.log')\n-    print '      run query...'\n-    s = urllib2.urlopen('http://localhost:8983/solr/select/?q=video').read()\n+    print('      run query...')\n+    s = urllib.request.urlopen('http://localhost:8983/solr/select/?q=video').read().decode('UTF-8')\n     if s.find('<result name=\"response\" numFound=\"3\" start=\"0\">') == -1:\n-      print 'FAILED: response is:\\n%s' % s\n+      print('FAILED: response is:\\n%s' % s)\n       raise RuntimeError('query on solr example instance failed')\n   finally:\n     # Stop server:\n-    print '      stop server (SIGINT)...'\n+    print('      stop server (SIGINT)...')\n     os.kill(server.pid, signal.SIGINT)\n \n     # Give it 10 seconds to gracefully shut down\n     serverThread.join(10.0)\n \n     if serverThread.isAlive():\n       # Kill server:\n-      print '***WARNING***: Solr instance didn\\'t respond to SIGINT; using SIGKILL now...'\n+      print('***WARNING***: Solr instance didn\\'t respond to SIGINT; using SIGKILL now...')\n       os.kill(server.pid, signal.SIGKILL)\n \n       serverThread.join(10.0)\n \n       if serverThread.isAlive():\n         # Shouldn't happen unless something is seriously wrong...\n-        print '***WARNING***: Solr instance didn\\'t respond to SIGKILL; ignoring...'\n+        print('***WARNING***: Solr instance didn\\'t respond to SIGKILL; ignoring...')\n \n   os.chdir('..')\n     \n@@ -615,13 +621,13 @@ def checkJavadocpath(path):\n   if checkJavaDocs.checkPackageSummaries(path):\n     # disabled: RM cannot fix all this, see LUCENE-3887\n     # raise RuntimeError('javadoc problems')\n-    print '\\n***WARNING***: javadocs want to fail!\\n'\n+    print('\\n***WARNING***: javadocs want to fail!\\n')\n \n   if checkJavadocLinks.checkAll(path):\n     raise RuntimeError('broken javadocs links found!')\n \n def testDemo(isSrc, version):\n-  print '    test demo...'\n+  print('    test demo...')\n   sep = ';' if cygwin else ':'\n   if isSrc:\n     cp = 'build/core/classes/java{0}build/demo/classes/java{0}build/analysis/common/classes/java{0}build/queryparser/classes/java'.format(sep)\n@@ -632,14 +638,14 @@ def testDemo(isSrc, version):\n   run('%s; java -cp \"%s\" org.apache.lucene.demo.IndexFiles -index index -docs %s' % (javaExe('1.6'), cp, docsDir), 'index.log')\n   run('%s; java -cp \"%s\" org.apache.lucene.demo.SearchFiles -index index -query lucene' % (javaExe('1.6'), cp), 'search.log')\n   reMatchingDocs = re.compile('(\\d+) total matching documents')\n-  m = reMatchingDocs.search(open('search.log', 'rb').read())\n+  m = reMatchingDocs.search(open('search.log', encoding='UTF-8').read())\n   if m is None:\n     raise RuntimeError('lucene demo\\'s SearchFiles found no results')\n   else:\n     numHits = int(m.group(1))\n     if numHits < 100:\n       raise RuntimeError('lucene demo\\'s SearchFiles found too few results: %s' % numHits)\n-    print '      got %d hits for query \"lucene\"' % numHits\n+    print('      got %d hits for query \"lucene\"' % numHits)\n \n def checkMaven(baseURL, tmpDir, version, isSigned):\n   # Locate the release branch in subversion\n@@ -652,42 +658,42 @@ def checkMaven(baseURL, tmpDir, version, isSigned):\n     if text == releaseBranchText:\n       releaseBranchSvnURL = subURL\n \n-  print '    get POM templates',\n+  print('    get POM templates', end=' ')\n   POMtemplates = defaultdict()\n   getPOMtemplates(POMtemplates, tmpDir, releaseBranchSvnURL)\n-  print\n-  print '    download artifacts',\n+  print()\n+  print('    download artifacts', end=' ')\n   artifacts = {'lucene': [], 'solr': []}\n   for project in ('lucene', 'solr'):\n     artifactsURL = '%s/%s/maven/org/apache/%s' % (baseURL, project, project)\n     targetDir = '%s/maven/org/apache/%s' % (tmpDir, project)\n     if not os.path.exists(targetDir):\n       os.makedirs(targetDir)\n     crawl(artifacts[project], artifactsURL, targetDir)\n-  print\n-  print '    verify that each binary artifact has a deployed POM...'\n+  print()\n+  print('    verify that each binary artifact has a deployed POM...')\n   verifyPOMperBinaryArtifact(artifacts, version)\n-  print '    verify that there is an artifact for each POM template...'\n+  print('    verify that there is an artifact for each POM template...')\n   verifyArtifactPerPOMtemplate(POMtemplates, artifacts, tmpDir, version)\n-  print \"    verify Maven artifacts' md5/sha1 digests...\"\n+  print(\"    verify Maven artifacts' md5/sha1 digests...\")\n   verifyMavenDigests(artifacts)\n-  print '    verify that all non-Mavenized deps are deployed...'\n+  print('    verify that all non-Mavenized deps are deployed...')\n   nonMavenizedDeps = dict()\n   checkNonMavenizedDeps(nonMavenizedDeps, POMtemplates, artifacts, tmpDir,\n                         version, releaseBranchSvnURL)\n-  print '    check for javadoc and sources artifacts...'\n+  print('    check for javadoc and sources artifacts...')\n   checkJavadocAndSourceArtifacts(nonMavenizedDeps, artifacts, version)\n-  print \"    verify deployed POMs' coordinates...\"\n+  print(\"    verify deployed POMs' coordinates...\")\n   verifyDeployedPOMsCoordinates(artifacts, version)\n   if isSigned:\n-    print '    verify maven artifact sigs',\n+    print('    verify maven artifact sigs', end=' ')\n     verifyMavenSigs(baseURL, tmpDir, artifacts)\n \n   distributionFiles = getDistributionsForMavenChecks(tmpDir, version, baseURL)\n \n-  print '    verify that non-Mavenized deps are same as in the binary distribution...'\n+  print('    verify that non-Mavenized deps are same as in the binary distribution...')\n   checkIdenticalNonMavenizedDeps(distributionFiles, nonMavenizedDeps)\n-  print '    verify that Maven artifacts are same as in the binary distribution...'\n+  print('    verify that Maven artifacts are same as in the binary distribution...')\n   checkIdenticalMavenArtifacts(distributionFiles, nonMavenizedDeps, artifacts, version)\n \n def getDistributionsForMavenChecks(tmpDir, version, baseURL):\n@@ -697,19 +703,19 @@ def getDistributionsForMavenChecks(tmpDir, version, baseURL):\n     if project == 'solr': distribution = 'apache-' + distribution\n     if not os.path.exists('%s/%s' % (tmpDir, distribution)):\n       distURL = '%s/%s/%s' % (baseURL, project, distribution)\n-      print '    download %s...' % distribution,\n+      print('    download %s...' % distribution, end=' ')\n       download(distribution, distURL, tmpDir)\n     destDir = '%s/unpack-%s-maven' % (tmpDir, project)\n     if os.path.exists(destDir):\n       shutil.rmtree(destDir)\n     os.makedirs(destDir)\n     os.chdir(destDir)\n-    print '    unpack %s...' % distribution\n+    print('    unpack %s...' % distribution)\n     unpackLogFile = '%s/unpack-%s-maven-checks.log' % (tmpDir, distribution)\n     run('tar xzf %s/%s' % (tmpDir, distribution), unpackLogFile)\n     if project == 'solr': # unpack the Solr war\n       unpackLogFile = '%s/unpack-solr-war-maven-checks.log' % tmpDir\n-      print '        unpack Solr war...'\n+      print('        unpack Solr war...')\n       run('jar xvf */dist/*.war', unpackLogFile)\n     distributionFiles[project] = []\n     for root, dirs, files in os.walk(destDir):\n@@ -719,7 +725,7 @@ def getDistributionsForMavenChecks(tmpDir, version, baseURL):\n def checkJavadocAndSourceArtifacts(nonMavenizedDeps, artifacts, version):\n   for project in ('lucene', 'solr'):\n     for artifact in artifacts[project]:\n-      if artifact.endswith(version + '.jar') and artifact not in nonMavenizedDeps.keys():\n+      if artifact.endswith(version + '.jar') and artifact not in list(nonMavenizedDeps.keys()):\n         javadocJar = artifact[:-4] + '-javadoc.jar'\n         if javadocJar not in artifacts[project]:\n           raise RuntimeError('missing: %s' % javadocJar)\n@@ -732,7 +738,7 @@ def checkIdenticalNonMavenizedDeps(distributionFiles, nonMavenizedDeps):\n     distFilenames = dict()\n     for file in distributionFiles[project]:\n       distFilenames[os.path.basename(file)] = file\n-    for dep in nonMavenizedDeps.keys():\n+    for dep in list(nonMavenizedDeps.keys()):\n       if ('/%s/' % project) in dep:\n         depOrigFilename = os.path.basename(nonMavenizedDeps[dep])\n         if not depOrigFilename in distFilenames:\n@@ -753,9 +759,9 @@ def checkIdenticalMavenArtifacts(distributionFiles, nonMavenizedDeps, artifacts,\n       distFilenames[baseName] = file\n     for artifact in artifacts[project]:\n       if reJarWar.search(artifact):\n-        if artifact not in nonMavenizedDeps.keys():\n+        if artifact not in list(nonMavenizedDeps.keys()):\n           artifactFilename = os.path.basename(artifact)\n-          if artifactFilename not in distFilenames.keys():\n+          if artifactFilename not in list(distFilenames.keys()):\n             raise RuntimeError('Maven artifact %s is not present in %s binary distribution'\n                               % (artifact, project))\n          # TODO: Either fix the build to ensure that maven artifacts *are* identical, or recursively compare contents\n@@ -772,16 +778,17 @@ def verifyMavenDigests(artifacts):\n         raise RuntimeError('missing: MD5 digest for %s' % artifactFile)\n       if artifactFile + '.sha1' not in artifacts[project]:\n         raise RuntimeError('missing: SHA1 digest for %s' % artifactFile)\n-      with open(artifactFile + '.md5', 'r') as md5File:\n+      with open(artifactFile + '.md5', encoding='UTF-8') as md5File:\n         md5Expected = md5File.read().strip()\n-      with open(artifactFile + '.sha1', 'r') as sha1File:\n+      with open(artifactFile + '.sha1', encoding='UTF-8') as sha1File:\n         sha1Expected = sha1File.read().strip()\n       md5 = hashlib.md5()\n       sha1 = hashlib.sha1()\n-      inputFile = open(artifactFile)\n+      inputFile = open(artifactFile, 'rb')\n       while True:\n         bytes = inputFile.read(65536)\n-        if bytes == '': break\n+        if len(bytes) == 0:\n+          break\n         md5.update(bytes)\n         sha1.update(bytes)\n       inputFile.close()\n@@ -846,7 +853,7 @@ def checkNonMavenizedDeps(nonMavenizedDependencies, POMtemplates, artifacts,\n                 if releaseBranchSvnURL is None:\n                   pomPath = '%s/%s/%s' % (workingCopy, pomDir, pomFile)\n                   if os.path.exists(pomPath):\n-                    doc2 = ET.XML(open(pomPath).read())\n+                    doc2 = ET.XML(open(pomPath, encoding='UTF-8').read())\n                     break\n                 else:\n                   entries = getDirEntries('%s/%s' % (releaseBranchSvnURL, pomDir))\n@@ -891,7 +898,7 @@ def verifyMavenSigs(baseURL, tmpDir, artifacts):\n     gpgHomeDir = '%s/%s.gpg' % (tmpDir, project)\n     if os.path.exists(gpgHomeDir):\n       shutil.rmtree(gpgHomeDir)\n-    os.makedirs(gpgHomeDir, 0700)\n+    os.makedirs(gpgHomeDir, 0o700)\n     run('gpg --homedir %s --import %s' % (gpgHomeDir, keysFile),\n         '%s/%s.gpg.import.log' % (tmpDir, project))\n \n@@ -904,12 +911,12 @@ def verifyMavenSigs(baseURL, tmpDir, artifacts):\n       run('gpg --homedir %s --verify %s %s' % (gpgHomeDir, sigFile, artifactFile),\n           logFile)\n       # Forward any GPG warnings, except the expected one (since its a clean world)\n-      f = open(logFile, 'rb')\n+      f = open(logFile, encoding='UTF-8')\n       for line in f.readlines():\n         if line.lower().find('warning') != -1 \\\n            and line.find('WARNING: This key is not certified with a trusted signature') == -1 \\\n            and line.find('WARNING: using insecure memory') == -1:\n-          print '      GPG: %s' % line.strip()\n+          print('      GPG: %s' % line.strip())\n       f.close()\n \n       # Test trust (this is done with the real users config)\n@@ -918,16 +925,16 @@ def verifyMavenSigs(baseURL, tmpDir, artifacts):\n       logFile = '%s/%s.%s.gpg.trust.log' % (tmpDir, project, artifact)\n       run('gpg --verify %s %s' % (sigFile, artifactFile), logFile)\n       # Forward any GPG warnings:\n-      f = open(logFile, 'rb')\n+      f = open(logFile, encoding='UTF-8')\n       for line in f.readlines():\n         if line.lower().find('warning') != -1 \\\n            and line.find('WARNING: This key is not certified with a trusted signature') == -1 \\\n            and line.find('WARNING: using insecure memory') == -1:\n-          print '      GPG: %s' % line.strip()\n+          print('      GPG: %s' % line.strip())\n       f.close()\n \n       sys.stdout.write('.')\n-  print\n+  print()\n \n def verifyPOMperBinaryArtifact(artifacts, version):\n   \"\"\"verify that each binary jar and war has a corresponding POM file\"\"\"\n@@ -1023,17 +1030,20 @@ def crawl(downloadedFiles, urlString, targetDir, exclusions=set()):\n \n def main():\n \n-  if len(sys.argv) != 4:\n-    print\n-    print 'Usage python -u %s BaseURL version tmpDir' % sys.argv[0]\n-    print\n+  if len(sys.argv) < 4:\n+    print()\n+    print('Usage python -u %s BaseURL version tmpDir' % sys.argv[0])\n+    print()\n     sys.exit(1)\n \n   baseURL = sys.argv[1]\n   version = sys.argv[2]\n   tmpDir = os.path.abspath(sys.argv[3])\n+  isSigned = True \n+  if len(sys.argv) == 5:\n+    isSigned = (sys.argv[4] == \"True\")\n \n-  smokeTest(baseURL, version, tmpDir, True)\n+  smokeTest(baseURL, version, tmpDir, isSigned)\n \n def smokeTest(baseURL, version, tmpDir, isSigned):\n \n@@ -1046,11 +1056,11 @@ def smokeTest(baseURL, version, tmpDir, isSigned):\n   \n   lucenePath = None\n   solrPath = None\n-  print\n-  print 'Load release URL \"%s\"...' % baseURL\n+  print()\n+  print('Load release URL \"%s\"...' % baseURL)\n   newBaseURL = unshortenURL(baseURL)\n   if newBaseURL != baseURL:\n-    print '  unshortened: %s' % newBaseURL\n+    print('  unshortened: %s' % newBaseURL)\n     baseURL = newBaseURL\n     \n   for text, subURL in getDirEntries(baseURL):\n@@ -1064,23 +1074,28 @@ def smokeTest(baseURL, version, tmpDir, isSigned):\n   if solrPath is None:\n     raise RuntimeError('could not find solr subdir')\n \n-  print\n-  print 'Test Lucene...'\n+  print()\n+  print('Test Lucene...')\n   checkSigs('lucene', lucenePath, version, tmpDir, isSigned)\n   for artifact in ('lucene-%s.tgz' % version, 'lucene-%s.zip' % version):\n     unpack('lucene', tmpDir, artifact, version)\n   unpack('lucene', tmpDir, 'lucene-%s-src.tgz' % version, version)\n \n-  print\n-  print 'Test Solr...'\n+  print()\n+  print('Test Solr...')\n   checkSigs('solr', solrPath, version, tmpDir, isSigned)\n   for artifact in ('apache-solr-%s.tgz' % version, 'apache-solr-%s.zip' % version):\n     unpack('solr', tmpDir, artifact, version)\n   unpack('solr', tmpDir, 'apache-solr-%s-src.tgz' % version, version)\n \n-  print 'Test Maven artifacts for Lucene and Solr...'\n+  print('Test Maven artifacts for Lucene and Solr...')\n   checkMaven(baseURL, tmpDir, version, isSigned)\n \n if __name__ == '__main__':\n-  main()\n-  \n+  try:\n+    main()\n+  except:\n+    import traceback\n+    traceback.print_exc()\n+    sys.exit(1)\n+  sys.exit(0)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/dev-tools/scripts/smokeTestRelease.py",
                "sha": "42c07ca2656396fdacf9010922d9bcda4ecce090",
                "status": "modified"
            },
            {
                "additions": 80,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/CHANGES.txt",
                "changes": 80,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -6,6 +6,15 @@ http://s.apache.org/luceneversions\n \n ======================= Lucene 5.0.0 =======================\n \n+======================= Lucene 4.0.0 =======================\n+\n+Bug Fixes\n+\n+* LUCENE-4297: BooleanScorer2 would multiply the coord() factor\n+  twice for conjunctions: for most users this is no problem, but\n+  if you had a customized Similarity that returned something other\n+  than 1 when overlap == maxOverlap (always the case for conjunctions),\n+  then the score would be incorrect.  (Pascal Chollet, Robert Muir)\n \n ======================= Lucene 4.0.0-BETA =======================\n \n@@ -15,6 +24,9 @@ New features\n   underlying PayloadFunction's explanation as the explanation\n   for the payload score. (Scott Smerchek via Robert Muir)\n   \n+* LUCENE-4069: Added BloomFilteringPostingsFormat for use with low-frequency terms\n+  such as primary keys (Mark Harwood, Mike McCandless) \n+  \n * LUCENE-4201: Added JapaneseIterationMarkCharFilter to normalize Japanese\n   iteration marks. (Robert Muir, Christian Moen)\n \n@@ -34,6 +46,22 @@ New features\n   CharFilterFactories to the lucene-analysis module. The API is still\n   experimental.  (Chris Male, Robert Muir, Uwe Schindler)\n \n+* LUCENE-4230: When pulling a DocsAndPositionsEnum you can now\n+  specify whether or not you require payloads (in addition to\n+  offsets); turning one or both off may allow some codec\n+  implementations to optimize the enum implementation.  (Robert Muir,\n+  Mike McCandless)\n+\n+* LUCENE-4203: Add IndexWriter.tryDeleteDocument(AtomicReader reader,\n+  int docID), to attempt deletion by docID as long as the provided\n+  reader is an NRT reader, and the segment has not yet been merged\n+  away (Mike McCandless).\n+  \n+* LUCENE-4286: Added option to CJKBigramFilter to always also output\n+  unigrams. This can be used for a unigram+bigram approach, or at \n+  index-time only for better support of short queries.\n+  (Tom Burton-West, Robert Muir)\n+\n API Changes\n \n * LUCENE-4138: update of morfologik (Polish morphological analyzer) to 1.5.3.\n@@ -69,6 +97,23 @@ API Changes\n \n * LUCENE-3747: Support Unicode 6.1.0. (Steve Rowe)\n \n+* LUCENE-3884: Moved ElisionFilter out of org.apache.lucene.analysis.fr\n+  package into org.apache.lucene.analysis.util.  (Robert Muir)\n+\n+* LUCENE-4230: When pulling a DocsAndPositionsEnum you now pass an int\n+  flags instead of the previous boolean needOffsets.  Currently\n+  recognized flags are DocsAndPositionsEnum.FLAG_PAYLOADS and\n+  DocsAndPositionsEnum.FLAG_OFFSETS (Robert Muir, Mike McCandless)\n+\n+* LUCENE-4273: When pulling a DocsEnum, you can pass an int flags\n+  instead of the previous boolean needsFlags; consistent with the changes\n+  for DocsAndPositionsEnum in LUCENE-4230. Currently othe only flag\n+  is DocsEnum.FLAG_FREQS. (Robert Muir, Mike McCandless)\n+  \n+* LUCENE-3616: TextField(String, Reader, Store) was reduced to TextField(String, Reader),\n+  as the Store parameter didn't make sense: if you supplied Store.YES, you would only \n+  receive an exception anyway. (Robert Muir)\n+\n Optimizations\n \n * LUCENE-4171: Performance improvements to Packed64.\n@@ -80,8 +125,19 @@ Optimizations\n * LUCENE-4235: Remove enforcing of Filter rewrite for NRQ queries.\n   (Uwe Schindler)\n \n+* LUCENE-4279: Regenerated snowball Stemmers from snowball r554,\n+  making them substantially more lightweight. Behavior is unchanged. \n+  (Robert Muir)\n+\n+* LUCENE-4291: Reduced internal buffer size for Jflex-based tokenizers \n+  such as StandardTokenizer from 32kb to 8kb.  \n+  (Raintung Li, Steven Rowe, Robert Muir)\n+\n Bug Fixes\n \n+* LUCENE-4109: BooleanQueries are not parsed correctly with the \n+  flexible query parser. (Karsten Rauch via Robert Muir)\n+\n * LUCENE-4176: Fix AnalyzingQueryParser to analyze range endpoints as bytes,\n   so that it works correctly with Analyzers that produce binary non-UTF-8 terms\n   such as CollationAnalyzer. (Nattapong Sirilappanich via Robert Muir) \n@@ -113,6 +169,30 @@ Bug Fixes\n * LUCENE-4245: Make IndexWriter#close() and MergeScheduler#close()\n   non-interruptible.  (Mark Miller, Uwe Schindler)\n \n+* LUCENE-4190: restrict allowed filenames that a codec may create to\n+  the patterns recognized by IndexFileNames.  This also fixes\n+  IndexWriter to only delete files matching this pattern from an index\n+  directory, to reduce risk when the wrong index path is accidentally\n+  passed to IndexWriter (Robert Muir, Mike McCandless)\n+  \n+* LUCENE-4277: Fix IndexWriter deadlock during rollback if flushable DWPT\n+  instance are already checked out and queued up but not yet flushed. \n+  (Simon Willnauer)\n+\n+* LUCENE-4282: Automaton FuzzyQuery didnt always deliver all results.\n+  (Johannes Christen, Uwe Schindler, Robert Muir)\n+\n+* LUCENE-4289: Fix minor idf inconsistencies/inefficiencies in highlighter.\n+  (Robert Muir)\n+\n+Changes in Runtime Behavior\n+\n+* LUCENE-4109: Enable position increments in the flexible queryparser by default.\n+  (Karsten Rauch via Robert Muir)\n+  \n+* LUCENE-3616: Field throws exception if you try to set a boost on an \n+  unindexed field or one that omits norms. (Robert Muir)\n+\n Build\n \n * LUCENE-4094: Support overriding file.encoding on forked test JVMs",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/CHANGES.txt",
                "sha": "e2b7c05f4d916f9ba8e693e664ccb8128b0f0aea",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/MIGRATE.txt",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/MIGRATE.txt?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 29,
                "filename": "lucene/MIGRATE.txt",
                "patch": "@@ -57,30 +57,6 @@ enumeration APIs.  Here are the major changes:\n           ...\n         }\n \n-    The bulk read API has also changed.  Instead of this:\n-\n-        int[] docs = new int[256];\n-        int[] freqs = new int[256];\n-\n-        while(true) {\n-          int count = td.read(docs, freqs)\n-          if (count == 0) {\n-            break;\n-          }\n-          // use docs[i], freqs[i]\n-        }\n-\n-    do this:\n-\n-        DocsEnum.BulkReadResult bulk = td.getBulkResult();\n-        while(true) {\n-          int count = td.read();\n-          if (count == 0) {\n-            break;\n-          }\n-          // use bulk.docs.ints[i] and bulk.freqs.ints[i]\n-        }\n-\n   * TermPositions is renamed to DocsAndPositionsEnum, and no longer\n     extends the docs only enumerator (DocsEnum).\n \n@@ -170,7 +146,7 @@ enumeration APIs.  Here are the major changes:\n         Bits liveDocs = reader.getLiveDocs();\n         DocsEnum docsEnum = null;\n \n-        docsEnum = termsEnum.docs(liveDocs, docsEnum);\n+        docsEnum = termsEnum.docs(liveDocs, docsEnum, needsFreqs);\n \n     You can pass in a prior DocsEnum and it will be reused if possible.\n \n@@ -187,7 +163,7 @@ enumeration APIs.  Here are the major changes:\n \n         String field;\n         BytesRef text;\n-        DocsEnum docsEnum = reader.termDocsEnum(reader.getLiveDocs(), field, text);\n+        DocsEnum docsEnum = reader.termDocsEnum(reader.getLiveDocs(), field, text, needsFreqs);\n \n     Likewise for DocsAndPositionsEnum.\n \n@@ -340,11 +316,12 @@ an AtomicReader. Note: using \"atomicity emulators\" can cause serious\n slowdowns due to the need to merge terms, postings, DocValues, and \n FieldCache, use them with care! \n \n-## LUCENE-2413: Analyzer package changes\n+## LUCENE-2413,LUCENE-3396: Analyzer package changes\n \n Lucene's core and contrib analyzers, along with Solr's analyzers,\n were consolidated into lucene/analysis. During the refactoring some\n-package names have changed:\n+package names have changed, and ReusableAnalyzerBase was renamed to\n+Analyzer:\n \n   - o.a.l.analysis.KeywordAnalyzer -> o.a.l.analysis.core.KeywordAnalyzer\n   - o.a.l.analysis.KeywordTokenizer -> o.a.l.analysis.core.KeywordTokenizer\n@@ -369,7 +346,7 @@ package names have changed:\n   - o.a.l.analysis.NormalizeCharMap -> o.a.l.analysis.charfilter.NormalizeCharMap\n   - o.a.l.analysis.CharArraySet -> o.a.l.analysis.util.CharArraySet\n   - o.a.l.analysis.CharArrayMap -> o.a.l.analysis.util.CharArrayMap\n-  - o.a.l.analysis.ReusableAnalyzerBase -> o.a.l.analysis.util.ReusableAnalyzerBase\n+  - o.a.l.analysis.ReusableAnalyzerBase -> o.a.l.analysis.Analyzer\n   - o.a.l.analysis.StopwordAnalyzerBase -> o.a.l.analysis.util.StopwordAnalyzerBase\n   - o.a.l.analysis.WordListLoader -> o.a.l.analysis.util.WordListLoader\n   - o.a.l.analysis.CharTokenizer -> o.a.l.analysis.util.CharTokenizer",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/MIGRATE.txt",
                "sha": "51185e80b73c3c9d465b0e8e7f20aecd81d870fe",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java",
                "patch": "@@ -24,14 +24,14 @@\n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.core.LowerCaseFilter;\n import org.apache.lucene.analysis.core.StopFilter;\n-import org.apache.lucene.analysis.fr.ElisionFilter;\n import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.Tokenizer;\n import org.apache.lucene.analysis.snowball.SnowballFilter;\n import org.apache.lucene.analysis.standard.StandardFilter;\n import org.apache.lucene.analysis.standard.StandardTokenizer;\n import org.apache.lucene.analysis.util.CharArraySet;\n+import org.apache.lucene.analysis.util.ElisionFilter;\n import org.apache.lucene.analysis.util.StopwordAnalyzerBase;\n import org.apache.lucene.util.Version;\n import org.tartarus.snowball.ext.CatalanStemmer;\n@@ -127,7 +127,7 @@ protected TokenStreamComponents createComponents(String fieldName,\n       Reader reader) {\n     final Tokenizer source = new StandardTokenizer(matchVersion, reader);\n     TokenStream result = new StandardFilter(matchVersion, source);\n-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);\n+    result = new ElisionFilter(result, DEFAULT_ARTICLES);\n     result = new LowerCaseFilter(matchVersion, result);\n     result = new StopFilter(matchVersion, result, stopwords);\n     if(!stemExclusionSet.isEmpty())",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java",
                "sha": "6101ab8e77ef6b2a9144c3ceada5a174ea7201f8",
                "status": "modified"
            },
            {
                "additions": 359,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java",
                "changes": 718,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 359,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java",
                "patch": "@@ -1,4 +1,4 @@\n-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/26/12 6:22 PM */\n+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 8/6/12 11:57 AM */\n \n package org.apache.lucene.analysis.charfilter;\n \n@@ -40,8 +40,8 @@\n /**\n  * This class is a scanner generated by \n  * <a href=\"http://www.jflex.de/\">JFlex</a> 1.5.0-SNAPSHOT\n- * on 7/26/12 6:22 PM from the specification file\n- * <tt>C:/svn/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex</tt>\n+ * on 8/6/12 11:57 AM from the specification file\n+ * <tt>/home/rmuir/workspace/lucene-trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex</tt>\n  */\n public final class HTMLStripCharFilter extends BaseCharFilter {\n \n@@ -31255,88 +31255,56 @@ else if (zzAtEOF) {\n           { yybegin(STYLE);\n           }\n         case 55: break;\n-        case 51: \n-          { // Handle paired UTF-16 surrogates.\n-    String surrogatePair = yytext();\n-    char highSurrogate = '\\u0000';\n-    char lowSurrogate = '\\u0000';\n-    try {\n-      highSurrogate = (char)Integer.parseInt(surrogatePair.substring(2, 6), 16);\n-    } catch(Exception e) { // should never happen\n-      assert false: \"Exception parsing high surrogate '\"\n-                  + surrogatePair.substring(2, 6) + \"'\";\n-    }\n-    try { // Low surrogates are in decimal range [56320, 57343]\n-      lowSurrogate = (char)Integer.parseInt(surrogatePair.substring(9, 14));\n-    } catch(Exception e) { // should never happen\n-      assert false: \"Exception parsing low surrogate '\"\n-                  + surrogatePair.substring(9, 14) + \"'\";\n-    }\n-    if (Character.isLowSurrogate(lowSurrogate)) {\n-      outputSegment = entitySegment;\n-      outputSegment.clear();\n-      outputSegment.unsafeWrite(lowSurrogate);\n-      // add (previously matched input length) + (this match length) - (substitution length)\n-      cumulativeDiff += inputSegment.length() + yylength() - 2;\n-      // position the correction at (already output length) + (substitution length)\n-      addOffCorrectMap(outputCharCount + 2, cumulativeDiff);\n-      inputSegment.clear();\n-      yybegin(YYINITIAL);\n-      return highSurrogate;\n-    }\n-    yypushback(surrogatePair.length() - 1); // Consume only '#'\n-    inputSegment.append('#');\n-    yybegin(NUMERIC_CHARACTER);\n+        case 27: \n+          { // add (previously matched input length) + (this match length) - (substitution length)\n+    cumulativeDiff += inputSegment.length() + yylength() - 1;\n+    // position the correction at (already output length) + (substitution length)\n+    addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n+    inputSegment.clear();\n+    yybegin(YYINITIAL);\n+    return BLOCK_LEVEL_START_TAG_REPLACEMENT;\n           }\n         case 56: break;\n-        case 21: \n-          { previousRestoreState = restoreState;\n-    restoreState = SERVER_SIDE_INCLUDE;\n-    yybegin(SINGLE_QUOTED_STRING);\n+        case 30: \n+          { int length = yylength();\n+    inputSegment.write(zzBuffer, zzStartRead, length);\n+    entitySegment.clear();\n+    char ch = entityValues.get(zzBuffer, zzStartRead, length).charValue();\n+    entitySegment.append(ch);\n+    outputSegment = entitySegment;\n+    yybegin(CHARACTER_REFERENCE_TAIL);\n           }\n         case 57: break;\n-        case 31: \n-          { int matchLength = yylength();\n-    inputSegment.write(zzBuffer, zzStartRead, matchLength);\n-    if (matchLength <= 6) { // 10FFFF: max 6 hex chars\n-      String hexCharRef\n-          = new String(zzBuffer, zzStartRead + 1, matchLength - 1);\n-      int codePoint = 0;\n-      try {\n-        codePoint = Integer.parseInt(hexCharRef, 16);\n-      } catch(Exception e) {\n-        assert false: \"Exception parsing hex code point '\" + hexCharRef + \"'\";\n-      }\n-      if (codePoint <= 0x10FFFF) {\n-        outputSegment = entitySegment;\n-        outputSegment.clear();\n-        if (codePoint >= Character.MIN_SURROGATE\n-            && codePoint <= Character.MAX_SURROGATE) {\n-          outputSegment.unsafeWrite(REPLACEMENT_CHARACTER);\n-        } else {\n-          outputSegment.setLength\n-              (Character.toChars(codePoint, outputSegment.getArray(), 0));\n-        }\n-        yybegin(CHARACTER_REFERENCE_TAIL);\n-      } else {\n-        outputSegment = inputSegment;\n-        yybegin(YYINITIAL);\n-        return outputSegment.nextChar();\n-      }\n-    } else {\n+        case 48: \n+          { inputSegment.clear();\n+    yybegin(YYINITIAL);\n+    // add (previously matched input length) -- current match and substitution handled below\n+    cumulativeDiff += yychar - inputStart;\n+    // position the offset correction at (already output length) -- substitution handled below\n+    int offsetCorrectionPos = outputCharCount;\n+    int returnValue;\n+    if (escapeSTYLE) {\n+      inputSegment.write(zzBuffer, zzStartRead, yylength());\n       outputSegment = inputSegment;\n-      yybegin(YYINITIAL);\n-      return outputSegment.nextChar();\n+      returnValue = outputSegment.nextChar();\n+    } else {\n+      // add (this match length) - (substitution length)\n+      cumulativeDiff += yylength() - 1;\n+      // add (substitution length)\n+      ++offsetCorrectionPos;\n+      returnValue = STYLE_REPLACEMENT;\n     }\n+    addOffCorrectMap(offsetCorrectionPos, cumulativeDiff);\n+    return returnValue;\n           }\n         case 58: break;\n-        case 19: \n+        case 8: \n           { inputSegment.write(zzBuffer, zzStartRead, yylength());\n     if (null != escapedTags\n         && escapedTags.contains(zzBuffer, zzStartRead, yylength())) {\n-      yybegin(END_TAG_TAIL_INCLUDE);\n+      yybegin(START_TAG_TAIL_INCLUDE);\n     } else {\n-      yybegin(END_TAG_TAIL_EXCLUDE);\n+      yybegin(START_TAG_TAIL_SUBSTITUTE);\n     }\n           }\n         case 59: break;\n@@ -31347,113 +31315,79 @@ else if (zzAtEOF) {\n   yybegin(LEFT_ANGLE_BRACKET);\n           }\n         case 60: break;\n-        case 27: \n-          { // add (previously matched input length) + (this match length) - (substitution length)\n-    cumulativeDiff += inputSegment.length() + yylength() - 1;\n-    // position the correction at (already output length) + (substitution length)\n-    addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n-    inputSegment.clear();\n-    yybegin(YYINITIAL);\n-    return BLOCK_LEVEL_START_TAG_REPLACEMENT;\n-          }\n-        case 61: break;\n         case 44: \n           { restoreState = STYLE_COMMENT; yybegin(SERVER_SIDE_INCLUDE);\n           }\n+        case 61: break;\n+        case 21: \n+          { previousRestoreState = restoreState;\n+    restoreState = SERVER_SIDE_INCLUDE;\n+    yybegin(SINGLE_QUOTED_STRING);\n+          }\n         case 62: break;\n+        case 11: \n+          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n+    yybegin(LEFT_ANGLE_BRACKET_SPACE);\n+          }\n+        case 63: break;\n         case 35: \n           { yybegin(SCRIPT);\n           }\n-        case 63: break;\n+        case 64: break;\n         case 42: \n           { restoreState = COMMENT; yybegin(SERVER_SIDE_INCLUDE);\n           }\n-        case 64: break;\n+        case 65: break;\n         case 10: \n           { inputSegment.append('!'); yybegin(BANG);\n           }\n-        case 65: break;\n-        case 33: \n-          { yybegin(YYINITIAL);\n-    if (escapeBR) {\n-      inputSegment.write(zzBuffer, zzStartRead, yylength());\n-      outputSegment = inputSegment;\n-      return outputSegment.nextChar();\n-    } else {\n-      // add (previously matched input length) + (this match length) - (substitution length)\n-      cumulativeDiff += inputSegment.length() + yylength() - 1;\n-      // position the correction at (already output length) + (substitution length)\n-      addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n-      inputSegment.reset();\n-      return BR_START_TAG_REPLACEMENT;\n-    }\n-          }\n         case 66: break;\n-        case 53: \n+        case 51: \n           { // Handle paired UTF-16 surrogates.\n     String surrogatePair = yytext();\n     char highSurrogate = '\\u0000';\n-    try { // High surrogates are in decimal range [55296, 56319]\n-      highSurrogate = (char)Integer.parseInt(surrogatePair.substring(1, 6));\n+    char lowSurrogate = '\\u0000';\n+    try {\n+      highSurrogate = (char)Integer.parseInt(surrogatePair.substring(2, 6), 16);\n     } catch(Exception e) { // should never happen\n       assert false: \"Exception parsing high surrogate '\"\n-                  + surrogatePair.substring(1, 6) + \"'\";\n+                  + surrogatePair.substring(2, 6) + \"'\";\n     }\n-    if (Character.isHighSurrogate(highSurrogate)) {\n-      char lowSurrogate = '\\u0000';\n-      try { // Low surrogates are in decimal range [56320, 57343]\n-        lowSurrogate = (char)Integer.parseInt(surrogatePair.substring(9, 14));\n-      } catch(Exception e) { // should never happen\n-        assert false: \"Exception parsing low surrogate '\"\n-                    + surrogatePair.substring(9, 14) + \"'\";\n-      }\n-      if (Character.isLowSurrogate(lowSurrogate)) {\n-        outputSegment = entitySegment;\n-        outputSegment.clear();\n-        outputSegment.unsafeWrite(lowSurrogate);\n-        // add (previously matched input length) + (this match length) - (substitution length)\n-        cumulativeDiff += inputSegment.length() + yylength() - 2;\n-        // position the correction at (already output length) + (substitution length)\n-        addOffCorrectMap(outputCharCount + 2, cumulativeDiff);\n-        inputSegment.clear();\n-        yybegin(YYINITIAL);\n-        return highSurrogate;\n-      }\n+    try { // Low surrogates are in decimal range [56320, 57343]\n+      lowSurrogate = (char)Integer.parseInt(surrogatePair.substring(9, 14));\n+    } catch(Exception e) { // should never happen\n+      assert false: \"Exception parsing low surrogate '\"\n+                  + surrogatePair.substring(9, 14) + \"'\";\n+    }\n+    if (Character.isLowSurrogate(lowSurrogate)) {\n+      outputSegment = entitySegment;\n+      outputSegment.clear();\n+      outputSegment.unsafeWrite(lowSurrogate);\n+      // add (previously matched input length) + (this match length) - (substitution length)\n+      cumulativeDiff += inputSegment.length() + yylength() - 2;\n+      // position the correction at (already output length) + (substitution length)\n+      addOffCorrectMap(outputCharCount + 2, cumulativeDiff);\n+      inputSegment.clear();\n+      yybegin(YYINITIAL);\n+      return highSurrogate;\n     }\n     yypushback(surrogatePair.length() - 1); // Consume only '#'\n     inputSegment.append('#');\n     yybegin(NUMERIC_CHARACTER);\n           }\n         case 67: break;\n-        case 43: \n-          { restoreState = SCRIPT_COMMENT; yybegin(SERVER_SIDE_INCLUDE);\n+        case 4: \n+          { yypushback(1);\n+    outputSegment = inputSegment;\n+    outputSegment.restart();\n+    yybegin(YYINITIAL);\n+    return outputSegment.nextChar();\n           }\n         case 68: break;\n-        case 30: \n-          { int length = yylength();\n-    inputSegment.write(zzBuffer, zzStartRead, length);\n-    entitySegment.clear();\n-    char ch = entityValues.get(zzBuffer, zzStartRead, length).charValue();\n-    entitySegment.append(ch);\n-    outputSegment = entitySegment;\n-    yybegin(CHARACTER_REFERENCE_TAIL);\n+        case 43: \n+          { restoreState = SCRIPT_COMMENT; yybegin(SERVER_SIDE_INCLUDE);\n           }\n         case 69: break;\n-        case 28: \n-          { restoreState = STYLE_COMMENT; yybegin(SINGLE_QUOTED_STRING);\n-          }\n-        case 70: break;\n-        case 3: \n-          { inputStart = yychar;\n-  inputSegment.clear();\n-  inputSegment.append('&');\n-  yybegin(AMPERSAND);\n-          }\n-        case 71: break;\n-        case 16: \n-          { restoreState = SCRIPT_COMMENT; yybegin(SINGLE_QUOTED_STRING);\n-          }\n-        case 72: break;\n         case 52: \n           { // Handle paired UTF-16 surrogates.\n     String surrogatePair = yytext();\n@@ -31486,174 +31420,11 @@ else if (zzAtEOF) {\n     inputSegment.append('#');\n     yybegin(NUMERIC_CHARACTER);\n           }\n-        case 73: break;\n-        case 6: \n-          { int matchLength = yylength();\n-    inputSegment.write(zzBuffer, zzStartRead, matchLength);\n-    if (matchLength <= 7) { // 0x10FFFF = 1114111: max 7 decimal chars\n-      String decimalCharRef = yytext();\n-      int codePoint = 0;\n-      try {\n-        codePoint = Integer.parseInt(decimalCharRef);\n-      } catch(Exception e) {\n-        assert false: \"Exception parsing code point '\" + decimalCharRef + \"'\";\n-      }\n-      if (codePoint <= 0x10FFFF) {\n-        outputSegment = entitySegment;\n-        outputSegment.clear();\n-        if (codePoint >= Character.MIN_SURROGATE\n-            && codePoint <= Character.MAX_SURROGATE) {\n-          outputSegment.unsafeWrite(REPLACEMENT_CHARACTER);\n-        } else {\n-          outputSegment.setLength\n-              (Character.toChars(codePoint, outputSegment.getArray(), 0));\n-        }\n-        yybegin(CHARACTER_REFERENCE_TAIL);\n-      } else {\n-        outputSegment = inputSegment;\n-        yybegin(YYINITIAL);\n-        return outputSegment.nextChar();\n-      }\n-    } else {\n-      outputSegment = inputSegment;\n-      yybegin(YYINITIAL);\n-      return outputSegment.nextChar();\n-    }\n-          }\n-        case 74: break;\n-        case 37: \n-          { // add (this match length) [ - (substitution length) = 0 ]\n-    cumulativeDiff += yylength();\n-    // position the correction at (already output length) [ + (substitution length) = 0 ]\n-    addOffCorrectMap(outputCharCount, cumulativeDiff);\n-    yybegin(YYINITIAL);\n-          }\n-        case 75: break;\n-        case 8: \n-          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n-    if (null != escapedTags\n-        && escapedTags.contains(zzBuffer, zzStartRead, yylength())) {\n-      yybegin(START_TAG_TAIL_INCLUDE);\n-    } else {\n-      yybegin(START_TAG_TAIL_SUBSTITUTE);\n-    }\n-          }\n-        case 76: break;\n-        case 46: \n-          { yybegin(SCRIPT);\n-    if (escapeSCRIPT) {\n-      inputSegment.write(zzBuffer, zzStartRead, yylength());\n-      outputSegment = inputSegment;\n-      inputStart += 1 + yylength();\n-      return outputSegment.nextChar();\n-    }\n-          }\n-        case 77: break;\n-        case 11: \n-          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n-    yybegin(LEFT_ANGLE_BRACKET_SPACE);\n-          }\n-        case 78: break;\n-        case 20: \n-          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n-          }\n-        case 79: break;\n-        case 34: \n-          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0]\n-    cumulativeDiff += yychar - inputStart + yylength();\n-    // position the correction at (already output length) [ + (substitution length) = 0]\n-    addOffCorrectMap(outputCharCount, cumulativeDiff);\n-    inputSegment.clear();\n-    yybegin(YYINITIAL);\n-          }\n-        case 80: break;\n-        case 23: \n-          { yybegin(restoreState); restoreState = previousRestoreState;\n-          }\n-        case 81: break;\n-        case 32: \n-          { yybegin(COMMENT);\n-          }\n-        case 82: break;\n-        case 14: \n-          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0 ]\n-    cumulativeDiff += inputSegment.length() + yylength();\n-    // position the correction at (already output length) [ + (substitution length) = 0 ]\n-    addOffCorrectMap(outputCharCount, cumulativeDiff);\n-    inputSegment.clear();\n-    yybegin(YYINITIAL);\n-          }\n-        case 83: break;\n-        case 18: \n-          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n-    if (null != escapedTags\n-        && escapedTags.contains(zzBuffer, zzStartRead, yylength())) {\n-      yybegin(END_TAG_TAIL_INCLUDE);\n-    } else {\n-      yybegin(END_TAG_TAIL_SUBSTITUTE);\n-    }\n-          }\n-        case 84: break;\n-        case 25: \n-          { // add (previously matched input length) + (this match length) - (substitution length)\n-    cumulativeDiff += inputSegment.length() + yylength() - 1;\n-    // position the correction at (already output length) + (substitution length)\n-    addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n-    inputSegment.clear();\n-    yybegin(YYINITIAL);\n-    return BLOCK_LEVEL_END_TAG_REPLACEMENT;\n-          }\n-        case 85: break;\n-        case 7: \n-          { // add (previously matched input length) + (this match length) - (substitution length)\n-    cumulativeDiff += inputSegment.length() + yylength() - outputSegment.length();\n-    // position the correction at (already output length) + (substitution length)\n-    addOffCorrectMap(outputCharCount + outputSegment.length(), cumulativeDiff);\n-    yybegin(YYINITIAL);\n-    return outputSegment.nextChar();\n-          }\n-        case 86: break;\n-        case 48: \n-          { inputSegment.clear();\n-    yybegin(YYINITIAL);\n-    // add (previously matched input length) -- current match and substitution handled below\n-    cumulativeDiff += yychar - inputStart;\n-    // position the offset correction at (already output length) -- substitution handled below\n-    int offsetCorrectionPos = outputCharCount;\n-    int returnValue;\n-    if (escapeSTYLE) {\n-      inputSegment.write(zzBuffer, zzStartRead, yylength());\n-      outputSegment = inputSegment;\n-      returnValue = outputSegment.nextChar();\n-    } else {\n-      // add (this match length) - (substitution length)\n-      cumulativeDiff += yylength() - 1;\n-      // add (substitution length)\n-      ++offsetCorrectionPos;\n-      returnValue = STYLE_REPLACEMENT;\n-    }\n-    addOffCorrectMap(offsetCorrectionPos, cumulativeDiff);\n-    return returnValue;\n-          }\n-        case 87: break;\n-        case 5: \n-          { inputSegment.append('#'); yybegin(NUMERIC_CHARACTER);\n-          }\n-        case 88: break;\n-        case 26: \n-          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0 ]\n-    cumulativeDiff += inputSegment.length() + yylength();\n-    // position the correction at (already output length) [ + (substitution length) = 0 ]\n-    addOffCorrectMap(outputCharCount, cumulativeDiff);\n-    inputSegment.clear();\n-    outputSegment = inputSegment;\n-    yybegin(YYINITIAL);\n-          }\n-        case 89: break;\n-        case 13: \n-          { inputSegment.append(zzBuffer[zzStartRead]);\n+        case 70: break;\n+        case 28: \n+          { restoreState = STYLE_COMMENT; yybegin(SINGLE_QUOTED_STRING);\n           }\n-        case 90: break;\n+        case 71: break;\n         case 50: \n           { // Handle paired UTF-16 surrogates.\n     outputSegment = entitySegment;\n@@ -31681,32 +31452,41 @@ else if (zzAtEOF) {\n     yybegin(YYINITIAL);\n     return highSurrogate;\n           }\n-        case 91: break;\n-        case 40: \n-          { yybegin(SCRIPT_COMMENT);\n-          }\n-        case 92: break;\n-        case 45: \n-          { yybegin(STYLE);\n-    if (escapeSTYLE) {\n-      inputSegment.write(zzBuffer, zzStartRead, yylength());\n-      outputSegment = inputSegment;\n-      inputStart += 1 + yylength();\n-      return outputSegment.nextChar();\n-    }\n+        case 72: break;\n+        case 16: \n+          { restoreState = SCRIPT_COMMENT; yybegin(SINGLE_QUOTED_STRING);\n           }\n-        case 93: break;\n+        case 73: break;\n         case 22: \n           { previousRestoreState = restoreState;\n     restoreState = SERVER_SIDE_INCLUDE;\n     yybegin(DOUBLE_QUOTED_STRING);\n           }\n-        case 94: break;\n-        case 12: \n-          { inputSegment.append('/'); yybegin(LEFT_ANGLE_BRACKET_SLASH);\n+        case 74: break;\n+        case 26: \n+          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0 ]\n+    cumulativeDiff += inputSegment.length() + yylength();\n+    // position the correction at (already output length) [ + (substitution length) = 0 ]\n+    addOffCorrectMap(outputCharCount, cumulativeDiff);\n+    inputSegment.clear();\n+    outputSegment = inputSegment;\n+    yybegin(YYINITIAL);\n           }\n-        case 95: break;\n-        case 36: \n+        case 75: break;\n+        case 20: \n+          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n+          }\n+        case 76: break;\n+        case 47: \n+          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0 ]\n+    cumulativeDiff += inputSegment.length() + yylength();\n+    // position the correction at (already output length) [ + (substitution length) = 0 ]\n+    addOffCorrectMap(outputCharCount, cumulativeDiff);\n+    inputSegment.clear();\n+    yybegin(CDATA);\n+          }\n+        case 77: break;\n+        case 33: \n           { yybegin(YYINITIAL);\n     if (escapeBR) {\n       inputSegment.write(zzBuffer, zzStartRead, yylength());\n@@ -31718,34 +31498,128 @@ else if (zzAtEOF) {\n       // position the correction at (already output length) + (substitution length)\n       addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n       inputSegment.reset();\n-      return BR_END_TAG_REPLACEMENT;\n+      return BR_START_TAG_REPLACEMENT;\n     }\n           }\n-        case 96: break;\n+        case 78: break;\n+        case 23: \n+          { yybegin(restoreState); restoreState = previousRestoreState;\n+          }\n+        case 79: break;\n+        case 32: \n+          { yybegin(COMMENT);\n+          }\n+        case 80: break;\n         case 24: \n           { inputSegment.write(zzBuffer, zzStartRead, yylength());\n      outputSegment = inputSegment;\n      yybegin(YYINITIAL);\n      return outputSegment.nextChar();\n           }\n-        case 97: break;\n-        case 47: \n+        case 81: break;\n+        case 3: \n+          { inputStart = yychar;\n+  inputSegment.clear();\n+  inputSegment.append('&');\n+  yybegin(AMPERSAND);\n+          }\n+        case 82: break;\n+        case 46: \n+          { yybegin(SCRIPT);\n+    if (escapeSCRIPT) {\n+      inputSegment.write(zzBuffer, zzStartRead, yylength());\n+      outputSegment = inputSegment;\n+      inputStart += 1 + yylength();\n+      return outputSegment.nextChar();\n+    }\n+          }\n+        case 83: break;\n+        case 14: \n           { // add (previously matched input length) + (this match length) [ - (substitution length) = 0 ]\n     cumulativeDiff += inputSegment.length() + yylength();\n     // position the correction at (already output length) [ + (substitution length) = 0 ]\n     addOffCorrectMap(outputCharCount, cumulativeDiff);\n     inputSegment.clear();\n-    yybegin(CDATA);\n+    yybegin(YYINITIAL);\n           }\n-        case 98: break;\n-        case 29: \n-          { restoreState = STYLE_COMMENT; yybegin(DOUBLE_QUOTED_STRING);\n+        case 84: break;\n+        case 6: \n+          { int matchLength = yylength();\n+    inputSegment.write(zzBuffer, zzStartRead, matchLength);\n+    if (matchLength <= 7) { // 0x10FFFF = 1114111: max 7 decimal chars\n+      String decimalCharRef = yytext();\n+      int codePoint = 0;\n+      try {\n+        codePoint = Integer.parseInt(decimalCharRef);\n+      } catch(Exception e) {\n+        assert false: \"Exception parsing code point '\" + decimalCharRef + \"'\";\n+      }\n+      if (codePoint <= 0x10FFFF) {\n+        outputSegment = entitySegment;\n+        outputSegment.clear();\n+        if (codePoint >= Character.MIN_SURROGATE\n+            && codePoint <= Character.MAX_SURROGATE) {\n+          outputSegment.unsafeWrite(REPLACEMENT_CHARACTER);\n+        } else {\n+          outputSegment.setLength\n+              (Character.toChars(codePoint, outputSegment.getArray(), 0));\n+        }\n+        yybegin(CHARACTER_REFERENCE_TAIL);\n+      } else {\n+        outputSegment = inputSegment;\n+        yybegin(YYINITIAL);\n+        return outputSegment.nextChar();\n+      }\n+    } else {\n+      outputSegment = inputSegment;\n+      yybegin(YYINITIAL);\n+      return outputSegment.nextChar();\n+    }\n           }\n-        case 99: break;\n-        case 17: \n-          { restoreState = SCRIPT_COMMENT; yybegin(DOUBLE_QUOTED_STRING);\n+        case 85: break;\n+        case 34: \n+          { // add (previously matched input length) + (this match length) [ - (substitution length) = 0]\n+    cumulativeDiff += yychar - inputStart + yylength();\n+    // position the correction at (already output length) [ + (substitution length) = 0]\n+    addOffCorrectMap(outputCharCount, cumulativeDiff);\n+    inputSegment.clear();\n+    yybegin(YYINITIAL);\n           }\n-        case 100: break;\n+        case 86: break;\n+        case 5: \n+          { inputSegment.append('#'); yybegin(NUMERIC_CHARACTER);\n+          }\n+        case 87: break;\n+        case 13: \n+          { inputSegment.append(zzBuffer[zzStartRead]);\n+          }\n+        case 88: break;\n+        case 18: \n+          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n+    if (null != escapedTags\n+        && escapedTags.contains(zzBuffer, zzStartRead, yylength())) {\n+      yybegin(END_TAG_TAIL_INCLUDE);\n+    } else {\n+      yybegin(END_TAG_TAIL_SUBSTITUTE);\n+    }\n+          }\n+        case 89: break;\n+        case 40: \n+          { yybegin(SCRIPT_COMMENT);\n+          }\n+        case 90: break;\n+        case 37: \n+          { // add (this match length) [ - (substitution length) = 0 ]\n+    cumulativeDiff += yylength();\n+    // position the correction at (already output length) [ + (substitution length) = 0 ]\n+    addOffCorrectMap(outputCharCount, cumulativeDiff);\n+    yybegin(YYINITIAL);\n+          }\n+        case 91: break;\n+        case 12: \n+          { inputSegment.append('/'); yybegin(LEFT_ANGLE_BRACKET_SLASH);\n+          }\n+        case 92: break;\n         case 9: \n           { inputSegment.write(zzBuffer, zzStartRead, yylength());\n     if (null != escapedTags\n@@ -31755,7 +31629,7 @@ else if (zzAtEOF) {\n       yybegin(START_TAG_TAIL_EXCLUDE);\n     }\n           }\n-        case 101: break;\n+        case 93: break;\n         case 49: \n           { inputSegment.clear();\n     yybegin(YYINITIAL);\n@@ -31778,26 +31652,152 @@ else if (zzAtEOF) {\n     addOffCorrectMap(offsetCorrectionPos, cumulativeDiff);\n     return returnValue;\n           }\n+        case 94: break;\n+        case 29: \n+          { restoreState = STYLE_COMMENT; yybegin(DOUBLE_QUOTED_STRING);\n+          }\n+        case 95: break;\n+        case 17: \n+          { restoreState = SCRIPT_COMMENT; yybegin(DOUBLE_QUOTED_STRING);\n+          }\n+        case 96: break;\n+        case 45: \n+          { yybegin(STYLE);\n+    if (escapeSTYLE) {\n+      inputSegment.write(zzBuffer, zzStartRead, yylength());\n+      outputSegment = inputSegment;\n+      inputStart += 1 + yylength();\n+      return outputSegment.nextChar();\n+    }\n+          }\n+        case 97: break;\n+        case 7: \n+          { // add (previously matched input length) + (this match length) - (substitution length)\n+    cumulativeDiff += inputSegment.length() + yylength() - outputSegment.length();\n+    // position the correction at (already output length) + (substitution length)\n+    addOffCorrectMap(outputCharCount + outputSegment.length(), cumulativeDiff);\n+    yybegin(YYINITIAL);\n+    return outputSegment.nextChar();\n+          }\n+        case 98: break;\n+        case 19: \n+          { inputSegment.write(zzBuffer, zzStartRead, yylength());\n+    if (null != escapedTags\n+        && escapedTags.contains(zzBuffer, zzStartRead, yylength())) {\n+      yybegin(END_TAG_TAIL_INCLUDE);\n+    } else {\n+      yybegin(END_TAG_TAIL_EXCLUDE);\n+    }\n+          }\n+        case 99: break;\n+        case 25: \n+          { // add (previously matched input length) + (this match length) - (substitution length)\n+    cumulativeDiff += inputSegment.length() + yylength() - 1;\n+    // position the correction at (already output length) + (substitution length)\n+    addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n+    inputSegment.clear();\n+    yybegin(YYINITIAL);\n+    return BLOCK_LEVEL_END_TAG_REPLACEMENT;\n+          }\n+        case 100: break;\n+        case 31: \n+          { int matchLength = yylength();\n+    inputSegment.write(zzBuffer, zzStartRead, matchLength);\n+    if (matchLength <= 6) { // 10FFFF: max 6 hex chars\n+      String hexCharRef\n+          = new String(zzBuffer, zzStartRead + 1, matchLength - 1);\n+      int codePoint = 0;\n+      try {\n+        codePoint = Integer.parseInt(hexCharRef, 16);\n+      } catch(Exception e) {\n+        assert false: \"Exception parsing hex code point '\" + hexCharRef + \"'\";\n+      }\n+      if (codePoint <= 0x10FFFF) {\n+        outputSegment = entitySegment;\n+        outputSegment.clear();\n+        if (codePoint >= Character.MIN_SURROGATE\n+            && codePoint <= Character.MAX_SURROGATE) {\n+          outputSegment.unsafeWrite(REPLACEMENT_CHARACTER);\n+        } else {\n+          outputSegment.setLength\n+              (Character.toChars(codePoint, outputSegment.getArray(), 0));\n+        }\n+        yybegin(CHARACTER_REFERENCE_TAIL);\n+      } else {\n+        outputSegment = inputSegment;\n+        yybegin(YYINITIAL);\n+        return outputSegment.nextChar();\n+      }\n+    } else {\n+      outputSegment = inputSegment;\n+      yybegin(YYINITIAL);\n+      return outputSegment.nextChar();\n+    }\n+          }\n+        case 101: break;\n+        case 53: \n+          { // Handle paired UTF-16 surrogates.\n+    String surrogatePair = yytext();\n+    char highSurrogate = '\\u0000';\n+    try { // High surrogates are in decimal range [55296, 56319]\n+      highSurrogate = (char)Integer.parseInt(surrogatePair.substring(1, 6));\n+    } catch(Exception e) { // should never happen\n+      assert false: \"Exception parsing high surrogate '\"\n+                  + surrogatePair.substring(1, 6) + \"'\";\n+    }\n+    if (Character.isHighSurrogate(highSurrogate)) {\n+      char lowSurrogate = '\\u0000';\n+      try { // Low surrogates are in decimal range [56320, 57343]\n+        lowSurrogate = (char)Integer.parseInt(surrogatePair.substring(9, 14));\n+      } catch(Exception e) { // should never happen\n+        assert false: \"Exception parsing low surrogate '\"\n+                    + surrogatePair.substring(9, 14) + \"'\";\n+      }\n+      if (Character.isLowSurrogate(lowSurrogate)) {\n+        outputSegment = entitySegment;\n+        outputSegment.clear();\n+        outputSegment.unsafeWrite(lowSurrogate);\n+        // add (previously matched input length) + (this match length) - (substitution length)\n+        cumulativeDiff += inputSegment.length() + yylength() - 2;\n+        // position the correction at (already output length) + (substitution length)\n+        addOffCorrectMap(outputCharCount + 2, cumulativeDiff);\n+        inputSegment.clear();\n+        yybegin(YYINITIAL);\n+        return highSurrogate;\n+      }\n+    }\n+    yypushback(surrogatePair.length() - 1); // Consume only '#'\n+    inputSegment.append('#');\n+    yybegin(NUMERIC_CHARACTER);\n+          }\n         case 102: break;\n+        case 36: \n+          { yybegin(YYINITIAL);\n+    if (escapeBR) {\n+      inputSegment.write(zzBuffer, zzStartRead, yylength());\n+      outputSegment = inputSegment;\n+      return outputSegment.nextChar();\n+    } else {\n+      // add (previously matched input length) + (this match length) - (substitution length)\n+      cumulativeDiff += inputSegment.length() + yylength() - 1;\n+      // position the correction at (already output length) + (substitution length)\n+      addOffCorrectMap(outputCharCount + 1, cumulativeDiff);\n+      inputSegment.reset();\n+      return BR_END_TAG_REPLACEMENT;\n+    }\n+          }\n+        case 103: break;\n         case 38: \n           { yybegin(restoreState);\n           }\n-        case 103: break;\n+        case 104: break;\n         case 41: \n           { yybegin(STYLE_COMMENT);\n           }\n-        case 104: break;\n+        case 105: break;\n         case 1: \n           { return zzBuffer[zzStartRead];\n           }\n-        case 105: break;\n-        case 4: \n-          { yypushback(1);\n-    outputSegment = inputSegment;\n-    outputSegment.restart();\n-    yybegin(YYINITIAL);\n-    return outputSegment.nextChar();\n-          }\n         case 106: break;\n         default: \n           if (zzInput == YYEOF && zzStartRead == zzCurrentPos) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java",
                "sha": "7b74620591de8335951678fe97dce8ce56ee14ee",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex",
                "patch": "@@ -141,9 +141,9 @@ InlineElment = ( [aAbBiIqQsSuU]                   |\n                  [vV][aA][rR]                     )\n \n \n-%include src/java/org/apache/lucene/analysis/charfilter/HTMLCharacterEntities.jflex\n+%include HTMLCharacterEntities.jflex\n \n-%include src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.SUPPLEMENTARY.jflex-macro\n+%include HTMLStripCharFilter.SUPPLEMENTARY.jflex-macro\n \n %{\n   private static final int INITIAL_INPUT_SEGMENT_SIZE = 1024;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex",
                "sha": "fc6675546969a58b07079f82f0273c569e0f08a5",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java",
                "changes": 66,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 5,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java",
                "patch": "@@ -24,6 +24,8 @@\n import org.apache.lucene.analysis.standard.StandardTokenizer;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;\n+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;\n+import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;\n import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n import org.apache.lucene.util.ArrayUtil;\n \n@@ -35,6 +37,12 @@\n  * {@link #CJKBigramFilter(TokenStream, int)} to explicitly control which\n  * of the CJK scripts are turned into bigrams.\n  * <p>\n+ * By default, when a CJK character has no adjacent characters to form\n+ * a bigram, it is output in unigram form. If you want to always output\n+ * both unigrams and bigrams, set the <code>outputUnigrams</code>\n+ * flag in {@link CJKBigramFilter#CJKBigramFilter(TokenStream, int, boolean)}.\n+ * This can be used for a combined unigram+bigram approach.\n+ * <p>\n  * In all cases, all non-CJK input is passed thru unmodified.\n  */\n public final class CJKBigramFilter extends TokenFilter {\n@@ -67,10 +75,16 @@\n   private final Object doHiragana;\n   private final Object doKatakana;\n   private final Object doHangul;\n+  \n+  // true if we should output unigram tokens always\n+  private final boolean outputUnigrams;\n+  private boolean ngramState; // false = output unigram, true = output bigram\n     \n   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n   private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n   private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n+  private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);\n+  private final PositionLengthAttribute posLengthAtt = addAttribute(PositionLengthAttribute.class);\n   \n   // buffers containing codepoint and offsets in parallel\n   int buffer[] = new int[8];\n@@ -88,23 +102,36 @@\n   \n   /** \n    * Calls {@link CJKBigramFilter#CJKBigramFilter(TokenStream, int)\n-   *       CJKBigramFilter(HAN | HIRAGANA | KATAKANA | HANGUL)}\n+   *       CJKBigramFilter(in, HAN | HIRAGANA | KATAKANA | HANGUL)}\n    */\n   public CJKBigramFilter(TokenStream in) {\n     this(in, HAN | HIRAGANA | KATAKANA | HANGUL);\n   }\n   \n   /** \n-   * Create a new CJKBigramFilter, specifying which writing systems should be bigrammed.\n+   * Calls {@link CJKBigramFilter#CJKBigramFilter(TokenStream, int, boolean)\n+   *       CJKBigramFilter(in, flags, false)}\n+   */\n+  public CJKBigramFilter(TokenStream in, int flags) {\n+    this(in, flags, false);\n+  }\n+  \n+  /**\n+   * Create a new CJKBigramFilter, specifying which writing systems should be bigrammed,\n+   * and whether or not unigrams should also be output.\n    * @param flags OR'ed set from {@link CJKBigramFilter#HAN}, {@link CJKBigramFilter#HIRAGANA}, \n    *        {@link CJKBigramFilter#KATAKANA}, {@link CJKBigramFilter#HANGUL}\n+   * @param outputUnigrams true if unigrams for the selected writing systems should also be output.\n+   *        when this is false, this is only done when there are no adjacent characters to form\n+   *        a bigram.\n    */\n-  public CJKBigramFilter(TokenStream in, int flags) {\n+  public CJKBigramFilter(TokenStream in, int flags, boolean outputUnigrams) {\n     super(in);\n     doHan =      (flags & HAN) == 0      ? NO : HAN_TYPE;\n     doHiragana = (flags & HIRAGANA) == 0 ? NO : HIRAGANA_TYPE;\n     doKatakana = (flags & KATAKANA) == 0 ? NO : KATAKANA_TYPE;\n     doHangul =   (flags & HANGUL) == 0   ? NO : HANGUL_TYPE;\n+    this.outputUnigrams = outputUnigrams;\n   }\n   \n   /*\n@@ -120,7 +147,24 @@ public boolean incrementToken() throws IOException {\n         // case 1: we have multiple remaining codepoints buffered,\n         // so we can emit a bigram here.\n         \n-        flushBigram();\n+        if (outputUnigrams) {\n+\n+          // when also outputting unigrams, we output the unigram first,\n+          // then rewind back to revisit the bigram.\n+          // so an input of ABC is A + (rewind)AB + B + (rewind)BC + C\n+          // the logic in hasBufferedUnigram ensures we output the C, \n+          // even though it did actually have adjacent CJK characters.\n+\n+          if (ngramState) {\n+            flushBigram();\n+          } else {\n+            flushUnigram();\n+            index--;\n+          }\n+          ngramState = !ngramState;\n+        } else {\n+          flushBigram();\n+        }\n         return true;\n       } else if (doNext()) {\n         \n@@ -260,6 +304,11 @@ private void flushBigram() {\n     termAtt.setLength(len2);\n     offsetAtt.setOffset(startOffset[index], endOffset[index+1]);\n     typeAtt.setType(DOUBLE_TYPE);\n+    // when outputting unigrams, all bigrams are synonyms that span two unigrams\n+    if (outputUnigrams) {\n+      posIncAtt.setPositionIncrement(0);\n+      posLengthAtt.setPositionLength(2);\n+    }\n     index++;\n   }\n   \n@@ -292,7 +341,13 @@ private boolean hasBufferedBigram() {\n    * inputs.\n    */\n   private boolean hasBufferedUnigram() {\n-    return bufferLen == 1 && index == 0;\n+    if (outputUnigrams) {\n+      // when outputting unigrams always\n+      return bufferLen - index == 1;\n+    } else {\n+      // otherwise its only when we have a lone CJK character\n+      return bufferLen == 1 && index == 0;\n+    }\n   }\n \n   @Override\n@@ -303,5 +358,6 @@ public void reset() throws IOException {\n     lastEndOffset = 0;\n     loneState = null;\n     exhausted = false;\n+    ngramState = false;\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java",
                "sha": "dc98909e5a853c7382defc543bdf0e46f0d2862c",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java",
                "patch": "@@ -33,12 +33,13 @@\n  *     &lt;filter class=\"solr.LowerCaseFilterFactory\"/&gt;\n  *     &lt;filter class=\"solr.CJKBigramFilterFactory\" \n  *       han=\"true\" hiragana=\"true\" \n- *       katakana=\"true\" hangul=\"true\" /&gt;\n+ *       katakana=\"true\" hangul=\"true\" outputUnigrams=\"false\" /&gt;\n  *   &lt;/analyzer&gt;\n  * &lt;/fieldType&gt;</pre>\n  */\n public class CJKBigramFilterFactory extends TokenFilterFactory {\n   int flags;\n+  boolean outputUnigrams;\n \n   @Override\n   public void init(Map<String,String> args) {\n@@ -56,10 +57,11 @@ public void init(Map<String,String> args) {\n     if (getBoolean(\"hangul\", true)) {\n       flags |= CJKBigramFilter.HANGUL;\n     }\n+    outputUnigrams = getBoolean(\"outputUnigrams\", false);\n   }\n   \n   @Override\n   public TokenStream create(TokenStream input) {\n-    return new CJKBigramFilter(input, flags);\n+    return new CJKBigramFilter(input, flags, outputUnigrams);\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java",
                "sha": "7675e5b16edab353d00fdaa6b5e12a805cea5b3e",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java",
                "patch": "@@ -28,13 +28,15 @@\n import org.apache.lucene.analysis.standard.StandardTokenizer;\n import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc\n import org.apache.lucene.analysis.util.CharArraySet;\n+import org.apache.lucene.analysis.util.ElisionFilter;\n import org.apache.lucene.analysis.util.StopwordAnalyzerBase;\n import org.apache.lucene.analysis.util.WordlistLoader;\n import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.Version;\n \n import java.io.IOException;\n import java.io.Reader;\n+import java.util.Arrays;\n \n /**\n  * {@link Analyzer} for French language. \n@@ -54,6 +56,11 @@\n   /** File containing default French stopwords. */\n   public final static String DEFAULT_STOPWORD_FILE = \"french_stop.txt\";\n   \n+  /** Default set of articles for ElisionFilter */\n+  public static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(\n+      new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(\n+          \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\"), true));\n+\n   /**\n    * Contains words that should be indexed but not stemmed.\n    */\n@@ -134,7 +141,7 @@ protected TokenStreamComponents createComponents(String fieldName,\n       Reader reader) {\n     final Tokenizer source = new StandardTokenizer(matchVersion, reader);\n     TokenStream result = new StandardFilter(matchVersion, source);\n-    result = new ElisionFilter(matchVersion, result);\n+    result = new ElisionFilter(result, DEFAULT_ARTICLES);\n     result = new LowerCaseFilter(matchVersion, result);\n     result = new StopFilter(matchVersion, result, stopwords);\n     if(!excltable.isEmpty())",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java",
                "sha": "9a6016bce1c3c8f071ad685b92b33508009653db",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java",
                "patch": "@@ -23,14 +23,14 @@\n \n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.core.StopFilter;\n-import org.apache.lucene.analysis.fr.ElisionFilter;\n import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.Tokenizer;\n import org.apache.lucene.analysis.snowball.SnowballFilter;\n import org.apache.lucene.analysis.standard.StandardFilter;\n import org.apache.lucene.analysis.standard.StandardTokenizer;\n import org.apache.lucene.analysis.util.CharArraySet;\n+import org.apache.lucene.analysis.util.ElisionFilter;\n import org.apache.lucene.analysis.util.StopwordAnalyzerBase;\n import org.apache.lucene.util.Version;\n import org.tartarus.snowball.ext.IrishStemmer;\n@@ -140,7 +140,7 @@ protected TokenStreamComponents createComponents(String fieldName,\n     StopFilter s = new StopFilter(matchVersion, result, HYPHENATIONS);\n     s.setEnablePositionIncrements(false);\n     result = s;\n-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);\n+    result = new ElisionFilter(result, DEFAULT_ARTICLES);\n     result = new IrishLowerCaseFilter(result);\n     result = new StopFilter(matchVersion, result, stopwords);\n     if(!stemExclusionSet.isEmpty())",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishAnalyzer.java",
                "sha": "f716cdb28a78a0102d5e84cbe58849fdf035f3bc",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java",
                "patch": "@@ -24,14 +24,14 @@\n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.core.LowerCaseFilter;\n import org.apache.lucene.analysis.core.StopFilter;\n-import org.apache.lucene.analysis.fr.ElisionFilter;\n import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.Tokenizer;\n import org.apache.lucene.analysis.snowball.SnowballFilter;\n import org.apache.lucene.analysis.standard.StandardFilter;\n import org.apache.lucene.analysis.standard.StandardTokenizer;\n import org.apache.lucene.analysis.util.CharArraySet;\n+import org.apache.lucene.analysis.util.ElisionFilter;\n import org.apache.lucene.analysis.util.StopwordAnalyzerBase;\n import org.apache.lucene.analysis.util.WordlistLoader;\n import org.apache.lucene.util.IOUtils;\n@@ -129,7 +129,7 @@ protected TokenStreamComponents createComponents(String fieldName,\n       Reader reader) {\n     final Tokenizer source = new StandardTokenizer(matchVersion, reader);\n     TokenStream result = new StandardFilter(matchVersion, source);\n-    result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);\n+    result = new ElisionFilter(result, DEFAULT_ARTICLES);\n     result = new LowerCaseFilter(matchVersion, result);\n     result = new StopFilter(matchVersion, result, stopwords);\n     if(!stemExclusionSet.isEmpty())",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java",
                "sha": "086d7bcbcb2d766612efb89cb82161b1556eb877",
                "status": "modified"
            },
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 5,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java",
                "patch": "@@ -27,13 +27,47 @@\n \n /**\n  * Factory for {@link PathHierarchyTokenizer}. \n+ * <p>\n+ * This factory is typically configured for use only in the <code>index</code> \n+ * Analyzer (or only in the <code>query</code> Analyzer, but never both).\n+ * </p>\n+ * <p>\n+ * For example, in the configuration below a query for \n+ * <code>Books/NonFic</code> will match documents indexed with values like \n+ * <code>Books/NonFic</code>, <code>Books/NonFic/Law</code>, \n+ * <code>Books/NonFic/Science/Physics</code>, etc. But it will not match \n+ * documents indexed with values like <code>Books</code>, or \n+ * <code>Books/Fic</code>...\n+ * </p>\n+ *\n  * <pre class=\"prettyprint\" >\n- * &lt;fieldType name=\"text_path\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n- *   &lt;analyzer&gt;\n- *     &lt;tokenizer class=\"solr.PathHierarchyTokenizerFactory\" delimiter=\"\\\" replace=\"/\"/&gt;\n+ * &lt;fieldType name=\"descendent_path\" class=\"solr.TextField\"&gt;\n+ *   &lt;analyzer type=\"index\"&gt;\n+ * \t   &lt;tokenizer class=\"solr.PathHierarchyTokenizerFactory\" delimiter=\"/\" /&gt;\n  *   &lt;/analyzer&gt;\n- * &lt;/fieldType&gt;</pre> \n- *\n+ *   &lt;analyzer type=\"query\"&gt;\n+ * \t   &lt;tokenizer class=\"solr.KeywordTokenizerFactory\" /&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;\n+ * </pre>\n+ * <p>\n+ * In this example however we see the oposite configuration, so that a query \n+ * for <code>Books/NonFic/Science/Physics</code> would match documents \n+ * containing <code>Books/NonFic</code>, <code>Books/NonFic/Science</code>, \n+ * or <code>Books/NonFic/Science/Physics</code>, but not \n+ * <code>Books/NonFic/Science/Physics/Theory</code> or \n+ * <code>Books/NonFic/Law</code>.\n+ * </p>\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"descendent_path\" class=\"solr.TextField\"&gt;\n+ *   &lt;analyzer type=\"index\"&gt;\n+ * \t   &lt;tokenizer class=\"solr.KeywordTokenizerFactory\" /&gt;\n+ *   &lt;/analyzer&gt;\n+ *   &lt;analyzer type=\"query\"&gt;\n+ * \t   &lt;tokenizer class=\"solr.PathHierarchyTokenizerFactory\" delimiter=\"/\" /&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;\n+ * </pre>\n  */\n public class PathHierarchyTokenizerFactory extends TokenizerFactory {\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java",
                "sha": "14122d8cd3acb34fb4a2d3d379fc4afc94907280",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 4,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java",
                "patch": "@@ -1,4 +1,4 @@\n-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/15/12 1:57 AM */\n+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 8/6/12 11:57 AM */\n \n package org.apache.lucene.analysis.standard;\n \n@@ -33,16 +33,16 @@\n /**\n  * This class is a scanner generated by \n  * <a href=\"http://www.jflex.de/\">JFlex</a> 1.5.0-SNAPSHOT\n- * on 7/15/12 1:57 AM from the specification file\n- * <tt>C:/cygwin/home/s/svn/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex</tt>\n+ * on 8/6/12 11:57 AM from the specification file\n+ * <tt>/home/rmuir/workspace/lucene-trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex</tt>\n  */\n class ClassicTokenizerImpl implements StandardTokenizerInterface {\n \n   /** This character denotes the end of file */\n   public static final int YYEOF = -1;\n \n   /** initial size of the lookahead buffer */\n-  private static final int ZZ_BUFFERSIZE = 16384;\n+  private static final int ZZ_BUFFERSIZE = 4096;\n \n   /** lexical states */\n   public static final int YYINITIAL = 0;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java",
                "sha": "ecfa18ab0d2634a1bf49f6fe46c71682e7b5a8d7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex",
                "patch": "@@ -36,6 +36,7 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n %function getNextToken\n %pack\n %char\n+%buffer 4096\n \n %{\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex",
                "sha": "da8a41045a543cead8c355f9227299204151e091",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro",
                "patch": "@@ -14,7 +14,7 @@\n  * limitations under the License.\n  */\n \n-// Generated using ICU4J 49.1.0.0 on Thursday, July 26, 2012 10:22:01 PM UTC\n+// Generated using ICU4J 49.1.0.0 on Monday, August 6, 2012 3:57:23 PM UTC\n // by org.apache.lucene.analysis.icu.GenerateJFlexSupplementaryMacros\n \n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro",
                "sha": "64c05aac079a29e9532a209bb03cdf10907947e4",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java",
                "patch": "@@ -1,4 +1,4 @@\n-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/26/12 6:22 PM */\n+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 8/6/12 11:57 AM */\n \n package org.apache.lucene.analysis.standard;\n \n@@ -43,7 +43,7 @@\n   public static final int YYEOF = -1;\n \n   /** initial size of the lookahead buffer */\n-  private static final int ZZ_BUFFERSIZE = 16384;\n+  private static final int ZZ_BUFFERSIZE = 4096;\n \n   /** lexical states */\n   public static final int YYINITIAL = 0;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.java",
                "sha": "f12e4b72ededb1cd99e5396e93082efb65f60d9a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex",
                "patch": "@@ -44,8 +44,9 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n %implements StandardTokenizerInterface\n %function getNextToken\n %char\n+%buffer 4096\n \n-%include src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro\n+%include SUPPLEMENTARY.jflex-macro\n ALetter = ([\\p{WB:ALetter}] | {ALetterSupp})\n Format =  ([\\p{WB:Format}] | {FormatSupp})\n Numeric = ([\\p{WB:Numeric}] | {NumericSupp})",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex",
                "sha": "a519b4a259f153fbdffa078d1ad69c8ed5601882",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.java",
                "patch": "@@ -1,4 +1,4 @@\n-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/26/12 6:22 PM */\n+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 8/6/12 11:57 AM */\n \n package org.apache.lucene.analysis.standard;\n \n@@ -46,7 +46,7 @@\n   public static final int YYEOF = -1;\n \n   /** initial size of the lookahead buffer */\n-  private static final int ZZ_BUFFERSIZE = 16384;\n+  private static final int ZZ_BUFFERSIZE = 4096;\n \n   /** lexical states */\n   public static final int YYINITIAL = 0;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.java",
                "sha": "d044805499eb6a38999a9afcce01eb3a5a91e965",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.jflex",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.jflex?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 2,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.jflex",
                "patch": "@@ -47,8 +47,9 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n %implements StandardTokenizerInterface\n %function getNextToken\n %char\n+%buffer 4096\n \n-%include src/java/org/apache/lucene/analysis/standard/SUPPLEMENTARY.jflex-macro\n+%include SUPPLEMENTARY.jflex-macro\n ALetter = ([\\p{WB:ALetter}] | {ALetterSupp})\n Format =  ([\\p{WB:Format}] | {FormatSupp})\n Numeric = ([\\p{WB:Numeric}] | {NumericSupp})\n@@ -88,7 +89,7 @@ HiraganaEx = {Hiragana} ({Format} | {Extend})*\n //     RFC-5321: Simple Mail Transfer Protocol\n //     RFC-5322: Internet Message Format\n \n-%include src/java/org/apache/lucene/analysis/standard/ASCIITLD.jflex-macro\n+%include ASCIITLD.jflex-macro\n \n DomainLabel = [A-Za-z0-9] ([-A-Za-z0-9]* [A-Za-z0-9])?\n DomainNameStrict = {DomainLabel} (\".\" {DomainLabel})* {ASCIITLD}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerImpl.jflex",
                "sha": "4c41d0de1cae2df7506be1938eab8d71504e4dd4",
                "status": "modified"
            },
            {
                "additions": 80,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ClasspathResourceLoader.java",
                "changes": 80,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ClasspathResourceLoader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ClasspathResourceLoader.java",
                "patch": "@@ -0,0 +1,80 @@\n+package org.apache.lucene.analysis.util;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * Simple {@link ResourceLoader} that uses {@link ClassLoader#getResourceAsStream(String)}\n+ * and {@link Class#forName(String,boolean,ClassLoader)} to open resources and\n+ * classes, respectively.\n+ */\n+public final class ClasspathResourceLoader implements ResourceLoader {\n+  private final Class<?> clazz;\n+  private final ClassLoader loader;\n+  \n+  /**\n+   * Creates an instance using the context classloader to load Resources and classes.\n+   * Resource paths must be absolute.\n+   */\n+  public ClasspathResourceLoader() {\n+    this(Thread.currentThread().getContextClassLoader());\n+  }\n+\n+  /**\n+   * Creates an instance using the given classloader to load Resources and classes.\n+   * Resource paths must be absolute.\n+   */\n+  public ClasspathResourceLoader(ClassLoader loader) {\n+    this(null, loader);\n+  }\n+\n+  /**\n+   * Creates an instance using the context classloader to load Resources and classes\n+   * Resources are resolved relative to the given class, if path is not absolute.\n+   */\n+  public ClasspathResourceLoader(Class<?> clazz) {\n+    this(clazz, clazz.getClassLoader());\n+  }\n+\n+  private ClasspathResourceLoader(Class<?> clazz, ClassLoader loader) {\n+    this.clazz = clazz;\n+    this.loader = loader;\n+  }\n+\n+  @Override\n+  public InputStream openResource(String resource) throws IOException {\n+    final InputStream stream = (clazz != null) ?\n+      clazz.getResourceAsStream(resource) :\n+      loader.getResourceAsStream(resource);\n+    if (stream == null)\n+      throw new IOException(\"Resource not found: \" + resource);\n+    return stream;\n+  }\n+\n+  @Override\n+  public <T> T newInstance(String cname, Class<T> expectedType) {\n+    try {\n+      final Class<? extends T> clazz = Class.forName(cname, true, loader).asSubclass(expectedType);\n+      return clazz.newInstance();\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Cannot instantiate class: \" + cname, e);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ClasspathResourceLoader.java",
                "sha": "e0097b4601b008c9f0b089e2821771e1682784a7",
                "status": "added"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 32,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java",
                "patch": "@@ -1,4 +1,4 @@\n-package org.apache.lucene.analysis.fr;\n+package org.apache.lucene.analysis.util;\n \n /*\n  * Licensed to the Apache Software Foundation (ASF) under one or more\n@@ -18,13 +18,11 @@\n  */\n \n import java.io.IOException;\n-import java.util.Arrays;\n \n import org.apache.lucene.analysis.TokenFilter;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.apache.lucene.analysis.util.CharArraySet;\n-import org.apache.lucene.util.Version;\n \n /**\n  * Removes elisions from a {@link TokenStream}. For example, \"l'avion\" (the plane) will be\n@@ -33,31 +31,17 @@\n  * @see <a href=\"http://fr.wikipedia.org/wiki/%C3%89lision\">Elision in Wikipedia</a>\n  */\n public final class ElisionFilter extends TokenFilter {\n-  private CharArraySet articles = CharArraySet.EMPTY_SET;\n+  private final CharArraySet articles;\n   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n-  private static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(\n-      new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(\n-          \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\"), true));\n   \n-  private static char[] apostrophes = {'\\'', '\\u2019'};\n-  \n-  /**\n-   * Constructs an elision filter with standard stop words\n-   */\n-  public ElisionFilter(Version matchVersion, TokenStream input) {\n-    this(matchVersion, input, DEFAULT_ARTICLES);\n-  }\n-\n   /**\n    * Constructs an elision filter with a Set of stop words\n-   * @param matchVersion the lucene backwards compatibility version\n    * @param input the source {@link TokenStream}\n    * @param articles a set of stopword articles\n    */\n-  public ElisionFilter(Version matchVersion, TokenStream input, CharArraySet articles) {\n+  public ElisionFilter(TokenStream input, CharArraySet articles) {\n     super(input);\n-    this.articles = CharArraySet.unmodifiableSet(\n-        new CharArraySet(matchVersion, articles, true));\n+    this.articles = articles;\n   }\n \n   /**\n@@ -69,22 +53,18 @@ public final boolean incrementToken() throws IOException {\n       char[] termBuffer = termAtt.buffer();\n       int termLength = termAtt.length();\n \n-      int minPoz = Integer.MAX_VALUE;\n-      for (int i = 0; i < apostrophes.length; i++) {\n-        char apos = apostrophes[i];\n-        // The equivalent of String.indexOf(ch)\n-        for (int poz = 0; poz < termLength ; poz++) {\n-          if (termBuffer[poz] == apos) {\n-            minPoz = Math.min(poz, minPoz);\n-            break;\n-          }\n+      int index = -1;\n+      for (int i = 0; i < termLength; i++) {\n+        char ch = termBuffer[i];\n+        if (ch == '\\'' || ch == '\\u2019') {\n+          index = i;\n+          break;\n         }\n       }\n \n       // An apostrophe has been found. If the prefix is an article strip it off.\n-      if (minPoz != Integer.MAX_VALUE\n-          && articles.contains(termAtt.buffer(), 0, minPoz)) {\n-        termAtt.copyBuffer(termAtt.buffer(), minPoz + 1, termAtt.length() - (minPoz + 1));\n+      if (index >= 0 && articles.contains(termBuffer, 0, index)) {\n+        termAtt.copyBuffer(termBuffer, index + 1, termLength - (index + 1));\n       }\n \n       return true;",
                "previous_filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilter.java",
                "sha": "c04d28760adb5c717ef6a2392167db135b080773",
                "status": "renamed"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 6,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java",
                "patch": "@@ -1,4 +1,4 @@\n-package org.apache.lucene.analysis.fr;\n+package org.apache.lucene.analysis.util;\n \n /*\n  * Licensed to the Apache Software Foundation (ASF) under one or more\n@@ -17,10 +17,9 @@\n  * limitations under the License.\n  */\n \n-import org.apache.lucene.analysis.util.*;\n-\n import java.io.IOException;\n import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.fr.FrenchAnalyzer;\n \n /**\n  * Factory for {@link ElisionFilter}.\n@@ -46,12 +45,13 @@ public void inform(ResourceLoader loader) throws IOException {\n     if (articlesFile != null) {\n       articles = getWordSet(loader, articlesFile, ignoreCase);\n     }\n+    if (articles == null) {\n+      articles = FrenchAnalyzer.DEFAULT_ARTICLES;\n+    }\n   }\n \n   public ElisionFilter create(TokenStream input) {\n-    assureMatchVersion();\n-    return articles == null ? new ElisionFilter(luceneMatchVersion,input) : \n-        new ElisionFilter(luceneMatchVersion,input,articles);\n+    return new ElisionFilter(input, articles);\n   }\n }\n ",
                "previous_filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ElisionFilterFactory.java",
                "sha": "aec6687b6bccbb05ac416ec140badd615106f2b2",
                "status": "renamed"
            },
            {
                "additions": 94,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/FilesystemResourceLoader.java",
                "changes": 94,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/FilesystemResourceLoader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/FilesystemResourceLoader.java",
                "patch": "@@ -0,0 +1,94 @@\n+package org.apache.lucene.analysis.util;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * Simple {@link ResourceLoader} that opens resource files\n+ * from the local file system, optionally resolving against\n+ * a base directory.\n+ * \n+ * <p>This loader wraps a delegate {@link ResourceLoader}\n+ * that is used to resolve all files, the current base directory\n+ * does not contain. {@link #newInstance} is always resolved\n+ * against the delegate, as a {@link ClassLoader} is needed.\n+ * \n+ * <p>You can chain several {@code FilesystemResourceLoader}s\n+ * to allow lookup of files in more than one base directory.\n+ */\n+public final class FilesystemResourceLoader implements ResourceLoader {\n+  private final File baseDirectory;\n+  private final ResourceLoader delegate;\n+  \n+  /**\n+   * Creates a resource loader that requires absolute filenames or relative to CWD\n+   * to resolve resources. Files not found in file system and class lookups\n+   * are delegated to context classloader.\n+   */\n+  public FilesystemResourceLoader() {\n+    this((File) null);\n+  }\n+\n+  /**\n+   * Creates a resource loader that resolves resources against the given\n+   * base directory (may be {@code null} to refer to CWD).\n+   * Files not found in file system and class lookups are delegated to context\n+   * classloader.\n+   */\n+  public FilesystemResourceLoader(File baseDirectory) {\n+    this(baseDirectory, new ClasspathResourceLoader());\n+  }\n+\n+  /**\n+   * Creates a resource loader that resolves resources against the given\n+   * base directory (may be {@code null} to refer to CWD).\n+   * Files not found in file system and class lookups are delegated\n+   * to the given delegate {@link ResourceLoader}.\n+   */\n+  public FilesystemResourceLoader(File baseDirectory, ResourceLoader delegate) {\n+    if (baseDirectory != null && !baseDirectory.isDirectory())\n+      throw new IllegalArgumentException(\"baseDirectory is not a directory or null\");\n+    if (delegate == null)\n+      throw new IllegalArgumentException(\"delegate ResourceLoader may not be null\");\n+    this.baseDirectory = baseDirectory;\n+    this.delegate = delegate;\n+  }\n+\n+  @Override\n+  public InputStream openResource(String resource) throws IOException {\n+    try {\n+      File file = new File (resource);\n+      if (baseDirectory != null && !file.isAbsolute()) {\n+        file = new File(baseDirectory, resource);\n+      }\n+      return new FileInputStream(file);\n+    } catch (FileNotFoundException fnfe) {\n+      return delegate.openResource(resource);\n+    }\n+  }\n+\n+  @Override\n+  public <T> T newInstance(String cname, Class<T> expectedType) {\n+    return delegate.newInstance(cname, expectedType);\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/FilesystemResourceLoader.java",
                "sha": "744b1b70ee3f326acc6246fc08632ec6ec7f1264",
                "status": "added"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 4,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.java",
                "patch": "@@ -1,4 +1,4 @@\n-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/15/12 1:57 AM */\n+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 8/6/12 11:57 AM */\n \n package org.apache.lucene.analysis.wikipedia;\n \n@@ -25,16 +25,16 @@\n /**\n  * This class is a scanner generated by \n  * <a href=\"http://www.jflex.de/\">JFlex</a> 1.5.0-SNAPSHOT\n- * on 7/15/12 1:57 AM from the specification file\n- * <tt>C:/cygwin/home/s/svn/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex</tt>\n+ * on 8/6/12 11:57 AM from the specification file\n+ * <tt>/home/rmuir/workspace/lucene-trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex</tt>\n  */\n class WikipediaTokenizerImpl {\n \n   /** This character denotes the end of file */\n   public static final int YYEOF = -1;\n \n   /** initial size of the lookahead buffer */\n-  private static final int ZZ_BUFFERSIZE = 16384;\n+  private static final int ZZ_BUFFERSIZE = 4096;\n \n   /** lexical states */\n   public static final int THREE_SINGLE_QUOTES_STATE = 10;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.java",
                "sha": "db7ac88ffebb816669bc14925f3c617397e7d999",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex",
                "patch": "@@ -27,6 +27,7 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n %function getNextToken\n %pack\n %char\n+%buffer 4096\n \n %{\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerImpl.jflex",
                "sha": "dfbf660b63c9074713d1ab084db230b54969dcfe",
                "status": "modified"
            },
            {
                "additions": 383,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DanishStemmer.java",
                "changes": 750,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DanishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 367,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/DanishStemmer.java",
                "patch": "@@ -1,423 +1,439 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class DanishStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"hed\", -1, 1, \"\", this),\n-            new Among ( \"ethed\", 0, 1, \"\", this),\n-            new Among ( \"ered\", -1, 1, \"\", this),\n-            new Among ( \"e\", -1, 1, \"\", this),\n-            new Among ( \"erede\", 3, 1, \"\", this),\n-            new Among ( \"ende\", 3, 1, \"\", this),\n-            new Among ( \"erende\", 5, 1, \"\", this),\n-            new Among ( \"ene\", 3, 1, \"\", this),\n-            new Among ( \"erne\", 3, 1, \"\", this),\n-            new Among ( \"ere\", 3, 1, \"\", this),\n-            new Among ( \"en\", -1, 1, \"\", this),\n-            new Among ( \"heden\", 10, 1, \"\", this),\n-            new Among ( \"eren\", 10, 1, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"heder\", 13, 1, \"\", this),\n-            new Among ( \"erer\", 13, 1, \"\", this),\n-            new Among ( \"s\", -1, 2, \"\", this),\n-            new Among ( \"heds\", 16, 1, \"\", this),\n-            new Among ( \"es\", 16, 1, \"\", this),\n-            new Among ( \"endes\", 18, 1, \"\", this),\n-            new Among ( \"erendes\", 19, 1, \"\", this),\n-            new Among ( \"enes\", 18, 1, \"\", this),\n-            new Among ( \"ernes\", 18, 1, \"\", this),\n-            new Among ( \"eres\", 18, 1, \"\", this),\n-            new Among ( \"ens\", 16, 1, \"\", this),\n-            new Among ( \"hedens\", 24, 1, \"\", this),\n-            new Among ( \"erens\", 24, 1, \"\", this),\n-            new Among ( \"ers\", 16, 1, \"\", this),\n-            new Among ( \"ets\", 16, 1, \"\", this),\n-            new Among ( \"erets\", 28, 1, \"\", this),\n-            new Among ( \"et\", -1, 1, \"\", this),\n-            new Among ( \"eret\", 30, 1, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"gd\", -1, -1, \"\", this),\n-            new Among ( \"dt\", -1, -1, \"\", this),\n-            new Among ( \"gt\", -1, -1, \"\", this),\n-            new Among ( \"kt\", -1, -1, \"\", this)\n-        };\n+        private final static DanishStemmer methodObject = new DanishStemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"ig\", -1, 1, \"\", this),\n-            new Among ( \"lig\", 0, 1, \"\", this),\n-            new Among ( \"elig\", 1, 1, \"\", this),\n-            new Among ( \"els\", -1, 1, \"\", this),\n-            new Among ( \"l\\u00F8st\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"hed\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ethed\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"ered\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"e\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"erede\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"ende\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"erende\", 5, 1, \"\", methodObject ),\n+                    new Among ( \"ene\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"erne\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"ere\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"en\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"heden\", 10, 1, \"\", methodObject ),\n+                    new Among ( \"eren\", 10, 1, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"heder\", 13, 1, \"\", methodObject ),\n+                    new Among ( \"erer\", 13, 1, \"\", methodObject ),\n+                    new Among ( \"s\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"heds\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"es\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"endes\", 18, 1, \"\", methodObject ),\n+                    new Among ( \"erendes\", 19, 1, \"\", methodObject ),\n+                    new Among ( \"enes\", 18, 1, \"\", methodObject ),\n+                    new Among ( \"ernes\", 18, 1, \"\", methodObject ),\n+                    new Among ( \"eres\", 18, 1, \"\", methodObject ),\n+                    new Among ( \"ens\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"hedens\", 24, 1, \"\", methodObject ),\n+                    new Among ( \"erens\", 24, 1, \"\", methodObject ),\n+                    new Among ( \"ers\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"ets\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"erets\", 28, 1, \"\", methodObject ),\n+                    new Among ( \"et\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"eret\", 30, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 0, 128 };\n+                private final static Among a_1[] = {\n+                    new Among ( \"gd\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"dt\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"gt\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"kt\", -1, -1, \"\", methodObject )\n+                };\n \n-        private static final char g_s_ending[] = {239, 254, 42, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16 };\n+                private final static Among a_2[] = {\n+                    new Among ( \"ig\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lig\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"elig\", 1, 1, \"\", methodObject ),\n+                    new Among ( \"els\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"l\\u00F8st\", -1, 2, \"\", methodObject )\n+                };\n+\n+                private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 0, 128 };\n+\n+                private static final char g_s_ending[] = {239, 254, 42, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16 };\n \n         private int I_x;\n         private int I_p1;\n-        private StringBuilder S_ch = new StringBuilder();\n+        private java.lang.StringBuilder S_ch = new java.lang.StringBuilder();\n \n-        private void copy_from(DanishStemmer other) {\n-            I_x = other.I_x;\n-            I_p1 = other.I_p1;\n-            S_ch = other.S_ch;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(DanishStemmer other) {\n+                    I_x = other.I_x;\n+                    I_p1 = other.I_p1;\n+                    S_ch = other.S_ch;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n             int v_2;\n-            // (, line 29\n-            I_p1 = limit;\n-            // test, line 33\n-            v_1 = cursor;\n-            // (, line 33\n-            // hop, line 33\n-            {\n-                int c = cursor + 3;\n-                if (0 > c || c > limit)\n-                {\n-                    return false;\n-                }\n-                cursor = c;\n-            }\n-            // setmark x, line 33\n-            I_x = cursor;\n-            cursor = v_1;\n-            // goto, line 34\n-            golab0: while(true)\n-            {\n-                v_2 = cursor;\n-                lab1: do {\n-                    if (!(in_grouping(g_v, 97, 248)))\n+                    // (, line 29\n+                    I_p1 = limit;\n+                    // test, line 33\n+                    v_1 = cursor;\n+                    // (, line 33\n+                    // hop, line 33\n                     {\n-                        break lab1;\n+                        int c = cursor + 3;\n+                        if (0 > c || c > limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor = c;\n                     }\n-                    cursor = v_2;\n-                    break golab0;\n-                } while (false);\n-                cursor = v_2;\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 34\n-            golab2: while(true)\n-            {\n-                lab3: do {\n-                    if (!(out_grouping(g_v, 97, 248)))\n+                    // setmark x, line 33\n+                    I_x = cursor;\n+                    cursor = v_1;\n+                    // goto, line 34\n+                    golab0: while(true)\n+                    {\n+                        v_2 = cursor;\n+                        lab1: do {\n+                            if (!(in_grouping(g_v, 97, 248)))\n+                            {\n+                                break lab1;\n+                            }\n+                            cursor = v_2;\n+                            break golab0;\n+                        } while (false);\n+                        cursor = v_2;\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n+                    }\n+                    // gopast, line 34\n+                    golab2: while(true)\n                     {\n-                        break lab3;\n+                        lab3: do {\n+                            if (!(out_grouping(g_v, 97, 248)))\n+                            {\n+                                break lab3;\n+                            }\n+                            break golab2;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab2;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // setmark p1, line 34\n-            I_p1 = cursor;\n-            // try, line 35\n-            lab4: do {\n-                // (, line 35\n-                if (!(I_p1 < I_x))\n-                {\n-                    break lab4;\n+                    // setmark p1, line 34\n+                    I_p1 = cursor;\n+                    // try, line 35\n+                    lab4: do {\n+                        // (, line 35\n+                        if (!(I_p1 < I_x))\n+                        {\n+                            break lab4;\n+                        }\n+                        I_p1 = I_x;\n+                    } while (false);\n+                    return true;\n                 }\n-                I_p1 = I_x;\n-            } while (false);\n-            return true;\n-        }\n \n-        private boolean r_main_suffix() {\n+                private boolean r_main_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n-            // (, line 40\n-            // setlimit, line 41\n-            v_1 = limit - cursor;\n-            // tomark, line 41\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 41\n-            // [, line 41\n-            ket = cursor;\n-            // substring, line 41\n-            among_var = find_among_b(a_0, 32);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 41\n-            bra = cursor;\n-            limit_backward = v_2;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 48\n-                    // delete, line 48\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 50\n-                    if (!(in_grouping_b(g_s_ending, 97, 229)))\n+                    // (, line 40\n+                    // setlimit, line 41\n+                    v_1 = limit - cursor;\n+                    // tomark, line 41\n+                    if (cursor < I_p1)\n                     {\n                         return false;\n                     }\n-                    // delete, line 50\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 41\n+                    // [, line 41\n+                    ket = cursor;\n+                    // substring, line 41\n+                    among_var = find_among_b(a_0, 32);\n+                    if (among_var == 0)\n+                    {\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    // ], line 41\n+                    bra = cursor;\n+                    limit_backward = v_2;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 48\n+                            // delete, line 48\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 50\n+                            if (!(in_grouping_b(g_s_ending, 97, 229)))\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 50\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_consonant_pair() {\n+                private boolean r_consonant_pair() {\n             int v_1;\n             int v_2;\n             int v_3;\n-            // (, line 54\n-            // test, line 55\n-            v_1 = limit - cursor;\n-            // (, line 55\n-            // setlimit, line 56\n-            v_2 = limit - cursor;\n-            // tomark, line 56\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_3 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_2;\n-            // (, line 56\n-            // [, line 56\n-            ket = cursor;\n-            // substring, line 56\n-            if (find_among_b(a_1, 4) == 0)\n-            {\n-                limit_backward = v_3;\n-                return false;\n-            }\n-            // ], line 56\n-            bra = cursor;\n-            limit_backward = v_3;\n-            cursor = limit - v_1;\n-            // next, line 62\n-            if (cursor <= limit_backward)\n-            {\n-                return false;\n-            }\n-            cursor--;\n-            // ], line 62\n-            bra = cursor;\n-            // delete, line 62\n-            slice_del();\n-            return true;\n-        }\n+                    // (, line 54\n+                    // test, line 55\n+                    v_1 = limit - cursor;\n+                    // (, line 55\n+                    // setlimit, line 56\n+                    v_2 = limit - cursor;\n+                    // tomark, line 56\n+                    if (cursor < I_p1)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_3 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_2;\n+                    // (, line 56\n+                    // [, line 56\n+                    ket = cursor;\n+                    // substring, line 56\n+                    if (find_among_b(a_1, 4) == 0)\n+                    {\n+                        limit_backward = v_3;\n+                        return false;\n+                    }\n+                    // ], line 56\n+                    bra = cursor;\n+                    limit_backward = v_3;\n+                    cursor = limit - v_1;\n+                    // next, line 62\n+                    if (cursor <= limit_backward)\n+                    {\n+                        return false;\n+                    }\n+                    cursor--;\n+                    // ], line 62\n+                    bra = cursor;\n+                    // delete, line 62\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_other_suffix() {\n+                private boolean r_other_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n-            // (, line 65\n-            // do, line 66\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 66\n-                // [, line 66\n-                ket = cursor;\n-                // literal, line 66\n-                if (!(eq_s_b(2, \"st\")))\n-                {\n-                    break lab0;\n-                }\n-                // ], line 66\n-                bra = cursor;\n-                // literal, line 66\n-                if (!(eq_s_b(2, \"ig\")))\n-                {\n-                    break lab0;\n-                }\n-                // delete, line 66\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_1;\n-            // setlimit, line 67\n-            v_2 = limit - cursor;\n-            // tomark, line 67\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_3 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_2;\n-            // (, line 67\n-            // [, line 67\n-            ket = cursor;\n-            // substring, line 67\n-            among_var = find_among_b(a_2, 5);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_3;\n-                return false;\n-            }\n-            // ], line 67\n-            bra = cursor;\n-            limit_backward = v_3;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 70\n-                    // delete, line 70\n-                    slice_del();\n-                    // do, line 70\n-                    v_4 = limit - cursor;\n-                    lab1: do {\n-                        // call consonant_pair, line 70\n-                        if (!r_consonant_pair())\n+                    // (, line 65\n+                    // do, line 66\n+                    v_1 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 66\n+                        // [, line 66\n+                        ket = cursor;\n+                        // literal, line 66\n+                        if (!(eq_s_b(2, \"st\")))\n                         {\n-                            break lab1;\n+                            break lab0;\n+                        }\n+                        // ], line 66\n+                        bra = cursor;\n+                        // literal, line 66\n+                        if (!(eq_s_b(2, \"ig\")))\n+                        {\n+                            break lab0;\n                         }\n+                        // delete, line 66\n+                        slice_del();\n                     } while (false);\n-                    cursor = limit - v_4;\n-                    break;\n-                case 2:\n-                    // (, line 72\n-                    // <-, line 72\n-                    slice_from(\"l\\u00F8s\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    cursor = limit - v_1;\n+                    // setlimit, line 67\n+                    v_2 = limit - cursor;\n+                    // tomark, line 67\n+                    if (cursor < I_p1)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_3 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_2;\n+                    // (, line 67\n+                    // [, line 67\n+                    ket = cursor;\n+                    // substring, line 67\n+                    among_var = find_among_b(a_2, 5);\n+                    if (among_var == 0)\n+                    {\n+                        limit_backward = v_3;\n+                        return false;\n+                    }\n+                    // ], line 67\n+                    bra = cursor;\n+                    limit_backward = v_3;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 70\n+                            // delete, line 70\n+                            slice_del();\n+                            // do, line 70\n+                            v_4 = limit - cursor;\n+                            lab1: do {\n+                                // call consonant_pair, line 70\n+                                if (!r_consonant_pair())\n+                                {\n+                                    break lab1;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_4;\n+                            break;\n+                        case 2:\n+                            // (, line 72\n+                            // <-, line 72\n+                            slice_from(\"l\\u00F8s\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_undouble() {\n+                private boolean r_undouble() {\n             int v_1;\n             int v_2;\n-            // (, line 75\n-            // setlimit, line 76\n-            v_1 = limit - cursor;\n-            // tomark, line 76\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 76\n-            // [, line 76\n-            ket = cursor;\n-            if (!(out_grouping_b(g_v, 97, 248)))\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 76\n-            bra = cursor;\n-            // -> ch, line 76\n-            S_ch = slice_to(S_ch);\n-            limit_backward = v_2;\n-            // name ch, line 77\n-            if (!(eq_v_b(S_ch)))\n-            {\n-                return false;\n-            }\n-            // delete, line 78\n-            slice_del();\n-            return true;\n-        }\n+                    // (, line 75\n+                    // setlimit, line 76\n+                    v_1 = limit - cursor;\n+                    // tomark, line 76\n+                    if (cursor < I_p1)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 76\n+                    // [, line 76\n+                    ket = cursor;\n+                    if (!(out_grouping_b(g_v, 97, 248)))\n+                    {\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    // ], line 76\n+                    bra = cursor;\n+                    // -> ch, line 76\n+                    S_ch = slice_to(S_ch);\n+                    limit_backward = v_2;\n+                    // name ch, line 77\n+                    if (!(eq_v_b(S_ch)))\n+                    {\n+                        return false;\n+                    }\n+                    // delete, line 78\n+                    slice_del();\n+                    return true;\n+                }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n-            // (, line 82\n-            // do, line 84\n-            v_1 = cursor;\n-            lab0: do {\n-                // call mark_regions, line 84\n-                if (!r_mark_regions())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // backwards, line 85\n-            limit_backward = cursor; cursor = limit;\n-            // (, line 85\n-            // do, line 86\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // call main_suffix, line 86\n-                if (!r_main_suffix())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 87\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call consonant_pair, line 87\n-                if (!r_consonant_pair())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 88\n-            v_4 = limit - cursor;\n-            lab3: do {\n-                // call other_suffix, line 88\n-                if (!r_other_suffix())\n-                {\n-                    break lab3;\n-                }\n-            } while (false);\n-            cursor = limit - v_4;\n-            // do, line 89\n-            v_5 = limit - cursor;\n-            lab4: do {\n-                // call undouble, line 89\n-                if (!r_undouble())\n-                {\n-                    break lab4;\n+                    // (, line 82\n+                    // do, line 84\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call mark_regions, line 84\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // backwards, line 85\n+                    limit_backward = cursor; cursor = limit;\n+                    // (, line 85\n+                    // do, line 86\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // call main_suffix, line 86\n+                        if (!r_main_suffix())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_2;\n+                    // do, line 87\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call consonant_pair, line 87\n+                        if (!r_consonant_pair())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    // do, line 88\n+                    v_4 = limit - cursor;\n+                    lab3: do {\n+                        // call other_suffix, line 88\n+                        if (!r_other_suffix())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_4;\n+                    // do, line 89\n+                    v_5 = limit - cursor;\n+                    lab4: do {\n+                        // call undouble, line 89\n+                        if (!r_undouble())\n+                        {\n+                            break lab4;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_5;\n+                    cursor = limit_backward;                    return true;\n                 }\n-            } while (false);\n-            cursor = limit - v_5;\n-            cursor = limit_backward;            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof DanishStemmer;\n         }\n \n-}\n+        public int hashCode() {\n+            return DanishStemmer.class.getName().hashCode();\n+        }\n \n+\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DanishStemmer.java",
                "sha": "820c39174fc681196771b4c9cf468d8d4ebc6a37",
                "status": "modified"
            },
            {
                "additions": 726,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DutchStemmer.java",
                "changes": 1435,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DutchStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 709,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/DutchStemmer.java",
                "patch": "@@ -1,490 +1,497 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class DutchStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"\", -1, 6, \"\", this),\n-            new Among ( \"\\u00E1\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E4\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E9\", 0, 2, \"\", this),\n-            new Among ( \"\\u00EB\", 0, 2, \"\", this),\n-            new Among ( \"\\u00ED\", 0, 3, \"\", this),\n-            new Among ( \"\\u00EF\", 0, 3, \"\", this),\n-            new Among ( \"\\u00F3\", 0, 4, \"\", this),\n-            new Among ( \"\\u00F6\", 0, 4, \"\", this),\n-            new Among ( \"\\u00FA\", 0, 5, \"\", this),\n-            new Among ( \"\\u00FC\", 0, 5, \"\", this)\n-        };\n-\n-        private Among a_1[] = {\n-            new Among ( \"\", -1, 3, \"\", this),\n-            new Among ( \"I\", 0, 2, \"\", this),\n-            new Among ( \"Y\", 0, 1, \"\", this)\n-        };\n-\n-        private Among a_2[] = {\n-            new Among ( \"dd\", -1, -1, \"\", this),\n-            new Among ( \"kk\", -1, -1, \"\", this),\n-            new Among ( \"tt\", -1, -1, \"\", this)\n-        };\n-\n-        private Among a_3[] = {\n-            new Among ( \"ene\", -1, 2, \"\", this),\n-            new Among ( \"se\", -1, 3, \"\", this),\n-            new Among ( \"en\", -1, 2, \"\", this),\n-            new Among ( \"heden\", 2, 1, \"\", this),\n-            new Among ( \"s\", -1, 3, \"\", this)\n-        };\n-\n-        private Among a_4[] = {\n-            new Among ( \"end\", -1, 1, \"\", this),\n-            new Among ( \"ig\", -1, 2, \"\", this),\n-            new Among ( \"ing\", -1, 1, \"\", this),\n-            new Among ( \"lijk\", -1, 3, \"\", this),\n-            new Among ( \"baar\", -1, 4, \"\", this),\n-            new Among ( \"bar\", -1, 5, \"\", this)\n-        };\n-\n-        private Among a_5[] = {\n-            new Among ( \"aa\", -1, -1, \"\", this),\n-            new Among ( \"ee\", -1, -1, \"\", this),\n-            new Among ( \"oo\", -1, -1, \"\", this),\n-            new Among ( \"uu\", -1, -1, \"\", this)\n-        };\n-\n-        private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n-\n-        private static final char g_v_I[] = {1, 0, 0, 17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n-\n-        private static final char g_v_j[] = {17, 67, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n+private static final long serialVersionUID = 1L;\n+\n+        private final static DutchStemmer methodObject = new DutchStemmer ();\n+\n+                private final static Among a_0[] = {\n+                    new Among ( \"\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E1\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E4\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00EB\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00ED\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00EF\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00F3\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00F6\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00FA\", 0, 5, \"\", methodObject ),\n+                    new Among ( \"\\u00FC\", 0, 5, \"\", methodObject )\n+                };\n+\n+                private final static Among a_1[] = {\n+                    new Among ( \"\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"I\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"Y\", 0, 1, \"\", methodObject )\n+                };\n+\n+                private final static Among a_2[] = {\n+                    new Among ( \"dd\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"kk\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"tt\", -1, -1, \"\", methodObject )\n+                };\n+\n+                private final static Among a_3[] = {\n+                    new Among ( \"ene\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"se\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"en\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"heden\", 2, 1, \"\", methodObject ),\n+                    new Among ( \"s\", -1, 3, \"\", methodObject )\n+                };\n+\n+                private final static Among a_4[] = {\n+                    new Among ( \"end\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ig\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ing\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lijk\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"baar\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"bar\", -1, 5, \"\", methodObject )\n+                };\n+\n+                private final static Among a_5[] = {\n+                    new Among ( \"aa\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ee\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"oo\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"uu\", -1, -1, \"\", methodObject )\n+                };\n+\n+                private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n+\n+                private static final char g_v_I[] = {1, 0, 0, 17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n+\n+                private static final char g_v_j[] = {17, 67, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128 };\n \n         private int I_p2;\n         private int I_p1;\n         private boolean B_e_found;\n \n-        private void copy_from(DutchStemmer other) {\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            B_e_found = other.B_e_found;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(DutchStemmer other) {\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    B_e_found = other.B_e_found;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_prelude() {\n+                private boolean r_prelude() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n             int v_6;\n-            // (, line 41\n-            // test, line 42\n-            v_1 = cursor;\n-            // repeat, line 42\n-            replab0: while(true)\n-            {\n-                v_2 = cursor;\n-                lab1: do {\n-                    // (, line 42\n-                    // [, line 43\n-                    bra = cursor;\n-                    // substring, line 43\n-                    among_var = find_among(a_0, 11);\n-                    if (among_var == 0)\n+                    // (, line 41\n+                    // test, line 42\n+                    v_1 = cursor;\n+                    // repeat, line 42\n+                    replab0: while(true)\n                     {\n-                        break lab1;\n-                    }\n-                    // ], line 43\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab1;\n-                        case 1:\n-                            // (, line 45\n-                            // <-, line 45\n-                            slice_from(\"a\");\n-                            break;\n-                        case 2:\n-                            // (, line 47\n-                            // <-, line 47\n-                            slice_from(\"e\");\n-                            break;\n-                        case 3:\n-                            // (, line 49\n-                            // <-, line 49\n-                            slice_from(\"i\");\n-                            break;\n-                        case 4:\n-                            // (, line 51\n-                            // <-, line 51\n-                            slice_from(\"o\");\n-                            break;\n-                        case 5:\n-                            // (, line 53\n-                            // <-, line 53\n-                            slice_from(\"u\");\n-                            break;\n-                        case 6:\n-                            // (, line 54\n-                            // next, line 54\n-                            if (cursor >= limit)\n+                        v_2 = cursor;\n+                        lab1: do {\n+                            // (, line 42\n+                            // [, line 43\n+                            bra = cursor;\n+                            // substring, line 43\n+                            among_var = find_among(a_0, 11);\n+                            if (among_var == 0)\n                             {\n                                 break lab1;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 43\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 45\n+                                    // <-, line 45\n+                                    slice_from(\"a\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 47\n+                                    // <-, line 47\n+                                    slice_from(\"e\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 49\n+                                    // <-, line 49\n+                                    slice_from(\"i\");\n+                                    break;\n+                                case 4:\n+                                    // (, line 51\n+                                    // <-, line 51\n+                                    slice_from(\"o\");\n+                                    break;\n+                                case 5:\n+                                    // (, line 53\n+                                    // <-, line 53\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 6:\n+                                    // (, line 54\n+                                    // next, line 54\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_2;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_2;\n-                break replab0;\n-            }\n-            cursor = v_1;\n-            // try, line 57\n-            v_3 = cursor;\n-            lab2: do {\n-                // (, line 57\n-                // [, line 57\n-                bra = cursor;\n-                // literal, line 57\n-                if (!(eq_s(1, \"y\")))\n-                {\n-                    cursor = v_3;\n-                    break lab2;\n-                }\n-                // ], line 57\n-                ket = cursor;\n-                // <-, line 57\n-                slice_from(\"Y\");\n-            } while (false);\n-            // repeat, line 58\n-            replab3: while(true)\n-            {\n-                v_4 = cursor;\n-                lab4: do {\n-                    // goto, line 58\n-                    golab5: while(true)\n+                    cursor = v_1;\n+                    // try, line 57\n+                    v_3 = cursor;\n+                    lab2: do {\n+                        // (, line 57\n+                        // [, line 57\n+                        bra = cursor;\n+                        // literal, line 57\n+                        if (!(eq_s(1, \"y\")))\n+                        {\n+                            cursor = v_3;\n+                            break lab2;\n+                        }\n+                        // ], line 57\n+                        ket = cursor;\n+                        // <-, line 57\n+                        slice_from(\"Y\");\n+                    } while (false);\n+                    // repeat, line 58\n+                    replab3: while(true)\n                     {\n-                        v_5 = cursor;\n-                        lab6: do {\n-                            // (, line 58\n-                            if (!(in_grouping(g_v, 97, 232)))\n+                        v_4 = cursor;\n+                        lab4: do {\n+                            // goto, line 58\n+                            golab5: while(true)\n                             {\n-                                break lab6;\n-                            }\n-                            // [, line 59\n-                            bra = cursor;\n-                            // or, line 59\n-                            lab7: do {\n-                                v_6 = cursor;\n-                                lab8: do {\n-                                    // (, line 59\n-                                    // literal, line 59\n-                                    if (!(eq_s(1, \"i\")))\n-                                    {\n-                                        break lab8;\n-                                    }\n-                                    // ], line 59\n-                                    ket = cursor;\n+                                v_5 = cursor;\n+                                lab6: do {\n+                                    // (, line 58\n                                     if (!(in_grouping(g_v, 97, 232)))\n                                     {\n-                                        break lab8;\n+                                        break lab6;\n                                     }\n-                                    // <-, line 59\n-                                    slice_from(\"I\");\n-                                    break lab7;\n+                                    // [, line 59\n+                                    bra = cursor;\n+                                    // or, line 59\n+                                    lab7: do {\n+                                        v_6 = cursor;\n+                                        lab8: do {\n+                                            // (, line 59\n+                                            // literal, line 59\n+                                            if (!(eq_s(1, \"i\")))\n+                                            {\n+                                                break lab8;\n+                                            }\n+                                            // ], line 59\n+                                            ket = cursor;\n+                                            if (!(in_grouping(g_v, 97, 232)))\n+                                            {\n+                                                break lab8;\n+                                            }\n+                                            // <-, line 59\n+                                            slice_from(\"I\");\n+                                            break lab7;\n+                                        } while (false);\n+                                        cursor = v_6;\n+                                        // (, line 60\n+                                        // literal, line 60\n+                                        if (!(eq_s(1, \"y\")))\n+                                        {\n+                                            break lab6;\n+                                        }\n+                                        // ], line 60\n+                                        ket = cursor;\n+                                        // <-, line 60\n+                                        slice_from(\"Y\");\n+                                    } while (false);\n+                                    cursor = v_5;\n+                                    break golab5;\n                                 } while (false);\n-                                cursor = v_6;\n-                                // (, line 60\n-                                // literal, line 60\n-                                if (!(eq_s(1, \"y\")))\n+                                cursor = v_5;\n+                                if (cursor >= limit)\n                                 {\n-                                    break lab6;\n+                                    break lab4;\n                                 }\n-                                // ], line 60\n-                                ket = cursor;\n-                                // <-, line 60\n-                                slice_from(\"Y\");\n-                            } while (false);\n-                            cursor = v_5;\n-                            break golab5;\n+                                cursor++;\n+                            }\n+                            continue replab3;\n+                        } while (false);\n+                        cursor = v_4;\n+                        break replab3;\n+                    }\n+                    return true;\n+                }\n+\n+                private boolean r_mark_regions() {\n+                    // (, line 64\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // gopast, line 69\n+                    golab0: while(true)\n+                    {\n+                        lab1: do {\n+                            if (!(in_grouping(g_v, 97, 232)))\n+                            {\n+                                break lab1;\n+                            }\n+                            break golab0;\n                         } while (false);\n-                        cursor = v_5;\n                         if (cursor >= limit)\n                         {\n-                            break lab4;\n+                            return false;\n                         }\n                         cursor++;\n                     }\n-                    continue replab3;\n-                } while (false);\n-                cursor = v_4;\n-                break replab3;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_mark_regions() {\n-            // (, line 64\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // gopast, line 69\n-            golab0: while(true)\n-            {\n-                lab1: do {\n-                    if (!(in_grouping(g_v, 97, 232)))\n-                    {\n-                        break lab1;\n-                    }\n-                    break golab0;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 69\n-            golab2: while(true)\n-            {\n-                lab3: do {\n-                    if (!(out_grouping(g_v, 97, 232)))\n+                    // gopast, line 69\n+                    golab2: while(true)\n                     {\n-                        break lab3;\n+                        lab3: do {\n+                            if (!(out_grouping(g_v, 97, 232)))\n+                            {\n+                                break lab3;\n+                            }\n+                            break golab2;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab2;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // setmark p1, line 69\n-            I_p1 = cursor;\n-            // try, line 70\n-            lab4: do {\n-                // (, line 70\n-                if (!(I_p1 < 3))\n-                {\n-                    break lab4;\n-                }\n-                I_p1 = 3;\n-            } while (false);\n-            // gopast, line 71\n-            golab5: while(true)\n-            {\n-                lab6: do {\n-                    if (!(in_grouping(g_v, 97, 232)))\n+                    // setmark p1, line 69\n+                    I_p1 = cursor;\n+                    // try, line 70\n+                    lab4: do {\n+                        // (, line 70\n+                        if (!(I_p1 < 3))\n+                        {\n+                            break lab4;\n+                        }\n+                        I_p1 = 3;\n+                    } while (false);\n+                    // gopast, line 71\n+                    golab5: while(true)\n                     {\n-                        break lab6;\n+                        lab6: do {\n+                            if (!(in_grouping(g_v, 97, 232)))\n+                            {\n+                                break lab6;\n+                            }\n+                            break golab5;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab5;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 71\n-            golab7: while(true)\n-            {\n-                lab8: do {\n-                    if (!(out_grouping(g_v, 97, 232)))\n+                    // gopast, line 71\n+                    golab7: while(true)\n                     {\n-                        break lab8;\n+                        lab8: do {\n+                            if (!(out_grouping(g_v, 97, 232)))\n+                            {\n+                                break lab8;\n+                            }\n+                            break golab7;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab7;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n+                    // setmark p2, line 71\n+                    I_p2 = cursor;\n+                    return true;\n                 }\n-                cursor++;\n-            }\n-            // setmark p2, line 71\n-            I_p2 = cursor;\n-            return true;\n-        }\n \n-        private boolean r_postlude() {\n+                private boolean r_postlude() {\n             int among_var;\n             int v_1;\n-            // repeat, line 75\n-            replab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // (, line 75\n-                    // [, line 77\n-                    bra = cursor;\n-                    // substring, line 77\n-                    among_var = find_among(a_1, 3);\n-                    if (among_var == 0)\n+                    // repeat, line 75\n+                    replab0: while(true)\n                     {\n-                        break lab1;\n-                    }\n-                    // ], line 77\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab1;\n-                        case 1:\n-                            // (, line 78\n-                            // <-, line 78\n-                            slice_from(\"y\");\n-                            break;\n-                        case 2:\n-                            // (, line 79\n-                            // <-, line 79\n-                            slice_from(\"i\");\n-                            break;\n-                        case 3:\n-                            // (, line 80\n-                            // next, line 80\n-                            if (cursor >= limit)\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // (, line 75\n+                            // [, line 77\n+                            bra = cursor;\n+                            // substring, line 77\n+                            among_var = find_among(a_1, 3);\n+                            if (among_var == 0)\n                             {\n                                 break lab1;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 77\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 78\n+                                    // <-, line 78\n+                                    slice_from(\"y\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 79\n+                                    // <-, line 79\n+                                    slice_from(\"i\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 80\n+                                    // next, line 80\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_1;\n-                break replab0;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_undouble() {\n+                private boolean r_undouble() {\n             int v_1;\n-            // (, line 90\n-            // test, line 91\n-            v_1 = limit - cursor;\n-            // among, line 91\n-            if (find_among_b(a_2, 3) == 0)\n-            {\n-                return false;\n-            }\n-            cursor = limit - v_1;\n-            // [, line 91\n-            ket = cursor;\n-            // next, line 91\n-            if (cursor <= limit_backward)\n-            {\n-                return false;\n-            }\n-            cursor--;\n-            // ], line 91\n-            bra = cursor;\n-            // delete, line 91\n-            slice_del();\n-            return true;\n-        }\n+                    // (, line 90\n+                    // test, line 91\n+                    v_1 = limit - cursor;\n+                    // among, line 91\n+                    if (find_among_b(a_2, 3) == 0)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = limit - v_1;\n+                    // [, line 91\n+                    ket = cursor;\n+                    // next, line 91\n+                    if (cursor <= limit_backward)\n+                    {\n+                        return false;\n+                    }\n+                    cursor--;\n+                    // ], line 91\n+                    bra = cursor;\n+                    // delete, line 91\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_e_ending() {\n+                private boolean r_e_ending() {\n             int v_1;\n-            // (, line 94\n-            // unset e_found, line 95\n-            B_e_found = false;\n-            // [, line 96\n-            ket = cursor;\n-            // literal, line 96\n-            if (!(eq_s_b(1, \"e\")))\n-            {\n-                return false;\n-            }\n-            // ], line 96\n-            bra = cursor;\n-            // call R1, line 96\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            // test, line 96\n-            v_1 = limit - cursor;\n-            if (!(out_grouping_b(g_v, 97, 232)))\n-            {\n-                return false;\n-            }\n-            cursor = limit - v_1;\n-            // delete, line 96\n-            slice_del();\n-            // set e_found, line 97\n-            B_e_found = true;\n-            // call undouble, line 98\n-            if (!r_undouble())\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    // (, line 94\n+                    // unset e_found, line 95\n+                    B_e_found = false;\n+                    // [, line 96\n+                    ket = cursor;\n+                    // literal, line 96\n+                    if (!(eq_s_b(1, \"e\")))\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 96\n+                    bra = cursor;\n+                    // call R1, line 96\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    // test, line 96\n+                    v_1 = limit - cursor;\n+                    if (!(out_grouping_b(g_v, 97, 232)))\n+                    {\n+                        return false;\n+                    }\n+                    cursor = limit - v_1;\n+                    // delete, line 96\n+                    slice_del();\n+                    // set e_found, line 97\n+                    B_e_found = true;\n+                    // call undouble, line 98\n+                    if (!r_undouble())\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_en_ending() {\n+                private boolean r_en_ending() {\n             int v_1;\n             int v_2;\n-            // (, line 101\n-            // call R1, line 102\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            // and, line 102\n-            v_1 = limit - cursor;\n-            if (!(out_grouping_b(g_v, 97, 232)))\n-            {\n-                return false;\n-            }\n-            cursor = limit - v_1;\n-            // not, line 102\n-            {\n-                v_2 = limit - cursor;\n-                lab0: do {\n-                    // literal, line 102\n-                    if (!(eq_s_b(3, \"gem\")))\n+                    // (, line 101\n+                    // call R1, line 102\n+                    if (!r_R1())\n                     {\n-                        break lab0;\n+                        return false;\n                     }\n-                    return false;\n-                } while (false);\n-                cursor = limit - v_2;\n-            }\n-            // delete, line 102\n-            slice_del();\n-            // call undouble, line 103\n-            if (!r_undouble())\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    // and, line 102\n+                    v_1 = limit - cursor;\n+                    if (!(out_grouping_b(g_v, 97, 232)))\n+                    {\n+                        return false;\n+                    }\n+                    cursor = limit - v_1;\n+                    // not, line 102\n+                    {\n+                        v_2 = limit - cursor;\n+                        lab0: do {\n+                            // literal, line 102\n+                            if (!(eq_s_b(3, \"gem\")))\n+                            {\n+                                break lab0;\n+                            }\n+                            return false;\n+                        } while (false);\n+                        cursor = limit - v_2;\n+                    }\n+                    // delete, line 102\n+                    slice_del();\n+                    // call undouble, line 103\n+                    if (!r_undouble())\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_standard_suffix() {\n+                private boolean r_standard_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n@@ -496,342 +503,352 @@ private boolean r_standard_suffix() {\n             int v_8;\n             int v_9;\n             int v_10;\n-            // (, line 106\n-            // do, line 107\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 107\n-                // [, line 108\n-                ket = cursor;\n-                // substring, line 108\n-                among_var = find_among_b(a_3, 5);\n-                if (among_var == 0)\n-                {\n-                    break lab0;\n-                }\n-                // ], line 108\n-                bra = cursor;\n-                switch(among_var) {\n-                    case 0:\n-                        break lab0;\n-                    case 1:\n-                        // (, line 110\n-                        // call R1, line 110\n-                        if (!r_R1())\n+                    // (, line 106\n+                    // do, line 107\n+                    v_1 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 107\n+                        // [, line 108\n+                        ket = cursor;\n+                        // substring, line 108\n+                        among_var = find_among_b(a_3, 5);\n+                        if (among_var == 0)\n                         {\n                             break lab0;\n                         }\n-                        // <-, line 110\n-                        slice_from(\"heid\");\n-                        break;\n-                    case 2:\n-                        // (, line 113\n-                        // call en_ending, line 113\n-                        if (!r_en_ending())\n+                        // ], line 108\n+                        bra = cursor;\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab0;\n+                            case 1:\n+                                // (, line 110\n+                                // call R1, line 110\n+                                if (!r_R1())\n+                                {\n+                                    break lab0;\n+                                }\n+                                // <-, line 110\n+                                slice_from(\"heid\");\n+                                break;\n+                            case 2:\n+                                // (, line 113\n+                                // call en_ending, line 113\n+                                if (!r_en_ending())\n+                                {\n+                                    break lab0;\n+                                }\n+                                break;\n+                            case 3:\n+                                // (, line 116\n+                                // call R1, line 116\n+                                if (!r_R1())\n+                                {\n+                                    break lab0;\n+                                }\n+                                if (!(out_grouping_b(g_v_j, 97, 232)))\n+                                {\n+                                    break lab0;\n+                                }\n+                                // delete, line 116\n+                                slice_del();\n+                                break;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_1;\n+                    // do, line 120\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // call e_ending, line 120\n+                        if (!r_e_ending())\n                         {\n-                            break lab0;\n+                            break lab1;\n                         }\n-                        break;\n-                    case 3:\n-                        // (, line 116\n-                        // call R1, line 116\n-                        if (!r_R1())\n+                    } while (false);\n+                    cursor = limit - v_2;\n+                    // do, line 122\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // (, line 122\n+                        // [, line 122\n+                        ket = cursor;\n+                        // literal, line 122\n+                        if (!(eq_s_b(4, \"heid\")))\n                         {\n-                            break lab0;\n+                            break lab2;\n                         }\n-                        if (!(out_grouping_b(g_v_j, 97, 232)))\n+                        // ], line 122\n+                        bra = cursor;\n+                        // call R2, line 122\n+                        if (!r_R2())\n                         {\n-                            break lab0;\n+                            break lab2;\n+                        }\n+                        // not, line 122\n+                        {\n+                            v_4 = limit - cursor;\n+                            lab3: do {\n+                                // literal, line 122\n+                                if (!(eq_s_b(1, \"c\")))\n+                                {\n+                                    break lab3;\n+                                }\n+                                break lab2;\n+                            } while (false);\n+                            cursor = limit - v_4;\n                         }\n-                        // delete, line 116\n+                        // delete, line 122\n                         slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_1;\n-            // do, line 120\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // call e_ending, line 120\n-                if (!r_e_ending())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 122\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // (, line 122\n-                // [, line 122\n-                ket = cursor;\n-                // literal, line 122\n-                if (!(eq_s_b(4, \"heid\")))\n-                {\n-                    break lab2;\n-                }\n-                // ], line 122\n-                bra = cursor;\n-                // call R2, line 122\n-                if (!r_R2())\n-                {\n-                    break lab2;\n-                }\n-                // not, line 122\n-                {\n-                    v_4 = limit - cursor;\n-                    lab3: do {\n-                        // literal, line 122\n-                        if (!(eq_s_b(1, \"c\")))\n+                        // [, line 123\n+                        ket = cursor;\n+                        // literal, line 123\n+                        if (!(eq_s_b(2, \"en\")))\n                         {\n-                            break lab3;\n+                            break lab2;\n+                        }\n+                        // ], line 123\n+                        bra = cursor;\n+                        // call en_ending, line 123\n+                        if (!r_en_ending())\n+                        {\n+                            break lab2;\n                         }\n-                        break lab2;\n                     } while (false);\n-                    cursor = limit - v_4;\n-                }\n-                // delete, line 122\n-                slice_del();\n-                // [, line 123\n-                ket = cursor;\n-                // literal, line 123\n-                if (!(eq_s_b(2, \"en\")))\n-                {\n-                    break lab2;\n-                }\n-                // ], line 123\n-                bra = cursor;\n-                // call en_ending, line 123\n-                if (!r_en_ending())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 126\n-            v_5 = limit - cursor;\n-            lab4: do {\n-                // (, line 126\n-                // [, line 127\n-                ket = cursor;\n-                // substring, line 127\n-                among_var = find_among_b(a_4, 6);\n-                if (among_var == 0)\n-                {\n-                    break lab4;\n-                }\n-                // ], line 127\n-                bra = cursor;\n-                switch(among_var) {\n-                    case 0:\n-                        break lab4;\n-                    case 1:\n-                        // (, line 129\n-                        // call R2, line 129\n-                        if (!r_R2())\n+                    cursor = limit - v_3;\n+                    // do, line 126\n+                    v_5 = limit - cursor;\n+                    lab4: do {\n+                        // (, line 126\n+                        // [, line 127\n+                        ket = cursor;\n+                        // substring, line 127\n+                        among_var = find_among_b(a_4, 6);\n+                        if (among_var == 0)\n                         {\n                             break lab4;\n                         }\n-                        // delete, line 129\n-                        slice_del();\n-                        // or, line 130\n-                        lab5: do {\n-                            v_6 = limit - cursor;\n-                            lab6: do {\n-                                // (, line 130\n-                                // [, line 130\n-                                ket = cursor;\n-                                // literal, line 130\n-                                if (!(eq_s_b(2, \"ig\")))\n+                        // ], line 127\n+                        bra = cursor;\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab4;\n+                            case 1:\n+                                // (, line 129\n+                                // call R2, line 129\n+                                if (!r_R2())\n                                 {\n-                                    break lab6;\n+                                    break lab4;\n                                 }\n-                                // ], line 130\n-                                bra = cursor;\n-                                // call R2, line 130\n+                                // delete, line 129\n+                                slice_del();\n+                                // or, line 130\n+                                lab5: do {\n+                                    v_6 = limit - cursor;\n+                                    lab6: do {\n+                                        // (, line 130\n+                                        // [, line 130\n+                                        ket = cursor;\n+                                        // literal, line 130\n+                                        if (!(eq_s_b(2, \"ig\")))\n+                                        {\n+                                            break lab6;\n+                                        }\n+                                        // ], line 130\n+                                        bra = cursor;\n+                                        // call R2, line 130\n+                                        if (!r_R2())\n+                                        {\n+                                            break lab6;\n+                                        }\n+                                        // not, line 130\n+                                        {\n+                                            v_7 = limit - cursor;\n+                                            lab7: do {\n+                                                // literal, line 130\n+                                                if (!(eq_s_b(1, \"e\")))\n+                                                {\n+                                                    break lab7;\n+                                                }\n+                                                break lab6;\n+                                            } while (false);\n+                                            cursor = limit - v_7;\n+                                        }\n+                                        // delete, line 130\n+                                        slice_del();\n+                                        break lab5;\n+                                    } while (false);\n+                                    cursor = limit - v_6;\n+                                    // call undouble, line 130\n+                                    if (!r_undouble())\n+                                    {\n+                                        break lab4;\n+                                    }\n+                                } while (false);\n+                                break;\n+                            case 2:\n+                                // (, line 133\n+                                // call R2, line 133\n                                 if (!r_R2())\n                                 {\n-                                    break lab6;\n+                                    break lab4;\n                                 }\n-                                // not, line 130\n+                                // not, line 133\n                                 {\n-                                    v_7 = limit - cursor;\n-                                    lab7: do {\n-                                        // literal, line 130\n+                                    v_8 = limit - cursor;\n+                                    lab8: do {\n+                                        // literal, line 133\n                                         if (!(eq_s_b(1, \"e\")))\n                                         {\n-                                            break lab7;\n+                                            break lab8;\n                                         }\n-                                        break lab6;\n+                                        break lab4;\n                                     } while (false);\n-                                    cursor = limit - v_7;\n+                                    cursor = limit - v_8;\n                                 }\n-                                // delete, line 130\n+                                // delete, line 133\n                                 slice_del();\n-                                break lab5;\n-                            } while (false);\n-                            cursor = limit - v_6;\n-                            // call undouble, line 130\n-                            if (!r_undouble())\n-                            {\n-                                break lab4;\n-                            }\n-                        } while (false);\n-                        break;\n-                    case 2:\n-                        // (, line 133\n-                        // call R2, line 133\n-                        if (!r_R2())\n-                        {\n-                            break lab4;\n-                        }\n-                        // not, line 133\n-                        {\n-                            v_8 = limit - cursor;\n-                            lab8: do {\n-                                // literal, line 133\n-                                if (!(eq_s_b(1, \"e\")))\n+                                break;\n+                            case 3:\n+                                // (, line 136\n+                                // call R2, line 136\n+                                if (!r_R2())\n                                 {\n-                                    break lab8;\n+                                    break lab4;\n                                 }\n-                                break lab4;\n-                            } while (false);\n-                            cursor = limit - v_8;\n+                                // delete, line 136\n+                                slice_del();\n+                                // call e_ending, line 136\n+                                if (!r_e_ending())\n+                                {\n+                                    break lab4;\n+                                }\n+                                break;\n+                            case 4:\n+                                // (, line 139\n+                                // call R2, line 139\n+                                if (!r_R2())\n+                                {\n+                                    break lab4;\n+                                }\n+                                // delete, line 139\n+                                slice_del();\n+                                break;\n+                            case 5:\n+                                // (, line 142\n+                                // call R2, line 142\n+                                if (!r_R2())\n+                                {\n+                                    break lab4;\n+                                }\n+                                // Boolean test e_found, line 142\n+                                if (!(B_e_found))\n+                                {\n+                                    break lab4;\n+                                }\n+                                // delete, line 142\n+                                slice_del();\n+                                break;\n                         }\n-                        // delete, line 133\n-                        slice_del();\n-                        break;\n-                    case 3:\n-                        // (, line 136\n-                        // call R2, line 136\n-                        if (!r_R2())\n+                    } while (false);\n+                    cursor = limit - v_5;\n+                    // do, line 146\n+                    v_9 = limit - cursor;\n+                    lab9: do {\n+                        // (, line 146\n+                        if (!(out_grouping_b(g_v_I, 73, 232)))\n                         {\n-                            break lab4;\n+                            break lab9;\n                         }\n-                        // delete, line 136\n-                        slice_del();\n-                        // call e_ending, line 136\n-                        if (!r_e_ending())\n+                        // test, line 148\n+                        v_10 = limit - cursor;\n+                        // (, line 148\n+                        // among, line 149\n+                        if (find_among_b(a_5, 4) == 0)\n                         {\n-                            break lab4;\n+                            break lab9;\n                         }\n-                        break;\n-                    case 4:\n-                        // (, line 139\n-                        // call R2, line 139\n-                        if (!r_R2())\n+                        if (!(out_grouping_b(g_v, 97, 232)))\n                         {\n-                            break lab4;\n+                            break lab9;\n                         }\n-                        // delete, line 139\n-                        slice_del();\n-                        break;\n-                    case 5:\n-                        // (, line 142\n-                        // call R2, line 142\n-                        if (!r_R2())\n+                        cursor = limit - v_10;\n+                        // [, line 152\n+                        ket = cursor;\n+                        // next, line 152\n+                        if (cursor <= limit_backward)\n                         {\n-                            break lab4;\n+                            break lab9;\n                         }\n-                        // Boolean test e_found, line 142\n-                        if (!(B_e_found))\n-                        {\n-                            break lab4;\n-                        }\n-                        // delete, line 142\n+                        cursor--;\n+                        // ], line 152\n+                        bra = cursor;\n+                        // delete, line 152\n                         slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_5;\n-            // do, line 146\n-            v_9 = limit - cursor;\n-            lab9: do {\n-                // (, line 146\n-                if (!(out_grouping_b(g_v_I, 73, 232)))\n-                {\n-                    break lab9;\n-                }\n-                // test, line 148\n-                v_10 = limit - cursor;\n-                // (, line 148\n-                // among, line 149\n-                if (find_among_b(a_5, 4) == 0)\n-                {\n-                    break lab9;\n-                }\n-                if (!(out_grouping_b(g_v, 97, 232)))\n-                {\n-                    break lab9;\n-                }\n-                cursor = limit - v_10;\n-                // [, line 152\n-                ket = cursor;\n-                // next, line 152\n-                if (cursor <= limit_backward)\n-                {\n-                    break lab9;\n+                    } while (false);\n+                    cursor = limit - v_9;\n+                    return true;\n                 }\n-                cursor--;\n-                // ], line 152\n-                bra = cursor;\n-                // delete, line 152\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_9;\n-            return true;\n-        }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n-            // (, line 157\n-            // do, line 159\n-            v_1 = cursor;\n-            lab0: do {\n-                // call prelude, line 159\n-                if (!r_prelude())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 160\n-            v_2 = cursor;\n-            lab1: do {\n-                // call mark_regions, line 160\n-                if (!r_mark_regions())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = v_2;\n-            // backwards, line 161\n-            limit_backward = cursor; cursor = limit;\n-            // do, line 162\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call standard_suffix, line 162\n-                if (!r_standard_suffix())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            cursor = limit_backward;            // do, line 163\n-            v_4 = cursor;\n-            lab3: do {\n-                // call postlude, line 163\n-                if (!r_postlude())\n-                {\n-                    break lab3;\n+                    // (, line 157\n+                    // do, line 159\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call prelude, line 159\n+                        if (!r_prelude())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // do, line 160\n+                    v_2 = cursor;\n+                    lab1: do {\n+                        // call mark_regions, line 160\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = v_2;\n+                    // backwards, line 161\n+                    limit_backward = cursor; cursor = limit;\n+                    // do, line 162\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call standard_suffix, line 162\n+                        if (!r_standard_suffix())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    cursor = limit_backward;                    // do, line 163\n+                    v_4 = cursor;\n+                    lab3: do {\n+                        // call postlude, line 163\n+                        if (!r_postlude())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = v_4;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = v_4;\n-            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof DutchStemmer;\n         }\n \n+        public int hashCode() {\n+            return DutchStemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/DutchStemmer.java",
                "sha": "0ef63180ec2450ccb9b0dbc2994ef828479699d5",
                "status": "modified"
            },
            {
                "additions": 1150,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/EnglishStemmer.java",
                "changes": 2283,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/EnglishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1133,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/EnglishStemmer.java",
                "patch": "@@ -1,1146 +1,1153 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class EnglishStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"arsen\", -1, -1, \"\", this),\n-            new Among ( \"commun\", -1, -1, \"\", this),\n-            new Among ( \"gener\", -1, -1, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"'\", -1, 1, \"\", this),\n-            new Among ( \"'s'\", 0, 1, \"\", this),\n-            new Among ( \"'s\", -1, 1, \"\", this)\n-        };\n+        private final static EnglishStemmer methodObject = new EnglishStemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"ied\", -1, 2, \"\", this),\n-            new Among ( \"s\", -1, 3, \"\", this),\n-            new Among ( \"ies\", 1, 2, \"\", this),\n-            new Among ( \"sses\", 1, 1, \"\", this),\n-            new Among ( \"ss\", 1, -1, \"\", this),\n-            new Among ( \"us\", 1, -1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"arsen\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"commun\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"gener\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"\", -1, 3, \"\", this),\n-            new Among ( \"bb\", 0, 2, \"\", this),\n-            new Among ( \"dd\", 0, 2, \"\", this),\n-            new Among ( \"ff\", 0, 2, \"\", this),\n-            new Among ( \"gg\", 0, 2, \"\", this),\n-            new Among ( \"bl\", 0, 1, \"\", this),\n-            new Among ( \"mm\", 0, 2, \"\", this),\n-            new Among ( \"nn\", 0, 2, \"\", this),\n-            new Among ( \"pp\", 0, 2, \"\", this),\n-            new Among ( \"rr\", 0, 2, \"\", this),\n-            new Among ( \"at\", 0, 1, \"\", this),\n-            new Among ( \"tt\", 0, 2, \"\", this),\n-            new Among ( \"iz\", 0, 1, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"'\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"'s'\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"'s\", -1, 1, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"ed\", -1, 2, \"\", this),\n-            new Among ( \"eed\", 0, 1, \"\", this),\n-            new Among ( \"ing\", -1, 2, \"\", this),\n-            new Among ( \"edly\", -1, 2, \"\", this),\n-            new Among ( \"eedly\", 3, 1, \"\", this),\n-            new Among ( \"ingly\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"ied\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"s\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"ies\", 1, 2, \"\", methodObject ),\n+                    new Among ( \"sses\", 1, 1, \"\", methodObject ),\n+                    new Among ( \"ss\", 1, -1, \"\", methodObject ),\n+                    new Among ( \"us\", 1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_5[] = {\n-            new Among ( \"anci\", -1, 3, \"\", this),\n-            new Among ( \"enci\", -1, 2, \"\", this),\n-            new Among ( \"ogi\", -1, 13, \"\", this),\n-            new Among ( \"li\", -1, 16, \"\", this),\n-            new Among ( \"bli\", 3, 12, \"\", this),\n-            new Among ( \"abli\", 4, 4, \"\", this),\n-            new Among ( \"alli\", 3, 8, \"\", this),\n-            new Among ( \"fulli\", 3, 14, \"\", this),\n-            new Among ( \"lessli\", 3, 15, \"\", this),\n-            new Among ( \"ousli\", 3, 10, \"\", this),\n-            new Among ( \"entli\", 3, 5, \"\", this),\n-            new Among ( \"aliti\", -1, 8, \"\", this),\n-            new Among ( \"biliti\", -1, 12, \"\", this),\n-            new Among ( \"iviti\", -1, 11, \"\", this),\n-            new Among ( \"tional\", -1, 1, \"\", this),\n-            new Among ( \"ational\", 14, 7, \"\", this),\n-            new Among ( \"alism\", -1, 8, \"\", this),\n-            new Among ( \"ation\", -1, 7, \"\", this),\n-            new Among ( \"ization\", 17, 6, \"\", this),\n-            new Among ( \"izer\", -1, 6, \"\", this),\n-            new Among ( \"ator\", -1, 7, \"\", this),\n-            new Among ( \"iveness\", -1, 11, \"\", this),\n-            new Among ( \"fulness\", -1, 9, \"\", this),\n-            new Among ( \"ousness\", -1, 10, \"\", this)\n-        };\n+                private final static Among a_3[] = {\n+                    new Among ( \"\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"bb\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"dd\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"ff\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"gg\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"bl\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"mm\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"nn\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"pp\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"rr\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"at\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"tt\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"iz\", 0, 1, \"\", methodObject )\n+                };\n \n-        private Among a_6[] = {\n-            new Among ( \"icate\", -1, 4, \"\", this),\n-            new Among ( \"ative\", -1, 6, \"\", this),\n-            new Among ( \"alize\", -1, 3, \"\", this),\n-            new Among ( \"iciti\", -1, 4, \"\", this),\n-            new Among ( \"ical\", -1, 4, \"\", this),\n-            new Among ( \"tional\", -1, 1, \"\", this),\n-            new Among ( \"ational\", 5, 2, \"\", this),\n-            new Among ( \"ful\", -1, 5, \"\", this),\n-            new Among ( \"ness\", -1, 5, \"\", this)\n-        };\n+                private final static Among a_4[] = {\n+                    new Among ( \"ed\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"eed\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"ing\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"edly\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"eedly\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"ingly\", -1, 2, \"\", methodObject )\n+                };\n \n-        private Among a_7[] = {\n-            new Among ( \"ic\", -1, 1, \"\", this),\n-            new Among ( \"ance\", -1, 1, \"\", this),\n-            new Among ( \"ence\", -1, 1, \"\", this),\n-            new Among ( \"able\", -1, 1, \"\", this),\n-            new Among ( \"ible\", -1, 1, \"\", this),\n-            new Among ( \"ate\", -1, 1, \"\", this),\n-            new Among ( \"ive\", -1, 1, \"\", this),\n-            new Among ( \"ize\", -1, 1, \"\", this),\n-            new Among ( \"iti\", -1, 1, \"\", this),\n-            new Among ( \"al\", -1, 1, \"\", this),\n-            new Among ( \"ism\", -1, 1, \"\", this),\n-            new Among ( \"ion\", -1, 2, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"ous\", -1, 1, \"\", this),\n-            new Among ( \"ant\", -1, 1, \"\", this),\n-            new Among ( \"ent\", -1, 1, \"\", this),\n-            new Among ( \"ment\", 15, 1, \"\", this),\n-            new Among ( \"ement\", 16, 1, \"\", this)\n-        };\n+                private final static Among a_5[] = {\n+                    new Among ( \"anci\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"enci\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ogi\", -1, 13, \"\", methodObject ),\n+                    new Among ( \"li\", -1, 16, \"\", methodObject ),\n+                    new Among ( \"bli\", 3, 12, \"\", methodObject ),\n+                    new Among ( \"abli\", 4, 4, \"\", methodObject ),\n+                    new Among ( \"alli\", 3, 8, \"\", methodObject ),\n+                    new Among ( \"fulli\", 3, 14, \"\", methodObject ),\n+                    new Among ( \"lessli\", 3, 15, \"\", methodObject ),\n+                    new Among ( \"ousli\", 3, 10, \"\", methodObject ),\n+                    new Among ( \"entli\", 3, 5, \"\", methodObject ),\n+                    new Among ( \"aliti\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"biliti\", -1, 12, \"\", methodObject ),\n+                    new Among ( \"iviti\", -1, 11, \"\", methodObject ),\n+                    new Among ( \"tional\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ational\", 14, 7, \"\", methodObject ),\n+                    new Among ( \"alism\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"ation\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"ization\", 17, 6, \"\", methodObject ),\n+                    new Among ( \"izer\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"ator\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"iveness\", -1, 11, \"\", methodObject ),\n+                    new Among ( \"fulness\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"ousness\", -1, 10, \"\", methodObject )\n+                };\n \n-        private Among a_8[] = {\n-            new Among ( \"e\", -1, 1, \"\", this),\n-            new Among ( \"l\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_6[] = {\n+                    new Among ( \"icate\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"ative\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"alize\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"iciti\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"ical\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"tional\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ational\", 5, 2, \"\", methodObject ),\n+                    new Among ( \"ful\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"ness\", -1, 5, \"\", methodObject )\n+                };\n \n-        private Among a_9[] = {\n-            new Among ( \"succeed\", -1, -1, \"\", this),\n-            new Among ( \"proceed\", -1, -1, \"\", this),\n-            new Among ( \"exceed\", -1, -1, \"\", this),\n-            new Among ( \"canning\", -1, -1, \"\", this),\n-            new Among ( \"inning\", -1, -1, \"\", this),\n-            new Among ( \"earring\", -1, -1, \"\", this),\n-            new Among ( \"herring\", -1, -1, \"\", this),\n-            new Among ( \"outing\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_7[] = {\n+                    new Among ( \"ic\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ance\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ence\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"able\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ible\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ate\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ive\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ize\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"al\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ism\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ion\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ous\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ant\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ent\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ment\", 15, 1, \"\", methodObject ),\n+                    new Among ( \"ement\", 16, 1, \"\", methodObject )\n+                };\n \n-        private Among a_10[] = {\n-            new Among ( \"andes\", -1, -1, \"\", this),\n-            new Among ( \"atlas\", -1, -1, \"\", this),\n-            new Among ( \"bias\", -1, -1, \"\", this),\n-            new Among ( \"cosmos\", -1, -1, \"\", this),\n-            new Among ( \"dying\", -1, 3, \"\", this),\n-            new Among ( \"early\", -1, 9, \"\", this),\n-            new Among ( \"gently\", -1, 7, \"\", this),\n-            new Among ( \"howe\", -1, -1, \"\", this),\n-            new Among ( \"idly\", -1, 6, \"\", this),\n-            new Among ( \"lying\", -1, 4, \"\", this),\n-            new Among ( \"news\", -1, -1, \"\", this),\n-            new Among ( \"only\", -1, 10, \"\", this),\n-            new Among ( \"singly\", -1, 11, \"\", this),\n-            new Among ( \"skies\", -1, 2, \"\", this),\n-            new Among ( \"skis\", -1, 1, \"\", this),\n-            new Among ( \"sky\", -1, -1, \"\", this),\n-            new Among ( \"tying\", -1, 5, \"\", this),\n-            new Among ( \"ugly\", -1, 8, \"\", this)\n-        };\n+                private final static Among a_8[] = {\n+                    new Among ( \"e\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"l\", -1, 2, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 1 };\n+                private final static Among a_9[] = {\n+                    new Among ( \"succeed\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"proceed\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"exceed\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"canning\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"inning\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"earring\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"herring\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"outing\", -1, -1, \"\", methodObject )\n+                };\n \n-        private static final char g_v_WXY[] = {1, 17, 65, 208, 1 };\n+                private final static Among a_10[] = {\n+                    new Among ( \"andes\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"atlas\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"bias\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"cosmos\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"dying\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"early\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"gently\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"howe\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"idly\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"lying\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"news\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"only\", -1, 10, \"\", methodObject ),\n+                    new Among ( \"singly\", -1, 11, \"\", methodObject ),\n+                    new Among ( \"skies\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"skis\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"sky\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"tying\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"ugly\", -1, 8, \"\", methodObject )\n+                };\n \n-        private static final char g_valid_LI[] = {55, 141, 2 };\n+                private static final char g_v[] = {17, 65, 16, 1 };\n+\n+                private static final char g_v_WXY[] = {1, 17, 65, 208, 1 };\n+\n+                private static final char g_valid_LI[] = {55, 141, 2 };\n \n         private boolean B_Y_found;\n         private int I_p2;\n         private int I_p1;\n \n-        private void copy_from(EnglishStemmer other) {\n-            B_Y_found = other.B_Y_found;\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(EnglishStemmer other) {\n+                    B_Y_found = other.B_Y_found;\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_prelude() {\n+                private boolean r_prelude() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n-            // (, line 25\n-            // unset Y_found, line 26\n-            B_Y_found = false;\n-            // do, line 27\n-            v_1 = cursor;\n-            lab0: do {\n-                // (, line 27\n-                // [, line 27\n-                bra = cursor;\n-                // literal, line 27\n-                if (!(eq_s(1, \"'\")))\n-                {\n-                    break lab0;\n-                }\n-                // ], line 27\n-                ket = cursor;\n-                // delete, line 27\n-                slice_del();\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 28\n-            v_2 = cursor;\n-            lab1: do {\n-                // (, line 28\n-                // [, line 28\n-                bra = cursor;\n-                // literal, line 28\n-                if (!(eq_s(1, \"y\")))\n-                {\n-                    break lab1;\n-                }\n-                // ], line 28\n-                ket = cursor;\n-                // <-, line 28\n-                slice_from(\"Y\");\n-                // set Y_found, line 28\n-                B_Y_found = true;\n-            } while (false);\n-            cursor = v_2;\n-            // do, line 29\n-            v_3 = cursor;\n-            lab2: do {\n-                // repeat, line 29\n-                replab3: while(true)\n-                {\n-                    v_4 = cursor;\n-                    lab4: do {\n-                        // (, line 29\n-                        // goto, line 29\n-                        golab5: while(true)\n+                    // (, line 25\n+                    // unset Y_found, line 26\n+                    B_Y_found = false;\n+                    // do, line 27\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // (, line 27\n+                        // [, line 27\n+                        bra = cursor;\n+                        // literal, line 27\n+                        if (!(eq_s(1, \"'\")))\n                         {\n-                            v_5 = cursor;\n-                            lab6: do {\n+                            break lab0;\n+                        }\n+                        // ], line 27\n+                        ket = cursor;\n+                        // delete, line 27\n+                        slice_del();\n+                    } while (false);\n+                    cursor = v_1;\n+                    // do, line 28\n+                    v_2 = cursor;\n+                    lab1: do {\n+                        // (, line 28\n+                        // [, line 28\n+                        bra = cursor;\n+                        // literal, line 28\n+                        if (!(eq_s(1, \"y\")))\n+                        {\n+                            break lab1;\n+                        }\n+                        // ], line 28\n+                        ket = cursor;\n+                        // <-, line 28\n+                        slice_from(\"Y\");\n+                        // set Y_found, line 28\n+                        B_Y_found = true;\n+                    } while (false);\n+                    cursor = v_2;\n+                    // do, line 29\n+                    v_3 = cursor;\n+                    lab2: do {\n+                        // repeat, line 29\n+                        replab3: while(true)\n+                        {\n+                            v_4 = cursor;\n+                            lab4: do {\n                                 // (, line 29\n+                                // goto, line 29\n+                                golab5: while(true)\n+                                {\n+                                    v_5 = cursor;\n+                                    lab6: do {\n+                                        // (, line 29\n+                                        if (!(in_grouping(g_v, 97, 121)))\n+                                        {\n+                                            break lab6;\n+                                        }\n+                                        // [, line 29\n+                                        bra = cursor;\n+                                        // literal, line 29\n+                                        if (!(eq_s(1, \"y\")))\n+                                        {\n+                                            break lab6;\n+                                        }\n+                                        // ], line 29\n+                                        ket = cursor;\n+                                        cursor = v_5;\n+                                        break golab5;\n+                                    } while (false);\n+                                    cursor = v_5;\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab4;\n+                                    }\n+                                    cursor++;\n+                                }\n+                                // <-, line 29\n+                                slice_from(\"Y\");\n+                                // set Y_found, line 29\n+                                B_Y_found = true;\n+                                continue replab3;\n+                            } while (false);\n+                            cursor = v_4;\n+                            break replab3;\n+                        }\n+                    } while (false);\n+                    cursor = v_3;\n+                    return true;\n+                }\n+\n+                private boolean r_mark_regions() {\n+            int v_1;\n+            int v_2;\n+                    // (, line 32\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // do, line 35\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // (, line 35\n+                        // or, line 41\n+                        lab1: do {\n+                            v_2 = cursor;\n+                            lab2: do {\n+                                // among, line 36\n+                                if (find_among(a_0, 3) == 0)\n+                                {\n+                                    break lab2;\n+                                }\n+                                break lab1;\n+                            } while (false);\n+                            cursor = v_2;\n+                            // (, line 41\n+                            // gopast, line 41\n+                            golab3: while(true)\n+                            {\n+                                lab4: do {\n+                                    if (!(in_grouping(g_v, 97, 121)))\n+                                    {\n+                                        break lab4;\n+                                    }\n+                                    break golab3;\n+                                } while (false);\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab0;\n+                                }\n+                                cursor++;\n+                            }\n+                            // gopast, line 41\n+                            golab5: while(true)\n+                            {\n+                                lab6: do {\n+                                    if (!(out_grouping(g_v, 97, 121)))\n+                                    {\n+                                        break lab6;\n+                                    }\n+                                    break golab5;\n+                                } while (false);\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab0;\n+                                }\n+                                cursor++;\n+                            }\n+                        } while (false);\n+                        // setmark p1, line 42\n+                        I_p1 = cursor;\n+                        // gopast, line 43\n+                        golab7: while(true)\n+                        {\n+                            lab8: do {\n                                 if (!(in_grouping(g_v, 97, 121)))\n                                 {\n-                                    break lab6;\n+                                    break lab8;\n                                 }\n-                                // [, line 29\n-                                bra = cursor;\n-                                // literal, line 29\n-                                if (!(eq_s(1, \"y\")))\n+                                break golab7;\n+                            } while (false);\n+                            if (cursor >= limit)\n+                            {\n+                                break lab0;\n+                            }\n+                            cursor++;\n+                        }\n+                        // gopast, line 43\n+                        golab9: while(true)\n+                        {\n+                            lab10: do {\n+                                if (!(out_grouping(g_v, 97, 121)))\n                                 {\n-                                    break lab6;\n+                                    break lab10;\n                                 }\n-                                // ], line 29\n-                                ket = cursor;\n-                                cursor = v_5;\n-                                break golab5;\n+                                break golab9;\n                             } while (false);\n-                            cursor = v_5;\n                             if (cursor >= limit)\n                             {\n-                                break lab4;\n+                                break lab0;\n                             }\n                             cursor++;\n                         }\n-                        // <-, line 29\n-                        slice_from(\"Y\");\n-                        // set Y_found, line 29\n-                        B_Y_found = true;\n-                        continue replab3;\n+                        // setmark p2, line 43\n+                        I_p2 = cursor;\n                     } while (false);\n-                    cursor = v_4;\n-                    break replab3;\n+                    cursor = v_1;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = v_3;\n-            return true;\n-        }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_shortv() {\n             int v_1;\n-            int v_2;\n-            // (, line 32\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // do, line 35\n-            v_1 = cursor;\n-            lab0: do {\n-                // (, line 35\n-                // or, line 41\n-                lab1: do {\n-                    v_2 = cursor;\n-                    lab2: do {\n-                        // among, line 36\n-                        if (find_among(a_0, 3) == 0)\n-                        {\n-                            break lab2;\n-                        }\n-                        break lab1;\n-                    } while (false);\n-                    cursor = v_2;\n-                    // (, line 41\n-                    // gopast, line 41\n-                    golab3: while(true)\n-                    {\n-                        lab4: do {\n-                            if (!(in_grouping(g_v, 97, 121)))\n+                    // (, line 49\n+                    // or, line 51\n+                    lab0: do {\n+                        v_1 = limit - cursor;\n+                        lab1: do {\n+                            // (, line 50\n+                            if (!(out_grouping_b(g_v_WXY, 89, 121)))\n                             {\n-                                break lab4;\n+                                break lab1;\n                             }\n-                            break golab3;\n-                        } while (false);\n-                        if (cursor >= limit)\n-                        {\n-                            break lab0;\n-                        }\n-                        cursor++;\n-                    }\n-                    // gopast, line 41\n-                    golab5: while(true)\n-                    {\n-                        lab6: do {\n-                            if (!(out_grouping(g_v, 97, 121)))\n+                            if (!(in_grouping_b(g_v, 97, 121)))\n                             {\n-                                break lab6;\n+                                break lab1;\n                             }\n-                            break golab5;\n+                            if (!(out_grouping_b(g_v, 97, 121)))\n+                            {\n+                                break lab1;\n+                            }\n+                            break lab0;\n                         } while (false);\n-                        if (cursor >= limit)\n+                        cursor = limit - v_1;\n+                        // (, line 52\n+                        if (!(out_grouping_b(g_v, 97, 121)))\n                         {\n-                            break lab0;\n+                            return false;\n                         }\n-                        cursor++;\n-                    }\n-                } while (false);\n-                // setmark p1, line 42\n-                I_p1 = cursor;\n-                // gopast, line 43\n-                golab7: while(true)\n-                {\n-                    lab8: do {\n-                        if (!(in_grouping(g_v, 97, 121)))\n+                        if (!(in_grouping_b(g_v, 97, 121)))\n                         {\n-                            break lab8;\n+                            return false;\n                         }\n-                        break golab7;\n-                    } while (false);\n-                    if (cursor >= limit)\n-                    {\n-                        break lab0;\n-                    }\n-                    cursor++;\n-                }\n-                // gopast, line 43\n-                golab9: while(true)\n-                {\n-                    lab10: do {\n-                        if (!(out_grouping(g_v, 97, 121)))\n+                        // atlimit, line 52\n+                        if (cursor > limit_backward)\n                         {\n-                            break lab10;\n+                            return false;\n                         }\n-                        break golab9;\n                     } while (false);\n-                    if (cursor >= limit)\n-                    {\n-                        break lab0;\n-                    }\n-                    cursor++;\n+                    return true;\n                 }\n-                // setmark p2, line 43\n-                I_p2 = cursor;\n-            } while (false);\n-            cursor = v_1;\n-            return true;\n-        }\n \n-        private boolean r_shortv() {\n-            int v_1;\n-            // (, line 49\n-            // or, line 51\n-            lab0: do {\n-                v_1 = limit - cursor;\n-                lab1: do {\n-                    // (, line 50\n-                    if (!(out_grouping_b(g_v_WXY, 89, 121)))\n-                    {\n-                        break lab1;\n-                    }\n-                    if (!(in_grouping_b(g_v, 97, 121)))\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n                     {\n-                        break lab1;\n+                        return false;\n                     }\n-                    if (!(out_grouping_b(g_v, 97, 121)))\n+                    return true;\n+                }\n+\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n                     {\n-                        break lab1;\n+                        return false;\n                     }\n-                    break lab0;\n-                } while (false);\n-                cursor = limit - v_1;\n-                // (, line 52\n-                if (!(out_grouping_b(g_v, 97, 121)))\n-                {\n-                    return false;\n-                }\n-                if (!(in_grouping_b(g_v, 97, 121)))\n-                {\n-                    return false;\n-                }\n-                // atlimit, line 52\n-                if (cursor > limit_backward)\n-                {\n-                    return false;\n+                    return true;\n                 }\n-            } while (false);\n-            return true;\n-        }\n-\n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n \n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_Step_1a() {\n+                private boolean r_Step_1a() {\n             int among_var;\n             int v_1;\n             int v_2;\n-            // (, line 58\n-            // try, line 59\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 59\n-                // [, line 60\n-                ket = cursor;\n-                // substring, line 60\n-                among_var = find_among_b(a_1, 3);\n-                if (among_var == 0)\n-                {\n-                    cursor = limit - v_1;\n-                    break lab0;\n-                }\n-                // ], line 60\n-                bra = cursor;\n-                switch(among_var) {\n-                    case 0:\n-                        cursor = limit - v_1;\n-                        break lab0;\n-                    case 1:\n-                        // (, line 62\n-                        // delete, line 62\n-                        slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            // [, line 65\n-            ket = cursor;\n-            // substring, line 65\n-            among_var = find_among_b(a_2, 6);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 65\n-            bra = cursor;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 66\n-                    // <-, line 66\n-                    slice_from(\"ss\");\n-                    break;\n-                case 2:\n-                    // (, line 68\n-                    // or, line 68\n-                    lab1: do {\n-                        v_2 = limit - cursor;\n-                        lab2: do {\n-                            // (, line 68\n-                            // hop, line 68\n-                            {\n-                                int c = cursor - 2;\n-                                if (limit_backward > c || c > limit)\n-                                {\n-                                    break lab2;\n-                                }\n-                                cursor = c;\n-                            }\n-                            // <-, line 68\n-                            slice_from(\"i\");\n-                            break lab1;\n-                        } while (false);\n-                        cursor = limit - v_2;\n-                        // <-, line 68\n-                        slice_from(\"ie\");\n+                    // (, line 58\n+                    // try, line 59\n+                    v_1 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 59\n+                        // [, line 60\n+                        ket = cursor;\n+                        // substring, line 60\n+                        among_var = find_among_b(a_1, 3);\n+                        if (among_var == 0)\n+                        {\n+                            cursor = limit - v_1;\n+                            break lab0;\n+                        }\n+                        // ], line 60\n+                        bra = cursor;\n+                        switch(among_var) {\n+                            case 0:\n+                                cursor = limit - v_1;\n+                                break lab0;\n+                            case 1:\n+                                // (, line 62\n+                                // delete, line 62\n+                                slice_del();\n+                                break;\n+                        }\n                     } while (false);\n-                    break;\n-                case 3:\n-                    // (, line 69\n-                    // next, line 69\n-                    if (cursor <= limit_backward)\n+                    // [, line 65\n+                    ket = cursor;\n+                    // substring, line 65\n+                    among_var = find_among_b(a_2, 6);\n+                    if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    cursor--;\n-                    // gopast, line 69\n-                    golab3: while(true)\n-                    {\n-                        lab4: do {\n-                            if (!(in_grouping_b(g_v, 97, 121)))\n+                    // ], line 65\n+                    bra = cursor;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 66\n+                            // <-, line 66\n+                            slice_from(\"ss\");\n+                            break;\n+                        case 2:\n+                            // (, line 68\n+                            // or, line 68\n+                            lab1: do {\n+                                v_2 = limit - cursor;\n+                                lab2: do {\n+                                    // (, line 68\n+                                    // hop, line 68\n+                                    {\n+                                        int c = cursor - 2;\n+                                        if (limit_backward > c || c > limit)\n+                                        {\n+                                            break lab2;\n+                                        }\n+                                        cursor = c;\n+                                    }\n+                                    // <-, line 68\n+                                    slice_from(\"i\");\n+                                    break lab1;\n+                                } while (false);\n+                                cursor = limit - v_2;\n+                                // <-, line 68\n+                                slice_from(\"ie\");\n+                            } while (false);\n+                            break;\n+                        case 3:\n+                            // (, line 69\n+                            // next, line 69\n+                            if (cursor <= limit_backward)\n                             {\n-                                break lab4;\n+                                return false;\n                             }\n-                            break golab3;\n-                        } while (false);\n-                        if (cursor <= limit_backward)\n-                        {\n-                            return false;\n-                        }\n-                        cursor--;\n+                            cursor--;\n+                            // gopast, line 69\n+                            golab3: while(true)\n+                            {\n+                                lab4: do {\n+                                    if (!(in_grouping_b(g_v, 97, 121)))\n+                                    {\n+                                        break lab4;\n+                                    }\n+                                    break golab3;\n+                                } while (false);\n+                                if (cursor <= limit_backward)\n+                                {\n+                                    return false;\n+                                }\n+                                cursor--;\n+                            }\n+                            // delete, line 69\n+                            slice_del();\n+                            break;\n                     }\n-                    // delete, line 69\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_Step_1b() {\n+                private boolean r_Step_1b() {\n             int among_var;\n             int v_1;\n             int v_3;\n             int v_4;\n-            // (, line 74\n-            // [, line 75\n-            ket = cursor;\n-            // substring, line 75\n-            among_var = find_among_b(a_4, 6);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 75\n-            bra = cursor;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 77\n-                    // call R1, line 77\n-                    if (!r_R1())\n+                    // (, line 74\n+                    // [, line 75\n+                    ket = cursor;\n+                    // substring, line 75\n+                    among_var = find_among_b(a_4, 6);\n+                    if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    // <-, line 77\n-                    slice_from(\"ee\");\n-                    break;\n-                case 2:\n-                    // (, line 79\n-                    // test, line 80\n-                    v_1 = limit - cursor;\n-                    // gopast, line 80\n-                    golab0: while(true)\n-                    {\n+                    // ], line 75\n+                    bra = cursor;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 77\n+                            // call R1, line 77\n+                            if (!r_R1())\n+                            {\n+                                return false;\n+                            }\n+                            // <-, line 77\n+                            slice_from(\"ee\");\n+                            break;\n+                        case 2:\n+                            // (, line 79\n+                            // test, line 80\n+                            v_1 = limit - cursor;\n+                            // gopast, line 80\n+                            golab0: while(true)\n+                            {\n+                                lab1: do {\n+                                    if (!(in_grouping_b(g_v, 97, 121)))\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    break golab0;\n+                                } while (false);\n+                                if (cursor <= limit_backward)\n+                                {\n+                                    return false;\n+                                }\n+                                cursor--;\n+                            }\n+                            cursor = limit - v_1;\n+                            // delete, line 80\n+                            slice_del();\n+                            // test, line 81\n+                            v_3 = limit - cursor;\n+                            // substring, line 81\n+                            among_var = find_among_b(a_3, 13);\n+                            if (among_var == 0)\n+                            {\n+                                return false;\n+                            }\n+                            cursor = limit - v_3;\n+                            switch(among_var) {\n+                                case 0:\n+                                    return false;\n+                                case 1:\n+                                    // (, line 83\n+                                    // <+, line 83\n+                                    {\n+                                        int c = cursor;\n+                                        insert(cursor, cursor, \"e\");\n+                                        cursor = c;\n+                                    }\n+                                    break;\n+                                case 2:\n+                                    // (, line 86\n+                                    // [, line 86\n+                                    ket = cursor;\n+                                    // next, line 86\n+                                    if (cursor <= limit_backward)\n+                                    {\n+                                        return false;\n+                                    }\n+                                    cursor--;\n+                                    // ], line 86\n+                                    bra = cursor;\n+                                    // delete, line 86\n+                                    slice_del();\n+                                    break;\n+                                case 3:\n+                                    // (, line 87\n+                                    // atmark, line 87\n+                                    if (cursor != I_p1)\n+                                    {\n+                                        return false;\n+                                    }\n+                                    // test, line 87\n+                                    v_4 = limit - cursor;\n+                                    // call shortv, line 87\n+                                    if (!r_shortv())\n+                                    {\n+                                        return false;\n+                                    }\n+                                    cursor = limit - v_4;\n+                                    // <+, line 87\n+                                    {\n+                                        int c = cursor;\n+                                        insert(cursor, cursor, \"e\");\n+                                        cursor = c;\n+                                    }\n+                                    break;\n+                            }\n+                            break;\n+                    }\n+                    return true;\n+                }\n+\n+                private boolean r_Step_1c() {\n+            int v_1;\n+            int v_2;\n+                    // (, line 93\n+                    // [, line 94\n+                    ket = cursor;\n+                    // or, line 94\n+                    lab0: do {\n+                        v_1 = limit - cursor;\n                         lab1: do {\n-                            if (!(in_grouping_b(g_v, 97, 121)))\n+                            // literal, line 94\n+                            if (!(eq_s_b(1, \"y\")))\n                             {\n                                 break lab1;\n                             }\n-                            break golab0;\n+                            break lab0;\n                         } while (false);\n-                        if (cursor <= limit_backward)\n+                        cursor = limit - v_1;\n+                        // literal, line 94\n+                        if (!(eq_s_b(1, \"Y\")))\n                         {\n                             return false;\n                         }\n-                        cursor--;\n+                    } while (false);\n+                    // ], line 94\n+                    bra = cursor;\n+                    if (!(out_grouping_b(g_v, 97, 121)))\n+                    {\n+                        return false;\n                     }\n-                    cursor = limit - v_1;\n-                    // delete, line 80\n-                    slice_del();\n-                    // test, line 81\n-                    v_3 = limit - cursor;\n-                    // substring, line 81\n-                    among_var = find_among_b(a_3, 13);\n+                    // not, line 95\n+                    {\n+                        v_2 = limit - cursor;\n+                        lab2: do {\n+                            // atlimit, line 95\n+                            if (cursor > limit_backward)\n+                            {\n+                                break lab2;\n+                            }\n+                            return false;\n+                        } while (false);\n+                        cursor = limit - v_2;\n+                    }\n+                    // <-, line 96\n+                    slice_from(\"i\");\n+                    return true;\n+                }\n+\n+                private boolean r_Step_2() {\n+            int among_var;\n+                    // (, line 99\n+                    // [, line 100\n+                    ket = cursor;\n+                    // substring, line 100\n+                    among_var = find_among_b(a_5, 24);\n                     if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    cursor = limit - v_3;\n+                    // ], line 100\n+                    bra = cursor;\n+                    // call R1, line 100\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n                     switch(among_var) {\n                         case 0:\n                             return false;\n                         case 1:\n-                            // (, line 83\n-                            // <+, line 83\n-                            {\n-                                int c = cursor;\n-                                insert(cursor, cursor, \"e\");\n-                                cursor = c;\n-                            }\n+                            // (, line 101\n+                            // <-, line 101\n+                            slice_from(\"tion\");\n                             break;\n                         case 2:\n-                            // (, line 86\n-                            // [, line 86\n-                            ket = cursor;\n-                            // next, line 86\n-                            if (cursor <= limit_backward)\n-                            {\n-                                return false;\n-                            }\n-                            cursor--;\n-                            // ], line 86\n-                            bra = cursor;\n-                            // delete, line 86\n-                            slice_del();\n+                            // (, line 102\n+                            // <-, line 102\n+                            slice_from(\"ence\");\n                             break;\n                         case 3:\n-                            // (, line 87\n-                            // atmark, line 87\n-                            if (cursor != I_p1)\n+                            // (, line 103\n+                            // <-, line 103\n+                            slice_from(\"ance\");\n+                            break;\n+                        case 4:\n+                            // (, line 104\n+                            // <-, line 104\n+                            slice_from(\"able\");\n+                            break;\n+                        case 5:\n+                            // (, line 105\n+                            // <-, line 105\n+                            slice_from(\"ent\");\n+                            break;\n+                        case 6:\n+                            // (, line 107\n+                            // <-, line 107\n+                            slice_from(\"ize\");\n+                            break;\n+                        case 7:\n+                            // (, line 109\n+                            // <-, line 109\n+                            slice_from(\"ate\");\n+                            break;\n+                        case 8:\n+                            // (, line 111\n+                            // <-, line 111\n+                            slice_from(\"al\");\n+                            break;\n+                        case 9:\n+                            // (, line 112\n+                            // <-, line 112\n+                            slice_from(\"ful\");\n+                            break;\n+                        case 10:\n+                            // (, line 114\n+                            // <-, line 114\n+                            slice_from(\"ous\");\n+                            break;\n+                        case 11:\n+                            // (, line 116\n+                            // <-, line 116\n+                            slice_from(\"ive\");\n+                            break;\n+                        case 12:\n+                            // (, line 118\n+                            // <-, line 118\n+                            slice_from(\"ble\");\n+                            break;\n+                        case 13:\n+                            // (, line 119\n+                            // literal, line 119\n+                            if (!(eq_s_b(1, \"l\")))\n                             {\n                                 return false;\n                             }\n-                            // test, line 87\n-                            v_4 = limit - cursor;\n-                            // call shortv, line 87\n-                            if (!r_shortv())\n+                            // <-, line 119\n+                            slice_from(\"og\");\n+                            break;\n+                        case 14:\n+                            // (, line 120\n+                            // <-, line 120\n+                            slice_from(\"ful\");\n+                            break;\n+                        case 15:\n+                            // (, line 121\n+                            // <-, line 121\n+                            slice_from(\"less\");\n+                            break;\n+                        case 16:\n+                            // (, line 122\n+                            if (!(in_grouping_b(g_valid_LI, 99, 116)))\n                             {\n                                 return false;\n                             }\n-                            cursor = limit - v_4;\n-                            // <+, line 87\n-                            {\n-                                int c = cursor;\n-                                insert(cursor, cursor, \"e\");\n-                                cursor = c;\n-                            }\n+                            // delete, line 122\n+                            slice_del();\n                             break;\n                     }\n-                    break;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_Step_1c() {\n-            int v_1;\n-            int v_2;\n-            // (, line 93\n-            // [, line 94\n-            ket = cursor;\n-            // or, line 94\n-            lab0: do {\n-                v_1 = limit - cursor;\n-                lab1: do {\n-                    // literal, line 94\n-                    if (!(eq_s_b(1, \"y\")))\n-                    {\n-                        break lab1;\n-                    }\n-                    break lab0;\n-                } while (false);\n-                cursor = limit - v_1;\n-                // literal, line 94\n-                if (!(eq_s_b(1, \"Y\")))\n-                {\n-                    return false;\n+                    return true;\n                 }\n-            } while (false);\n-            // ], line 94\n-            bra = cursor;\n-            if (!(out_grouping_b(g_v, 97, 121)))\n-            {\n-                return false;\n-            }\n-            // not, line 95\n-            {\n-                v_2 = limit - cursor;\n-                lab2: do {\n-                    // atlimit, line 95\n-                    if (cursor > limit_backward)\n-                    {\n-                        break lab2;\n-                    }\n-                    return false;\n-                } while (false);\n-                cursor = limit - v_2;\n-            }\n-            // <-, line 96\n-            slice_from(\"i\");\n-            return true;\n-        }\n \n-        private boolean r_Step_2() {\n+                private boolean r_Step_3() {\n             int among_var;\n-            // (, line 99\n-            // [, line 100\n-            ket = cursor;\n-            // substring, line 100\n-            among_var = find_among_b(a_5, 24);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 100\n-            bra = cursor;\n-            // call R1, line 100\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 101\n-                    // <-, line 101\n-                    slice_from(\"tion\");\n-                    break;\n-                case 2:\n-                    // (, line 102\n-                    // <-, line 102\n-                    slice_from(\"ence\");\n-                    break;\n-                case 3:\n-                    // (, line 103\n-                    // <-, line 103\n-                    slice_from(\"ance\");\n-                    break;\n-                case 4:\n-                    // (, line 104\n-                    // <-, line 104\n-                    slice_from(\"able\");\n-                    break;\n-                case 5:\n-                    // (, line 105\n-                    // <-, line 105\n-                    slice_from(\"ent\");\n-                    break;\n-                case 6:\n-                    // (, line 107\n-                    // <-, line 107\n-                    slice_from(\"ize\");\n-                    break;\n-                case 7:\n-                    // (, line 109\n-                    // <-, line 109\n-                    slice_from(\"ate\");\n-                    break;\n-                case 8:\n-                    // (, line 111\n-                    // <-, line 111\n-                    slice_from(\"al\");\n-                    break;\n-                case 9:\n-                    // (, line 112\n-                    // <-, line 112\n-                    slice_from(\"ful\");\n-                    break;\n-                case 10:\n-                    // (, line 114\n-                    // <-, line 114\n-                    slice_from(\"ous\");\n-                    break;\n-                case 11:\n-                    // (, line 116\n-                    // <-, line 116\n-                    slice_from(\"ive\");\n-                    break;\n-                case 12:\n-                    // (, line 118\n-                    // <-, line 118\n-                    slice_from(\"ble\");\n-                    break;\n-                case 13:\n-                    // (, line 119\n-                    // literal, line 119\n-                    if (!(eq_s_b(1, \"l\")))\n+                    // (, line 126\n+                    // [, line 127\n+                    ket = cursor;\n+                    // substring, line 127\n+                    among_var = find_among_b(a_6, 9);\n+                    if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    // <-, line 119\n-                    slice_from(\"og\");\n-                    break;\n-                case 14:\n-                    // (, line 120\n-                    // <-, line 120\n-                    slice_from(\"ful\");\n-                    break;\n-                case 15:\n-                    // (, line 121\n-                    // <-, line 121\n-                    slice_from(\"less\");\n-                    break;\n-                case 16:\n-                    // (, line 122\n-                    if (!(in_grouping_b(g_valid_LI, 99, 116)))\n+                    // ], line 127\n+                    bra = cursor;\n+                    // call R1, line 127\n+                    if (!r_R1())\n                     {\n                         return false;\n                     }\n-                    // delete, line 122\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 128\n+                            // <-, line 128\n+                            slice_from(\"tion\");\n+                            break;\n+                        case 2:\n+                            // (, line 129\n+                            // <-, line 129\n+                            slice_from(\"ate\");\n+                            break;\n+                        case 3:\n+                            // (, line 130\n+                            // <-, line 130\n+                            slice_from(\"al\");\n+                            break;\n+                        case 4:\n+                            // (, line 132\n+                            // <-, line 132\n+                            slice_from(\"ic\");\n+                            break;\n+                        case 5:\n+                            // (, line 134\n+                            // delete, line 134\n+                            slice_del();\n+                            break;\n+                        case 6:\n+                            // (, line 136\n+                            // call R2, line 136\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 136\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_Step_3() {\n+                private boolean r_Step_4() {\n             int among_var;\n-            // (, line 126\n-            // [, line 127\n-            ket = cursor;\n-            // substring, line 127\n-            among_var = find_among_b(a_6, 9);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 127\n-            bra = cursor;\n-            // call R1, line 127\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 128\n-                    // <-, line 128\n-                    slice_from(\"tion\");\n-                    break;\n-                case 2:\n-                    // (, line 129\n-                    // <-, line 129\n-                    slice_from(\"ate\");\n-                    break;\n-                case 3:\n-                    // (, line 130\n-                    // <-, line 130\n-                    slice_from(\"al\");\n-                    break;\n-                case 4:\n-                    // (, line 132\n-                    // <-, line 132\n-                    slice_from(\"ic\");\n-                    break;\n-                case 5:\n-                    // (, line 134\n-                    // delete, line 134\n-                    slice_del();\n-                    break;\n-                case 6:\n-                    // (, line 136\n-                    // call R2, line 136\n+            int v_1;\n+                    // (, line 140\n+                    // [, line 141\n+                    ket = cursor;\n+                    // substring, line 141\n+                    among_var = find_among_b(a_7, 18);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 141\n+                    bra = cursor;\n+                    // call R2, line 141\n                     if (!r_R2())\n                     {\n                         return false;\n                     }\n-                    // delete, line 136\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_Step_4() {\n-            int among_var;\n-            int v_1;\n-            // (, line 140\n-            // [, line 141\n-            ket = cursor;\n-            // substring, line 141\n-            among_var = find_among_b(a_7, 18);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 141\n-            bra = cursor;\n-            // call R2, line 141\n-            if (!r_R2())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 144\n-                    // delete, line 144\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 145\n-                    // or, line 145\n-                    lab0: do {\n-                        v_1 = limit - cursor;\n-                        lab1: do {\n-                            // literal, line 145\n-                            if (!(eq_s_b(1, \"s\")))\n-                            {\n-                                break lab1;\n-                            }\n-                            break lab0;\n-                        } while (false);\n-                        cursor = limit - v_1;\n-                        // literal, line 145\n-                        if (!(eq_s_b(1, \"t\")))\n-                        {\n+                    switch(among_var) {\n+                        case 0:\n                             return false;\n-                        }\n-                    } while (false);\n-                    // delete, line 145\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                        case 1:\n+                            // (, line 144\n+                            // delete, line 144\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 145\n+                            // or, line 145\n+                            lab0: do {\n+                                v_1 = limit - cursor;\n+                                lab1: do {\n+                                    // literal, line 145\n+                                    if (!(eq_s_b(1, \"s\")))\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    break lab0;\n+                                } while (false);\n+                                cursor = limit - v_1;\n+                                // literal, line 145\n+                                if (!(eq_s_b(1, \"t\")))\n+                                {\n+                                    return false;\n+                                }\n+                            } while (false);\n+                            // delete, line 145\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_Step_5() {\n+                private boolean r_Step_5() {\n             int among_var;\n             int v_1;\n             int v_2;\n-            // (, line 149\n-            // [, line 150\n-            ket = cursor;\n-            // substring, line 150\n-            among_var = find_among_b(a_8, 2);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 150\n-            bra = cursor;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 151\n-                    // or, line 151\n-                    lab0: do {\n-                        v_1 = limit - cursor;\n-                        lab1: do {\n-                            // call R2, line 151\n-                            if (!r_R2())\n-                            {\n-                                break lab1;\n-                            }\n-                            break lab0;\n-                        } while (false);\n-                        cursor = limit - v_1;\n-                        // (, line 151\n-                        // call R1, line 151\n-                        if (!r_R1())\n-                        {\n+                    // (, line 149\n+                    // [, line 150\n+                    ket = cursor;\n+                    // substring, line 150\n+                    among_var = find_among_b(a_8, 2);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 150\n+                    bra = cursor;\n+                    switch(among_var) {\n+                        case 0:\n                             return false;\n-                        }\n-                        // not, line 151\n-                        {\n-                            v_2 = limit - cursor;\n-                            lab2: do {\n-                                // call shortv, line 151\n-                                if (!r_shortv())\n+                        case 1:\n+                            // (, line 151\n+                            // or, line 151\n+                            lab0: do {\n+                                v_1 = limit - cursor;\n+                                lab1: do {\n+                                    // call R2, line 151\n+                                    if (!r_R2())\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    break lab0;\n+                                } while (false);\n+                                cursor = limit - v_1;\n+                                // (, line 151\n+                                // call R1, line 151\n+                                if (!r_R1())\n                                 {\n-                                    break lab2;\n+                                    return false;\n+                                }\n+                                // not, line 151\n+                                {\n+                                    v_2 = limit - cursor;\n+                                    lab2: do {\n+                                        // call shortv, line 151\n+                                        if (!r_shortv())\n+                                        {\n+                                            break lab2;\n+                                        }\n+                                        return false;\n+                                    } while (false);\n+                                    cursor = limit - v_2;\n                                 }\n-                                return false;\n                             } while (false);\n-                            cursor = limit - v_2;\n-                        }\n-                    } while (false);\n-                    // delete, line 151\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 152\n-                    // call R2, line 152\n-                    if (!r_R2())\n+                            // delete, line 151\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 152\n+                            // call R2, line 152\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // literal, line 152\n+                            if (!(eq_s_b(1, \"l\")))\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 152\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n+\n+                private boolean r_exception2() {\n+                    // (, line 156\n+                    // [, line 158\n+                    ket = cursor;\n+                    // substring, line 158\n+                    if (find_among_b(a_9, 8) == 0)\n                     {\n                         return false;\n                     }\n-                    // literal, line 152\n-                    if (!(eq_s_b(1, \"l\")))\n+                    // ], line 158\n+                    bra = cursor;\n+                    // atlimit, line 158\n+                    if (cursor > limit_backward)\n                     {\n                         return false;\n                     }\n-                    // delete, line 152\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_exception2() {\n-            // (, line 156\n-            // [, line 158\n-            ket = cursor;\n-            // substring, line 158\n-            if (find_among_b(a_9, 8) == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 158\n-            bra = cursor;\n-            // atlimit, line 158\n-            if (cursor > limit_backward)\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_exception1() {\n+                private boolean r_exception1() {\n             int among_var;\n-            // (, line 168\n-            // [, line 170\n-            bra = cursor;\n-            // substring, line 170\n-            among_var = find_among(a_10, 18);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 170\n-            ket = cursor;\n-            // atlimit, line 170\n-            if (cursor < limit)\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 174\n-                    // <-, line 174\n-                    slice_from(\"ski\");\n-                    break;\n-                case 2:\n-                    // (, line 175\n-                    // <-, line 175\n-                    slice_from(\"sky\");\n-                    break;\n-                case 3:\n-                    // (, line 176\n-                    // <-, line 176\n-                    slice_from(\"die\");\n-                    break;\n-                case 4:\n-                    // (, line 177\n-                    // <-, line 177\n-                    slice_from(\"lie\");\n-                    break;\n-                case 5:\n-                    // (, line 178\n-                    // <-, line 178\n-                    slice_from(\"tie\");\n-                    break;\n-                case 6:\n-                    // (, line 182\n-                    // <-, line 182\n-                    slice_from(\"idl\");\n-                    break;\n-                case 7:\n-                    // (, line 183\n-                    // <-, line 183\n-                    slice_from(\"gentl\");\n-                    break;\n-                case 8:\n-                    // (, line 184\n-                    // <-, line 184\n-                    slice_from(\"ugli\");\n-                    break;\n-                case 9:\n-                    // (, line 185\n-                    // <-, line 185\n-                    slice_from(\"earli\");\n-                    break;\n-                case 10:\n-                    // (, line 186\n-                    // <-, line 186\n-                    slice_from(\"onli\");\n-                    break;\n-                case 11:\n-                    // (, line 187\n-                    // <-, line 187\n-                    slice_from(\"singl\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 168\n+                    // [, line 170\n+                    bra = cursor;\n+                    // substring, line 170\n+                    among_var = find_among(a_10, 18);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 170\n+                    ket = cursor;\n+                    // atlimit, line 170\n+                    if (cursor < limit)\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 174\n+                            // <-, line 174\n+                            slice_from(\"ski\");\n+                            break;\n+                        case 2:\n+                            // (, line 175\n+                            // <-, line 175\n+                            slice_from(\"sky\");\n+                            break;\n+                        case 3:\n+                            // (, line 176\n+                            // <-, line 176\n+                            slice_from(\"die\");\n+                            break;\n+                        case 4:\n+                            // (, line 177\n+                            // <-, line 177\n+                            slice_from(\"lie\");\n+                            break;\n+                        case 5:\n+                            // (, line 178\n+                            // <-, line 178\n+                            slice_from(\"tie\");\n+                            break;\n+                        case 6:\n+                            // (, line 182\n+                            // <-, line 182\n+                            slice_from(\"idl\");\n+                            break;\n+                        case 7:\n+                            // (, line 183\n+                            // <-, line 183\n+                            slice_from(\"gentl\");\n+                            break;\n+                        case 8:\n+                            // (, line 184\n+                            // <-, line 184\n+                            slice_from(\"ugli\");\n+                            break;\n+                        case 9:\n+                            // (, line 185\n+                            // <-, line 185\n+                            slice_from(\"earli\");\n+                            break;\n+                        case 10:\n+                            // (, line 186\n+                            // <-, line 186\n+                            slice_from(\"onli\");\n+                            break;\n+                        case 11:\n+                            // (, line 187\n+                            // <-, line 187\n+                            slice_from(\"singl\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_postlude() {\n+                private boolean r_postlude() {\n             int v_1;\n             int v_2;\n-            // (, line 203\n-            // Boolean test Y_found, line 203\n-            if (!(B_Y_found))\n-            {\n-                return false;\n-            }\n-            // repeat, line 203\n-            replab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n                     // (, line 203\n-                    // goto, line 203\n-                    golab2: while(true)\n+                    // Boolean test Y_found, line 203\n+                    if (!(B_Y_found))\n                     {\n-                        v_2 = cursor;\n-                        lab3: do {\n+                        return false;\n+                    }\n+                    // repeat, line 203\n+                    replab0: while(true)\n+                    {\n+                        v_1 = cursor;\n+                        lab1: do {\n                             // (, line 203\n-                            // [, line 203\n-                            bra = cursor;\n-                            // literal, line 203\n-                            if (!(eq_s(1, \"Y\")))\n+                            // goto, line 203\n+                            golab2: while(true)\n                             {\n-                                break lab3;\n+                                v_2 = cursor;\n+                                lab3: do {\n+                                    // (, line 203\n+                                    // [, line 203\n+                                    bra = cursor;\n+                                    // literal, line 203\n+                                    if (!(eq_s(1, \"Y\")))\n+                                    {\n+                                        break lab3;\n+                                    }\n+                                    // ], line 203\n+                                    ket = cursor;\n+                                    cursor = v_2;\n+                                    break golab2;\n+                                } while (false);\n+                                cursor = v_2;\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab1;\n+                                }\n+                                cursor++;\n                             }\n-                            // ], line 203\n-                            ket = cursor;\n-                            cursor = v_2;\n-                            break golab2;\n+                            // <-, line 203\n+                            slice_from(\"y\");\n+                            continue replab0;\n                         } while (false);\n-                        cursor = v_2;\n-                        if (cursor >= limit)\n-                        {\n-                            break lab1;\n-                        }\n-                        cursor++;\n+                        cursor = v_1;\n+                        break replab0;\n                     }\n-                    // <-, line 203\n-                    slice_from(\"y\");\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_1;\n-                break replab0;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n@@ -1154,161 +1161,171 @@ public boolean stem() {\n             int v_11;\n             int v_12;\n             int v_13;\n-            // (, line 205\n-            // or, line 207\n-            lab0: do {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // call exception1, line 207\n-                    if (!r_exception1())\n-                    {\n-                        break lab1;\n-                    }\n-                    break lab0;\n-                } while (false);\n-                cursor = v_1;\n-                lab2: do {\n-                    // not, line 208\n-                    {\n-                        v_2 = cursor;\n-                        lab3: do {\n-                            // hop, line 208\n+                    // (, line 205\n+                    // or, line 207\n+                    lab0: do {\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // call exception1, line 207\n+                            if (!r_exception1())\n+                            {\n+                                break lab1;\n+                            }\n+                            break lab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        lab2: do {\n+                            // not, line 208\n+                            {\n+                                v_2 = cursor;\n+                                lab3: do {\n+                                    // hop, line 208\n+                                    {\n+                                        int c = cursor + 3;\n+                                        if (0 > c || c > limit)\n+                                        {\n+                                            break lab3;\n+                                        }\n+                                        cursor = c;\n+                                    }\n+                                    break lab2;\n+                                } while (false);\n+                                cursor = v_2;\n+                            }\n+                            break lab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        // (, line 208\n+                        // do, line 209\n+                        v_3 = cursor;\n+                        lab4: do {\n+                            // call prelude, line 209\n+                            if (!r_prelude())\n+                            {\n+                                break lab4;\n+                            }\n+                        } while (false);\n+                        cursor = v_3;\n+                        // do, line 210\n+                        v_4 = cursor;\n+                        lab5: do {\n+                            // call mark_regions, line 210\n+                            if (!r_mark_regions())\n+                            {\n+                                break lab5;\n+                            }\n+                        } while (false);\n+                        cursor = v_4;\n+                        // backwards, line 211\n+                        limit_backward = cursor; cursor = limit;\n+                        // (, line 211\n+                        // do, line 213\n+                        v_5 = limit - cursor;\n+                        lab6: do {\n+                            // call Step_1a, line 213\n+                            if (!r_Step_1a())\n                             {\n-                                int c = cursor + 3;\n-                                if (0 > c || c > limit)\n+                                break lab6;\n+                            }\n+                        } while (false);\n+                        cursor = limit - v_5;\n+                        // or, line 215\n+                        lab7: do {\n+                            v_6 = limit - cursor;\n+                            lab8: do {\n+                                // call exception2, line 215\n+                                if (!r_exception2())\n+                                {\n+                                    break lab8;\n+                                }\n+                                break lab7;\n+                            } while (false);\n+                            cursor = limit - v_6;\n+                            // (, line 215\n+                            // do, line 217\n+                            v_7 = limit - cursor;\n+                            lab9: do {\n+                                // call Step_1b, line 217\n+                                if (!r_Step_1b())\n                                 {\n-                                    break lab3;\n+                                    break lab9;\n                                 }\n-                                cursor = c;\n+                            } while (false);\n+                            cursor = limit - v_7;\n+                            // do, line 218\n+                            v_8 = limit - cursor;\n+                            lab10: do {\n+                                // call Step_1c, line 218\n+                                if (!r_Step_1c())\n+                                {\n+                                    break lab10;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_8;\n+                            // do, line 220\n+                            v_9 = limit - cursor;\n+                            lab11: do {\n+                                // call Step_2, line 220\n+                                if (!r_Step_2())\n+                                {\n+                                    break lab11;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_9;\n+                            // do, line 221\n+                            v_10 = limit - cursor;\n+                            lab12: do {\n+                                // call Step_3, line 221\n+                                if (!r_Step_3())\n+                                {\n+                                    break lab12;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_10;\n+                            // do, line 222\n+                            v_11 = limit - cursor;\n+                            lab13: do {\n+                                // call Step_4, line 222\n+                                if (!r_Step_4())\n+                                {\n+                                    break lab13;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_11;\n+                            // do, line 224\n+                            v_12 = limit - cursor;\n+                            lab14: do {\n+                                // call Step_5, line 224\n+                                if (!r_Step_5())\n+                                {\n+                                    break lab14;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_12;\n+                        } while (false);\n+                        cursor = limit_backward;                        // do, line 227\n+                        v_13 = cursor;\n+                        lab15: do {\n+                            // call postlude, line 227\n+                            if (!r_postlude())\n+                            {\n+                                break lab15;\n                             }\n-                            break lab2;\n                         } while (false);\n-                        cursor = v_2;\n-                    }\n-                    break lab0;\n-                } while (false);\n-                cursor = v_1;\n-                // (, line 208\n-                // do, line 209\n-                v_3 = cursor;\n-                lab4: do {\n-                    // call prelude, line 209\n-                    if (!r_prelude())\n-                    {\n-                        break lab4;\n-                    }\n-                } while (false);\n-                cursor = v_3;\n-                // do, line 210\n-                v_4 = cursor;\n-                lab5: do {\n-                    // call mark_regions, line 210\n-                    if (!r_mark_regions())\n-                    {\n-                        break lab5;\n-                    }\n-                } while (false);\n-                cursor = v_4;\n-                // backwards, line 211\n-                limit_backward = cursor; cursor = limit;\n-                // (, line 211\n-                // do, line 213\n-                v_5 = limit - cursor;\n-                lab6: do {\n-                    // call Step_1a, line 213\n-                    if (!r_Step_1a())\n-                    {\n-                        break lab6;\n-                    }\n-                } while (false);\n-                cursor = limit - v_5;\n-                // or, line 215\n-                lab7: do {\n-                    v_6 = limit - cursor;\n-                    lab8: do {\n-                        // call exception2, line 215\n-                        if (!r_exception2())\n-                        {\n-                            break lab8;\n-                        }\n-                        break lab7;\n-                    } while (false);\n-                    cursor = limit - v_6;\n-                    // (, line 215\n-                    // do, line 217\n-                    v_7 = limit - cursor;\n-                    lab9: do {\n-                        // call Step_1b, line 217\n-                        if (!r_Step_1b())\n-                        {\n-                            break lab9;\n-                        }\n-                    } while (false);\n-                    cursor = limit - v_7;\n-                    // do, line 218\n-                    v_8 = limit - cursor;\n-                    lab10: do {\n-                        // call Step_1c, line 218\n-                        if (!r_Step_1c())\n-                        {\n-                            break lab10;\n-                        }\n-                    } while (false);\n-                    cursor = limit - v_8;\n-                    // do, line 220\n-                    v_9 = limit - cursor;\n-                    lab11: do {\n-                        // call Step_2, line 220\n-                        if (!r_Step_2())\n-                        {\n-                            break lab11;\n-                        }\n-                    } while (false);\n-                    cursor = limit - v_9;\n-                    // do, line 221\n-                    v_10 = limit - cursor;\n-                    lab12: do {\n-                        // call Step_3, line 221\n-                        if (!r_Step_3())\n-                        {\n-                            break lab12;\n-                        }\n-                    } while (false);\n-                    cursor = limit - v_10;\n-                    // do, line 222\n-                    v_11 = limit - cursor;\n-                    lab13: do {\n-                        // call Step_4, line 222\n-                        if (!r_Step_4())\n-                        {\n-                            break lab13;\n-                        }\n+                        cursor = v_13;\n                     } while (false);\n-                    cursor = limit - v_11;\n-                    // do, line 224\n-                    v_12 = limit - cursor;\n-                    lab14: do {\n-                        // call Step_5, line 224\n-                        if (!r_Step_5())\n-                        {\n-                            break lab14;\n-                        }\n-                    } while (false);\n-                    cursor = limit - v_12;\n-                } while (false);\n-                cursor = limit_backward;                // do, line 227\n-                v_13 = cursor;\n-                lab15: do {\n-                    // call postlude, line 227\n-                    if (!r_postlude())\n-                    {\n-                        break lab15;\n-                    }\n-                } while (false);\n-                cursor = v_13;\n-            } while (false);\n-            return true;\n+                    return true;\n+                }\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof EnglishStemmer;\n         }\n \n+        public int hashCode() {\n+            return EnglishStemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/EnglishStemmer.java",
                "sha": "b3b7890e2dcde7e1a3d9b11146efa7ab5ed67bda",
                "status": "modified"
            },
            {
                "additions": 901,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FinnishStemmer.java",
                "changes": 1785,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FinnishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 884,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/FinnishStemmer.java",
                "patch": "@@ -1,754 +1,761 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class FinnishStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"pa\", -1, 1, \"\", this),\n-            new Among ( \"sti\", -1, 2, \"\", this),\n-            new Among ( \"kaan\", -1, 1, \"\", this),\n-            new Among ( \"han\", -1, 1, \"\", this),\n-            new Among ( \"kin\", -1, 1, \"\", this),\n-            new Among ( \"h\\u00E4n\", -1, 1, \"\", this),\n-            new Among ( \"k\\u00E4\\u00E4n\", -1, 1, \"\", this),\n-            new Among ( \"ko\", -1, 1, \"\", this),\n-            new Among ( \"p\\u00E4\", -1, 1, \"\", this),\n-            new Among ( \"k\\u00F6\", -1, 1, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n+\n+        private final static FinnishStemmer methodObject = new FinnishStemmer ();\n \n-        private Among a_1[] = {\n-            new Among ( \"lla\", -1, -1, \"\", this),\n-            new Among ( \"na\", -1, -1, \"\", this),\n-            new Among ( \"ssa\", -1, -1, \"\", this),\n-            new Among ( \"ta\", -1, -1, \"\", this),\n-            new Among ( \"lta\", 3, -1, \"\", this),\n-            new Among ( \"sta\", 3, -1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"pa\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"sti\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"kaan\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"han\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"kin\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"h\\u00E4n\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"k\\u00E4\\u00E4n\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ko\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"p\\u00E4\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"k\\u00F6\", -1, 1, \"\", methodObject )\n+                };\n \n-        private Among a_2[] = {\n-            new Among ( \"ll\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"n\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"ss\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"t\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"lt\\u00E4\", 3, -1, \"\", this),\n-            new Among ( \"st\\u00E4\", 3, -1, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"lla\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"na\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ssa\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ta\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"lta\", 3, -1, \"\", methodObject ),\n+                    new Among ( \"sta\", 3, -1, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"lle\", -1, -1, \"\", this),\n-            new Among ( \"ine\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"ll\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"n\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ss\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"t\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"lt\\u00E4\", 3, -1, \"\", methodObject ),\n+                    new Among ( \"st\\u00E4\", 3, -1, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"nsa\", -1, 3, \"\", this),\n-            new Among ( \"mme\", -1, 3, \"\", this),\n-            new Among ( \"nne\", -1, 3, \"\", this),\n-            new Among ( \"ni\", -1, 2, \"\", this),\n-            new Among ( \"si\", -1, 1, \"\", this),\n-            new Among ( \"an\", -1, 4, \"\", this),\n-            new Among ( \"en\", -1, 6, \"\", this),\n-            new Among ( \"\\u00E4n\", -1, 5, \"\", this),\n-            new Among ( \"ns\\u00E4\", -1, 3, \"\", this)\n-        };\n+                private final static Among a_3[] = {\n+                    new Among ( \"lle\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ine\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_5[] = {\n-            new Among ( \"aa\", -1, -1, \"\", this),\n-            new Among ( \"ee\", -1, -1, \"\", this),\n-            new Among ( \"ii\", -1, -1, \"\", this),\n-            new Among ( \"oo\", -1, -1, \"\", this),\n-            new Among ( \"uu\", -1, -1, \"\", this),\n-            new Among ( \"\\u00E4\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"\\u00F6\\u00F6\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_4[] = {\n+                    new Among ( \"nsa\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"mme\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"nne\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"ni\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"si\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"an\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"en\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E4n\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"ns\\u00E4\", -1, 3, \"\", methodObject )\n+                };\n \n-        private Among a_6[] = {\n-            new Among ( \"a\", -1, 8, \"\", this),\n-            new Among ( \"lla\", 0, -1, \"\", this),\n-            new Among ( \"na\", 0, -1, \"\", this),\n-            new Among ( \"ssa\", 0, -1, \"\", this),\n-            new Among ( \"ta\", 0, -1, \"\", this),\n-            new Among ( \"lta\", 4, -1, \"\", this),\n-            new Among ( \"sta\", 4, -1, \"\", this),\n-            new Among ( \"tta\", 4, 9, \"\", this),\n-            new Among ( \"lle\", -1, -1, \"\", this),\n-            new Among ( \"ine\", -1, -1, \"\", this),\n-            new Among ( \"ksi\", -1, -1, \"\", this),\n-            new Among ( \"n\", -1, 7, \"\", this),\n-            new Among ( \"han\", 11, 1, \"\", this),\n-            new Among ( \"den\", 11, -1, \"r_VI\", this),\n-            new Among ( \"seen\", 11, -1, \"r_LONG\", this),\n-            new Among ( \"hen\", 11, 2, \"\", this),\n-            new Among ( \"tten\", 11, -1, \"r_VI\", this),\n-            new Among ( \"hin\", 11, 3, \"\", this),\n-            new Among ( \"siin\", 11, -1, \"r_VI\", this),\n-            new Among ( \"hon\", 11, 4, \"\", this),\n-            new Among ( \"h\\u00E4n\", 11, 5, \"\", this),\n-            new Among ( \"h\\u00F6n\", 11, 6, \"\", this),\n-            new Among ( \"\\u00E4\", -1, 8, \"\", this),\n-            new Among ( \"ll\\u00E4\", 22, -1, \"\", this),\n-            new Among ( \"n\\u00E4\", 22, -1, \"\", this),\n-            new Among ( \"ss\\u00E4\", 22, -1, \"\", this),\n-            new Among ( \"t\\u00E4\", 22, -1, \"\", this),\n-            new Among ( \"lt\\u00E4\", 26, -1, \"\", this),\n-            new Among ( \"st\\u00E4\", 26, -1, \"\", this),\n-            new Among ( \"tt\\u00E4\", 26, 9, \"\", this)\n-        };\n+                private final static Among a_5[] = {\n+                    new Among ( \"aa\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ee\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ii\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"oo\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"uu\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00E4\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00F6\\u00F6\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_7[] = {\n-            new Among ( \"eja\", -1, -1, \"\", this),\n-            new Among ( \"mma\", -1, 1, \"\", this),\n-            new Among ( \"imma\", 1, -1, \"\", this),\n-            new Among ( \"mpa\", -1, 1, \"\", this),\n-            new Among ( \"impa\", 3, -1, \"\", this),\n-            new Among ( \"mmi\", -1, 1, \"\", this),\n-            new Among ( \"immi\", 5, -1, \"\", this),\n-            new Among ( \"mpi\", -1, 1, \"\", this),\n-            new Among ( \"impi\", 7, -1, \"\", this),\n-            new Among ( \"ej\\u00E4\", -1, -1, \"\", this),\n-            new Among ( \"mm\\u00E4\", -1, 1, \"\", this),\n-            new Among ( \"imm\\u00E4\", 10, -1, \"\", this),\n-            new Among ( \"mp\\u00E4\", -1, 1, \"\", this),\n-            new Among ( \"imp\\u00E4\", 12, -1, \"\", this)\n-        };\n+                private final static Among a_6[] = {\n+                    new Among ( \"a\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"lla\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"na\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"ssa\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"ta\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"lta\", 4, -1, \"\", methodObject ),\n+                    new Among ( \"sta\", 4, -1, \"\", methodObject ),\n+                    new Among ( \"tta\", 4, 9, \"\", methodObject ),\n+                    new Among ( \"lle\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ine\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ksi\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"n\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"han\", 11, 1, \"\", methodObject ),\n+                    new Among ( \"den\", 11, -1, \"r_VI\", methodObject ),\n+                    new Among ( \"seen\", 11, -1, \"r_LONG\", methodObject ),\n+                    new Among ( \"hen\", 11, 2, \"\", methodObject ),\n+                    new Among ( \"tten\", 11, -1, \"r_VI\", methodObject ),\n+                    new Among ( \"hin\", 11, 3, \"\", methodObject ),\n+                    new Among ( \"siin\", 11, -1, \"r_VI\", methodObject ),\n+                    new Among ( \"hon\", 11, 4, \"\", methodObject ),\n+                    new Among ( \"h\\u00E4n\", 11, 5, \"\", methodObject ),\n+                    new Among ( \"h\\u00F6n\", 11, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E4\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"ll\\u00E4\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"n\\u00E4\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"ss\\u00E4\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"t\\u00E4\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"lt\\u00E4\", 26, -1, \"\", methodObject ),\n+                    new Among ( \"st\\u00E4\", 26, -1, \"\", methodObject ),\n+                    new Among ( \"tt\\u00E4\", 26, 9, \"\", methodObject )\n+                };\n \n-        private Among a_8[] = {\n-            new Among ( \"i\", -1, -1, \"\", this),\n-            new Among ( \"j\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_7[] = {\n+                    new Among ( \"eja\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"mma\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"imma\", 1, -1, \"\", methodObject ),\n+                    new Among ( \"mpa\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"impa\", 3, -1, \"\", methodObject ),\n+                    new Among ( \"mmi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"immi\", 5, -1, \"\", methodObject ),\n+                    new Among ( \"mpi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"impi\", 7, -1, \"\", methodObject ),\n+                    new Among ( \"ej\\u00E4\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"mm\\u00E4\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"imm\\u00E4\", 10, -1, \"\", methodObject ),\n+                    new Among ( \"mp\\u00E4\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"imp\\u00E4\", 12, -1, \"\", methodObject )\n+                };\n \n-        private Among a_9[] = {\n-            new Among ( \"mma\", -1, 1, \"\", this),\n-            new Among ( \"imma\", 0, -1, \"\", this)\n-        };\n+                private final static Among a_8[] = {\n+                    new Among ( \"i\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"j\", -1, -1, \"\", methodObject )\n+                };\n \n-        private static final char g_AEI[] = {17, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8 };\n+                private final static Among a_9[] = {\n+                    new Among ( \"mma\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"imma\", 0, -1, \"\", methodObject )\n+                };\n \n-        private static final char g_V1[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n+                private static final char g_AEI[] = {17, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8 };\n \n-        private static final char g_V2[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n+                private static final char g_V1[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n \n-        private static final char g_particle_end[] = {17, 97, 24, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n+                private static final char g_V2[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n+\n+                private static final char g_particle_end[] = {17, 97, 24, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32 };\n \n         private boolean B_ending_removed;\n-        private StringBuilder S_x = new StringBuilder();\n+        private java.lang.StringBuilder S_x = new java.lang.StringBuilder();\n         private int I_p2;\n         private int I_p1;\n \n-        private void copy_from(FinnishStemmer other) {\n-            B_ending_removed = other.B_ending_removed;\n-            S_x = other.S_x;\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(FinnishStemmer other) {\n+                    B_ending_removed = other.B_ending_removed;\n+                    S_x = other.S_x;\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n             int v_3;\n-            // (, line 41\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // goto, line 46\n-            golab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n-                    if (!(in_grouping(g_V1, 97, 246)))\n+                    // (, line 41\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // goto, line 46\n+                    golab0: while(true)\n                     {\n-                        break lab1;\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            if (!(in_grouping(g_V1, 97, 246)))\n+                            {\n+                                break lab1;\n+                            }\n+                            cursor = v_1;\n+                            break golab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    cursor = v_1;\n-                    break golab0;\n-                } while (false);\n-                cursor = v_1;\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 46\n-            golab2: while(true)\n-            {\n-                lab3: do {\n-                    if (!(out_grouping(g_V1, 97, 246)))\n+                    // gopast, line 46\n+                    golab2: while(true)\n                     {\n-                        break lab3;\n+                        lab3: do {\n+                            if (!(out_grouping(g_V1, 97, 246)))\n+                            {\n+                                break lab3;\n+                            }\n+                            break golab2;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab2;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // setmark p1, line 46\n-            I_p1 = cursor;\n-            // goto, line 47\n-            golab4: while(true)\n-            {\n-                v_3 = cursor;\n-                lab5: do {\n-                    if (!(in_grouping(g_V1, 97, 246)))\n+                    // setmark p1, line 46\n+                    I_p1 = cursor;\n+                    // goto, line 47\n+                    golab4: while(true)\n                     {\n-                        break lab5;\n+                        v_3 = cursor;\n+                        lab5: do {\n+                            if (!(in_grouping(g_V1, 97, 246)))\n+                            {\n+                                break lab5;\n+                            }\n+                            cursor = v_3;\n+                            break golab4;\n+                        } while (false);\n+                        cursor = v_3;\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    cursor = v_3;\n-                    break golab4;\n-                } while (false);\n-                cursor = v_3;\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 47\n-            golab6: while(true)\n-            {\n-                lab7: do {\n-                    if (!(out_grouping(g_V1, 97, 246)))\n+                    // gopast, line 47\n+                    golab6: while(true)\n                     {\n-                        break lab7;\n+                        lab7: do {\n+                            if (!(out_grouping(g_V1, 97, 246)))\n+                            {\n+                                break lab7;\n+                            }\n+                            break golab6;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab6;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n+                    // setmark p2, line 47\n+                    I_p2 = cursor;\n+                    return true;\n                 }\n-                cursor++;\n-            }\n-            // setmark p2, line 47\n-            I_p2 = cursor;\n-            return true;\n-        }\n \n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_particle_etc() {\n+                private boolean r_particle_etc() {\n             int among_var;\n             int v_1;\n             int v_2;\n-            // (, line 54\n-            // setlimit, line 55\n-            v_1 = limit - cursor;\n-            // tomark, line 55\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 55\n-            // [, line 55\n-            ket = cursor;\n-            // substring, line 55\n-            among_var = find_among_b(a_0, 10);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 55\n-            bra = cursor;\n-            limit_backward = v_2;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 62\n-                    if (!(in_grouping_b(g_particle_end, 97, 246)))\n+                    // (, line 54\n+                    // setlimit, line 55\n+                    v_1 = limit - cursor;\n+                    // tomark, line 55\n+                    if (cursor < I_p1)\n                     {\n                         return false;\n                     }\n-                    break;\n-                case 2:\n-                    // (, line 64\n-                    // call R2, line 64\n-                    if (!r_R2())\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 55\n+                    // [, line 55\n+                    ket = cursor;\n+                    // substring, line 55\n+                    among_var = find_among_b(a_0, 10);\n+                    if (among_var == 0)\n                     {\n+                        limit_backward = v_2;\n                         return false;\n                     }\n-                    break;\n-            }\n-            // delete, line 66\n-            slice_del();\n-            return true;\n-        }\n+                    // ], line 55\n+                    bra = cursor;\n+                    limit_backward = v_2;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 62\n+                            if (!(in_grouping_b(g_particle_end, 97, 246)))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 2:\n+                            // (, line 64\n+                            // call R2, line 64\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                    }\n+                    // delete, line 66\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_possessive() {\n+                private boolean r_possessive() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n-            // (, line 68\n-            // setlimit, line 69\n-            v_1 = limit - cursor;\n-            // tomark, line 69\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 69\n-            // [, line 69\n-            ket = cursor;\n-            // substring, line 69\n-            among_var = find_among_b(a_4, 9);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 69\n-            bra = cursor;\n-            limit_backward = v_2;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 72\n-                    // not, line 72\n+                    // (, line 68\n+                    // setlimit, line 69\n+                    v_1 = limit - cursor;\n+                    // tomark, line 69\n+                    if (cursor < I_p1)\n                     {\n-                        v_3 = limit - cursor;\n-                        lab0: do {\n-                            // literal, line 72\n-                            if (!(eq_s_b(1, \"k\")))\n-                            {\n-                                break lab0;\n-                            }\n-                            return false;\n-                        } while (false);\n-                        cursor = limit - v_3;\n+                        return false;\n                     }\n-                    // delete, line 72\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 74\n-                    // delete, line 74\n-                    slice_del();\n-                    // [, line 74\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 69\n+                    // [, line 69\n                     ket = cursor;\n-                    // literal, line 74\n-                    if (!(eq_s_b(3, \"kse\")))\n+                    // substring, line 69\n+                    among_var = find_among_b(a_4, 9);\n+                    if (among_var == 0)\n                     {\n+                        limit_backward = v_2;\n                         return false;\n                     }\n-                    // ], line 74\n+                    // ], line 69\n                     bra = cursor;\n-                    // <-, line 74\n-                    slice_from(\"ksi\");\n-                    break;\n-                case 3:\n-                    // (, line 78\n-                    // delete, line 78\n-                    slice_del();\n-                    break;\n-                case 4:\n-                    // (, line 81\n-                    // among, line 81\n-                    if (find_among_b(a_1, 6) == 0)\n+                    limit_backward = v_2;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 72\n+                            // not, line 72\n+                            {\n+                                v_3 = limit - cursor;\n+                                lab0: do {\n+                                    // literal, line 72\n+                                    if (!(eq_s_b(1, \"k\")))\n+                                    {\n+                                        break lab0;\n+                                    }\n+                                    return false;\n+                                } while (false);\n+                                cursor = limit - v_3;\n+                            }\n+                            // delete, line 72\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 74\n+                            // delete, line 74\n+                            slice_del();\n+                            // [, line 74\n+                            ket = cursor;\n+                            // literal, line 74\n+                            if (!(eq_s_b(3, \"kse\")))\n+                            {\n+                                return false;\n+                            }\n+                            // ], line 74\n+                            bra = cursor;\n+                            // <-, line 74\n+                            slice_from(\"ksi\");\n+                            break;\n+                        case 3:\n+                            // (, line 78\n+                            // delete, line 78\n+                            slice_del();\n+                            break;\n+                        case 4:\n+                            // (, line 81\n+                            // among, line 81\n+                            if (find_among_b(a_1, 6) == 0)\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 81\n+                            slice_del();\n+                            break;\n+                        case 5:\n+                            // (, line 83\n+                            // among, line 83\n+                            if (find_among_b(a_2, 6) == 0)\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 84\n+                            slice_del();\n+                            break;\n+                        case 6:\n+                            // (, line 86\n+                            // among, line 86\n+                            if (find_among_b(a_3, 2) == 0)\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 86\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n+\n+                private boolean r_LONG() {\n+                    // among, line 91\n+                    if (find_among_b(a_5, 7) == 0)\n                     {\n                         return false;\n                     }\n-                    // delete, line 81\n-                    slice_del();\n-                    break;\n-                case 5:\n-                    // (, line 83\n-                    // among, line 83\n-                    if (find_among_b(a_2, 6) == 0)\n+                    return true;\n+                }\n+\n+                private boolean r_VI() {\n+                    // (, line 93\n+                    // literal, line 93\n+                    if (!(eq_s_b(1, \"i\")))\n                     {\n                         return false;\n                     }\n-                    // delete, line 84\n-                    slice_del();\n-                    break;\n-                case 6:\n-                    // (, line 86\n-                    // among, line 86\n-                    if (find_among_b(a_3, 2) == 0)\n+                    if (!(in_grouping_b(g_V2, 97, 246)))\n                     {\n                         return false;\n                     }\n-                    // delete, line 86\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_LONG() {\n-            // among, line 91\n-            if (find_among_b(a_5, 7) == 0)\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_VI() {\n-            // (, line 93\n-            // literal, line 93\n-            if (!(eq_s_b(1, \"i\")))\n-            {\n-                return false;\n-            }\n-            if (!(in_grouping_b(g_V2, 97, 246)))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_case_ending() {\n+                private boolean r_case_ending() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n-            // (, line 95\n-            // setlimit, line 96\n-            v_1 = limit - cursor;\n-            // tomark, line 96\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 96\n-            // [, line 96\n-            ket = cursor;\n-            // substring, line 96\n-            among_var = find_among_b(a_6, 30);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 96\n-            bra = cursor;\n-            limit_backward = v_2;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 98\n-                    // literal, line 98\n-                    if (!(eq_s_b(1, \"a\")))\n-                    {\n-                        return false;\n-                    }\n-                    break;\n-                case 2:\n-                    // (, line 99\n-                    // literal, line 99\n-                    if (!(eq_s_b(1, \"e\")))\n-                    {\n-                        return false;\n-                    }\n-                    break;\n-                case 3:\n-                    // (, line 100\n-                    // literal, line 100\n-                    if (!(eq_s_b(1, \"i\")))\n+                    // (, line 95\n+                    // setlimit, line 96\n+                    v_1 = limit - cursor;\n+                    // tomark, line 96\n+                    if (cursor < I_p1)\n                     {\n                         return false;\n                     }\n-                    break;\n-                case 4:\n-                    // (, line 101\n-                    // literal, line 101\n-                    if (!(eq_s_b(1, \"o\")))\n-                    {\n-                        return false;\n-                    }\n-                    break;\n-                case 5:\n-                    // (, line 102\n-                    // literal, line 102\n-                    if (!(eq_s_b(1, \"\\u00E4\")))\n-                    {\n-                        return false;\n-                    }\n-                    break;\n-                case 6:\n-                    // (, line 103\n-                    // literal, line 103\n-                    if (!(eq_s_b(1, \"\\u00F6\")))\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 96\n+                    // [, line 96\n+                    ket = cursor;\n+                    // substring, line 96\n+                    among_var = find_among_b(a_6, 30);\n+                    if (among_var == 0)\n                     {\n+                        limit_backward = v_2;\n                         return false;\n                     }\n-                    break;\n-                case 7:\n-                    // (, line 111\n-                    // try, line 111\n-                    v_3 = limit - cursor;\n-                    lab0: do {\n-                        // (, line 111\n-                        // and, line 113\n-                        v_4 = limit - cursor;\n-                        // or, line 112\n-                        lab1: do {\n-                            v_5 = limit - cursor;\n-                            lab2: do {\n-                                // call LONG, line 111\n-                                if (!r_LONG())\n+                    // ], line 96\n+                    bra = cursor;\n+                    limit_backward = v_2;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 98\n+                            // literal, line 98\n+                            if (!(eq_s_b(1, \"a\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 2:\n+                            // (, line 99\n+                            // literal, line 99\n+                            if (!(eq_s_b(1, \"e\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 3:\n+                            // (, line 100\n+                            // literal, line 100\n+                            if (!(eq_s_b(1, \"i\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 4:\n+                            // (, line 101\n+                            // literal, line 101\n+                            if (!(eq_s_b(1, \"o\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 5:\n+                            // (, line 102\n+                            // literal, line 102\n+                            if (!(eq_s_b(1, \"\\u00E4\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 6:\n+                            // (, line 103\n+                            // literal, line 103\n+                            if (!(eq_s_b(1, \"\\u00F6\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 7:\n+                            // (, line 111\n+                            // try, line 111\n+                            v_3 = limit - cursor;\n+                            lab0: do {\n+                                // (, line 111\n+                                // and, line 113\n+                                v_4 = limit - cursor;\n+                                // or, line 112\n+                                lab1: do {\n+                                    v_5 = limit - cursor;\n+                                    lab2: do {\n+                                        // call LONG, line 111\n+                                        if (!r_LONG())\n+                                        {\n+                                            break lab2;\n+                                        }\n+                                        break lab1;\n+                                    } while (false);\n+                                    cursor = limit - v_5;\n+                                    // literal, line 112\n+                                    if (!(eq_s_b(2, \"ie\")))\n+                                    {\n+                                        cursor = limit - v_3;\n+                                        break lab0;\n+                                    }\n+                                } while (false);\n+                                cursor = limit - v_4;\n+                                // next, line 113\n+                                if (cursor <= limit_backward)\n                                 {\n-                                    break lab2;\n+                                    cursor = limit - v_3;\n+                                    break lab0;\n                                 }\n-                                break lab1;\n+                                cursor--;\n+                                // ], line 113\n+                                bra = cursor;\n                             } while (false);\n-                            cursor = limit - v_5;\n-                            // literal, line 112\n-                            if (!(eq_s_b(2, \"ie\")))\n+                            break;\n+                        case 8:\n+                            // (, line 119\n+                            if (!(in_grouping_b(g_V1, 97, 246)))\n                             {\n-                                cursor = limit - v_3;\n-                                break lab0;\n+                                return false;\n                             }\n-                        } while (false);\n-                        cursor = limit - v_4;\n-                        // next, line 113\n-                        if (cursor <= limit_backward)\n-                        {\n-                            cursor = limit - v_3;\n-                            break lab0;\n-                        }\n-                        cursor--;\n-                        // ], line 113\n-                        bra = cursor;\n-                    } while (false);\n-                    break;\n-                case 8:\n-                    // (, line 119\n-                    if (!(in_grouping_b(g_V1, 97, 246)))\n-                    {\n-                        return false;\n-                    }\n-                    if (!(out_grouping_b(g_V1, 97, 246)))\n-                    {\n-                        return false;\n-                    }\n-                    break;\n-                case 9:\n-                    // (, line 121\n-                    // literal, line 121\n-                    if (!(eq_s_b(1, \"e\")))\n-                    {\n-                        return false;\n+                            if (!(out_grouping_b(g_V1, 97, 246)))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 9:\n+                            // (, line 121\n+                            // literal, line 121\n+                            if (!(eq_s_b(1, \"e\")))\n+                            {\n+                                return false;\n+                            }\n+                            break;\n                     }\n-                    break;\n-            }\n-            // delete, line 138\n-            slice_del();\n-            // set ending_removed, line 139\n-            B_ending_removed = true;\n-            return true;\n-        }\n+                    // delete, line 138\n+                    slice_del();\n+                    // set ending_removed, line 139\n+                    B_ending_removed = true;\n+                    return true;\n+                }\n \n-        private boolean r_other_endings() {\n+                private boolean r_other_endings() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n-            // (, line 141\n-            // setlimit, line 142\n-            v_1 = limit - cursor;\n-            // tomark, line 142\n-            if (cursor < I_p2)\n-            {\n-                return false;\n-            }\n-            cursor = I_p2;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 142\n-            // [, line 142\n-            ket = cursor;\n-            // substring, line 142\n-            among_var = find_among_b(a_7, 14);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 142\n-            bra = cursor;\n-            limit_backward = v_2;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 146\n-                    // not, line 146\n+                    // (, line 141\n+                    // setlimit, line 142\n+                    v_1 = limit - cursor;\n+                    // tomark, line 142\n+                    if (cursor < I_p2)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p2;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 142\n+                    // [, line 142\n+                    ket = cursor;\n+                    // substring, line 142\n+                    among_var = find_among_b(a_7, 14);\n+                    if (among_var == 0)\n                     {\n-                        v_3 = limit - cursor;\n-                        lab0: do {\n-                            // literal, line 146\n-                            if (!(eq_s_b(2, \"po\")))\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    // ], line 142\n+                    bra = cursor;\n+                    limit_backward = v_2;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 146\n+                            // not, line 146\n                             {\n-                                break lab0;\n+                                v_3 = limit - cursor;\n+                                lab0: do {\n+                                    // literal, line 146\n+                                    if (!(eq_s_b(2, \"po\")))\n+                                    {\n+                                        break lab0;\n+                                    }\n+                                    return false;\n+                                } while (false);\n+                                cursor = limit - v_3;\n                             }\n-                            return false;\n-                        } while (false);\n-                        cursor = limit - v_3;\n+                            break;\n                     }\n-                    break;\n-            }\n-            // delete, line 151\n-            slice_del();\n-            return true;\n-        }\n+                    // delete, line 151\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_i_plural() {\n+                private boolean r_i_plural() {\n             int v_1;\n             int v_2;\n-            // (, line 153\n-            // setlimit, line 154\n-            v_1 = limit - cursor;\n-            // tomark, line 154\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 154\n-            // [, line 154\n-            ket = cursor;\n-            // substring, line 154\n-            if (find_among_b(a_8, 2) == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 154\n-            bra = cursor;\n-            limit_backward = v_2;\n-            // delete, line 158\n-            slice_del();\n-            return true;\n-        }\n+                    // (, line 153\n+                    // setlimit, line 154\n+                    v_1 = limit - cursor;\n+                    // tomark, line 154\n+                    if (cursor < I_p1)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 154\n+                    // [, line 154\n+                    ket = cursor;\n+                    // substring, line 154\n+                    if (find_among_b(a_8, 2) == 0)\n+                    {\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    // ], line 154\n+                    bra = cursor;\n+                    limit_backward = v_2;\n+                    // delete, line 158\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_t_plural() {\n+                private boolean r_t_plural() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n             int v_6;\n-            // (, line 160\n-            // setlimit, line 161\n-            v_1 = limit - cursor;\n-            // tomark, line 161\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 161\n-            // [, line 162\n-            ket = cursor;\n-            // literal, line 162\n-            if (!(eq_s_b(1, \"t\")))\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 162\n-            bra = cursor;\n-            // test, line 162\n-            v_3 = limit - cursor;\n-            if (!(in_grouping_b(g_V1, 97, 246)))\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            cursor = limit - v_3;\n-            // delete, line 163\n-            slice_del();\n-            limit_backward = v_2;\n-            // setlimit, line 165\n-            v_4 = limit - cursor;\n-            // tomark, line 165\n-            if (cursor < I_p2)\n-            {\n-                return false;\n-            }\n-            cursor = I_p2;\n-            v_5 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_4;\n-            // (, line 165\n-            // [, line 165\n-            ket = cursor;\n-            // substring, line 165\n-            among_var = find_among_b(a_9, 2);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_5;\n-                return false;\n-            }\n-            // ], line 165\n-            bra = cursor;\n-            limit_backward = v_5;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 167\n-                    // not, line 167\n+                    // (, line 160\n+                    // setlimit, line 161\n+                    v_1 = limit - cursor;\n+                    // tomark, line 161\n+                    if (cursor < I_p1)\n                     {\n-                        v_6 = limit - cursor;\n-                        lab0: do {\n-                            // literal, line 167\n-                            if (!(eq_s_b(2, \"po\")))\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 161\n+                    // [, line 162\n+                    ket = cursor;\n+                    // literal, line 162\n+                    if (!(eq_s_b(1, \"t\")))\n+                    {\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    // ], line 162\n+                    bra = cursor;\n+                    // test, line 162\n+                    v_3 = limit - cursor;\n+                    if (!(in_grouping_b(g_V1, 97, 246)))\n+                    {\n+                        limit_backward = v_2;\n+                        return false;\n+                    }\n+                    cursor = limit - v_3;\n+                    // delete, line 163\n+                    slice_del();\n+                    limit_backward = v_2;\n+                    // setlimit, line 165\n+                    v_4 = limit - cursor;\n+                    // tomark, line 165\n+                    if (cursor < I_p2)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p2;\n+                    v_5 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_4;\n+                    // (, line 165\n+                    // [, line 165\n+                    ket = cursor;\n+                    // substring, line 165\n+                    among_var = find_among_b(a_9, 2);\n+                    if (among_var == 0)\n+                    {\n+                        limit_backward = v_5;\n+                        return false;\n+                    }\n+                    // ], line 165\n+                    bra = cursor;\n+                    limit_backward = v_5;\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 167\n+                            // not, line 167\n                             {\n-                                break lab0;\n+                                v_6 = limit - cursor;\n+                                lab0: do {\n+                                    // literal, line 167\n+                                    if (!(eq_s_b(2, \"po\")))\n+                                    {\n+                                        break lab0;\n+                                    }\n+                                    return false;\n+                                } while (false);\n+                                cursor = limit - v_6;\n                             }\n-                            return false;\n-                        } while (false);\n-                        cursor = limit - v_6;\n+                            break;\n                     }\n-                    break;\n-            }\n-            // delete, line 170\n-            slice_del();\n-            return true;\n-        }\n+                    // delete, line 170\n+                    slice_del();\n+                    return true;\n+                }\n \n-        private boolean r_tidy() {\n+                private boolean r_tidy() {\n             int v_1;\n             int v_2;\n             int v_3;\n@@ -758,166 +765,166 @@ private boolean r_tidy() {\n             int v_7;\n             int v_8;\n             int v_9;\n-            // (, line 172\n-            // setlimit, line 173\n-            v_1 = limit - cursor;\n-            // tomark, line 173\n-            if (cursor < I_p1)\n-            {\n-                return false;\n-            }\n-            cursor = I_p1;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 173\n-            // do, line 174\n-            v_3 = limit - cursor;\n-            lab0: do {\n-                // (, line 174\n-                // and, line 174\n-                v_4 = limit - cursor;\n-                // call LONG, line 174\n-                if (!r_LONG())\n-                {\n-                    break lab0;\n-                }\n-                cursor = limit - v_4;\n-                // (, line 174\n-                // [, line 174\n-                ket = cursor;\n-                // next, line 174\n-                if (cursor <= limit_backward)\n-                {\n-                    break lab0;\n-                }\n-                cursor--;\n-                // ], line 174\n-                bra = cursor;\n-                // delete, line 174\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 175\n-            v_5 = limit - cursor;\n-            lab1: do {\n-                // (, line 175\n-                // [, line 175\n-                ket = cursor;\n-                if (!(in_grouping_b(g_AEI, 97, 228)))\n-                {\n-                    break lab1;\n-                }\n-                // ], line 175\n-                bra = cursor;\n-                if (!(out_grouping_b(g_V1, 97, 246)))\n-                {\n-                    break lab1;\n-                }\n-                // delete, line 175\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_5;\n-            // do, line 176\n-            v_6 = limit - cursor;\n-            lab2: do {\n-                // (, line 176\n-                // [, line 176\n-                ket = cursor;\n-                // literal, line 176\n-                if (!(eq_s_b(1, \"j\")))\n-                {\n-                    break lab2;\n-                }\n-                // ], line 176\n-                bra = cursor;\n-                // or, line 176\n-                lab3: do {\n-                    v_7 = limit - cursor;\n-                    lab4: do {\n+                    // (, line 172\n+                    // setlimit, line 173\n+                    v_1 = limit - cursor;\n+                    // tomark, line 173\n+                    if (cursor < I_p1)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = I_p1;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 173\n+                    // do, line 174\n+                    v_3 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 174\n+                        // and, line 174\n+                        v_4 = limit - cursor;\n+                        // call LONG, line 174\n+                        if (!r_LONG())\n+                        {\n+                            break lab0;\n+                        }\n+                        cursor = limit - v_4;\n+                        // (, line 174\n+                        // [, line 174\n+                        ket = cursor;\n+                        // next, line 174\n+                        if (cursor <= limit_backward)\n+                        {\n+                            break lab0;\n+                        }\n+                        cursor--;\n+                        // ], line 174\n+                        bra = cursor;\n+                        // delete, line 174\n+                        slice_del();\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    // do, line 175\n+                    v_5 = limit - cursor;\n+                    lab1: do {\n+                        // (, line 175\n+                        // [, line 175\n+                        ket = cursor;\n+                        if (!(in_grouping_b(g_AEI, 97, 228)))\n+                        {\n+                            break lab1;\n+                        }\n+                        // ], line 175\n+                        bra = cursor;\n+                        if (!(out_grouping_b(g_V1, 97, 246)))\n+                        {\n+                            break lab1;\n+                        }\n+                        // delete, line 175\n+                        slice_del();\n+                    } while (false);\n+                    cursor = limit - v_5;\n+                    // do, line 176\n+                    v_6 = limit - cursor;\n+                    lab2: do {\n+                        // (, line 176\n+                        // [, line 176\n+                        ket = cursor;\n                         // literal, line 176\n+                        if (!(eq_s_b(1, \"j\")))\n+                        {\n+                            break lab2;\n+                        }\n+                        // ], line 176\n+                        bra = cursor;\n+                        // or, line 176\n+                        lab3: do {\n+                            v_7 = limit - cursor;\n+                            lab4: do {\n+                                // literal, line 176\n+                                if (!(eq_s_b(1, \"o\")))\n+                                {\n+                                    break lab4;\n+                                }\n+                                break lab3;\n+                            } while (false);\n+                            cursor = limit - v_7;\n+                            // literal, line 176\n+                            if (!(eq_s_b(1, \"u\")))\n+                            {\n+                                break lab2;\n+                            }\n+                        } while (false);\n+                        // delete, line 176\n+                        slice_del();\n+                    } while (false);\n+                    cursor = limit - v_6;\n+                    // do, line 177\n+                    v_8 = limit - cursor;\n+                    lab5: do {\n+                        // (, line 177\n+                        // [, line 177\n+                        ket = cursor;\n+                        // literal, line 177\n                         if (!(eq_s_b(1, \"o\")))\n                         {\n-                            break lab4;\n+                            break lab5;\n+                        }\n+                        // ], line 177\n+                        bra = cursor;\n+                        // literal, line 177\n+                        if (!(eq_s_b(1, \"j\")))\n+                        {\n+                            break lab5;\n                         }\n-                        break lab3;\n+                        // delete, line 177\n+                        slice_del();\n                     } while (false);\n-                    cursor = limit - v_7;\n-                    // literal, line 176\n-                    if (!(eq_s_b(1, \"u\")))\n+                    cursor = limit - v_8;\n+                    limit_backward = v_2;\n+                    // goto, line 179\n+                    golab6: while(true)\n                     {\n-                        break lab2;\n+                        v_9 = limit - cursor;\n+                        lab7: do {\n+                            if (!(out_grouping_b(g_V1, 97, 246)))\n+                            {\n+                                break lab7;\n+                            }\n+                            cursor = limit - v_9;\n+                            break golab6;\n+                        } while (false);\n+                        cursor = limit - v_9;\n+                        if (cursor <= limit_backward)\n+                        {\n+                            return false;\n+                        }\n+                        cursor--;\n                     }\n-                } while (false);\n-                // delete, line 176\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_6;\n-            // do, line 177\n-            v_8 = limit - cursor;\n-            lab5: do {\n-                // (, line 177\n-                // [, line 177\n-                ket = cursor;\n-                // literal, line 177\n-                if (!(eq_s_b(1, \"o\")))\n-                {\n-                    break lab5;\n-                }\n-                // ], line 177\n-                bra = cursor;\n-                // literal, line 177\n-                if (!(eq_s_b(1, \"j\")))\n-                {\n-                    break lab5;\n-                }\n-                // delete, line 177\n-                slice_del();\n-            } while (false);\n-            cursor = limit - v_8;\n-            limit_backward = v_2;\n-            // goto, line 179\n-            golab6: while(true)\n-            {\n-                v_9 = limit - cursor;\n-                lab7: do {\n-                    if (!(out_grouping_b(g_V1, 97, 246)))\n+                    // [, line 179\n+                    ket = cursor;\n+                    // next, line 179\n+                    if (cursor <= limit_backward)\n                     {\n-                        break lab7;\n+                        return false;\n                     }\n-                    cursor = limit - v_9;\n-                    break golab6;\n-                } while (false);\n-                cursor = limit - v_9;\n-                if (cursor <= limit_backward)\n-                {\n-                    return false;\n+                    cursor--;\n+                    // ], line 179\n+                    bra = cursor;\n+                    // -> x, line 179\n+                    S_x = slice_to(S_x);\n+                    // name x, line 179\n+                    if (!(eq_v_b(S_x)))\n+                    {\n+                        return false;\n+                    }\n+                    // delete, line 179\n+                    slice_del();\n+                    return true;\n                 }\n-                cursor--;\n-            }\n-            // [, line 179\n-            ket = cursor;\n-            // next, line 179\n-            if (cursor <= limit_backward)\n-            {\n-                return false;\n-            }\n-            cursor--;\n-            // ], line 179\n-            bra = cursor;\n-            // -> x, line 179\n-            S_x = slice_to(S_x);\n-            // name x, line 179\n-            if (!(eq_v_b(S_x)))\n-            {\n-                return false;\n-            }\n-            // delete, line 179\n-            slice_del();\n-            return true;\n-        }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n@@ -927,108 +934,118 @@ public boolean stem() {\n             int v_7;\n             int v_8;\n             int v_9;\n-            // (, line 183\n-            // do, line 185\n-            v_1 = cursor;\n-            lab0: do {\n-                // call mark_regions, line 185\n-                if (!r_mark_regions())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // unset ending_removed, line 186\n-            B_ending_removed = false;\n-            // backwards, line 187\n-            limit_backward = cursor; cursor = limit;\n-            // (, line 187\n-            // do, line 188\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // call particle_etc, line 188\n-                if (!r_particle_etc())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 189\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call possessive, line 189\n-                if (!r_possessive())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 190\n-            v_4 = limit - cursor;\n-            lab3: do {\n-                // call case_ending, line 190\n-                if (!r_case_ending())\n-                {\n-                    break lab3;\n-                }\n-            } while (false);\n-            cursor = limit - v_4;\n-            // do, line 191\n-            v_5 = limit - cursor;\n-            lab4: do {\n-                // call other_endings, line 191\n-                if (!r_other_endings())\n-                {\n-                    break lab4;\n-                }\n-            } while (false);\n-            cursor = limit - v_5;\n-            // or, line 192\n-            lab5: do {\n-                v_6 = limit - cursor;\n-                lab6: do {\n-                    // (, line 192\n-                    // Boolean test ending_removed, line 192\n-                    if (!(B_ending_removed))\n-                    {\n-                        break lab6;\n-                    }\n-                    // do, line 192\n-                    v_7 = limit - cursor;\n-                    lab7: do {\n-                        // call i_plural, line 192\n-                        if (!r_i_plural())\n+                    // (, line 183\n+                    // do, line 185\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call mark_regions, line 185\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // unset ending_removed, line 186\n+                    B_ending_removed = false;\n+                    // backwards, line 187\n+                    limit_backward = cursor; cursor = limit;\n+                    // (, line 187\n+                    // do, line 188\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // call particle_etc, line 188\n+                        if (!r_particle_etc())\n                         {\n-                            break lab7;\n+                            break lab1;\n                         }\n                     } while (false);\n-                    cursor = limit - v_7;\n-                    break lab5;\n-                } while (false);\n-                cursor = limit - v_6;\n-                // do, line 192\n-                v_8 = limit - cursor;\n-                lab8: do {\n-                    // call t_plural, line 192\n-                    if (!r_t_plural())\n-                    {\n-                        break lab8;\n-                    }\n-                } while (false);\n-                cursor = limit - v_8;\n-            } while (false);\n-            // do, line 193\n-            v_9 = limit - cursor;\n-            lab9: do {\n-                // call tidy, line 193\n-                if (!r_tidy())\n-                {\n-                    break lab9;\n+                    cursor = limit - v_2;\n+                    // do, line 189\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call possessive, line 189\n+                        if (!r_possessive())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    // do, line 190\n+                    v_4 = limit - cursor;\n+                    lab3: do {\n+                        // call case_ending, line 190\n+                        if (!r_case_ending())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_4;\n+                    // do, line 191\n+                    v_5 = limit - cursor;\n+                    lab4: do {\n+                        // call other_endings, line 191\n+                        if (!r_other_endings())\n+                        {\n+                            break lab4;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_5;\n+                    // or, line 192\n+                    lab5: do {\n+                        v_6 = limit - cursor;\n+                        lab6: do {\n+                            // (, line 192\n+                            // Boolean test ending_removed, line 192\n+                            if (!(B_ending_removed))\n+                            {\n+                                break lab6;\n+                            }\n+                            // do, line 192\n+                            v_7 = limit - cursor;\n+                            lab7: do {\n+                                // call i_plural, line 192\n+                                if (!r_i_plural())\n+                                {\n+                                    break lab7;\n+                                }\n+                            } while (false);\n+                            cursor = limit - v_7;\n+                            break lab5;\n+                        } while (false);\n+                        cursor = limit - v_6;\n+                        // do, line 192\n+                        v_8 = limit - cursor;\n+                        lab8: do {\n+                            // call t_plural, line 192\n+                            if (!r_t_plural())\n+                            {\n+                                break lab8;\n+                            }\n+                        } while (false);\n+                        cursor = limit - v_8;\n+                    } while (false);\n+                    // do, line 193\n+                    v_9 = limit - cursor;\n+                    lab9: do {\n+                        // call tidy, line 193\n+                        if (!r_tidy())\n+                        {\n+                            break lab9;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_9;\n+                    cursor = limit_backward;                    return true;\n                 }\n-            } while (false);\n-            cursor = limit - v_9;\n-            cursor = limit_backward;            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof FinnishStemmer;\n         }\n \n+        public int hashCode() {\n+            return FinnishStemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FinnishStemmer.java",
                "sha": "26f3ce1ed8cf122ed03c3b07aa29f9b6876e42e6",
                "status": "modified"
            },
            {
                "additions": 1318,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FrenchStemmer.java",
                "changes": 2619,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FrenchStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1301,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/FrenchStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/FrenchStemmer.java",
                "sha": "4f5cac30aaad0878b808968f016d25a24d7823dc",
                "status": "modified"
            },
            {
                "additions": 640,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/German2Stemmer.java",
                "changes": 1263,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/German2Stemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 623,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/German2Stemmer.java",
                "patch": "@@ -1,412 +1,419 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class German2Stemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"\", -1, 6, \"\", this),\n-            new Among ( \"ae\", 0, 2, \"\", this),\n-            new Among ( \"oe\", 0, 3, \"\", this),\n-            new Among ( \"qu\", 0, 5, \"\", this),\n-            new Among ( \"ue\", 0, 4, \"\", this),\n-            new Among ( \"\\u00DF\", 0, 1, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"\", -1, 6, \"\", this),\n-            new Among ( \"U\", 0, 2, \"\", this),\n-            new Among ( \"Y\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E4\", 0, 3, \"\", this),\n-            new Among ( \"\\u00F6\", 0, 4, \"\", this),\n-            new Among ( \"\\u00FC\", 0, 5, \"\", this)\n-        };\n+        private final static German2Stemmer methodObject = new German2Stemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"e\", -1, 1, \"\", this),\n-            new Among ( \"em\", -1, 1, \"\", this),\n-            new Among ( \"en\", -1, 1, \"\", this),\n-            new Among ( \"ern\", -1, 1, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"s\", -1, 2, \"\", this),\n-            new Among ( \"es\", 5, 1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"ae\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"oe\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"qu\", 0, 5, \"\", methodObject ),\n+                    new Among ( \"ue\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00DF\", 0, 1, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"en\", -1, 1, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"st\", -1, 2, \"\", this),\n-            new Among ( \"est\", 2, 1, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"U\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"Y\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E4\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00F6\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00FC\", 0, 5, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"ig\", -1, 1, \"\", this),\n-            new Among ( \"lich\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"e\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"em\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"en\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ern\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"s\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"es\", 5, 1, \"\", methodObject )\n+                };\n \n-        private Among a_5[] = {\n-            new Among ( \"end\", -1, 1, \"\", this),\n-            new Among ( \"ig\", -1, 2, \"\", this),\n-            new Among ( \"ung\", -1, 1, \"\", this),\n-            new Among ( \"lich\", -1, 3, \"\", this),\n-            new Among ( \"isch\", -1, 2, \"\", this),\n-            new Among ( \"ik\", -1, 2, \"\", this),\n-            new Among ( \"heit\", -1, 3, \"\", this),\n-            new Among ( \"keit\", -1, 4, \"\", this)\n-        };\n+                private final static Among a_3[] = {\n+                    new Among ( \"en\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"st\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"est\", 2, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32, 8 };\n+                private final static Among a_4[] = {\n+                    new Among ( \"ig\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lich\", -1, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_s_ending[] = {117, 30, 5 };\n+                private final static Among a_5[] = {\n+                    new Among ( \"end\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ig\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ung\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lich\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"isch\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ik\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"heit\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"keit\", -1, 4, \"\", methodObject )\n+                };\n \n-        private static final char g_st_ending[] = {117, 30, 4 };\n+                private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32, 8 };\n+\n+                private static final char g_s_ending[] = {117, 30, 5 };\n+\n+                private static final char g_st_ending[] = {117, 30, 4 };\n \n         private int I_x;\n         private int I_p2;\n         private int I_p1;\n \n-        private void copy_from(German2Stemmer other) {\n-            I_x = other.I_x;\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(German2Stemmer other) {\n+                    I_x = other.I_x;\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_prelude() {\n+                private boolean r_prelude() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n-            // (, line 28\n-            // test, line 30\n-            v_1 = cursor;\n-            // repeat, line 30\n-            replab0: while(true)\n-            {\n-                v_2 = cursor;\n-                lab1: do {\n-                    // goto, line 30\n-                    golab2: while(true)\n+                    // (, line 28\n+                    // test, line 30\n+                    v_1 = cursor;\n+                    // repeat, line 30\n+                    replab0: while(true)\n                     {\n-                        v_3 = cursor;\n-                        lab3: do {\n-                            // (, line 30\n-                            if (!(in_grouping(g_v, 97, 252)))\n+                        v_2 = cursor;\n+                        lab1: do {\n+                            // goto, line 30\n+                            golab2: while(true)\n                             {\n-                                break lab3;\n-                            }\n-                            // [, line 31\n-                            bra = cursor;\n-                            // or, line 31\n-                            lab4: do {\n-                                v_4 = cursor;\n-                                lab5: do {\n-                                    // (, line 31\n-                                    // literal, line 31\n-                                    if (!(eq_s(1, \"u\")))\n-                                    {\n-                                        break lab5;\n-                                    }\n-                                    // ], line 31\n-                                    ket = cursor;\n+                                v_3 = cursor;\n+                                lab3: do {\n+                                    // (, line 30\n                                     if (!(in_grouping(g_v, 97, 252)))\n                                     {\n-                                        break lab5;\n+                                        break lab3;\n                                     }\n-                                    // <-, line 31\n-                                    slice_from(\"U\");\n-                                    break lab4;\n+                                    // [, line 31\n+                                    bra = cursor;\n+                                    // or, line 31\n+                                    lab4: do {\n+                                        v_4 = cursor;\n+                                        lab5: do {\n+                                            // (, line 31\n+                                            // literal, line 31\n+                                            if (!(eq_s(1, \"u\")))\n+                                            {\n+                                                break lab5;\n+                                            }\n+                                            // ], line 31\n+                                            ket = cursor;\n+                                            if (!(in_grouping(g_v, 97, 252)))\n+                                            {\n+                                                break lab5;\n+                                            }\n+                                            // <-, line 31\n+                                            slice_from(\"U\");\n+                                            break lab4;\n+                                        } while (false);\n+                                        cursor = v_4;\n+                                        // (, line 32\n+                                        // literal, line 32\n+                                        if (!(eq_s(1, \"y\")))\n+                                        {\n+                                            break lab3;\n+                                        }\n+                                        // ], line 32\n+                                        ket = cursor;\n+                                        if (!(in_grouping(g_v, 97, 252)))\n+                                        {\n+                                            break lab3;\n+                                        }\n+                                        // <-, line 32\n+                                        slice_from(\"Y\");\n+                                    } while (false);\n+                                    cursor = v_3;\n+                                    break golab2;\n                                 } while (false);\n-                                cursor = v_4;\n-                                // (, line 32\n-                                // literal, line 32\n-                                if (!(eq_s(1, \"y\")))\n-                                {\n-                                    break lab3;\n-                                }\n-                                // ], line 32\n-                                ket = cursor;\n-                                if (!(in_grouping(g_v, 97, 252)))\n+                                cursor = v_3;\n+                                if (cursor >= limit)\n                                 {\n-                                    break lab3;\n+                                    break lab1;\n                                 }\n-                                // <-, line 32\n-                                slice_from(\"Y\");\n-                            } while (false);\n-                            cursor = v_3;\n-                            break golab2;\n+                                cursor++;\n+                            }\n+                            continue replab0;\n                         } while (false);\n-                        cursor = v_3;\n-                        if (cursor >= limit)\n-                        {\n-                            break lab1;\n-                        }\n-                        cursor++;\n+                        cursor = v_2;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_2;\n-                break replab0;\n-            }\n-            cursor = v_1;\n-            // repeat, line 35\n-            replab6: while(true)\n-            {\n-                v_5 = cursor;\n-                lab7: do {\n-                    // (, line 35\n-                    // [, line 36\n-                    bra = cursor;\n-                    // substring, line 36\n-                    among_var = find_among(a_0, 6);\n-                    if (among_var == 0)\n+                    cursor = v_1;\n+                    // repeat, line 35\n+                    replab6: while(true)\n                     {\n-                        break lab7;\n-                    }\n-                    // ], line 36\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab7;\n-                        case 1:\n-                            // (, line 37\n-                            // <-, line 37\n-                            slice_from(\"ss\");\n-                            break;\n-                        case 2:\n-                            // (, line 38\n-                            // <-, line 38\n-                            slice_from(\"\\u00E4\");\n-                            break;\n-                        case 3:\n-                            // (, line 39\n-                            // <-, line 39\n-                            slice_from(\"\\u00F6\");\n-                            break;\n-                        case 4:\n-                            // (, line 40\n-                            // <-, line 40\n-                            slice_from(\"\\u00FC\");\n-                            break;\n-                        case 5:\n-                            // (, line 41\n-                            // hop, line 41\n-                            {\n-                                int c = cursor + 2;\n-                                if (0 > c || c > limit)\n-                                {\n-                                    break lab7;\n-                                }\n-                                cursor = c;\n-                            }\n-                            break;\n-                        case 6:\n-                            // (, line 42\n-                            // next, line 42\n-                            if (cursor >= limit)\n+                        v_5 = cursor;\n+                        lab7: do {\n+                            // (, line 35\n+                            // [, line 36\n+                            bra = cursor;\n+                            // substring, line 36\n+                            among_var = find_among(a_0, 6);\n+                            if (among_var == 0)\n                             {\n                                 break lab7;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 36\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab7;\n+                                case 1:\n+                                    // (, line 37\n+                                    // <-, line 37\n+                                    slice_from(\"ss\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 38\n+                                    // <-, line 38\n+                                    slice_from(\"\\u00E4\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 39\n+                                    // <-, line 39\n+                                    slice_from(\"\\u00F6\");\n+                                    break;\n+                                case 4:\n+                                    // (, line 40\n+                                    // <-, line 40\n+                                    slice_from(\"\\u00FC\");\n+                                    break;\n+                                case 5:\n+                                    // (, line 41\n+                                    // hop, line 41\n+                                    {\n+                                        int c = cursor + 2;\n+                                        if (0 > c || c > limit)\n+                                        {\n+                                            break lab7;\n+                                        }\n+                                        cursor = c;\n+                                    }\n+                                    break;\n+                                case 6:\n+                                    // (, line 42\n+                                    // next, line 42\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab7;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab6;\n+                        } while (false);\n+                        cursor = v_5;\n+                        break replab6;\n                     }\n-                    continue replab6;\n-                } while (false);\n-                cursor = v_5;\n-                break replab6;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n-            // (, line 48\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // test, line 53\n-            v_1 = cursor;\n-            // (, line 53\n-            // hop, line 53\n-            {\n-                int c = cursor + 3;\n-                if (0 > c || c > limit)\n-                {\n-                    return false;\n-                }\n-                cursor = c;\n-            }\n-            // setmark x, line 53\n-            I_x = cursor;\n-            cursor = v_1;\n-            // gopast, line 55\n-            golab0: while(true)\n-            {\n-                lab1: do {\n-                    if (!(in_grouping(g_v, 97, 252)))\n+                    // (, line 48\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // test, line 53\n+                    v_1 = cursor;\n+                    // (, line 53\n+                    // hop, line 53\n                     {\n-                        break lab1;\n+                        int c = cursor + 3;\n+                        if (0 > c || c > limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor = c;\n                     }\n-                    break golab0;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 55\n-            golab2: while(true)\n-            {\n-                lab3: do {\n-                    if (!(out_grouping(g_v, 97, 252)))\n+                    // setmark x, line 53\n+                    I_x = cursor;\n+                    cursor = v_1;\n+                    // gopast, line 55\n+                    golab0: while(true)\n                     {\n-                        break lab3;\n+                        lab1: do {\n+                            if (!(in_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab1;\n+                            }\n+                            break golab0;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab2;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // setmark p1, line 55\n-            I_p1 = cursor;\n-            // try, line 56\n-            lab4: do {\n-                // (, line 56\n-                if (!(I_p1 < I_x))\n-                {\n-                    break lab4;\n-                }\n-                I_p1 = I_x;\n-            } while (false);\n-            // gopast, line 57\n-            golab5: while(true)\n-            {\n-                lab6: do {\n-                    if (!(in_grouping(g_v, 97, 252)))\n+                    // gopast, line 55\n+                    golab2: while(true)\n                     {\n-                        break lab6;\n+                        lab3: do {\n+                            if (!(out_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab3;\n+                            }\n+                            break golab2;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab5;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 57\n-            golab7: while(true)\n-            {\n-                lab8: do {\n-                    if (!(out_grouping(g_v, 97, 252)))\n+                    // setmark p1, line 55\n+                    I_p1 = cursor;\n+                    // try, line 56\n+                    lab4: do {\n+                        // (, line 56\n+                        if (!(I_p1 < I_x))\n+                        {\n+                            break lab4;\n+                        }\n+                        I_p1 = I_x;\n+                    } while (false);\n+                    // gopast, line 57\n+                    golab5: while(true)\n+                    {\n+                        lab6: do {\n+                            if (!(in_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab6;\n+                            }\n+                            break golab5;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n+                    }\n+                    // gopast, line 57\n+                    golab7: while(true)\n                     {\n-                        break lab8;\n+                        lab8: do {\n+                            if (!(out_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab8;\n+                            }\n+                            break golab7;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab7;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n+                    // setmark p2, line 57\n+                    I_p2 = cursor;\n+                    return true;\n                 }\n-                cursor++;\n-            }\n-            // setmark p2, line 57\n-            I_p2 = cursor;\n-            return true;\n-        }\n \n-        private boolean r_postlude() {\n+                private boolean r_postlude() {\n             int among_var;\n             int v_1;\n-            // repeat, line 61\n-            replab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // (, line 61\n-                    // [, line 63\n-                    bra = cursor;\n-                    // substring, line 63\n-                    among_var = find_among(a_1, 6);\n-                    if (among_var == 0)\n+                    // repeat, line 61\n+                    replab0: while(true)\n                     {\n-                        break lab1;\n-                    }\n-                    // ], line 63\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab1;\n-                        case 1:\n-                            // (, line 64\n-                            // <-, line 64\n-                            slice_from(\"y\");\n-                            break;\n-                        case 2:\n-                            // (, line 65\n-                            // <-, line 65\n-                            slice_from(\"u\");\n-                            break;\n-                        case 3:\n-                            // (, line 66\n-                            // <-, line 66\n-                            slice_from(\"a\");\n-                            break;\n-                        case 4:\n-                            // (, line 67\n-                            // <-, line 67\n-                            slice_from(\"o\");\n-                            break;\n-                        case 5:\n-                            // (, line 68\n-                            // <-, line 68\n-                            slice_from(\"u\");\n-                            break;\n-                        case 6:\n-                            // (, line 69\n-                            // next, line 69\n-                            if (cursor >= limit)\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // (, line 61\n+                            // [, line 63\n+                            bra = cursor;\n+                            // substring, line 63\n+                            among_var = find_among(a_1, 6);\n+                            if (among_var == 0)\n                             {\n                                 break lab1;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 63\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 64\n+                                    // <-, line 64\n+                                    slice_from(\"y\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 65\n+                                    // <-, line 65\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 66\n+                                    // <-, line 66\n+                                    slice_from(\"a\");\n+                                    break;\n+                                case 4:\n+                                    // (, line 67\n+                                    // <-, line 67\n+                                    slice_from(\"o\");\n+                                    break;\n+                                case 5:\n+                                    // (, line 68\n+                                    // <-, line 68\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 6:\n+                                    // (, line 69\n+                                    // next, line 69\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_1;\n-                break replab0;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_standard_suffix() {\n+                private boolean r_standard_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n@@ -417,310 +424,320 @@ private boolean r_standard_suffix() {\n             int v_7;\n             int v_8;\n             int v_9;\n-            // (, line 79\n-            // do, line 80\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 80\n-                // [, line 81\n-                ket = cursor;\n-                // substring, line 81\n-                among_var = find_among_b(a_2, 7);\n-                if (among_var == 0)\n-                {\n-                    break lab0;\n-                }\n-                // ], line 81\n-                bra = cursor;\n-                // call R1, line 81\n-                if (!r_R1())\n-                {\n-                    break lab0;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab0;\n-                    case 1:\n-                        // (, line 83\n-                        // delete, line 83\n-                        slice_del();\n-                        break;\n-                    case 2:\n-                        // (, line 86\n-                        if (!(in_grouping_b(g_s_ending, 98, 116)))\n+                    // (, line 79\n+                    // do, line 80\n+                    v_1 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 80\n+                        // [, line 81\n+                        ket = cursor;\n+                        // substring, line 81\n+                        among_var = find_among_b(a_2, 7);\n+                        if (among_var == 0)\n                         {\n                             break lab0;\n                         }\n-                        // delete, line 86\n-                        slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_1;\n-            // do, line 90\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // (, line 90\n-                // [, line 91\n-                ket = cursor;\n-                // substring, line 91\n-                among_var = find_among_b(a_3, 4);\n-                if (among_var == 0)\n-                {\n-                    break lab1;\n-                }\n-                // ], line 91\n-                bra = cursor;\n-                // call R1, line 91\n-                if (!r_R1())\n-                {\n-                    break lab1;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab1;\n-                    case 1:\n-                        // (, line 93\n-                        // delete, line 93\n-                        slice_del();\n-                        break;\n-                    case 2:\n-                        // (, line 96\n-                        if (!(in_grouping_b(g_st_ending, 98, 116)))\n+                        // ], line 81\n+                        bra = cursor;\n+                        // call R1, line 81\n+                        if (!r_R1())\n+                        {\n+                            break lab0;\n+                        }\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab0;\n+                            case 1:\n+                                // (, line 83\n+                                // delete, line 83\n+                                slice_del();\n+                                break;\n+                            case 2:\n+                                // (, line 86\n+                                if (!(in_grouping_b(g_s_ending, 98, 116)))\n+                                {\n+                                    break lab0;\n+                                }\n+                                // delete, line 86\n+                                slice_del();\n+                                break;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_1;\n+                    // do, line 90\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // (, line 90\n+                        // [, line 91\n+                        ket = cursor;\n+                        // substring, line 91\n+                        among_var = find_among_b(a_3, 4);\n+                        if (among_var == 0)\n                         {\n                             break lab1;\n                         }\n-                        // hop, line 96\n+                        // ], line 91\n+                        bra = cursor;\n+                        // call R1, line 91\n+                        if (!r_R1())\n                         {\n-                            int c = cursor - 3;\n-                            if (limit_backward > c || c > limit)\n-                            {\n-                                break lab1;\n-                            }\n-                            cursor = c;\n+                            break lab1;\n                         }\n-                        // delete, line 96\n-                        slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 100\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // (, line 100\n-                // [, line 101\n-                ket = cursor;\n-                // substring, line 101\n-                among_var = find_among_b(a_5, 8);\n-                if (among_var == 0)\n-                {\n-                    break lab2;\n-                }\n-                // ], line 101\n-                bra = cursor;\n-                // call R2, line 101\n-                if (!r_R2())\n-                {\n-                    break lab2;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab2;\n-                    case 1:\n-                        // (, line 103\n-                        // delete, line 103\n-                        slice_del();\n-                        // try, line 104\n-                        v_4 = limit - cursor;\n-                        lab3: do {\n-                            // (, line 104\n-                            // [, line 104\n-                            ket = cursor;\n-                            // literal, line 104\n-                            if (!(eq_s_b(2, \"ig\")))\n-                            {\n-                                cursor = limit - v_4;\n-                                break lab3;\n-                            }\n-                            // ], line 104\n-                            bra = cursor;\n-                            // not, line 104\n-                            {\n-                                v_5 = limit - cursor;\n-                                lab4: do {\n-                                    // literal, line 104\n-                                    if (!(eq_s_b(1, \"e\")))\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab1;\n+                            case 1:\n+                                // (, line 93\n+                                // delete, line 93\n+                                slice_del();\n+                                break;\n+                            case 2:\n+                                // (, line 96\n+                                if (!(in_grouping_b(g_st_ending, 98, 116)))\n+                                {\n+                                    break lab1;\n+                                }\n+                                // hop, line 96\n+                                {\n+                                    int c = cursor - 3;\n+                                    if (limit_backward > c || c > limit)\n                                     {\n-                                        break lab4;\n+                                        break lab1;\n                                     }\n-                                    cursor = limit - v_4;\n-                                    break lab3;\n-                                } while (false);\n-                                cursor = limit - v_5;\n-                            }\n-                            // call R2, line 104\n-                            if (!r_R2())\n-                            {\n-                                cursor = limit - v_4;\n-                                break lab3;\n-                            }\n-                            // delete, line 104\n-                            slice_del();\n-                        } while (false);\n-                        break;\n-                    case 2:\n-                        // (, line 107\n-                        // not, line 107\n-                        {\n-                            v_6 = limit - cursor;\n-                            lab5: do {\n-                                // literal, line 107\n-                                if (!(eq_s_b(1, \"e\")))\n-                                {\n-                                    break lab5;\n+                                    cursor = c;\n                                 }\n-                                break lab2;\n-                            } while (false);\n-                            cursor = limit - v_6;\n+                                // delete, line 96\n+                                slice_del();\n+                                break;\n                         }\n-                        // delete, line 107\n-                        slice_del();\n-                        break;\n-                    case 3:\n-                        // (, line 110\n-                        // delete, line 110\n-                        slice_del();\n-                        // try, line 111\n-                        v_7 = limit - cursor;\n-                        lab6: do {\n-                            // (, line 111\n-                            // [, line 112\n-                            ket = cursor;\n-                            // or, line 112\n-                            lab7: do {\n-                                v_8 = limit - cursor;\n-                                lab8: do {\n-                                    // literal, line 112\n-                                    if (!(eq_s_b(2, \"er\")))\n+                    } while (false);\n+                    cursor = limit - v_2;\n+                    // do, line 100\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // (, line 100\n+                        // [, line 101\n+                        ket = cursor;\n+                        // substring, line 101\n+                        among_var = find_among_b(a_5, 8);\n+                        if (among_var == 0)\n+                        {\n+                            break lab2;\n+                        }\n+                        // ], line 101\n+                        bra = cursor;\n+                        // call R2, line 101\n+                        if (!r_R2())\n+                        {\n+                            break lab2;\n+                        }\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab2;\n+                            case 1:\n+                                // (, line 103\n+                                // delete, line 103\n+                                slice_del();\n+                                // try, line 104\n+                                v_4 = limit - cursor;\n+                                lab3: do {\n+                                    // (, line 104\n+                                    // [, line 104\n+                                    ket = cursor;\n+                                    // literal, line 104\n+                                    if (!(eq_s_b(2, \"ig\")))\n                                     {\n-                                        break lab8;\n+                                        cursor = limit - v_4;\n+                                        break lab3;\n                                     }\n-                                    break lab7;\n+                                    // ], line 104\n+                                    bra = cursor;\n+                                    // not, line 104\n+                                    {\n+                                        v_5 = limit - cursor;\n+                                        lab4: do {\n+                                            // literal, line 104\n+                                            if (!(eq_s_b(1, \"e\")))\n+                                            {\n+                                                break lab4;\n+                                            }\n+                                            cursor = limit - v_4;\n+                                            break lab3;\n+                                        } while (false);\n+                                        cursor = limit - v_5;\n+                                    }\n+                                    // call R2, line 104\n+                                    if (!r_R2())\n+                                    {\n+                                        cursor = limit - v_4;\n+                                        break lab3;\n+                                    }\n+                                    // delete, line 104\n+                                    slice_del();\n                                 } while (false);\n-                                cursor = limit - v_8;\n-                                // literal, line 112\n-                                if (!(eq_s_b(2, \"en\")))\n+                                break;\n+                            case 2:\n+                                // (, line 107\n+                                // not, line 107\n                                 {\n-                                    cursor = limit - v_7;\n-                                    break lab6;\n+                                    v_6 = limit - cursor;\n+                                    lab5: do {\n+                                        // literal, line 107\n+                                        if (!(eq_s_b(1, \"e\")))\n+                                        {\n+                                            break lab5;\n+                                        }\n+                                        break lab2;\n+                                    } while (false);\n+                                    cursor = limit - v_6;\n                                 }\n-                            } while (false);\n-                            // ], line 112\n-                            bra = cursor;\n-                            // call R1, line 112\n-                            if (!r_R1())\n-                            {\n-                                cursor = limit - v_7;\n-                                break lab6;\n-                            }\n-                            // delete, line 112\n-                            slice_del();\n-                        } while (false);\n-                        break;\n-                    case 4:\n-                        // (, line 116\n-                        // delete, line 116\n-                        slice_del();\n-                        // try, line 117\n-                        v_9 = limit - cursor;\n-                        lab9: do {\n-                            // (, line 117\n-                            // [, line 118\n-                            ket = cursor;\n-                            // substring, line 118\n-                            among_var = find_among_b(a_4, 2);\n-                            if (among_var == 0)\n-                            {\n-                                cursor = limit - v_9;\n-                                break lab9;\n-                            }\n-                            // ], line 118\n-                            bra = cursor;\n-                            // call R2, line 118\n-                            if (!r_R2())\n-                            {\n-                                cursor = limit - v_9;\n-                                break lab9;\n-                            }\n-                            switch(among_var) {\n-                                case 0:\n-                                    cursor = limit - v_9;\n-                                    break lab9;\n-                                case 1:\n-                                    // (, line 120\n-                                    // delete, line 120\n+                                // delete, line 107\n+                                slice_del();\n+                                break;\n+                            case 3:\n+                                // (, line 110\n+                                // delete, line 110\n+                                slice_del();\n+                                // try, line 111\n+                                v_7 = limit - cursor;\n+                                lab6: do {\n+                                    // (, line 111\n+                                    // [, line 112\n+                                    ket = cursor;\n+                                    // or, line 112\n+                                    lab7: do {\n+                                        v_8 = limit - cursor;\n+                                        lab8: do {\n+                                            // literal, line 112\n+                                            if (!(eq_s_b(2, \"er\")))\n+                                            {\n+                                                break lab8;\n+                                            }\n+                                            break lab7;\n+                                        } while (false);\n+                                        cursor = limit - v_8;\n+                                        // literal, line 112\n+                                        if (!(eq_s_b(2, \"en\")))\n+                                        {\n+                                            cursor = limit - v_7;\n+                                            break lab6;\n+                                        }\n+                                    } while (false);\n+                                    // ], line 112\n+                                    bra = cursor;\n+                                    // call R1, line 112\n+                                    if (!r_R1())\n+                                    {\n+                                        cursor = limit - v_7;\n+                                        break lab6;\n+                                    }\n+                                    // delete, line 112\n                                     slice_del();\n-                                    break;\n-                            }\n-                        } while (false);\n-                        break;\n+                                } while (false);\n+                                break;\n+                            case 4:\n+                                // (, line 116\n+                                // delete, line 116\n+                                slice_del();\n+                                // try, line 117\n+                                v_9 = limit - cursor;\n+                                lab9: do {\n+                                    // (, line 117\n+                                    // [, line 118\n+                                    ket = cursor;\n+                                    // substring, line 118\n+                                    among_var = find_among_b(a_4, 2);\n+                                    if (among_var == 0)\n+                                    {\n+                                        cursor = limit - v_9;\n+                                        break lab9;\n+                                    }\n+                                    // ], line 118\n+                                    bra = cursor;\n+                                    // call R2, line 118\n+                                    if (!r_R2())\n+                                    {\n+                                        cursor = limit - v_9;\n+                                        break lab9;\n+                                    }\n+                                    switch(among_var) {\n+                                        case 0:\n+                                            cursor = limit - v_9;\n+                                            break lab9;\n+                                        case 1:\n+                                            // (, line 120\n+                                            // delete, line 120\n+                                            slice_del();\n+                                            break;\n+                                    }\n+                                } while (false);\n+                                break;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = limit - v_3;\n-            return true;\n-        }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n-            // (, line 130\n-            // do, line 131\n-            v_1 = cursor;\n-            lab0: do {\n-                // call prelude, line 131\n-                if (!r_prelude())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 132\n-            v_2 = cursor;\n-            lab1: do {\n-                // call mark_regions, line 132\n-                if (!r_mark_regions())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = v_2;\n-            // backwards, line 133\n-            limit_backward = cursor; cursor = limit;\n-            // do, line 134\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call standard_suffix, line 134\n-                if (!r_standard_suffix())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            cursor = limit_backward;            // do, line 135\n-            v_4 = cursor;\n-            lab3: do {\n-                // call postlude, line 135\n-                if (!r_postlude())\n-                {\n-                    break lab3;\n+                    // (, line 130\n+                    // do, line 131\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call prelude, line 131\n+                        if (!r_prelude())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // do, line 132\n+                    v_2 = cursor;\n+                    lab1: do {\n+                        // call mark_regions, line 132\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = v_2;\n+                    // backwards, line 133\n+                    limit_backward = cursor; cursor = limit;\n+                    // do, line 134\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call standard_suffix, line 134\n+                        if (!r_standard_suffix())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    cursor = limit_backward;                    // do, line 135\n+                    v_4 = cursor;\n+                    lab3: do {\n+                        // call postlude, line 135\n+                        if (!r_postlude())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = v_4;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = v_4;\n-            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof German2Stemmer;\n         }\n \n+        public int hashCode() {\n+            return German2Stemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/German2Stemmer.java",
                "sha": "e0501bb6d35fe597d81db81aa407599d5eb4c013",
                "status": "modified"
            },
            {
                "additions": 606,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/GermanStemmer.java",
                "changes": 1195,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/GermanStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 589,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/GermanStemmer.java",
                "patch": "@@ -1,374 +1,381 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class GermanStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"\", -1, 6, \"\", this),\n-            new Among ( \"U\", 0, 2, \"\", this),\n-            new Among ( \"Y\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E4\", 0, 3, \"\", this),\n-            new Among ( \"\\u00F6\", 0, 4, \"\", this),\n-            new Among ( \"\\u00FC\", 0, 5, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"e\", -1, 1, \"\", this),\n-            new Among ( \"em\", -1, 1, \"\", this),\n-            new Among ( \"en\", -1, 1, \"\", this),\n-            new Among ( \"ern\", -1, 1, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"s\", -1, 2, \"\", this),\n-            new Among ( \"es\", 5, 1, \"\", this)\n-        };\n+        private final static GermanStemmer methodObject = new GermanStemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"en\", -1, 1, \"\", this),\n-            new Among ( \"er\", -1, 1, \"\", this),\n-            new Among ( \"st\", -1, 2, \"\", this),\n-            new Among ( \"est\", 2, 1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"U\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"Y\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E4\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00F6\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00FC\", 0, 5, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"ig\", -1, 1, \"\", this),\n-            new Among ( \"lich\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"e\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"em\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"en\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ern\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"s\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"es\", 5, 1, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"end\", -1, 1, \"\", this),\n-            new Among ( \"ig\", -1, 2, \"\", this),\n-            new Among ( \"ung\", -1, 1, \"\", this),\n-            new Among ( \"lich\", -1, 3, \"\", this),\n-            new Among ( \"isch\", -1, 2, \"\", this),\n-            new Among ( \"ik\", -1, 2, \"\", this),\n-            new Among ( \"heit\", -1, 3, \"\", this),\n-            new Among ( \"keit\", -1, 4, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"en\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"st\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"est\", 2, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32, 8 };\n+                private final static Among a_3[] = {\n+                    new Among ( \"ig\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lich\", -1, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_s_ending[] = {117, 30, 5 };\n+                private final static Among a_4[] = {\n+                    new Among ( \"end\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ig\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ung\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"lich\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"isch\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ik\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"heit\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"keit\", -1, 4, \"\", methodObject )\n+                };\n \n-        private static final char g_st_ending[] = {117, 30, 4 };\n+                private static final char g_v[] = {17, 65, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 32, 8 };\n+\n+                private static final char g_s_ending[] = {117, 30, 5 };\n+\n+                private static final char g_st_ending[] = {117, 30, 4 };\n \n         private int I_x;\n         private int I_p2;\n         private int I_p1;\n \n-        private void copy_from(GermanStemmer other) {\n-            I_x = other.I_x;\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(GermanStemmer other) {\n+                    I_x = other.I_x;\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_prelude() {\n+                private boolean r_prelude() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n             int v_6;\n-            // (, line 28\n-            // test, line 30\n-            v_1 = cursor;\n-            // repeat, line 30\n-            replab0: while(true)\n-            {\n-                v_2 = cursor;\n-                lab1: do {\n-                    // (, line 30\n-                    // or, line 33\n-                    lab2: do {\n-                        v_3 = cursor;\n-                        lab3: do {\n-                            // (, line 31\n-                            // [, line 32\n-                            bra = cursor;\n-                            // literal, line 32\n-                            if (!(eq_s(1, \"\\u00DF\")))\n-                            {\n-                                break lab3;\n-                            }\n-                            // ], line 32\n-                            ket = cursor;\n-                            // <-, line 32\n-                            slice_from(\"ss\");\n-                            break lab2;\n-                        } while (false);\n-                        cursor = v_3;\n-                        // next, line 33\n-                        if (cursor >= limit)\n-                        {\n-                            break lab1;\n-                        }\n-                        cursor++;\n-                    } while (false);\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_2;\n-                break replab0;\n-            }\n-            cursor = v_1;\n-            // repeat, line 36\n-            replab4: while(true)\n-            {\n-                v_4 = cursor;\n-                lab5: do {\n-                    // goto, line 36\n-                    golab6: while(true)\n+                    // (, line 28\n+                    // test, line 30\n+                    v_1 = cursor;\n+                    // repeat, line 30\n+                    replab0: while(true)\n                     {\n-                        v_5 = cursor;\n-                        lab7: do {\n-                            // (, line 36\n-                            if (!(in_grouping(g_v, 97, 252)))\n-                            {\n-                                break lab7;\n-                            }\n-                            // [, line 37\n-                            bra = cursor;\n-                            // or, line 37\n-                            lab8: do {\n-                                v_6 = cursor;\n-                                lab9: do {\n-                                    // (, line 37\n-                                    // literal, line 37\n-                                    if (!(eq_s(1, \"u\")))\n+                        v_2 = cursor;\n+                        lab1: do {\n+                            // (, line 30\n+                            // or, line 33\n+                            lab2: do {\n+                                v_3 = cursor;\n+                                lab3: do {\n+                                    // (, line 31\n+                                    // [, line 32\n+                                    bra = cursor;\n+                                    // literal, line 32\n+                                    if (!(eq_s(1, \"\\u00DF\")))\n                                     {\n-                                        break lab9;\n+                                        break lab3;\n                                     }\n-                                    // ], line 37\n+                                    // ], line 32\n                                     ket = cursor;\n+                                    // <-, line 32\n+                                    slice_from(\"ss\");\n+                                    break lab2;\n+                                } while (false);\n+                                cursor = v_3;\n+                                // next, line 33\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab1;\n+                                }\n+                                cursor++;\n+                            } while (false);\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_2;\n+                        break replab0;\n+                    }\n+                    cursor = v_1;\n+                    // repeat, line 36\n+                    replab4: while(true)\n+                    {\n+                        v_4 = cursor;\n+                        lab5: do {\n+                            // goto, line 36\n+                            golab6: while(true)\n+                            {\n+                                v_5 = cursor;\n+                                lab7: do {\n+                                    // (, line 36\n                                     if (!(in_grouping(g_v, 97, 252)))\n                                     {\n-                                        break lab9;\n+                                        break lab7;\n                                     }\n-                                    // <-, line 37\n-                                    slice_from(\"U\");\n-                                    break lab8;\n+                                    // [, line 37\n+                                    bra = cursor;\n+                                    // or, line 37\n+                                    lab8: do {\n+                                        v_6 = cursor;\n+                                        lab9: do {\n+                                            // (, line 37\n+                                            // literal, line 37\n+                                            if (!(eq_s(1, \"u\")))\n+                                            {\n+                                                break lab9;\n+                                            }\n+                                            // ], line 37\n+                                            ket = cursor;\n+                                            if (!(in_grouping(g_v, 97, 252)))\n+                                            {\n+                                                break lab9;\n+                                            }\n+                                            // <-, line 37\n+                                            slice_from(\"U\");\n+                                            break lab8;\n+                                        } while (false);\n+                                        cursor = v_6;\n+                                        // (, line 38\n+                                        // literal, line 38\n+                                        if (!(eq_s(1, \"y\")))\n+                                        {\n+                                            break lab7;\n+                                        }\n+                                        // ], line 38\n+                                        ket = cursor;\n+                                        if (!(in_grouping(g_v, 97, 252)))\n+                                        {\n+                                            break lab7;\n+                                        }\n+                                        // <-, line 38\n+                                        slice_from(\"Y\");\n+                                    } while (false);\n+                                    cursor = v_5;\n+                                    break golab6;\n                                 } while (false);\n-                                cursor = v_6;\n-                                // (, line 38\n-                                // literal, line 38\n-                                if (!(eq_s(1, \"y\")))\n-                                {\n-                                    break lab7;\n-                                }\n-                                // ], line 38\n-                                ket = cursor;\n-                                if (!(in_grouping(g_v, 97, 252)))\n+                                cursor = v_5;\n+                                if (cursor >= limit)\n                                 {\n-                                    break lab7;\n+                                    break lab5;\n                                 }\n-                                // <-, line 38\n-                                slice_from(\"Y\");\n-                            } while (false);\n-                            cursor = v_5;\n-                            break golab6;\n+                                cursor++;\n+                            }\n+                            continue replab4;\n                         } while (false);\n-                        cursor = v_5;\n-                        if (cursor >= limit)\n-                        {\n-                            break lab5;\n-                        }\n-                        cursor++;\n+                        cursor = v_4;\n+                        break replab4;\n                     }\n-                    continue replab4;\n-                } while (false);\n-                cursor = v_4;\n-                break replab4;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n-            // (, line 42\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // test, line 47\n-            v_1 = cursor;\n-            // (, line 47\n-            // hop, line 47\n-            {\n-                int c = cursor + 3;\n-                if (0 > c || c > limit)\n-                {\n-                    return false;\n-                }\n-                cursor = c;\n-            }\n-            // setmark x, line 47\n-            I_x = cursor;\n-            cursor = v_1;\n-            // gopast, line 49\n-            golab0: while(true)\n-            {\n-                lab1: do {\n-                    if (!(in_grouping(g_v, 97, 252)))\n+                    // (, line 42\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // test, line 47\n+                    v_1 = cursor;\n+                    // (, line 47\n+                    // hop, line 47\n                     {\n-                        break lab1;\n+                        int c = cursor + 3;\n+                        if (0 > c || c > limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor = c;\n                     }\n-                    break golab0;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 49\n-            golab2: while(true)\n-            {\n-                lab3: do {\n-                    if (!(out_grouping(g_v, 97, 252)))\n+                    // setmark x, line 47\n+                    I_x = cursor;\n+                    cursor = v_1;\n+                    // gopast, line 49\n+                    golab0: while(true)\n                     {\n-                        break lab3;\n+                        lab1: do {\n+                            if (!(in_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab1;\n+                            }\n+                            break golab0;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab2;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // setmark p1, line 49\n-            I_p1 = cursor;\n-            // try, line 50\n-            lab4: do {\n-                // (, line 50\n-                if (!(I_p1 < I_x))\n-                {\n-                    break lab4;\n-                }\n-                I_p1 = I_x;\n-            } while (false);\n-            // gopast, line 51\n-            golab5: while(true)\n-            {\n-                lab6: do {\n-                    if (!(in_grouping(g_v, 97, 252)))\n+                    // gopast, line 49\n+                    golab2: while(true)\n                     {\n-                        break lab6;\n+                        lab3: do {\n+                            if (!(out_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab3;\n+                            }\n+                            break golab2;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab5;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n-                }\n-                cursor++;\n-            }\n-            // gopast, line 51\n-            golab7: while(true)\n-            {\n-                lab8: do {\n-                    if (!(out_grouping(g_v, 97, 252)))\n+                    // setmark p1, line 49\n+                    I_p1 = cursor;\n+                    // try, line 50\n+                    lab4: do {\n+                        // (, line 50\n+                        if (!(I_p1 < I_x))\n+                        {\n+                            break lab4;\n+                        }\n+                        I_p1 = I_x;\n+                    } while (false);\n+                    // gopast, line 51\n+                    golab5: while(true)\n                     {\n-                        break lab8;\n+                        lab6: do {\n+                            if (!(in_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab6;\n+                            }\n+                            break golab5;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n                     }\n-                    break golab7;\n-                } while (false);\n-                if (cursor >= limit)\n-                {\n-                    return false;\n+                    // gopast, line 51\n+                    golab7: while(true)\n+                    {\n+                        lab8: do {\n+                            if (!(out_grouping(g_v, 97, 252)))\n+                            {\n+                                break lab8;\n+                            }\n+                            break golab7;\n+                        } while (false);\n+                        if (cursor >= limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor++;\n+                    }\n+                    // setmark p2, line 51\n+                    I_p2 = cursor;\n+                    return true;\n                 }\n-                cursor++;\n-            }\n-            // setmark p2, line 51\n-            I_p2 = cursor;\n-            return true;\n-        }\n \n-        private boolean r_postlude() {\n+                private boolean r_postlude() {\n             int among_var;\n             int v_1;\n-            // repeat, line 55\n-            replab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // (, line 55\n-                    // [, line 57\n-                    bra = cursor;\n-                    // substring, line 57\n-                    among_var = find_among(a_0, 6);\n-                    if (among_var == 0)\n+                    // repeat, line 55\n+                    replab0: while(true)\n                     {\n-                        break lab1;\n-                    }\n-                    // ], line 57\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab1;\n-                        case 1:\n-                            // (, line 58\n-                            // <-, line 58\n-                            slice_from(\"y\");\n-                            break;\n-                        case 2:\n-                            // (, line 59\n-                            // <-, line 59\n-                            slice_from(\"u\");\n-                            break;\n-                        case 3:\n-                            // (, line 60\n-                            // <-, line 60\n-                            slice_from(\"a\");\n-                            break;\n-                        case 4:\n-                            // (, line 61\n-                            // <-, line 61\n-                            slice_from(\"o\");\n-                            break;\n-                        case 5:\n-                            // (, line 62\n-                            // <-, line 62\n-                            slice_from(\"u\");\n-                            break;\n-                        case 6:\n-                            // (, line 63\n-                            // next, line 63\n-                            if (cursor >= limit)\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // (, line 55\n+                            // [, line 57\n+                            bra = cursor;\n+                            // substring, line 57\n+                            among_var = find_among(a_0, 6);\n+                            if (among_var == 0)\n                             {\n                                 break lab1;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 57\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 58\n+                                    // <-, line 58\n+                                    slice_from(\"y\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 59\n+                                    // <-, line 59\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 60\n+                                    // <-, line 60\n+                                    slice_from(\"a\");\n+                                    break;\n+                                case 4:\n+                                    // (, line 61\n+                                    // <-, line 61\n+                                    slice_from(\"o\");\n+                                    break;\n+                                case 5:\n+                                    // (, line 62\n+                                    // <-, line 62\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 6:\n+                                    // (, line 63\n+                                    // next, line 63\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_1;\n-                break replab0;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_standard_suffix() {\n+                private boolean r_standard_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n@@ -379,310 +386,320 @@ private boolean r_standard_suffix() {\n             int v_7;\n             int v_8;\n             int v_9;\n-            // (, line 73\n-            // do, line 74\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 74\n-                // [, line 75\n-                ket = cursor;\n-                // substring, line 75\n-                among_var = find_among_b(a_1, 7);\n-                if (among_var == 0)\n-                {\n-                    break lab0;\n-                }\n-                // ], line 75\n-                bra = cursor;\n-                // call R1, line 75\n-                if (!r_R1())\n-                {\n-                    break lab0;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab0;\n-                    case 1:\n-                        // (, line 77\n-                        // delete, line 77\n-                        slice_del();\n-                        break;\n-                    case 2:\n-                        // (, line 80\n-                        if (!(in_grouping_b(g_s_ending, 98, 116)))\n+                    // (, line 73\n+                    // do, line 74\n+                    v_1 = limit - cursor;\n+                    lab0: do {\n+                        // (, line 74\n+                        // [, line 75\n+                        ket = cursor;\n+                        // substring, line 75\n+                        among_var = find_among_b(a_1, 7);\n+                        if (among_var == 0)\n                         {\n                             break lab0;\n                         }\n-                        // delete, line 80\n-                        slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_1;\n-            // do, line 84\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // (, line 84\n-                // [, line 85\n-                ket = cursor;\n-                // substring, line 85\n-                among_var = find_among_b(a_2, 4);\n-                if (among_var == 0)\n-                {\n-                    break lab1;\n-                }\n-                // ], line 85\n-                bra = cursor;\n-                // call R1, line 85\n-                if (!r_R1())\n-                {\n-                    break lab1;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab1;\n-                    case 1:\n-                        // (, line 87\n-                        // delete, line 87\n-                        slice_del();\n-                        break;\n-                    case 2:\n-                        // (, line 90\n-                        if (!(in_grouping_b(g_st_ending, 98, 116)))\n+                        // ], line 75\n+                        bra = cursor;\n+                        // call R1, line 75\n+                        if (!r_R1())\n+                        {\n+                            break lab0;\n+                        }\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab0;\n+                            case 1:\n+                                // (, line 77\n+                                // delete, line 77\n+                                slice_del();\n+                                break;\n+                            case 2:\n+                                // (, line 80\n+                                if (!(in_grouping_b(g_s_ending, 98, 116)))\n+                                {\n+                                    break lab0;\n+                                }\n+                                // delete, line 80\n+                                slice_del();\n+                                break;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_1;\n+                    // do, line 84\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // (, line 84\n+                        // [, line 85\n+                        ket = cursor;\n+                        // substring, line 85\n+                        among_var = find_among_b(a_2, 4);\n+                        if (among_var == 0)\n                         {\n                             break lab1;\n                         }\n-                        // hop, line 90\n+                        // ], line 85\n+                        bra = cursor;\n+                        // call R1, line 85\n+                        if (!r_R1())\n                         {\n-                            int c = cursor - 3;\n-                            if (limit_backward > c || c > limit)\n-                            {\n-                                break lab1;\n-                            }\n-                            cursor = c;\n+                            break lab1;\n                         }\n-                        // delete, line 90\n-                        slice_del();\n-                        break;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 94\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // (, line 94\n-                // [, line 95\n-                ket = cursor;\n-                // substring, line 95\n-                among_var = find_among_b(a_4, 8);\n-                if (among_var == 0)\n-                {\n-                    break lab2;\n-                }\n-                // ], line 95\n-                bra = cursor;\n-                // call R2, line 95\n-                if (!r_R2())\n-                {\n-                    break lab2;\n-                }\n-                switch(among_var) {\n-                    case 0:\n-                        break lab2;\n-                    case 1:\n-                        // (, line 97\n-                        // delete, line 97\n-                        slice_del();\n-                        // try, line 98\n-                        v_4 = limit - cursor;\n-                        lab3: do {\n-                            // (, line 98\n-                            // [, line 98\n-                            ket = cursor;\n-                            // literal, line 98\n-                            if (!(eq_s_b(2, \"ig\")))\n-                            {\n-                                cursor = limit - v_4;\n-                                break lab3;\n-                            }\n-                            // ], line 98\n-                            bra = cursor;\n-                            // not, line 98\n-                            {\n-                                v_5 = limit - cursor;\n-                                lab4: do {\n-                                    // literal, line 98\n-                                    if (!(eq_s_b(1, \"e\")))\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab1;\n+                            case 1:\n+                                // (, line 87\n+                                // delete, line 87\n+                                slice_del();\n+                                break;\n+                            case 2:\n+                                // (, line 90\n+                                if (!(in_grouping_b(g_st_ending, 98, 116)))\n+                                {\n+                                    break lab1;\n+                                }\n+                                // hop, line 90\n+                                {\n+                                    int c = cursor - 3;\n+                                    if (limit_backward > c || c > limit)\n                                     {\n-                                        break lab4;\n+                                        break lab1;\n                                     }\n-                                    cursor = limit - v_4;\n-                                    break lab3;\n-                                } while (false);\n-                                cursor = limit - v_5;\n-                            }\n-                            // call R2, line 98\n-                            if (!r_R2())\n-                            {\n-                                cursor = limit - v_4;\n-                                break lab3;\n-                            }\n-                            // delete, line 98\n-                            slice_del();\n-                        } while (false);\n-                        break;\n-                    case 2:\n-                        // (, line 101\n-                        // not, line 101\n-                        {\n-                            v_6 = limit - cursor;\n-                            lab5: do {\n-                                // literal, line 101\n-                                if (!(eq_s_b(1, \"e\")))\n-                                {\n-                                    break lab5;\n+                                    cursor = c;\n                                 }\n-                                break lab2;\n-                            } while (false);\n-                            cursor = limit - v_6;\n+                                // delete, line 90\n+                                slice_del();\n+                                break;\n                         }\n-                        // delete, line 101\n-                        slice_del();\n-                        break;\n-                    case 3:\n-                        // (, line 104\n-                        // delete, line 104\n-                        slice_del();\n-                        // try, line 105\n-                        v_7 = limit - cursor;\n-                        lab6: do {\n-                            // (, line 105\n-                            // [, line 106\n-                            ket = cursor;\n-                            // or, line 106\n-                            lab7: do {\n-                                v_8 = limit - cursor;\n-                                lab8: do {\n-                                    // literal, line 106\n-                                    if (!(eq_s_b(2, \"er\")))\n+                    } while (false);\n+                    cursor = limit - v_2;\n+                    // do, line 94\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // (, line 94\n+                        // [, line 95\n+                        ket = cursor;\n+                        // substring, line 95\n+                        among_var = find_among_b(a_4, 8);\n+                        if (among_var == 0)\n+                        {\n+                            break lab2;\n+                        }\n+                        // ], line 95\n+                        bra = cursor;\n+                        // call R2, line 95\n+                        if (!r_R2())\n+                        {\n+                            break lab2;\n+                        }\n+                        switch(among_var) {\n+                            case 0:\n+                                break lab2;\n+                            case 1:\n+                                // (, line 97\n+                                // delete, line 97\n+                                slice_del();\n+                                // try, line 98\n+                                v_4 = limit - cursor;\n+                                lab3: do {\n+                                    // (, line 98\n+                                    // [, line 98\n+                                    ket = cursor;\n+                                    // literal, line 98\n+                                    if (!(eq_s_b(2, \"ig\")))\n+                                    {\n+                                        cursor = limit - v_4;\n+                                        break lab3;\n+                                    }\n+                                    // ], line 98\n+                                    bra = cursor;\n+                                    // not, line 98\n+                                    {\n+                                        v_5 = limit - cursor;\n+                                        lab4: do {\n+                                            // literal, line 98\n+                                            if (!(eq_s_b(1, \"e\")))\n+                                            {\n+                                                break lab4;\n+                                            }\n+                                            cursor = limit - v_4;\n+                                            break lab3;\n+                                        } while (false);\n+                                        cursor = limit - v_5;\n+                                    }\n+                                    // call R2, line 98\n+                                    if (!r_R2())\n                                     {\n-                                        break lab8;\n+                                        cursor = limit - v_4;\n+                                        break lab3;\n                                     }\n-                                    break lab7;\n+                                    // delete, line 98\n+                                    slice_del();\n                                 } while (false);\n-                                cursor = limit - v_8;\n-                                // literal, line 106\n-                                if (!(eq_s_b(2, \"en\")))\n+                                break;\n+                            case 2:\n+                                // (, line 101\n+                                // not, line 101\n                                 {\n-                                    cursor = limit - v_7;\n-                                    break lab6;\n+                                    v_6 = limit - cursor;\n+                                    lab5: do {\n+                                        // literal, line 101\n+                                        if (!(eq_s_b(1, \"e\")))\n+                                        {\n+                                            break lab5;\n+                                        }\n+                                        break lab2;\n+                                    } while (false);\n+                                    cursor = limit - v_6;\n                                 }\n-                            } while (false);\n-                            // ], line 106\n-                            bra = cursor;\n-                            // call R1, line 106\n-                            if (!r_R1())\n-                            {\n-                                cursor = limit - v_7;\n-                                break lab6;\n-                            }\n-                            // delete, line 106\n-                            slice_del();\n-                        } while (false);\n-                        break;\n-                    case 4:\n-                        // (, line 110\n-                        // delete, line 110\n-                        slice_del();\n-                        // try, line 111\n-                        v_9 = limit - cursor;\n-                        lab9: do {\n-                            // (, line 111\n-                            // [, line 112\n-                            ket = cursor;\n-                            // substring, line 112\n-                            among_var = find_among_b(a_3, 2);\n-                            if (among_var == 0)\n-                            {\n-                                cursor = limit - v_9;\n-                                break lab9;\n-                            }\n-                            // ], line 112\n-                            bra = cursor;\n-                            // call R2, line 112\n-                            if (!r_R2())\n-                            {\n-                                cursor = limit - v_9;\n-                                break lab9;\n-                            }\n-                            switch(among_var) {\n-                                case 0:\n-                                    cursor = limit - v_9;\n-                                    break lab9;\n-                                case 1:\n-                                    // (, line 114\n-                                    // delete, line 114\n+                                // delete, line 101\n+                                slice_del();\n+                                break;\n+                            case 3:\n+                                // (, line 104\n+                                // delete, line 104\n+                                slice_del();\n+                                // try, line 105\n+                                v_7 = limit - cursor;\n+                                lab6: do {\n+                                    // (, line 105\n+                                    // [, line 106\n+                                    ket = cursor;\n+                                    // or, line 106\n+                                    lab7: do {\n+                                        v_8 = limit - cursor;\n+                                        lab8: do {\n+                                            // literal, line 106\n+                                            if (!(eq_s_b(2, \"er\")))\n+                                            {\n+                                                break lab8;\n+                                            }\n+                                            break lab7;\n+                                        } while (false);\n+                                        cursor = limit - v_8;\n+                                        // literal, line 106\n+                                        if (!(eq_s_b(2, \"en\")))\n+                                        {\n+                                            cursor = limit - v_7;\n+                                            break lab6;\n+                                        }\n+                                    } while (false);\n+                                    // ], line 106\n+                                    bra = cursor;\n+                                    // call R1, line 106\n+                                    if (!r_R1())\n+                                    {\n+                                        cursor = limit - v_7;\n+                                        break lab6;\n+                                    }\n+                                    // delete, line 106\n                                     slice_del();\n-                                    break;\n-                            }\n-                        } while (false);\n-                        break;\n+                                } while (false);\n+                                break;\n+                            case 4:\n+                                // (, line 110\n+                                // delete, line 110\n+                                slice_del();\n+                                // try, line 111\n+                                v_9 = limit - cursor;\n+                                lab9: do {\n+                                    // (, line 111\n+                                    // [, line 112\n+                                    ket = cursor;\n+                                    // substring, line 112\n+                                    among_var = find_among_b(a_3, 2);\n+                                    if (among_var == 0)\n+                                    {\n+                                        cursor = limit - v_9;\n+                                        break lab9;\n+                                    }\n+                                    // ], line 112\n+                                    bra = cursor;\n+                                    // call R2, line 112\n+                                    if (!r_R2())\n+                                    {\n+                                        cursor = limit - v_9;\n+                                        break lab9;\n+                                    }\n+                                    switch(among_var) {\n+                                        case 0:\n+                                            cursor = limit - v_9;\n+                                            break lab9;\n+                                        case 1:\n+                                            // (, line 114\n+                                            // delete, line 114\n+                                            slice_del();\n+                                            break;\n+                                    }\n+                                } while (false);\n+                                break;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = limit - v_3;\n-            return true;\n-        }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n-            // (, line 124\n-            // do, line 125\n-            v_1 = cursor;\n-            lab0: do {\n-                // call prelude, line 125\n-                if (!r_prelude())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 126\n-            v_2 = cursor;\n-            lab1: do {\n-                // call mark_regions, line 126\n-                if (!r_mark_regions())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = v_2;\n-            // backwards, line 127\n-            limit_backward = cursor; cursor = limit;\n-            // do, line 128\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call standard_suffix, line 128\n-                if (!r_standard_suffix())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            cursor = limit_backward;            // do, line 129\n-            v_4 = cursor;\n-            lab3: do {\n-                // call postlude, line 129\n-                if (!r_postlude())\n-                {\n-                    break lab3;\n+                    // (, line 124\n+                    // do, line 125\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call prelude, line 125\n+                        if (!r_prelude())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // do, line 126\n+                    v_2 = cursor;\n+                    lab1: do {\n+                        // call mark_regions, line 126\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = v_2;\n+                    // backwards, line 127\n+                    limit_backward = cursor; cursor = limit;\n+                    // do, line 128\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call standard_suffix, line 128\n+                        if (!r_standard_suffix())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    cursor = limit_backward;                    // do, line 129\n+                    v_4 = cursor;\n+                    lab3: do {\n+                        // call postlude, line 129\n+                        if (!r_postlude())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = v_4;\n+                    return true;\n                 }\n-            } while (false);\n-            cursor = v_4;\n-            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof GermanStemmer;\n         }\n \n+        public int hashCode() {\n+            return GermanStemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/GermanStemmer.java",
                "sha": "85582705fbaed4c50e0818faa5dbe54c17760593",
                "status": "modified"
            },
            {
                "additions": 1084,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/HungarianStemmer.java",
                "changes": 2151,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/HungarianStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1067,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/HungarianStemmer.java",
                "patch": "@@ -1,1042 +1,1049 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class HungarianStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"cs\", -1, -1, \"\", this),\n-            new Among ( \"dzs\", -1, -1, \"\", this),\n-            new Among ( \"gy\", -1, -1, \"\", this),\n-            new Among ( \"ly\", -1, -1, \"\", this),\n-            new Among ( \"ny\", -1, -1, \"\", this),\n-            new Among ( \"sz\", -1, -1, \"\", this),\n-            new Among ( \"ty\", -1, -1, \"\", this),\n-            new Among ( \"zs\", -1, -1, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"\\u00E1\", -1, 1, \"\", this),\n-            new Among ( \"\\u00E9\", -1, 2, \"\", this)\n-        };\n+        private final static HungarianStemmer methodObject = new HungarianStemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"bb\", -1, -1, \"\", this),\n-            new Among ( \"cc\", -1, -1, \"\", this),\n-            new Among ( \"dd\", -1, -1, \"\", this),\n-            new Among ( \"ff\", -1, -1, \"\", this),\n-            new Among ( \"gg\", -1, -1, \"\", this),\n-            new Among ( \"jj\", -1, -1, \"\", this),\n-            new Among ( \"kk\", -1, -1, \"\", this),\n-            new Among ( \"ll\", -1, -1, \"\", this),\n-            new Among ( \"mm\", -1, -1, \"\", this),\n-            new Among ( \"nn\", -1, -1, \"\", this),\n-            new Among ( \"pp\", -1, -1, \"\", this),\n-            new Among ( \"rr\", -1, -1, \"\", this),\n-            new Among ( \"ccs\", -1, -1, \"\", this),\n-            new Among ( \"ss\", -1, -1, \"\", this),\n-            new Among ( \"zzs\", -1, -1, \"\", this),\n-            new Among ( \"tt\", -1, -1, \"\", this),\n-            new Among ( \"vv\", -1, -1, \"\", this),\n-            new Among ( \"ggy\", -1, -1, \"\", this),\n-            new Among ( \"lly\", -1, -1, \"\", this),\n-            new Among ( \"nny\", -1, -1, \"\", this),\n-            new Among ( \"tty\", -1, -1, \"\", this),\n-            new Among ( \"ssz\", -1, -1, \"\", this),\n-            new Among ( \"zz\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"cs\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"dzs\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"gy\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ly\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ny\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"sz\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ty\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"zs\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"al\", -1, 1, \"\", this),\n-            new Among ( \"el\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"\\u00E1\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", -1, 2, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"ba\", -1, -1, \"\", this),\n-            new Among ( \"ra\", -1, -1, \"\", this),\n-            new Among ( \"be\", -1, -1, \"\", this),\n-            new Among ( \"re\", -1, -1, \"\", this),\n-            new Among ( \"ig\", -1, -1, \"\", this),\n-            new Among ( \"nak\", -1, -1, \"\", this),\n-            new Among ( \"nek\", -1, -1, \"\", this),\n-            new Among ( \"val\", -1, -1, \"\", this),\n-            new Among ( \"vel\", -1, -1, \"\", this),\n-            new Among ( \"ul\", -1, -1, \"\", this),\n-            new Among ( \"n\\u00E1l\", -1, -1, \"\", this),\n-            new Among ( \"n\\u00E9l\", -1, -1, \"\", this),\n-            new Among ( \"b\\u00F3l\", -1, -1, \"\", this),\n-            new Among ( \"r\\u00F3l\", -1, -1, \"\", this),\n-            new Among ( \"t\\u00F3l\", -1, -1, \"\", this),\n-            new Among ( \"b\\u00F5l\", -1, -1, \"\", this),\n-            new Among ( \"r\\u00F5l\", -1, -1, \"\", this),\n-            new Among ( \"t\\u00F5l\", -1, -1, \"\", this),\n-            new Among ( \"\\u00FCl\", -1, -1, \"\", this),\n-            new Among ( \"n\", -1, -1, \"\", this),\n-            new Among ( \"an\", 19, -1, \"\", this),\n-            new Among ( \"ban\", 20, -1, \"\", this),\n-            new Among ( \"en\", 19, -1, \"\", this),\n-            new Among ( \"ben\", 22, -1, \"\", this),\n-            new Among ( \"k\\u00E9ppen\", 22, -1, \"\", this),\n-            new Among ( \"on\", 19, -1, \"\", this),\n-            new Among ( \"\\u00F6n\", 19, -1, \"\", this),\n-            new Among ( \"k\\u00E9pp\", -1, -1, \"\", this),\n-            new Among ( \"kor\", -1, -1, \"\", this),\n-            new Among ( \"t\", -1, -1, \"\", this),\n-            new Among ( \"at\", 29, -1, \"\", this),\n-            new Among ( \"et\", 29, -1, \"\", this),\n-            new Among ( \"k\\u00E9nt\", 29, -1, \"\", this),\n-            new Among ( \"ank\\u00E9nt\", 32, -1, \"\", this),\n-            new Among ( \"enk\\u00E9nt\", 32, -1, \"\", this),\n-            new Among ( \"onk\\u00E9nt\", 32, -1, \"\", this),\n-            new Among ( \"ot\", 29, -1, \"\", this),\n-            new Among ( \"\\u00E9rt\", 29, -1, \"\", this),\n-            new Among ( \"\\u00F6t\", 29, -1, \"\", this),\n-            new Among ( \"hez\", -1, -1, \"\", this),\n-            new Among ( \"hoz\", -1, -1, \"\", this),\n-            new Among ( \"h\\u00F6z\", -1, -1, \"\", this),\n-            new Among ( \"v\\u00E1\", -1, -1, \"\", this),\n-            new Among ( \"v\\u00E9\", -1, -1, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"bb\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"cc\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"dd\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ff\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"gg\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"jj\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"kk\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ll\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"mm\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"nn\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"pp\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"rr\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ccs\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ss\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"zzs\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"tt\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"vv\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ggy\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"lly\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"nny\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"tty\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ssz\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"zz\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_5[] = {\n-            new Among ( \"\\u00E1n\", -1, 2, \"\", this),\n-            new Among ( \"\\u00E9n\", -1, 1, \"\", this),\n-            new Among ( \"\\u00E1nk\\u00E9nt\", -1, 3, \"\", this)\n-        };\n+                private final static Among a_3[] = {\n+                    new Among ( \"al\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"el\", -1, 2, \"\", methodObject )\n+                };\n \n-        private Among a_6[] = {\n-            new Among ( \"stul\", -1, 2, \"\", this),\n-            new Among ( \"astul\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E1stul\", 0, 3, \"\", this),\n-            new Among ( \"st\\u00FCl\", -1, 2, \"\", this),\n-            new Among ( \"est\\u00FCl\", 3, 1, \"\", this),\n-            new Among ( \"\\u00E9st\\u00FCl\", 3, 4, \"\", this)\n-        };\n+                private final static Among a_4[] = {\n+                    new Among ( \"ba\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ra\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"be\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"re\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ig\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"nak\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"nek\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"val\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"vel\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ul\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"n\\u00E1l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"n\\u00E9l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"b\\u00F3l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"r\\u00F3l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"t\\u00F3l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"b\\u00F5l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"r\\u00F5l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"t\\u00F5l\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00FCl\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"n\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"an\", 19, -1, \"\", methodObject ),\n+                    new Among ( \"ban\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"en\", 19, -1, \"\", methodObject ),\n+                    new Among ( \"ben\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"k\\u00E9ppen\", 22, -1, \"\", methodObject ),\n+                    new Among ( \"on\", 19, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00F6n\", 19, -1, \"\", methodObject ),\n+                    new Among ( \"k\\u00E9pp\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"kor\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"t\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"at\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"et\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"k\\u00E9nt\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"ank\\u00E9nt\", 32, -1, \"\", methodObject ),\n+                    new Among ( \"enk\\u00E9nt\", 32, -1, \"\", methodObject ),\n+                    new Among ( \"onk\\u00E9nt\", 32, -1, \"\", methodObject ),\n+                    new Among ( \"ot\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9rt\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"\\u00F6t\", 29, -1, \"\", methodObject ),\n+                    new Among ( \"hez\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"hoz\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"h\\u00F6z\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"v\\u00E1\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"v\\u00E9\", -1, -1, \"\", methodObject )\n+                };\n \n-        private Among a_7[] = {\n-            new Among ( \"\\u00E1\", -1, 1, \"\", this),\n-            new Among ( \"\\u00E9\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_5[] = {\n+                    new Among ( \"\\u00E1n\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00E9n\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E1nk\\u00E9nt\", -1, 3, \"\", methodObject )\n+                };\n \n-        private Among a_8[] = {\n-            new Among ( \"k\", -1, 7, \"\", this),\n-            new Among ( \"ak\", 0, 4, \"\", this),\n-            new Among ( \"ek\", 0, 6, \"\", this),\n-            new Among ( \"ok\", 0, 5, \"\", this),\n-            new Among ( \"\\u00E1k\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E9k\", 0, 2, \"\", this),\n-            new Among ( \"\\u00F6k\", 0, 3, \"\", this)\n-        };\n+                private final static Among a_6[] = {\n+                    new Among ( \"stul\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"astul\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E1stul\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"st\\u00FCl\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"est\\u00FCl\", 3, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9st\\u00FCl\", 3, 4, \"\", methodObject )\n+                };\n \n-        private Among a_9[] = {\n-            new Among ( \"\\u00E9i\", -1, 7, \"\", this),\n-            new Among ( \"\\u00E1\\u00E9i\", 0, 6, \"\", this),\n-            new Among ( \"\\u00E9\\u00E9i\", 0, 5, \"\", this),\n-            new Among ( \"\\u00E9\", -1, 9, \"\", this),\n-            new Among ( \"k\\u00E9\", 3, 4, \"\", this),\n-            new Among ( \"ak\\u00E9\", 4, 1, \"\", this),\n-            new Among ( \"ek\\u00E9\", 4, 1, \"\", this),\n-            new Among ( \"ok\\u00E9\", 4, 1, \"\", this),\n-            new Among ( \"\\u00E1k\\u00E9\", 4, 3, \"\", this),\n-            new Among ( \"\\u00E9k\\u00E9\", 4, 2, \"\", this),\n-            new Among ( \"\\u00F6k\\u00E9\", 4, 1, \"\", this),\n-            new Among ( \"\\u00E9\\u00E9\", 3, 8, \"\", this)\n-        };\n+                private final static Among a_7[] = {\n+                    new Among ( \"\\u00E1\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", -1, 2, \"\", methodObject )\n+                };\n \n-        private Among a_10[] = {\n-            new Among ( \"a\", -1, 18, \"\", this),\n-            new Among ( \"ja\", 0, 17, \"\", this),\n-            new Among ( \"d\", -1, 16, \"\", this),\n-            new Among ( \"ad\", 2, 13, \"\", this),\n-            new Among ( \"ed\", 2, 13, \"\", this),\n-            new Among ( \"od\", 2, 13, \"\", this),\n-            new Among ( \"\\u00E1d\", 2, 14, \"\", this),\n-            new Among ( \"\\u00E9d\", 2, 15, \"\", this),\n-            new Among ( \"\\u00F6d\", 2, 13, \"\", this),\n-            new Among ( \"e\", -1, 18, \"\", this),\n-            new Among ( \"je\", 9, 17, \"\", this),\n-            new Among ( \"nk\", -1, 4, \"\", this),\n-            new Among ( \"unk\", 11, 1, \"\", this),\n-            new Among ( \"\\u00E1nk\", 11, 2, \"\", this),\n-            new Among ( \"\\u00E9nk\", 11, 3, \"\", this),\n-            new Among ( \"\\u00FCnk\", 11, 1, \"\", this),\n-            new Among ( \"uk\", -1, 8, \"\", this),\n-            new Among ( \"juk\", 16, 7, \"\", this),\n-            new Among ( \"\\u00E1juk\", 17, 5, \"\", this),\n-            new Among ( \"\\u00FCk\", -1, 8, \"\", this),\n-            new Among ( \"j\\u00FCk\", 19, 7, \"\", this),\n-            new Among ( \"\\u00E9j\\u00FCk\", 20, 6, \"\", this),\n-            new Among ( \"m\", -1, 12, \"\", this),\n-            new Among ( \"am\", 22, 9, \"\", this),\n-            new Among ( \"em\", 22, 9, \"\", this),\n-            new Among ( \"om\", 22, 9, \"\", this),\n-            new Among ( \"\\u00E1m\", 22, 10, \"\", this),\n-            new Among ( \"\\u00E9m\", 22, 11, \"\", this),\n-            new Among ( \"o\", -1, 18, \"\", this),\n-            new Among ( \"\\u00E1\", -1, 19, \"\", this),\n-            new Among ( \"\\u00E9\", -1, 20, \"\", this)\n-        };\n+                private final static Among a_8[] = {\n+                    new Among ( \"k\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"ak\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"ek\", 0, 6, \"\", methodObject ),\n+                    new Among ( \"ok\", 0, 5, \"\", methodObject ),\n+                    new Among ( \"\\u00E1k\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9k\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00F6k\", 0, 3, \"\", methodObject )\n+                };\n \n-        private Among a_11[] = {\n-            new Among ( \"id\", -1, 10, \"\", this),\n-            new Among ( \"aid\", 0, 9, \"\", this),\n-            new Among ( \"jaid\", 1, 6, \"\", this),\n-            new Among ( \"eid\", 0, 9, \"\", this),\n-            new Among ( \"jeid\", 3, 6, \"\", this),\n-            new Among ( \"\\u00E1id\", 0, 7, \"\", this),\n-            new Among ( \"\\u00E9id\", 0, 8, \"\", this),\n-            new Among ( \"i\", -1, 15, \"\", this),\n-            new Among ( \"ai\", 7, 14, \"\", this),\n-            new Among ( \"jai\", 8, 11, \"\", this),\n-            new Among ( \"ei\", 7, 14, \"\", this),\n-            new Among ( \"jei\", 10, 11, \"\", this),\n-            new Among ( \"\\u00E1i\", 7, 12, \"\", this),\n-            new Among ( \"\\u00E9i\", 7, 13, \"\", this),\n-            new Among ( \"itek\", -1, 24, \"\", this),\n-            new Among ( \"eitek\", 14, 21, \"\", this),\n-            new Among ( \"jeitek\", 15, 20, \"\", this),\n-            new Among ( \"\\u00E9itek\", 14, 23, \"\", this),\n-            new Among ( \"ik\", -1, 29, \"\", this),\n-            new Among ( \"aik\", 18, 26, \"\", this),\n-            new Among ( \"jaik\", 19, 25, \"\", this),\n-            new Among ( \"eik\", 18, 26, \"\", this),\n-            new Among ( \"jeik\", 21, 25, \"\", this),\n-            new Among ( \"\\u00E1ik\", 18, 27, \"\", this),\n-            new Among ( \"\\u00E9ik\", 18, 28, \"\", this),\n-            new Among ( \"ink\", -1, 20, \"\", this),\n-            new Among ( \"aink\", 25, 17, \"\", this),\n-            new Among ( \"jaink\", 26, 16, \"\", this),\n-            new Among ( \"eink\", 25, 17, \"\", this),\n-            new Among ( \"jeink\", 28, 16, \"\", this),\n-            new Among ( \"\\u00E1ink\", 25, 18, \"\", this),\n-            new Among ( \"\\u00E9ink\", 25, 19, \"\", this),\n-            new Among ( \"aitok\", -1, 21, \"\", this),\n-            new Among ( \"jaitok\", 32, 20, \"\", this),\n-            new Among ( \"\\u00E1itok\", -1, 22, \"\", this),\n-            new Among ( \"im\", -1, 5, \"\", this),\n-            new Among ( \"aim\", 35, 4, \"\", this),\n-            new Among ( \"jaim\", 36, 1, \"\", this),\n-            new Among ( \"eim\", 35, 4, \"\", this),\n-            new Among ( \"jeim\", 38, 1, \"\", this),\n-            new Among ( \"\\u00E1im\", 35, 2, \"\", this),\n-            new Among ( \"\\u00E9im\", 35, 3, \"\", this)\n-        };\n+                private final static Among a_9[] = {\n+                    new Among ( \"\\u00E9i\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"\\u00E1\\u00E9i\", 0, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\\u00E9i\", 0, 5, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"k\\u00E9\", 3, 4, \"\", methodObject ),\n+                    new Among ( \"ak\\u00E9\", 4, 1, \"\", methodObject ),\n+                    new Among ( \"ek\\u00E9\", 4, 1, \"\", methodObject ),\n+                    new Among ( \"ok\\u00E9\", 4, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E1k\\u00E9\", 4, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00E9k\\u00E9\", 4, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00F6k\\u00E9\", 4, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\\u00E9\", 3, 8, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 17, 52, 14 };\n+                private final static Among a_10[] = {\n+                    new Among ( \"a\", -1, 18, \"\", methodObject ),\n+                    new Among ( \"ja\", 0, 17, \"\", methodObject ),\n+                    new Among ( \"d\", -1, 16, \"\", methodObject ),\n+                    new Among ( \"ad\", 2, 13, \"\", methodObject ),\n+                    new Among ( \"ed\", 2, 13, \"\", methodObject ),\n+                    new Among ( \"od\", 2, 13, \"\", methodObject ),\n+                    new Among ( \"\\u00E1d\", 2, 14, \"\", methodObject ),\n+                    new Among ( \"\\u00E9d\", 2, 15, \"\", methodObject ),\n+                    new Among ( \"\\u00F6d\", 2, 13, \"\", methodObject ),\n+                    new Among ( \"e\", -1, 18, \"\", methodObject ),\n+                    new Among ( \"je\", 9, 17, \"\", methodObject ),\n+                    new Among ( \"nk\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"unk\", 11, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E1nk\", 11, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00E9nk\", 11, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00FCnk\", 11, 1, \"\", methodObject ),\n+                    new Among ( \"uk\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"juk\", 16, 7, \"\", methodObject ),\n+                    new Among ( \"\\u00E1juk\", 17, 5, \"\", methodObject ),\n+                    new Among ( \"\\u00FCk\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"j\\u00FCk\", 19, 7, \"\", methodObject ),\n+                    new Among ( \"\\u00E9j\\u00FCk\", 20, 6, \"\", methodObject ),\n+                    new Among ( \"m\", -1, 12, \"\", methodObject ),\n+                    new Among ( \"am\", 22, 9, \"\", methodObject ),\n+                    new Among ( \"em\", 22, 9, \"\", methodObject ),\n+                    new Among ( \"om\", 22, 9, \"\", methodObject ),\n+                    new Among ( \"\\u00E1m\", 22, 10, \"\", methodObject ),\n+                    new Among ( \"\\u00E9m\", 22, 11, \"\", methodObject ),\n+                    new Among ( \"o\", -1, 18, \"\", methodObject ),\n+                    new Among ( \"\\u00E1\", -1, 19, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", -1, 20, \"\", methodObject )\n+                };\n+\n+                private final static Among a_11[] = {\n+                    new Among ( \"id\", -1, 10, \"\", methodObject ),\n+                    new Among ( \"aid\", 0, 9, \"\", methodObject ),\n+                    new Among ( \"jaid\", 1, 6, \"\", methodObject ),\n+                    new Among ( \"eid\", 0, 9, \"\", methodObject ),\n+                    new Among ( \"jeid\", 3, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E1id\", 0, 7, \"\", methodObject ),\n+                    new Among ( \"\\u00E9id\", 0, 8, \"\", methodObject ),\n+                    new Among ( \"i\", -1, 15, \"\", methodObject ),\n+                    new Among ( \"ai\", 7, 14, \"\", methodObject ),\n+                    new Among ( \"jai\", 8, 11, \"\", methodObject ),\n+                    new Among ( \"ei\", 7, 14, \"\", methodObject ),\n+                    new Among ( \"jei\", 10, 11, \"\", methodObject ),\n+                    new Among ( \"\\u00E1i\", 7, 12, \"\", methodObject ),\n+                    new Among ( \"\\u00E9i\", 7, 13, \"\", methodObject ),\n+                    new Among ( \"itek\", -1, 24, \"\", methodObject ),\n+                    new Among ( \"eitek\", 14, 21, \"\", methodObject ),\n+                    new Among ( \"jeitek\", 15, 20, \"\", methodObject ),\n+                    new Among ( \"\\u00E9itek\", 14, 23, \"\", methodObject ),\n+                    new Among ( \"ik\", -1, 29, \"\", methodObject ),\n+                    new Among ( \"aik\", 18, 26, \"\", methodObject ),\n+                    new Among ( \"jaik\", 19, 25, \"\", methodObject ),\n+                    new Among ( \"eik\", 18, 26, \"\", methodObject ),\n+                    new Among ( \"jeik\", 21, 25, \"\", methodObject ),\n+                    new Among ( \"\\u00E1ik\", 18, 27, \"\", methodObject ),\n+                    new Among ( \"\\u00E9ik\", 18, 28, \"\", methodObject ),\n+                    new Among ( \"ink\", -1, 20, \"\", methodObject ),\n+                    new Among ( \"aink\", 25, 17, \"\", methodObject ),\n+                    new Among ( \"jaink\", 26, 16, \"\", methodObject ),\n+                    new Among ( \"eink\", 25, 17, \"\", methodObject ),\n+                    new Among ( \"jeink\", 28, 16, \"\", methodObject ),\n+                    new Among ( \"\\u00E1ink\", 25, 18, \"\", methodObject ),\n+                    new Among ( \"\\u00E9ink\", 25, 19, \"\", methodObject ),\n+                    new Among ( \"aitok\", -1, 21, \"\", methodObject ),\n+                    new Among ( \"jaitok\", 32, 20, \"\", methodObject ),\n+                    new Among ( \"\\u00E1itok\", -1, 22, \"\", methodObject ),\n+                    new Among ( \"im\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"aim\", 35, 4, \"\", methodObject ),\n+                    new Among ( \"jaim\", 36, 1, \"\", methodObject ),\n+                    new Among ( \"eim\", 35, 4, \"\", methodObject ),\n+                    new Among ( \"jeim\", 38, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E1im\", 35, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00E9im\", 35, 3, \"\", methodObject )\n+                };\n+\n+                private static final char g_v[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 17, 52, 14 };\n \n         private int I_p1;\n \n-        private void copy_from(HungarianStemmer other) {\n-            I_p1 = other.I_p1;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(HungarianStemmer other) {\n+                    I_p1 = other.I_p1;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n             int v_2;\n             int v_3;\n-            // (, line 44\n-            I_p1 = limit;\n-            // or, line 51\n-            lab0: do {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // (, line 48\n-                    if (!(in_grouping(g_v, 97, 252)))\n-                    {\n-                        break lab1;\n-                    }\n-                    // goto, line 48\n-                    golab2: while(true)\n-                    {\n-                        v_2 = cursor;\n-                        lab3: do {\n-                            if (!(out_grouping(g_v, 97, 252)))\n+                    // (, line 44\n+                    I_p1 = limit;\n+                    // or, line 51\n+                    lab0: do {\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // (, line 48\n+                            if (!(in_grouping(g_v, 97, 252)))\n                             {\n-                                break lab3;\n+                                break lab1;\n                             }\n-                            cursor = v_2;\n-                            break golab2;\n-                        } while (false);\n-                        cursor = v_2;\n-                        if (cursor >= limit)\n-                        {\n-                            break lab1;\n-                        }\n-                        cursor++;\n-                    }\n-                    // or, line 49\n-                    lab4: do {\n-                        v_3 = cursor;\n-                        lab5: do {\n-                            // among, line 49\n-                            if (find_among(a_0, 8) == 0)\n+                            // goto, line 48\n+                            golab2: while(true)\n                             {\n-                                break lab5;\n+                                v_2 = cursor;\n+                                lab3: do {\n+                                    if (!(out_grouping(g_v, 97, 252)))\n+                                    {\n+                                        break lab3;\n+                                    }\n+                                    cursor = v_2;\n+                                    break golab2;\n+                                } while (false);\n+                                cursor = v_2;\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab1;\n+                                }\n+                                cursor++;\n                             }\n-                            break lab4;\n+                            // or, line 49\n+                            lab4: do {\n+                                v_3 = cursor;\n+                                lab5: do {\n+                                    // among, line 49\n+                                    if (find_among(a_0, 8) == 0)\n+                                    {\n+                                        break lab5;\n+                                    }\n+                                    break lab4;\n+                                } while (false);\n+                                cursor = v_3;\n+                                // next, line 49\n+                                if (cursor >= limit)\n+                                {\n+                                    break lab1;\n+                                }\n+                                cursor++;\n+                            } while (false);\n+                            // setmark p1, line 50\n+                            I_p1 = cursor;\n+                            break lab0;\n                         } while (false);\n-                        cursor = v_3;\n-                        // next, line 49\n-                        if (cursor >= limit)\n+                        cursor = v_1;\n+                        // (, line 53\n+                        if (!(out_grouping(g_v, 97, 252)))\n                         {\n-                            break lab1;\n+                            return false;\n                         }\n-                        cursor++;\n-                    } while (false);\n-                    // setmark p1, line 50\n-                    I_p1 = cursor;\n-                    break lab0;\n-                } while (false);\n-                cursor = v_1;\n-                // (, line 53\n-                if (!(out_grouping(g_v, 97, 252)))\n-                {\n-                    return false;\n-                }\n-                // gopast, line 53\n-                golab6: while(true)\n-                {\n-                    lab7: do {\n-                        if (!(in_grouping(g_v, 97, 252)))\n+                        // gopast, line 53\n+                        golab6: while(true)\n                         {\n-                            break lab7;\n+                            lab7: do {\n+                                if (!(in_grouping(g_v, 97, 252)))\n+                                {\n+                                    break lab7;\n+                                }\n+                                break golab6;\n+                            } while (false);\n+                            if (cursor >= limit)\n+                            {\n+                                return false;\n+                            }\n+                            cursor++;\n                         }\n-                        break golab6;\n+                        // setmark p1, line 53\n+                        I_p1 = cursor;\n                     } while (false);\n-                    if (cursor >= limit)\n+                    return true;\n+                }\n+\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n                     {\n                         return false;\n                     }\n-                    cursor++;\n+                    return true;\n                 }\n-                // setmark p1, line 53\n-                I_p1 = cursor;\n-            } while (false);\n-            return true;\n-        }\n \n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_v_ending() {\n+                private boolean r_v_ending() {\n             int among_var;\n-            // (, line 60\n-            // [, line 61\n-            ket = cursor;\n-            // substring, line 61\n-            among_var = find_among_b(a_1, 2);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 61\n-            bra = cursor;\n-            // call R1, line 61\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 62\n-                    // <-, line 62\n-                    slice_from(\"a\");\n-                    break;\n-                case 2:\n-                    // (, line 63\n-                    // <-, line 63\n-                    slice_from(\"e\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 60\n+                    // [, line 61\n+                    ket = cursor;\n+                    // substring, line 61\n+                    among_var = find_among_b(a_1, 2);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 61\n+                    bra = cursor;\n+                    // call R1, line 61\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 62\n+                            // <-, line 62\n+                            slice_from(\"a\");\n+                            break;\n+                        case 2:\n+                            // (, line 63\n+                            // <-, line 63\n+                            slice_from(\"e\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_double() {\n+                private boolean r_double() {\n             int v_1;\n-            // (, line 67\n-            // test, line 68\n-            v_1 = limit - cursor;\n-            // among, line 68\n-            if (find_among_b(a_2, 23) == 0)\n-            {\n-                return false;\n-            }\n-            cursor = limit - v_1;\n-            return true;\n-        }\n+                    // (, line 67\n+                    // test, line 68\n+                    v_1 = limit - cursor;\n+                    // among, line 68\n+                    if (find_among_b(a_2, 23) == 0)\n+                    {\n+                        return false;\n+                    }\n+                    cursor = limit - v_1;\n+                    return true;\n+                }\n \n-        private boolean r_undouble() {\n-            // (, line 72\n-            // next, line 73\n-            if (cursor <= limit_backward)\n-            {\n-                return false;\n-            }\n-            cursor--;\n-            // [, line 73\n-            ket = cursor;\n-            // hop, line 73\n-            {\n-                int c = cursor - 1;\n-                if (limit_backward > c || c > limit)\n-                {\n-                    return false;\n+                private boolean r_undouble() {\n+                    // (, line 72\n+                    // next, line 73\n+                    if (cursor <= limit_backward)\n+                    {\n+                        return false;\n+                    }\n+                    cursor--;\n+                    // [, line 73\n+                    ket = cursor;\n+                    // hop, line 73\n+                    {\n+                        int c = cursor - 1;\n+                        if (limit_backward > c || c > limit)\n+                        {\n+                            return false;\n+                        }\n+                        cursor = c;\n+                    }\n+                    // ], line 73\n+                    bra = cursor;\n+                    // delete, line 73\n+                    slice_del();\n+                    return true;\n                 }\n-                cursor = c;\n-            }\n-            // ], line 73\n-            bra = cursor;\n-            // delete, line 73\n-            slice_del();\n-            return true;\n-        }\n \n-        private boolean r_instrum() {\n+                private boolean r_instrum() {\n             int among_var;\n-            // (, line 76\n-            // [, line 77\n-            ket = cursor;\n-            // substring, line 77\n-            among_var = find_among_b(a_3, 2);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 77\n-            bra = cursor;\n-            // call R1, line 77\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 78\n-                    // call double, line 78\n-                    if (!r_double())\n+                    // (, line 76\n+                    // [, line 77\n+                    ket = cursor;\n+                    // substring, line 77\n+                    among_var = find_among_b(a_3, 2);\n+                    if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    break;\n-                case 2:\n-                    // (, line 79\n-                    // call double, line 79\n-                    if (!r_double())\n+                    // ], line 77\n+                    bra = cursor;\n+                    // call R1, line 77\n+                    if (!r_R1())\n                     {\n                         return false;\n                     }\n-                    break;\n-            }\n-            // delete, line 81\n-            slice_del();\n-            // call undouble, line 82\n-            if (!r_undouble())\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 78\n+                            // call double, line 78\n+                            if (!r_double())\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 2:\n+                            // (, line 79\n+                            // call double, line 79\n+                            if (!r_double())\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                    }\n+                    // delete, line 81\n+                    slice_del();\n+                    // call undouble, line 82\n+                    if (!r_undouble())\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_case() {\n-            // (, line 86\n-            // [, line 87\n-            ket = cursor;\n-            // substring, line 87\n-            if (find_among_b(a_4, 44) == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 87\n-            bra = cursor;\n-            // call R1, line 87\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            // delete, line 111\n-            slice_del();\n-            // call v_ending, line 112\n-            if (!r_v_ending())\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                private boolean r_case() {\n+                    // (, line 86\n+                    // [, line 87\n+                    ket = cursor;\n+                    // substring, line 87\n+                    if (find_among_b(a_4, 44) == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 87\n+                    bra = cursor;\n+                    // call R1, line 87\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    // delete, line 111\n+                    slice_del();\n+                    // call v_ending, line 112\n+                    if (!r_v_ending())\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_case_special() {\n+                private boolean r_case_special() {\n             int among_var;\n-            // (, line 115\n-            // [, line 116\n-            ket = cursor;\n-            // substring, line 116\n-            among_var = find_among_b(a_5, 3);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 116\n-            bra = cursor;\n-            // call R1, line 116\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 117\n-                    // <-, line 117\n-                    slice_from(\"e\");\n-                    break;\n-                case 2:\n-                    // (, line 118\n-                    // <-, line 118\n-                    slice_from(\"a\");\n-                    break;\n-                case 3:\n-                    // (, line 119\n-                    // <-, line 119\n-                    slice_from(\"a\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 115\n+                    // [, line 116\n+                    ket = cursor;\n+                    // substring, line 116\n+                    among_var = find_among_b(a_5, 3);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 116\n+                    bra = cursor;\n+                    // call R1, line 116\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 117\n+                            // <-, line 117\n+                            slice_from(\"e\");\n+                            break;\n+                        case 2:\n+                            // (, line 118\n+                            // <-, line 118\n+                            slice_from(\"a\");\n+                            break;\n+                        case 3:\n+                            // (, line 119\n+                            // <-, line 119\n+                            slice_from(\"a\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_case_other() {\n+                private boolean r_case_other() {\n             int among_var;\n-            // (, line 123\n-            // [, line 124\n-            ket = cursor;\n-            // substring, line 124\n-            among_var = find_among_b(a_6, 6);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 124\n-            bra = cursor;\n-            // call R1, line 124\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 125\n-                    // delete, line 125\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 126\n-                    // delete, line 126\n-                    slice_del();\n-                    break;\n-                case 3:\n-                    // (, line 127\n-                    // <-, line 127\n-                    slice_from(\"a\");\n-                    break;\n-                case 4:\n-                    // (, line 128\n-                    // <-, line 128\n-                    slice_from(\"e\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 123\n+                    // [, line 124\n+                    ket = cursor;\n+                    // substring, line 124\n+                    among_var = find_among_b(a_6, 6);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 124\n+                    bra = cursor;\n+                    // call R1, line 124\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 125\n+                            // delete, line 125\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 126\n+                            // delete, line 126\n+                            slice_del();\n+                            break;\n+                        case 3:\n+                            // (, line 127\n+                            // <-, line 127\n+                            slice_from(\"a\");\n+                            break;\n+                        case 4:\n+                            // (, line 128\n+                            // <-, line 128\n+                            slice_from(\"e\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_factive() {\n+                private boolean r_factive() {\n             int among_var;\n-            // (, line 132\n-            // [, line 133\n-            ket = cursor;\n-            // substring, line 133\n-            among_var = find_among_b(a_7, 2);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 133\n-            bra = cursor;\n-            // call R1, line 133\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 134\n-                    // call double, line 134\n-                    if (!r_double())\n+                    // (, line 132\n+                    // [, line 133\n+                    ket = cursor;\n+                    // substring, line 133\n+                    among_var = find_among_b(a_7, 2);\n+                    if (among_var == 0)\n                     {\n                         return false;\n                     }\n-                    break;\n-                case 2:\n-                    // (, line 135\n-                    // call double, line 135\n-                    if (!r_double())\n+                    // ], line 133\n+                    bra = cursor;\n+                    // call R1, line 133\n+                    if (!r_R1())\n                     {\n                         return false;\n                     }\n-                    break;\n-            }\n-            // delete, line 137\n-            slice_del();\n-            // call undouble, line 138\n-            if (!r_undouble())\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 134\n+                            // call double, line 134\n+                            if (!r_double())\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                        case 2:\n+                            // (, line 135\n+                            // call double, line 135\n+                            if (!r_double())\n+                            {\n+                                return false;\n+                            }\n+                            break;\n+                    }\n+                    // delete, line 137\n+                    slice_del();\n+                    // call undouble, line 138\n+                    if (!r_undouble())\n+                    {\n+                        return false;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_plural() {\n+                private boolean r_plural() {\n             int among_var;\n-            // (, line 141\n-            // [, line 142\n-            ket = cursor;\n-            // substring, line 142\n-            among_var = find_among_b(a_8, 7);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 142\n-            bra = cursor;\n-            // call R1, line 142\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 143\n-                    // <-, line 143\n-                    slice_from(\"a\");\n-                    break;\n-                case 2:\n-                    // (, line 144\n-                    // <-, line 144\n-                    slice_from(\"e\");\n-                    break;\n-                case 3:\n-                    // (, line 145\n-                    // delete, line 145\n-                    slice_del();\n-                    break;\n-                case 4:\n-                    // (, line 146\n-                    // delete, line 146\n-                    slice_del();\n-                    break;\n-                case 5:\n-                    // (, line 147\n-                    // delete, line 147\n-                    slice_del();\n-                    break;\n-                case 6:\n-                    // (, line 148\n-                    // delete, line 148\n-                    slice_del();\n-                    break;\n-                case 7:\n-                    // (, line 149\n-                    // delete, line 149\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 141\n+                    // [, line 142\n+                    ket = cursor;\n+                    // substring, line 142\n+                    among_var = find_among_b(a_8, 7);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 142\n+                    bra = cursor;\n+                    // call R1, line 142\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 143\n+                            // <-, line 143\n+                            slice_from(\"a\");\n+                            break;\n+                        case 2:\n+                            // (, line 144\n+                            // <-, line 144\n+                            slice_from(\"e\");\n+                            break;\n+                        case 3:\n+                            // (, line 145\n+                            // delete, line 145\n+                            slice_del();\n+                            break;\n+                        case 4:\n+                            // (, line 146\n+                            // delete, line 146\n+                            slice_del();\n+                            break;\n+                        case 5:\n+                            // (, line 147\n+                            // delete, line 147\n+                            slice_del();\n+                            break;\n+                        case 6:\n+                            // (, line 148\n+                            // delete, line 148\n+                            slice_del();\n+                            break;\n+                        case 7:\n+                            // (, line 149\n+                            // delete, line 149\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_owned() {\n+                private boolean r_owned() {\n             int among_var;\n-            // (, line 153\n-            // [, line 154\n-            ket = cursor;\n-            // substring, line 154\n-            among_var = find_among_b(a_9, 12);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 154\n-            bra = cursor;\n-            // call R1, line 154\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 155\n-                    // delete, line 155\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 156\n-                    // <-, line 156\n-                    slice_from(\"e\");\n-                    break;\n-                case 3:\n-                    // (, line 157\n-                    // <-, line 157\n-                    slice_from(\"a\");\n-                    break;\n-                case 4:\n-                    // (, line 158\n-                    // delete, line 158\n-                    slice_del();\n-                    break;\n-                case 5:\n-                    // (, line 159\n-                    // <-, line 159\n-                    slice_from(\"e\");\n-                    break;\n-                case 6:\n-                    // (, line 160\n-                    // <-, line 160\n-                    slice_from(\"a\");\n-                    break;\n-                case 7:\n-                    // (, line 161\n-                    // delete, line 161\n-                    slice_del();\n-                    break;\n-                case 8:\n-                    // (, line 162\n-                    // <-, line 162\n-                    slice_from(\"e\");\n-                    break;\n-                case 9:\n-                    // (, line 163\n-                    // delete, line 163\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 153\n+                    // [, line 154\n+                    ket = cursor;\n+                    // substring, line 154\n+                    among_var = find_among_b(a_9, 12);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 154\n+                    bra = cursor;\n+                    // call R1, line 154\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 155\n+                            // delete, line 155\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 156\n+                            // <-, line 156\n+                            slice_from(\"e\");\n+                            break;\n+                        case 3:\n+                            // (, line 157\n+                            // <-, line 157\n+                            slice_from(\"a\");\n+                            break;\n+                        case 4:\n+                            // (, line 158\n+                            // delete, line 158\n+                            slice_del();\n+                            break;\n+                        case 5:\n+                            // (, line 159\n+                            // <-, line 159\n+                            slice_from(\"e\");\n+                            break;\n+                        case 6:\n+                            // (, line 160\n+                            // <-, line 160\n+                            slice_from(\"a\");\n+                            break;\n+                        case 7:\n+                            // (, line 161\n+                            // delete, line 161\n+                            slice_del();\n+                            break;\n+                        case 8:\n+                            // (, line 162\n+                            // <-, line 162\n+                            slice_from(\"e\");\n+                            break;\n+                        case 9:\n+                            // (, line 163\n+                            // delete, line 163\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_sing_owner() {\n+                private boolean r_sing_owner() {\n             int among_var;\n-            // (, line 167\n-            // [, line 168\n-            ket = cursor;\n-            // substring, line 168\n-            among_var = find_among_b(a_10, 31);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 168\n-            bra = cursor;\n-            // call R1, line 168\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 169\n-                    // delete, line 169\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 170\n-                    // <-, line 170\n-                    slice_from(\"a\");\n-                    break;\n-                case 3:\n-                    // (, line 171\n-                    // <-, line 171\n-                    slice_from(\"e\");\n-                    break;\n-                case 4:\n-                    // (, line 172\n-                    // delete, line 172\n-                    slice_del();\n-                    break;\n-                case 5:\n-                    // (, line 173\n-                    // <-, line 173\n-                    slice_from(\"a\");\n-                    break;\n-                case 6:\n-                    // (, line 174\n-                    // <-, line 174\n-                    slice_from(\"e\");\n-                    break;\n-                case 7:\n-                    // (, line 175\n-                    // delete, line 175\n-                    slice_del();\n-                    break;\n-                case 8:\n-                    // (, line 176\n-                    // delete, line 176\n-                    slice_del();\n-                    break;\n-                case 9:\n-                    // (, line 177\n-                    // delete, line 177\n-                    slice_del();\n-                    break;\n-                case 10:\n-                    // (, line 178\n-                    // <-, line 178\n-                    slice_from(\"a\");\n-                    break;\n-                case 11:\n-                    // (, line 179\n-                    // <-, line 179\n-                    slice_from(\"e\");\n-                    break;\n-                case 12:\n-                    // (, line 180\n-                    // delete, line 180\n-                    slice_del();\n-                    break;\n-                case 13:\n-                    // (, line 181\n-                    // delete, line 181\n-                    slice_del();\n-                    break;\n-                case 14:\n-                    // (, line 182\n-                    // <-, line 182\n-                    slice_from(\"a\");\n-                    break;\n-                case 15:\n-                    // (, line 183\n-                    // <-, line 183\n-                    slice_from(\"e\");\n-                    break;\n-                case 16:\n-                    // (, line 184\n-                    // delete, line 184\n-                    slice_del();\n-                    break;\n-                case 17:\n-                    // (, line 185\n-                    // delete, line 185\n-                    slice_del();\n-                    break;\n-                case 18:\n-                    // (, line 186\n-                    // delete, line 186\n-                    slice_del();\n-                    break;\n-                case 19:\n-                    // (, line 187\n-                    // <-, line 187\n-                    slice_from(\"a\");\n-                    break;\n-                case 20:\n-                    // (, line 188\n-                    // <-, line 188\n-                    slice_from(\"e\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 167\n+                    // [, line 168\n+                    ket = cursor;\n+                    // substring, line 168\n+                    among_var = find_among_b(a_10, 31);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 168\n+                    bra = cursor;\n+                    // call R1, line 168\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 169\n+                            // delete, line 169\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 170\n+                            // <-, line 170\n+                            slice_from(\"a\");\n+                            break;\n+                        case 3:\n+                            // (, line 171\n+                            // <-, line 171\n+                            slice_from(\"e\");\n+                            break;\n+                        case 4:\n+                            // (, line 172\n+                            // delete, line 172\n+                            slice_del();\n+                            break;\n+                        case 5:\n+                            // (, line 173\n+                            // <-, line 173\n+                            slice_from(\"a\");\n+                            break;\n+                        case 6:\n+                            // (, line 174\n+                            // <-, line 174\n+                            slice_from(\"e\");\n+                            break;\n+                        case 7:\n+                            // (, line 175\n+                            // delete, line 175\n+                            slice_del();\n+                            break;\n+                        case 8:\n+                            // (, line 176\n+                            // delete, line 176\n+                            slice_del();\n+                            break;\n+                        case 9:\n+                            // (, line 177\n+                            // delete, line 177\n+                            slice_del();\n+                            break;\n+                        case 10:\n+                            // (, line 178\n+                            // <-, line 178\n+                            slice_from(\"a\");\n+                            break;\n+                        case 11:\n+                            // (, line 179\n+                            // <-, line 179\n+                            slice_from(\"e\");\n+                            break;\n+                        case 12:\n+                            // (, line 180\n+                            // delete, line 180\n+                            slice_del();\n+                            break;\n+                        case 13:\n+                            // (, line 181\n+                            // delete, line 181\n+                            slice_del();\n+                            break;\n+                        case 14:\n+                            // (, line 182\n+                            // <-, line 182\n+                            slice_from(\"a\");\n+                            break;\n+                        case 15:\n+                            // (, line 183\n+                            // <-, line 183\n+                            slice_from(\"e\");\n+                            break;\n+                        case 16:\n+                            // (, line 184\n+                            // delete, line 184\n+                            slice_del();\n+                            break;\n+                        case 17:\n+                            // (, line 185\n+                            // delete, line 185\n+                            slice_del();\n+                            break;\n+                        case 18:\n+                            // (, line 186\n+                            // delete, line 186\n+                            slice_del();\n+                            break;\n+                        case 19:\n+                            // (, line 187\n+                            // <-, line 187\n+                            slice_from(\"a\");\n+                            break;\n+                        case 20:\n+                            // (, line 188\n+                            // <-, line 188\n+                            slice_from(\"e\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        private boolean r_plur_owner() {\n+                private boolean r_plur_owner() {\n             int among_var;\n-            // (, line 192\n-            // [, line 193\n-            ket = cursor;\n-            // substring, line 193\n-            among_var = find_among_b(a_11, 42);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 193\n-            bra = cursor;\n-            // call R1, line 193\n-            if (!r_R1())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 194\n-                    // delete, line 194\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 195\n-                    // <-, line 195\n-                    slice_from(\"a\");\n-                    break;\n-                case 3:\n-                    // (, line 196\n-                    // <-, line 196\n-                    slice_from(\"e\");\n-                    break;\n-                case 4:\n-                    // (, line 197\n-                    // delete, line 197\n-                    slice_del();\n-                    break;\n-                case 5:\n-                    // (, line 198\n-                    // delete, line 198\n-                    slice_del();\n-                    break;\n-                case 6:\n-                    // (, line 199\n-                    // delete, line 199\n-                    slice_del();\n-                    break;\n-                case 7:\n-                    // (, line 200\n-                    // <-, line 200\n-                    slice_from(\"a\");\n-                    break;\n-                case 8:\n-                    // (, line 201\n-                    // <-, line 201\n-                    slice_from(\"e\");\n-                    break;\n-                case 9:\n-                    // (, line 202\n-                    // delete, line 202\n-                    slice_del();\n-                    break;\n-                case 10:\n-                    // (, line 203\n-                    // delete, line 203\n-                    slice_del();\n-                    break;\n-                case 11:\n-                    // (, line 204\n-                    // delete, line 204\n-                    slice_del();\n-                    break;\n-                case 12:\n-                    // (, line 205\n-                    // <-, line 205\n-                    slice_from(\"a\");\n-                    break;\n-                case 13:\n-                    // (, line 206\n-                    // <-, line 206\n-                    slice_from(\"e\");\n-                    break;\n-                case 14:\n-                    // (, line 207\n-                    // delete, line 207\n-                    slice_del();\n-                    break;\n-                case 15:\n-                    // (, line 208\n-                    // delete, line 208\n-                    slice_del();\n-                    break;\n-                case 16:\n-                    // (, line 209\n-                    // delete, line 209\n-                    slice_del();\n-                    break;\n-                case 17:\n-                    // (, line 210\n-                    // delete, line 210\n-                    slice_del();\n-                    break;\n-                case 18:\n-                    // (, line 211\n-                    // <-, line 211\n-                    slice_from(\"a\");\n-                    break;\n-                case 19:\n-                    // (, line 212\n-                    // <-, line 212\n-                    slice_from(\"e\");\n-                    break;\n-                case 20:\n-                    // (, line 214\n-                    // delete, line 214\n-                    slice_del();\n-                    break;\n-                case 21:\n-                    // (, line 215\n-                    // delete, line 215\n-                    slice_del();\n-                    break;\n-                case 22:\n-                    // (, line 216\n-                    // <-, line 216\n-                    slice_from(\"a\");\n-                    break;\n-                case 23:\n-                    // (, line 217\n-                    // <-, line 217\n-                    slice_from(\"e\");\n-                    break;\n-                case 24:\n-                    // (, line 218\n-                    // delete, line 218\n-                    slice_del();\n-                    break;\n-                case 25:\n-                    // (, line 219\n-                    // delete, line 219\n-                    slice_del();\n-                    break;\n-                case 26:\n-                    // (, line 220\n-                    // delete, line 220\n-                    slice_del();\n-                    break;\n-                case 27:\n-                    // (, line 221\n-                    // <-, line 221\n-                    slice_from(\"a\");\n-                    break;\n-                case 28:\n-                    // (, line 222\n-                    // <-, line 222\n-                    slice_from(\"e\");\n-                    break;\n-                case 29:\n-                    // (, line 223\n-                    // delete, line 223\n-                    slice_del();\n-                    break;\n-            }\n-            return true;\n-        }\n+                    // (, line 192\n+                    // [, line 193\n+                    ket = cursor;\n+                    // substring, line 193\n+                    among_var = find_among_b(a_11, 42);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 193\n+                    bra = cursor;\n+                    // call R1, line 193\n+                    if (!r_R1())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 194\n+                            // delete, line 194\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 195\n+                            // <-, line 195\n+                            slice_from(\"a\");\n+                            break;\n+                        case 3:\n+                            // (, line 196\n+                            // <-, line 196\n+                            slice_from(\"e\");\n+                            break;\n+                        case 4:\n+                            // (, line 197\n+                            // delete, line 197\n+                            slice_del();\n+                            break;\n+                        case 5:\n+                            // (, line 198\n+                            // delete, line 198\n+                            slice_del();\n+                            break;\n+                        case 6:\n+                            // (, line 199\n+                            // delete, line 199\n+                            slice_del();\n+                            break;\n+                        case 7:\n+                            // (, line 200\n+                            // <-, line 200\n+                            slice_from(\"a\");\n+                            break;\n+                        case 8:\n+                            // (, line 201\n+                            // <-, line 201\n+                            slice_from(\"e\");\n+                            break;\n+                        case 9:\n+                            // (, line 202\n+                            // delete, line 202\n+                            slice_del();\n+                            break;\n+                        case 10:\n+                            // (, line 203\n+                            // delete, line 203\n+                            slice_del();\n+                            break;\n+                        case 11:\n+                            // (, line 204\n+                            // delete, line 204\n+                            slice_del();\n+                            break;\n+                        case 12:\n+                            // (, line 205\n+                            // <-, line 205\n+                            slice_from(\"a\");\n+                            break;\n+                        case 13:\n+                            // (, line 206\n+                            // <-, line 206\n+                            slice_from(\"e\");\n+                            break;\n+                        case 14:\n+                            // (, line 207\n+                            // delete, line 207\n+                            slice_del();\n+                            break;\n+                        case 15:\n+                            // (, line 208\n+                            // delete, line 208\n+                            slice_del();\n+                            break;\n+                        case 16:\n+                            // (, line 209\n+                            // delete, line 209\n+                            slice_del();\n+                            break;\n+                        case 17:\n+                            // (, line 210\n+                            // delete, line 210\n+                            slice_del();\n+                            break;\n+                        case 18:\n+                            // (, line 211\n+                            // <-, line 211\n+                            slice_from(\"a\");\n+                            break;\n+                        case 19:\n+                            // (, line 212\n+                            // <-, line 212\n+                            slice_from(\"e\");\n+                            break;\n+                        case 20:\n+                            // (, line 214\n+                            // delete, line 214\n+                            slice_del();\n+                            break;\n+                        case 21:\n+                            // (, line 215\n+                            // delete, line 215\n+                            slice_del();\n+                            break;\n+                        case 22:\n+                            // (, line 216\n+                            // <-, line 216\n+                            slice_from(\"a\");\n+                            break;\n+                        case 23:\n+                            // (, line 217\n+                            // <-, line 217\n+                            slice_from(\"e\");\n+                            break;\n+                        case 24:\n+                            // (, line 218\n+                            // delete, line 218\n+                            slice_del();\n+                            break;\n+                        case 25:\n+                            // (, line 219\n+                            // delete, line 219\n+                            slice_del();\n+                            break;\n+                        case 26:\n+                            // (, line 220\n+                            // delete, line 220\n+                            slice_del();\n+                            break;\n+                        case 27:\n+                            // (, line 221\n+                            // <-, line 221\n+                            slice_from(\"a\");\n+                            break;\n+                        case 28:\n+                            // (, line 222\n+                            // <-, line 222\n+                            slice_from(\"e\");\n+                            break;\n+                        case 29:\n+                            // (, line 223\n+                            // delete, line 223\n+                            slice_del();\n+                            break;\n+                    }\n+                    return true;\n+                }\n \n-        public boolean stem() {\n+                public boolean stem() {\n             int v_1;\n             int v_2;\n             int v_3;\n@@ -1047,112 +1054,122 @@ public boolean stem() {\n             int v_8;\n             int v_9;\n             int v_10;\n-            // (, line 228\n-            // do, line 229\n-            v_1 = cursor;\n-            lab0: do {\n-                // call mark_regions, line 229\n-                if (!r_mark_regions())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // backwards, line 230\n-            limit_backward = cursor; cursor = limit;\n-            // (, line 230\n-            // do, line 231\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // call instrum, line 231\n-                if (!r_instrum())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = limit - v_2;\n-            // do, line 232\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call case, line 232\n-                if (!r_case())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 233\n-            v_4 = limit - cursor;\n-            lab3: do {\n-                // call case_special, line 233\n-                if (!r_case_special())\n-                {\n-                    break lab3;\n-                }\n-            } while (false);\n-            cursor = limit - v_4;\n-            // do, line 234\n-            v_5 = limit - cursor;\n-            lab4: do {\n-                // call case_other, line 234\n-                if (!r_case_other())\n-                {\n-                    break lab4;\n-                }\n-            } while (false);\n-            cursor = limit - v_5;\n-            // do, line 235\n-            v_6 = limit - cursor;\n-            lab5: do {\n-                // call factive, line 235\n-                if (!r_factive())\n-                {\n-                    break lab5;\n-                }\n-            } while (false);\n-            cursor = limit - v_6;\n-            // do, line 236\n-            v_7 = limit - cursor;\n-            lab6: do {\n-                // call owned, line 236\n-                if (!r_owned())\n-                {\n-                    break lab6;\n-                }\n-            } while (false);\n-            cursor = limit - v_7;\n-            // do, line 237\n-            v_8 = limit - cursor;\n-            lab7: do {\n-                // call sing_owner, line 237\n-                if (!r_sing_owner())\n-                {\n-                    break lab7;\n-                }\n-            } while (false);\n-            cursor = limit - v_8;\n-            // do, line 238\n-            v_9 = limit - cursor;\n-            lab8: do {\n-                // call plur_owner, line 238\n-                if (!r_plur_owner())\n-                {\n-                    break lab8;\n-                }\n-            } while (false);\n-            cursor = limit - v_9;\n-            // do, line 239\n-            v_10 = limit - cursor;\n-            lab9: do {\n-                // call plural, line 239\n-                if (!r_plural())\n-                {\n-                    break lab9;\n+                    // (, line 228\n+                    // do, line 229\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call mark_regions, line 229\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab0;\n+                        }\n+                    } while (false);\n+                    cursor = v_1;\n+                    // backwards, line 230\n+                    limit_backward = cursor; cursor = limit;\n+                    // (, line 230\n+                    // do, line 231\n+                    v_2 = limit - cursor;\n+                    lab1: do {\n+                        // call instrum, line 231\n+                        if (!r_instrum())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_2;\n+                    // do, line 232\n+                    v_3 = limit - cursor;\n+                    lab2: do {\n+                        // call case, line 232\n+                        if (!r_case())\n+                        {\n+                            break lab2;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_3;\n+                    // do, line 233\n+                    v_4 = limit - cursor;\n+                    lab3: do {\n+                        // call case_special, line 233\n+                        if (!r_case_special())\n+                        {\n+                            break lab3;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_4;\n+                    // do, line 234\n+                    v_5 = limit - cursor;\n+                    lab4: do {\n+                        // call case_other, line 234\n+                        if (!r_case_other())\n+                        {\n+                            break lab4;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_5;\n+                    // do, line 235\n+                    v_6 = limit - cursor;\n+                    lab5: do {\n+                        // call factive, line 235\n+                        if (!r_factive())\n+                        {\n+                            break lab5;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_6;\n+                    // do, line 236\n+                    v_7 = limit - cursor;\n+                    lab6: do {\n+                        // call owned, line 236\n+                        if (!r_owned())\n+                        {\n+                            break lab6;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_7;\n+                    // do, line 237\n+                    v_8 = limit - cursor;\n+                    lab7: do {\n+                        // call sing_owner, line 237\n+                        if (!r_sing_owner())\n+                        {\n+                            break lab7;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_8;\n+                    // do, line 238\n+                    v_9 = limit - cursor;\n+                    lab8: do {\n+                        // call plur_owner, line 238\n+                        if (!r_plur_owner())\n+                        {\n+                            break lab8;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_9;\n+                    // do, line 239\n+                    v_10 = limit - cursor;\n+                    lab9: do {\n+                        // call plural, line 239\n+                        if (!r_plural())\n+                        {\n+                            break lab9;\n+                        }\n+                    } while (false);\n+                    cursor = limit - v_10;\n+                    cursor = limit_backward;                    return true;\n                 }\n-            } while (false);\n-            cursor = limit - v_10;\n-            cursor = limit_backward;            return true;\n+\n+        public boolean equals( Object o ) {\n+            return o instanceof HungarianStemmer;\n         }\n \n+        public int hashCode() {\n+            return HungarianStemmer.class.getName().hashCode();\n+        }\n+\n+\n+\n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/HungarianStemmer.java",
                "sha": "f730187115b1e6c3af01939cb2893781d2be011e",
                "status": "modified"
            },
            {
                "additions": 1025,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/ItalianStemmer.java",
                "changes": 2033,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/ItalianStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 1008,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/ItalianStemmer.java",
                "patch": "@@ -1,1180 +1,1197 @@\n // This file was generated automatically by the Snowball to Java compiler\n \n package org.tartarus.snowball.ext;\n-import org.tartarus.snowball.SnowballProgram;\n+\n import org.tartarus.snowball.Among;\n+import org.tartarus.snowball.SnowballProgram;\n+\n+ /**\n+  * This class was automatically generated by a Snowball to Java compiler \n+  * It implements the stemming algorithm defined by a snowball script.\n+  */\n \n-/**\n- * Generated class implementing code defined by a snowball script.\n- */\n public class ItalianStemmer extends SnowballProgram {\n \n-        private Among a_0[] = {\n-            new Among ( \"\", -1, 7, \"\", this),\n-            new Among ( \"qu\", 0, 6, \"\", this),\n-            new Among ( \"\\u00E1\", 0, 1, \"\", this),\n-            new Among ( \"\\u00E9\", 0, 2, \"\", this),\n-            new Among ( \"\\u00ED\", 0, 3, \"\", this),\n-            new Among ( \"\\u00F3\", 0, 4, \"\", this),\n-            new Among ( \"\\u00FA\", 0, 5, \"\", this)\n-        };\n+private static final long serialVersionUID = 1L;\n \n-        private Among a_1[] = {\n-            new Among ( \"\", -1, 3, \"\", this),\n-            new Among ( \"I\", 0, 1, \"\", this),\n-            new Among ( \"U\", 0, 2, \"\", this)\n-        };\n+        private final static ItalianStemmer methodObject = new ItalianStemmer ();\n \n-        private Among a_2[] = {\n-            new Among ( \"la\", -1, -1, \"\", this),\n-            new Among ( \"cela\", 0, -1, \"\", this),\n-            new Among ( \"gliela\", 0, -1, \"\", this),\n-            new Among ( \"mela\", 0, -1, \"\", this),\n-            new Among ( \"tela\", 0, -1, \"\", this),\n-            new Among ( \"vela\", 0, -1, \"\", this),\n-            new Among ( \"le\", -1, -1, \"\", this),\n-            new Among ( \"cele\", 6, -1, \"\", this),\n-            new Among ( \"gliele\", 6, -1, \"\", this),\n-            new Among ( \"mele\", 6, -1, \"\", this),\n-            new Among ( \"tele\", 6, -1, \"\", this),\n-            new Among ( \"vele\", 6, -1, \"\", this),\n-            new Among ( \"ne\", -1, -1, \"\", this),\n-            new Among ( \"cene\", 12, -1, \"\", this),\n-            new Among ( \"gliene\", 12, -1, \"\", this),\n-            new Among ( \"mene\", 12, -1, \"\", this),\n-            new Among ( \"sene\", 12, -1, \"\", this),\n-            new Among ( \"tene\", 12, -1, \"\", this),\n-            new Among ( \"vene\", 12, -1, \"\", this),\n-            new Among ( \"ci\", -1, -1, \"\", this),\n-            new Among ( \"li\", -1, -1, \"\", this),\n-            new Among ( \"celi\", 20, -1, \"\", this),\n-            new Among ( \"glieli\", 20, -1, \"\", this),\n-            new Among ( \"meli\", 20, -1, \"\", this),\n-            new Among ( \"teli\", 20, -1, \"\", this),\n-            new Among ( \"veli\", 20, -1, \"\", this),\n-            new Among ( \"gli\", 20, -1, \"\", this),\n-            new Among ( \"mi\", -1, -1, \"\", this),\n-            new Among ( \"si\", -1, -1, \"\", this),\n-            new Among ( \"ti\", -1, -1, \"\", this),\n-            new Among ( \"vi\", -1, -1, \"\", this),\n-            new Among ( \"lo\", -1, -1, \"\", this),\n-            new Among ( \"celo\", 31, -1, \"\", this),\n-            new Among ( \"glielo\", 31, -1, \"\", this),\n-            new Among ( \"melo\", 31, -1, \"\", this),\n-            new Among ( \"telo\", 31, -1, \"\", this),\n-            new Among ( \"velo\", 31, -1, \"\", this)\n-        };\n+                private final static Among a_0[] = {\n+                    new Among ( \"\", -1, 7, \"\", methodObject ),\n+                    new Among ( \"qu\", 0, 6, \"\", methodObject ),\n+                    new Among ( \"\\u00E1\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"\\u00E9\", 0, 2, \"\", methodObject ),\n+                    new Among ( \"\\u00ED\", 0, 3, \"\", methodObject ),\n+                    new Among ( \"\\u00F3\", 0, 4, \"\", methodObject ),\n+                    new Among ( \"\\u00FA\", 0, 5, \"\", methodObject )\n+                };\n \n-        private Among a_3[] = {\n-            new Among ( \"ando\", -1, 1, \"\", this),\n-            new Among ( \"endo\", -1, 1, \"\", this),\n-            new Among ( \"ar\", -1, 2, \"\", this),\n-            new Among ( \"er\", -1, 2, \"\", this),\n-            new Among ( \"ir\", -1, 2, \"\", this)\n-        };\n+                private final static Among a_1[] = {\n+                    new Among ( \"\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"I\", 0, 1, \"\", methodObject ),\n+                    new Among ( \"U\", 0, 2, \"\", methodObject )\n+                };\n \n-        private Among a_4[] = {\n-            new Among ( \"ic\", -1, -1, \"\", this),\n-            new Among ( \"abil\", -1, -1, \"\", this),\n-            new Among ( \"os\", -1, -1, \"\", this),\n-            new Among ( \"iv\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_2[] = {\n+                    new Among ( \"la\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"cela\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"gliela\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"mela\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"tela\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"vela\", 0, -1, \"\", methodObject ),\n+                    new Among ( \"le\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"cele\", 6, -1, \"\", methodObject ),\n+                    new Among ( \"gliele\", 6, -1, \"\", methodObject ),\n+                    new Among ( \"mele\", 6, -1, \"\", methodObject ),\n+                    new Among ( \"tele\", 6, -1, \"\", methodObject ),\n+                    new Among ( \"vele\", 6, -1, \"\", methodObject ),\n+                    new Among ( \"ne\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"cene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"gliene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"mene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"sene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"tene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"vene\", 12, -1, \"\", methodObject ),\n+                    new Among ( \"ci\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"li\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"celi\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"glieli\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"meli\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"teli\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"veli\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"gli\", 20, -1, \"\", methodObject ),\n+                    new Among ( \"mi\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"si\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"ti\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"vi\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"lo\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"celo\", 31, -1, \"\", methodObject ),\n+                    new Among ( \"glielo\", 31, -1, \"\", methodObject ),\n+                    new Among ( \"melo\", 31, -1, \"\", methodObject ),\n+                    new Among ( \"telo\", 31, -1, \"\", methodObject ),\n+                    new Among ( \"velo\", 31, -1, \"\", methodObject )\n+                };\n \n-        private Among a_5[] = {\n-            new Among ( \"ic\", -1, 1, \"\", this),\n-            new Among ( \"abil\", -1, 1, \"\", this),\n-            new Among ( \"iv\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_3[] = {\n+                    new Among ( \"ando\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"endo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ar\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"er\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ir\", -1, 2, \"\", methodObject )\n+                };\n \n-        private Among a_6[] = {\n-            new Among ( \"ica\", -1, 1, \"\", this),\n-            new Among ( \"logia\", -1, 3, \"\", this),\n-            new Among ( \"osa\", -1, 1, \"\", this),\n-            new Among ( \"ista\", -1, 1, \"\", this),\n-            new Among ( \"iva\", -1, 9, \"\", this),\n-            new Among ( \"anza\", -1, 1, \"\", this),\n-            new Among ( \"enza\", -1, 5, \"\", this),\n-            new Among ( \"ice\", -1, 1, \"\", this),\n-            new Among ( \"atrice\", 7, 1, \"\", this),\n-            new Among ( \"iche\", -1, 1, \"\", this),\n-            new Among ( \"logie\", -1, 3, \"\", this),\n-            new Among ( \"abile\", -1, 1, \"\", this),\n-            new Among ( \"ibile\", -1, 1, \"\", this),\n-            new Among ( \"usione\", -1, 4, \"\", this),\n-            new Among ( \"azione\", -1, 2, \"\", this),\n-            new Among ( \"uzione\", -1, 4, \"\", this),\n-            new Among ( \"atore\", -1, 2, \"\", this),\n-            new Among ( \"ose\", -1, 1, \"\", this),\n-            new Among ( \"ante\", -1, 1, \"\", this),\n-            new Among ( \"mente\", -1, 1, \"\", this),\n-            new Among ( \"amente\", 19, 7, \"\", this),\n-            new Among ( \"iste\", -1, 1, \"\", this),\n-            new Among ( \"ive\", -1, 9, \"\", this),\n-            new Among ( \"anze\", -1, 1, \"\", this),\n-            new Among ( \"enze\", -1, 5, \"\", this),\n-            new Among ( \"ici\", -1, 1, \"\", this),\n-            new Among ( \"atrici\", 25, 1, \"\", this),\n-            new Among ( \"ichi\", -1, 1, \"\", this),\n-            new Among ( \"abili\", -1, 1, \"\", this),\n-            new Among ( \"ibili\", -1, 1, \"\", this),\n-            new Among ( \"ismi\", -1, 1, \"\", this),\n-            new Among ( \"usioni\", -1, 4, \"\", this),\n-            new Among ( \"azioni\", -1, 2, \"\", this),\n-            new Among ( \"uzioni\", -1, 4, \"\", this),\n-            new Among ( \"atori\", -1, 2, \"\", this),\n-            new Among ( \"osi\", -1, 1, \"\", this),\n-            new Among ( \"anti\", -1, 1, \"\", this),\n-            new Among ( \"amenti\", -1, 6, \"\", this),\n-            new Among ( \"imenti\", -1, 6, \"\", this),\n-            new Among ( \"isti\", -1, 1, \"\", this),\n-            new Among ( \"ivi\", -1, 9, \"\", this),\n-            new Among ( \"ico\", -1, 1, \"\", this),\n-            new Among ( \"ismo\", -1, 1, \"\", this),\n-            new Among ( \"oso\", -1, 1, \"\", this),\n-            new Among ( \"amento\", -1, 6, \"\", this),\n-            new Among ( \"imento\", -1, 6, \"\", this),\n-            new Among ( \"ivo\", -1, 9, \"\", this),\n-            new Among ( \"it\\u00E0\", -1, 8, \"\", this),\n-            new Among ( \"ist\\u00E0\", -1, 1, \"\", this),\n-            new Among ( \"ist\\u00E8\", -1, 1, \"\", this),\n-            new Among ( \"ist\\u00EC\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_4[] = {\n+                    new Among ( \"ic\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"abil\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"os\", -1, -1, \"\", methodObject ),\n+                    new Among ( \"iv\", -1, 1, \"\", methodObject )\n+                };\n \n-        private Among a_7[] = {\n-            new Among ( \"isca\", -1, 1, \"\", this),\n-            new Among ( \"enda\", -1, 1, \"\", this),\n-            new Among ( \"ata\", -1, 1, \"\", this),\n-            new Among ( \"ita\", -1, 1, \"\", this),\n-            new Among ( \"uta\", -1, 1, \"\", this),\n-            new Among ( \"ava\", -1, 1, \"\", this),\n-            new Among ( \"eva\", -1, 1, \"\", this),\n-            new Among ( \"iva\", -1, 1, \"\", this),\n-            new Among ( \"erebbe\", -1, 1, \"\", this),\n-            new Among ( \"irebbe\", -1, 1, \"\", this),\n-            new Among ( \"isce\", -1, 1, \"\", this),\n-            new Among ( \"ende\", -1, 1, \"\", this),\n-            new Among ( \"are\", -1, 1, \"\", this),\n-            new Among ( \"ere\", -1, 1, \"\", this),\n-            new Among ( \"ire\", -1, 1, \"\", this),\n-            new Among ( \"asse\", -1, 1, \"\", this),\n-            new Among ( \"ate\", -1, 1, \"\", this),\n-            new Among ( \"avate\", 16, 1, \"\", this),\n-            new Among ( \"evate\", 16, 1, \"\", this),\n-            new Among ( \"ivate\", 16, 1, \"\", this),\n-            new Among ( \"ete\", -1, 1, \"\", this),\n-            new Among ( \"erete\", 20, 1, \"\", this),\n-            new Among ( \"irete\", 20, 1, \"\", this),\n-            new Among ( \"ite\", -1, 1, \"\", this),\n-            new Among ( \"ereste\", -1, 1, \"\", this),\n-            new Among ( \"ireste\", -1, 1, \"\", this),\n-            new Among ( \"ute\", -1, 1, \"\", this),\n-            new Among ( \"erai\", -1, 1, \"\", this),\n-            new Among ( \"irai\", -1, 1, \"\", this),\n-            new Among ( \"isci\", -1, 1, \"\", this),\n-            new Among ( \"endi\", -1, 1, \"\", this),\n-            new Among ( \"erei\", -1, 1, \"\", this),\n-            new Among ( \"irei\", -1, 1, \"\", this),\n-            new Among ( \"assi\", -1, 1, \"\", this),\n-            new Among ( \"ati\", -1, 1, \"\", this),\n-            new Among ( \"iti\", -1, 1, \"\", this),\n-            new Among ( \"eresti\", -1, 1, \"\", this),\n-            new Among ( \"iresti\", -1, 1, \"\", this),\n-            new Among ( \"uti\", -1, 1, \"\", this),\n-            new Among ( \"avi\", -1, 1, \"\", this),\n-            new Among ( \"evi\", -1, 1, \"\", this),\n-            new Among ( \"ivi\", -1, 1, \"\", this),\n-            new Among ( \"isco\", -1, 1, \"\", this),\n-            new Among ( \"ando\", -1, 1, \"\", this),\n-            new Among ( \"endo\", -1, 1, \"\", this),\n-            new Among ( \"Yamo\", -1, 1, \"\", this),\n-            new Among ( \"iamo\", -1, 1, \"\", this),\n-            new Among ( \"avamo\", -1, 1, \"\", this),\n-            new Among ( \"evamo\", -1, 1, \"\", this),\n-            new Among ( \"ivamo\", -1, 1, \"\", this),\n-            new Among ( \"eremo\", -1, 1, \"\", this),\n-            new Among ( \"iremo\", -1, 1, \"\", this),\n-            new Among ( \"assimo\", -1, 1, \"\", this),\n-            new Among ( \"ammo\", -1, 1, \"\", this),\n-            new Among ( \"emmo\", -1, 1, \"\", this),\n-            new Among ( \"eremmo\", 54, 1, \"\", this),\n-            new Among ( \"iremmo\", 54, 1, \"\", this),\n-            new Among ( \"immo\", -1, 1, \"\", this),\n-            new Among ( \"ano\", -1, 1, \"\", this),\n-            new Among ( \"iscano\", 58, 1, \"\", this),\n-            new Among ( \"avano\", 58, 1, \"\", this),\n-            new Among ( \"evano\", 58, 1, \"\", this),\n-            new Among ( \"ivano\", 58, 1, \"\", this),\n-            new Among ( \"eranno\", -1, 1, \"\", this),\n-            new Among ( \"iranno\", -1, 1, \"\", this),\n-            new Among ( \"ono\", -1, 1, \"\", this),\n-            new Among ( \"iscono\", 65, 1, \"\", this),\n-            new Among ( \"arono\", 65, 1, \"\", this),\n-            new Among ( \"erono\", 65, 1, \"\", this),\n-            new Among ( \"irono\", 65, 1, \"\", this),\n-            new Among ( \"erebbero\", -1, 1, \"\", this),\n-            new Among ( \"irebbero\", -1, 1, \"\", this),\n-            new Among ( \"assero\", -1, 1, \"\", this),\n-            new Among ( \"essero\", -1, 1, \"\", this),\n-            new Among ( \"issero\", -1, 1, \"\", this),\n-            new Among ( \"ato\", -1, 1, \"\", this),\n-            new Among ( \"ito\", -1, 1, \"\", this),\n-            new Among ( \"uto\", -1, 1, \"\", this),\n-            new Among ( \"avo\", -1, 1, \"\", this),\n-            new Among ( \"evo\", -1, 1, \"\", this),\n-            new Among ( \"ivo\", -1, 1, \"\", this),\n-            new Among ( \"ar\", -1, 1, \"\", this),\n-            new Among ( \"ir\", -1, 1, \"\", this),\n-            new Among ( \"er\\u00E0\", -1, 1, \"\", this),\n-            new Among ( \"ir\\u00E0\", -1, 1, \"\", this),\n-            new Among ( \"er\\u00F2\", -1, 1, \"\", this),\n-            new Among ( \"ir\\u00F2\", -1, 1, \"\", this)\n-        };\n+                private final static Among a_5[] = {\n+                    new Among ( \"ic\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"abil\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iv\", -1, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_v[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 8, 2, 1 };\n+                private final static Among a_6[] = {\n+                    new Among ( \"ica\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"logia\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"osa\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ista\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iva\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"anza\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"enza\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"ice\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"atrice\", 7, 1, \"\", methodObject ),\n+                    new Among ( \"iche\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"logie\", -1, 3, \"\", methodObject ),\n+                    new Among ( \"abile\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ibile\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"usione\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"azione\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"uzione\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"atore\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"ose\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ante\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"mente\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"amente\", 19, 7, \"\", methodObject ),\n+                    new Among ( \"iste\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ive\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"anze\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"enze\", -1, 5, \"\", methodObject ),\n+                    new Among ( \"ici\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"atrici\", 25, 1, \"\", methodObject ),\n+                    new Among ( \"ichi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"abili\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ibili\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ismi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"usioni\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"azioni\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"uzioni\", -1, 4, \"\", methodObject ),\n+                    new Among ( \"atori\", -1, 2, \"\", methodObject ),\n+                    new Among ( \"osi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"anti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"amenti\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"imenti\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"isti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ivi\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"ico\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ismo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"oso\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"amento\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"imento\", -1, 6, \"\", methodObject ),\n+                    new Among ( \"ivo\", -1, 9, \"\", methodObject ),\n+                    new Among ( \"it\\u00E0\", -1, 8, \"\", methodObject ),\n+                    new Among ( \"ist\\u00E0\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ist\\u00E8\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ist\\u00EC\", -1, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_AEIO[] = {17, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 8, 2 };\n+                private final static Among a_7[] = {\n+                    new Among ( \"isca\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"enda\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ata\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ita\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"uta\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ava\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"eva\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iva\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"erebbe\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"irebbe\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"isce\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ende\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"are\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ere\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ire\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"asse\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ate\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"avate\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"evate\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"ivate\", 16, 1, \"\", methodObject ),\n+                    new Among ( \"ete\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"erete\", 20, 1, \"\", methodObject ),\n+                    new Among ( \"irete\", 20, 1, \"\", methodObject ),\n+                    new Among ( \"ite\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ereste\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ireste\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ute\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"erai\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"irai\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"isci\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"endi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"erei\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"irei\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"assi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ati\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"eresti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iresti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"uti\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"avi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"evi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ivi\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"isco\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ando\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"endo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"Yamo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iamo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"avamo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"evamo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ivamo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"eremo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iremo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"assimo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ammo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"emmo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"eremmo\", 54, 1, \"\", methodObject ),\n+                    new Among ( \"iremmo\", 54, 1, \"\", methodObject ),\n+                    new Among ( \"immo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ano\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iscano\", 58, 1, \"\", methodObject ),\n+                    new Among ( \"avano\", 58, 1, \"\", methodObject ),\n+                    new Among ( \"evano\", 58, 1, \"\", methodObject ),\n+                    new Among ( \"ivano\", 58, 1, \"\", methodObject ),\n+                    new Among ( \"eranno\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iranno\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ono\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"iscono\", 65, 1, \"\", methodObject ),\n+                    new Among ( \"arono\", 65, 1, \"\", methodObject ),\n+                    new Among ( \"erono\", 65, 1, \"\", methodObject ),\n+                    new Among ( \"irono\", 65, 1, \"\", methodObject ),\n+                    new Among ( \"erebbero\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"irebbero\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"assero\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"essero\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"issero\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ato\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ito\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"uto\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"avo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"evo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ivo\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ar\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ir\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\\u00E0\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ir\\u00E0\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"er\\u00F2\", -1, 1, \"\", methodObject ),\n+                    new Among ( \"ir\\u00F2\", -1, 1, \"\", methodObject )\n+                };\n \n-        private static final char g_CG[] = {17 };\n+                private static final char g_v[] = {17, 65, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 8, 2, 1 };\n+\n+                private static final char g_AEIO[] = {17, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 128, 8, 2 };\n+\n+                private static final char g_CG[] = {17 };\n \n         private int I_p2;\n         private int I_p1;\n         private int I_pV;\n \n-        private void copy_from(ItalianStemmer other) {\n-            I_p2 = other.I_p2;\n-            I_p1 = other.I_p1;\n-            I_pV = other.I_pV;\n-            super.copy_from(other);\n-        }\n+                private void copy_from(ItalianStemmer other) {\n+                    I_p2 = other.I_p2;\n+                    I_p1 = other.I_p1;\n+                    I_pV = other.I_pV;\n+                    super.copy_from(other);\n+                }\n \n-        private boolean r_prelude() {\n+                private boolean r_prelude() {\n             int among_var;\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_4;\n             int v_5;\n-            // (, line 34\n-            // test, line 35\n-            v_1 = cursor;\n-            // repeat, line 35\n-            replab0: while(true)\n-            {\n-                v_2 = cursor;\n-                lab1: do {\n-                    // (, line 35\n-                    // [, line 36\n-                    bra = cursor;\n-                    // substring, line 36\n-                    among_var = find_among(a_0, 7);\n-                    if (among_var == 0)\n+                    // (, line 34\n+                    // test, line 35\n+                    v_1 = cursor;\n+                    // repeat, line 35\n+                    replab0: while(true)\n                     {\n-                        break lab1;\n-                    }\n-                    // ], line 36\n-                    ket = cursor;\n-                    switch(among_var) {\n-                        case 0:\n-                            break lab1;\n-                        case 1:\n-                            // (, line 37\n-                            // <-, line 37\n-                            slice_from(\"\\u00E0\");\n-                            break;\n-                        case 2:\n-                            // (, line 38\n-                            // <-, line 38\n-                            slice_from(\"\\u00E8\");\n-                            break;\n-                        case 3:\n-                            // (, line 39\n-                            // <-, line 39\n-                            slice_from(\"\\u00EC\");\n-                            break;\n-                        case 4:\n-                            // (, line 40\n-                            // <-, line 40\n-                            slice_from(\"\\u00F2\");\n-                            break;\n-                        case 5:\n-                            // (, line 41\n-                            // <-, line 41\n-                            slice_from(\"\\u00F9\");\n-                            break;\n-                        case 6:\n-                            // (, line 42\n-                            // <-, line 42\n-                            slice_from(\"qU\");\n-                            break;\n-                        case 7:\n-                            // (, line 43\n-                            // next, line 43\n-                            if (cursor >= limit)\n+                        v_2 = cursor;\n+                        lab1: do {\n+                            // (, line 35\n+                            // [, line 36\n+                            bra = cursor;\n+                            // substring, line 36\n+                            among_var = find_among(a_0, 7);\n+                            if (among_var == 0)\n                             {\n                                 break lab1;\n                             }\n-                            cursor++;\n-                            break;\n+                            // ], line 36\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 37\n+                                    // <-, line 37\n+                                    slice_from(\"\\u00E0\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 38\n+                                    // <-, line 38\n+                                    slice_from(\"\\u00E8\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 39\n+                                    // <-, line 39\n+                                    slice_from(\"\\u00EC\");\n+                                    break;\n+                                case 4:\n+                                    // (, line 40\n+                                    // <-, line 40\n+                                    slice_from(\"\\u00F2\");\n+                                    break;\n+                                case 5:\n+                                    // (, line 41\n+                                    // <-, line 41\n+                                    slice_from(\"\\u00F9\");\n+                                    break;\n+                                case 6:\n+                                    // (, line 42\n+                                    // <-, line 42\n+                                    slice_from(\"qU\");\n+                                    break;\n+                                case 7:\n+                                    // (, line 43\n+                                    // next, line 43\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_2;\n+                        break replab0;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_2;\n-                break replab0;\n-            }\n-            cursor = v_1;\n-            // repeat, line 46\n-            replab2: while(true)\n-            {\n-                v_3 = cursor;\n-                lab3: do {\n-                    // goto, line 46\n-                    golab4: while(true)\n+                    cursor = v_1;\n+                    // repeat, line 46\n+                    replab2: while(true)\n                     {\n-                        v_4 = cursor;\n-                        lab5: do {\n-                            // (, line 46\n-                            if (!(in_grouping(g_v, 97, 249)))\n+                        v_3 = cursor;\n+                        lab3: do {\n+                            // goto, line 46\n+                            golab4: while(true)\n                             {\n-                                break lab5;\n-                            }\n-                            // [, line 47\n-                            bra = cursor;\n-                            // or, line 47\n-                            lab6: do {\n-                                v_5 = cursor;\n-                                lab7: do {\n-                                    // (, line 47\n-                                    // literal, line 47\n-                                    if (!(eq_s(1, \"u\")))\n-                                    {\n-                                        break lab7;\n-                                    }\n-                                    // ], line 47\n-                                    ket = cursor;\n+                                v_4 = cursor;\n+                                lab5: do {\n+                                    // (, line 46\n                                     if (!(in_grouping(g_v, 97, 249)))\n                                     {\n-                                        break lab7;\n+                                        break lab5;\n                                     }\n-                                    // <-, line 47\n-                                    slice_from(\"U\");\n-                                    break lab6;\n+                                    // [, line 47\n+                                    bra = cursor;\n+                                    // or, line 47\n+                                    lab6: do {\n+                                        v_5 = cursor;\n+                                        lab7: do {\n+                                            // (, line 47\n+                                            // literal, line 47\n+                                            if (!(eq_s(1, \"u\")))\n+                                            {\n+                                                break lab7;\n+                                            }\n+                                            // ], line 47\n+                                            ket = cursor;\n+                                            if (!(in_grouping(g_v, 97, 249)))\n+                                            {\n+                                                break lab7;\n+                                            }\n+                                            // <-, line 47\n+                                            slice_from(\"U\");\n+                                            break lab6;\n+                                        } while (false);\n+                                        cursor = v_5;\n+                                        // (, line 48\n+                                        // literal, line 48\n+                                        if (!(eq_s(1, \"i\")))\n+                                        {\n+                                            break lab5;\n+                                        }\n+                                        // ], line 48\n+                                        ket = cursor;\n+                                        if (!(in_grouping(g_v, 97, 249)))\n+                                        {\n+                                            break lab5;\n+                                        }\n+                                        // <-, line 48\n+                                        slice_from(\"I\");\n+                                    } while (false);\n+                                    cursor = v_4;\n+                                    break golab4;\n                                 } while (false);\n-                                cursor = v_5;\n-                                // (, line 48\n-                                // literal, line 48\n-                                if (!(eq_s(1, \"i\")))\n-                                {\n-                                    break lab5;\n-                                }\n-                                // ], line 48\n-                                ket = cursor;\n-                                if (!(in_grouping(g_v, 97, 249)))\n+                                cursor = v_4;\n+                                if (cursor >= limit)\n                                 {\n-                                    break lab5;\n+                                    break lab3;\n                                 }\n-                                // <-, line 48\n-                                slice_from(\"I\");\n-                            } while (false);\n-                            cursor = v_4;\n-                            break golab4;\n+                                cursor++;\n+                            }\n+                            continue replab2;\n                         } while (false);\n-                        cursor = v_4;\n-                        if (cursor >= limit)\n-                        {\n-                            break lab3;\n-                        }\n-                        cursor++;\n+                        cursor = v_3;\n+                        break replab2;\n                     }\n-                    continue replab2;\n-                } while (false);\n-                cursor = v_3;\n-                break replab2;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_mark_regions() {\n+                private boolean r_mark_regions() {\n             int v_1;\n             int v_2;\n             int v_3;\n             int v_6;\n             int v_8;\n-            // (, line 52\n-            I_pV = limit;\n-            I_p1 = limit;\n-            I_p2 = limit;\n-            // do, line 58\n-            v_1 = cursor;\n-            lab0: do {\n-                // (, line 58\n-                // or, line 60\n-                lab1: do {\n-                    v_2 = cursor;\n-                    lab2: do {\n-                        // (, line 59\n-                        if (!(in_grouping(g_v, 97, 249)))\n-                        {\n-                            break lab2;\n-                        }\n-                        // or, line 59\n-                        lab3: do {\n-                            v_3 = cursor;\n-                            lab4: do {\n+                    // (, line 52\n+                    I_pV = limit;\n+                    I_p1 = limit;\n+                    I_p2 = limit;\n+                    // do, line 58\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // (, line 58\n+                        // or, line 60\n+                        lab1: do {\n+                            v_2 = cursor;\n+                            lab2: do {\n                                 // (, line 59\n-                                if (!(out_grouping(g_v, 97, 249)))\n+                                if (!(in_grouping(g_v, 97, 249)))\n                                 {\n-                                    break lab4;\n+                                    break lab2;\n                                 }\n-                                // gopast, line 59\n-                                golab5: while(true)\n-                                {\n-                                    lab6: do {\n-                                        if (!(in_grouping(g_v, 97, 249)))\n+                                // or, line 59\n+                                lab3: do {\n+                                    v_3 = cursor;\n+                                    lab4: do {\n+                                        // (, line 59\n+                                        if (!(out_grouping(g_v, 97, 249)))\n                                         {\n-                                            break lab6;\n+                                            break lab4;\n+                                        }\n+                                        // gopast, line 59\n+                                        golab5: while(true)\n+                                        {\n+                                            lab6: do {\n+                                                if (!(in_grouping(g_v, 97, 249)))\n+                                                {\n+                                                    break lab6;\n+                                                }\n+                                                break golab5;\n+                                            } while (false);\n+                                            if (cursor >= limit)\n+                                            {\n+                                                break lab4;\n+                                            }\n+                                            cursor++;\n                                         }\n-                                        break golab5;\n+                                        break lab3;\n                                     } while (false);\n-                                    if (cursor >= limit)\n+                                    cursor = v_3;\n+                                    // (, line 59\n+                                    if (!(in_grouping(g_v, 97, 249)))\n                                     {\n-                                        break lab4;\n+                                        break lab2;\n                                     }\n-                                    cursor++;\n-                                }\n-                                break lab3;\n+                                    // gopast, line 59\n+                                    golab7: while(true)\n+                                    {\n+                                        lab8: do {\n+                                            if (!(out_grouping(g_v, 97, 249)))\n+                                            {\n+                                                break lab8;\n+                                            }\n+                                            break golab7;\n+                                        } while (false);\n+                                        if (cursor >= limit)\n+                                        {\n+                                            break lab2;\n+                                        }\n+                                        cursor++;\n+                                    }\n+                                } while (false);\n+                                break lab1;\n                             } while (false);\n-                            cursor = v_3;\n-                            // (, line 59\n-                            if (!(in_grouping(g_v, 97, 249)))\n+                            cursor = v_2;\n+                            // (, line 61\n+                            if (!(out_grouping(g_v, 97, 249)))\n                             {\n-                                break lab2;\n+                                break lab0;\n                             }\n-                            // gopast, line 59\n-                            golab7: while(true)\n-                            {\n-                                lab8: do {\n+                            // or, line 61\n+                            lab9: do {\n+                                v_6 = cursor;\n+                                lab10: do {\n+                                    // (, line 61\n                                     if (!(out_grouping(g_v, 97, 249)))\n                                     {\n-                                        break lab8;\n+                                        break lab10;\n                                     }\n-                                    break golab7;\n+                                    // gopast, line 61\n+                                    golab11: while(true)\n+                                    {\n+                                        lab12: do {\n+                                            if (!(in_grouping(g_v, 97, 249)))\n+                                            {\n+                                                break lab12;\n+                                            }\n+                                            break golab11;\n+                                        } while (false);\n+                                        if (cursor >= limit)\n+                                        {\n+                                            break lab10;\n+                                        }\n+                                        cursor++;\n+                                    }\n+                                    break lab9;\n                                 } while (false);\n+                                cursor = v_6;\n+                                // (, line 61\n+                                if (!(in_grouping(g_v, 97, 249)))\n+                                {\n+                                    break lab0;\n+                                }\n+                                // next, line 61\n                                 if (cursor >= limit)\n                                 {\n-                                    break lab2;\n+                                    break lab0;\n                                 }\n                                 cursor++;\n-                            }\n+                            } while (false);\n                         } while (false);\n-                        break lab1;\n+                        // setmark pV, line 62\n+                        I_pV = cursor;\n                     } while (false);\n-                    cursor = v_2;\n-                    // (, line 61\n-                    if (!(out_grouping(g_v, 97, 249)))\n-                    {\n-                        break lab0;\n-                    }\n-                    // or, line 61\n-                    lab9: do {\n-                        v_6 = cursor;\n-                        lab10: do {\n-                            // (, line 61\n-                            if (!(out_grouping(g_v, 97, 249)))\n+                    cursor = v_1;\n+                    // do, line 64\n+                    v_8 = cursor;\n+                    lab13: do {\n+                        // (, line 64\n+                        // gopast, line 65\n+                        golab14: while(true)\n+                        {\n+                            lab15: do {\n+                                if (!(in_grouping(g_v, 97, 249)))\n+                                {\n+                                    break lab15;\n+                                }\n+                                break golab14;\n+                            } while (false);\n+                            if (cursor >= limit)\n                             {\n-                                break lab10;\n+                                break lab13;\n                             }\n-                            // gopast, line 61\n-                            golab11: while(true)\n-                            {\n-                                lab12: do {\n-                                    if (!(in_grouping(g_v, 97, 249)))\n-                                    {\n-                                        break lab12;\n-                                    }\n-                                    break golab11;\n-                                } while (false);\n-                                if (cursor >= limit)\n+                            cursor++;\n+                        }\n+                        // gopast, line 65\n+                        golab16: while(true)\n+                        {\n+                            lab17: do {\n+                                if (!(out_grouping(g_v, 97, 249)))\n                                 {\n-                                    break lab10;\n+                                    break lab17;\n                                 }\n-                                cursor++;\n+                                break golab16;\n+                            } while (false);\n+                            if (cursor >= limit)\n+                            {\n+                                break lab13;\n                             }\n-                            break lab9;\n-                        } while (false);\n-                        cursor = v_6;\n-                        // (, line 61\n-                        if (!(in_grouping(g_v, 97, 249)))\n-                        {\n-                            break lab0;\n+                            cursor++;\n                         }\n-                        // next, line 61\n-                        if (cursor >= limit)\n+                        // setmark p1, line 65\n+                        I_p1 = cursor;\n+                        // gopast, line 66\n+                        golab18: while(true)\n                         {\n-                            break lab0;\n+                            lab19: do {\n+                                if (!(in_grouping(g_v, 97, 249)))\n+                                {\n+                                    break lab19;\n+                                }\n+                                break golab18;\n+                            } while (false);\n+                            if (cursor >= limit)\n+                            {\n+                                break lab13;\n+                            }\n+                            cursor++;\n                         }\n-                        cursor++;\n-                    } while (false);\n-                } while (false);\n-                // setmark pV, line 62\n-                I_pV = cursor;\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 64\n-            v_8 = cursor;\n-            lab13: do {\n-                // (, line 64\n-                // gopast, line 65\n-                golab14: while(true)\n-                {\n-                    lab15: do {\n-                        if (!(in_grouping(g_v, 97, 249)))\n+                        // gopast, line 66\n+                        golab20: while(true)\n                         {\n-                            break lab15;\n+                            lab21: do {\n+                                if (!(out_grouping(g_v, 97, 249)))\n+                                {\n+                                    break lab21;\n+                                }\n+                                break golab20;\n+                            } while (false);\n+                            if (cursor >= limit)\n+                            {\n+                                break lab13;\n+                            }\n+                            cursor++;\n                         }\n-                        break golab14;\n+                        // setmark p2, line 66\n+                        I_p2 = cursor;\n                     } while (false);\n-                    if (cursor >= limit)\n+                    cursor = v_8;\n+                    return true;\n+                }\n+\n+                private boolean r_postlude() {\n+            int among_var;\n+            int v_1;\n+                    // repeat, line 70\n+                    replab0: while(true)\n                     {\n-                        break lab13;\n+                        v_1 = cursor;\n+                        lab1: do {\n+                            // (, line 70\n+                            // [, line 72\n+                            bra = cursor;\n+                            // substring, line 72\n+                            among_var = find_among(a_1, 3);\n+                            if (among_var == 0)\n+                            {\n+                                break lab1;\n+                            }\n+                            // ], line 72\n+                            ket = cursor;\n+                            switch(among_var) {\n+                                case 0:\n+                                    break lab1;\n+                                case 1:\n+                                    // (, line 73\n+                                    // <-, line 73\n+                                    slice_from(\"i\");\n+                                    break;\n+                                case 2:\n+                                    // (, line 74\n+                                    // <-, line 74\n+                                    slice_from(\"u\");\n+                                    break;\n+                                case 3:\n+                                    // (, line 75\n+                                    // next, line 75\n+                                    if (cursor >= limit)\n+                                    {\n+                                        break lab1;\n+                                    }\n+                                    cursor++;\n+                                    break;\n+                            }\n+                            continue replab0;\n+                        } while (false);\n+                        cursor = v_1;\n+                        break replab0;\n                     }\n-                    cursor++;\n+                    return true;\n                 }\n-                // gopast, line 65\n-                golab16: while(true)\n-                {\n-                    lab17: do {\n-                        if (!(out_grouping(g_v, 97, 249)))\n-                        {\n-                            break lab17;\n-                        }\n-                        break golab16;\n-                    } while (false);\n-                    if (cursor >= limit)\n+\n+                private boolean r_RV() {\n+                    if (!(I_pV <= cursor))\n                     {\n-                        break lab13;\n+                        return false;\n                     }\n-                    cursor++;\n+                    return true;\n                 }\n-                // setmark p1, line 65\n-                I_p1 = cursor;\n-                // gopast, line 66\n-                golab18: while(true)\n-                {\n-                    lab19: do {\n-                        if (!(in_grouping(g_v, 97, 249)))\n-                        {\n-                            break lab19;\n-                        }\n-                        break golab18;\n-                    } while (false);\n-                    if (cursor >= limit)\n+\n+                private boolean r_R1() {\n+                    if (!(I_p1 <= cursor))\n                     {\n-                        break lab13;\n+                        return false;\n                     }\n-                    cursor++;\n+                    return true;\n                 }\n-                // gopast, line 66\n-                golab20: while(true)\n-                {\n-                    lab21: do {\n-                        if (!(out_grouping(g_v, 97, 249)))\n-                        {\n-                            break lab21;\n-                        }\n-                        break golab20;\n-                    } while (false);\n-                    if (cursor >= limit)\n+\n+                private boolean r_R2() {\n+                    if (!(I_p2 <= cursor))\n                     {\n-                        break lab13;\n+                        return false;\n                     }\n-                    cursor++;\n+                    return true;\n                 }\n-                // setmark p2, line 66\n-                I_p2 = cursor;\n-            } while (false);\n-            cursor = v_8;\n-            return true;\n-        }\n \n-        private boolean r_postlude() {\n+                private boolean r_attached_pronoun() {\n             int among_var;\n-            int v_1;\n-            // repeat, line 70\n-            replab0: while(true)\n-            {\n-                v_1 = cursor;\n-                lab1: do {\n-                    // (, line 70\n-                    // [, line 72\n+                    // (, line 86\n+                    // [, line 87\n+                    ket = cursor;\n+                    // substring, line 87\n+                    if (find_among_b(a_2, 37) == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 87\n                     bra = cursor;\n-                    // substring, line 72\n-                    among_var = find_among(a_1, 3);\n+                    // among, line 97\n+                    among_var = find_among_b(a_3, 5);\n                     if (among_var == 0)\n                     {\n-                        break lab1;\n+                        return false;\n                     }\n-                    // ], line 72\n+                    // (, line 97\n+                    // call RV, line 97\n+                    if (!r_RV())\n+                    {\n+                        return false;\n+                    }\n+                    switch(among_var) {\n+                        case 0:\n+                            return false;\n+                        case 1:\n+                            // (, line 98\n+                            // delete, line 98\n+                            slice_del();\n+                            break;\n+                        case 2:\n+                            // (, line 99\n+                            // <-, line 99\n+                            slice_from(\"e\");\n+                            break;\n+                    }\n+                    return true;\n+                }\n+\n+                private boolean r_standard_suffix() {\n+            int among_var;\n+            int v_1;\n+            int v_2;\n+            int v_3;\n+            int v_4;\n+                    // (, line 103\n+                    // [, line 104\n                     ket = cursor;\n+                    // substring, line 104\n+                    among_var = find_among_b(a_6, 51);\n+                    if (among_var == 0)\n+                    {\n+                        return false;\n+                    }\n+                    // ], line 104\n+                    bra = cursor;\n                     switch(among_var) {\n                         case 0:\n-                            break lab1;\n+                            return false;\n                         case 1:\n-                            // (, line 73\n-                            // <-, line 73\n-                            slice_from(\"i\");\n+                            // (, line 111\n+                            // call R2, line 111\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 111\n+                            slice_del();\n                             break;\n                         case 2:\n-                            // (, line 74\n-                            // <-, line 74\n-                            slice_from(\"u\");\n+                            // (, line 113\n+                            // call R2, line 113\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 113\n+                            slice_del();\n+                            // try, line 114\n+                            v_1 = limit - cursor;\n+                            lab0: do {\n+                                // (, line 114\n+                                // [, line 114\n+                                ket = cursor;\n+                                // literal, line 114\n+                                if (!(eq_s_b(2, \"ic\")))\n+                                {\n+                                    cursor = limit - v_1;\n+                                    break lab0;\n+                                }\n+                                // ], line 114\n+                                bra = cursor;\n+                                // call R2, line 114\n+                                if (!r_R2())\n+                                {\n+                                    cursor = limit - v_1;\n+                                    break lab0;\n+                                }\n+                                // delete, line 114\n+                                slice_del();\n+                            } while (false);\n                             break;\n                         case 3:\n-                            // (, line 75\n-                            // next, line 75\n-                            if (cursor >= limit)\n+                            // (, line 117\n+                            // call R2, line 117\n+                            if (!r_R2())\n                             {\n-                                break lab1;\n+                                return false;\n                             }\n-                            cursor++;\n+                            // <-, line 117\n+                            slice_from(\"log\");\n+                            break;\n+                        case 4:\n+                            // (, line 119\n+                            // call R2, line 119\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // <-, line 119\n+                            slice_from(\"u\");\n+                            break;\n+                        case 5:\n+                            // (, line 121\n+                            // call R2, line 121\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // <-, line 121\n+                            slice_from(\"ente\");\n+                            break;\n+                        case 6:\n+                            // (, line 123\n+                            // call RV, line 123\n+                            if (!r_RV())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 123\n+                            slice_del();\n+                            break;\n+                        case 7:\n+                            // (, line 124\n+                            // call R1, line 125\n+                            if (!r_R1())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 125\n+                            slice_del();\n+                            // try, line 126\n+                            v_2 = limit - cursor;\n+                            lab1: do {\n+                                // (, line 126\n+                                // [, line 127\n+                                ket = cursor;\n+                                // substring, line 127\n+                                among_var = find_among_b(a_4, 4);\n+                                if (among_var == 0)\n+                                {\n+                                    cursor = limit - v_2;\n+                                    break lab1;\n+                                }\n+                                // ], line 127\n+                                bra = cursor;\n+                                // call R2, line 127\n+                                if (!r_R2())\n+                                {\n+                                    cursor = limit - v_2;\n+                                    break lab1;\n+                                }\n+                                // delete, line 127\n+                                slice_del();\n+                                switch(among_var) {\n+                                    case 0:\n+                                        cursor = limit - v_2;\n+                                        break lab1;\n+                                    case 1:\n+                                        // (, line 128\n+                                        // [, line 128\n+                                        ket = cursor;\n+                                        // literal, line 128\n+                                        if (!(eq_s_b(2, \"at\")))\n+                                        {\n+                                            cursor = limit - v_2;\n+                                            break lab1;\n+                                        }\n+                                        // ], line 128\n+                                        bra = cursor;\n+                                        // call R2, line 128\n+                                        if (!r_R2())\n+                                        {\n+                                            cursor = limit - v_2;\n+                                            break lab1;\n+                                        }\n+                                        // delete, line 128\n+                                        slice_del();\n+                                        break;\n+                                }\n+                            } while (false);\n+                            break;\n+                        case 8:\n+                            // (, line 133\n+                            // call R2, line 134\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 134\n+                            slice_del();\n+                            // try, line 135\n+                            v_3 = limit - cursor;\n+                            lab2: do {\n+                                // (, line 135\n+                                // [, line 136\n+                                ket = cursor;\n+                                // substring, line 136\n+                                among_var = find_among_b(a_5, 3);\n+                                if (among_var == 0)\n+                                {\n+                                    cursor = limit - v_3;\n+                                    break lab2;\n+                                }\n+                                // ], line 136\n+                                bra = cursor;\n+                                switch(among_var) {\n+                                    case 0:\n+                                        cursor = limit - v_3;\n+                                        break lab2;\n+                                    case 1:\n+                                        // (, line 137\n+                                        // call R2, line 137\n+                                        if (!r_R2())\n+                                        {\n+                                            cursor = limit - v_3;\n+                                            break lab2;\n+                                        }\n+                                        // delete, line 137\n+                                        slice_del();\n+                                        break;\n+                                }\n+                            } while (false);\n+                            break;\n+                        case 9:\n+                            // (, line 141\n+                            // call R2, line 142\n+                            if (!r_R2())\n+                            {\n+                                return false;\n+                            }\n+                            // delete, line 142\n+                            slice_del();\n+                            // try, line 143\n+                            v_4 = limit - cursor;\n+                            lab3: do {\n+                                // (, line 143\n+                                // [, line 143\n+                                ket = cursor;\n+                                // literal, line 143\n+                                if (!(eq_s_b(2, \"at\")))\n+                                {\n+                                    cursor = limit - v_4;\n+                                    break lab3;\n+                                }\n+                                // ], line 143\n+                                bra = cursor;\n+                                // call R2, line 143\n+                                if (!r_R2())\n+                                {\n+                                    cursor = limit - v_4;\n+                                    break lab3;\n+                                }\n+                                // delete, line 143\n+                                slice_del();\n+                                // [, line 143\n+                                ket = cursor;\n+                                // literal, line 143\n+                                if (!(eq_s_b(2, \"ic\")))\n+                                {\n+                                    cursor = limit - v_4;\n+                                    break lab3;\n+                                }\n+                                // ], line 143\n+                                bra = cursor;\n+                                // call R2, line 143\n+                                if (!r_R2())\n+                                {\n+                                    cursor = limit - v_4;\n+                                    break lab3;\n+                                }\n+                                // delete, line 143\n+                                slice_del();\n+                            } while (false);\n                             break;\n                     }\n-                    continue replab0;\n-                } while (false);\n-                cursor = v_1;\n-                break replab0;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_RV() {\n-            if (!(I_pV <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_R1() {\n-            if (!(I_p1 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_R2() {\n-            if (!(I_p2 <= cursor))\n-            {\n-                return false;\n-            }\n-            return true;\n-        }\n-\n-        private boolean r_attached_pronoun() {\n-            int among_var;\n-            // (, line 86\n-            // [, line 87\n-            ket = cursor;\n-            // substring, line 87\n-            if (find_among_b(a_2, 37) == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 87\n-            bra = cursor;\n-            // among, line 97\n-            among_var = find_among_b(a_3, 5);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // (, line 97\n-            // call RV, line 97\n-            if (!r_RV())\n-            {\n-                return false;\n-            }\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 98\n-                    // delete, line 98\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 99\n-                    // <-, line 99\n-                    slice_from(\"e\");\n-                    break;\n-            }\n-            return true;\n-        }\n+                    return true;\n+                }\n \n-        private boolean r_standard_suffix() {\n+                private boolean r_verb_suffix() {\n             int among_var;\n             int v_1;\n             int v_2;\n-            int v_3;\n-            int v_4;\n-            // (, line 103\n-            // [, line 104\n-            ket = cursor;\n-            // substring, line 104\n-            among_var = find_among_b(a_6, 51);\n-            if (among_var == 0)\n-            {\n-                return false;\n-            }\n-            // ], line 104\n-            bra = cursor;\n-            switch(among_var) {\n-                case 0:\n-                    return false;\n-                case 1:\n-                    // (, line 111\n-                    // call R2, line 111\n-                    if (!r_R2())\n+                    // setlimit, line 148\n+                    v_1 = limit - cursor;\n+                    // tomark, line 148\n+                    if (cursor < I_pV)\n                     {\n                         return false;\n                     }\n-                    // delete, line 111\n-                    slice_del();\n-                    break;\n-                case 2:\n-                    // (, line 113\n-                    // call R2, line 113\n-                    if (!r_R2())\n+                    cursor = I_pV;\n+                    v_2 = limit_backward;\n+                    limit_backward = cursor;\n+                    cursor = limit - v_1;\n+                    // (, line 148\n+                    // [, line 149\n+                    ket = cursor;\n+                    // substring, line 149\n+                    among_var = find_among_b(a_7, 87);\n+                    if (among_var == 0)\n                     {\n+                        limit_backward = v_2;\n                         return false;\n                     }\n-                    // delete, line 113\n-                    slice_del();\n-                    // try, line 114\n+                    // ], line 149\n+                    bra = cursor;\n+                    switch(among_var) {\n+                        case 0:\n+                            limit_backward = v_2;\n+                            return false;\n+                        case 1:\n+                            // (, line 163\n+                            // delete, line 163\n+                            slice_del();\n+                            break;\n+                    }\n+                    limit_backward = v_2;\n+                    return true;\n+                }\n+\n+                private boolean r_vowel_suffix() {\n+            int v_1;\n+            int v_2;\n+                    // (, line 170\n+                    // try, line 171\n                     v_1 = limit - cursor;\n                     lab0: do {\n-                        // (, line 114\n-                        // [, line 114\n+                        // (, line 171\n+                        // [, line 172\n                         ket = cursor;\n-                        // literal, line 114\n-                        if (!(eq_s_b(2, \"ic\")))\n+                        if (!(in_grouping_b(g_AEIO, 97, 242)))\n                         {\n                             cursor = limit - v_1;\n                             break lab0;\n                         }\n-                        // ], line 114\n+                        // ], line 172\n                         bra = cursor;\n-                        // call R2, line 114\n-                        if (!r_R2())\n+                        // call RV, line 172\n+                        if (!r_RV())\n                         {\n                             cursor = limit - v_1;\n                             break lab0;\n                         }\n-                        // delete, line 114\n+                        // delete, line 172\n+                        slice_del();\n+                        // [, line 173\n+                        ket = cursor;\n+                        // literal, line 173\n+                        if (!(eq_s_b(1, \"i\")))\n+                        {\n+                            cursor = limit - v_1;\n+                            break lab0;\n+                        }\n+                        // ], line 173\n+                        bra = cursor;\n+                        // call RV, line 173\n+                        if (!r_RV())\n+                        {\n+                            cursor = limit - v_1;\n+                            break lab0;\n+                        }\n+                        // delete, line 173\n                         slice_del();\n                     } while (false);\n-                    break;\n-                case 3:\n-                    // (, line 117\n-                    // call R2, line 117\n-                    if (!r_R2())\n-                    {\n-                        return false;\n-                    }\n-                    // <-, line 117\n-                    slice_from(\"log\");\n-                    break;\n-                case 4:\n-                    // (, line 119\n-                    // call R2, line 119\n-                    if (!r_R2())\n-                    {\n-                        return false;\n-                    }\n-                    // <-, line 119\n-                    slice_from(\"u\");\n-                    break;\n-                case 5:\n-                    // (, line 121\n-                    // call R2, line 121\n-                    if (!r_R2())\n-                    {\n-                        return false;\n-                    }\n-                    // <-, line 121\n-                    slice_from(\"ente\");\n-                    break;\n-                case 6:\n-                    // (, line 123\n-                    // call RV, line 123\n-                    if (!r_RV())\n-                    {\n-                        return false;\n-                    }\n-                    // delete, line 123\n-                    slice_del();\n-                    break;\n-                case 7:\n-                    // (, line 124\n-                    // call R1, line 125\n-                    if (!r_R1())\n-                    {\n-                        return false;\n-                    }\n-                    // delete, line 125\n-                    slice_del();\n-                    // try, line 126\n+                    // try, line 175\n                     v_2 = limit - cursor;\n                     lab1: do {\n-                        // (, line 126\n-                        // [, line 127\n+                        // (, line 175\n+                        // [, line 176\n                         ket = cursor;\n-                        // substring, line 127\n-                        among_var = find_among_b(a_4, 4);\n-                        if (among_var == 0)\n+                        // literal, line 176\n+                        if (!(eq_s_b(1, \"h\")))\n                         {\n                             cursor = limit - v_2;\n                             break lab1;\n                         }\n-                        // ], line 127\n+                        // ], line 176\n                         bra = cursor;\n-                        // call R2, line 127\n-                        if (!r_R2())\n+                        if (!(in_grouping_b(g_CG, 99, 103)))\n                         {\n                             cursor = limit - v_2;\n                             break lab1;\n                         }\n-                        // delete, line 127\n+                        // call RV, line 176\n+                        if (!r_RV())\n+                        {\n+                            cursor = limit - v_2;\n+                            break lab1;\n+                        }\n+                        // delete, line 176\n                         slice_del();\n-                        switch(among_var) {\n-                            case 0:\n-                                cursor = limit - v_2;\n-                                break lab1;\n-                            case 1:\n-                                // (, line 128\n-                                // [, line 128\n-                                ket = cursor;\n-                                // literal, line 128\n-                                if (!(eq_s_b(2, \"at\")))\n-                                {\n-                                    cursor = limit - v_2;\n-                                    break lab1;\n-                                }\n-                                // ], line 128\n-                                bra = cursor;\n-                                // call R2, line 128\n-                                if (!r_R2())\n-                                {\n-                                    cursor = limit - v_2;\n-                                    break lab1;\n-                                }\n-                                // delete, line 128\n-                                slice_del();\n-                                break;\n+                    } while (false);\n+                    return true;\n+                }\n+\n+                public boolean stem() {\n+            int v_1;\n+            int v_2;\n+            int v_3;\n+            int v_4;\n+            int v_5;\n+            int v_6;\n+            int v_7;\n+                    // (, line 181\n+                    // do, line 182\n+                    v_1 = cursor;\n+                    lab0: do {\n+                        // call prelude, line 182\n+                        if (!r_prelude())\n+                        {\n+                            break lab0;\n                         }\n                     } while (false);\n-                    break;\n-                case 8:\n-                    // (, line 133\n-                    // call R2, line 134\n-                    if (!r_R2())\n-                    {\n-                        return false;\n-                    }\n-                    // delete, line 134\n-                    slice_del();\n-                    // try, line 135\n+                    cursor = v_1;\n+                    // do, line 183\n+                    v_2 = cursor;\n+                    lab1: do {\n+                        // call mark_regions, line 183\n+                        if (!r_mark_regions())\n+                        {\n+                            break lab1;\n+                        }\n+                    } while (false);\n+                    cursor = v_2;\n+                    // backwards, line 184\n+                    limit_backward = cursor; cursor = limit;\n+                    // (, line 184\n+                    // do, line 185\n                     v_3 = limit - cursor;\n                     lab2: do {\n-                        // (, line 135\n-                        // [, line 136\n-                        ket = cursor;\n-                        // substring, line 136\n-                        among_var = find_among_b(a_5, 3);\n-                        if (among_var == 0)\n+                        // call attached_pronoun, line 185\n+                        if (!r_attached_pronoun())\n                         {\n-                            cursor = limit - v_3;\n                             break lab2;\n                         }\n-                        // ], line 136\n-                        bra = cursor;\n-                        switch(among_var) {\n-                            case 0:\n-                                cursor = limit - v_3;\n-                                break lab2;\n-                            case 1:\n-                                // (, line 137\n-                                // call R2, line 137\n-                                if (!r_R2())\n-                                {\n-                                    cursor = limit - v_3;\n-                                    break lab2;\n-                                }\n-                                // delete, line 137\n-                                slice_del();\n-                                break;\n-                        }\n                     } while (false);\n-                    break;\n-                case 9:\n-                    // (, line 141\n-                    // call R2, line 142\n-                    if (!r_R2())\n-                    {\n-                        return false;\n-                    }\n-                    // delete, line 142\n-                    slice_del();\n-                    // try, line 143\n+                    cursor = limit - v_3;\n+                    // do, line 186\n                     v_4 = limit - cursor;\n                     lab3: do {\n-                        // (, line 143\n-                        // [, line 143\n-                        ket = cursor;\n-                        // literal, line 143\n-                        if (!(eq_s_b(2, \"at\")))\n-                        {\n-                            cursor = limit - v_4;\n-                            break lab3;\n-                        }\n-                        // ], line 143\n-                        bra = cursor;\n-                        // call R2, line 143\n-                        if (!r_R2())\n-                        {\n-                            cursor = limit - v_4;\n-                            break lab3;\n-                        }\n-                        // delete, line 143\n-                        slice_del();\n-                        // [, line 143\n-                        ket = cursor;\n-                        // literal, line 143\n-                        if (!(eq_s_b(2, \"ic\")))\n+                        // (, line 186\n+                        // or, line 186\n+                        lab4: do {\n+                            v_5 = limit - cursor;\n+                            lab5: do {\n+                                // call standard_suffix, line 186\n+                                if (!r_standard_suffix())\n+                                {\n+                                    break lab5;\n+                                }\n+                                break lab4;\n+                            } while (false);\n+                            cursor = limit - v_5;\n+                            // call verb_suffix, line 186\n+                            if (!r_verb_suffix())\n+                            {\n+                                break lab3;\n+                            }\n+                        } while (false);\n+                    } while (false);\n+                    cursor = limit - v_4;\n+                    // do, line 187\n+                    v_6 = limit - cursor;\n+                    lab6: do {\n+                        // call vowel_suffix, line 187\n+                        if (!r_vowel_suffix())\n                         {\n-                            cursor = limit - v_4;\n-                            break lab3;\n+                            break lab6;\n                         }\n-                        // ], line 143\n-                        bra = cursor;\n-                        // call R2, line 143\n-                        if (!r_R2())\n+                    } while (false);\n+                    cursor = limit - v_6;\n+                    cursor = limit_backward;                    // do, line 189\n+                    v_7 = cursor;\n+                    lab7: do {\n+                        // call postlude, line 189\n+                        if (!r_postlude())\n                         {\n-                            cursor = limit - v_4;\n-                            break lab3;\n+                            break lab7;\n                         }\n-                        // delete, line 143\n-                        slice_del();\n                     } while (false);\n-                    break;\n-            }\n-            return true;\n-        }\n+                    cursor = v_7;\n+                    return true;\n+                }\n \n-        private boolean r_verb_suffix() {\n-            int among_var;\n-            int v_1;\n-            int v_2;\n-            // setlimit, line 148\n-            v_1 = limit - cursor;\n-            // tomark, line 148\n-            if (cursor < I_pV)\n-            {\n-                return false;\n-            }\n-            cursor = I_pV;\n-            v_2 = limit_backward;\n-            limit_backward = cursor;\n-            cursor = limit - v_1;\n-            // (, line 148\n-            // [, line 149\n-            ket = cursor;\n-            // substring, line 149\n-            among_var = find_among_b(a_7, 87);\n-            if (among_var == 0)\n-            {\n-                limit_backward = v_2;\n-                return false;\n-            }\n-            // ], line 149\n-            bra = cursor;\n-            switch(among_var) {\n-                case 0:\n-                    limit_backward = v_2;\n-                    return false;\n-                case 1:\n-                    // (, line 163\n-                    // delete, line 163\n-                    slice_del();\n-                    break;\n-            }\n-            limit_backward = v_2;\n-            return true;\n+        public boolean equals( Object o ) {\n+            return o instanceof ItalianStemmer;\n         }\n \n-        private boolean r_vowel_suffix() {\n-            int v_1;\n-            int v_2;\n-            // (, line 170\n-            // try, line 171\n-            v_1 = limit - cursor;\n-            lab0: do {\n-                // (, line 171\n-                // [, line 172\n-                ket = cursor;\n-                if (!(in_grouping_b(g_AEIO, 97, 242)))\n-                {\n-                    cursor = limit - v_1;\n-                    break lab0;\n-                }\n-                // ], line 172\n-                bra = cursor;\n-                // call RV, line 172\n-                if (!r_RV())\n-                {\n-                    cursor = limit - v_1;\n-                    break lab0;\n-                }\n-                // delete, line 172\n-                slice_del();\n-                // [, line 173\n-                ket = cursor;\n-                // literal, line 173\n-                if (!(eq_s_b(1, \"i\")))\n-                {\n-                    cursor = limit - v_1;\n-                    break lab0;\n-                }\n-                // ], line 173\n-                bra = cursor;\n-                // call RV, line 173\n-                if (!r_RV())\n-                {\n-                    cursor = limit - v_1;\n-                    break lab0;\n-                }\n-                // delete, line 173\n-                slice_del();\n-            } while (false);\n-            // try, line 175\n-            v_2 = limit - cursor;\n-            lab1: do {\n-                // (, line 175\n-                // [, line 176\n-                ket = cursor;\n-                // literal, line 176\n-                if (!(eq_s_b(1, \"h\")))\n-                {\n-                    cursor = limit - v_2;\n-                    break lab1;\n-                }\n-                // ], line 176\n-                bra = cursor;\n-                if (!(in_grouping_b(g_CG, 99, 103)))\n-                {\n-                    cursor = limit - v_2;\n-                    break lab1;\n-                }\n-                // call RV, line 176\n-                if (!r_RV())\n-                {\n-                    cursor = limit - v_2;\n-                    break lab1;\n-                }\n-                // delete, line 176\n-                slice_del();\n-            } while (false);\n-            return true;\n+        public int hashCode() {\n+            return ItalianStemmer.class.getName().hashCode();\n         }\n \n-        public boolean stem() {\n-            int v_1;\n-            int v_2;\n-            int v_3;\n-            int v_4;\n-            int v_5;\n-            int v_6;\n-            int v_7;\n-            // (, line 181\n-            // do, line 182\n-            v_1 = cursor;\n-            lab0: do {\n-                // call prelude, line 182\n-                if (!r_prelude())\n-                {\n-                    break lab0;\n-                }\n-            } while (false);\n-            cursor = v_1;\n-            // do, line 183\n-            v_2 = cursor;\n-            lab1: do {\n-                // call mark_regions, line 183\n-                if (!r_mark_regions())\n-                {\n-                    break lab1;\n-                }\n-            } while (false);\n-            cursor = v_2;\n-            // backwards, line 184\n-            limit_backward = cursor; cursor = limit;\n-            // (, line 184\n-            // do, line 185\n-            v_3 = limit - cursor;\n-            lab2: do {\n-                // call attached_pronoun, line 185\n-                if (!r_attached_pronoun())\n-                {\n-                    break lab2;\n-                }\n-            } while (false);\n-            cursor = limit - v_3;\n-            // do, line 186\n-            v_4 = limit - cursor;\n-            lab3: do {\n-                // (, line 186\n-                // or, line 186\n-                lab4: do {\n-                    v_5 = limit - cursor;\n-                    lab5: do {\n-                        // call standard_suffix, line 186\n-                        if (!r_standard_suffix())\n-                        {\n-                            break lab5;\n-                        }\n-                        break lab4;\n-                    } while (false);\n-                    cursor = limit - v_5;\n-                    // call verb_suffix, line 186\n-                    if (!r_verb_suffix())\n-                    {\n-                        break lab3;\n-                    }\n-                } while (false);\n-            } while (false);\n-            cursor = limit - v_4;\n-            // do, line 187\n-            v_6 = limit - cursor;\n-            lab6: do {\n-                // call vowel_suffix, line 187\n-                if (!r_vowel_suffix())\n-                {\n-                    break lab6;\n-                }\n-            } while (false);\n-            cursor = limit - v_6;\n-            cursor = limit_backward;            // do, line 189\n-            v_7 = cursor;\n-            lab7: do {\n-                // call postlude, line 189\n-                if (!r_postlude())\n-                {\n-                    break lab7;\n-                }\n-            } while (false);\n-            cursor = v_7;\n-            return true;\n-        }\n+\n \n }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/ItalianStemmer.java",
                "sha": "b349a987a0648ac462dffb4c170c8a465bc06cb0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/KpStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/KpStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/KpStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/KpStemmer.java",
                "sha": "9ddf7e6e40bb844602cb27beeb9ae5b6ab1c8a44",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/LovinsStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/LovinsStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/LovinsStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/LovinsStemmer.java",
                "sha": "8300459d5c16eba51ebcb23dcbb3cd8fcfcecbd6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/NorwegianStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/NorwegianStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/NorwegianStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/NorwegianStemmer.java",
                "sha": "0ce96f6d87cd2a2cefe2ec0c5ce41b1f9043f503",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PorterStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PorterStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/PorterStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PorterStemmer.java",
                "sha": "7d17c7f8ed828d2ee8603ee13f6bae02a0794d04",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PortugueseStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PortugueseStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/PortugueseStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/PortugueseStemmer.java",
                "sha": "d230c237ab61b3e7a115ce6396a209b54d62b304",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RomanianStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RomanianStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/RomanianStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RomanianStemmer.java",
                "sha": "1e0906831ce9c1616972bb9a3e272a7fe73a7141",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RussianStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RussianStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/RussianStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/RussianStemmer.java",
                "sha": "7629b5de55fed4b46d5bb3b5666ff7c9e55369b8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SpanishStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SpanishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/SpanishStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SpanishStemmer.java",
                "sha": "d660178dcce41ff6ff8a0d417cb35f365077739b",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SwedishStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SwedishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/SwedishStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/SwedishStemmer.java",
                "sha": "26f53de1cd294680db86c19acd0c0837e4500525",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/TurkishStemmer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/tartarus/snowball/ext/TurkishStemmer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/tartarus/snowball/ext/TurkishStemmer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/java/org/tartarus/snowball/ext/TurkishStemmer.java",
                "sha": "7ea4d6dcc1d833ccf14f6b68941c0f9e47b45fc8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory",
                "sha": "f790d02d3e43da25bd4c60c0b9a305e05348559e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilter.java",
                "sha": "80c595856d2afeb2497bb8bbee5f51b6d4de2b28",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKBigramFilterFactory.java",
                "sha": "8eb1092f721c6bd91b89372aa9ca9248e9aa6788",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java",
                "sha": "c71676825756bd07dbc81b3e5b6793653e133511",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java",
                "sha": "070228ac8713b22471630aa223ceb81d1ec3b650",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java",
                "sha": "e466257941c9bdec53af5767773bbd92a07a42a1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java",
                "sha": "bf1f8d40f99f2f7f372e341f425dea4dd6b11ea6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java",
                "sha": "e2a1ea07ff6f6826fa2fbeb97f0a50e6b1aba242",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer.java",
                "sha": "391e91ccae89e3054bcb7867b78a713fe5c698e0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java",
                "sha": "3e6c519d1a6a6684134391d75143a2b4c1da481e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java",
                "sha": "39cd5e4cca92f3d48c274b3afcd78f0fe825c0ef",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java",
                "sha": "8caac4a578e5dd03a67b19961fc72b2a67350489",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java",
                "sha": "f17ca59f8adcb37b77cc9defba6b6323ae348508",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java",
                "sha": "dd0954e3d74d134d5f71e035e4b66759af8a4256",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java",
                "sha": "0650ebc6caed3f330174d1f4a7aab3a1438f76f2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilterFactory.java",
                "sha": "18fec95673f4f8e635e29d6a7e3b605b3111b835",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "previous_filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElision.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "sha": "c48c86c47c8ed7d9b18c5c45557ab88e32bc7520",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java",
                "previous_filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElisionFilterFactory.java",
                "sha": "dbdc621a6e18b80f4881818ef60617a0b871fec8",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestFilesystemResourceLoader.java",
                "sha": "01887ef923931b4f220586265d2c4575151b94ad",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/frenchArticles.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/frenchArticles.txt?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/util/frenchArticles.txt",
                "previous_filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/frenchArticles.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/frenchArticles.txt",
                "sha": "914161185f7650c91fdbd53bdf35918e274821ff",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/stempel/src/test/org/apache/lucene/analysis/stempel/TestStempelPolishStemFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/stempel/src/test/org/apache/lucene/analysis/stempel/TestStempelPolishStemFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/analysis/stempel/src/test/org/apache/lucene/analysis/stempel/TestStempelPolishStemFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/analysis/stempel/src/test/org/apache/lucene/analysis/stempel/TestStempelPolishStemFilterFactory.java",
                "sha": "8c57d4ab1cc5ce27c00ebb05993ebf9df2636731",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/TaskSequence.java",
                "sha": "5f80c5f0ec37886a01de5f517bbebd7b2d4516d8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic.java",
                "sha": "614791bd7a5d28a97dca05517dae4fa4fb396705",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/build.xml",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/build.xml?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/build.xml",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/build.xml",
                "sha": "6ab5f62ca0b3678a737132c966fc6f876a9a5503",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/common-build.xml",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/common-build.xml?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/common-build.xml",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/common-build.xml",
                "sha": "65e3d2b15e39d5cf99125af9b312259850ad8922",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/analysis/package.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/analysis/package.html?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/analysis/package.html",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/analysis/package.html",
                "sha": "0495e488486cefd69e493f962030d6cf7b1c2b8f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java",
                "sha": "1eeec1b5136aecc8594666cb2ac74a5af8dbf52e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java",
                "sha": "67c3464c339d8229850c903b26d2bf1ee923a965",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/PostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/PostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/PostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/PostingsFormat.java",
                "sha": "0c48c1a767bf57f128e5a746c983e1286656f2cf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/PostingsReaderBase.java",
                "sha": "e840f2cc647251bf1a751a335514459987be785e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter.java",
                "sha": "9896d2cf3f4121bb3aa466914796582d16d596eb",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer.java",
                "sha": "d3ac4bbdf295734f125455b0fcc12426af5f3185",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilterFactory.java",
                "sha": "43fda309b398abc6444ad35e708fed6ffccf2d11",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.java",
                "sha": "889842848d3a40f992a8315f98fe2b5cb3b916d0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/DefaultBloomFilterFactory.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/bloom/DefaultBloomFilterFactory.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/bloom/DefaultBloomFilterFactory.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/DefaultBloomFilterFactory.java",
                "sha": "804f56bb4274cc72bf278a8793f4d6552df23323",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/package.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/bloom/package.html?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/bloom/package.html",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/bloom/package.html",
                "sha": "2d9b335173b12e4723a26c16415d835dee53b4a7",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40PostingsReader.java",
                "sha": "a2ab6db81923a3911605eab0b908e4a4c4f131f1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader.java",
                "sha": "347bdb9fe50e37d627e2aabc2ec5f3e79347e2cd",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java",
                "sha": "0d218f7818ca19d94e61464b713866bb4ea10dd7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java",
                "sha": "05509505a837844472161d7d0a46774a54007113",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsReader.java",
                "sha": "7dbdfc3ed296ecff82c5e34b22326694fb838ed2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/sep/SepPostingsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/sep/SepPostingsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/sep/SepPostingsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/sep/SepPostingsReader.java",
                "sha": "5b5af157f33ae56de17768d2e08987b3c372d750",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextFieldsReader.java",
                "sha": "35069688c8cf45144dbcb9530935c6578f374e88",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextTermVectorsReader.java",
                "sha": "049cd094630aab15a93b6bf9dc368d522956afd6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/Field.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/document/Field.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/document/Field.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/Field.java",
                "sha": "9ad07e782949cde5af9aa8cb57a42452d7df3249",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/StoredField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/document/StoredField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/document/StoredField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/StoredField.java",
                "sha": "1da116930e9c49c185f66b34c1681207bd141375",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/StringField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/document/StringField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/document/StringField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/StringField.java",
                "sha": "372b34b4ace6ea2657d264f9ae5ff522075c97ef",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/TextField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/document/TextField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/document/TextField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/document/TextField.java",
                "sha": "2d082e387c2d8ce431122fbccb0da0538d57343f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/AtomicReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/AtomicReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/AtomicReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/AtomicReader.java",
                "sha": "94ef1760df895565ebc281914bf03e0132147800",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/AtomicReaderContext.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/AtomicReaderContext.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/AtomicReaderContext.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/AtomicReaderContext.java",
                "sha": "2d6f1d735704aaa3e172b96569ac47e1ea8a2c86",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream.java",
                "sha": "b4bb4deaac39b8fe1afbf6669b6a744dba1be0aa",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "sha": "69fbeda26737688e2f3afc11cfa50630b0f1181d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DirectoryReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DirectoryReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DirectoryReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DirectoryReader.java",
                "sha": "beea8ae320a7846fe3c8cec83b1082ecac5435b5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "sha": "500dc3eb8f5c868a880536bfb5b244cd71efc1f0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocsAndPositionsEnum.java",
                "sha": "d604439a16980019870f9c72cf139e3b4b1db9a1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocsEnum.java",
                "sha": "07d0373c25a4ed26bc155bc72a255a18c1b817da",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java",
                "sha": "f29dd86c643752d2a68344086f9a30a27daf49b9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java",
                "sha": "4d264144cab8e0294ab422c450ea81f32c83d082",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FilterAtomicReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/FilterAtomicReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/FilterAtomicReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FilterAtomicReader.java",
                "sha": "e4c3665fa1121230e5abd8e4553f0b0be80349a3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FilteredTermsEnum.java",
                "sha": "a47c7ab68adddc1c7a0d19f9e7cd3e66db1607f0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java",
                "sha": "118d35a1ff9c62b3c9a0ada8e3b20993afc64a15",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "sha": "2c0856e78f65e05059eb7721670fb07c0ff67519",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java",
                "sha": "dfa975256296a5ca737347263c290b913f894c35",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexReaderContext.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/IndexReaderContext.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/IndexReaderContext.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexReaderContext.java",
                "sha": "76e57aa86def3aab7b2400390dc5c4e9ce500f61",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
                "sha": "e33947a228c76e5fecde948e3ad72611f956aa3d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java",
                "sha": "47023680dd055829866b933b464e4137438ce1e3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/LiveIndexWriterConfig.java",
                "sha": "35436848a111db9915561f047d3230d840e02cce",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/MultiFields.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/MultiFields.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java",
                "sha": "a60cac3f9db6838b668f9fb2a9e8285e79c9ba5c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/MultiTermsEnum.java",
                "sha": "290d510ad4524435617a7f463208fae41836b4bd",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/SegmentInfo.java",
                "sha": "9ec55e278e8880b881fcf8a77765e7a1c781c4b6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/index/TermsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/index/TermsEnum.java",
                "sha": "787ce0253bbb21009a4244295c2db3ed8ba7eb9c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/BooleanQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/BooleanQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/BooleanQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/BooleanQuery.java",
                "sha": "401fe9a9c4f9d1b58fa3f308830b17ef5d8dc568",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/BooleanScorer2.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/BooleanScorer2.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/BooleanScorer2.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/BooleanScorer2.java",
                "sha": "629118cf3a97196d9d7f2ec1d714702e8c53e3d2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/ConjunctionScorer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/ConjunctionScorer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/ConjunctionScorer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/ConjunctionScorer.java",
                "sha": "f22ab894241151762942447e9d83baf0c80a0a5c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/ConjunctionTermScorer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/ConjunctionTermScorer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/ConjunctionTermScorer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/ConjunctionTermScorer.java",
                "sha": "5db1e03b066f11f31917005c2beb6646c4c27b6c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/FieldCacheImpl.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/FieldCacheImpl.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/FieldCacheImpl.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/FieldCacheImpl.java",
                "sha": "9b281ab5b3ba62408458dc67becffbaa4e343a2a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/FuzzyTermsEnum.java",
                "sha": "05e9b34f79242dbc73aa88a105deca623201bc44",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/core/src/java/org/apache/lucene/search/MatchOnlyTermScorer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/MatchOnlyTermScorer.java?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/MatchOnlyTermScorer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/core/src/java/org/apache/lucene/search/MatchOnlyTermScorer.java",
                "sha": "742f0be51471d2add24204c9f0a62c3fc506a515",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "sha": "69b4ebcb8c21e9e6141d728f4b00bc9bab0a0aa5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter.java",
                "sha": "0fba7df9e50e4c12c1b8fc2356276565aab0af29",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/NRTManager.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/NRTManager.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/NRTManager.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/NRTManager.java",
                "sha": "cfe8028bb1a82ce6a027bcd83c06965dc181eeb8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/PhraseQuery.java",
                "sha": "b51c54daad5b08898ae753362ce7284231c7b892",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/TermQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/TermQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/TermQuery.java",
                "sha": "cf9ef6c7a38db39e0a7f5335bf52e1b98e3e952d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/search/spans/SpanTermQuery.java",
                "sha": "7fcbfa0135ddee46945b248059dc8fd4ef9567cd",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/Constants.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/Constants.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/Constants.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/Constants.java",
                "sha": "f44a5f4b6f9e45ea9aac62c3616c9a2a26dc3e5b",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/FixedBitSet.java",
                "sha": "9f772c7d89a1a927db60622f4d45473b339d5c15",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/FuzzySet.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/FuzzySet.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/FuzzySet.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/FuzzySet.java",
                "sha": "dec9a6e67b24f4ebbbccb6aba691f6c4f47d7e24",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/HashFunction.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/hash/HashFunction.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/hash/HashFunction.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/HashFunction.java",
                "sha": "fdb7b0133453ce12bff8303bcd31590a6f3200cf",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/MurmurHash2.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/hash/MurmurHash2.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/hash/MurmurHash2.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/MurmurHash2.java",
                "sha": "50b85aca9439c7c2a5d46c5da046e20b451ad161",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/package.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/hash/package.html?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/hash/package.html",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/java/org/apache/lucene/util/hash/package.html",
                "sha": "174f92e21b00e75c6d66318aeab33979dcf04b8e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "sha": "f72bfaaab46f921ab1874f4ddfa20afa67d26cc1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/resources/META-INF/services/org.apache.lucene.util.hash.HashFunction",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/resources/META-INF/services/org.apache.lucene.util.hash.HashFunction?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/resources/META-INF/services/org.apache.lucene.util.hash.HashFunction",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/resources/META-INF/services/org.apache.lucene.util.hash.HashFunction",
                "sha": "eee5167895fa4fc5000097e23b5def6815655e36",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java",
                "sha": "af307bbd0a637b95cc7fc5b0bff32ce43311166f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec.java",
                "sha": "bd25164bcae2c0766b4862cd1e2c070b17b107f7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum.java",
                "sha": "611006511ddd088baf7f25d497b07dc103c08e78",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/pulsing/Test10KPulsings.java",
                "sha": "3e47dc549cc6aae944c52721fb9ead6fb310164e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse.java",
                "sha": "a37770d31c30c99417ec624d054532f28caf7600",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/document/TestDocument.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/document/TestDocument.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/document/TestDocument.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/document/TestDocument.java",
                "sha": "672b961d82d76c9fcf2a70da535f189d99ca1e3c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/document/TestField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/document/TestField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/document/TestField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/document/TestField.java",
                "sha": "d6c26bd958a634c458b8631472d0c568bb29eaa8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestAddIndexes.java",
                "sha": "a24b51c467be05cec138300eb0d0ebed123592ae",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java",
                "sha": "78f96dd537c154dd5289e900a9b7eaa9cba8023a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestByteSlices.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestByteSlices.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestByteSlices.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestByteSlices.java",
                "sha": "35c97f3b537b0580bc64bf10abdd61cfb6d6117b",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestCodecs.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestCodecs.java",
                "sha": "5fd9e2d2da54861d2831b7d5885edb41b7aa671e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader.java",
                "sha": "5c0f6cc57cadcfd5056cd30a4e0edaeb4b164173",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDoc.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDoc.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDoc.java",
                "sha": "3f9862f5de20732661d1112822820c04a6e56c07",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDocCount.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocCount.java",
                "sha": "c183932be625ba63f0650295aab7291ae30d95ab",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java",
                "sha": "0ce1e2dd531405768eb5dd1cbbca9c30cb3ecaea",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions.java",
                "sha": "ddc5e293848a37bda82d1af29d6bcaa6c5c215ba",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter.java",
                "sha": "c6ae00af85de766ee6d06151e2adfbc0d894eb51",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestDuelingCodecs.java",
                "sha": "4e35aac6e9ca0893ed9f48b4fe8b192498fe2c2c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestFilterAtomicReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestFilterAtomicReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestFilterAtomicReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestFilterAtomicReader.java",
                "sha": "93f3cbd6b9ba4dbdc0182cd1ab4ee1409e21d991",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "sha": "de4beb42b3a09ac16256cc51132de3428ca22613",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterDelete.java",
                "sha": "a92c4902ae412a8d5a3ffe0a3979ba94cc2e1a40",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java",
                "sha": "8e2836047cea5efdc88b5dfe4e4b33a10ed60070",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader.java",
                "sha": "c1f675a10bd2694b007fa98b01a89b7f5ef92f3f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java",
                "sha": "268f952b765c985325a0b296806c8dd2d4ea59b8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestIndexableField.java",
                "sha": "1e52c8d4d7c026006a3b0ef45e5ba2340c57f741",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestLazyProxSkipping.java",
                "sha": "bc346a366f57eb2a6f975d58e03fcae51b059a13",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestLongPostings.java",
                "sha": "2851177359e1bf7021a0f17fdddd186938bf7d8b",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestMultiFields.java",
                "sha": "a7a4a3fb427abc79f26fa8794b7bcd03f0a03dd3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java",
                "sha": "1746109a8716208519bf354965891bd261e15b07",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestOmitPositions.java",
                "sha": "7050b17ee4322851bc0b55729e8385f6e856a5e1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestParallelTermEnum.java",
                "sha": "8a9bbf0418438f339bb878f5dbe8160cb235b4f5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java",
                "sha": "f2b2657d4edc558c3d7c10a33299f1a3c66b4c85",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPayloads.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPayloads.java",
                "sha": "977e7d6c2976632e35c5bc00e0fbe15e09b47240",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes.java",
                "sha": "5117d3949795aa831a0069f67595d9696707f1f5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPostingsFormat.java",
                "sha": "39ec96a5a89ebac2cdc449d02a763be551124cf7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets.java",
                "sha": "3c1bcfec5c1e5cd46e7436a9305c8fbea9d94b87",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates.java",
                "sha": "4376db45d5742d4b118adc26538554489458ace0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentMerger.java",
                "sha": "f78b4eae481287c90b2b07a52ee5f671d0cdd625",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentReader.java",
                "sha": "03ec8699c2f97462df5c9eab9d8e8c83b51904ed",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestSegmentTermDocs.java",
                "sha": "5f52bf1aa4252ef00c1f4a41feaa8bf1e70e74d9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestStressAdvance.java",
                "sha": "c30a381096717b06047a98e6cfd27fa1bc5ff198",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.java",
                "sha": "291ed55f3a80f27d244aae4c496f747a29d1c985",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsReader.java",
                "sha": "e904a0548457b199e50aecd974334166fc194ce6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermVectorsWriter.java",
                "sha": "fb2a425e651162738a2e4ab26c99fb649a11ba11",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermdocPerf.java",
                "sha": "cb721d8742a86bf913ce076dda836928ec1fd964",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/index/TestTermsEnum.java",
                "sha": "5b1ff5e73fe2e5d3b3668f2ed7e80585df65234c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestBoolean2.java",
                "sha": "859bbeb417e7a527b4df922f5ede3ce25715f47d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestFuzzyQuery.java",
                "sha": "7f4da03a6005675d79c288f8b354358deece1066",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestPositionIncrement.java",
                "sha": "8a76d64b156f3647d1d2aee14707cfb6cdf555f9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestShardSearching.java",
                "sha": "d0153dbf0abc1b33fdfa6818afafd758917a57c7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestSort.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestSort.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestSort.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestSort.java",
                "sha": "392ccedc8c7244016175b67247c32998fcd3f5df",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestSubScorerFreqs.java",
                "sha": "a51f118ce180a0412b16e7208fcc079a6c3663e8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestTermVectors.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestTermVectors.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestTermVectors.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/TestTermVectors.java",
                "sha": "192ec412b0e15393f6990ddf06f3693ff3fb0ef7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java",
                "sha": "353ffd3590b8880ad24ecb9605941b0b7a2cb004",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java",
                "sha": "1e38b9a9d5e40ec7e8488d08d21919a4134affa8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java",
                "previous_filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ResourceAsStreamResourceLoader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java",
                "sha": "6ccb95f41f12b693b941a35eb4d9562ab9755d6d",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java",
                "sha": "6f3444690027ffac51b825ab90398888a1089e1e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/search/PayloadIterator.java",
                "sha": "0ce41e09aa11846fce155e62bcef5d671e15bfe4",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/TakmiSampleFixer.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/TakmiSampleFixer.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/java/org/apache/lucene/facet/search/sampling/TakmiSampleFixer.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/search/sampling/TakmiSampleFixer.java",
                "sha": "2f214d3fc73428a861d8aa22cb79746910e4c567",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java",
                "sha": "2dbf7878ca4f57ea70331b8a1ac2bd2cc542496f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java",
                "sha": "1274a7b537884f7617045e3732c3d7b185baaa5a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/ParentArray.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/ParentArray.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/ParentArray.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/ParentArray.java",
                "sha": "4b6b1d62ae53ded5b28057beaa7304714d9eb5a9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/test/org/apache/lucene/facet/FacetTestBase.java",
                "sha": "5d15032ba4990583586f722aa2d3ea4b33b5c2e2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/facet/src/test/org/apache/lucene/facet/search/TestMultipleCategoryLists.java",
                "sha": "59b3e3816b2b2effe3d1408a16583a62d40a2e01",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermExtractor.java",
                "sha": "147209f1c66d57227e25f2987b05f9bec84793c9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java",
                "sha": "05b4716934b8eab148fe9af1b6f680607e01813c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector.java",
                "sha": "2a0dbc2beec42aeb3af4d95e71de247ed011b832",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java",
                "sha": "61efe7544d5c7f1c66f8d1778945188f5acc9ebd",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java",
                "sha": "ac1e39c9e1e2eb8f22e879cdc27c62aa3d288bdf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery.java",
                "sha": "da5b72f225b42f8a81ed4698ef80a7ea520c6a29",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/join/src/test/org/apache/lucene/search/join/TestJoinUtil.java",
                "sha": "fe33f91b26f4bd1c0b8112e709ba1c8e3423be9d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "sha": "78915447a707a6fdc4868a5d9f17d7cf7bf2e296",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "sha": "02aacfb0a16869dd881e4b79bdb96932330e5166",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/misc/src/java/org/apache/lucene/index/BalancedSegmentMergePolicy.java",
                "sha": "95d234a41ef736494519dc95dfb0a717c68bf653",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms.java",
                "sha": "98be12c0615140e8d592b07b50449aff4618832a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/misc/src/test/org/apache/lucene/index/TestBalancedSegmentMergePolicy.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/misc/src/test/org/apache/lucene/index/TestBalancedSegmentMergePolicy.java?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "lucene/misc/src/test/org/apache/lucene/index/TestBalancedSegmentMergePolicy.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/lucene/misc/src/test/org/apache/lucene/index/TestBalancedSegmentMergePolicy.java",
                "sha": "8db6164676b08104df9c6eb2b4ebe9b3cb223f6b",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/TermsFilter.java",
                "sha": "e0b35d9eafa7e865c1a70f6ab78d6e77f0dfcc95",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TFValueSource.java",
                "sha": "d8803ace2a78bba7cbe4be59b5e1380cf025c696",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/TermFreqValueSource.java",
                "sha": "eab10bcf83570cfe8f5a34a6c9888a08fb13bde7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java",
                "sha": "363de8310740f58c3882bcc19ebad6dbd492d245",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/precedence/processors/PrecedenceQueryNodeProcessorPipeline.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/precedence/processors/PrecedenceQueryNodeProcessorPipeline.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/precedence/processors/PrecedenceQueryNodeProcessorPipeline.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/precedence/processors/PrecedenceQueryNodeProcessorPipeline.java",
                "sha": "5b0b0e2b35c4e18404571590f0c13825e033bf56",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/CommonQueryParserConfiguration.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/CommonQueryParserConfiguration.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/CommonQueryParserConfiguration.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/CommonQueryParserConfiguration.java",
                "sha": "89a07c8ffa69738a90adf32f8c053b251618758f",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/StandardQueryParser.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/StandardQueryParser.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/StandardQueryParser.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/StandardQueryParser.java",
                "sha": "cb4decd4c71cbbcf9bbb72992f8c29f4b7cffad4",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/BooleanQuery2ModifierNodeProcessor.java",
                "sha": "ae762cdee9d6c9231a4b5dcecb3b103c5c089eae",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/GroupQueryNodeProcessor.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/GroupQueryNodeProcessor.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/GroupQueryNodeProcessor.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/GroupQueryNodeProcessor.java",
                "sha": "6868974d8e9e88b6cfb0dee4b51dfbe1f145038d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/MultiFieldQueryNodeProcessor.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/MultiFieldQueryNodeProcessor.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/MultiFieldQueryNodeProcessor.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/MultiFieldQueryNodeProcessor.java",
                "sha": "99a121cbbdf6e8029373e8ec2abe3130fc89accf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/StandardQueryNodeProcessorPipeline.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/StandardQueryNodeProcessorPipeline.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/StandardQueryNodeProcessorPipeline.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/processors/StandardQueryNodeProcessorPipeline.java",
                "sha": "0cbcd73c11d449beb8daf5564f650f45077d191c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestQueryParser.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestQueryParser.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestQueryParser.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/classic/TestQueryParser.java",
                "sha": "d67c1c8862520a40060422dff8035f077c75802d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/ext/TestExtendableQueryParser.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/ext/TestExtendableQueryParser.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/ext/TestExtendableQueryParser.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/ext/TestExtendableQueryParser.java",
                "sha": "4d6bba4cc73dc744c1f6d73f7b9eb9abde9b27c9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiAnalyzerQPHelper.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiAnalyzerQPHelper.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiAnalyzerQPHelper.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiAnalyzerQPHelper.java",
                "sha": "cea26f91b5aee3d9f7bd086d48e40eabe51d35cf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestMultiFieldQPHelper.java",
                "sha": "d0b5218d961795ddf1ff634b3825e3e8e907ad0a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestQPHelper.java",
                "sha": "41106a2148bff2e3e587668a537214235f43a2f2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestStandardQP.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestStandardQP.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestStandardQP.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/flexible/standard/TestStandardQP.java",
                "sha": "3ab6ee4a6110e98b8fee155115d217fd038a8c6c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/queryparser/src/test/org/apache/lucene/queryparser/util/QueryParserTestBase.java",
                "sha": "122868437887b34b083c5b3ab18b1d54fb2f7c44",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/DuplicateFilter.java",
                "sha": "35dfd0c2285c1c56f8708f6012099395426b944d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/DuplicateFilterTest.java",
                "sha": "b21d455271d3865f770114807550cb7dd6066f41",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/TestSlowFuzzyQuery.java",
                "sha": "a4226f2d7bf861422c7aeed67c40ff7f8639d0c6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/RecursivePrefixTreeFilter.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/RecursivePrefixTreeFilter.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/spatial/src/java/org/apache/lucene/spatial/prefix/RecursivePrefixTreeFilter.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/RecursivePrefixTreeFilter.java",
                "sha": "905cd871c264b97f292393c423376c52823d2918",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/spatial/src/java/org/apache/lucene/spatial/util/ShapeFieldCacheProvider.java",
                "sha": "ef587bf9911167137e59dc41c4a884ca4066f4b2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/TestBloomFilteredLucene40Postings.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/TestBloomFilteredLucene40Postings.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/TestBloomFilteredLucene40Postings.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/TestBloomFilteredLucene40Postings.java",
                "sha": "286ad88759b58c5be63dbe57b298795ca3834df5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/package.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/package.html?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/package.html",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/bloom/package.html",
                "sha": "862537461f70ae70ae4842433442bb3dc5af7a8d",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/codecs/ramonly/RAMOnlyPostingsFormat.java",
                "sha": "21b278247002fb6d4c805d773280e48108154a48",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/index/AssertingAtomicReader.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/index/AssertingAtomicReader.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/index/AssertingAtomicReader.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/index/AssertingAtomicReader.java",
                "sha": "7f9a196c8bce4107a208b7fd53e95674e13a1359",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java",
                "sha": "9bc4856a3604d18720b2035fb15114fe50057d21",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/search/RandomSimilarityProvider.java",
                "sha": "3fc0792a7bef4c8ce19982634077f8ce5ae75730",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.java",
                "sha": "158980b8a91230b26e8da3d2b9cdb2f5693bf7b0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/store/BaseDirectoryWrapper.java",
                "sha": "d744e3c8a950bf4501e2d8870ae11f44a6af532e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/store/MockDirectoryWrapper.java",
                "sha": "af5dd013575ddb55a559c1e191c708a90774f6d8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/java/org/apache/lucene/util/_TestUtil.java",
                "sha": "3301f360feabe4242e16258eda93429811e78bc2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "lucene/test-framework/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/lucene/test-framework/src/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat",
                "sha": "4c82a0146bb714d9d2ded24a7f9212bffe69f136",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/CHANGES.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/CHANGES.txt",
                "sha": "b482c37cd14c433b7da8a0d0b8f5a7c6aaaf27b2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/build.xml",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/build.xml?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/build.xml",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/build.xml",
                "sha": "24374051b5f1ffb171d006fc3a2e293bca764a41",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example1.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/example1.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/example1.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example1.sh",
                "sha": "cb926bb62b1a63141b37ffbfdc7cc557e5299380",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example2.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/example2.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/example2.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example2.sh",
                "sha": "3c44ec014d7f4f478f0c03d8b48eb5cb6f3f7f3f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example3.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/example3.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/example3.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/example3.sh",
                "sha": "f95fa7cc33f2d8759fd45e225f4c71e20e3f0d5c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-extzk-start.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/solrcloud-extzk-start.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/solrcloud-extzk-start.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-extzk-start.sh",
                "sha": "3ff2a8e61a71616512403723e38c35f257372631",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-multi-start.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/solrcloud-multi-start.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/solrcloud-multi-start.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-multi-start.sh",
                "sha": "32d8fca3807ff10dbb49374fdc89b085ad394bb1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-start-existing.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/solrcloud-start-existing.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/solrcloud-start-existing.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-start-existing.sh",
                "sha": "5e13e91d1bd2eb5ab4c100e9ad310d77e8df3230",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-start.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/cloud-dev/solrcloud-start.sh?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/cloud-dev/solrcloud-start.sh",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/cloud-dev/solrcloud-start.sh",
                "sha": "3f9c389e7e1ce3b24cb8dbe29467aef77c64d2f7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/analysis-extras/CHANGES.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/analysis-extras/CHANGES.txt?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "solr/contrib/analysis-extras/CHANGES.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/analysis-extras/CHANGES.txt",
                "sha": "22ff964f1e151d023521621a2b3ca9fd8af435f5",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/clustering/CHANGES.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/clustering/CHANGES.txt?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "solr/contrib/clustering/CHANGES.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/clustering/CHANGES.txt",
                "sha": "5469984c7e8fd541b2155ae4d2b96d7be2d1b3cd",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/dataimporthandler/CHANGES.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/CHANGES.txt?ref=e7811cfa6c06bbc11bb712b451e7966ed81049b5",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/CHANGES.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e7811cfa6c06bbc11bb712b451e7966ed81049b5/solr/contrib/dataimporthandler/CHANGES.txt",
                "sha": "45737d4666db750bbaed4108b657e1272b09dfc9",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/contrib/dataimporthandler/README.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/README.txt?ref=148d99cbbc1201c1812ea0b7d63604355f55ff8b",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/README.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/148d99cbbc1201c1812ea0b7d63604355f55ff8b/solr/contrib/dataimporthandler/README.txt",
                "sha": "c9698725abfa0927548d99d452519135997710ba",
                "status": "modified"
            }
        ],
        "message": "LUCENE-3312: Merged revision(s) 1366639-1371131 from lucene/dev/trunk:\n\nSOLR-3259: default /get to json\n........\nminor tweaks to update script example\n........\nLUCENE-4268: Rename ResourceAsStreamReasourceLoader to ClasspathResourceLoader, provide FilesystemResourceLoader, bug fixing\n........\nLUCENE-4268: Fix test bug\n........\nSOLR-3648: Fix Velocity template loading in SolrCloud mode\n........\nfix confusing IW infoStream message\n........\nFix rawtypes warning in java 7 and 8, make the SuppressWarnings more local\n........\nNicer solution to generic array creation (still problematic in Java 6, but correct in Java 7 if done this way)\n........\nDisable test failing with Java 8\n........\nAllow detecting of Java 8\n........\nLUCENE-4109: BooleanQueries are not parsed correctly with the flexible queryparser\n........\nLUCENE-4269: remove BalancedSegmentMergePolicy (use TieredMergePolicy instead)\n........\nLUCENE-4269: deprecate BalancedSegmentMergePolicy (use TieredMergePolicy instead)\n........\nLUCENE-4190: restrict allowed filenames to reduce risk of deleting non-lucene file from the index directory\n........\nfix the monkey: connection loss and expiration cause NPE\n........\nupgrade checkJavaDocs.py to python3\n........\nLUCENE-3884: Move ElisionFilter out of .fr package\n........\nfix encoding in javadocs checker\n........\nLUCENE-2501: fix thread hazard when threads add same field with different IndexOptions at the same time\n........\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene3312@1371142 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/e7811cfa6c06bbc11bb712b451e7966ed81049b5",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestCatalanAnalyzer.java",
            "HTMLStripCharFilterTest.java",
            "HTMLStripCharFilterTest.java",
            "TestCJKBigramFilter.java",
            "TestCJKBigramFilterFactory.java",
            "TestFrenchAnalyzer.java",
            "TestIrishAnalyzer.java",
            "TestItalianAnalyzer.java",
            "PathHierarchyTokenizerFactoryTest.java",
            "TestElisionFilterFactory.java",
            "TestFilesystemResourceLoader.java",
            "TestTermVectorsWriter.java",
            "TestDirectPostingsFormat.java",
            "TestField.java",
            "TestCheckIndex.java",
            "TestDirectoryReader.java",
            "TestDocTermOrds.java",
            "TestIndexFileDeleter.java",
            "TestIndexWriter.java",
            "TestIndexWriterConfig.java",
            "TestMultiFields.java",
            "TestMultiTermsEnum.java",
            "TestTermsEnum.java",
            "TestBooleanQuery.java",
            "TestMultiPhraseQuery.java",
            "TestPhraseQuery.java",
            "TestTermQuery.java",
            "TestSpanTermQuery.java",
            "TestFixedBitSet.java",
            "TestDirectoryTaxonomyReader.java",
            "TestDirectoryTaxonomyWriter.java",
            "TokenSourcesTest.java",
            "FieldTermStackTest.java",
            "TestMemoryIndex.java",
            "TestHighFreqTerms.java",
            "TestMockDirectoryWrapper.java"
        ]
    },
    "lucene-solr_14d7225": {
        "bug_id": "lucene-solr_14d7225",
        "commit": "https://github.com/apache/lucene-solr/commit/14d72257a656f41773dad0d974c98605af68fc36",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -134,6 +134,9 @@ Bug Fixes\n \n * SOLR-6023: FieldAnalysisRequestHandler throws NPE if no parameters are supplied.\n   (shalin)\n+  \n+* SOLR-5090: SpellCheckComponent sometimes throws NPE if \n+  \"spellcheck.alternativeTermCount\" is set to zero (James Dyer).\n \n Other Changes\n ---------------------",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/CHANGES.txt",
                "sha": "fa519e948577b570d2412df78d3f6119075e04f6",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent.java?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent.java",
                "patch": "@@ -158,7 +158,7 @@ public void process(ResponseBuilder rb) throws IOException {\n         boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false); \n         boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n         float accuracy = params.getFloat(SPELLCHECK_ACCURACY, Float.MIN_VALUE);\n-        Integer alternativeTermCount = params.getInt(SpellingParams.SPELLCHECK_ALTERNATIVE_TERM_COUNT); \n+        int alternativeTermCount = params.getInt(SpellingParams.SPELLCHECK_ALTERNATIVE_TERM_COUNT, 0); \n         Integer maxResultsForSuggest = params.getInt(SpellingParams.SPELLCHECK_MAX_RESULTS_FOR_SUGGEST);\n         ModifiableSolrParams customParams = new ModifiableSolrParams();\n         for (String checkerName : getDictionaryNames(params)) {\n@@ -177,7 +177,7 @@ public void process(ResponseBuilder rb) throws IOException {\n           SuggestMode suggestMode = SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX;\n           if (onlyMorePopular) {\n             suggestMode = SuggestMode.SUGGEST_MORE_POPULAR;\n-          } else if (alternativeTermCount != null) {\n+          } else if (alternativeTermCount > 0) {\n             suggestMode = SuggestMode.SUGGEST_ALWAYS;\n           }\n           ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent.java",
                "sha": "77de7ecf5cc36dfa568ad36378838247b6e3f263",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java",
                "patch": "@@ -156,17 +156,17 @@ public SpellingResult getSuggestions(SpellingOptions options) throws IOException\n         docFreq = reader.docFreq(term);\n       }\n       String[] suggestions = spellChecker.suggestSimilar(tokenText,\n-          ((options.alternativeTermCount == null || docFreq == 0) ? count\n+          ((options.alternativeTermCount == 0 || docFreq == 0) ? count\n               : options.alternativeTermCount), field != null ? reader : null, // workaround LUCENE-1295\n           field, options.suggestMode, theAccuracy);\n       if (suggestions.length == 1 && suggestions[0].equals(tokenText)\n-          && options.alternativeTermCount == null) {\n+          && options.alternativeTermCount == 0) {\n         // These are spelled the same, continue on\n         continue;\n       }\n       // If considering alternatives to \"correctly-spelled\" terms, then add the\n       // original as a viable suggestion.\n-      if (options.alternativeTermCount != null && docFreq > 0) {\n+      if (options.alternativeTermCount > 0 && docFreq > 0) {\n         boolean foundOriginal = false;\n         String[] suggestionsWithOrig = new String[suggestions.length + 1];\n         for (int i = 0; i < suggestions.length; i++) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java",
                "sha": "41ba2ecbabd7683df31c8bff24c4c95b06fe8584",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/DirectSolrSpellChecker.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/spelling/DirectSolrSpellChecker.java?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/spelling/DirectSolrSpellChecker.java",
                "patch": "@@ -185,13 +185,13 @@ public SpellingResult getSuggestions(SpellingOptions options)\n       String tokenText = token.toString();\n       Term term = new Term(field, tokenText);\n       int freq = options.reader.docFreq(term);\n-      int count = (options.alternativeTermCount != null && freq > 0) ? options.alternativeTermCount: options.count;\n+      int count = (options.alternativeTermCount > 0 && freq > 0) ? options.alternativeTermCount: options.count;\n       SuggestWord[] suggestions = checker.suggestSimilar(term, count,options.reader, options.suggestMode, accuracy);\n       result.addFrequency(token, freq);\n             \n       // If considering alternatives to \"correctly-spelled\" terms, then add the\n       // original as a viable suggestion.\n-      if (options.alternativeTermCount != null && freq > 0) {\n+      if (options.alternativeTermCount > 0 && freq > 0) {\n         boolean foundOriginal = false;\n         SuggestWord[] suggestionsWithOrig = new SuggestWord[suggestions.length + 1];\n         for (int i = 0; i < suggestions.length; i++) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/DirectSolrSpellChecker.java",
                "sha": "14e26f1cbfe7a90d79dae18eb8f3254dfd632f82",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/SpellingOptions.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/spelling/SpellingOptions.java?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/spelling/SpellingOptions.java",
                "patch": "@@ -43,7 +43,7 @@\n    */\n   public int count = 1;\n   \n-  public Integer alternativeTermCount = null;\n+  public int alternativeTermCount = 0;\n   \n   public SuggestMode suggestMode = SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX;\n   /**\n@@ -95,7 +95,7 @@ public SpellingOptions(Collection<Token> tokens, IndexReader reader,\n   }\n   \n   public SpellingOptions(Collection<Token> tokens, IndexReader reader,\n-      int count, Integer alternativeTermCount, SuggestMode suggestMode,\n+      int count, int alternativeTermCount, SuggestMode suggestMode,\n       boolean extendedResults, float accuracy, SolrParams customParams) {\n     this.tokens = tokens;\n     this.reader = reader;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/java/org/apache/solr/spelling/SpellingOptions.java",
                "sha": "d0d211e42fbe8e7b694a0fa54ac5c34c8008f0cc",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java?ref=14d72257a656f41773dad0d974c98605af68fc36",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java",
                "patch": "@@ -463,6 +463,14 @@ public void testContextSensitiveCollate() throws Exception {\n         \"//lst[@name='spellcheck']/lst[@name='suggestions']/lst[@name='collation']/int[@name='hits']=1\",\n         \"//lst[@name='spellcheck']/lst[@name='suggestions']/lst[@name='collation']/lst[@name='misspellingsAndCorrections']/str[@name='june']='jane'\"\n       );\n+      //SOLR-5090, alternativeTermCount==0 was being evaluated, sometimes would throw NPE\n+      assertQ(req(\"q\", \"teststop:(june customs)\", \"mm\", \"2\", \"qt\",\n+          \"spellCheckCompRH\", \"indent\", \"true\",\n+          SpellCheckComponent.COMPONENT_NAME, \"true\",\n+          SpellCheckComponent.SPELLCHECK_DICT, dictionary[i],\n+          SpellCheckComponent.SPELLCHECK_COUNT, \"10\",\n+          SpellCheckComponent.SPELLCHECK_ALTERNATIVE_TERM_COUNT, \"0\",\n+          SpellCheckComponent.SPELLCHECK_COLLATE, \"true\"));\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/14d72257a656f41773dad0d974c98605af68fc36/solr/core/src/test/org/apache/solr/spelling/SpellCheckCollatorTest.java",
                "sha": "8e0063bd09555fae7fc4f60441155018af2d683d",
                "status": "modified"
            }
        ],
        "message": "SOLR-5090: SpellCheckComponent sometimes throws NPE when \"spellcheck.alternativeTermCount\" is set to zero\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1592591 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/3c14dc6a576a2cc141d220e8fd598a642fe00579",
        "repo": "lucene-solr",
        "unit_tests": [
            "SpellCheckComponentTest.java",
            "DirectSolrSpellCheckerTest.java"
        ]
    },
    "lucene-solr_1779767": {
        "bug_id": "lucene-solr_1779767",
        "commit": "https://github.com/apache/lucene-solr/commit/17797673f2eb152c09af022e5d2e03bf5c1d584b",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=17797673f2eb152c09af022e5d2e03bf5c1d584b",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -189,6 +189,8 @@ Bug Fixes\n \n * SOLR-9308: Fix distributed RTG to forward request params, fixes fq and non-default fl params (hossman)\n \n+* SOLR-9179: NPE in IndexSchema using IBM JDK (noble, Colvin Cowie)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/CHANGES.txt",
                "sha": "787edee55a4c7980bb3dceed9f69cb438bce9023",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java?ref=17797673f2eb152c09af022e5d2e03bf5c1d584b",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/SchemaHandler.java",
                "patch": "@@ -185,7 +185,7 @@ private void handleGET(SolrQueryRequest req, SolrQueryResponse rsp) {\n           if (parts.get(0).isEmpty()) parts.remove(0);\n           if (parts.size() > 1 && level2.containsKey(parts.get(1))) {\n             String realName = parts.get(1);\n-            String fieldName = IndexSchema.SchemaProps.nameMapping.get(realName);\n+            String fieldName = IndexSchema.nameMapping.get(realName);\n \n             String pathParam = level2.get(realName);\n             if (parts.size() > 2) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/core/src/java/org/apache/solr/handler/SchemaHandler.java",
                "sha": "35e463b44caa1ba92bd65a96e4ac66f2ff6ad2ff",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/core/src/java/org/apache/solr/schema/IndexSchema.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/schema/IndexSchema.java?ref=17797673f2eb152c09af022e5d2e03bf5c1d584b",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/schema/IndexSchema.java",
                "patch": "@@ -1500,10 +1500,12 @@ SimpleOrderedMap getProperties(SchemaField sf) {\n               (v1, v2) -> v2,\n               LinkedHashMap::new));\n     }\n-    public static Map<String,String> nameMapping = Collections.unmodifiableMap(Stream.of(Handler.values())\n-        .collect(Collectors.toMap(Handler::getNameLower , Handler::getRealName)));\n   }\n \n+  public static Map<String,String> nameMapping = Collections.unmodifiableMap(Stream.of(SchemaProps.Handler.values())\n+      .collect(Collectors.toMap(SchemaProps.Handler::getNameLower , SchemaProps.Handler::getRealName)));\n+\n+\n   public Map<String, Object> getNamedPropertyValues(String name, SolrParams params) {\n     return new SchemaProps(name, params, this).toMap();\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/17797673f2eb152c09af022e5d2e03bf5c1d584b/solr/core/src/java/org/apache/solr/schema/IndexSchema.java",
                "sha": "c48518ca583ee6ff769e52f89892a6de20e18cbd",
                "status": "modified"
            }
        ],
        "message": "SOLR-9179: NPE in IndexSchema using IBM JDK",
        "parent": "https://github.com/apache/lucene-solr/commit/2c4542ea0204f8cb3a966fc697651226e09d2ee5",
        "repo": "lucene-solr",
        "unit_tests": [
            "IndexSchemaTest.java"
        ]
    },
    "lucene-solr_179c8f9": {
        "bug_id": "lucene-solr_179c8f9",
        "commit": "https://github.com/apache/lucene-solr/commit/179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/CHANGES.txt",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -123,6 +123,12 @@ New Features\n \n * SOLR-12536: autoscaling policy support to equally distribute replicas on the basis of arbitrary properties (noble)\n \n+* SOLR-11990: Make it possible to co-locate replicas of multiple collections together in a node. A collection may be\n+  co-located with another collection during collection creation time by specifying a 'withCollection' parameter. It can\n+  also be co-located afterwards by using the modify collection API. The co-location guarantee is enforced regardless of\n+  future cluster operations whether they are invoked manually via the Collection API or by the Autoscaling framework.\n+  (noble, shalin)\n+\n Bug Fixes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/CHANGES.txt",
                "sha": "c68c397bc2182f4356d39cdb7514508684e3de11",
                "status": "modified"
            },
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java",
                "changes": 53,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 14,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java",
                "patch": "@@ -23,15 +23,16 @@\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n+import java.util.List;\n import java.util.Locale;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicReference;\n \n import org.apache.commons.lang.StringUtils;\n+import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.Policy;\n import org.apache.solr.client.solrj.cloud.autoscaling.PolicyHelper;\n-import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.cloud.ActiveReplicaWatcher;\n import org.apache.solr.cloud.CloudUtil;\n import org.apache.solr.cloud.Overseer;\n@@ -43,6 +44,7 @@\n import org.apache.solr.common.cloud.Slice;\n import org.apache.solr.common.cloud.ZkNodeProps;\n import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.common.params.CommonAdminParams;\n import org.apache.solr.common.params.CoreAdminParams;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.params.ShardParams;\n@@ -52,11 +54,12 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.SKIP_CREATE_REPLICA_IN_CLUSTER_STATE;\n import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.CORE_NAME_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;\n+import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICA;\n import static org.apache.solr.common.params.CommonAdminParams.ASYNC;\n import static org.apache.solr.common.params.CommonAdminParams.TIMEOUT;\n@@ -79,16 +82,17 @@ public void call(ClusterState state, ZkNodeProps message, NamedList results) thr\n   ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList results, Runnable onComplete)\n       throws IOException, InterruptedException {\n     log.debug(\"addReplica() : {}\", Utils.toJSONString(message));\n+\n+    String collectionName = message.getStr(COLLECTION_PROP);\n+    DocCollection coll = clusterState.getCollection(collectionName);\n+\n     boolean waitForFinalState = message.getBool(WAIT_FOR_FINAL_STATE, false);\n     boolean skipCreateReplicaInClusterState = message.getBool(SKIP_CREATE_REPLICA_IN_CLUSTER_STATE, false);\n     final String asyncId = message.getStr(ASYNC);\n \n     AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n     message = assignReplicaDetails(ocmh.cloudManager, clusterState, message, sessionWrapper);\n \n-    String collection = message.getStr(COLLECTION_PROP);\n-    DocCollection coll = clusterState.getCollection(collection);\n-\n     String node = message.getStr(CoreAdminParams.NODE);\n     String shard = message.getStr(SHARD_ID_PROP);\n     String coreName = message.getStr(CoreAdminParams.NAME);\n@@ -97,14 +101,35 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n     Replica.Type replicaType = Replica.Type.valueOf(message.getStr(ZkStateReader.REPLICA_TYPE, Replica.Type.NRT.name()).toUpperCase(Locale.ROOT));\n     boolean parallel = message.getBool(\"parallel\", false);\n \n+    if (coll.getStr(WITH_COLLECTION) != null) {\n+      String withCollectionName = coll.getStr(WITH_COLLECTION);\n+      DocCollection withCollection = clusterState.getCollection(withCollectionName);\n+      if (withCollection.getActiveSlices().size() > 1)  {\n+        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + withCollection.getActiveSlices().size());\n+      }\n+      String withCollectionShard = withCollection.getActiveSlices().iterator().next().getName();\n+\n+      List<Replica> replicas = withCollection.getReplicas(node);\n+      if (replicas == null || replicas.isEmpty()) {\n+        // create a replica of withCollection on the identified node before proceeding further\n+        ZkNodeProps props = new ZkNodeProps(\n+            Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n+            ZkStateReader.COLLECTION_PROP, withCollectionName,\n+            ZkStateReader.SHARD_ID_PROP, withCollectionShard,\n+            \"node\", node,\n+            CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.TRUE.toString()); // set to true because we want `withCollection` to be ready after this collection is created\n+        addReplica(clusterState, props, results, null);\n+      }\n+    }\n+\n     ModifiableSolrParams params = new ModifiableSolrParams();\n \n     ZkStateReader zkStateReader = ocmh.zkStateReader;\n     if (!Overseer.isLegacy(zkStateReader)) {\n       if (!skipCreateReplicaInClusterState) {\n         ZkNodeProps props = new ZkNodeProps(\n             Overseer.QUEUE_OPERATION, ADDREPLICA.toLower(),\n-            ZkStateReader.COLLECTION_PROP, collection,\n+            ZkStateReader.COLLECTION_PROP, collectionName,\n             ZkStateReader.SHARD_ID_PROP, shard,\n             ZkStateReader.CORE_NAME_PROP, coreName,\n             ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n@@ -121,10 +146,10 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n         }\n       }\n       params.set(CoreAdminParams.CORE_NODE_NAME,\n-          ocmh.waitToSeeReplicasInState(collection, Collections.singletonList(coreName)).get(coreName).getName());\n+          ocmh.waitToSeeReplicasInState(collectionName, Collections.singletonList(coreName)).get(coreName).getName());\n     }\n \n-    String configName = zkStateReader.readConfigName(collection);\n+    String configName = zkStateReader.readConfigName(collectionName);\n     String routeKey = message.getStr(ShardParams._ROUTE_);\n     String dataDir = message.getStr(CoreAdminParams.DATA_DIR);\n     String ulogDir = message.getStr(CoreAdminParams.ULOG_DIR);\n@@ -133,7 +158,7 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n     params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.CREATE.toString());\n     params.set(CoreAdminParams.NAME, coreName);\n     params.set(COLL_CONF, configName);\n-    params.set(CoreAdminParams.COLLECTION, collection);\n+    params.set(CoreAdminParams.COLLECTION, collectionName);\n     params.set(CoreAdminParams.REPLICA_TYPE, replicaType.name());\n     if (shard != null) {\n       params.set(CoreAdminParams.SHARD, shard);\n@@ -172,7 +197,7 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n \n     Runnable runnable = () -> {\n       ocmh.processResponses(results, shardHandler, true, \"ADDREPLICA failed to create replica\", asyncId, requestMap);\n-      ocmh.waitForCoreNodeName(collection, fnode, fcoreName);\n+      ocmh.waitForCoreNodeName(collectionName, fnode, fcoreName);\n       if (sessionWrapper.get() != null) {\n         sessionWrapper.get().release();\n       }\n@@ -182,15 +207,15 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n     if (!parallel || waitForFinalState) {\n       if (waitForFinalState) {\n         SolrCloseableLatch latch = new SolrCloseableLatch(1, ocmh);\n-        ActiveReplicaWatcher watcher = new ActiveReplicaWatcher(collection, null, Collections.singletonList(coreName), latch);\n+        ActiveReplicaWatcher watcher = new ActiveReplicaWatcher(collectionName, null, Collections.singletonList(coreName), latch);\n         try {\n-          zkStateReader.registerCollectionStateWatcher(collection, watcher);\n+          zkStateReader.registerCollectionStateWatcher(collectionName, watcher);\n           runnable.run();\n           if (!latch.await(timeout, TimeUnit.SECONDS)) {\n             throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Timeout waiting \" + timeout + \" seconds for replica to become active.\");\n           }\n         } finally {\n-          zkStateReader.removeCollectionStateWatcher(collection, watcher);\n+          zkStateReader.removeCollectionStateWatcher(collectionName, watcher);\n         }\n       } else {\n         runnable.run();\n@@ -201,7 +226,7 @@ ZkNodeProps addReplica(ClusterState clusterState, ZkNodeProps message, NamedList\n \n \n     return new ZkNodeProps(\n-        ZkStateReader.COLLECTION_PROP, collection,\n+        ZkStateReader.COLLECTION_PROP, collectionName,\n         ZkStateReader.SHARD_ID_PROP, shard,\n         ZkStateReader.CORE_NAME_PROP, coreName,\n         ZkStateReader.NODE_NAME_PROP, node",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java",
                "sha": "0feeec99d09a488be82d27afb8beced543e58b09",
                "status": "modified"
            },
            {
                "additions": 108,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "changes": 145,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 37,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "patch": "@@ -32,21 +32,22 @@\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicReference;\n \n+import org.apache.solr.client.solrj.cloud.DistribStateManager;\n+import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.AlreadyExistsException;\n import org.apache.solr.client.solrj.cloud.autoscaling.AutoScalingConfig;\n import org.apache.solr.client.solrj.cloud.autoscaling.BadVersionException;\n-import org.apache.solr.client.solrj.cloud.DistribStateManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.NotEmptyException;\n import org.apache.solr.client.solrj.cloud.autoscaling.Policy;\n import org.apache.solr.client.solrj.cloud.autoscaling.PolicyHelper;\n-import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.VersionedData;\n import org.apache.solr.cloud.Overseer;\n import org.apache.solr.cloud.ZkController;\n import org.apache.solr.cloud.overseer.ClusterStateMutator;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.SolrException.ErrorCode;\n import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n import org.apache.solr.common.cloud.DocRouter;\n import org.apache.solr.common.cloud.ImplicitDocRouter;\n import org.apache.solr.common.cloud.Replica;\n@@ -73,13 +74,14 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;\n import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;\n import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;\n import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;\n import static org.apache.solr.common.cloud.ZkStateReader.TLOG_REPLICAS;\n+import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICA;\n+import static org.apache.solr.common.params.CollectionParams.CollectionAction.MODIFYCOLLECTION;\n import static org.apache.solr.common.params.CommonAdminParams.ASYNC;\n import static org.apache.solr.common.params.CommonAdminParams.WAIT_FOR_FINAL_STATE;\n import static org.apache.solr.common.params.CommonParams.NAME;\n@@ -106,26 +108,48 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n       throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"collection already exists: \" + collectionName);\n     }\n \n+    String withCollection = message.getStr(CollectionAdminParams.WITH_COLLECTION);\n+    String withCollectionShard = null;\n+    if (withCollection != null) {\n+      if (!clusterState.hasCollection(withCollection)) {\n+        throw new SolrException(ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n+      } else  {\n+        DocCollection collection = clusterState.getCollection(withCollection);\n+        if (collection.getActiveSlices().size() > 1)  {\n+          throw new SolrException(ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n+        }\n+        withCollectionShard = collection.getActiveSlices().iterator().next().getName();\n+      }\n+    }\n+\n     String configName = getConfigName(collectionName, message);\n     if (configName == null) {\n       throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No config set found to associate with the collection.\");\n     }\n \n     ocmh.validateConfigOrThrowSolrException(configName);\n+\n+    List<String> nodeList = new ArrayList<>();\n+    String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n+    String policy = message.getStr(Policy.POLICY);\n+    AutoScalingConfig autoScalingConfig = ocmh.cloudManager.getDistribStateManager().getAutoScalingConfig();\n+    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n+\n+    // fail fast if parameters are wrong or incomplete\n+    List<String> shardNames = populateShardNames(message, router);\n+    checkMaxShardsPerNode(message, usePolicyFramework);\n+    checkReplicaTypes(message);\n+\n     AtomicReference<PolicyHelper.SessionWrapper> sessionWrapper = new AtomicReference<>();\n \n     try {\n \n       final String async = message.getStr(ASYNC);\n \n-      List<String> nodeList = new ArrayList<>();\n-      List<String> shardNames = new ArrayList<>();\n-      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n-          nodeList, shardNames, sessionWrapper);\n       ZkStateReader zkStateReader = ocmh.zkStateReader;\n       boolean isLegacyCloud = Overseer.isLegacy(zkStateReader);\n \n-      ocmh.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n+      OverseerCollectionMessageHandler.createConfNode(stateManager, configName, collectionName, isLegacyCloud);\n \n       Map<String,String> collectionParams = new HashMap<>();\n       Map<String,Object> collectionProps = message.getProperties();\n@@ -134,21 +158,25 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n           collectionParams.put(propName.substring(ZkController.COLLECTION_PARAM_PREFIX.length()), (String) collectionProps.get(propName));\n         }\n       }\n-      \n+\n       createCollectionZkNode(stateManager, collectionName, collectionParams);\n-      \n+\n       Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(message));\n \n-      // wait for a while until we don't see the collection\n+      // wait for a while until we see the collection\n       TimeOut waitUntil = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n       boolean created = false;\n       while (! waitUntil.hasTimedOut()) {\n         waitUntil.sleep(100);\n         created = ocmh.cloudManager.getClusterStateProvider().getClusterState().hasCollection(collectionName);\n         if(created) break;\n       }\n-      if (!created)\n+      if (!created) {\n         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Could not fully create collection: \" + collectionName);\n+      }\n+\n+      List<ReplicaPosition> replicaPositions = buildReplicaPositions(ocmh.cloudManager, clusterState, message,\n+          nodeList, shardNames, sessionWrapper);\n \n       if (nodeList.isEmpty()) {\n         log.debug(\"Finished create command for collection: {}\", collectionName);\n@@ -165,6 +193,23 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n       ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n       for (ReplicaPosition replicaPosition : replicaPositions) {\n         String nodeName = replicaPosition.node;\n+\n+        if (withCollection != null) {\n+          // check that we have a replica of `withCollection` on this node and if not, create one\n+          DocCollection collection = clusterState.getCollection(withCollection);\n+          List<Replica> replicas = collection.getReplicas(nodeName);\n+          if (replicas == null || replicas.isEmpty()) {\n+            ZkNodeProps props = new ZkNodeProps(\n+                Overseer.QUEUE_OPERATION, ADDREPLICA.toString(),\n+                ZkStateReader.COLLECTION_PROP, withCollection,\n+                ZkStateReader.SHARD_ID_PROP, withCollectionShard,\n+                \"node\", nodeName,\n+                CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.TRUE.toString()); // set to true because we want `withCollection` to be ready after this collection is created\n+            new AddReplicaCmd(ocmh).call(clusterState, props, results);\n+            clusterState = zkStateReader.getClusterState(); // refresh\n+          }\n+        }\n+\n         String coreName = Assign.buildSolrCoreName(ocmh.cloudManager.getDistribStateManager(),\n             ocmh.cloudManager.getClusterStateProvider().getClusterState().getCollection(collectionName),\n             replicaPosition.shard, replicaPosition.type, true);\n@@ -251,6 +296,16 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n               + \" curl http://{host:port}/solr/\" + collectionName + \"/config -d '{\\\"set-user-property\\\": {\\\"update.autoCreateFields\\\":\\\"false\\\"}}'\");\n         }\n       }\n+\n+      // modify the `withCollection` and store this new collection's name with it\n+      if (withCollection != null) {\n+        ZkNodeProps props = new ZkNodeProps(\n+            Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n+            ZkStateReader.COLLECTION_PROP, withCollection,\n+            CollectionAdminParams.COLOCATED_WITH, collectionName);\n+        Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(props));\n+      }\n+\n     } catch (SolrException ex) {\n       throw ex;\n     } catch (Exception ex) {\n@@ -274,29 +329,8 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n     String policy = message.getStr(Policy.POLICY);\n     boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n \n-    Integer numSlices = message.getInt(OverseerCollectionMessageHandler.NUM_SLICES, null);\n-    String router = message.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n-    if(ImplicitDocRouter.NAME.equals(router)){\n-      ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n-      numSlices = shardNames.size();\n-    } else {\n-      if (numSlices == null ) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, OverseerCollectionMessageHandler.NUM_SLICES + \" is a required param (when using CompositeId router).\");\n-      }\n-      if (numSlices <= 0) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, OverseerCollectionMessageHandler.NUM_SLICES + \" must be > 0\");\n-      }\n-      ClusterStateMutator.getShardNames(numSlices, shardNames);\n-    }\n-\n-    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n-    if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n-      throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n-    }\n-    if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n-    if (numNrtReplicas + numTlogReplicas <= 0) {\n-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n-    }\n+    Integer numSlices = shardNames.size();\n+    int maxShardsPerNode = checkMaxShardsPerNode(message, usePolicyFramework);\n \n     // we need to look at every node and see how many cores it serves\n     // add our new cores to existing nodes serving the least number of cores\n@@ -343,6 +377,43 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n     return replicaPositions;\n   }\n \n+  public static int checkMaxShardsPerNode(ZkNodeProps message, boolean usePolicyFramework) {\n+    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);\n+    if (usePolicyFramework && message.getStr(MAX_SHARDS_PER_NODE) != null && maxShardsPerNode > 0) {\n+      throw new SolrException(ErrorCode.BAD_REQUEST, \"'maxShardsPerNode>0' is not supported when autoScaling policies are used\");\n+    }\n+    if (maxShardsPerNode == -1 || usePolicyFramework) maxShardsPerNode = Integer.MAX_VALUE;\n+\n+    return maxShardsPerNode;\n+  }\n+\n+  public static void checkReplicaTypes(ZkNodeProps message) {\n+    int numTlogReplicas = message.getInt(TLOG_REPLICAS, 0);\n+    int numNrtReplicas = message.getInt(NRT_REPLICAS, message.getInt(REPLICATION_FACTOR, numTlogReplicas > 0 ? 0 : 1));\n+\n+    if (numNrtReplicas + numTlogReplicas <= 0) {\n+      throw new SolrException(ErrorCode.BAD_REQUEST, NRT_REPLICAS + \" + \" + TLOG_REPLICAS + \" must be greater than 0\");\n+    }\n+  }\n+\n+  public static List<String> populateShardNames(ZkNodeProps message, String router) {\n+    List<String> shardNames = new ArrayList<>();\n+    Integer numSlices = message.getInt(OverseerCollectionMessageHandler.NUM_SLICES, null);\n+    if (ImplicitDocRouter.NAME.equals(router)) {\n+      ClusterStateMutator.getShardNames(shardNames, message.getStr(\"shards\", null));\n+      numSlices = shardNames.size();\n+    } else {\n+      if (numSlices == null) {\n+        throw new SolrException(ErrorCode.BAD_REQUEST, OverseerCollectionMessageHandler.NUM_SLICES + \" is a required param (when using CompositeId router).\");\n+      }\n+      if (numSlices <= 0) {\n+        throw new SolrException(ErrorCode.BAD_REQUEST, OverseerCollectionMessageHandler.NUM_SLICES + \" must be > 0\");\n+      }\n+      ClusterStateMutator.getShardNames(numSlices, shardNames);\n+    }\n+    return shardNames;\n+  }\n+\n   String getConfigName(String coll, ZkNodeProps message) throws KeeperException, InterruptedException {\n     String configName = message.getStr(COLL_CONF);\n \n@@ -370,7 +441,7 @@ String getConfigName(String coll, ZkNodeProps message) throws KeeperException, I\n     }\n     return \"\".equals(configName)? null: configName;\n   }\n-  \n+\n   /**\n    * Copies the _default configset to the specified configset name (overwrites if pre-existing)\n    */\n@@ -476,7 +547,7 @@ public static void createCollectionZkNode(DistribStateManager stateManager, Stri\n     }\n \n   }\n-  \n+\n   private static void getConfName(DistribStateManager stateManager, String collection, String collectionPath, Map<String,Object> collectionProps) throws IOException,\n       KeeperException, InterruptedException {\n     // check for configName",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java",
                "sha": "45ced2b674dcc277138f8795c76b3fd14c506093",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteCollectionCmd.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteCollectionCmd.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteCollectionCmd.java",
                "patch": "@@ -31,6 +31,7 @@\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.cloud.Aliases;\n import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n import org.apache.solr.common.cloud.Replica;\n import org.apache.solr.common.cloud.SolrZkClient;\n import org.apache.solr.common.cloud.ZkNodeProps;\n@@ -49,6 +50,8 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import static org.apache.solr.common.params.CollectionAdminParams.COLOCATED_WITH;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETE;\n import static org.apache.solr.common.params.CommonAdminParams.ASYNC;\n import static org.apache.solr.common.params.CommonParams.NAME;\n@@ -69,6 +72,7 @@ public void call(ClusterState state, ZkNodeProps message, NamedList results) thr\n     ZkStateReader zkStateReader = ocmh.zkStateReader;\n \n     checkNotReferencedByAlias(zkStateReader, collection);\n+    checkNotColocatedWith(zkStateReader, collection);\n \n     final boolean deleteHistory = message.getBool(CoreAdminParams.DELETE_METRICS_HISTORY, true);\n \n@@ -181,4 +185,21 @@ private String referencedByAlias(String collection, Aliases aliases) {\n         .map(Map.Entry::getKey) // alias name\n         .findFirst().orElse(null);\n   }\n+\n+  private void checkNotColocatedWith(ZkStateReader zkStateReader, String collection) throws Exception {\n+    DocCollection docCollection = zkStateReader.getClusterState().getCollectionOrNull(collection);\n+    if (docCollection != null)  {\n+      String colocatedWith = docCollection.getStr(COLOCATED_WITH);\n+      if (colocatedWith != null) {\n+        DocCollection colocatedCollection = zkStateReader.getClusterState().getCollectionOrNull(colocatedWith);\n+        if (colocatedCollection != null && collection.equals(colocatedCollection.getStr(WITH_COLLECTION))) {\n+          // todo how do we clean up if reverse-link is not present?\n+          // can't delete this collection because it is still co-located with another collection\n+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+              \"Collection: \" + collection + \" is co-located with collection: \" + colocatedWith\n+                  + \" remove the link using modify collection API or delete the co-located collection: \" + colocatedWith);\n+        }\n+      }\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteCollectionCmd.java",
                "sha": "9a569d13d708b51773f75ba5d7c05a5bb0c1183e",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/MoveReplicaCmd.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/MoveReplicaCmd.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 12,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/MoveReplicaCmd.java",
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.solr.common.cloud.Slice;\n import org.apache.solr.common.cloud.ZkNodeProps;\n import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.common.params.CollectionAdminParams;\n import org.apache.solr.common.params.CollectionParams;\n import org.apache.solr.common.params.CoreAdminParams;\n import org.apache.solr.common.util.NamedList;\n@@ -104,19 +105,34 @@ private void moveReplica(ClusterState clusterState, ZkNodeProps message, NamedLi\n       if (shardId == null) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'\" + SHARD_ID_PROP + \"' is a required param\");\n       }\n-      Slice slice = clusterState.getCollection(collection).getSlice(shardId);\n-      List<Replica> sliceReplicas = new ArrayList<>(slice.getReplicas());\n-      Collections.shuffle(sliceReplicas, OverseerCollectionMessageHandler.RANDOM);\n-      // this picks up a single random replica from the sourceNode\n-      for (Replica r : slice.getReplicas()) {\n-        if (r.getNodeName().equals(sourceNode)) {\n-          replica = r;\n-        }\n-      }\n-      if (replica == null) {\n+      Slice slice = coll.getSlice(shardId);\n+      List<Replica> sliceReplicas = new ArrayList<>(slice.getReplicas(r -> sourceNode.equals(r.getNodeName())));\n+      if (sliceReplicas.isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Collection: \" + collection + \" node: \" + sourceNode + \" does not have any replica belonging to shard: \" + shardId);\n       }\n+      Collections.shuffle(sliceReplicas, OverseerCollectionMessageHandler.RANDOM);\n+      replica = sliceReplicas.iterator().next();\n+    }\n+\n+    if (coll.getStr(CollectionAdminParams.COLOCATED_WITH) != null) {\n+      // we must ensure that moving this replica does not cause the co-location to break\n+      String sourceNode = replica.getNodeName();\n+      String colocatedCollectionName = coll.getStr(CollectionAdminParams.COLOCATED_WITH);\n+      DocCollection colocatedCollection = clusterState.getCollectionOrNull(colocatedCollectionName);\n+      if (colocatedCollection != null) {\n+        if (colocatedCollection.getReplica((s, r) -> sourceNode.equals(r.getNodeName())) != null) {\n+          // check if we have at least two replicas of the collection on the source node\n+          // only then it is okay to move one out to another node\n+          List<Replica> replicasOnSourceNode = coll.getReplicas(replica.getNodeName());\n+          if (replicasOnSourceNode == null || replicasOnSourceNode.size() < 2) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"Collection: \" + collection + \" is co-located with collection: \" + colocatedCollectionName\n+                    + \" and has a single replica: \" + replica.getName() + \" on node: \" + replica.getNodeName()\n+                    + \" so it is not possible to move it to another node\");\n+          }\n+        }\n+      }\n     }\n \n     log.info(\"Replica will be moved to node {}: {}\", targetNode, replica);\n@@ -151,7 +167,7 @@ private void moveHdfsReplica(ClusterState clusterState, NamedList results, Strin\n       );\n       removeReplicasProps.getProperties().put(CoreAdminParams.DELETE_DATA_DIR, false);\n       removeReplicasProps.getProperties().put(CoreAdminParams.DELETE_INDEX, false);\n-      if(async!=null) removeReplicasProps.getProperties().put(ASYNC, async);\n+      if (async != null) removeReplicasProps.getProperties().put(ASYNC, async);\n       NamedList deleteResult = new NamedList();\n       ocmh.deleteReplica(clusterState, removeReplicasProps, deleteResult, null);\n       if (deleteResult.get(\"failure\") != null) {\n@@ -256,7 +272,7 @@ private void moveNormalReplica(ClusterState clusterState, NamedList results, Str\n     }\n     if (addResult.get(\"failure\") != null) {\n       String errorString = String.format(Locale.ROOT, \"Failed to create replica for collection=%s shard=%s\" +\n-          \" on node=%s, failure=\", coll.getName(), slice.getName(), targetNode, addResult.get(\"failure\"));\n+          \" on node=%s, failure=%s\", coll.getName(), slice.getName(), targetNode, addResult.get(\"failure\"));\n       log.warn(errorString);\n       results.add(\"failure\", errorString);\n       if (watcher != null) { // unregister",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/MoveReplicaCmd.java",
                "sha": "4a9bd599190e9c5eb5386e11d70f8bb33d6ceff3",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java",
                "patch": "@@ -105,6 +105,8 @@\n import static org.apache.solr.common.cloud.ZkStateReader.REPLICA_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;\n import static org.apache.solr.common.params.CollectionAdminParams.COLLECTION;\n+import static org.apache.solr.common.params.CollectionAdminParams.COLOCATED_WITH;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.*;\n import static org.apache.solr.common.params.CommonAdminParams.ASYNC;\n import static org.apache.solr.common.params.CommonParams.NAME;\n@@ -149,7 +151,9 @@\n       ZkStateReader.AUTO_ADD_REPLICAS, \"false\",\n       DocCollection.RULE, null,\n       POLICY, null,\n-      SNITCH, null));\n+      SNITCH, null,\n+      WITH_COLLECTION, null,\n+      COLOCATED_WITH, null));\n \n   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java",
                "sha": "e15c389906405f091dfe779c66e6e328e3845497",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 5,
                "filename": "solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java",
                "patch": "@@ -28,11 +28,11 @@\n import java.util.concurrent.atomic.AtomicInteger;\n \n import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.AutoScalingConfig;\n import org.apache.solr.client.solrj.cloud.autoscaling.NoneSuggester;\n import org.apache.solr.client.solrj.cloud.autoscaling.Policy;\n import org.apache.solr.client.solrj.cloud.autoscaling.PolicyHelper;\n-import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n import org.apache.solr.client.solrj.cloud.autoscaling.Suggester;\n import org.apache.solr.client.solrj.cloud.autoscaling.UnsupportedSuggester;\n import org.apache.solr.common.SolrException;\n@@ -89,8 +89,8 @@ public void process(TriggerEvent event, ActionContext context) throws Exception\n         log.trace(\"-- state: {}\", clusterState);\n       }\n       try {\n-        Suggester intialSuggester = getSuggester(session, event, context, cloudManager);\n-        Suggester suggester = intialSuggester;\n+        Suggester initialSuggester = getSuggester(session, event, context, cloudManager);\n+        Suggester suggester = initialSuggester;\n         int maxOperations = getMaxNumOps(event, autoScalingConf, clusterState);\n         int requestedOperations = getRequestedNumOps(event);\n         if (requestedOperations > maxOperations) {\n@@ -119,13 +119,13 @@ public void process(TriggerEvent event, ActionContext context) throws Exception\n           // unless a specific number of ops was requested\n           // uncomment the following to log too many operations\n           /*if (opCount > 10) {\n-            PolicyHelper.logState(cloudManager, intialSuggester);\n+            PolicyHelper.logState(cloudManager, initialSuggester);\n           }*/\n \n           if (operation == null) {\n             if (requestedOperations < 0) {\n               //uncomment the following to log zero operations\n-//              PolicyHelper.logState(cloudManager, intialSuggester);\n+//              PolicyHelper.logState(cloudManager, initialSuggester);\n               break;\n             } else {\n               log.info(\"Computed plan empty, remained \" + (opCount - opLimit) + \" requested ops to try.\");\n@@ -225,6 +225,7 @@ protected Suggester getSuggester(Policy.Session session, TriggerEvent event, Act\n         for (Map.Entry<Suggester.Hint, Object> e : op.getHints().entrySet()) {\n           suggester = suggester.hint(e.getKey(), e.getValue());\n         }\n+        suggester = suggester.forceOperation(true);\n         start++;\n         event.getProperties().put(START, start);\n         break;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java",
                "sha": "4cb15ead8758bf23d27be1c3ae5d19c08feb832a",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 5,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "patch": "@@ -104,7 +104,6 @@\n import static org.apache.solr.client.solrj.response.RequestStatusState.RUNNING;\n import static org.apache.solr.client.solrj.response.RequestStatusState.SUBMITTED;\n import static org.apache.solr.cloud.Overseer.QUEUE_OPERATION;\n-import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.COLL_PROP_PREFIX;\n import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.CREATE_NODE_SET;\n import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY;\n@@ -137,9 +136,11 @@\n import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.TLOG_REPLICAS;\n import static org.apache.solr.common.params.CollectionAdminParams.COLLECTION;\n+import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n import static org.apache.solr.common.params.CollectionAdminParams.COUNT_PROP;\n import static org.apache.solr.common.params.CollectionAdminParams.PROPERTY_NAME;\n import static org.apache.solr.common.params.CollectionAdminParams.PROPERTY_VALUE;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.*;\n import static org.apache.solr.common.params.CommonAdminParams.ASYNC;\n import static org.apache.solr.common.params.CommonAdminParams.IN_PLACE_MOVE;\n@@ -480,11 +481,10 @@ private static void addStatusToResponse(NamedList<Object> results, RequestStatus\n           TLOG_REPLICAS,\n           NRT_REPLICAS,\n           POLICY,\n-          WAIT_FOR_FINAL_STATE);\n+          WAIT_FOR_FINAL_STATE,\n+          WITH_COLLECTION);\n \n-      if (props.get(STATE_FORMAT) == null) {\n-        props.put(STATE_FORMAT, \"2\");\n-      }\n+      props.putIfAbsent(STATE_FORMAT, \"2\");\n \n       if (props.get(REPLICATION_FACTOR) != null && props.get(NRT_REPLICAS) != null) {\n         //TODO: Remove this in 8.0 . Keep this for SolrJ client back-compat. See SOLR-11676 for more details",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "sha": "8d7cdbf43c42bf1ed975cbf2df53bcfcc7b35129",
                "status": "modified"
            },
            {
                "additions": 611,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/test/org/apache/solr/cloud/TestWithCollection.java",
                "changes": 611,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/TestWithCollection.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/cloud/TestWithCollection.java",
                "patch": "@@ -0,0 +1,611 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.cloud;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.nio.charset.StandardCharsets;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.cloud.SolrCloudManager;\n+import org.apache.solr.client.solrj.embedded.JettySolrRunner;\n+import org.apache.solr.client.solrj.impl.CloudSolrClient;\n+import org.apache.solr.client.solrj.impl.HttpSolrClient;\n+import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n+import org.apache.solr.cloud.autoscaling.ActionContext;\n+import org.apache.solr.cloud.autoscaling.ComputePlanAction;\n+import org.apache.solr.cloud.autoscaling.ExecutePlanAction;\n+import org.apache.solr.cloud.autoscaling.TriggerActionBase;\n+import org.apache.solr.cloud.autoscaling.TriggerEvent;\n+import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n+import org.apache.solr.common.cloud.Replica;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.common.util.TimeSource;\n+import org.apache.solr.util.LogLevel;\n+import org.apache.solr.util.TimeOut;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.solr.cloud.autoscaling.AutoScalingHandlerTest.createAutoScalingRequest;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n+\n+/**\n+ * Tests for co-locating a collection with another collection such that any Collection API\n+ * always ensures that the co-location is never broken.\n+ *\n+ * See SOLR-11990 for more details.\n+ */\n+@LogLevel(\"org.apache.solr.cloud.autoscaling=TRACE;org.apache.solr.client.solrj.cloud.autoscaling=DEBUG\")\n+public class TestWithCollection extends SolrCloudTestCase {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  private static SolrCloudManager cloudManager;\n+\n+  private static final int NUM_JETTIES = 2;\n+\n+  @BeforeClass\n+  public static void setupCluster() throws Exception {\n+    configureCluster(NUM_JETTIES)\n+        .addConfig(\"conf\", configset(\"cloud-minimal\"))\n+        .configure();\n+  }\n+\n+  @Override\n+  public void setUp() throws Exception {\n+    super.setUp();\n+    if (zkClient().exists(ZkStateReader.SOLR_AUTOSCALING_CONF_PATH, true))  {\n+      zkClient().setData(ZkStateReader.SOLR_AUTOSCALING_CONF_PATH, \"{}\".getBytes(StandardCharsets.UTF_8), true);\n+    }\n+    ClusterState clusterState = cluster.getSolrClient().getZkStateReader().getClusterState();\n+    for (Map.Entry<String, ClusterState.CollectionRef> entry : clusterState.getCollectionStates().entrySet()) {\n+      if (entry.getKey().contains(\"_xyz\"))  {\n+        try {\n+          CollectionAdminRequest.deleteCollection(entry.getKey()).process(cluster.getSolrClient());\n+        } catch (Exception e) {\n+          log.error(\"Exception while deleting collection: \" + entry.getKey());\n+        }\n+      }\n+    }\n+    cluster.deleteAllCollections();\n+    cluster.getSolrClient().setDefaultCollection(null);\n+\n+    cloudManager = cluster.getJettySolrRunner(0).getCoreContainer().getZkController().getSolrCloudManager();\n+    deleteChildrenRecursively(ZkStateReader.SOLR_AUTOSCALING_EVENTS_PATH);\n+    deleteChildrenRecursively(ZkStateReader.SOLR_AUTOSCALING_TRIGGER_STATE_PATH);\n+    deleteChildrenRecursively(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n+    deleteChildrenRecursively(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n+    LATCH = new CountDownLatch(1);\n+\n+    int jettys = cluster.getJettySolrRunners().size();\n+    if (jettys < NUM_JETTIES) {\n+      for (int i = jettys; i < NUM_JETTIES; i++) {\n+        cluster.startJettySolrRunner();\n+      }\n+    } else  {\n+      for (int i = jettys; i > NUM_JETTIES; i--) {\n+        cluster.stopJettySolrRunner(i - 1);\n+      }\n+    }\n+  }\n+\n+  private void deleteChildrenRecursively(String path) throws Exception {\n+    cloudManager.getDistribStateManager().removeRecursively(path, true, false);\n+  }\n+\n+  @Test\n+  public void testCreateCollectionNoWithCollection() throws IOException, SolrServerException {\n+    String prefix = \"testCreateCollectionNoWithCollection\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+    try {\n+\n+      CollectionAdminRequest.createCollection(xyz, 1, 1)\n+          .setWithCollection(abc).process(solrClient);\n+    } catch (HttpSolrClient.RemoteSolrException e) {\n+      assertTrue(e.getMessage().contains(\"The 'withCollection' does not exist\"));\n+    }\n+\n+    CollectionAdminRequest.createCollection(abc, 2, 1)\n+        .process(solrClient);\n+    try {\n+      CollectionAdminRequest.createCollection(xyz, 1, 1)\n+          .setWithCollection(abc).process(solrClient);\n+    } catch (HttpSolrClient.RemoteSolrException e) {\n+      assertTrue(e.getMessage().contains(\"The `withCollection` must have only one shard, found: 2\"));\n+    }\n+  }\n+\n+  public void testCreateCollection() throws Exception {\n+    String prefix = \"testCreateCollection\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    DocCollection c1 = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(xyz);\n+    assertNotNull(c1);\n+    assertEquals(abc, c1.getStr(WITH_COLLECTION));\n+    Replica replica = c1.getReplicas().get(0);\n+    String nodeName = replica.getNodeName();\n+\n+    assertEquals(chosenNode, nodeName);\n+  }\n+\n+  @Test\n+  public void testDeleteWithCollection() throws IOException, SolrServerException, InterruptedException {\n+    String prefix = \"testDeleteWithCollection\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+    try {\n+      CollectionAdminRequest.deleteCollection(abc).process(solrClient);\n+    } catch (HttpSolrClient.RemoteSolrException e) {\n+      assertTrue(e.getMessage().contains(\"is co-located with collection\"));\n+    }\n+\n+    // delete the co-located collection first\n+    CollectionAdminRequest.deleteCollection(xyz).process(solrClient);\n+    // deleting the with collection should succeed now\n+    CollectionAdminRequest.deleteCollection(abc).process(solrClient);\n+\n+    xyz = xyz + \"_2\";\n+    abc = abc + \"_2\";\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+    // sanity check\n+    try {\n+      CollectionAdminRequest.deleteCollection(abc).process(solrClient);\n+    } catch (HttpSolrClient.RemoteSolrException e) {\n+      assertTrue(e.getMessage().contains(\"is co-located with collection\"));\n+    }\n+\n+    CollectionAdminRequest.modifyCollection(xyz, null)\n+        .unsetAttribute(\"withCollection\")\n+        .process(solrClient);\n+    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n+    while (!timeOut.hasTimedOut()) {\n+      DocCollection c1 = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(xyz);\n+      if (c1.getStr(\"withCollection\") == null) break;\n+      Thread.sleep(200);\n+    }\n+    DocCollection c1 = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(xyz);\n+    assertNull(c1.getStr(\"withCollection\"));\n+    CollectionAdminRequest.deleteCollection(abc).process(solrClient);\n+  }\n+\n+  @Test\n+  public void testAddReplicaSimple() throws Exception {\n+    String prefix = \"testAddReplica\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    String otherNode = null;\n+    for (JettySolrRunner jettySolrRunner : cluster.getJettySolrRunners()) {\n+      if (!chosenNode.equals(jettySolrRunner.getNodeName())) {\n+        otherNode = jettySolrRunner.getNodeName();\n+      }\n+    }\n+    CollectionAdminRequest.addReplicaToShard(xyz, \"shard1\")\n+        .setNode(otherNode)\n+        .process(solrClient);\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    assertTrue(collection.getReplicas().stream().noneMatch(replica -> withCollection.getReplicas(replica.getNodeName()).isEmpty()));\n+  }\n+\n+  public void testAddReplicaWithPolicy() throws Exception {\n+    String prefix = \"testAddReplicaWithPolicy\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"      {'replica':'<2', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    assertEquals(chosenNode, collection.getReplicas().iterator().next().getNodeName());\n+\n+//    zkClient().printLayoutToStdOut();\n+\n+    CollectionAdminRequest.addReplicaToShard(xyz, \"shard1\")\n+        .process(solrClient);\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    assertTrue(collection.getReplicas().stream().noneMatch(\n+        replica -> withCollection.getReplicas(replica.getNodeName()) == null\n+            || withCollection.getReplicas(replica.getNodeName()).isEmpty()));\n+  }\n+\n+  @Test\n+  public void testMoveReplicaMainCollection() throws Exception {\n+    String prefix = \"testMoveReplicaMainCollection\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"      {'replica':'<2', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    String otherNode = null;\n+    for (JettySolrRunner jettySolrRunner : cluster.getJettySolrRunners()) {\n+      if (!chosenNode.equals(jettySolrRunner.getNodeName())) {\n+        otherNode = jettySolrRunner.getNodeName();\n+      }\n+    }\n+\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+    assertNull(collection.getReplicas(otherNode)); // sanity check\n+    assertNull(withCollection.getReplicas(otherNode)); // sanity check\n+\n+    new CollectionAdminRequest.MoveReplica(xyz, collection.getReplicas().iterator().next().getName(), otherNode)\n+        .process(solrClient);\n+//    zkClient().printLayoutToStdOut();\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz); // refresh\n+    DocCollection withCollectionRefreshed = solrClient.getZkStateReader().getClusterState().getCollection(abc); // refresh\n+    assertTrue(collection.getReplicas().stream().noneMatch(\n+        replica -> withCollectionRefreshed.getReplicas(replica.getNodeName()) == null\n+            || withCollectionRefreshed.getReplicas(replica.getNodeName()).isEmpty()));\n+  }\n+\n+  @Test\n+  public void testMoveReplicaWithCollection() throws Exception {\n+    String prefix = \"testMoveReplicaWithCollection\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"      {'replica':'<2', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    assertEquals(chosenNode, collection.getReplicas().iterator().next().getNodeName());\n+\n+    String otherNode = null;\n+    for (JettySolrRunner jettySolrRunner : cluster.getJettySolrRunners()) {\n+      if (!chosenNode.equals(jettySolrRunner.getNodeName())) {\n+        otherNode = jettySolrRunner.getNodeName();\n+      }\n+    }\n+\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+    assertNull(collection.getReplicas(otherNode)); // sanity check\n+    assertNull(withCollection.getReplicas(otherNode)); // sanity check\n+\n+    try {\n+      new CollectionAdminRequest.MoveReplica(abc, collection.getReplicas().iterator().next().getName(), otherNode)\n+          .process(solrClient);\n+      fail(\"Expected moving a replica of 'withCollection': \" + abc + \" to fail\");\n+    } catch (HttpSolrClient.RemoteSolrException e) {\n+      assertTrue(e.getMessage().contains(\"Collection: testMoveReplicaWithCollection_abc is co-located with collection: testMoveReplicaWithCollection_xyz\"));\n+    }\n+//    zkClient().printLayoutToStdOut();\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz); // refresh\n+    DocCollection withCollectionRefreshed = solrClient.getZkStateReader().getClusterState().getCollection(abc); // refresh\n+\n+    // sanity check that the failed move operation didn't actually change our co-location guarantees\n+    assertTrue(collection.getReplicas().stream().noneMatch(\n+        replica -> withCollectionRefreshed.getReplicas(replica.getNodeName()) == null\n+            || withCollectionRefreshed.getReplicas(replica.getNodeName()).isEmpty()));\n+  }\n+\n+  /**\n+   * Tests that when a new node is added to the cluster and autoscaling framework\n+   * moves replicas to the new node, we maintain all co-locating guarantees\n+   */\n+  public void testNodeAdded() throws Exception  {\n+    String prefix = \"testNodeAdded\";\n+    String xyz = prefix + \"_xyz\";\n+    String abc = prefix + \"_abc\";\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"      {'replica':'<2', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getRandomJetty(random()).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode) // randomize to avoid choosing the first node always\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    assertEquals(chosenNode, collection.getReplicas().iterator().next().getNodeName());\n+\n+    String setTriggerCommand = \"{\" +\n+        \"'set-trigger' : {\" +\n+        \"'name' : 'node_added_trigger1',\" +\n+        \"'event' : 'nodeAdded',\" +\n+        \"'waitFor' : '0s',\" +\n+        \"'actions' : [\" +\n+        \"{'name' : 'compute', 'class' : '\" + ComputePlanAction.class.getName() + \"'}\" +\n+        \"{'name' : 'execute', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}\" +\n+        \"{'name' : 'compute', 'class' : '\" + CapturingAction.class.getName() + \"'}\" +\n+        \"]\" +\n+        \"}}\";\n+    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n+    solrClient.request(req);\n+\n+    Optional<JettySolrRunner> other = cluster.getJettySolrRunners()\n+        .stream().filter(j -> !chosenNode.equals(j.getNodeName())).findAny();\n+    String otherNode = other.orElseThrow(AssertionError::new).getNodeName();\n+\n+    // add an extra replica of abc collection on a different node\n+    CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(abc, \"shard1\")\n+        .setNode(otherNode);\n+    addReplica.setWaitForFinalState(true);\n+    addReplica.process(solrClient);\n+\n+    // refresh\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    // sanity check\n+    assertColocated(collection, otherNode, withCollection);\n+\n+    assertEquals(1, collection.getReplicas().size());\n+    Replica xyzReplica = collection.getReplicas().get(0);\n+\n+    // start a new node\n+    JettySolrRunner newNode = cluster.startJettySolrRunner();\n+    assertTrue(\"Action was not fired till 30 seconds\", LATCH.await(30, TimeUnit.SECONDS));\n+    // refresh\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    // sanity check\n+    assertColocated(collection, otherNode, withCollection);\n+\n+    // assert that the replica of xyz collection was not moved\n+    assertNotNull(collection.getReplica(xyzReplica.getName()));\n+    assertEquals(chosenNode, collection.getReplicas().get(0).getNodeName());\n+\n+    // add an extra replica of xyz collection -- this should be placed on the 'otherNode'\n+    addReplica = CollectionAdminRequest.addReplicaToShard(xyz, \"shard1\");\n+    addReplica.setWaitForFinalState(true);\n+    addReplica.process(solrClient);\n+\n+    // refresh\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    List<Replica> replicas = collection.getReplicas(otherNode);\n+    assertNotNull(replicas);\n+    assertEquals(1, replicas.size());\n+    replicas = withCollection.getReplicas(otherNode);\n+    assertNotNull(replicas);\n+    assertEquals(1, replicas.size());\n+\n+    // add an extra replica of xyz collection -- this should be placed on the 'newNode'\n+    addReplica = CollectionAdminRequest.addReplicaToShard(xyz, \"shard1\");\n+    addReplica.setWaitForFinalState(true);\n+    addReplica.process(solrClient);\n+\n+    // refresh\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+\n+    assertNotNull(collection.getReplicas(newNode.getNodeName()));\n+    replicas = collection.getReplicas(newNode.getNodeName());\n+    assertNotNull(replicas);\n+    assertEquals(1, replicas.size());\n+    replicas = withCollection.getReplicas(newNode.getNodeName());\n+    assertNotNull(replicas);\n+    assertEquals(1, replicas.size());\n+  }\n+\n+  public void testMultipleWithCollections() throws Exception {\n+    String prefix = \"testMultipleWithCollections\";\n+    String xyz = prefix + \"_xyz\";\n+    String xyz2 = prefix + \"_xyz2\";\n+    String abc = prefix + \"_abc\";\n+    String abc2 = prefix + \"_abc2\";\n+\n+    // start 2 more nodes so we have 4 in total\n+    cluster.startJettySolrRunner();\n+    cluster.startJettySolrRunner();\n+    cluster.waitForAllNodes(30);\n+\n+    CloudSolrClient solrClient = cluster.getSolrClient();\n+\n+    String setClusterPolicyCommand = \"{\" +\n+        \" 'set-cluster-policy': [\" +\n+        \"      {'cores':'<10', 'node':'#ANY'},\" +\n+        \"      {'replica':'<2', 'node':'#ANY'},\" +\n+        \"    ]\" +\n+        \"}\";\n+    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setClusterPolicyCommand);\n+    solrClient.request(req);\n+\n+    String chosenNode = cluster.getJettySolrRunner(0).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode, abc);\n+\n+    CollectionAdminRequest.createCollection(abc, 1, 1)\n+        .setCreateNodeSet(chosenNode)\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz, 1, 1)\n+        .setWithCollection(abc)\n+        .process(solrClient);\n+\n+    String chosenNode2 = cluster.getJettySolrRunner(1).getNodeName();\n+    log.info(\"Chosen node {} for collection {}\", chosenNode2, abc2);\n+    CollectionAdminRequest.createCollection(abc2, 1, 1)\n+        .setCreateNodeSet(chosenNode2)\n+        .process(solrClient);\n+    CollectionAdminRequest.createCollection(xyz2, 1, 1)\n+        .setWithCollection(abc2)\n+        .process(solrClient);\n+\n+    // refresh\n+    DocCollection collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    DocCollection collection2 = solrClient.getZkStateReader().getClusterState().getCollection(xyz2);\n+    DocCollection withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+    DocCollection withCollection2 = solrClient.getZkStateReader().getClusterState().getCollection(abc2);\n+\n+    // sanity check\n+    assertColocated(collection, chosenNode2, withCollection); // no replica should be on chosenNode2\n+    assertColocated(collection2, chosenNode, withCollection2); // no replica should be on chosenNode\n+\n+    String chosenNode3 = cluster.getJettySolrRunner(2).getNodeName();\n+    CollectionAdminRequest.addReplicaToShard(xyz, \"shard1\")\n+        .setNode(chosenNode3)\n+        .process(solrClient);\n+    String chosenNode4 = cluster.getJettySolrRunner(2).getNodeName();\n+    CollectionAdminRequest.addReplicaToShard(xyz2, \"shard1\")\n+        .setNode(chosenNode4)\n+        .process(solrClient);\n+\n+    collection = solrClient.getZkStateReader().getClusterState().getCollection(xyz);\n+    collection2 = solrClient.getZkStateReader().getClusterState().getCollection(xyz2);\n+    withCollection = solrClient.getZkStateReader().getClusterState().getCollection(abc);\n+    withCollection2 = solrClient.getZkStateReader().getClusterState().getCollection(abc2);\n+\n+    // sanity check\n+    assertColocated(collection, null, withCollection);\n+    assertColocated(collection2, null, withCollection2);\n+  }\n+\n+  /**\n+   * Asserts that all replicas of collection are colocated with at least one\n+   * replica of the withCollection and none of them should be on the given 'noneOnNode'.\n+   */\n+  private void assertColocated(DocCollection collection, String noneOnNode, DocCollection withCollection) {\n+    // sanity check\n+    assertTrue(collection.getReplicas().stream().noneMatch(\n+        replica -> withCollection.getReplicas(replica.getNodeName()) == null\n+            || withCollection.getReplicas(replica.getNodeName()).isEmpty()));\n+\n+    if (noneOnNode != null) {\n+      assertTrue(collection.getReplicas().stream().noneMatch(\n+          replica -> noneOnNode.equals(replica.getNodeName())));\n+    }\n+  }\n+\n+  private static CountDownLatch LATCH = new CountDownLatch(1);\n+  public static class CapturingAction extends TriggerActionBase {\n+    @Override\n+    public void process(TriggerEvent event, ActionContext context) throws Exception {\n+      LATCH.countDown();\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/test/org/apache/solr/cloud/TestWithCollection.java",
                "sha": "a4816a01b56d9bdd12b43ca2370d472834349253",
                "status": "added"
            },
            {
                "additions": 69,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "changes": 71,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 2,
                "filename": "solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "patch": "@@ -42,6 +42,7 @@\n \n import org.apache.solr.client.solrj.cloud.autoscaling.AutoScalingConfig;\n import org.apache.solr.client.solrj.cloud.DistribStateManager;\n+import org.apache.solr.client.solrj.cloud.autoscaling.Policy;\n import org.apache.solr.client.solrj.cloud.autoscaling.PolicyHelper;\n import org.apache.solr.client.solrj.cloud.autoscaling.ReplicaInfo;\n import org.apache.solr.client.solrj.cloud.autoscaling.Suggestion;\n@@ -92,6 +93,7 @@\n import static org.apache.solr.common.cloud.ZkStateReader.REPLICA_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;\n import static org.apache.solr.common.cloud.ZkStateReader.TLOG_REPLICAS;\n+import static org.apache.solr.common.params.CollectionParams.CollectionAction.MODIFYCOLLECTION;\n import static org.apache.solr.common.params.CommonParams.NAME;\n \n /**\n@@ -680,11 +682,37 @@ public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exc\n     }\n     boolean waitForFinalState = props.getBool(CommonAdminParams.WAIT_FOR_FINAL_STATE, false);\n     List<String> nodeList = new ArrayList<>();\n-    List<String> shardNames = new ArrayList<>();\n     final String collectionName = props.getStr(NAME);\n+\n+    String router = props.getStr(\"router.name\", DocRouter.DEFAULT_NAME);\n+    String policy = props.getStr(Policy.POLICY);\n+    AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n+    boolean usePolicyFramework = !autoScalingConfig.getPolicy().getClusterPolicy().isEmpty() || policy != null;\n+\n+    // fail fast if parameters are wrong or incomplete\n+    List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);\n+    CreateCollectionCmd.checkMaxShardsPerNode(props, usePolicyFramework);\n+    CreateCollectionCmd.checkReplicaTypes(props);\n+\n     // always force getting fresh state\n     collectionsStatesRef.set(null);\n-    ClusterState clusterState = getClusterState();\n+    final ClusterState clusterState = getClusterState();\n+\n+    String withCollection = props.getStr(CollectionAdminParams.WITH_COLLECTION);\n+    String wcShard = null;\n+    if (withCollection != null) {\n+      if (!clusterState.hasCollection(withCollection)) {\n+        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The 'withCollection' does not exist: \" + withCollection);\n+      } else  {\n+        DocCollection collection = clusterState.getCollection(withCollection);\n+        if (collection.getActiveSlices().size() > 1)  {\n+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The `withCollection` must have only one shard, found: \" + collection.getActiveSlices().size());\n+        }\n+        wcShard = collection.getActiveSlices().iterator().next().getName();\n+      }\n+    }\n+    final String withCollectionShard = wcShard;\n+\n     ZkWriteCommand cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);\n     if (cmd.noop) {\n       LOG.warn(\"Collection {} already exists. exit\", collectionName);\n@@ -710,6 +738,35 @@ public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exc\n     final CountDownLatch finalStateLatch = new CountDownLatch(replicaPositions.size());\n     AtomicInteger replicaNum = new AtomicInteger(1);\n     replicaPositions.forEach(pos -> {\n+\n+      if (withCollection != null) {\n+        // check that we have a replica of `withCollection` on this node and if not, create one\n+        DocCollection collection = clusterState.getCollection(withCollection);\n+        List<Replica> replicas = collection.getReplicas(pos.node);\n+        if (replicas == null || replicas.isEmpty()) {\n+          Map<String, Object> replicaProps = new HashMap<>();\n+          replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n+          replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n+          String coreName = String.format(Locale.ROOT, \"%s_%s_replica_%s%s\", withCollection, withCollectionShard, pos.type.name().substring(0,1).toLowerCase(Locale.ROOT),\n+              collection.getReplicas().size() + 1);\n+          try {\n+            replicaProps.put(ZkStateReader.CORE_NAME_PROP, coreName);\n+            replicaProps.put(\"SEARCHER.searcher.deletedDocs\", 0);\n+            replicaProps.put(\"SEARCHER.searcher.numDocs\", 0);\n+            replicaProps.put(\"SEARCHER.searcher.maxDoc\", 0);\n+            ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, withCollection, 0),\n+                coreName, withCollection, withCollectionShard, pos.type, pos.node, replicaProps);\n+            cloudManager.submit(() -> {\n+              simAddReplica(pos.node, ri, false);\n+              // do not count down the latch here\n+              return true;\n+            });\n+          } catch (Exception e) {\n+            throw new RuntimeException(e);\n+          }\n+        }\n+      }\n+\n       Map<String, Object> replicaProps = new HashMap<>();\n       replicaProps.put(ZkStateReader.NODE_NAME_PROP, pos.node);\n       replicaProps.put(ZkStateReader.REPLICA_TYPE, pos.type.toString());\n@@ -744,6 +801,16 @@ public void simCreateCollection(ZkNodeProps props, NamedList results) throws Exc\n         }\n       });\n     });\n+\n+    // modify the `withCollection` and store this new collection's name with it\n+    if (withCollection != null) {\n+      ZkNodeProps message = new ZkNodeProps(\n+          Overseer.QUEUE_OPERATION, MODIFYCOLLECTION.toString(),\n+          ZkStateReader.COLLECTION_PROP, withCollection,\n+          CollectionAdminParams.COLOCATED_WITH, collectionName);\n+      cmd = new CollectionMutator(cloudManager).modifyCollection(clusterState,message);\n+    }\n+\n     // force recreation of collection states\n     collectionsStatesRef.set(null);\n     simRunLeaderElection(Collections.singleton(collectionName), true);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "sha": "6024790a3a18bdf9f40209c16b4a3dcf80d480b3",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/collections-api.adoc",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/collections-api.adoc?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/collections-api.adoc",
                "patch": "@@ -112,6 +112,11 @@ Details of the snitch provider. See the section <<rule-based-replica-placement.a\n `waitForFinalState`::\n If `true`, the request will complete only when all affected replicas become active. The default is `false`, which means that the API will return the status of the single action, which may be before the new replica is online and active.\n \n+`withCollection`::\n+The name of the collection with which all replicas of this collection must be co-located. The collection must already exist and must have a single shard named `shard1`.\n+See <<colocating-collections.adoc#colocating-collections, Colocating collections>> for more details.\n+\n+\n === CREATE Response\n \n The response will include the status of the request and the new core names. If the status is anything other than \"success\", an error message will explain why the request failed.\n@@ -181,6 +186,7 @@ The attributes that can be modified are:\n * rule\n * snitch\n * policy\n+* withCollection\n \n See the <<create,CREATE action>> section above for details on these attributes.\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/collections-api.adoc",
                "sha": "527f4c7c9c522a3642baa1ac549a8d16e948c3a3",
                "status": "modified"
            },
            {
                "additions": 76,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/colocating-collections.adoc",
                "changes": 76,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/colocating-collections.adoc?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/colocating-collections.adoc",
                "patch": "@@ -0,0 +1,76 @@\n+= Colocating Collections\n+:page-toclevels: 1\n+:page-tocclass: right\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+Solr provides a way to co-locate a collection with another so that cross-collection joins are always possible.\n+\n+The co-location guarantee applies to all future Collection operations made either via Collections API or by Autoscaling\n+actions.\n+\n+A collection may only be colocated with exactly one `withCollection`. However, arbitrarily many collections may be\n+_linked_ to the same `withCollection`.\n+\n+== Create Collection using `withCollection`\n+The Create Collection API supports a parameter named `withCollection` which can be used to specify a collection\n+with which the replicas of the newly created collection should be co-located. See <<collections-api.adoc#create, Create Collection API>>\n+\n+`/admin/collections?action=CREATE&name=techproducts&numShards=1&replicationFactor=2&withCollection=tech_categories`\n+\n+In the above example, all replicas of the `techproducts` collection will be co-located on a node with at least one\n+replica of the `tech_categories` collection.\n+\n+== Colocating existing collections\n+When collections already exist beforehand, the <<collections-api.adoc#modifycollection, Modify Collection API>> can be\n+used to set the `withCollection` parameter so that the two collections can be linked. This will *not* trigger\n+changes to the cluster automatically because moving a large number of replicas immediately might de-stabilize the system.\n+Instead, it is recommended that the Suggestions UI page should be consulted on the operations that can be performed\n+to change the cluster manually.\n+\n+Example:\n+`/admin/collections?action=MODIFYCOLLECTION&collection=techproducts&withCollection=tech_categories`\n+\n+== Deleting colocated collections\n+Deleting a collection which has been linked to another will fail unless the link itself is deleted first by using the\n+<<collections-api.adoc#modifycollection, Modify Collection API>> to un-set the `withCollection` attribute.\n+\n+Example:\n+`/admin/collections?action=MODIFYCOLLECTION&collection=techproducts&withCollection=`\n+\n+== Limitations and caveats\n+\n+The collection being used as the `withCollection` must have one shard only and that shard should be named `shard1`. Note\n+that when using the default router, the shard name is always set to `shard1` but special care must be taken to name the\n+shard as `shard1` when using the implicit router.\n+\n+In case new replicas of the `withCollection` have to be added to maintain the co-location guarantees then the new replicas\n+will be of type `NRT` only. Automatically creating replicas of `TLOG` or `PULL` types is not supported.\n+\n+In case, replicas have to be moved from one node to another, perhaps in response to a node lost trigger, then the target\n+nodes will be chosen by preferring nodes that already have a replica of the `withCollection` so that the number of moves\n+is minimized. However, this also means that unless there are Autoscaling policy violations, Solr will continue to move\n+such replicas to already loaded nodes instead of preferring empty nodes. Therefore, it is advised to have policy rules\n+which can prevent such overloading by e.g. setting the maximum number of cores per node to a fixed value.\n+\n+Example:\n+`{'cores' : '<8', 'node' : '#ANY'}`\n+\n+The co-location guarantee is one-way only i.e. a collection 'X' co-located with 'Y' will always have one or more\n+replicas of 'Y' on any node that has a replica of 'X' but the reverse is not true. There may be nodes which have one or\n+more replicas of 'Y' but no replicas of 'X'. Such replicas of 'Y' will not be considered a violation of co-location\n+rules and will not be cleaned up automatically.\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/colocating-collections.adoc",
                "sha": "cc6b5184b6e39a3a4fa2a42330b221e8d8e27b1f",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/solrcloud.adoc",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/solrcloud.adoc?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 1,
                "filename": "solr/solr-ref-guide/src/solrcloud.adoc",
                "patch": "@@ -1,5 +1,5 @@\n = SolrCloud\n-:page-children: getting-started-with-solrcloud, how-solrcloud-works, solrcloud-resilience, solrcloud-configuration-and-parameters, rule-based-replica-placement, cross-data-center-replication-cdcr, solrcloud-autoscaling\n+:page-children: getting-started-with-solrcloud, how-solrcloud-works, solrcloud-resilience, solrcloud-configuration-and-parameters, rule-based-replica-placement, cross-data-center-replication-cdcr, solrcloud-autoscaling, colocating-collections\n // Licensed to the Apache Software Foundation (ASF) under one\n // or more contributor license agreements.  See the NOTICE file\n // distributed with this work for additional information\n@@ -46,3 +46,4 @@ In this section, we'll cover everything you need to know about using Solr in Sol\n * <<rule-based-replica-placement.adoc#rule-based-replica-placement,Rule-based Replica Placement>>\n * <<cross-data-center-replication-cdcr.adoc#cross-data-center-replication-cdcr,Cross Data Center Replication (CDCR)>>\n * <<solrcloud-autoscaling.adoc#solrcloud-autoscaling,SolrCloud Autoscaling>>\n+* <<colocating-collections.adoc#colocating-collections,Colocating collections together>>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solr-ref-guide/src/solrcloud.adoc",
                "sha": "7e611225434aa8002acf68bea75dbb1ff5059f68",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/AddReplicaSuggester.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/AddReplicaSuggester.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 2,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/AddReplicaSuggester.java",
                "patch": "@@ -50,7 +50,7 @@ SolrRequest tryEachNode(boolean strict) {\n       for (int i = getMatrix().size() - 1; i >= 0; i--) {\n         Row row = getMatrix().get(i);\n         if (!isNodeSuitableForReplicaAddition(row)) continue;\n-        Row tmpRow = row.addReplica(shard.first(), shard.second(), type);\n+        Row tmpRow = row.addReplica(shard.first(), shard.second(), type, strict);\n         List<Violation> errs = testChangedMatrix(strict, tmpRow.session);\n \n         if (!containsNewErrors(errs)) {\n@@ -77,4 +77,4 @@ SolrRequest tryEachNode(boolean strict) {\n   public CollectionParams.CollectionAction getAction() {\n     return ADDREPLICA;\n   }\n-}\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/AddReplicaSuggester.java",
                "sha": "2a31e710e738be18aed3e25a3ae0f0cfd9f94680",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Clause.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Clause.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 8,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Clause.java",
                "patch": "@@ -38,7 +38,6 @@\n import org.apache.solr.common.util.Utils;\n \n import static java.util.Collections.singletonMap;\n-import static org.apache.solr.client.solrj.cloud.autoscaling.Clause.TestStatus.PASS;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Operand.EQUAL;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Operand.GREATER_THAN;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Operand.LESS_THAN;\n@@ -75,6 +74,17 @@ protected Clause(Clause clause, Function<Condition, Object> computedValueEvaluat\n     this.strict = clause.strict;\n   }\n \n+  // internal use only\n+  Clause(Map<String, Object> original, Condition tag, Condition globalTag, boolean isStrict)  {\n+    this.original = original;\n+    this.tag = tag;\n+    this.globalTag = globalTag;\n+    this.globalTag.clause = this;\n+    this.type = null;\n+    this.hasComputedValue = false;\n+    this.strict = isStrict;\n+  }\n+\n   private Clause(Map<String, Object> m) {\n     this.original = Utils.getDeepCopy(m, 10);\n     String type = (String) m.get(\"type\");\n@@ -374,7 +384,7 @@ private Operand getOperand(String strVal) {\n       for (Row r : session.matrix) {\n         SealedClause sealedClause = getSealedClause(computedValueEvaluator);\n         if (!sealedClause.getGlobalTag().isPass(r)) {\n-          ConditionType.CORES.addViolatingReplicas(ctx.reset(null, null,\n+          sealedClause.getGlobalTag().varType.addViolatingReplicas(ctx.reset(null, null,\n               new Violation(sealedClause, null, null, r.node, r.getVal(sealedClause.globalTag.name), sealedClause.globalTag.delta(r.getVal(globalTag.name)), null)));\n         }\n       }\n@@ -553,21 +563,21 @@ public Clause getClause() {\n     }\n \n     boolean isPass(Object inputVal) {\n+      return isPass(inputVal, null);\n+    }\n+\n+    boolean isPass(Object inputVal, Row row) {\n       if (computedType != null) {\n         throw new IllegalStateException(\"This is supposed to be called only from a Condition with no computed value or a SealedCondition\");\n \n       }\n       if (inputVal instanceof ReplicaCount) inputVal = ((ReplicaCount) inputVal).getVal(getClause().type);\n-      if (varType == ConditionType.LAZY) { // we don't know the type\n-        return op.match(parseString(val), parseString(inputVal)) == PASS;\n-      } else {\n-        return op.match(val, validate(name, inputVal, false)) == PASS;\n-      }\n+      return varType.match(inputVal, op, val, name, row);\n     }\n \n \n     boolean isPass(Row row) {\n-      return isPass(row.getVal(name));\n+      return isPass(row.getVal(name), row);\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Clause.java",
                "sha": "8fd815e3ba0db999a44eb56406d1dc5180480a4b",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/MoveReplicaSuggester.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/MoveReplicaSuggester.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 9,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/MoveReplicaSuggester.java",
                "patch": "@@ -17,17 +17,21 @@\n \n package org.apache.solr.client.solrj.cloud.autoscaling;\n \n+import java.lang.invoke.MethodHandles;\n import java.util.Comparator;\n import java.util.List;\n \n import org.apache.solr.client.solrj.SolrRequest;\n import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n import org.apache.solr.common.params.CollectionParams;\n import org.apache.solr.common.util.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import static org.apache.solr.common.params.CollectionParams.CollectionAction.MOVEREPLICA;\n \n public class MoveReplicaSuggester extends Suggester {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n \n   @Override\n   SolrRequest init() {\n@@ -56,20 +60,28 @@ SolrRequest tryEachNode(boolean strict) {\n         targetRow = session.matrix.get(j);\n         if (targetRow.node.equals(fromRow.node)) continue;\n         if (!isNodeSuitableForReplicaAddition(targetRow)) continue;\n-        targetRow = targetRow.addReplica(ri.getCollection(), ri.getShard(), ri.getType());//add replica to target first\n-        Pair<Row, ReplicaInfo> pair = targetRow.session.getNode(fromRow.node).removeReplica(ri.getCollection(), ri.getShard(), ri.getType());//then remove replica from source node\n-        if (pair == null) continue;//should not happen\n-        Row srcRowModified = pair.first();//this is the final state of the source row and session\n+        targetRow = targetRow.addReplica(ri.getCollection(), ri.getShard(), ri.getType(), strict); // add replica to target first\n+        Row srcRowModified = targetRow.session.getNode(fromRow.node).removeReplica(ri.getCollection(), ri.getShard(), ri.getType());//then remove replica from source node\n         List<Violation> errs = testChangedMatrix(strict, srcRowModified.session);\n-        srcRowModified.session.applyRules();// now resort the nodes with the new values\n+        srcRowModified.session.applyRules(); // now resort the nodes with the new values\n         Policy.Session tmpSession = srcRowModified.session;\n+\n         if (!containsNewErrors(errs) &&\n             isLessSerious(errs, leastSeriousViolation) &&\n             (force || (tmpSession.indexOf(srcRowModified.node) < tmpSession.indexOf(targetRow.node)))) {\n-          leastSeriousViolation = errs;\n-          bestSrcRow = srcRowModified;\n-          sourceReplicaInfo = ri;\n-          bestTargetRow = targetRow;\n+\n+          int result = -1;\n+          if (!force && srcRowModified.isLive && targetRow.isLive)  {\n+            result = tmpSession.getPolicy().clusterPreferences.get(0).compare(srcRowModified, tmpSession.getNode(targetRow.node), true);\n+            if (result == 0) result = tmpSession.getPolicy().clusterPreferences.get(0).compare(srcRowModified, tmpSession.getNode(targetRow.node), false);\n+          }\n+\n+          if (result <= 0) {\n+            leastSeriousViolation = errs;\n+            bestSrcRow = srcRowModified;\n+            sourceReplicaInfo = ri;\n+            bestTargetRow = targetRow;\n+          }\n         }\n       }\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/MoveReplicaSuggester.java",
                "sha": "fffaee2c75e935b685f4c4b26151c9dd7b1bab76",
                "status": "modified"
            },
            {
                "additions": 35,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java",
                "changes": 38,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 3,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java",
                "patch": "@@ -44,6 +44,7 @@\n import org.apache.solr.common.MapWriter;\n import org.apache.solr.common.cloud.ClusterState;\n import org.apache.solr.common.cloud.rule.ImplicitSnitch;\n+import org.apache.solr.common.params.CollectionAdminParams;\n import org.apache.solr.common.params.CollectionParams.CollectionAction;\n import org.apache.solr.common.util.Pair;\n import org.apache.solr.common.util.StrUtils;\n@@ -55,6 +56,8 @@\n import static java.util.Collections.emptyMap;\n import static java.util.stream.Collectors.collectingAndThen;\n import static java.util.stream.Collectors.toList;\n+import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.NODE;\n+import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.WITH_COLLECTION;\n \n /*The class that reads, parses and applies policies specified in\n  * autoscaling.json\n@@ -74,7 +77,7 @@\n   public static final String POLICIES = \"policies\";\n   public static final String CLUSTER_POLICY = \"cluster-policy\";\n   public static final String CLUSTER_PREFERENCES = \"cluster-preferences\";\n-  public static final Set<String> GLOBAL_ONLY_TAGS = Collections.singleton(\"cores\");\n+  public static final Set<String> GLOBAL_ONLY_TAGS = Collections.unmodifiableSet(new HashSet<>(Arrays.asList(\"cores\", CollectionAdminParams.WITH_COLLECTION)));\n   public static final List<Preference> DEFAULT_PREFERENCES = Collections.unmodifiableList(\n       Arrays.asList(\n           new Preference((Map<String, Object>) Utils.fromJSONString(\"{minimize : cores, precision:1}\")),\n@@ -131,9 +134,12 @@ public Policy(Map<String, Object> jsonMap) {\n \n     this.policies = Collections.unmodifiableMap(\n         policiesFromMap((Map<String, List<Map<String, Object>>>) jsonMap.getOrDefault(POLICIES, emptyMap()), newParams));\n-    this.params = Collections.unmodifiableList(newParams.stream()\n+    List<Pair<String, Suggestion.ConditionType>> params = newParams.stream()\n         .map(s -> new Pair<>(s, Suggestion.getTagType(s)))\n-        .collect(toList()));\n+        .collect(toList());\n+    //let this be there always, there is no extra cost\n+    params.add(new Pair<>(WITH_COLLECTION.tagName, WITH_COLLECTION));\n+    this.params = Collections.unmodifiableList(params);\n     perReplicaAttributes = readPerReplicaAttrs();\n   }\n \n@@ -501,6 +507,21 @@ private Session(List<String> nodes, SolrCloudManager cloudManager,\n           .filter(clause -> !clause.isPerCollectiontag())\n           .collect(Collectors.toList());\n \n+      if (nodes.size() > 0) {\n+        //if any collection has 'withCollection' irrespective of the node, the NodeStateProvider returns a map value\n+        Map<String, Object> vals = nodeStateProvider.getNodeValues(nodes.get(0), Collections.singleton(\"withCollection\"));\n+        if (!vals.isEmpty() && vals.get(\"withCollection\") != null) {\n+          Map<String, String> withCollMap = (Map<String, String>) vals.get(\"withCollection\");\n+          if (!withCollMap.isEmpty()) {\n+            Clause withCollClause = new Clause((Map<String,Object>)Utils.fromJSONString(\"{withCollection:'*' , node: '#ANY'}\") ,\n+                new Clause.Condition(NODE.tagName, \"#ANY\", Operand.EQUAL, null, null),\n+                new Clause.Condition(WITH_COLLECTION.tagName,\"*\" , Operand.EQUAL, null, null), true\n+            );\n+            expandedClauses.add(withCollClause);\n+          }\n+        }\n+      }\n+\n       ClusterStateProvider stateProvider = cloudManager.getClusterStateProvider();\n       for (String c : collections) {\n         addClausesForCollection(stateProvider, c);\n@@ -594,4 +615,15 @@ public int indexOf(String node) {\n       throw new RuntimeException(\"NO such node found \" + node);\n     }\n   }\n+  static final Map<String, Suggestion.ConditionType> validatetypes = new HashMap<>();\n+  static {\n+    for (Suggestion.ConditionType t : Suggestion.ConditionType.values())\n+      validatetypes.put(t.tagName, t);\n+  }\n+  public static ConditionType getTagType(String name) {\n+    ConditionType info = validatetypes.get(name);\n+    if (info == null && name.startsWith(ImplicitSnitch.SYSPROP)) info = ConditionType.STRING;\n+    if (info == null && name.startsWith(Clause.METRICS_PREFIX)) info = ConditionType.LAZY;\n+    return info;\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java",
                "sha": "879bb74d50fbc8658046a700673e53d5e74e8c13",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/PolicyHelper.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/PolicyHelper.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 14,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/PolicyHelper.java",
                "patch": "@@ -93,7 +93,7 @@ public DistribStateManager getDistribStateManager() {\n         if (autoScalingConfig != null) {\n           return new DelegatingDistribStateManager(null) {\n             @Override\n-            public AutoScalingConfig getAutoScalingConfig() throws InterruptedException, IOException {\n+            public AutoScalingConfig getAutoScalingConfig() {\n               return autoScalingConfig;\n             }\n           };\n@@ -135,7 +135,7 @@ public AutoScalingConfig getAutoScalingConfig() throws InterruptedException, IOE\n           }\n         }\n       } catch (IOException e) {\n-        /*ignore*/\n+        log.warn(\"Exception while reading disk free metric values for nodes to be used for collection: \" + collName, e);\n       }\n \n \n@@ -178,7 +178,7 @@ public AutoScalingConfig getAutoScalingConfig() throws InterruptedException, IOE\n   }\n \n \n-  public static final int SESSION_EXPIRY = 180;//3 seconds\n+  public static final int SESSION_EXPIRY = 180; // 3 minutes\n \n   public static MapWriter getDiagnostics(Policy policy, SolrCloudManager cloudManager) {\n     Policy.Session session = policy.createSession(cloudManager);\n@@ -230,7 +230,7 @@ public static MapWriter getDiagnostics(Policy policy, SolrCloudManager cloudMana\n   /**Use this to dump the state of a system and to generate a testcase\n    */\n   public static void logState(SolrCloudManager cloudManager, Suggester suggester) {\n-    if(log.isTraceEnabled()) {\n+    if (log.isTraceEnabled()) {\n       log.trace(\"LOGSTATE: {}\",\n           Utils.toJSONString((MapWriter) ew -> {\n             ew.put(\"liveNodes\", cloudManager.getClusterStateProvider().getLiveNodes());\n@@ -249,9 +249,9 @@ public static void logState(SolrCloudManager cloudManager, Suggester suggester)\n \n   public enum Status {\n     NULL,\n-    //it is just created and not yet used or all operations on it has been competed fully\n+    //it is just created and not yet used or all operations on it has been completed fully\n     UNUSED,\n-    COMPUTING, EXECUTING;\n+    COMPUTING, EXECUTING\n   }\n \n   /**\n@@ -265,7 +265,7 @@ public static void logState(SolrCloudManager cloudManager, Suggester suggester)\n    */\n   static class SessionRef {\n     private final Object lockObj = new Object();\n-    private SessionWrapper sessionWrapper = SessionWrapper.DEF_INST;\n+    private SessionWrapper sessionWrapper = SessionWrapper.DEFAULT_INSTANCE;\n \n \n     public SessionRef() {\n@@ -286,7 +286,7 @@ private void release(SessionWrapper sessionWrapper) {\n       synchronized (lockObj) {\n         if (sessionWrapper.createTime == this.sessionWrapper.createTime && this.sessionWrapper.refCount.get() <= 0) {\n           log.debug(\"session set to NULL\");\n-          this.sessionWrapper = SessionWrapper.DEF_INST;\n+          this.sessionWrapper = SessionWrapper.DEFAULT_INSTANCE;\n         } // else somebody created a new session b/c of expiry . So no need to do anything about it\n       }\n     }\n@@ -311,7 +311,7 @@ private void returnSession(SessionWrapper sessionWrapper) {\n           //one thread who is waiting for this need to be notified.\n           lockObj.notify();\n         } else {\n-          log.info(\"create time NOT SAME {} \", SessionWrapper.DEF_INST.createTime);\n+          log.info(\"create time NOT SAME {} \", SessionWrapper.DEFAULT_INSTANCE.createTime);\n           //else just ignore it\n         }\n       }\n@@ -343,7 +343,7 @@ public SessionWrapper get(SolrCloudManager cloudManager) throws IOException, Int\n             }\n             log.debug(\"out of waiting curr-time:{} time-elapsed {}\", time(timeSource, MILLISECONDS), timeElapsed(timeSource, waitStart, MILLISECONDS));\n             // now this thread has woken up because it got timed out after 10 seconds or it is notified after\n-            //the session was returned from another COMPUTING operation\n+            // the session was returned from another COMPUTING operation\n             if (this.sessionWrapper.status == Status.UNUSED || this.sessionWrapper.status == Status.EXECUTING) {\n               log.debug(\"Wait over. reusing the existing session \");\n               this.sessionWrapper.status = Status.COMPUTING;\n@@ -401,12 +401,12 @@ public static SessionWrapper getLastSessionWrapper(boolean clear) {\n \n \n   public static class SessionWrapper {\n-    public static final SessionWrapper DEF_INST = new SessionWrapper(null, null);\n+    public static final SessionWrapper DEFAULT_INSTANCE = new SessionWrapper(null, null);\n \n     static {\n-      DEF_INST.status = Status.NULL;\n-      DEF_INST.createTime = -1l;\n-      DEF_INST.lastUpdateTime = -1l;\n+      DEFAULT_INSTANCE.status = Status.NULL;\n+      DEFAULT_INSTANCE.createTime = -1L;\n+      DEFAULT_INSTANCE.lastUpdateTime = -1L;\n     }\n \n     private long createTime;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/PolicyHelper.java",
                "sha": "ed2a3956fc90c4ea5ba908559d241a38fad80402",
                "status": "modified"
            },
            {
                "additions": 63,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Row.java",
                "changes": 69,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Row.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 6,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Row.java",
                "patch": "@@ -18,10 +18,12 @@\n package org.apache.solr.client.solrj.cloud.autoscaling;\n \n import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n import java.util.HashMap;\n+import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n import java.util.Random;\n@@ -33,13 +35,17 @@\n import org.apache.solr.common.cloud.ZkStateReader;\n import org.apache.solr.common.util.Pair;\n import org.apache.solr.common.util.Utils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import static org.apache.solr.common.params.CoreAdminParams.NODE;\n \n /**\n  * Each instance represents a node in the cluster\n  */\n public class Row implements MapWriter {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   public final String node;\n   final Cell[] cells;\n   //this holds the details of each replica in the node\n@@ -109,6 +115,14 @@ public String toString() {\n     return jsonStr();\n   }\n \n+  public Row addReplica(String coll, String shard, Replica.Type type) {\n+    return addReplica(coll, shard, type, 0, true);\n+  }\n+\n+  public Row addReplica(String coll, String shard, Replica.Type type, boolean strictMode) {\n+    return addReplica(coll, shard, type, 0, strictMode);\n+  }\n+\n   /**\n    * this simulates adding a replica of a certain coll+shard to node. as a result of adding a replica ,\n    * values of certain attributes will be modified, in this node as well as other nodes. Please note that\n@@ -117,9 +131,18 @@ public String toString() {\n    * @param coll  collection name\n    * @param shard shard name\n    * @param type  replica type\n+   * @param recursionCount the number of times we have recursed to add more replicas\n+   * @param strictMode whether suggester is operating in strict mode or not\n    */\n-  public Row addReplica(String coll, String shard, Replica.Type type) {\n-    Row row = session.copy().getNode(this.node);\n+  Row addReplica(String coll, String shard, Replica.Type type, int recursionCount, boolean strictMode) {\n+    if (recursionCount > 3) {\n+      log.error(\"more than 3 levels of recursion \", new RuntimeException());\n+      return this;\n+    }\n+    List<OperationInfo> furtherOps = new LinkedList<>();\n+    Consumer<OperationInfo> opCollector = it -> furtherOps.add(it);\n+    Row row = null;\n+    row = session.copy().getNode(this.node);\n     if (row == null) throw new RuntimeException(\"couldn't get a row\");\n     Map<String, List<ReplicaInfo>> c = row.collectionVsShardVsReplicas.computeIfAbsent(coll, k -> new HashMap<>());\n     List<ReplicaInfo> replicas = c.computeIfAbsent(shard, k -> new ArrayList<>());\n@@ -128,12 +151,37 @@ public Row addReplica(String coll, String shard, Replica.Type type) {\n         Utils.makeMap(ZkStateReader.REPLICA_TYPE, type != null ? type.toString() : Replica.Type.NRT.toString()));\n     replicas.add(ri);\n     for (Cell cell : row.cells) {\n-      cell.type.projectAddReplica(cell, ri);\n+      cell.type.projectAddReplica(cell, ri, opCollector, strictMode);\n+    }\n+    for (OperationInfo op : furtherOps) {\n+      if (op.isAdd) {\n+        row = row.session.getNode(op.node).addReplica(op.coll, op.shard, op.type, recursionCount + 1, strictMode);\n+      } else {\n+        row.session.getNode(op.node).removeReplica(op.coll, op.shard, op.type, recursionCount+1);\n+      }\n     }\n+\n     return row;\n   }\n \n \n+  static class OperationInfo {\n+    final String coll, shard, node, cellName;\n+    final boolean isAdd;// true =addReplica, false=removeReplica\n+    final Replica.Type type;\n+\n+\n+    OperationInfo(String coll, String shard, String node, String cellName, boolean isAdd, Replica.Type type) {\n+      this.coll = coll;\n+      this.shard = shard;\n+      this.node = node;\n+      this.cellName = cellName;\n+      this.isAdd = isAdd;\n+      this.type = type;\n+    }\n+  }\n+\n+\n   public ReplicaInfo getReplica(String coll, String shard, Replica.Type type) {\n     Map<String, List<ReplicaInfo>> c = collectionVsShardVsReplicas.get(coll);\n     if (c == null) return null;\n@@ -150,9 +198,18 @@ public ReplicaInfo getReplica(String coll, String shard, Replica.Type type) {\n     if (idx == -1) return null;\n     return r.get(idx);\n   }\n+  public Row removeReplica(String coll, String shard, Replica.Type type) {\n+    return removeReplica(coll,shard, type, 0);\n \n+  }\n   // this simulates removing a replica from a node\n-  public Pair<Row, ReplicaInfo> removeReplica(String coll, String shard, Replica.Type type) {\n+  public Row removeReplica(String coll, String shard, Replica.Type type, int recursionCount) {\n+    if (recursionCount > 3) {\n+      log.error(\"more than 3 levels of recursion \", new RuntimeException());\n+      return this;\n+    }\n+    List<OperationInfo> furtherOps = new LinkedList<>();\n+    Consumer<OperationInfo> opCollector = it -> furtherOps.add(it);\n     Row row = session.copy().getNode(this.node);\n     Map<String, List<ReplicaInfo>> c = row.collectionVsShardVsReplicas.get(coll);\n     if (c == null) return null;\n@@ -169,9 +226,9 @@ public ReplicaInfo getReplica(String coll, String shard, Replica.Type type) {\n     if (idx == -1) return null;\n     ReplicaInfo removed = r.remove(idx);\n     for (Cell cell : row.cells) {\n-      cell.type.projectRemoveReplica(cell, removed);\n+      cell.type.projectRemoveReplica(cell, removed, opCollector);\n     }\n-    return new Pair(row, removed);\n+    return row;\n \n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Row.java",
                "sha": "8a14abd83bae6d253a38afeedc7e1e418b5be692",
                "status": "modified"
            },
            {
                "additions": 116,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggester.java",
                "changes": 130,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggester.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 14,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggester.java",
                "patch": "@@ -18,6 +18,7 @@\n package org.apache.solr.client.solrj.cloud.autoscaling;\n \n import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n@@ -27,20 +28,26 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n+import java.util.Optional;\n import java.util.Set;\n import java.util.function.Consumer;\n import java.util.function.Predicate;\n \n import org.apache.solr.client.solrj.SolrRequest;\n import org.apache.solr.client.solrj.impl.ClusterStateProvider;\n import org.apache.solr.common.MapWriter;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.cloud.DocCollection;\n import org.apache.solr.common.cloud.Replica;\n import org.apache.solr.common.cloud.rule.ImplicitSnitch;\n import org.apache.solr.common.params.CollectionParams;\n import org.apache.solr.common.util.Pair;\n import org.apache.solr.common.util.Utils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.FREEDISK;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n \n /* A suggester is capable of suggesting a collection operation\n  * given a particular session. Before it suggests a new operation,\n@@ -50,6 +57,8 @@\n  *\n  */\n public abstract class Suggester implements MapWriter {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   protected final EnumMap<Hint, Object> hints = new EnumMap<>(Hint.class);\n   Policy.Session session;\n   SolrRequest operation;\n@@ -94,34 +103,40 @@ protected boolean isNodeSuitableForReplicaAddition(Row row) {\n \n   abstract SolrRequest init();\n \n-\n+  @SuppressWarnings(\"unchecked\")\n   public SolrRequest getSuggestion() {\n     if (!isInitialized) {\n       Set<String> collections = (Set<String>) hints.getOrDefault(Hint.COLL, Collections.emptySet());\n       Set<Pair<String, String>> s = (Set<Pair<String, String>>) hints.getOrDefault(Hint.COLL_SHARD, Collections.emptySet());\n       if (!collections.isEmpty() || !s.isEmpty()) {\n-        HashSet<Pair<String, String>> shards = new HashSet<>(s);\n-        collections.stream().forEach(c -> shards.add(new Pair<>(c, null)));\n-        ClusterStateProvider stateProvider = session.cloudManager.getClusterStateProvider();\n-        for (Pair<String, String> shard : shards) {\n-          // if this is not a known collection from the existing clusterstate,\n-          // then add it\n-          if (session.matrix.stream().noneMatch(row -> row.collectionVsShardVsReplicas.containsKey(shard.first()))) {\n-            session.addClausesForCollection(stateProvider, shard.first());\n+        HashSet<Pair<String, String>> collectionShardPairs = new HashSet<>(s);\n+        collections.forEach(c -> collectionShardPairs.add(new Pair<>(c, null)));\n+        collections.forEach(c -> {\n+          try {\n+            getWithCollection(c).ifPresent(withCollection -> collectionShardPairs.add(new Pair<>(withCollection, null)));\n+          } catch (IOException e) {\n+            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+                \"Exception while fetching 'withCollection' attribute for collection: \" + c, e);\n           }\n-          for (Row row : session.matrix) {\n-            Map<String, List<ReplicaInfo>> shardInfo = row.collectionVsShardVsReplicas.computeIfAbsent(shard.first(), it -> new HashMap<>());\n-            if (shard.second() != null) shardInfo.computeIfAbsent(shard.second(), it -> new ArrayList<>());\n+        });\n+        s.forEach(kv -> {\n+          try {\n+            getWithCollection(kv.first()).ifPresent(withCollection -> collectionShardPairs.add(new Pair<>(withCollection, null)));\n+          } catch (IOException e) {\n+            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+                \"Exception while fetching 'withCollection' attribute for collection: \" + kv.first(), e);\n           }\n-        }\n+        });\n+        setupCollection(collectionShardPairs);\n         Collections.sort(session.expandedClauses);\n       }\n       Set<String> srcNodes = (Set<String>) hints.get(Hint.SRC_NODE);\n       if (srcNodes != null && !srcNodes.isEmpty()) {\n         // the source node is dead so live nodes may not have it\n         for (String srcNode : srcNodes) {\n-          if (session.matrix.stream().noneMatch(row -> row.node.equals(srcNode)))\n+          if (session.matrix.stream().noneMatch(row -> row.node.equals(srcNode))) {\n             session.matrix.add(new Row(srcNode, session.getPolicy().params, session.getPolicy().perReplicaAttributes, session));\n+          }\n         }\n       }\n       session.applyRules();\n@@ -135,6 +150,30 @@ public SolrRequest getSuggestion() {\n     return operation;\n   }\n \n+  protected Optional<String> getWithCollection(String collectionName) throws IOException {\n+    DocCollection collection = session.cloudManager.getClusterStateProvider().getCollection(collectionName);\n+    if (collection != null) {\n+      return Optional.ofNullable(collection.getStr(WITH_COLLECTION));\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private void setupCollection(HashSet<Pair<String, String>> collectionShardPairs) {\n+    ClusterStateProvider stateProvider = session.cloudManager.getClusterStateProvider();\n+    for (Pair<String, String> shard : collectionShardPairs) {\n+      // if this is not a known collection from the existing clusterstate,\n+      // then add it\n+      if (session.matrix.stream().noneMatch(row -> row.collectionVsShardVsReplicas.containsKey(shard.first()))) {\n+        session.addClausesForCollection(stateProvider, shard.first());\n+      }\n+      for (Row row : session.matrix) {\n+        Map<String, List<ReplicaInfo>> shardInfo = row.collectionVsShardVsReplicas.computeIfAbsent(shard.first(), it -> new HashMap<>());\n+        if (shard.second() != null) shardInfo.computeIfAbsent(shard.second(), it -> new ArrayList<>());\n+      }\n+    }\n+  }\n+\n   public Policy.Session getSession() {\n     return session;\n   }\n@@ -355,4 +394,67 @@ public void writeMap(EntryWriter ew) throws IOException {\n     ew.put(\"action\", String.valueOf(getAction()));\n     ew.put(\"hints\", (MapWriter) ew1 -> hints.forEach((hint, o) -> ew1.putNoEx(hint.toString(), o)));\n   }\n+\n+  protected Collection setupWithCollectionTargetNodes(Set<String> collections, Set<Pair<String, String>> s, String withCollection) {\n+    Collection originalTargetNodesCopy = null;\n+    if (withCollection != null) {\n+      if (log.isDebugEnabled()) {\n+        HashSet<String> set = new HashSet<>(collections);\n+        s.forEach(kv -> set.add(kv.first()));\n+        log.debug(\"Identified withCollection = {} for collection: {}\", withCollection, set);\n+      }\n+\n+      originalTargetNodesCopy = Utils.getDeepCopy((Collection) hints.get(Hint.TARGET_NODE), 10, true);\n+\n+      Set<String> withCollectionNodes = new HashSet<>();\n+\n+      for (Row row : getMatrix()) {\n+        row.forEachReplica(r -> {\n+          if (withCollection.equals(r.getCollection()) &&\n+              \"shard1\".equals(r.getShard())) {\n+            withCollectionNodes.add(r.getNode());\n+          }\n+        });\n+      }\n+\n+      if (originalTargetNodesCopy != null && !originalTargetNodesCopy.isEmpty()) {\n+        // find intersection of the set of target nodes with the set of 'withCollection' nodes\n+        Set<String> set = (Set<String>) hints.computeIfAbsent(Hint.TARGET_NODE, h -> new HashSet<>());\n+        set.retainAll(withCollectionNodes);\n+        if (set.isEmpty()) {\n+          // no nodes common between the sets, we have no choice but to restore the original target node hint\n+          hints.put(Hint.TARGET_NODE, originalTargetNodesCopy);\n+        }\n+      } else if (originalTargetNodesCopy == null) {\n+        hints.put(Hint.TARGET_NODE, withCollectionNodes);\n+      }\n+    }\n+    return originalTargetNodesCopy;\n+  }\n+\n+  protected String findWithCollection(Set<String> collections, Set<Pair<String, String>> s) {\n+    List<String> withCollections = new ArrayList<>(1);\n+    collections.forEach(c -> {\n+      try {\n+        getWithCollection(c).ifPresent(withCollections::add);\n+      } catch (IOException e) {\n+        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+            \"Exception while fetching 'withCollection' attribute for collection: \" + c, e);\n+      }\n+    });\n+    s.forEach(kv -> {\n+      try {\n+        getWithCollection(kv.first()).ifPresent(withCollections::add);\n+      } catch (IOException e) {\n+        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+            \"Exception while fetching 'withCollection' attribute for collection: \" + kv.first(), e);\n+      }\n+    });\n+\n+    if (withCollections.size() > 1) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+          \"The number of 'withCollection' attributes should be exactly 1 for any policy but found: \" + withCollections);\n+    }\n+    return withCollections.isEmpty() ? null : withCollections.get(0);\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggester.java",
                "sha": "67721ba3618cc7a436b92dd7c75d60d0425ea236",
                "status": "modified"
            },
            {
                "additions": 58,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggestion.java",
                "changes": 78,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggestion.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 20,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggestion.java",
                "patch": "@@ -25,12 +25,11 @@\n import java.util.Arrays;\n import java.util.Collection;\n import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n \n@@ -44,13 +43,14 @@\n \n import static java.util.Collections.emptySet;\n import static java.util.Collections.unmodifiableSet;\n+import static org.apache.solr.client.solrj.cloud.autoscaling.Clause.parseString;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Policy.ANY;\n import static org.apache.solr.common.params.CollectionParams.CollectionAction.MOVEREPLICA;\n \n public class Suggestion {\n   public static final String coreidxsize = \"INDEX.sizeInGB\";\n \n-  static final Map<String, ConditionType> validatetypes = new HashMap<>();\n+\n   private static final String NULL = \"\";\n \n   @Target(ElementType.FIELD)\n@@ -82,14 +82,13 @@\n \n     String metricsKey() default NULL;\n \n+    Class implementation() default void.class;\n+\n     ComputedType[] computedValues() default ComputedType.NULL;\n   }\n \n   public static ConditionType getTagType(String name) {\n-    ConditionType info = validatetypes.get(name);\n-    if (info == null && name.startsWith(ImplicitSnitch.SYSPROP)) info = ConditionType.STRING;\n-    if (info == null && name.startsWith(Clause.METRICS_PREFIX)) info = ConditionType.LAZY;\n-    return info;\n+    return Policy.getTagType(name);\n   }\n \n   private static Object getOperandAdjustedValue(Object val, Object original) {\n@@ -160,7 +159,9 @@ static boolean isIntegerEquivalent(Object val) {\n   /**\n    * Type details of each variable in policies\n    */\n-  public enum ConditionType {\n+  public enum ConditionType implements VarType {\n+    @Meta(name = \"withCollection\", type = String.class, isNodeSpecificVal = true, implementation = WithCollectionVarType.class)\n+    WITH_COLLECTION(),\n \n     @Meta(name = \"collection\",\n         type = String.class)\n@@ -375,7 +376,7 @@ public void getSuggestions(SuggestionCtx ctx) {\n \n       //When a replica is added, freedisk should be incremented\n       @Override\n-      public void projectAddReplica(Cell cell, ReplicaInfo ri) {\n+      public void projectAddReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> ops, boolean strictMode) {\n         //go through other replicas of this shard and copy the index size value into this\n         for (Row row : cell.getRow().session.matrix) {\n           row.forEachReplica(replicaInfo -> {\n@@ -395,7 +396,7 @@ public void projectAddReplica(Cell cell, ReplicaInfo ri) {\n       }\n \n       @Override\n-      public void projectRemoveReplica(Cell cell, ReplicaInfo ri) {\n+      public void projectRemoveReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector) {\n         Double idxSize = (Double) validate(CORE_IDX.tagName, ri.getVariable(CORE_IDX.tagName), false);\n         if (idxSize == null) return;\n         Double currFreeDisk = cell.val == null ? 0.0d : (Double) cell.val;\n@@ -464,12 +465,12 @@ public void getSuggestions(SuggestionCtx ctx) {\n       }\n \n       @Override\n-      public void projectAddReplica(Cell cell, ReplicaInfo ri) {\n+      public void projectAddReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> ops, boolean strictMode) {\n         cell.val = cell.val == null ? 0 : ((Number) cell.val).longValue() + 1;\n       }\n \n       @Override\n-      public void projectRemoveReplica(Cell cell, ReplicaInfo ri) {\n+      public void projectRemoveReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector) {\n         cell.val = cell.val == null ? 0 : ((Number) cell.val).longValue() - 1;\n       }\n     },\n@@ -525,7 +526,12 @@ public void getSuggestions(SuggestionCtx ctx) {\n     LAZY() {\n       @Override\n       public Object validate(String name, Object val, boolean isRuleVal) {\n-        return Clause.parseString(val);\n+        return parseString(val);\n+      }\n+\n+      @Override\n+      public boolean match(Object inputVal, Operand op, Object val, String name, Row row) {\n+        return op.match(parseString(val), parseString(inputVal)) == Clause.TestStatus.PASS;\n       }\n \n       @Override\n@@ -543,6 +549,8 @@ public void getSuggestions(SuggestionCtx ctx) {\n       public void getSuggestions(SuggestionCtx ctx) {\n         perNodeSuggestions(ctx);\n       }\n+\n+\n     };\n \n     public final String tagName;\n@@ -558,6 +566,7 @@ public void getSuggestions(SuggestionCtx ctx) {\n     public final Set<String> associatedPerNodeValues;\n     public final String metricsAttribute;\n     public final Set<ComputedType> supportedComputedTypes;\n+    private final VarType impl;\n \n \n     ConditionType() {\n@@ -569,6 +578,15 @@ public void getSuggestions(SuggestionCtx ctx) {\n       } catch (NoSuchFieldException e) {\n         //cannot happen\n       }\n+      if (meta.implementation() != void.class) {\n+        try {\n+          impl = (VarType) meta.implementation().newInstance();\n+        } catch (Exception e) {\n+          throw new RuntimeException(\"Unable to instantiate: \" + meta.implementation().getName());\n+        }\n+      } else {\n+        impl = null;\n+      }\n       this.tagName = meta.name();\n       this.type = meta.type();\n \n@@ -583,6 +601,7 @@ public void getSuggestions(SuggestionCtx ctx) {\n           emptySet() :\n           unmodifiableSet(new HashSet(Arrays.asList(meta.computedValues())));\n       this.wildCards = readSet(meta.wildCards());\n+\n     }\n \n     public String getTagName() {\n@@ -603,11 +622,21 @@ private Number readNum(double v) {\n       return unmodifiableSet(new HashSet<>(Arrays.asList(vals)));\n     }\n \n+    @Override\n     public void getSuggestions(SuggestionCtx ctx) {\n+      if (impl != null) {\n+        impl.getSuggestions(ctx);\n+        return;\n+      }\n       perNodeSuggestions(ctx);\n     }\n \n+    @Override\n     public void addViolatingReplicas(ViolationCtx ctx) {\n+      if (impl != null) {\n+        impl.addViolatingReplicas(ctx);\n+        return;\n+      }\n       for (Row row : ctx.allRows) {\n         if (ctx.clause.tag.varType.meta.isNodeSpecificVal() && !row.node.equals(ctx.tagKey)) continue;\n         collectViolatingReplicas(ctx, row);\n@@ -669,21 +698,35 @@ public Object validate(String name, Object val, boolean isRuleVal) {\n     /**\n      * Simulate a replica addition to a node in the cluster\n      */\n-    public void projectAddReplica(Cell cell, ReplicaInfo ri) {\n+    public void projectAddReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector, boolean strictMode) {\n+      if (impl != null) impl.projectAddReplica(cell, ri, opCollector, strictMode);\n     }\n \n-    public void projectRemoveReplica(Cell cell, ReplicaInfo ri) {\n+    public void projectRemoveReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector) {\n+      if (impl != null) {\n+        impl.projectRemoveReplica(cell, ri, opCollector);\n+      }\n     }\n \n+    @Override\n     public int compareViolation(Violation v1, Violation v2) {\n+      if (impl != null) return impl.compareViolation(v1, v2);\n       if (v2.replicaCountDelta == null || v1.replicaCountDelta == null) return 0;\n       if (Math.abs(v1.replicaCountDelta) == Math.abs(v2.replicaCountDelta)) return 0;\n       return Math.abs(v1.replicaCountDelta) < Math.abs(v2.replicaCountDelta) ? -1 : 1;\n     }\n \n+    @Override\n     public Object computeValue(Policy.Session session, Clause.Condition condition, String collection, String shard, String node) {\n+      if (impl != null) return impl.computeValue(session, condition, collection, shard, node);\n       return condition.val;\n     }\n+\n+    @Override\n+    public boolean match(Object inputVal, Operand op, Object val, String name, Row row) {\n+      if (impl != null) return impl.match(inputVal, op, val, name, row);\n+      return op.match(val, validate(name, inputVal, false)) == Clause.TestStatus.PASS;\n+    }\n   }\n \n   private static void collectViolatingReplicas(ViolationCtx ctx, Row row) {\n@@ -757,9 +800,4 @@ private static void perNodeSuggestions(SuggestionCtx ctx) {\n     }\n   }\n \n-  static {\n-    for (Suggestion.ConditionType t : Suggestion.ConditionType.values()) Suggestion.validatetypes.put(t.tagName, t);\n-  }\n-\n-\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggestion.java",
                "sha": "af20fac96b747afe85bf9114b91c4927e0bf124d",
                "status": "modified"
            },
            {
                "additions": 43,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/VarType.java",
                "changes": 43,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/VarType.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/VarType.java",
                "patch": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.cloud.autoscaling;\n+\n+import java.util.function.Consumer;\n+\n+/**\n+ * A Variable Type used in Autoscaling policy rules\n+ */\n+public interface VarType {\n+  boolean match(Object inputVal, Operand op, Object val, String name, Row row);\n+\n+  void projectAddReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector, boolean strictMode);\n+\n+  void addViolatingReplicas(Suggestion.ViolationCtx ctx);\n+\n+  default void getSuggestions(Suggestion.SuggestionCtx ctx) {\n+  }\n+\n+  default Object computeValue(Policy.Session session, Clause.Condition condition, String collection, String shard, String node) {\n+    return condition.val;\n+  }\n+\n+  int compareViolation(Violation v1, Violation v2);\n+\n+  default void projectRemoveReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector) {\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/VarType.java",
                "sha": "00224a95192b0acd8a430b82ee8672aec98534d4",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Violation.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Violation.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Violation.java",
                "patch": "@@ -30,7 +30,7 @@\n public class Violation implements MapWriter {\n   final String shard, coll, node;\n   final Object actualVal;\n-  final Double replicaCountDelta;//how many extra replicas\n+  Double replicaCountDelta;//how many extra replicas\n   final Object tagKey;\n   private final int hash;\n   private final Clause clause;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Violation.java",
                "sha": "7b0f0f3a5c9b01c6bda5d1577028078129424f4e",
                "status": "modified"
            },
            {
                "additions": 160,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/WithCollectionVarType.java",
                "changes": 160,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/WithCollectionVarType.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/WithCollectionVarType.java",
                "patch": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.cloud.autoscaling;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Consumer;\n+\n+import org.apache.solr.common.cloud.Replica;\n+import org.apache.solr.common.util.Pair;\n+\n+import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICA;\n+import static org.apache.solr.common.params.CollectionParams.CollectionAction.MOVEREPLICA;\n+\n+/**\n+ * Implements the 'withCollection' variable type\n+ */\n+public class WithCollectionVarType implements VarType {\n+  @Override\n+  public boolean match(Object inputVal, Operand op, Object val, String name, Row row) {\n+    Map<String, String> withCollectionMap = (Map<String, String>) inputVal;\n+    if (withCollectionMap == null || withCollectionMap.isEmpty()) return true;\n+\n+    Set<String> uniqueColls = new HashSet<>();\n+    row.forEachReplica(replicaInfo -> uniqueColls.add(replicaInfo.getCollection()));\n+\n+    for (Map.Entry<String, String> e : withCollectionMap.entrySet()) {\n+      if (uniqueColls.contains(e.getKey()) && !uniqueColls.contains(e.getValue())) return false;\n+    }\n+\n+    return true;\n+  }\n+\n+  public void projectAddReplica(Cell cell, ReplicaInfo ri, Consumer<Row.OperationInfo> opCollector, boolean strictMode) {\n+    if (strictMode) {\n+      // we do not want to add a replica of the 'withCollection' in strict mode\n+      return;\n+    }\n+\n+    Map<String, String> withCollectionMap = (Map<String, String>) cell.val;\n+    if (withCollectionMap == null || withCollectionMap.isEmpty()) return;\n+\n+    Set<String> uniqueColls = new HashSet<>();\n+    Row row = cell.row;\n+    row.forEachReplica(replicaInfo -> uniqueColls.add(replicaInfo.getCollection()));\n+\n+    for (Map.Entry<String, String> e : withCollectionMap.entrySet()) {\n+      if (uniqueColls.contains(e.getKey()) && !uniqueColls.contains(e.getValue())) {\n+        String withCollection = e.getValue();\n+\n+        opCollector.accept(new Row.OperationInfo(withCollection, \"shard1\", row.node, cell.name, true, Replica.Type.NRT));\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public int compareViolation(Violation v1, Violation v2) {\n+    return Integer.compare(v1.getViolatingReplicas().size(), v2.getViolatingReplicas().size());\n+  }\n+\n+  public void addViolatingReplicas(Suggestion.ViolationCtx ctx) {\n+    String node = ctx.currentViolation.node;\n+    for (Row row : ctx.allRows) {\n+      if (node.equals(row.node)) {\n+        Map<String, String> withCollectionMap = (Map<String, String>) row.getVal(\"withCollection\");\n+        if (withCollectionMap != null) {\n+          row.forEachReplica(r -> {\n+            String withCollection = withCollectionMap.get(r.getCollection());\n+            if (withCollection != null) {\n+              // test whether this row has at least 1 replica of withCollection, else there is a violation\n+              Set<String> uniqueCollections = new HashSet<>();\n+              row.forEachReplica(replicaInfo -> uniqueCollections.add(replicaInfo.getCollection()));\n+              if (!uniqueCollections.contains(withCollection)) {\n+                ctx.currentViolation.addReplica(new Violation.ReplicaInfoAndErr(r).withDelta(1.0d));\n+              }\n+            }\n+          });\n+          ctx.currentViolation.replicaCountDelta = (double) ctx.currentViolation.getViolatingReplicas().size();\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void getSuggestions(Suggestion.SuggestionCtx ctx) {\n+    if (ctx.violation.getViolatingReplicas().isEmpty()) return;\n+\n+    Map<String, Object> nodeValues = ctx.session.nodeStateProvider.getNodeValues(ctx.violation.node, Collections.singleton(\"withCollection\"));\n+    Map<String, String> withCollectionsMap = (Map<String, String>) nodeValues.get(\"withCollection\");\n+    if (withCollectionsMap == null) return;\n+\n+    Set<String> uniqueCollections = new HashSet<>();\n+    for (Violation.ReplicaInfoAndErr replicaInfoAndErr : ctx.violation.getViolatingReplicas()) {\n+      uniqueCollections.add(replicaInfoAndErr.replicaInfo.getCollection());\n+    }\n+\n+    collectionLoop:\n+    for (String collection : uniqueCollections) {\n+      String withCollection = withCollectionsMap.get(collection);\n+      if (withCollection == null) continue;\n+\n+      // can we find a node from which we can move a replica of the `withCollection`\n+      // without creating another violation?\n+      for (Row row : ctx.session.matrix) {\n+        if (ctx.violation.node.equals(row.node))  continue; // filter the violating node\n+\n+        Set<String> hostedCollections = new HashSet<>();\n+        row.forEachReplica(replicaInfo -> hostedCollections.add(replicaInfo.getCollection()));\n+\n+        if (hostedCollections.contains(withCollection) && !hostedCollections.contains(collection))  {\n+          // find the candidate replicas that we can move\n+          List<ReplicaInfo> movableReplicas = new ArrayList<>();\n+          row.forEachReplica(replicaInfo -> {\n+            if (replicaInfo.getCollection().equals(withCollection)) {\n+              movableReplicas.add(replicaInfo);\n+            }\n+          });\n+\n+          for (ReplicaInfo toMove : movableReplicas) {\n+            // candidate source node for a move replica operation\n+            Suggester suggester = ctx.session.getSuggester(MOVEREPLICA)\n+                .forceOperation(true)\n+                .hint(Suggester.Hint.COLL_SHARD, new Pair<>(withCollection, \"shard1\"))\n+                .hint(Suggester.Hint.SRC_NODE, row.node)\n+                .hint(Suggester.Hint.REPLICA, toMove.getName())\n+                .hint(Suggester.Hint.TARGET_NODE, ctx.violation.node);\n+            if (ctx.addSuggestion(suggester) != null)\n+              continue collectionLoop; // one suggestion is enough for this collection\n+          }\n+        }\n+      }\n+\n+      // we could not find a valid move, so we suggest adding a replica\n+      Suggester suggester = ctx.session.getSuggester(ADDREPLICA)\n+          .forceOperation(true)\n+          .hint(Suggester.Hint.COLL_SHARD, new Pair<>(withCollection, \"shard1\"))\n+          .hint(Suggester.Hint.TARGET_NODE, ctx.violation.node);\n+      ctx.addSuggestion(suggester);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/WithCollectionVarType.java",
                "sha": "989a0875c77b4d6d9460fc1482bd5029e950882c",
                "status": "added"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/impl/SolrClientNodeStateProvider.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/SolrClientNodeStateProvider.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/SolrClientNodeStateProvider.java",
                "patch": "@@ -45,6 +45,7 @@\n import org.apache.solr.common.cloud.DocCollection;\n import org.apache.solr.common.cloud.rule.ImplicitSnitch;\n import org.apache.solr.common.cloud.rule.SnitchContext;\n+import org.apache.solr.common.params.CollectionAdminParams;\n import org.apache.solr.common.params.CommonParams;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.params.SolrParams;\n@@ -60,6 +61,7 @@\n import static org.apache.solr.client.solrj.cloud.autoscaling.Clause.METRICS_PREFIX;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.FREEDISK;\n import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.TOTALDISK;\n+import static org.apache.solr.client.solrj.cloud.autoscaling.Suggestion.ConditionType.WITH_COLLECTION;\n \n /**\n  *\n@@ -75,6 +77,7 @@\n   protected final Map<String, Map<String, Map<String, List<ReplicaInfo>>>> nodeVsCollectionVsShardVsReplicaInfo = new HashMap<>();\n   private Map<String, Object> snitchSession = new HashMap<>();\n   private Map<String, Map> nodeVsTags = new HashMap<>();\n+  private Map<String, String> withCollectionsMap = new HashMap<>();\n \n   public SolrClientNodeStateProvider(CloudSolrClient solrClient) {\n     this.solrClient = solrClient;\n@@ -100,6 +103,9 @@ private void readReplicaDetails() throws IOException {\n     all.forEach((collName, ref) -> {\n       DocCollection coll = ref.get();\n       if (coll == null) return;\n+      if (coll.getProperties().get(CollectionAdminParams.WITH_COLLECTION) != null) {\n+        withCollectionsMap.put(coll.getName(), (String) coll.getProperties().get(CollectionAdminParams.WITH_COLLECTION));\n+      }\n       coll.forEachReplica((shard, replica) -> {\n         Map<String, Map<String, List<ReplicaInfo>>> nodeData = nodeVsCollectionVsShardVsReplicaInfo.computeIfAbsent(replica.getNodeName(), k -> new HashMap<>());\n         Map<String, List<ReplicaInfo>> collData = nodeData.computeIfAbsent(collName, k -> new HashMap<>());\n@@ -114,13 +120,15 @@ public void writeMap(EntryWriter ew) throws IOException {\n //    ew.put(\"liveNodes\", liveNodes);\n     ew.put(\"replicaInfo\", Utils.getDeepCopy(nodeVsCollectionVsShardVsReplicaInfo, 5));\n     ew.put(\"nodeValues\", nodeVsTags);\n-\n   }\n \n   @Override\n   public Map<String, Object> getNodeValues(String node, Collection<String> tags) {\n     Map<String, Object> tagVals = fetchTagValues(node, tags);\n     nodeVsTags.put(node, tagVals);\n+    if (tags.contains(WITH_COLLECTION.tagName)) {\n+      tagVals.put(WITH_COLLECTION.tagName, withCollectionsMap);\n+    }\n     return tagVals;\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/impl/SolrClientNodeStateProvider.java",
                "sha": "2015b52391f676f72875feb890fc1d4d8ee5dab7",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 3,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java",
                "patch": "@@ -59,9 +59,11 @@\n import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;\n import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;\n import static org.apache.solr.common.params.CollectionAdminParams.COLL_CONF;\n+import static org.apache.solr.common.params.CollectionAdminParams.COLOCATED_WITH;\n import static org.apache.solr.common.params.CollectionAdminParams.COUNT_PROP;\n import static org.apache.solr.common.params.CollectionAdminParams.CREATE_NODE_SET_PARAM;\n import static org.apache.solr.common.params.CollectionAdminParams.CREATE_NODE_SET_SHUFFLE_PARAM;\n+import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;\n \n /**\n  * This class is experimental and subject to change.\n@@ -80,7 +82,9 @@\n       MAX_SHARDS_PER_NODE,\n       AUTO_ADD_REPLICAS,\n       POLICY,\n-      COLL_CONF);\n+      COLL_CONF,\n+      WITH_COLLECTION,\n+      COLOCATED_WITH);\n \n   protected final CollectionAction action;\n \n@@ -417,10 +421,11 @@ public static Modify modifyCollection(String collection, Map<String, Object> pro\n     protected Integer pullReplicas;\n     protected Integer tlogReplicas;\n \n-    private Properties properties;\n+    protected Properties properties;\n     protected Boolean autoAddReplicas;\n     protected Integer stateFormat;\n-    private String[] rule , snitch;\n+    protected String[] rule , snitch;\n+    protected String withCollection;\n \n     /** Constructor intended for typical use cases */\n     protected Create(String collection, String config, Integer numShards, Integer numNrtReplicas, Integer numTlogReplicas, Integer numPullReplicas) { // TODO: maybe add other constructors\n@@ -557,13 +562,23 @@ public SolrParams getParams() {\n       if (rule != null) params.set(DocCollection.RULE, rule);\n       if (snitch != null) params.set(DocCollection.SNITCH, snitch);\n       params.setNonNull(POLICY, policy);\n+      params.setNonNull(WITH_COLLECTION, withCollection);\n       return params;\n     }\n \n     public Create setPolicy(String policy) {\n       this.policy = policy;\n       return this;\n     }\n+\n+    public String getWithCollection() {\n+      return withCollection;\n+    }\n+\n+    public Create setWithCollection(String withCollection) {\n+      this.withCollection = withCollection;\n+      return this;\n+    }\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java",
                "sha": "8d362960b91fab42de98e9396c336e15d82f8694",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                "patch": "@@ -27,6 +27,7 @@\n import java.util.Objects;\n import java.util.Set;\n import java.util.function.BiConsumer;\n+import java.util.function.BiPredicate;\n \n import org.apache.solr.client.solrj.cloud.autoscaling.Policy;\n import org.apache.solr.common.SolrException;\n@@ -174,6 +175,9 @@ public Slice getSlice(String sliceName) {\n     return slices.get(sliceName);\n   }\n \n+  /**\n+   * @param consumer consume shardName vs. replica\n+   */\n   public void forEachReplica(BiConsumer<String, Replica> consumer) {\n     slices.forEach((shard, slice) -> slice.getReplicasMap().forEach((s, replica) -> consumer.accept(shard, replica)));\n   }\n@@ -321,7 +325,22 @@ public static boolean isFullyActive(Set<String> liveNodes, DocCollection collect\n     }\n     return replicas;\n   }\n-  \n+\n+  /**\n+   * @param predicate test against shardName vs. replica\n+   * @return the first replica that matches the predicate\n+   */\n+  public Replica getReplica(BiPredicate<String, Replica> predicate) {\n+    final Replica[] result = new Replica[1];\n+    forEachReplica((s, replica) -> {\n+      if (result[0] != null) return;\n+      if (predicate.test(s, replica)) {\n+        result[0] = replica;\n+      }\n+    });\n+    return result[0];\n+  }\n+\n   public List<Replica> getReplicas(EnumSet<Replica.Type> s) {\n     List<Replica> replicas = new ArrayList<>();\n     for (Slice slice : this) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java",
                "sha": "411fe568205c273f44da378f3534db37d2f4b341",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java",
                "patch": "@@ -79,4 +79,15 @@\n    * The name of the config set to be used for a collection\n    */\n   String COLL_CONF = \"collection.configName\";\n+\n+  /**\n+   * The name of the collection with which a collection is to be co-located\n+   */\n+  String WITH_COLLECTION = \"withCollection\";\n+\n+  /**\n+   * The reverse-link to WITH_COLLECTION flag. It is stored in the cluster state of the `withCollection`\n+   * and points to the collection on which the `withCollection` was specified.\n+   */\n+  String COLOCATED_WITH = \"COLOCATED_WITH\";\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java",
                "sha": "a0ef11f4d68e406fd9e1637ba40a5d8e8009c928",
                "status": "modified"
            },
            {
                "additions": 563,
                "blob_url": "https://github.com/apache/lucene-solr/blob/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/test/org/apache/solr/client/solrj/cloud/autoscaling/TestPolicy.java",
                "changes": 568,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/test/org/apache/solr/client/solrj/cloud/autoscaling/TestPolicy.java?ref=179c8f9b48af9bf3c327226d0e1fdbe460c4a325",
                "deletions": 5,
                "filename": "solr/solrj/src/test/org/apache/solr/client/solrj/cloud/autoscaling/TestPolicy.java",
                "patch": "@@ -166,6 +166,564 @@ static SolrCloudManager createCloudManager(Map jsonObj) {\n     return result;\n   }\n \n+\n+  public void testWithCollection() {\n+    String clusterStateStr = \"{\" +\n+        \"  'comments_coll':{\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards':{},\" +\n+        \"    'withCollection' :'articles_coll'\" +\n+        \"  },\" +\n+        \"  'articles_coll': {\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards': {\" +\n+        \"      'shard1': {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:8983/solr',\" +\n+        \"            'node_name': 'node1',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          },\" +\n+        \"          'r2': {\" +\n+        \"            'core': 'r2',\" +\n+        \"            'base_url': 'http://10.0.0.4:7574/solr',\" +\n+        \"            'node_name': 'node2',\" +\n+        \"            'state': 'active'\" +\n+        \"          }\" +\n+        \"        }\" +\n+        \"      }\" +\n+        \"    }\" +\n+        \"  }\" +\n+        \"}\";\n+    ClusterState clusterState = ClusterState.load(1, clusterStateStr.getBytes(UTF_8),\n+        ImmutableSet.of(\"node1\", \"node2\", \"node3\", \"node4\", \"node5\"));\n+    DelegatingClusterStateProvider clusterStateProvider = new DelegatingClusterStateProvider(null) {\n+      @Override\n+      public ClusterState getClusterState() throws IOException {\n+        return clusterState;\n+      }\n+\n+      @Override\n+      public Set<String> getLiveNodes() {\n+        return clusterState.getLiveNodes();\n+      }\n+    };\n+\n+    SolrClientNodeStateProvider solrClientNodeStateProvider = new SolrClientNodeStateProvider(null) {\n+      @Override\n+      protected Map<String, Object> fetchTagValues(String node, Collection<String> tags) {\n+        Map<String, Object> result = new HashMap<>();\n+        AtomicInteger cores = new AtomicInteger();\n+        forEachReplica(node, replicaInfo -> cores.incrementAndGet());\n+        if (tags.contains(ImplicitSnitch.CORES)) result.put(ImplicitSnitch.CORES, cores.get());\n+        if (tags.contains(ImplicitSnitch.DISK)) result.put(ImplicitSnitch.DISK, 100);\n+        return result;\n+      }\n+\n+      @Override\n+      protected Map<String, Object> fetchReplicaMetrics(String solrNode, Map<String, Pair<String, ReplicaInfo>> metricsKeyVsTagReplica) {\n+        //e.g: solr.core.perReplicaDataColl.shard1.replica_n4:INDEX.sizeInBytes\n+        Map<String, Object> result = new HashMap<>();\n+        metricsKeyVsTagReplica.forEach((k, v) -> {\n+          if (k.endsWith(\":INDEX.sizeInBytes\")) result.put(k, 100);\n+        });\n+        return result;\n+      }\n+\n+      @Override\n+      protected ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+    };\n+    Map m = solrClientNodeStateProvider.getNodeValues(\"node1\", ImmutableSet.of(\"cores\", \"withCollection\"));\n+    assertNotNull(m.get(\"withCollection\"));\n+\n+    Map policies = (Map) Utils.fromJSONString(\"{\" +\n+        \"  'cluster-preferences': [\" +\n+        \"    { 'minimize': 'cores'},\" +\n+        \"    { 'maximize': 'freedisk', 'precision': 50}\" +\n+        \"  ],\" +\n+        \"  'cluster-policy': [\" +\n+        \"    { 'replica': 0, 'nodeRole': 'overseer'}\" +\n+        \"    { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n+        \"  ]\" +\n+        \"}\");\n+    AutoScalingConfig config = new AutoScalingConfig(policies);\n+    Policy policy = config.getPolicy();\n+    Policy.Session session = policy.createSession(new DelegatingCloudManager(null) {\n+      @Override\n+      public ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+\n+      @Override\n+      public NodeStateProvider getNodeStateProvider() {\n+        return solrClientNodeStateProvider;\n+      }\n+    });\n+    Suggester suggester = session.getSuggester(CollectionAction.ADDREPLICA);\n+    suggester.hint(Hint.COLL_SHARD, new Pair<>(\"comments_coll\", \"shard1\"));\n+    SolrRequest op = suggester.getSuggestion();\n+    assertNotNull(op);\n+    Set<String> nodes = new HashSet<>(2);\n+    nodes.add(op.getParams().get(\"node\"));\n+    session = suggester.getSession();\n+    suggester = session.getSuggester(ADDREPLICA);\n+    suggester.hint(Hint.COLL_SHARD, new Pair<>(\"comments_coll\", \"shard1\"));\n+    op = suggester.getSuggestion();\n+    assertNotNull(op);\n+    nodes.add(op.getParams().get(\"node\"));\n+    assertEquals(2, nodes.size());\n+    assertTrue(\"node1 should have been selected by add replica\", nodes.contains(\"node1\"));\n+    assertTrue(\"node2 should have been selected by add replica\", nodes.contains(\"node2\"));\n+\n+    session = suggester.getSession();\n+    suggester = session.getSuggester(MOVEREPLICA);\n+    suggester.hint(Hint.COLL_SHARD, new Pair<>(\"comments_coll\", \"shard1\"));\n+    op = suggester.getSuggestion();\n+    assertNull(op);\n+  }\n+\n+  public void testWithCollectionSuggestions() {\n+    String clusterStateStr = \"{\" +\n+        \"  'articles_coll':{\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards':{'shard1':{}},\" +\n+        \"  },\" +\n+        \"  'comments_coll': {\" +\n+        \"    'withCollection' :'articles_coll',\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards': {\" +\n+        \"      'shard1': {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:8983/solr',\" +\n+        \"            'node_name': 'node1',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          },\" +\n+        \"          'r2': {\" +\n+        \"            'core': 'r2',\" +\n+        \"            'base_url': 'http://10.0.0.4:7574/solr',\" +\n+        \"            'node_name': 'node2',\" +\n+        \"            'state': 'active'\" +\n+        \"          }\" +\n+        \"        }\" +\n+        \"      }\" +\n+        \"    }\" +\n+        \"  }\" +\n+        \"}\";\n+    ClusterState clusterState = ClusterState.load(1, clusterStateStr.getBytes(UTF_8),\n+        ImmutableSet.of(\"node1\", \"node2\", \"node3\", \"node4\", \"node5\"));\n+    DelegatingClusterStateProvider clusterStateProvider = new DelegatingClusterStateProvider(null) {\n+      @Override\n+      public ClusterState getClusterState() throws IOException {\n+        return clusterState;\n+      }\n+\n+      @Override\n+      public Set<String> getLiveNodes() {\n+        return clusterState.getLiveNodes();\n+      }\n+    };\n+\n+    SolrClientNodeStateProvider solrClientNodeStateProvider = new SolrClientNodeStateProvider(null) {\n+      @Override\n+      protected Map<String, Object> fetchTagValues(String node, Collection<String> tags) {\n+        Map<String, Object> result = new HashMap<>();\n+        AtomicInteger cores = new AtomicInteger();\n+        forEachReplica(node, replicaInfo -> cores.incrementAndGet());\n+        if (tags.contains(ImplicitSnitch.CORES)) result.put(ImplicitSnitch.CORES, cores.get());\n+        if (tags.contains(ImplicitSnitch.DISK)) result.put(ImplicitSnitch.DISK, 100);\n+        return result;\n+      }\n+\n+      @Override\n+      protected Map<String, Object> fetchReplicaMetrics(String solrNode, Map<String, Pair<String, ReplicaInfo>> metricsKeyVsTagReplica) {\n+        //e.g: solr.core.perReplicaDataColl.shard1.replica_n4:INDEX.sizeInBytes\n+        Map<String, Object> result = new HashMap<>();\n+        metricsKeyVsTagReplica.forEach((k, v) -> {\n+          if (k.endsWith(\":INDEX.sizeInBytes\")) result.put(k, 100);\n+        });\n+        return result;\n+      }\n+\n+      @Override\n+      protected ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+    };\n+    Map m = solrClientNodeStateProvider.getNodeValues(\"node1\", ImmutableSet.of(\"cores\", \"withCollection\"));\n+    assertNotNull(m.get(\"withCollection\"));\n+\n+    Map policies = (Map) Utils.fromJSONString(\"{\" +\n+        \"  'cluster-preferences': [\" +\n+        \"    { 'maximize': 'freedisk', 'precision': 50},\" +\n+        \"    { 'minimize': 'cores'}\" +\n+        \"  ],\" +\n+        \"  'cluster-policy': [\" +\n+        \"    { 'replica': 0, 'nodeRole': 'overseer'}\" +\n+        \"    { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n+        \"  ]\" +\n+        \"}\");\n+\n+    List<Suggester.SuggestionInfo> l = PolicyHelper.getSuggestions(new AutoScalingConfig(policies),\n+        new DelegatingCloudManager(null) {\n+          @Override\n+          public ClusterStateProvider getClusterStateProvider() {\n+            return clusterStateProvider;\n+          }\n+\n+          @Override\n+          public NodeStateProvider getNodeStateProvider() {\n+            return solrClientNodeStateProvider;\n+          }\n+        });\n+    assertNotNull(l);\n+    assertEquals(2, l.size());\n+\n+    // collect the set of nodes to which replicas are being added\n+    Set<String> nodes = new HashSet<>(2);\n+\n+    m = l.get(0).toMap(new LinkedHashMap<>());\n+    assertEquals(1.0d, Utils.getObjectByPath(m, true, \"violation/violation/delta\"));\n+    assertEquals(\"POST\", Utils.getObjectByPath(m, true, \"operation/method\"));\n+    assertEquals(\"/c/articles_coll/shards\", Utils.getObjectByPath(m, true, \"operation/path\"));\n+    assertNotNull(Utils.getObjectByPath(m, false, \"operation/command/add-replica\"));\n+    nodes.add((String) Utils.getObjectByPath(m, true, \"operation/command/add-replica/node\"));\n+\n+    m = l.get(1).toMap(new LinkedHashMap<>());\n+    assertEquals(1.0d, Utils.getObjectByPath(m, true, \"violation/violation/delta\"));\n+    assertEquals(\"POST\", Utils.getObjectByPath(m, true, \"operation/method\"));\n+    assertEquals(\"/c/articles_coll/shards\", Utils.getObjectByPath(m, true, \"operation/path\"));\n+    assertNotNull(Utils.getObjectByPath(m, false, \"operation/command/add-replica\"));\n+    nodes.add((String) Utils.getObjectByPath(m, true, \"operation/command/add-replica/node\"));\n+\n+    assertEquals(2, nodes.size());\n+    assertTrue(nodes.contains(\"node1\"));\n+    assertTrue(nodes.contains(\"node2\"));\n+  }\n+\n+  public void testWithCollectionMoveVsAddSuggestions() {\n+    String clusterStateStr = \"{\" +\n+        \"  'articles_coll':{\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards': {\" +\n+        \"      'shard1': {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:8983/solr',\" +\n+        \"            'node_name': 'node1',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          },\" +\n+        \"          'r2': {\" +\n+        \"            'core': 'r2',\" +\n+        \"            'base_url': 'http://10.0.0.4:7574/solr',\" +\n+        \"            'node_name': 'node2',\" +\n+        \"            'state': 'active'\" +\n+        \"          },\" +\n+        \"          'r3': {\" +\n+        \"            'core': 'r3',\" +\n+        \"            'base_url': 'http://10.0.0.4:7579/solr',\" +\n+        \"            'node_name': 'node6',\" +\n+        \"            'state': 'active'\" +\n+        \"          }\" +\n+        \"        }\" +\n+        \"      }\" +\n+        \"    }\" +\n+        \"  },\" +\n+        \"  'comments_coll': {\" +\n+        \"    'withCollection' :'articles_coll',\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards': {\" +\n+        \"      'shard1': {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:7576/solr',\" +\n+        \"            'node_name': 'node3',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          },\" +\n+        \"          'r2': {\" +\n+        \"            'core': 'r2',\" +\n+        \"            'base_url': 'http://10.0.0.4:7577/solr',\" +\n+        \"            'node_name': 'node4',\" +\n+        \"            'state': 'active'\" +\n+        \"          },\" +\n+        \"          'r3': {\" +\n+        \"            'core': 'r3',\" +\n+        \"            'base_url': 'http://10.0.0.4:7578/solr',\" +\n+        \"            'node_name': 'node5',\" +\n+        \"            'state': 'active'\" +\n+        \"          },\" +\n+        \"          'r4': {\" +\n+        \"            'core': 'r4',\" +\n+        \"            'base_url': 'http://10.0.0.4:7579/solr',\" +\n+        \"            'node_name': 'node6',\" +\n+        \"            'state': 'active'\" +\n+        \"          }\" +\n+        \"        }\" +\n+        \"      }\" +\n+        \"    }\" +\n+        \"  }\" +\n+        \"}\";\n+    ClusterState clusterState = ClusterState.load(1, clusterStateStr.getBytes(UTF_8),\n+        ImmutableSet.of(\"node1\", \"node2\", \"node3\", \"node4\", \"node5\", \"node6\"));\n+    DelegatingClusterStateProvider clusterStateProvider = new DelegatingClusterStateProvider(null) {\n+      @Override\n+      public ClusterState getClusterState() throws IOException {\n+        return clusterState;\n+      }\n+\n+      @Override\n+      public Set<String> getLiveNodes() {\n+        return clusterState.getLiveNodes();\n+      }\n+    };\n+\n+    SolrClientNodeStateProvider solrClientNodeStateProvider = new SolrClientNodeStateProvider(null) {\n+      @Override\n+      protected Map<String, Object> fetchTagValues(String node, Collection<String> tags) {\n+        Map<String, Object> result = new HashMap<>();\n+        AtomicInteger cores = new AtomicInteger();\n+        forEachReplica(node, replicaInfo -> cores.incrementAndGet());\n+        if (tags.contains(ImplicitSnitch.CORES)) result.put(ImplicitSnitch.CORES, cores.get());\n+        if (tags.contains(ImplicitSnitch.DISK)) result.put(ImplicitSnitch.DISK, 100);\n+        return result;\n+      }\n+\n+      @Override\n+      protected Map<String, Object> fetchReplicaMetrics(String solrNode, Map<String, Pair<String, ReplicaInfo>> metricsKeyVsTagReplica) {\n+        //e.g: solr.core.perReplicaDataColl.shard1.replica_n4:INDEX.sizeInBytes\n+        Map<String, Object> result = new HashMap<>();\n+        metricsKeyVsTagReplica.forEach((k, v) -> {\n+          if (k.endsWith(\":INDEX.sizeInBytes\")) result.put(k, 100);\n+        });\n+        return result;\n+      }\n+\n+      @Override\n+      protected ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+    };\n+    Map m = solrClientNodeStateProvider.getNodeValues(\"node1\", ImmutableSet.of(\"cores\", \"withCollection\"));\n+    assertNotNull(m.get(\"withCollection\"));\n+\n+    Map policies = (Map) Utils.fromJSONString(\"{\" +\n+        \"  'cluster-preferences': [\" +\n+        \"    { 'maximize': 'freedisk', 'precision': 50},\" +\n+        \"    { 'minimize': 'cores'}\" +\n+        \"  ],\" +\n+        \"  'cluster-policy': [\" +\n+        \"    { 'replica': 0, 'nodeRole': 'overseer'}\" +\n+        \"    { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n+        \"  ]\" +\n+        \"}\");\n+\n+    List<Suggester.SuggestionInfo> l = PolicyHelper.getSuggestions(new AutoScalingConfig(policies),\n+        new DelegatingCloudManager(null) {\n+          @Override\n+          public ClusterStateProvider getClusterStateProvider() {\n+            return clusterStateProvider;\n+          }\n+\n+          @Override\n+          public NodeStateProvider getNodeStateProvider() {\n+            return solrClientNodeStateProvider;\n+          }\n+        });\n+    assertNotNull(l);\n+    assertEquals(3, l.size());\n+\n+    // collect the set of nodes to which replicas are being added\n+    Set<String> nodes = new HashSet<>(2);\n+\n+    int numMoves = 0, numAdds = 0;\n+    Set<String> addNodes = new HashSet<>();\n+    Set<String> targetNodes = new HashSet<>();\n+    Set<String> movedReplicas = new HashSet<>();\n+    for (Suggester.SuggestionInfo suggestionInfo : l) {\n+      Map s = suggestionInfo.toMap(new LinkedHashMap<>());\n+      assertEquals(\"POST\", Utils.getObjectByPath(s, true, \"operation/method\"));\n+      if (Utils.getObjectByPath(s, false, \"operation/command/add-replica\") != null)  {\n+        numAdds++;\n+        assertEquals(1.0d, Utils.getObjectByPath(s, true, \"violation/violation/delta\"));\n+        assertEquals(\"/c/articles_coll/shards\", Utils.getObjectByPath(s, true, \"operation/path\"));\n+        addNodes.add((String) Utils.getObjectByPath(s, true, \"operation/command/add-replica/node\"));\n+      } else if (Utils.getObjectByPath(s, false, \"operation/command/move-replica\") != null) {\n+        numMoves++;\n+        assertEquals(\"/c/articles_coll\", Utils.getObjectByPath(s, true, \"operation/path\"));\n+        targetNodes.add((String) Utils.getObjectByPath(s, true, \"operation/command/move-replica/targetNode\"));\n+        movedReplicas.add((String) Utils.getObjectByPath(s, true, \"operation/command/move-replica/replica\"));\n+      } else  {\n+        fail(\"Unexpected operation type suggested for suggestion: \" + suggestionInfo);\n+      }\n+    }\n+\n+    assertEquals(2, targetNodes.size());\n+    assertEquals(1, addNodes.size());\n+    assertEquals(2, movedReplicas.size());\n+    Set<String> allTargetNodes = new HashSet<>(targetNodes);\n+    allTargetNodes.addAll(addNodes);\n+    assertEquals(3, allTargetNodes.size());\n+    assertTrue(allTargetNodes.contains(\"node3\"));\n+    assertTrue(allTargetNodes.contains(\"node4\"));\n+    assertTrue(allTargetNodes.contains(\"node5\"));\n+  }\n+\n+  public void testWithCollectionMoveReplica() {\n+    String clusterStateStr = \"{\" +\n+        \"  'comments_coll':{\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards':{\" +\n+        \"       'shard1' : {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:8983/solr',\" +\n+        \"            'node_name': 'node1',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          }\" +\n+        \"         }\" +\n+        \"       }\" +\n+        \"     },\" +\n+        \"    'withCollection' :'articles_coll'\" +\n+        \"  },\" +\n+        \"  'articles_coll': {\" +\n+        \"    'router': {\" +\n+        \"      'name': 'compositeId'\" +\n+        \"    },\" +\n+        \"    'shards': {\" +\n+        \"      'shard1': {\" +\n+        \"        'range': '80000000-ffffffff',\" +\n+        \"        'replicas': {\" +\n+        \"          'r1': {\" +\n+        \"            'core': 'r1',\" +\n+        \"            'base_url': 'http://10.0.0.4:8983/solr',\" +\n+        \"            'node_name': 'node1',\" +\n+        \"            'state': 'active',\" +\n+        \"            'leader': 'true'\" +\n+        \"          },\" +\n+        \"          'r2': {\" +\n+        \"            'core': 'r2',\" +\n+        \"            'base_url': 'http://10.0.0.4:7574/solr',\" +\n+        \"            'node_name': 'node2',\" +\n+        \"            'state': 'active'\" +\n+        \"          }\" +\n+        \"        }\" +\n+        \"      }\" +\n+        \"    }\" +\n+        \"  }\" +\n+        \"}\";\n+    ClusterState clusterState = ClusterState.load(1, clusterStateStr.getBytes(UTF_8),\n+        ImmutableSet.of(\"node2\", \"node3\", \"node4\", \"node5\"));\n+    DelegatingClusterStateProvider clusterStateProvider = new DelegatingClusterStateProvider(null) {\n+      @Override\n+      public ClusterState getClusterState() throws IOException {\n+        return clusterState;\n+      }\n+\n+      @Override\n+      public Set<String> getLiveNodes() {\n+        return clusterState.getLiveNodes();\n+      }\n+    };\n+\n+    SolrClientNodeStateProvider solrClientNodeStateProvider = new SolrClientNodeStateProvider(null) {\n+      @Override\n+      protected Map<String, Object> fetchTagValues(String node, Collection<String> tags) {\n+        Map<String, Object> result = new HashMap<>();\n+        AtomicInteger cores = new AtomicInteger();\n+        forEachReplica(node, replicaInfo -> cores.incrementAndGet());\n+        if (tags.contains(ImplicitSnitch.CORES)) result.put(ImplicitSnitch.CORES, cores.get());\n+        if (tags.contains(ImplicitSnitch.DISK)) result.put(ImplicitSnitch.DISK, 100);\n+        return result;\n+      }\n+\n+      @Override\n+      protected Map<String, Object> fetchReplicaMetrics(String solrNode, Map<String, Pair<String, ReplicaInfo>> metricsKeyVsTagReplica) {\n+        //e.g: solr.core.perReplicaDataColl.shard1.replica_n4:INDEX.sizeInBytes\n+        Map<String, Object> result = new HashMap<>();\n+        metricsKeyVsTagReplica.forEach((k, v) -> {\n+          if (k.endsWith(\":INDEX.sizeInBytes\")) result.put(k, 100);\n+        });\n+        return result;\n+      }\n+\n+      @Override\n+      protected ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+    };\n+    Map m = solrClientNodeStateProvider.getNodeValues(\"node1\", ImmutableSet.of(\"cores\", \"withCollection\"));\n+    assertNotNull(m.get(\"withCollection\"));\n+\n+    Map policies = (Map) Utils.fromJSONString(\"{\" +\n+        \"  'cluster-preferences': [\" +\n+        \"    { 'minimize': 'cores'},\" +\n+        \"    { 'maximize': 'freedisk', 'precision': 50}\" +\n+        \"  ],\" +\n+        \"  'cluster-policy': [\" +\n+        \"    { 'replica': 0, 'nodeRole': 'overseer'}\" +\n+        \"    { 'replica': '<2', 'shard': '#EACH', 'node': '#ANY'},\" +\n+        \"  ]\" +\n+        \"}\");\n+    AutoScalingConfig config = new AutoScalingConfig(policies);\n+    Policy policy = config.getPolicy();\n+    Policy.Session session = policy.createSession(new DelegatingCloudManager(null) {\n+      @Override\n+      public ClusterStateProvider getClusterStateProvider() {\n+        return clusterStateProvider;\n+      }\n+\n+      @Override\n+      public NodeStateProvider getNodeStateProvider() {\n+        return solrClientNodeStateProvider;\n+      }\n+    });\n+    Suggester suggester = session.getSuggester(CollectionAction.MOVEREPLICA);\n+    suggester.hint(Hint.COLL_SHARD, new Pair<>(\"comments_coll\", \"shard1\"));\n+    suggester.hint(Hint.SRC_NODE, \"node1\");\n+    SolrRequest op = suggester.getSuggestion();\n+    assertNotNull(op);\n+    assertEquals(\"node2 should have been selected by move replica\",\"node2\",\n+        op.getParams().get(\"targetNode\"));\n+\n+    session = suggester.getSession();\n+    suggester = session.getSuggester(MOVEREPLICA);\n+    suggester.hint(Hint.COLL_SHARD, new Pair<>(\"comments_coll\", \"shard1\"));\n+    suggester.hint(Hint.SRC_NODE, \"node1\");\n+    op = suggester.getSuggestion();\n+    assertNull(op);\n+  }\n+\n   public void testValidate() {\n     expectError(\"replica\", -1, \"must be greater than\");\n     expectError(\"replica\", \"hello\", \"not a valid number\");\n@@ -1228,7 +1786,7 @@ public DistribStateManager getDistribStateManager() {\n     assertTrue(session.getPolicy() == config.getPolicy());\n     assertEquals(sessionWrapper.status, PolicyHelper.Status.EXECUTING);\n     sessionWrapper.release();\n-    assertTrue(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEF_INST);\n+    assertTrue(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEFAULT_INSTANCE);\n     PolicyHelper.SessionWrapper s1 = PolicyHelper.getSession(solrCloudManager);\n     assertEquals(sessionRef.getSessionWrapper().getCreateTime(), s1.getCreateTime());\n     PolicyHelper.SessionWrapper[] s2 = new PolicyHelper.SessionWrapper[1];\n@@ -1256,9 +1814,9 @@ public DistribStateManager getDistribStateManager() {\n     assertEquals(2, s1.getRefCount());\n \n     s2[0].release();\n-    assertFalse(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEF_INST);\n+    assertFalse(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEFAULT_INSTANCE);\n     s1.release();\n-    assertTrue(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEF_INST);\n+    assertTrue(sessionRef.getSessionWrapper() == PolicyHelper.SessionWrapper.DEFAULT_INSTANCE);\n \n \n   }\n@@ -1479,7 +2037,7 @@ public String getPolicyNameByCollection(String coll) {\n     assertEquals(\"node2\", op.getNode());\n   }\n \n-  private SolrCloudManager getSolrCloudManager(final Map<String, Map> nodeValues, String clusterState) {\n+  private SolrCloudManager getSolrCloudManager(final Map<String, Map> nodeValues, String clusterS) {\n     return new SolrCloudManager() {\n       ObjectCache objectCache = new ObjectCache();\n \n@@ -1521,7 +2079,7 @@ public NodeStateProvider getNodeStateProvider() {\n \n           @Override\n           public Map<String, Map<String, List<ReplicaInfo>>> getReplicaInfo(String node, Collection<String> keys) {\n-            return getReplicaDetails(node, clusterState);\n+            return getReplicaDetails(node, clusterS);\n           }\n         };\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/179c8f9b48af9bf3c327226d0e1fdbe460c4a325/solr/solrj/src/test/org/apache/solr/client/solrj/cloud/autoscaling/TestPolicy.java",
                "sha": "16addd4dd0426378da03237bdedd7eb16d73ae1d",
                "status": "modified"
            }
        ],
        "message": "SOLR-11990: Make it possible to co-locate replicas of multiple collections together in a node.\n\nA collection may be co-located with another collection during collection creation time by specifying a\n'withCollection' parameter. It can also be co-located afterwards by using the modify collection API.\nThe co-location guarantee is enforced regardless of future cluster operations whether they are invoked\nmanually via the Collection API or automatically by the Autoscaling framework.\n\nSquashed commit of the following:\n\ncommit 3827703b38c598f1247c90ab57d3d640ab3a9e21\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 11:54:10 2018 +0530\n\n    SOLR-11990: Added change log entry\n\ncommit 7977222e07ba47274062cb8d8a69e7956d644000\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 11:52:17 2018 +0530\n\n    SOLR-11990: Added change log entry\n\ncommit 1857075fdb9d535b6149ad4369fed8b64b0c01f6\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 11:49:51 2018 +0530\n\n    SOLR-11990: Added note about co-location guarantees being one way only\n\ncommit 8557cbc8a511f21d1fcad99e11ea9d2104d0bef4\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 10:43:37 2018 +0530\n\n    SOLR-11990: Remove unused import\n\ncommit 864b013fd744edca9b6b84a8a7573fab3c5310d5\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 10:21:59 2018 +0530\n\n    SOLR-11990: Fixing compilation issues after merging master\n\ncommit dd840a2f7e765ee96c899d4d9ea89b6b67c5ae62\nMerge: bb4ffb3 828d281\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Sat Jul 28 10:03:50 2018 +0530\n\n    Merge branch 'master' into jira/solr-11990\n\n    # Conflicts:\n    #\tsolr/solr-ref-guide/src/collections-api.adoc\n    #\tsolr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Clause.java\n    #\tsolr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Suggestion.java\n\ncommit bb4ffb32c4960a2809ac8927e214e1e012204a73\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Fri Jul 27 14:09:44 2018 +0530\n\n    SOLR-11990: Ensure that the suggestion are validated by the policy engine otherwise move to the next candidate replica or the next candidate node\n\ncommit a97d45b22f9c232e939f979502c761001be9ae24\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Fri Jul 27 13:22:10 2018 +0530\n\n    SOLR-11990: Autoscaling suggestions for withCollection violations should prefer moving replicas before adding replicas\n\ncommit 7b5a84338dfe7335599a5e96aff2d26cb4eeaac6\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Fri Jul 27 12:22:45 2018 +0530\n\n    SOLR-11990: Fix statement about the behavior of the modify collection API when modifying the withCollection parameter\n\ncommit 63aec4fe0de7025c16b6ebc47dad1004531ecee1\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Thu Jul 26 07:29:07 2018 +0530\n\n    SOLR-11990: Added new page to the reference guide describing how to colocate collections together including guarantees and limitations\n\ncommit 6bfcd0786bb30353de9c26a01ec97ce3191b58f8\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 25 21:42:25 2018 +0530\n\n    SOLR-11990: Added another test which creates two collections which are colocated with two different collections and ensures that create collection and add replica operations work correctly\n\ncommit 4cead778f0044b6fb4012b085abf7b60350f495b\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 25 21:07:47 2018 +0530\n\n    SOLR-11990: Stop or start jettys in test setup to ensure that we always have exactly 2 replicas running before a test starts\n\ncommit 70dbfd042c2164fcd76d406eeab1518e4d3147fb\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 25 19:19:07 2018 +0530\n\n    SOLR-11990: Added description of the new withCollection parameter in the reference guide\n\ncommit 9d8260852b9d667d4d8e026432fd7727b7789393\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 25 19:16:46 2018 +0530\n\n    SOLR-11990: Reset count down latch during test setup\n\ncommit ae508165571b1afde54337859b8d5fdbb1d67312\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 25 15:43:54 2018 +0530\n\n    SOLR-11990: Add support for withCollection in simulated create collection API\n\ncommit 84f026b8c4cc25edb548430b8f5ad09d2486b3b5\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 17:21:33 2018 +0530\n\n    SOLR-11990: Ported the refactoring made in CreateCollectionCmd to the simulated version so that simulation tests are able to create collections correctly\n\ncommit defe111c9d31c8e4f0f00b4f2f3c875f5b2fa602\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 16:17:52 2018 +0530\n\n    SOLR-11990: Add missing javadoc for return statement\n\ncommit 8e47d5bc4545548c5441909c3fcc1a7901b38185\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 16:11:45 2018 +0530\n\n    SOLR-11990: Replace usage of forbidden Charsets with StandardCharsets class\n\ncommit 2d1b9eb25ea96a3a42c000ae654400ed44c17554\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 16:07:36 2018 +0530\n\n    SOLR-11990: Extract ConditionType to an interface VarType along with a WithCollectionVarType implementation\n\ncommit 1de2a4f52a59afca28de75bfa5156a3d6567a4f5\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 12:53:26 2018 +0530\n\n    SOLR-11990: Pass strict-ness parameter to the ConditionType so that WITH_COLLECTION can choose not to project add replica in strict mode.\n\n    This ensures that add replica or move replica suggesters always choose nodes that already have withCollection replicas first unless there are violations in doing so. Only if the first pass fails to find a suitable replica, do we go to the other nodes in the cluster. This also removes the need for the majority of changes in AddReplicaSuggester and so they've been reverted.\n\ncommit 0d616ed9e9bad791548c87086cba7760d724350d\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Jul 24 11:36:34 2018 +0530\n\n    SOLR-11990: Minor changes to formatting and code comments\n\ncommit 1228538f934f35f15797d89c2c66f2deb9cddd8c\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon Jul 23 14:26:19 2018 +0530\n\n    SOLR-11990: Added a test which simulates a lost node and asserts that move replica suggester moves the replica on the lost node to a node already having the withCollection present\n\ncommit 582f1fd98de93ab73c74a1f623749dd031beb381\nAuthor: Noble Paul <noble@apache.org>\nDate:   Mon Jul 23 18:35:22 2018 +1000\n\n    SOLR-11990: NPE removing unnecessary System.out.println\n\ncommit 501bc6c1d066321b344bbb8b1de3c2ead52f8c49\nAuthor: Noble Paul <noble@apache.org>\nDate:   Mon Jul 23 18:31:07 2018 +1000\n\n    SOLR-11990: NPE during class init\n\ncommit acbf4a69321e16cff11cc7cf0a1f076fd9ac0037\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon Jul 23 13:55:30 2018 +0530\n\n    SOLR-11990: Added asserts on the nodes that should be selected by the add replica suggester\n\ncommit 4824933fd6eb7d1773acbff1a1a0c5e670226e0b\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Fri Jul 20 14:30:52 2018 +0530\n\n    SOLR-11990: Added WITH_COLLECTION to global tags. Fixed implementation of addViolatingReplicas and getSuggestions in the clause impl. Added more asserts in testWithCollectionSuggestions.\n\ncommit dbadb33211c190026e08d8e3ea587b6f8df8720b\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Fri Jul 20 13:44:36 2018 +0530\n\n    SOLR-11990: Added support for comparing violations, generating suggestions and adding violating replicas\n\ncommit ada1f17d5c93a4186260473e4822d2bee1da0e16\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 18 19:14:56 2018 +0530\n\n    SOLR-11990: Fix mock node state provider in TestPolicy to use the right cluster state. Added nocommits to ensure that we return the right suggestions for this feature.\n\ncommit ef2d61812e0d96eb2275b3411906d9de57ab835e\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 18 18:39:51 2018 +0530\n\n    SOLR-11990: Add missing node in nodeValues configuration\n\ncommit 34841fc01fea4a9f1e6a9f64050e576f2247a72b\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Jul 18 16:32:57 2018 +0530\n\n    SOLR-11990: Make it possible to co-locate replicas of multiple collections together in a node",
        "parent": "https://github.com/apache/lucene-solr/commit/828d2815f1cff7504fd3bdc0376367f737c5166c",
        "repo": "lucene-solr",
        "unit_tests": [
            "ComputePlanActionTest.java",
            "TestSimClusterStateProvider.java",
            "MoveReplicaSuggesterTest.java",
            "TestPolicy.java",
            "SuggesterTest.java",
            "TestCollectionAdminRequest.java"
        ]
    },
    "lucene-solr_18c317a": {
        "bug_id": "lucene-solr_18c317a",
        "commit": "https://github.com/apache/lucene-solr/commit/18c317a1e6fca78a7db2077eecaca3285b52dad3",
        "file": [
            {
                "additions": 71,
                "blob_url": "https://github.com/apache/lucene-solr/blob/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/search/Grouping.java",
                "changes": 76,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/search/Grouping.java?ref=18c317a1e6fca78a7db2077eecaca3285b52dad3",
                "deletions": 5,
                "filename": "solr/src/java/org/apache/solr/search/Grouping.java",
                "patch": "@@ -19,10 +19,14 @@\n \n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.search.*;\n+import org.apache.lucene.util.BytesRef;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.common.util.SimpleOrderedMap;\n+import org.apache.solr.schema.StrFieldSource;\n import org.apache.solr.search.function.DocValues;\n+import org.apache.solr.search.function.StringIndexDocValues;\n import org.apache.solr.search.function.ValueSource;\n+import org.apache.solr.util.SentinelIntSet;\n \n import java.io.IOException;\n import java.util.*;\n@@ -141,6 +145,9 @@ void prepare() throws IOException {\n     Collector createCollector() throws IOException {\n       maxGroupToFind = getMax(offset, numGroups, maxDoc);\n \n+      // if we aren't going to return any groups, disregard the offset \n+      if (numGroups == 0) maxGroupToFind = 0;\n+\n       if (compareSorts(sort, groupSort)) {\n         collector = new TopGroupCollector(groupBy, context, normalizeSort(sort), maxGroupToFind);\n       } else {\n@@ -151,22 +158,32 @@ Collector createCollector() throws IOException {\n \n     @Override\n     Collector createNextCollector() throws IOException {\n+      if (numGroups == 0) return null;\n+\n       int docsToCollect = getMax(groupOffset, docsPerGroup, maxDoc);\n-      if (docsToCollect < 0 || docsToCollect > maxDoc) docsToCollect = maxDoc;\n \n-      collector2 = new Phase2GroupCollector(collector, groupBy, context, groupSort, docsToCollect, needScores, offset);\n+      if (false && groupBy instanceof StrFieldSource) {\n+        collector2 = new Phase2StringGroupCollector(collector, groupBy, context, groupSort, docsToCollect, needScores, offset);\n+      } else {\n+        collector2 = new Phase2GroupCollector(collector, groupBy, context, groupSort, docsToCollect, needScores, offset);\n+      }\n       return collector2;\n     }\n \n     @Override\n     void finish() throws IOException {\n       NamedList groupResult = commonResponse();\n \n-      if (collector.orderedGroups == null) collector.buildSet();\n-\n       List groupList = new ArrayList();\n       groupResult.add(\"groups\", groupList);        // grouped={ key={ groups=[\n \n+      // handle case of rows=0\n+      if (numGroups == 0) return;\n+\n+      if (collector.orderedGroups == null) collector.buildSet();\n+\n+\n+\n       int skipCount = offset;\n       for (SearchGroup group : collector.orderedGroups) {\n         if (skipCount > 0) {\n@@ -411,7 +428,7 @@ Collector getCollector() {\n   public TopGroupCollector(ValueSource groupByVS, Map vsContext, Sort sort, int nGroups) throws IOException {\n     this.vs = groupByVS;\n     this.context = vsContext;\n-    this.nGroups = nGroups;\n+    this.nGroups = nGroups = Math.max(1,nGroups);  // we need a minimum of 1 for this collector\n \n     SortField[] sortFields = sort.getSort();\n     this.comparators = new FieldComparator[sortFields.length];\n@@ -839,3 +856,52 @@ public boolean acceptsDocsOutOfOrder() {\n   TopDocsCollector collector;\n }\n \n+\n+\n+class Phase2StringGroupCollector extends Phase2GroupCollector {\n+  FieldCache.DocTermsIndex index;\n+  SentinelIntSet ordSet;\n+  SearchGroupDocs[] groups;\n+  BytesRef spare;\n+\n+  public Phase2StringGroupCollector(TopGroupCollector topGroups, ValueSource groupByVS, Map vsContext, Sort sort, int docsPerGroup, boolean getScores, int offset) throws IOException {\n+    super(topGroups, groupByVS, vsContext,sort,docsPerGroup,getScores,offset);\n+    ordSet = new SentinelIntSet(groupMap.size(), -1);\n+    groups = new SearchGroupDocs[ordSet.keys.length];\n+  }\n+\n+  @Override\n+  public void setScorer(Scorer scorer) throws IOException {\n+    this.scorer = scorer;\n+    for (SearchGroupDocs group : groupMap.values())\n+      group.collector.setScorer(scorer);\n+  }\n+\n+  @Override\n+  public void collect(int doc) throws IOException {\n+    int slot = ordSet.find(index.getOrd(doc));\n+    if (slot >= 0) {\n+      groups[slot].collector.collect(doc);\n+    }\n+  }\n+\n+  @Override\n+  public void setNextReader(IndexReader reader, int docBase) throws IOException {\n+    super.setNextReader(reader, docBase);\n+    index = ((StringIndexDocValues)docValues).getDocTermsIndex();\n+\n+    ordSet.clear();\n+    for (SearchGroupDocs group : groupMap.values()) {\n+      int ord = index.binarySearchLookup(((MutableValueStr)group.groupValue).value, spare);\n+      if (ord > 0) {\n+        int slot = ordSet.put(ord);\n+        groups[slot] = group;\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean acceptsDocsOutOfOrder() {\n+    return false;\n+  }\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/search/Grouping.java",
                "sha": "f8dc1f5e92d17ae38714a0e01829fae2aeb6ed80",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/search/function/StringIndexDocValues.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/search/function/StringIndexDocValues.java?ref=18c317a1e6fca78a7db2077eecaca3285b52dad3",
                "deletions": 0,
                "filename": "solr/src/java/org/apache/solr/search/function/StringIndexDocValues.java",
                "patch": "@@ -41,6 +41,10 @@ public StringIndexDocValues(ValueSource vs, IndexReader reader, String field) th\n       }\n       this.vs = vs;\n     }\n+\n+    public FieldCache.DocTermsIndex getDocTermsIndex() {\n+      return termsIndex;\n+    }\n   \n     protected abstract String toTerm(String readableValue);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/search/function/StringIndexDocValues.java",
                "sha": "fb22cfd3aef62d773a4e2290bab766d7751ad77e",
                "status": "modified"
            },
            {
                "additions": 132,
                "blob_url": "https://github.com/apache/lucene-solr/blob/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/util/SentinelIntSet.java",
                "changes": 132,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/util/SentinelIntSet.java?ref=18c317a1e6fca78a7db2077eecaca3285b52dad3",
                "deletions": 0,
                "filename": "solr/src/java/org/apache/solr/util/SentinelIntSet.java",
                "patch": "@@ -0,0 +1,132 @@\n+/**\r\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\r\n+ * contributor license agreements.  See the NOTICE file distributed with\r\n+ * this work for additional information regarding copyright ownership.\r\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\r\n+ * (the \"License\"); you may not use this file except in compliance with\r\n+ * the License.  You may obtain a copy of the License at\r\n+ *\r\n+ *     http://www.apache.org/licenses/LICENSE-2.0\r\n+ *\r\n+ * Unless required by applicable law or agreed to in writing, software\r\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n+ * See the License for the specific language governing permissions and\r\n+ * limitations under the License.\r\n+ */\r\n+\r\n+package org.apache.solr.util;\r\n+\r\n+import java.util.Arrays;\r\n+\r\n+/** A native int set where one value is reserved to mean \"EMPTY\" */\r\n+public class SentinelIntSet {\r\n+  public int[] keys;\r\n+  public int count;\r\n+  public final int emptyVal;\r\n+  public int rehashCount;   // the count at which a rehash should be done\r\n+\r\n+  public SentinelIntSet(int size, int emptyVal) {\r\n+    this.emptyVal = emptyVal;\r\n+    int tsize = Math.max(org.apache.lucene.util.BitUtil.nextHighestPowerOfTwo(size), 1);\r\n+    rehashCount = tsize - (tsize>>2);\r\n+    if (tsize <= rehashCount) {\r\n+      tsize <<= 1;\r\n+      rehashCount = tsize - (tsize>>2);\r\n+    }\r\n+    keys = new int[tsize];\r\n+    if (emptyVal != 0)\r\n+      clear();\r\n+  }\r\n+\r\n+  public void clear() {\r\n+    Arrays.fill(keys, emptyVal);\r\n+    count = 0;\r\n+  }\r\n+\r\n+  public int hash(int key) {\r\n+    return key;\r\n+  }\r\n+\r\n+  public int size() { return count; }\r\n+\r\n+  /** returns the slot for this key */\r\n+  public int getSlot(int key) {\r\n+    assert key != emptyVal;\r\n+    int h = hash(key);\r\n+    int s = h & (keys.length-1);\r\n+    if (keys[s] == key || keys[s]== emptyVal) return s;\r\n+\r\n+    int increment = (h>>7)|1;\r\n+    do {\r\n+      s = (s + increment) & (keys.length-1);\r\n+    } while (keys[s] != key && keys[s] != emptyVal);\r\n+    return s;\r\n+  }\r\n+\r\n+  /** returns the slot for this key, or -slot-1 if not found */\r\n+  public int find(int key) {\r\n+    assert key != emptyVal;\r\n+    int h = hash(key);\r\n+    int s = h & (keys.length-1);\r\n+    if (keys[s] == key) return s;\r\n+    if (keys[s] == emptyVal) return -s-1;\r\n+\r\n+    int increment = (h>>7)|1;\r\n+    for(;;) {\r\n+      s = (s + increment) & (keys.length-1);\r\n+      if (keys[s] == key) return s;\r\n+      if (keys[s] == emptyVal) return -s-1;\r\n+    }\r\n+  }\r\n+\r\n+\r\n+  public boolean exists(int key) {\r\n+    return find(key) >= 0;\r\n+  }\r\n+\r\n+\r\n+  public int put(int key) {\r\n+    int s = find(key);\r\n+    if (s < 0) {\r\n+      if (count >= rehashCount) {\r\n+        rehash();\r\n+        s = getSlot(key);\r\n+      } else {\r\n+        s = -s-1;\r\n+      }\r\n+      count++;\r\n+      keys[s] = key;\r\n+      putKey(key, s);\r\n+    } else {\r\n+      overwriteKey(key, s);\r\n+    }\r\n+    return s;\r\n+  }\r\n+\r\n+\r\n+  protected void putKey(int key, int slot) {}\r\n+  protected void overwriteKey(int key, int slot) {}\r\n+\r\n+  protected void startRehash(int newSize) {}\r\n+  protected void moveKey(int key, int oldSlot, int newSlot) {}\r\n+  protected void endRehash() {}\r\n+\r\n+  public void rehash() {\r\n+    int newSize = keys.length << 1;\r\n+    startRehash(newSize);\r\n+    int[] oldKeys = keys;\r\n+    keys = new int[newSize];\r\n+    for (int i=0; i<oldKeys.length; i++) {\r\n+      int key = oldKeys[i];\r\n+      if (key == emptyVal) continue;\r\n+      int newSlot = getSlot(key);\r\n+      keys[newSlot] = key;\r\n+      moveKey(key, i, newSlot);\r\n+    }\r\n+    endRehash();\r\n+    rehashCount = newSize - (newSize>>2);\r\n+\r\n+  }\r\n+\r\n+}\r",
                "raw_url": "https://github.com/apache/lucene-solr/raw/18c317a1e6fca78a7db2077eecaca3285b52dad3/solr/src/java/org/apache/solr/util/SentinelIntSet.java",
                "sha": "28ed7eba81fb0060dded42d34a4feb068143632c",
                "status": "added"
            }
        ],
        "message": "SOLR-236: grouping - fix NPE if rows=0, add prototype string grouping speedup\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1035074 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/a73f5e279c510a8746bbf0e4754d205248a0d355",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestGrouping.java",
            "TestSentinelIntSet.java"
        ]
    },
    "lucene-solr_1941777": {
        "bug_id": "lucene-solr_1941777",
        "commit": "https://github.com/apache/lucene-solr/commit/1941777fdcf4d7cb0600df9633a466f2790b4448",
        "file": [
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/lucene-solr/blob/1941777fdcf4d7cb0600df9633a466f2790b4448/solr/solrj/src/java/org/apache/solr/common/cloud/ConnectionManager.java",
                "changes": 39,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/cloud/ConnectionManager.java?ref=1941777fdcf4d7cb0600df9633a466f2790b4448",
                "deletions": 21,
                "filename": "solr/solrj/src/java/org/apache/solr/common/cloud/ConnectionManager.java",
                "patch": "@@ -63,20 +63,14 @@ public ConnectionManager(String name, SolrZkClient client, String zkServerAddres\n   }\n   \n   private synchronized void connected() {\n-    if (disconnectedTimer != null) {\n-      disconnectedTimer.cancel();\n-      disconnectedTimer = null;\n-    }\n+    cancelTimer();\n     connected = true;\n     likelyExpired = false;\n     notifyAll();\n   }\n \n   private synchronized void disconnected() {\n-    if (disconnectedTimer != null) {\n-      disconnectedTimer.cancel();\n-      disconnectedTimer = null;\n-    }\n+    cancelTimer();\n     if (!isClosed) {\n       disconnectedTimer = new Timer(true);\n       disconnectedTimer.schedule(new TimerTask() {\n@@ -90,14 +84,23 @@ public void run() {\n       if (isClosed) {\n         // we might have closed after getting by isClosed\n         // and before starting the new timer\n-        disconnectedTimer.cancel();\n-        disconnectedTimer = null;\n+        cancelTimer();\n       }\n     }\n     connected = false;\n     notifyAll();\n   }\n \n+  private void cancelTimer() {\n+    try {\n+      this.disconnectedTimer.cancel();\n+    } catch (NullPointerException e) {\n+      // fine\n+    } finally {\n+      this.disconnectedTimer = null;\n+    }\n+  }\n+\n   @Override\n   public void process(WatchedEvent event) {\n     if (log.isInfoEnabled()) {\n@@ -117,10 +120,10 @@ public void process(WatchedEvent event) {\n       clientConnected.countDown();\n       connectionStrategy.connected();\n     } else if (state == KeeperState.Expired) {\n-      if (disconnectedTimer != null) {\n-        disconnectedTimer.cancel();\n-        disconnectedTimer = null;\n-      }\n+      // we don't call disconnected because there\n+      // is no need to start the timer - if we are expired\n+      // likelyExpired can just be set to true\n+      cancelTimer();\n       \n       connected = false;\n       likelyExpired = true;\n@@ -197,13 +200,7 @@ public synchronized boolean isConnected() {\n   public void close() {\n     this.isClosed = true;\n     this.likelyExpired = true;\n-    try {\n-      this.disconnectedTimer.cancel();\n-    } catch (NullPointerException e) {\n-      // fine\n-    } finally {\n-      this.disconnectedTimer = null;\n-    }\n+    cancelTimer();\n   }\n   \n   public boolean isLikelyExpired() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/1941777fdcf4d7cb0600df9633a466f2790b4448/solr/solrj/src/java/org/apache/solr/common/cloud/ConnectionManager.java",
                "sha": "961ed35597576ee91de061306d943a014ecd71e9",
                "status": "modified"
            }
        ],
        "message": "SOLR-5577: Protect against NPE race with close - spotted by Greg Chanan\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1559844 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/fc9f019cdbbd9f8c30468f4439de76c20c6a90b8",
        "repo": "lucene-solr",
        "unit_tests": [
            "ConnectionManagerTest.java"
        ]
    },
    "lucene-solr_19a8be3": {
        "bug_id": "lucene-solr_19a8be3",
        "commit": "https://github.com/apache/lucene-solr/commit/19a8be3c9f4850d9f944ac8af97da58584b445a8",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=19a8be3c9f4850d9f944ac8af97da58584b445a8",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -99,6 +99,8 @@ Bug Fixes\n \n * SOLR-11255: Fix occasional ConcurrentModificationException when using SolrInfoMBeanHandler. (ab)\n \n+* SOLR-11272: fix NPE when EmbeddedSolrServer handles /admin/* request and so one (Stephen Allen via Mikhail Khludnev)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/CHANGES.txt",
                "sha": "13b6ed7e3ff629d2b3e7988a8bcd29cae9984f75",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java?ref=19a8be3c9f4850d9f944ac8af97da58584b445a8",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java",
                "patch": "@@ -127,6 +127,7 @@ public EmbeddedSolrServer(CoreContainer coreContainer, String coreName) {\n     if (handler != null) {\n       try {\n         SolrQueryRequest req = _parser.buildRequestFrom(null, request.getParams(), request.getContentStreams());\n+        req.getContext().put(PATH, path);\n         SolrQueryResponse resp = new SolrQueryResponse();\n         handler.handleRequest(req, resp);\n         checkForExceptions(resp);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java",
                "sha": "0c7ea25f1835ba0533560f1eacb86074503859cf",
                "status": "modified"
            },
            {
                "additions": 78,
                "blob_url": "https://github.com/apache/lucene-solr/blob/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/core/src/test/org/apache/solr/client/solrj/embedded/TestEmbeddedSolrServerAdminHandler.java",
                "changes": 78,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/client/solrj/embedded/TestEmbeddedSolrServerAdminHandler.java?ref=19a8be3c9f4850d9f944ac8af97da58584b445a8",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/client/solrj/embedded/TestEmbeddedSolrServerAdminHandler.java",
                "patch": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.client.solrj.embedded;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collection;\n+\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrClient;\n+import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.params.ModifiableSolrParams;\n+import org.apache.solr.common.params.SolrParams;\n+import org.apache.solr.common.util.ContentStream;\n+import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.core.NodeConfig;\n+import org.apache.solr.core.SolrResourceLoader;\n+import org.junit.Test;\n+\n+public class TestEmbeddedSolrServerAdminHandler extends SolrTestCaseJ4 {\n+\n+    @Test\n+    public void testPathIsAddedToContext() throws IOException, SolrServerException {\n+        final Path path = createTempDir();\n+\n+        final SolrResourceLoader loader = new SolrResourceLoader(path);\n+        final NodeConfig config = new NodeConfig.NodeConfigBuilder(\"testnode\", loader)\n+                .setConfigSetBaseDirectory(Paths.get(TEST_HOME()).resolve(\"configsets\").toString())\n+                .build();\n+\n+        try (final EmbeddedSolrServer server = new EmbeddedSolrServer(config, \"collection1\")) {\n+            final SystemInfoRequest info = new SystemInfoRequest();\n+            final NamedList response = server.request(info);\n+            assertTrue(response.size() > 0);\n+        }\n+    }\n+\n+    private static class SystemInfoRequest extends SolrRequest<QueryResponse> {\n+\n+        public SystemInfoRequest() {\n+            super(METHOD.GET, \"/admin/info/system\");\n+        }\n+\n+        @Override\n+        public SolrParams getParams() {\n+            return new ModifiableSolrParams();\n+        }\n+\n+        @Override\n+        public Collection<ContentStream> getContentStreams() throws IOException {\n+            return null;\n+        }\n+\n+        @Override\n+        protected QueryResponse createResponse(final SolrClient client) {\n+            return new QueryResponse();\n+        }\n+    }\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/19a8be3c9f4850d9f944ac8af97da58584b445a8/solr/core/src/test/org/apache/solr/client/solrj/embedded/TestEmbeddedSolrServerAdminHandler.java",
                "sha": "84ecedfa7d51660cb81e651af6fff9fac24c82cf",
                "status": "added"
            }
        ],
        "message": "SOLR-11272: fix NPE from EmbeddedSolrServer on /admin/info/system",
        "parent": "https://github.com/apache/lucene-solr/commit/946c6a95faa61902e6fffdb54373c04135c68ad9",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestEmbeddedSolrServer.java"
        ]
    },
    "lucene-solr_22f119d": {
        "bug_id": "lucene-solr_22f119d",
        "commit": "https://github.com/apache/lucene-solr/commit/22f119d50c62f695330005d8bfba09595e592439",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/22f119d50c62f695330005d8bfba09595e592439/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java?ref=22f119d50c62f695330005d8bfba09595e592439",
                "deletions": 1,
                "filename": "lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java",
                "patch": "@@ -227,7 +227,7 @@ public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean di\n         outputCompounds = false;\n         break;\n     }\n-    buffer.reset(input);\n+    buffer.reset(null); // best effort NPE consumers that don't call reset()\n \n     resetState();\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/22f119d50c62f695330005d8bfba09595e592439/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java",
                "sha": "b03c80effc8fcfeb7a0ee3e782fad0fa25c46055",
                "status": "modified"
            }
        ],
        "message": "throw a best-effort NPE from kuromoji if you don't consume the TS correctly\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1401461 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/e670e324717e6f0098cc4f1211ba276f6cd2989e",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestJapaneseTokenizer.java"
        ]
    },
    "lucene-solr_232aaa4": {
        "bug_id": "lucene-solr_232aaa4",
        "commit": "https://github.com/apache/lucene-solr/commit/232aaa42ed3d136672881d1bd1563aa29945fdbf",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/232aaa42ed3d136672881d1bd1563aa29945fdbf/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java?ref=232aaa42ed3d136672881d1bd1563aa29945fdbf",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "patch": "@@ -162,12 +162,16 @@ public void close() {\n     }\n     \n     try {\n-      defaultClient.getConnectionManager().shutdown();\n+      if(defaultClient != null) {\n+        defaultClient.getConnectionManager().shutdown();\n+      }\n     } catch (Throwable e) {\n       SolrException.log(log, e);\n     }\n     try {\n-      loadbalancer.shutdown();\n+      if(loadbalancer != null) {\n+        loadbalancer.shutdown();\n+      }\n     } catch (Throwable e) {\n       SolrException.log(log, e);\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/232aaa42ed3d136672881d1bd1563aa29945fdbf/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java",
                "sha": "9410f959a8798a6810b63cafc94740a68572a66d",
                "status": "modified"
            }
        ],
        "message": "SOLR-4218: SolrTestCaseJ4 throws NPE when closing the core (on the afterClass method)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1423932 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/aa695debba46841efe52125973ab12fca896bf79",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestHttpShardHandlerFactory.java"
        ]
    },
    "lucene-solr_24260eb": {
        "bug_id": "lucene-solr_24260eb",
        "commit": "https://github.com/apache/lucene-solr/commit/24260eb6daa0ad0470935fdffaeb773c6b6d7eb2",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/24260eb6daa0ad0470935fdffaeb773c6b6d7eb2/lucene/src/java/org/apache/lucene/index/SnapshotDeletionPolicy.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/java/org/apache/lucene/index/SnapshotDeletionPolicy.java?ref=24260eb6daa0ad0470935fdffaeb773c6b6d7eb2",
                "deletions": 0,
                "filename": "lucene/src/java/org/apache/lucene/index/SnapshotDeletionPolicy.java",
                "patch": "@@ -71,6 +71,10 @@ public synchronized void onCommit(List<? extends IndexCommit> commits) throws IO\n    *  consume an extra 1X of your total index size, until\n    *  you release the snapshot. */\n   public synchronized IndexCommit snapshot() {\n+    if (lastCommit == null) {\n+      throw new IllegalStateException(\"no index commits to snapshot !\");\n+    }\n+    \n     if (snapshot == null)\n       snapshot = lastCommit.getSegmentsFileName();\n     else",
                "raw_url": "https://github.com/apache/lucene-solr/raw/24260eb6daa0ad0470935fdffaeb773c6b6d7eb2/lucene/src/java/org/apache/lucene/index/SnapshotDeletionPolicy.java",
                "sha": "e067e70ecf17cb39048bd6e23e43b5d48ad8db10",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/24260eb6daa0ad0470935fdffaeb773c6b6d7eb2/lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java?ref=24260eb6daa0ad0470935fdffaeb773c6b6d7eb2",
                "deletions": 7,
                "filename": "lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java",
                "patch": "@@ -1,6 +1,4 @@\n-package org.apache.lucene;\n-// Intentionally not in org.apache.lucene.index, to assert\n-// that we do not require any package private access.\n+package org.apache.lucene.index;\n \n /**\n  * Licensed to the Apache Software Foundation (ASF) under one or more\n@@ -19,6 +17,8 @@\n  * limitations under the License.\n  */\n \n+import static org.junit.Assert.*;\n+\n import java.util.Collection;\n import java.io.File;\n import java.io.IOException;\n@@ -34,21 +34,22 @@\n import org.apache.lucene.index.IndexWriterConfig;\n import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;\n import org.apache.lucene.index.IndexWriter;\n-import org.apache.lucene.index.TestIndexWriter;\n import org.apache.lucene.index.SnapshotDeletionPolicy;\n+import org.apache.lucene.util.LuceneTestCaseJ4;\n import org.apache.lucene.util.ThreadInterruptedException;\n-import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.util._TestUtil;\n+import org.junit.Test;\n \n //\n // This was developed for Lucene In Action,\n // http://lucenebook.com\n //\n \n-public class TestSnapshotDeletionPolicy extends LuceneTestCase {\n+public class TestSnapshotDeletionPolicy extends LuceneTestCaseJ4 {\n   \n   public static final String INDEX_PATH = \"test.snapshots\";\n \n+  @Test\n   public void testSnapshotDeletionPolicy() throws Exception {\n     File dir = _TestUtil.getTempDir(INDEX_PATH);\n     try {\n@@ -64,6 +65,7 @@ public void testSnapshotDeletionPolicy() throws Exception {\n     dir2.close();\n   }\n \n+  @Test\n   public void testReuseAcrossWriters() throws Exception {\n     Directory dir = new MockRAMDirectory();\n \n@@ -235,5 +237,13 @@ private void readFile(Directory dir, String name) throws Exception {\n       input.close();\n     }\n   }\n+  \n+  @Test(expected=IllegalStateException.class)\n+  public void testNoCommits() throws Exception {\n+    // Tests that if there were no commits when snapshot() is called, then\n+    // IllegalStateException is thrown rather than NPE.\n+    SnapshotDeletionPolicy sdp = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());\n+    sdp.snapshot();\n+  }\n+  \n }\n-",
                "previous_filename": "lucene/src/test/org/apache/lucene/TestSnapshotDeletionPolicy.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/24260eb6daa0ad0470935fdffaeb773c6b6d7eb2/lucene/src/test/org/apache/lucene/index/TestSnapshotDeletionPolicy.java",
                "sha": "9e9464364e01fdbc9f9cf30141224de2fd68a789",
                "status": "renamed"
            }
        ],
        "message": "LUCENE-2397: SnapshotDeletionPolicy.snapshot() throws NPE if no commits happened\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@935522 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/baa94a8936cb65aa726d0a5145189c52e41d99a8",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSnapshotDeletionPolicy.java"
        ]
    },
    "lucene-solr_2482af4": {
        "bug_id": "lucene-solr_2482af4",
        "commit": "https://github.com/apache/lucene-solr/commit/2482af467d152d11d89993436256f848f8acb64a",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2482af467d152d11d89993436256f848f8acb64a/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=2482af467d152d11d89993436256f848f8acb64a",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -144,6 +144,9 @@ Bug Fixes\n   marked as 'down' if multiple replicas with the same core name exist in the cluster.\n   (shalin)\n \n+* SOLR-7418: Check and raise a SolrException instead of an NPE when an invalid doc id is sent\n+   to the MLTQParser. (Anshum Gupta)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2482af467d152d11d89993436256f848f8acb64a/solr/CHANGES.txt",
                "sha": "08fccb28ae174d18363fd6ae0a5e67a381fddf36",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2482af467d152d11d89993436256f848f8acb64a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java?ref=2482af467d152d11d89993436256f848f8acb64a",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "patch": "@@ -52,6 +52,11 @@ public Query parse() {\n     String id = localParams.get(QueryParsing.V);\n     // Do a Real Time Get for the document\n     SolrDocument doc = getDocument(id);\n+    if(doc == null) {\n+      new SolrException(\n+          SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n+          \"document with id [\" + id + \"]\");\n+    }\n     \n     MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n     // TODO: Are the mintf and mindf defaults ok at 1/0 ?",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2482af467d152d11d89993436256f848f8acb64a/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "sha": "5f2c300f6a58c76663abf1b9521bf0e6519db77c",
                "status": "modified"
            },
            {
                "additions": 51,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2482af467d152d11d89993436256f848f8acb64a/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "changes": 93,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java?ref=2482af467d152d11d89993436256f848f8acb64a",
                "deletions": 42,
                "filename": "solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "patch": "@@ -17,6 +17,7 @@\n  * limitations under the License.\n  */\n \n+import org.apache.solr.client.solrj.SolrServerException;\n import org.apache.solr.client.solrj.response.QueryResponse;\n import org.apache.solr.cloud.AbstractFullDistribZkTestBase;\n import org.apache.solr.common.SolrDocument;\n@@ -27,6 +28,7 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.HashSet;\n@@ -55,33 +57,35 @@ public void test() throws Exception {\n \n     String id = \"id\";\n     delQ(\"*:*\");\n-    indexDoc(sdoc(id, \"1\", \"lowerfilt\", \"toyota\"));\n-    indexDoc(sdoc(id, \"2\", \"lowerfilt\", \"chevrolet\"));\n-    indexDoc(sdoc(id, \"3\", \"lowerfilt\", \"bmw usa\"));\n-    indexDoc(sdoc(id, \"4\", \"lowerfilt\", \"ford\"));\n-    indexDoc(sdoc(id, \"5\", \"lowerfilt\", \"ferrari\"));\n-    indexDoc(sdoc(id, \"6\", \"lowerfilt\", \"jaguar\"));\n-    indexDoc(sdoc(id, \"7\", \"lowerfilt\", \"mclaren moon or the moon and moon moon shine and the moon but moon was good foxes too\"));\n-    indexDoc(sdoc(id, \"8\", \"lowerfilt\", \"sonata\"));\n-    indexDoc(sdoc(id, \"9\", \"lowerfilt\", \"The quick red fox jumped over the lazy big and large brown dogs.\"));\n-    indexDoc(sdoc(id, \"10\", \"lowerfilt\", \"blue\"));\n-    indexDoc(sdoc(id, \"12\", \"lowerfilt\", \"glue\"));\n-    indexDoc(sdoc(id, \"13\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"14\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"15\", \"lowerfilt\", \"The fat red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"16\", \"lowerfilt\", \"The slim red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"17\", \"lowerfilt\", \"The quote red fox jumped moon over the lazy brown dogs moon. Of course moon. Foxes and moon come back to the foxes and moon\"));\n-    indexDoc(sdoc(id, \"18\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"19\", \"lowerfilt\", \"The hose red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"20\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"21\", \"lowerfilt\", \"The court red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"22\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"23\", \"lowerfilt\", \"The quote red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"24\", \"lowerfilt\", \"The file red fox jumped over the lazy brown dogs.\"));\n-    indexDoc(sdoc(id, \"25\", \"lowerfilt\", \"rod fix\"));\n-    indexDoc(sdoc(id, \"26\", \"lowerfilt\", \"bmw usa 328i\"));\n-    indexDoc(sdoc(id, \"27\", \"lowerfilt\", \"bmw usa 535i\"));\n-    indexDoc(sdoc(id, \"28\", \"lowerfilt\", \"bmw 750Li\"));\n+    String FIELD1 = \"lowerfilt\" ;\n+    \n+    indexDoc(sdoc(id, \"1\", FIELD1, \"toyota\"));\n+    indexDoc(sdoc(id, \"2\", FIELD1, \"chevrolet\"));\n+    indexDoc(sdoc(id, \"3\", FIELD1, \"bmw usa\"));\n+    indexDoc(sdoc(id, \"4\", FIELD1, \"ford\"));\n+    indexDoc(sdoc(id, \"5\", FIELD1, \"ferrari\"));\n+    indexDoc(sdoc(id, \"6\", FIELD1, \"jaguar\"));\n+    indexDoc(sdoc(id, \"7\", FIELD1, \"mclaren moon or the moon and moon moon shine and the moon but moon was good foxes too\"));\n+    indexDoc(sdoc(id, \"8\", FIELD1, \"sonata\"));\n+    indexDoc(sdoc(id, \"9\", FIELD1, \"The quick red fox jumped over the lazy big and large brown dogs.\"));\n+    indexDoc(sdoc(id, \"10\", FIELD1, \"blue\"));\n+    indexDoc(sdoc(id, \"12\", FIELD1, \"glue\"));\n+    indexDoc(sdoc(id, \"13\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"14\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"15\", FIELD1, \"The fat red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"16\", FIELD1, \"The slim red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"17\", FIELD1, \"The quote red fox jumped moon over the lazy brown dogs moon. Of course moon. Foxes and moon come back to the foxes and moon\"));\n+    indexDoc(sdoc(id, \"18\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"19\", FIELD1, \"The hose red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"20\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"21\", FIELD1, \"The court red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"22\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"23\", FIELD1, \"The quote red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"24\", FIELD1, \"The file red fox jumped over the lazy brown dogs.\"));\n+    indexDoc(sdoc(id, \"25\", FIELD1, \"rod fix\"));\n+    indexDoc(sdoc(id, \"26\", FIELD1, \"bmw usa 328i\"));\n+    indexDoc(sdoc(id, \"27\", FIELD1, \"bmw usa 535i\"));\n+    indexDoc(sdoc(id, \"28\", FIELD1, \"bmw 750Li\"));\n \n     commit();\n \n@@ -131,22 +135,15 @@ public void test() throws Exception {\n     String expectedQueryString = \"lowerfilt:over lowerfilt:fox lowerfilt:lazy lowerfilt:brown \"\n         + \"lowerfilt:jumped lowerfilt:red lowerfilt:dogs. lowerfilt:quote lowerfilt:the\";\n     \n-    try {\n-      ArrayList<String> actualParsedQueries = (ArrayList<String>) queryResponse\n-          .getDebugMap().get(\"parsedquery\");\n-\n-      for (int counter = 0; counter < actualParsedQueries.size(); counter++) {\n-        assertTrue(\"Parsed queries aren't equal\",\n-            compareParsedQueryStrings(expectedQueryString,\n-                actualParsedQueries.get(counter)));\n-      }\n-    } catch (ClassCastException ex) {\n-      // TODO: Adding this to just track a rare test failure.\n-      // Once SOLR-6755 is resolved, this should be removed.\n-      log.info(\"QueryResponse.debugMap: {}\", queryResponse.getDebugMap().toString());\n-      log.info(\"ClusterState: {}\", cloudClient.getZkStateReader().getClusterState().toString());\n-    }\n+    ArrayList<String> actualParsedQueries = (ArrayList<String>) queryResponse\n+        .getDebugMap().get(\"parsedquery\");\n \n+    for (int counter = 0; counter < actualParsedQueries.size(); counter++) {\n+      assertTrue(\"Parsed queries aren't equal\",\n+          compareParsedQueryStrings(expectedQueryString,\n+              actualParsedQueries.get(counter)));\n+    }\n+  \n     // Assert that {!mlt}id does not throw an exception i.e. implicitly, only fields that are stored + have explicit\n     // analyzer are used for MLT Query construction.\n     params = new ModifiableSolrParams();\n@@ -162,6 +159,18 @@ public void test() throws Exception {\n     assertArrayEquals(expectedIds, actualIds);\n   }\n   \n+  @Test\n+  public void testInvalidDocument() throws IOException {\n+    ModifiableSolrParams params = new ModifiableSolrParams();\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}nonexistentdocid\");\n+    try {\n+      cloudClient.query(params);\n+      fail(\"The above query is supposed to throw an exception.\");\n+    } catch (SolrServerException e) {\n+      // Do nothing.\n+    }\n+  }\n+  \n   private boolean compareParsedQueryStrings(String expected, String actual) {\n     HashSet<String> expectedQueryParts = new HashSet<>();\n     expectedQueryParts.addAll(Arrays.asList(expected.split(\"\\\\s+\")));",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2482af467d152d11d89993436256f848f8acb64a/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "sha": "c0b0eb08203cd2b3d9703cc331fee2dc0d4a294f",
                "status": "modified"
            }
        ],
        "message": "SOLR-7418:  Check and raise a SolrException instead of an NPE when an invalid doc id is sent to the MLTQParser in Cloud mode\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1675230 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/1422c4607f30cb576333ac6fba7f864d8e9fdc4a",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudMLTQParserTest.java"
        ]
    },
    "lucene-solr_2559617": {
        "bug_id": "lucene-solr_2559617",
        "commit": "https://github.com/apache/lucene-solr/commit/255961719f8d0f3704dbfbf5c6191e3a6a88e029",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/255961719f8d0f3704dbfbf5c6191e3a6a88e029/solr/core/src/java/org/apache/solr/core/RequestHandlers.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/RequestHandlers.java?ref=255961719f8d0f3704dbfbf5c6191e3a6a88e029",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/core/RequestHandlers.java",
                "patch": "@@ -494,7 +494,7 @@ protected SolrRequestHandler createRequestHandler() {\n     public void close() throws Exception {\n       super.close();\n       if (_closed) return;\n-      classLoader.releaseJar();\n+      if(classLoader != null) classLoader.releaseJar();\n       _closed = true;\n     }\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/255961719f8d0f3704dbfbf5c6191e3a6a88e029/solr/core/src/java/org/apache/solr/core/RequestHandlers.java",
                "sha": "58d0449f3a182b11ed0c4b0ea0395ced89ef3afb",
                "status": "modified"
            }
        ],
        "message": "SOLR-6801 NPE on core reload\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1652431 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/94836356486b628aaa6e34b5c1be1cbcc83bb604",
        "repo": "lucene-solr",
        "unit_tests": [
            "RequestHandlersTest.java"
        ]
    },
    "lucene-solr_2671418": {
        "bug_id": "lucene-solr_2671418",
        "commit": "https://github.com/apache/lucene-solr/commit/2671418cfb65abe054ed58f4ee9152fd09454a81",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/CHANGES.txt",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -175,6 +175,14 @@ Bug Fixes\n \n * SOLR-6245: Socket and Connection configuration are ignored in HttpSolrServer when passing in HttpClient.\n   (Patanachai Tangchaisin, shalin)\n+  \n+* SOLR-6137: Schemaless concurrency improvements:\n+  - Fixed an NPE when reloading a managed schema with no dynamic copy fields\n+  - Moved parsing and schema fields addition to after the distributed phase\n+  - AddSchemaFieldsUpdateProcessor now uses a fixed schema rather than always\n+    retrieving the latest, and holds the schema update lock through the entire\n+    schema swap-out process\n+  (Gregory Chanan via Steve Rowe)\n \n Optimizations\n ---------------------",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/CHANGES.txt",
                "sha": "476eb1677f4548763c4c7e608539497b93de8398",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "patch": "@@ -336,7 +336,7 @@ ManagedIndexSchema reloadFields(InputSource inputSource, int schemaZkVersion) {\n       // create new copyField-related objects so we don't affect the\n       // old schema\n       newSchema.copyFieldsMap = new HashMap<>();\n-      newSchema.dynamicCopyFields = null;\n+      newSchema.dynamicCopyFields = new DynamicCopy[] {};\n       newSchema.copyFieldTargetCounts = new HashMap<>();\n       newSchema.loadCopyFields(document, xpath);\n       if (null != uniqueKeyField) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "sha": "ec898dee8265d1360bd189c289650e3957c346d8",
                "status": "modified"
            },
            {
                "additions": 46,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactory.java",
                "changes": 81,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactory.java?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 35,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactory.java",
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.solr.common.SolrInputField;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.core.SolrCore;\n+import org.apache.solr.core.SolrResourceLoader;\n import org.apache.solr.request.SolrQueryRequest;\n import org.apache.solr.response.SolrQueryResponse;\n import org.apache.solr.schema.IndexSchema;\n@@ -127,14 +128,9 @@\n   private List<TypeMapping> typeMappings = Collections.emptyList();\n   private SelectorParams inclusions = new SelectorParams();\n   private Collection<SelectorParams> exclusions = new ArrayList<>();\n-  private FieldNameSelector selector = null;\n+  private SolrResourceLoader solrResourceLoader = null;\n   private String defaultFieldType;\n \n-  protected final FieldMutatingUpdateProcessor.FieldNameSelector getSelector() {\n-    if (null != selector) return selector;\n-    throw new SolrException(SERVER_ERROR, \"selector was never initialized, inform(SolrCore) never called???\");\n-  }\n-\n   @Override\n   public UpdateRequestProcessor getInstance(SolrQueryRequest req, \n                                             SolrQueryResponse rsp, \n@@ -168,28 +164,13 @@ public void init(NamedList args) {\n \n   @Override\n   public void inform(SolrCore core) {\n-    selector = FieldMutatingUpdateProcessor.createFieldNameSelector\n-        (core.getResourceLoader(), core, inclusions, getDefaultSelector(core));\n-\n-    for (SelectorParams exc : exclusions) {\n-      selector = FieldMutatingUpdateProcessor.wrap(selector, FieldMutatingUpdateProcessor.createFieldNameSelector\n-          (core.getResourceLoader(), core, exc, FieldMutatingUpdateProcessor.SELECT_NO_FIELDS));\n-    }\n+    solrResourceLoader = core.getResourceLoader();\n \n     for (TypeMapping typeMapping : typeMappings) {\n       typeMapping.populateValueClasses(core);\n     }\n   }\n \n-  private FieldNameSelector getDefaultSelector(final SolrCore core) {\n-    return new FieldNameSelector() {\n-      @Override\n-      public boolean shouldMutate(final String fieldName) {\n-        return null == core.getLatestSchema().getFieldTypeNoEx(fieldName);\n-      }\n-    };\n-  }\n-\n   private static List<TypeMapping> parseTypeMappings(NamedList args) {\n     List<TypeMapping> typeMappings = new ArrayList<>();\n     List<Object> typeMappingsParams = args.getAll(TYPE_MAPPING_PARAM);\n@@ -281,17 +262,23 @@ public AddSchemaFieldsUpdateProcessor(UpdateRequestProcessor next) {\n     \n     @Override\n     public void processAdd(AddUpdateCommand cmd) throws IOException {\n-      if ( ! cmd.getReq().getCore().getLatestSchema().isMutable()) {\n+      if ( ! cmd.getReq().getSchema().isMutable()) {\n         final String message = \"This IndexSchema is not mutable.\";\n         throw new SolrException(BAD_REQUEST, message);\n       }\n       final SolrInputDocument doc = cmd.getSolrInputDocument();\n       final SolrCore core = cmd.getReq().getCore();\n+      // use the cmd's schema rather than the latest, because the schema\n+      // can be updated during processing.  Using the cmd's schema guarantees\n+      // this will be detected and the cmd's schema updated.\n+      IndexSchema oldSchema = cmd.getReq().getSchema();\n       for (;;) {\n-        final IndexSchema oldSchema = core.getLatestSchema();\n         List<SchemaField> newFields = new ArrayList<>();\n+        // build a selector each time through the loop b/c the schema we are\n+        // processing may have changed\n+        FieldNameSelector selector = buildSelector(oldSchema);\n         for (final String fieldName : doc.getFieldNames()) {\n-          if (selector.shouldMutate(fieldName)) { // returns false if the field already exists in the latest schema\n+          if (selector.shouldMutate(fieldName)) { // returns false if the field already exists in the current schema\n             String fieldTypeName = mapValueClassesToFieldType(doc.getField(fieldName));\n             newFields.add(oldSchema.newField(fieldName, fieldTypeName, Collections.<String,Object>emptyMap()));\n           }\n@@ -314,28 +301,32 @@ public void processAdd(AddUpdateCommand cmd) throws IOException {\n           builder.append(\"]\");\n           log.debug(builder.toString());\n         }\n-        try {\n-          synchronized (oldSchema.getSchemaUpdateLock()) {\n+        // Need to hold the lock during the entire attempt to ensure that\n+        // the schema on the request is the latest\n+        synchronized (oldSchema.getSchemaUpdateLock()) {\n+          try {\n             IndexSchema newSchema = oldSchema.addFields(newFields);\n             if (null != newSchema) {\n-              cmd.getReq().getCore().setLatestSchema(newSchema);\n+              core.setLatestSchema(newSchema);\n               cmd.getReq().updateSchemaToLatest();\n               log.debug(\"Successfully added field(s) to the schema.\");\n               break; // success - exit from the retry loop\n             } else {\n               throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Failed to add fields.\");\n             }\n+          } catch (ManagedIndexSchema.FieldExistsException e) {\n+            log.error(\"At least one field to be added already exists in the schema - retrying.\");\n+            oldSchema = core.getLatestSchema();\n+            cmd.getReq().updateSchemaToLatest();\n+          } catch (ManagedIndexSchema.SchemaChangedInZkException e) {\n+            log.debug(\"Schema changed while processing request - retrying.\");\n+            oldSchema = core.getLatestSchema();\n+            cmd.getReq().updateSchemaToLatest();\n           }\n-        } catch(ManagedIndexSchema.FieldExistsException e) {\n-          log.debug(\"At least one field to be added already exists in the schema - retrying.\");\n-          // No action: at least one field to be added already exists in the schema, so retry \n-          // We should never get here, since selector.shouldMutate(field) will exclude already existing fields\n-        } catch(ManagedIndexSchema.SchemaChangedInZkException e) {\n-          log.debug(\"Schema changed while processing request - retrying.\");\n         }\n       }\n       super.processAdd(cmd);\n-    }                          \n+    }\n \n     private String mapValueClassesToFieldType(SolrInputField field) {\n       NEXT_TYPE_MAPPING: for (TypeMapping typeMapping : typeMappings) {\n@@ -354,5 +345,25 @@ private String mapValueClassesToFieldType(SolrInputField field) {\n       // At least one of this field's values is not an instance of any configured fieldType's valueClass-s\n       return defaultFieldType;\n     }\n+\n+    private FieldNameSelector getDefaultSelector(final IndexSchema schema) {\n+      return new FieldNameSelector() {\n+        @Override\n+        public boolean shouldMutate(final String fieldName) {\n+          return null == schema.getFieldTypeNoEx(fieldName);\n+        }\n+      };\n+    }\n+\n+    private FieldNameSelector buildSelector(IndexSchema schema) {\n+      FieldNameSelector selector = FieldMutatingUpdateProcessor.createFieldNameSelector\n+        (solrResourceLoader, schema, inclusions, getDefaultSelector(schema));\n+\n+      for (SelectorParams exc : exclusions) {\n+        selector = FieldMutatingUpdateProcessor.wrap(selector, FieldMutatingUpdateProcessor.createFieldNameSelector\n+          (solrResourceLoader, schema, exc, FieldMutatingUpdateProcessor.SELECT_NO_FIELDS));\n+      }\n+      return selector;\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/update/processor/AddSchemaFieldsUpdateProcessorFactory.java",
                "sha": "fddbb05656421bdedc82437c87b3ee5ecf5fe7ed",
                "status": "modified"
            },
            {
                "additions": 43,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/update/processor/FieldMutatingUpdateProcessor.java",
                "changes": 59,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/FieldMutatingUpdateProcessor.java?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 16,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/FieldMutatingUpdateProcessor.java",
                "patch": "@@ -32,7 +32,7 @@\n import org.apache.solr.core.SolrCore;\n import org.apache.solr.core.SolrResourceLoader;\n import org.apache.solr.schema.FieldType;\n-\n+import org.apache.solr.schema.IndexSchema;\n import org.apache.solr.update.AddUpdateCommand;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -182,39 +182,68 @@ public boolean shouldMutate(final String fieldName) {\n     };\n   }\n \n+  /**\n+   * Utility method that can be used to define a FieldNameSelector\n+   * using the same types of rules as the FieldMutatingUpdateProcessor init\n+   * code.  This may be useful for Factories that wish to define default\n+   * selectors in similar terms to what the configuration would look like.\n+   * @lucene.internal\n+   */\n+  public static FieldNameSelector createFieldNameSelector\n+    (final SolrResourceLoader loader,\n+     final SolrCore core,\n+     final SelectorParams params,\n+     final FieldNameSelector defSelector) {\n+\n+    if (params.noSelectorsSpecified()) {\n+      return defSelector;\n+    }\n+\n+    final ConfigurableFieldNameSelectorHelper helper =\n+      new ConfigurableFieldNameSelectorHelper(loader, params);\n+    return new FieldNameSelector() {\n+      @Override\n+      public boolean shouldMutate(String fieldName) {\n+        return helper.shouldMutateBasedOnSchema(fieldName, core.getLatestSchema());\n+      }\n+    };\n+  }\n+\n   /**\n    * Utility method that can be used to define a FieldNameSelector\n    * using the same types of rules as the FieldMutatingUpdateProcessor init \n    * code.  This may be useful for Factories that wish to define default \n    * selectors in similar terms to what the configuration would look like.\n+   * Uses {@code schema} for checking field existence.\n    * @lucene.internal\n    */\n   public static FieldNameSelector createFieldNameSelector\n     (final SolrResourceLoader loader,\n-     final SolrCore core,\n+     final IndexSchema schema,\n      final SelectorParams params,\n      final FieldNameSelector defSelector) {\n \n     if (params.noSelectorsSpecified()) {\n       return defSelector;\n     }\n-    \n-    return new ConfigurableFieldNameSelector(loader, core, params); \n+\n+    final ConfigurableFieldNameSelectorHelper helper =\n+      new ConfigurableFieldNameSelectorHelper(loader, params);\n+    return new FieldNameSelector() {\n+      @Override\n+      public boolean shouldMutate(String fieldName) {\n+        return helper.shouldMutateBasedOnSchema(fieldName, schema);\n+      }\n+    };\n   }\n   \n-  \n-  \n-  private static final class ConfigurableFieldNameSelector \n-    implements FieldNameSelector {\n+  private static final class ConfigurableFieldNameSelectorHelper {\n \n-    final SolrCore core;\n     final SelectorParams params;\n     final Collection<Class> classes;\n \n-    private ConfigurableFieldNameSelector(final SolrResourceLoader loader,\n-                                          final SolrCore core,\n+    private ConfigurableFieldNameSelectorHelper(final SolrResourceLoader loader,\n                                           final SelectorParams params) {\n-      this.core = core;\n       this.params = params;\n \n       final Collection<Class> classes = new ArrayList<>(params.typeClass.size());\n@@ -229,9 +258,7 @@ private ConfigurableFieldNameSelector(final SolrResourceLoader loader,\n       this.classes = classes;\n     }\n \n-    @Override\n-    public boolean shouldMutate(final String fieldName) {\n-      \n+    public boolean shouldMutateBasedOnSchema(final String fieldName, IndexSchema schema) {\n       // order of checks is based on what should be quicker\n       // (ie: set lookups faster the looping over instanceOf / matches tests\n       \n@@ -241,7 +268,7 @@ public boolean shouldMutate(final String fieldName) {\n       \n       // do not consider it an error if the fieldName has no type\n       // there might be another processor dealing with it later\n-      FieldType t =  core.getLatestSchema().getFieldTypeNoEx(fieldName);\n+      FieldType t =  schema.getFieldTypeNoEx(fieldName);\n       final boolean fieldExists = (null != t);\n \n       if ( (null != params.fieldNameMatchesSchemaField) &&",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/java/org/apache/solr/update/processor/FieldMutatingUpdateProcessor.java",
                "sha": "1fa3c5d4947d7503604c79680c599d5f6fbdad1d",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test-files/solr/collection1/conf/solrconfig-add-schema-fields-update-processor-chains.xml",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/solrconfig-add-schema-fields-update-processor-chains.xml?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/solrconfig-add-schema-fields-update-processor-chains.xml",
                "patch": "@@ -66,6 +66,8 @@\n   </updateRequestProcessorChain>\n \n   <updateRequestProcessorChain name=\"add-fields\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\" />\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\" />\n     <processor class=\"solr.AddSchemaFieldsUpdateProcessorFactory\">\n       <str name=\"defaultFieldType\">text</str>\n       <lst name=\"typeMapping\">\n@@ -98,6 +100,8 @@\n   </updateRequestProcessorChain>\n \n   <updateRequestProcessorChain name=\"parse-and-add-fields\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\" />\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\" />\n     <processor class=\"solr.ParseBooleanFieldUpdateProcessorFactory\"/>\n     <processor class=\"solr.ParseLongFieldUpdateProcessorFactory\"/>\n     <processor class=\"solr.ParseDoubleFieldUpdateProcessorFactory\"/>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test-files/solr/collection1/conf/solrconfig-add-schema-fields-update-processor-chains.xml",
                "sha": "5cd0cbfd325129456438d0dd6a7c89c4157f1fe2",
                "status": "modified"
            },
            {
                "additions": 121,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml",
                "changes": 121,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml",
                "patch": "@@ -0,0 +1,121 @@\n+<?xml version=\"1.0\" ?>\n+\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+                                                           \n+<config>\n+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>\n+\n+  <xi:include href=\"solrconfig.snippet.randomindexconfig.xml\" xmlns:xi=\"http://www.w3.org/2001/XInclude\"/>\n+\n+  <schemaFactory class=\"ManagedIndexSchemaFactory\">\n+    <bool name=\"mutable\">${managed.schema.mutable}</bool>\n+    <str name=\"managedSchemaResourceName\">managed-schema</str>\n+  </schemaFactory>\n+\n+  <codecFactory class=\"solr.SchemaCodecFactory\"/>\n+\n+  <updateHandler>\n+    <updateLog enable=\"${enable.update.log}\">\n+      <str name=\"dir\">${solr.ulog.dir:}</str>\n+    </updateLog> \n+  </updateHandler>\n+\n+  <requestHandler name=\"standard\" class=\"solr.StandardRequestHandler\">\n+    <bool name=\"httpCaching\">true</bool>\n+  </requestHandler>\n+\n+  <requestHandler name=\"/get\" class=\"solr.RealTimeGetHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"omitHeader\">true</str>\n+    </lst>\n+  </requestHandler>\n+  <requestHandler name=\"/admin/\" class=\"org.apache.solr.handler.admin.AdminHandlers\" />\n+  <requestHandler name=\"/update\" class=\"solr.UpdateRequestHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"update.chain\">add-unknown-fields-to-the-schema</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <requestHandler name=\"/replication\" class=\"solr.ReplicationHandler\" startup=\"lazy\" />\n+\n+  <!-- Add unknown fields to the schema \n+  \n+       An example field type guessing update processor that will\n+       attempt to parse string-typed field values as Booleans, Longs,\n+       Doubles, or Dates, and then add schema fields with the guessed\n+       field types.  \n+       \n+       This requires that the schema is both managed and mutable, by\n+       declaring schemaFactory as ManagedIndexSchemaFactory, with\n+       mutable specified as true. \n+       \n+       See http://wiki.apache.org/solr/GuessingFieldTypes\n+    -->\n+  <updateRequestProcessorChain name=\"add-unknown-fields-to-the-schema\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\"/>\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\" />\n+    <processor class=\"solr.RemoveBlankFieldUpdateProcessorFactory\"/>\n+    <processor class=\"solr.ParseBooleanFieldUpdateProcessorFactory\"/>\n+    <processor class=\"solr.ParseLongFieldUpdateProcessorFactory\"/>\n+    <processor class=\"solr.ParseDoubleFieldUpdateProcessorFactory\"/>\n+    <processor class=\"solr.ParseDateFieldUpdateProcessorFactory\">\n+      <arr name=\"format\">\n+        <str>yyyy-MM-dd'T'HH:mm:ss.SSSZ</str>\n+        <str>yyyy-MM-dd'T'HH:mm:ss,SSSZ</str>\n+        <str>yyyy-MM-dd'T'HH:mm:ss.SSS</str>\n+        <str>yyyy-MM-dd'T'HH:mm:ss,SSS</str>\n+        <str>yyyy-MM-dd'T'HH:mm:ssZ</str>\n+        <str>yyyy-MM-dd'T'HH:mm:ss</str>\n+        <str>yyyy-MM-dd'T'HH:mmZ</str>\n+        <str>yyyy-MM-dd'T'HH:mm</str>\n+        <str>yyyy-MM-dd HH:mm:ss.SSSZ</str>\n+        <str>yyyy-MM-dd HH:mm:ss,SSSZ</str>\n+        <str>yyyy-MM-dd HH:mm:ss.SSS</str>\n+        <str>yyyy-MM-dd HH:mm:ss,SSS</str>\n+        <str>yyyy-MM-dd HH:mm:ssZ</str>\n+        <str>yyyy-MM-dd HH:mm:ss</str>\n+        <str>yyyy-MM-dd HH:mmZ</str>\n+        <str>yyyy-MM-dd HH:mm</str>\n+        <str>yyyy-MM-dd</str>\n+      </arr>\n+    </processor>\n+     \n+    <processor class=\"solr.AddSchemaFieldsUpdateProcessorFactory\">\n+      <str name=\"defaultFieldType\">text_general</str>\n+      <lst name=\"typeMapping\">\n+        <str name=\"valueClass\">java.lang.Boolean</str>\n+        <str name=\"fieldType\">boolean</str>\n+      </lst>\n+      <lst name=\"typeMapping\">\n+        <str name=\"valueClass\">java.util.Date</str>\n+        <str name=\"fieldType\">tdate</str>\n+      </lst>\n+      <lst name=\"typeMapping\">\n+        <str name=\"valueClass\">java.lang.Long</str>\n+        <str name=\"valueClass\">java.lang.Integer</str>\n+        <str name=\"fieldType\">tlong</str>\n+      </lst>\n+      <lst name=\"typeMapping\">\n+        <str name=\"valueClass\">java.lang.Number</str>\n+        <str name=\"fieldType\">tdouble</str>\n+      </lst>\n+    </processor>\n+    <processor class=\"solr.RunUpdateProcessorFactory\"/>\n+  </updateRequestProcessorChain>\n+\n+</config>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test-files/solr/collection1/conf/solrconfig-schemaless.xml",
                "sha": "29264c8c080fdc67e8c284de26cfe11efc543689",
                "status": "added"
            },
            {
                "additions": 184,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java",
                "changes": 184,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java",
                "patch": "@@ -0,0 +1,184 @@\n+package org.apache.solr.schema;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.solr.client.solrj.SolrServer;\n+import org.apache.solr.client.solrj.impl.HttpSolrServer;\n+import org.apache.solr.cloud.AbstractFullDistribZkTestBase;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.SolrException.ErrorCode;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.apache.solr.util.BaseTestHarness;\n+import org.apache.solr.util.RESTfulServerProvider;\n+import org.apache.solr.util.RestTestHarness;\n+import org.eclipse.jetty.servlet.ServletHolder;\n+import org.junit.BeforeClass;\n+import org.junit.Before;\n+import org.restlet.ext.servlet.ServerServlet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.Math;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.SortedMap;\n+import java.util.TreeMap;\n+\n+/**\n+ * Tests a schemaless collection configuration with SolrCloud\n+ */\n+public class TestCloudSchemaless extends AbstractFullDistribZkTestBase {\n+  private static final Logger log = LoggerFactory.getLogger(TestCloudManagedSchemaConcurrent.class);\n+  private static final String SUCCESS_XPATH = \"/response/lst[@name='responseHeader']/int[@name='status'][.='0']\";\n+\n+  @Before\n+  @Override\n+  public void setUp() throws Exception {\n+\n+    super.setUp();\n+\n+    useJettyDataDir = false;\n+\n+    System.setProperty(\"numShards\", Integer.toString(sliceCount));\n+  }\n+\n+  public TestCloudSchemaless() {\n+    schemaString = \"schema-add-schema-fields-update-processor.xml\";\n+    fixShardCount = true;\n+\n+    sliceCount = 4;\n+    shardCount = 8;\n+  }\n+\n+  @BeforeClass\n+  public static void initSysProperties() {\n+    System.setProperty(\"managed.schema.mutable\", \"true\");\n+    System.setProperty(\"enable.update.log\", \"true\");\n+  }\n+\n+  @Override\n+  protected String getCloudSolrConfig() {\n+    return \"solrconfig-schemaless.xml\";\n+  }\n+\n+  @Override\n+  public SortedMap<ServletHolder,String> getExtraServlets() {\n+    final SortedMap<ServletHolder,String> extraServlets = new TreeMap<>();\n+    final ServletHolder solrRestApi = new ServletHolder(\"SolrSchemaRestApi\", ServerServlet.class);\n+    solrRestApi.setInitParameter(\"org.restlet.application\", \"org.apache.solr.rest.SolrSchemaRestApi\");\n+    extraServlets.put(solrRestApi, \"/schema/*\");  // '/schema/*' matches '/schema', '/schema/', and '/schema/whatever...'\n+    return extraServlets;\n+  }\n+\n+  private List<RestTestHarness> restTestHarnesses = new ArrayList<>();\n+\n+  private void setupHarnesses() {\n+    for (final SolrServer client : clients) {\n+      RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {\n+        @Override\n+        public String getBaseURL() {\n+          return ((HttpSolrServer)client).getBaseURL();\n+        }\n+      });\n+      restTestHarnesses.add(harness);\n+    }\n+  }\n+\n+  private String[] getExpectedFieldResponses(int numberOfDocs) {\n+    String[] expectedAddFields = new String[1 + numberOfDocs];\n+    expectedAddFields[0] = SUCCESS_XPATH;\n+\n+    for (int i = 0; i < numberOfDocs; ++i) {\n+      String newFieldName = \"newTestFieldInt\" + i;\n+      expectedAddFields[1 + i] =\n+        \"/response/arr[@name='fields']/lst/str[@name='name'][.='\" + newFieldName + \"']\";\n+    }\n+    return expectedAddFields;\n+  }\n+\n+  @Override\n+  public void doTest() throws Exception {\n+    setupHarnesses();\n+\n+    // First, add a bunch of documents in a single update with the same new field.\n+    // This tests that the replicas properly handle schema additions.\n+\n+    int slices =  getCommonCloudSolrServer().getZkStateReader().getClusterState()\n+      .getActiveSlices(\"collection1\").size();\n+    int trials = 50;\n+    // generate enough docs so that we can expect at least a doc per slice\n+    int numDocsPerTrial = (int)(slices * (Math.log(slices) + 1));\n+    SolrServer ss = clients.get(random().nextInt(clients.size() + 1));\n+    int docNumber = 0;\n+    for (int i = 0; i < trials; ++i) {\n+      List<SolrInputDocument> docs = new ArrayList<>();\n+      for (int j =0; j < numDocsPerTrial; ++j) {\n+        SolrInputDocument doc = new SolrInputDocument();\n+        doc.addField(\"id\", Long.toHexString(Double.doubleToLongBits(random().nextDouble())));\n+        doc.addField(\"newTestFieldInt\" + docNumber++, \"123\");\n+        doc.addField(\"constantField\", \"3.14159\");\n+        docs.add(doc);\n+      }\n+\n+      ss.add(docs);\n+    }\n+    ss.commit();\n+\n+    String [] expectedFields = getExpectedFieldResponses(docNumber);\n+    // Check that all the fields were added\n+    for (RestTestHarness client : restTestHarnesses) {\n+      String request = \"/schema/fields?wt=xml\";\n+      String response = client.query(request);\n+      String result = BaseTestHarness.validateXPath(response, expectedFields);\n+      if (result != null) {\n+        String msg = \"QUERY FAILED: xpath=\" + result + \"  request=\" + request + \"  response=\" + response;\n+        log.error(msg);\n+        fail(msg);\n+      }\n+    }\n+\n+    // Now, let's ensure that writing the same field with two different types fails\n+    int failTrials = 50;\n+    for (int i = 0; i < failTrials; ++i) {\n+      List<SolrInputDocument> docs = null;\n+\n+      SolrInputDocument intDoc = new SolrInputDocument();\n+      intDoc.addField(\"id\", Long.toHexString(Double.doubleToLongBits(random().nextDouble())));\n+      intDoc.addField(\"longOrDateField\" + i, \"123\");\n+\n+      SolrInputDocument dateDoc = new SolrInputDocument();\n+      dateDoc.addField(\"id\", Long.toHexString(Double.doubleToLongBits(random().nextDouble())));\n+      dateDoc.addField(\"longOrDateField\" + i, \"1995-12-31T23:59:59Z\");\n+\n+      // randomize the order of the docs\n+      if (random().nextBoolean()) {\n+        docs = Arrays.asList(intDoc, dateDoc);\n+      } else {\n+        docs = Arrays.asList(dateDoc, intDoc);\n+      }\n+\n+      try {\n+        ss.add(docs);\n+        ss.commit();\n+        fail(\"Expected Bad Request Exception\");\n+      } catch (SolrException se) {\n+        assertEquals(ErrorCode.BAD_REQUEST, ErrorCode.getErrorCode(se.code()));\n+      }\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java",
                "sha": "eadc31e4267c1beb6f34808514b694c535bb1284",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/example/example-schemaless/solr/collection1/conf/solrconfig.xml",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/example/example-schemaless/solr/collection1/conf/solrconfig.xml?ref=2671418cfb65abe054ed58f4ee9152fd09454a81",
                "deletions": 1,
                "filename": "solr/example/example-schemaless/solr/collection1/conf/solrconfig.xml",
                "patch": "@@ -1549,6 +1549,8 @@\n        See http://wiki.apache.org/solr/GuessingFieldTypes\n     -->\n   <updateRequestProcessorChain name=\"add-unknown-fields-to-the-schema\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\"/>\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\"/>\n     <processor class=\"solr.RemoveBlankFieldUpdateProcessorFactory\"/>\n     <processor class=\"solr.ParseBooleanFieldUpdateProcessorFactory\"/>\n     <processor class=\"solr.ParseLongFieldUpdateProcessorFactory\"/>\n@@ -1594,7 +1596,6 @@\n         <str name=\"fieldType\">tdoubles</str>\n       </lst>\n     </processor>\n-    <processor class=\"solr.LogUpdateProcessorFactory\"/>\n     <processor class=\"solr.RunUpdateProcessorFactory\"/>\n   </updateRequestProcessorChain>\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2671418cfb65abe054ed58f4ee9152fd09454a81/solr/example/example-schemaless/solr/collection1/conf/solrconfig.xml",
                "sha": "98850fe21d5ee87767da9844733557e01cea975a",
                "status": "modified"
            }
        ],
        "message": "SOLR-6137: Schemaless concurrency improvements:\n- Fixed an NPE when reloading a managed schema with no dynamic copy fields\n- Moved parsing and schema fields addition to after the distributed phase\n- AddSchemaFieldsUpdateProcessor now uses a fixed schema rather than always retrieving the latest, and holds the schema update lock through the entire schema swap-out process\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1610725 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/7bb3f6044ea7fe297e783a08f57f24b2323fbe53",
        "repo": "lucene-solr",
        "unit_tests": [
            "AddSchemaFieldsUpdateProcessorFactoryTest.java",
            "FieldMutatingUpdateProcessorTest.java"
        ]
    },
    "lucene-solr_271576e": {
        "bug_id": "lucene-solr_271576e",
        "commit": "https://github.com/apache/lucene-solr/commit/271576ed0f81421b0717f6da23bf3371c6c1bd87",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -155,6 +155,9 @@ Bug Fixes\n * SOLR-6159: A ZooKeeper session expiry during setup can keep LeaderElector from joining elections.\n   (Steven Bower, shalin)\n \n+* SOLR-6223: SearchComponents may throw NPE when using shards.tolerant and there is a failure\n+  in the 'GET_FIELDS/GET_HIGHLIGHTS/GET_DEBUG' phase. (Tom\u00e1s Fern\u00e1ndez L\u00f6bbe via shalin)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/CHANGES.txt",
                "sha": "e654c02a84ee2262d1e2b76686cf56a01d82f696",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "patch": "@@ -230,7 +230,7 @@ public void finishStage(ResponseBuilder rb) {\n       }\n \n       if (rb.isDebugResults()) {\n-        explain = SolrPluginUtils.removeNulls(new SimpleOrderedMap<>(arr));\n+         explain = SolrPluginUtils.removeNulls(arr, new SimpleOrderedMap<>());\n       }\n \n       if (!hasGetDebugResponses) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "sha": "9a206cf872689f264c24a017c511a65347980046",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "patch": "@@ -182,6 +182,11 @@ public void finishStage(ResponseBuilder rb) {\n       for (ShardRequest sreq : rb.finished) {\n         if ((sreq.purpose & ShardRequest.PURPOSE_GET_HIGHLIGHTS) == 0) continue;\n         for (ShardResponse srsp : sreq.responses) {\n+          if (srsp.getException() != null) {\n+            // can't expect the highlight content if there was an exception for this request\n+            // this should only happen when using shards.tolerant=true\n+            continue;\n+          }\n           NamedList hl = (NamedList)srsp.getSolrResponse().getResponse().get(\"highlighting\");\n           for (int i=0; i<hl.size(); i++) {\n             String id = hl.getName(i);\n@@ -193,7 +198,7 @@ public void finishStage(ResponseBuilder rb) {\n       }\n \n       // remove nulls in case not all docs were able to be retrieved\n-      rb.rsp.add(\"highlighting\", SolrPluginUtils.removeNulls(new SimpleOrderedMap(arr)));      \n+      rb.rsp.add(\"highlighting\", SolrPluginUtils.removeNulls(arr, new SimpleOrderedMap<Object>()));      \n     }\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "sha": "87746c779d5e487ec2adf9bbb2a385a6494de429",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "patch": "@@ -133,6 +133,10 @@ public void handleResponses(ResponseBuilder rb, ShardRequest sreq) {\n         && rb.req.getParams().getBool(COMPONENT_NAME, false)) {\n       log.debug(\"ShardRequest.response.size: \" + sreq.responses.size());\n       for (ShardResponse r : sreq.responses) {\n+        if (r.getException() != null) {\n+          // This should only happen in case of using shards.tolerant=true. Omit this ShardResponse\n+          continue;\n+        }\n         NamedList<?> moreLikeThisReponse = (NamedList<?>) r.getSolrResponse()\n             .getResponse().get(\"moreLikeThis\");\n         log.debug(\"ShardRequest.response.shard: \" + r.getShard());",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "sha": "7df06b8cf54e6b0e23cdf9d0d5bf16eb8d4e253a",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "patch": "@@ -55,7 +55,6 @@\n import org.apache.solr.common.SolrDocumentList;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.*;\n-import org.apache.solr.common.params.CursorMarkParams;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.common.util.SimpleOrderedMap;\n import org.apache.solr.common.util.StrUtils;\n@@ -1064,7 +1063,9 @@ private void mergeIds(ResponseBuilder rb, ShardRequest sreq) {\n       populateNextCursorMarkFromMergedShards(rb);\n \n       if (partialResults) {\n-        rb.rsp.getResponseHeader().add( \"partialResults\", Boolean.TRUE );\n+        if(rb.rsp.getResponseHeader().get(\"partialResults\") == null) {\n+          rb.rsp.getResponseHeader().add(\"partialResults\", Boolean.TRUE);\n+        }\n       }\n   }\n \n@@ -1227,6 +1228,28 @@ private void returnFields(ResponseBuilder rb, ShardRequest sreq) {\n       boolean removeKeyField = !rb.rsp.getReturnFields().wantsField(keyFieldName);\n \n       for (ShardResponse srsp : sreq.responses) {\n+        if (srsp.getException() != null) {\n+          // Don't try to get the documents if there was an exception in the shard\n+          if(rb.req.getParams().getBool(ShardParams.SHARDS_INFO, false)) {\n+            @SuppressWarnings(\"unchecked\")\n+            NamedList<Object> shardInfo = (NamedList<Object>) rb.rsp.getValues().get(ShardParams.SHARDS_INFO);\n+            @SuppressWarnings(\"unchecked\")\n+            SimpleOrderedMap<Object> nl = (SimpleOrderedMap<Object>) shardInfo.get(srsp.getShard());\n+            if (nl.get(\"error\") == null) {\n+              // Add the error to the shards info section if it wasn't added before\n+              Throwable t = srsp.getException();\n+              if(t instanceof SolrServerException) {\n+                t = ((SolrServerException)t).getCause();\n+              }\n+              nl.add(\"error\", t.toString() );\n+              StringWriter trace = new StringWriter();\n+              t.printStackTrace(new PrintWriter(trace));\n+              nl.add(\"trace\", trace.toString() );\n+            }\n+          }\n+          \n+          continue;\n+        }\n         SolrDocumentList docs = (SolrDocumentList) srsp.getSolrResponse().getResponse().get(\"response\");\n \n         for (SolrDocument doc : docs) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "sha": "f6cf8a04d0b8faa4659a1a5795ad66d42475028e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "patch": "@@ -425,7 +425,7 @@ public void prepare(ResponseBuilder rb) throws IOException {\n   public void finishStage(ResponseBuilder rb) {\n     if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n       \n-      NamedList termVectors = new NamedList<>();\n+      NamedList<Object> termVectors = new NamedList<>();\n       Map.Entry<String, Object>[] arr = new NamedList.NamedListEntry[rb.resultIds.size()];\n \n       for (ShardRequest sreq : rb.finished) {\n@@ -450,7 +450,7 @@ public void finishStage(ResponseBuilder rb) {\n         }\n       }\n       // remove nulls in case not all docs were able to be retrieved\n-      termVectors.addAll(SolrPluginUtils.removeNulls(new NamedList<>(arr)));\n+      termVectors.addAll(SolrPluginUtils.removeNulls(arr, new NamedList<Object>()));\n       rb.rsp.add(TERM_VECTORS, termVectors);\n     }\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "sha": "ced30770180057b616b9107a4c0757271b2cf49f",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 12,
                "filename": "solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "patch": "@@ -702,21 +702,25 @@ public static CharSequence stripUnbalancedQuotes(CharSequence s) {\n     }\n     return s.toString().replace(\"\\\"\",\"\");\n   }\n-\n-  public static NamedList removeNulls(NamedList nl) {\n-    for (int i=0; i<nl.size(); i++) {\n-      if (nl.getName(i)==null) {\n-        NamedList newList = nl instanceof SimpleOrderedMap ? new SimpleOrderedMap() : new NamedList();\n-        for (int j=0; j<nl.size(); j++) {\n-          String n = nl.getName(j);\n-          if (n != null) {\n-            newList.add(n, nl.getVal(j));\n-          }\n+  \n+  /**\n+   * Adds to {@code dest} all the not-null elements of {@code entries} that have non-null names\n+   * \n+   * @param entries The array of entries to be added to the {@link NamedList} {@code dest}\n+   * @param dest The {@link NamedList} instance where the not-null elements of entries are added\n+   * @return Returns The {@code dest} input object\n+   */\n+  public static <T> NamedList<T> removeNulls(Map.Entry<String, T>[] entries, NamedList<T> dest) {\n+    for (int i=0; i<entries.length; i++) {\n+      Map.Entry<String, T> entry = entries[i];\n+      if (entry != null) {\n+        String key = entry.getKey();\n+        if (key != null) {\n+          dest.add(key, entry.getValue());\n         }\n-        return newList;\n       }\n     }\n-    return nl;\n+    return dest;\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "sha": "dcad40227115b40f4143eeec03939c12393c3968",
                "status": "modified"
            },
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/test-files/solr/collection1/conf/solrconfig-tolerant-search.xml",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/solrconfig-tolerant-search.xml?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/solrconfig-tolerant-search.xml",
                "patch": "@@ -0,0 +1,57 @@\n+<?xml version=\"1.0\" ?>\n+\n+<!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor \n+\tlicense agreements. See the NOTICE file distributed with this work for additional \n+\tinformation regarding copyright ownership. The ASF licenses this file to \n+\tYou under the Apache License, Version 2.0 (the \"License\"); you may not use \n+\tthis file except in compliance with the License. You may obtain a copy of \n+\tthe License at http://www.apache.org/licenses/LICENSE-2.0 Unless required \n+\tby applicable law or agreed to in writing, software distributed under the \n+\tLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS \n+\tOF ANY KIND, either express or implied. See the License for the specific \n+\tlanguage governing permissions and limitations under the License. -->\n+\n+<!-- This is a \"kitchen sink\" config file that tests can use. When writting \n+\ta new test, feel free to add *new* items (plugins, config options, etc...) \n+\tas long as they don't break any existing tests. if you need to test something \n+\tesoteric please add a new \"solrconfig-your-esoteric-purpose.xml\" config file. \n+\tNote in particular that this test is used by MinimalSchemaTest so Anything \n+\tadded to this file needs to work correctly even if there is now uniqueKey \n+\tor defaultSearch Field. -->\n+\n+<config>\n+\n+\t<dataDir>${solr.data.dir:}</dataDir>\n+\n+\t<directoryFactory name=\"DirectoryFactory\"\n+\t\tclass=\"${solr.directoryFactory:solr.NRTCachingDirectoryFactory}\" />\n+\n+\t<luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>\n+\n+\t<xi:include href=\"solrconfig.snippet.randomindexconfig.xml\"\n+\t\txmlns:xi=\"http://www.w3.org/2001/XInclude\" />\n+\n+\t<updateHandler class=\"solr.DirectUpdateHandler2\">\n+\t\t<commitWithin>\n+\t\t\t<softCommit>${solr.commitwithin.softcommit:true}</softCommit>\n+\t\t</commitWithin>\n+\n+\t</updateHandler>\n+\t<requestHandler name=\"/select\" class=\"solr.SearchHandler\">\n+\t\t<lst name=\"defaults\">\n+\t\t\t<str name=\"echoParams\">explicit</str>\n+\t\t\t<str name=\"indent\">true</str>\n+\t\t\t<str name=\"df\">text</str>\n+\t\t</lst>\n+\n+\t</requestHandler>\n+\t\n+\t<queryResponseWriter name=\"javabin\"\n+                       class=\"solr.TestTolerantSearch$BadResponseWriter\" />\n+\n+\t<requestHandler name=\"/admin/\"\n+\t\tclass=\"org.apache.solr.handler.admin.AdminHandlers\" />\n+\n+\t<requestHandler name=\"/update\" class=\"solr.UpdateRequestHandler\" />\n+</config>\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/test-files/solr/collection1/conf/solrconfig-tolerant-search.xml",
                "sha": "cb1ab3df944b2f3301bacdae523874926616c64e",
                "status": "added"
            },
            {
                "additions": 241,
                "blob_url": "https://github.com/apache/lucene-solr/blob/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/test/org/apache/solr/TestTolerantSearch.java",
                "changes": 241,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/TestTolerantSearch.java?ref=271576ed0f81421b0717f6da23bf3371c6c1bd87",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/TestTolerantSearch.java",
                "patch": "@@ -0,0 +1,241 @@\n+package org.apache.solr;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServer;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.impl.HttpSolrServer;\n+import org.apache.solr.client.solrj.request.CoreAdminRequest;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.apache.solr.common.params.ShardParams;\n+import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.response.BinaryResponseWriter;\n+import org.apache.solr.response.SolrQueryResponse;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+public class TestTolerantSearch extends SolrJettyTestBase {\n+  \n+  private static SolrServer collection1;\n+  private static SolrServer collection2;\n+  private static String shard1;\n+  private static String shard2;\n+  private static File solrHome;\n+  \n+  private static File createSolrHome() throws Exception {\n+    File workDir = createTempDir();\n+    setupJettyTestHome(workDir, \"collection1\");\n+    FileUtils.copyFile(new File(SolrTestCaseJ4.TEST_HOME() + \"/collection1/conf/solrconfig-tolerant-search.xml\"), new File(workDir, \"/collection1/conf/solrconfig.xml\"));\n+    FileUtils.copyDirectory(new File(workDir, \"collection1\"), new File(workDir, \"collection2\"));\n+    return workDir;\n+  }\n+  \n+  \n+  @BeforeClass\n+  public static void createThings() throws Exception {\n+    solrHome = createSolrHome();\n+    createJetty(solrHome.getAbsolutePath(), null, null);\n+    String url = jetty.getBaseUrl().toString();\n+    collection1 = new HttpSolrServer(url);\n+    collection2 = new HttpSolrServer(url + \"/collection2\");\n+    \n+    String urlCollection1 = jetty.getBaseUrl().toString() + \"/\" + \"collection1\";\n+    String urlCollection2 = jetty.getBaseUrl().toString() + \"/\" + \"collection2\";\n+    shard1 = urlCollection1.replaceAll(\"https?://\", \"\");\n+    shard2 = urlCollection2.replaceAll(\"https?://\", \"\");\n+    \n+    //create second core\n+    CoreAdminRequest.Create req = new CoreAdminRequest.Create();\n+    req.setCoreName(\"collection2\");\n+    collection1.request(req);\n+    \n+    SolrInputDocument doc = new SolrInputDocument();\n+    doc.setField(\"id\", \"1\");\n+    doc.setField(\"subject\", \"batman\");\n+    doc.setField(\"title\", \"foo bar\");\n+    collection1.add(doc);\n+    collection1.commit();\n+    \n+    doc.setField(\"id\", \"2\");\n+    doc.setField(\"subject\", \"superman\");\n+    collection2.add(doc);\n+    collection2.commit();\n+    \n+    doc = new SolrInputDocument();\n+    doc.setField(\"id\", \"3\");\n+    doc.setField(\"subject\", \"aquaman\");\n+    doc.setField(\"title\", \"foo bar\");\n+    collection1.add(doc);\n+    collection1.commit();\n+    \n+  }\n+  \n+  @AfterClass\n+  public static void destroyThings() throws Exception {\n+    collection1.shutdown();\n+    collection2.shutdown();\n+    collection1 = null;\n+    collection2 = null;\n+    jetty.stop();\n+    jetty=null;\n+    resetExceptionIgnores();\n+  }\n+  \n+  @SuppressWarnings(\"unchecked\")\n+  public void testGetFieldsPhaseError() throws SolrServerException {\n+    BadResponseWriter.failOnGetFields = true;\n+    BadResponseWriter.failOnGetTopIds = false;\n+    SolrQuery query = new SolrQuery();\n+    query.setQuery(\"subject:batman OR subject:superman\");\n+    query.addField(\"id\");\n+    query.addField(\"subject\");\n+    query.set(\"distrib\", \"true\");\n+    query.set(\"shards\", shard1 + \",\" + shard2);\n+    query.set(ShardParams.SHARDS_INFO, \"true\");\n+    query.set(\"debug\", \"true\");\n+    query.set(\"stats\", \"true\");\n+    query.set(\"stats.field\", \"id\");\n+    query.set(\"mlt\", \"true\");\n+    query.set(\"mlt.fl\", \"title\");\n+    query.set(\"mlt.count\", \"1\");\n+    query.set(\"mlt.mintf\", \"0\");\n+    query.set(\"mlt.mindf\", \"0\");\n+    query.setHighlight(true);\n+    query.addFacetField(\"id\");\n+    query.setFacet(true);\n+    \n+    ignoreException(\"Dummy exception in BadResponseWriter\");\n+    try {\n+      collection1.query(query);\n+      fail(\"Should get an exception\");\n+    } catch (Exception e) {\n+      //expected\n+    }\n+    query.set(ShardParams.SHARDS_TOLERANT, \"true\");\n+    QueryResponse response = collection1.query(query);\n+    assertTrue(response.getResponseHeader().getBooleanArg(\"partialResults\"));\n+    NamedList<Object> shardsInfo = ((NamedList<Object>)response.getResponse().get(\"shards.info\"));\n+    boolean foundError = false;\n+    for (int i = 0; i < shardsInfo.size(); i++) {\n+      if (shardsInfo.getName(i).contains(\"collection2\")) {\n+        assertNotNull(((NamedList<Object>)shardsInfo.getVal(i)).get(\"error\"));\n+        foundError = true;\n+        break;\n+      }\n+    }\n+    assertTrue(foundError);\n+    assertEquals(1, response.getResults().get(0).getFieldValue(\"id\"));\n+    assertEquals(\"batman\", response.getResults().get(0).getFirstValue(\"subject\"));\n+    unIgnoreException(\"Dummy exception in BadResponseWriter\");\n+  }\n+  \n+  @SuppressWarnings(\"unchecked\")\n+  public void testGetTopIdsPhaseError() throws SolrServerException {\n+    BadResponseWriter.failOnGetTopIds = true;\n+    BadResponseWriter.failOnGetFields = false;\n+    SolrQuery query = new SolrQuery();\n+    query.setQuery(\"subject:batman OR subject:superman\");\n+    query.addField(\"id\");\n+    query.addField(\"subject\");\n+    query.set(\"distrib\", \"true\");\n+    query.set(\"shards\", shard1 + \",\" + shard2);\n+    query.set(ShardParams.SHARDS_INFO, \"true\");\n+    query.set(\"debug\", \"true\");\n+    query.set(\"stats\", \"true\");\n+    query.set(\"stats.field\", \"id\");\n+    query.set(\"mlt\", \"true\");\n+    query.set(\"mlt.fl\", \"title\");\n+    query.set(\"mlt.count\", \"1\");\n+    query.set(\"mlt.mintf\", \"0\");\n+    query.set(\"mlt.mindf\", \"0\");\n+    query.setHighlight(true);\n+    query.addFacetField(\"id\");\n+    query.setFacet(true);\n+    \n+    ignoreException(\"Dummy exception in BadResponseWriter\");\n+    try {\n+      collection1.query(query);\n+      fail(\"Should get an exception\");\n+    } catch (Exception e) {\n+      //expected\n+    }\n+    query.set(ShardParams.SHARDS_TOLERANT, \"true\");\n+    QueryResponse response = collection1.query(query);\n+    assertTrue(response.getResponseHeader().getBooleanArg(\"partialResults\"));\n+    NamedList<Object> shardsInfo = ((NamedList<Object>)response.getResponse().get(\"shards.info\"));\n+    boolean foundError = false;\n+    for (int i = 0; i < shardsInfo.size(); i++) {\n+      if (shardsInfo.getName(i).contains(\"collection2\")) {\n+        assertNotNull(((NamedList<Object>)shardsInfo.getVal(i)).get(\"error\"));\n+        foundError = true;\n+        break;\n+      }\n+    }\n+    assertTrue(foundError);\n+    \n+    assertEquals(1, response.getResults().get(0).getFieldValue(\"id\"));\n+    assertEquals(\"batman\", response.getResults().get(0).getFirstValue(\"subject\"));\n+    unIgnoreException(\"Dummy exception in BadResponseWriter\");\n+  }\n+  \n+  public static class BadResponseWriter extends BinaryResponseWriter {\n+    \n+    private static boolean failOnGetFields = false;\n+    private static boolean failOnGetTopIds = false;\n+    \n+    public BadResponseWriter() {\n+      super();\n+    }\n+    \n+    @Override\n+    public void write(OutputStream out, SolrQueryRequest req,\n+        SolrQueryResponse response) throws IOException {\n+      \n+      // I want to fail on the shard request, not the original user request, and only on the \n+      // GET_FIELDS phase \n+      if (failOnGetFields && \n+          \"collection2\".equals(req.getCore().getName())\n+          && \"subject:batman OR subject:superman\".equals(req.getParams().get(\"q\", \"\"))\n+          && req.getParams().get(\"ids\") != null) {\n+        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n+            \"Dummy exception in BadResponseWriter\");\n+      } else if (failOnGetTopIds \n+          && \"collection2\".equals(req.getCore().getName())\n+          && \"subject:batman OR subject:superman\".equals(req.getParams().get(\"q\", \"\"))\n+          && req.getParams().get(\"ids\") == null\n+          && req.getParams().getBool(\"isShard\", false) == true) {\n+        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n+            \"Dummy exception in BadResponseWriter\");\n+      }\n+      super.write(out, req, response);\n+    }\n+    \n+    \n+  }\n+\n+  \n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/271576ed0f81421b0717f6da23bf3371c6c1bd87/solr/core/src/test/org/apache/solr/TestTolerantSearch.java",
                "sha": "81f65ad55dae82e823a9c4f77f683cc091eb51c6",
                "status": "added"
            }
        ],
        "message": "SOLR-6223: SearchComponents may throw NPE when using shards.tolerant and there is a failure in the 'GET_FIELDS/GET_HIGHLIGHTS/GET_DEBUG' phase\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1607897 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/2cc8facde24d456de81daf98425c43552d8b26e7",
        "repo": "lucene-solr",
        "unit_tests": [
            "DebugComponentTest.java",
            "MoreLikeThisComponentTest.java",
            "TermVectorComponentTest.java",
            "SolrPluginUtilsTest.java"
        ]
    },
    "lucene-solr_27c6275": {
        "bug_id": "lucene-solr_27c6275",
        "commit": "https://github.com/apache/lucene-solr/commit/27c6275c484f2dcb73cc64a06fb42ba2c4eefcbf",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/27c6275c484f2dcb73cc64a06fb42ba2c4eefcbf/solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/UpdateLog.java?ref=27c6275c484f2dcb73cc64a06fb42ba2c4eefcbf",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "patch": "@@ -295,8 +295,8 @@ public long getTotalLogsSize() {\n   /**\n    * @return the current transaction log's size (based on its output stream)\n    */\n-  public long getCurrentLogSizeFromStream() {\n-    return tlog.getLogSizeFromStream();\n+  public synchronized long getCurrentLogSizeFromStream() {\n+    return tlog == null ? 0 : tlog.getLogSizeFromStream();\n   }\n \n   public long getTotalLogsNumber() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/27c6275c484f2dcb73cc64a06fb42ba2c4eefcbf/solr/core/src/java/org/apache/solr/update/UpdateLog.java",
                "sha": "ef0e73e5f830f1332c14658e5a21f5491c77e755",
                "status": "modified"
            }
        ],
        "message": "SOLR-11277: Synchronize UpdateLog.getCurrentLogSizeFromStream and return size of tlog as 0 to avoid NPE",
        "parent": "https://github.com/apache/lucene-solr/commit/b1ee23c525a64017242148bca43111168fe1be3a",
        "repo": "lucene-solr",
        "unit_tests": [
            "UpdateLogTest.java"
        ]
    },
    "lucene-solr_28fb585": {
        "bug_id": "lucene-solr_28fb585",
        "commit": "https://github.com/apache/lucene-solr/commit/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/lucene/ivy-versions.properties",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/ivy-versions.properties?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 2,
                "filename": "lucene/ivy-versions.properties",
                "patch": "@@ -99,8 +99,8 @@ io.netty.netty-all.version = 4.0.36.Final\n /org.apache.ant/ant = 1.8.2\n /org.apache.avro/avro = 1.7.5\n \n-org.apache.calcite.version = 1.10.0\n-org.apache.calcite.avatica.version = 1.9.0-SNAPSHOT\n+org.apache.calcite.version = 1.11.0-SNAPSHOT\n+org.apache.calcite.avatica.version = 1.9.0\n /org.apache.calcite.avatica/avatica-core = ${org.apache.calcite.avatica.version}\n /org.apache.calcite/calcite-core = ${org.apache.calcite.version}\n /org.apache.calcite/calcite-linq4j = ${org.apache.calcite.version}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/lucene/ivy-versions.properties",
                "sha": "f42e70106722f3d66cb8d586296b02a01b127ba2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/core/src/java/org/apache/calcite/config/CalciteConnectionProperty.java",
                "changes": 182,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/calcite/config/CalciteConnectionProperty.java?ref=3856ce4b5cbedd1c9b6046d7a99206a086ba763a",
                "deletions": 182,
                "filename": "solr/core/src/java/org/apache/calcite/config/CalciteConnectionProperty.java",
                "patch": "@@ -1,182 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.calcite.config;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.Properties;\n-\n-import org.apache.calcite.avatica.ConnectionProperty;\n-import org.apache.calcite.avatica.util.Casing;\n-import org.apache.calcite.avatica.util.Quoting;\n-import org.apache.calcite.model.JsonSchema;\n-import org.apache.calcite.sql.validate.SqlConformance;\n-\n-import static org.apache.calcite.avatica.ConnectionConfigImpl.PropEnv;\n-import static org.apache.calcite.avatica.ConnectionConfigImpl.parse;\n-\n-/**\n- * Properties that may be specified on the JDBC connect string.\n- */\n-public enum CalciteConnectionProperty implements ConnectionProperty {\n-  /** Whether to store query results in temporary tables. */\n-  AUTO_TEMP(\"autoTemp\", Type.BOOLEAN, false, false),\n-\n-  /** Whether Calcite should use materializations. */\n-  MATERIALIZATIONS_ENABLED(\"materializationsEnabled\", Type.BOOLEAN, true,\n-      false),\n-\n-  /** Whether Calcite should create materializations. */\n-  CREATE_MATERIALIZATIONS(\"createMaterializations\", Type.BOOLEAN, true, false),\n-\n-  /** How NULL values should be sorted if neither NULLS FIRST nor NULLS LAST are\n-   * specified. The default, HIGH, sorts NULL values the same as Oracle. */\n-  DEFAULT_NULL_COLLATION(\"defaultNullCollation\", Type.ENUM, NullCollation.HIGH, NullCollation.class,\n-      true),\n-\n-  /** How many rows the Druid adapter should fetch at a time when executing\n-   * \"select\" queries. */\n-  DRUID_FETCH(\"druidFetch\", Type.NUMBER, 16384, false),\n-\n-  /** URI of the model. */\n-  MODEL(\"model\", Type.STRING, null, false),\n-\n-  /** Lexical policy. */\n-  LEX(\"lex\", Type.ENUM, Lex.ORACLE, Lex.class, false),\n-\n-  /** Collection of built-in functions and operators. Valid values include\n-   * \"standard\" and \"oracle\". */\n-  FUN(\"fun\", Type.STRING, \"standard\", true),\n-\n-  /** How identifiers are quoted.\n-   *  If not specified, value from {@link #LEX} is used. */\n-  QUOTING(\"quoting\", Type.ENUM, null, Quoting.class, false),\n-\n-  /** How identifiers are stored if they are quoted.\n-   *  If not specified, value from {@link #LEX} is used. */\n-  QUOTED_CASING(\"quotedCasing\", Type.ENUM, null, Casing.class, false),\n-\n-  /** How identifiers are stored if they are not quoted.\n-   *  If not specified, value from {@link #LEX} is used. */\n-  UNQUOTED_CASING(\"unquotedCasing\", Type.ENUM, null, Casing.class, false),\n-\n-  /** Whether identifiers are matched case-sensitively.\n-   *  If not specified, value from {@link #LEX} is used. */\n-  CASE_SENSITIVE(\"caseSensitive\", Type.BOOLEAN, null, false),\n-\n-  /** Name of initial schema. */\n-  SCHEMA(\"schema\", Type.STRING, null, false),\n-\n-  /** Schema factory.\n-   *\n-   * <p>The name of a class that implements\n-   * {@link org.apache.calcite.schema.SchemaFactory}.\n-   *\n-   * <p>Ignored if {@link #MODEL} is specified. */\n-  SCHEMA_FACTORY(\"schemaFactory\", Type.PLUGIN, null, false),\n-\n-  /** Schema type.\n-   *\n-   * <p>Value may be null, \"MAP\", \"JDBC\", or \"CUSTOM\"\n-   * (implicit if {@link #SCHEMA_FACTORY} is specified).\n-   * The value \"NONE\" is converted to null.\n-   *\n-   * <p>Ignored if {@link #MODEL} is specified. */\n-  SCHEMA_TYPE(\"schemaType\", Type.ENUM, JsonSchema.Type.NONE, JsonSchema.Type.class, false),\n-\n-  /** Specifies whether Spark should be used as the engine for processing that\n-   * cannot be pushed to the source system. If false (the default), Calcite\n-   * generates code that implements the Enumerable interface. */\n-  SPARK(\"spark\", Type.BOOLEAN, false, false),\n-\n-  /** Time zone, for example 'gmt-3'. Default is the JVM's time zone. */\n-  TIME_ZONE(\"timeZone\", Type.STRING, null, false),\n-\n-  /** If the planner should try de-correlating as much as it is possible.\n-   * If true (the default), Calcite de-correlates the plan. */\n-  FORCE_DECORRELATE(\"forceDecorrelate\", Type.BOOLEAN, true, false),\n-\n-  /** Type system. The name of a class that implements\n-   * {@link org.apache.calcite.rel.type.RelDataTypeSystem} and has a public\n-   * default constructor or an {@code INSTANCE} constant. */\n-  TYPE_SYSTEM(\"typeSystem\", Type.PLUGIN, null, false),\n-\n-  /** SQL conformance level. */\n-  CONFORMANCE(\"conformance\", Type.ENUM, SqlConformance.DEFAULT, SqlConformance.class, false);\n-\n-  private final String camelName;\n-  private final Type type;\n-  private final Object defaultValue;\n-  private final Class valueClass;\n-  private final boolean required;\n-\n-  private static final Map<String, CalciteConnectionProperty> NAME_TO_PROPS;\n-\n-  /** Deprecated; use {@link #TIME_ZONE}. */\n-  @Deprecated // to be removed before 2.0\n-  public static final CalciteConnectionProperty TIMEZONE = TIME_ZONE;\n-\n-  static {\n-    NAME_TO_PROPS = new HashMap<>();\n-    for (CalciteConnectionProperty p : CalciteConnectionProperty.values()) {\n-      NAME_TO_PROPS.put(p.camelName.toUpperCase(), p);\n-      NAME_TO_PROPS.put(p.name(), p);\n-    }\n-  }\n-\n-  CalciteConnectionProperty(String camelName, Type type, Object defaultValue,\n-                            boolean required) {\n-    this(camelName, type, defaultValue, type.defaultValueClass(), required);\n-  }\n-\n-  CalciteConnectionProperty(String camelName, Type type, Object defaultValue,\n-                            Class valueClass, boolean required) {\n-    this.camelName = camelName;\n-    this.type = type;\n-    this.defaultValue = defaultValue;\n-    this.valueClass = valueClass;\n-    this.required = required;\n-    assert defaultValue == null || type.valid(defaultValue, valueClass);\n-  }\n-\n-  public String camelName() {\n-    return camelName;\n-  }\n-\n-  public Object defaultValue() {\n-    return defaultValue;\n-  }\n-\n-  public Type type() {\n-    return type;\n-  }\n-\n-  public boolean required() {\n-    return required;\n-  }\n-\n-  public Class valueClass() {\n-    return valueClass;\n-  }\n-\n-  public PropEnv wrap(Properties properties) {\n-    return new PropEnv(parse(properties, NAME_TO_PROPS), this);\n-  }\n-\n-}\n-\n-// End CalciteConnectionProperty.java",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/core/src/java/org/apache/calcite/config/CalciteConnectionProperty.java",
                "sha": "b532c8382819ea787a76137583ef8d76ecc8d785",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/SQLHandler.java?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "patch": "@@ -101,7 +101,7 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n         throw new Exception(\"stmt parameter cannot be null\");\n       }\n \n-      String url = \"jdbc:calcitesolr:\";\n+      String url = CalciteSolrDriver.CONNECT_STRING_PREFIX;\n \n       Properties properties = new Properties();\n       // Add all query parameters",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "sha": "7b72a4ccdda04ee167ab0fa506c4c50a09d06040",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/core/src/java/org/apache/solr/handler/sql/CalciteSolrDriver.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/sql/CalciteSolrDriver.java?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/handler/sql/CalciteSolrDriver.java",
                "patch": "@@ -47,6 +47,10 @@ protected String getConnectStringPrefix() {\n \n   @Override\n   public Connection connect(String url, Properties info) throws SQLException {\n+    if(!this.acceptsURL(url)) {\n+      return null;\n+    }\n+\n     Connection connection = super.connect(url, info);\n     CalciteConnection calciteConnection = (CalciteConnection) connection;\n     final SchemaPlus rootSchema = calciteConnection.getRootSchema();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/core/src/java/org/apache/solr/handler/sql/CalciteSolrDriver.java",
                "sha": "3a7640de83e0d98dd088c445f56286ba9e69e5cb",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/avatica-core-1.9.0-SNAPSHOT.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/avatica-core-1.9.0-SNAPSHOT.jar.sha1?ref=3856ce4b5cbedd1c9b6046d7a99206a086ba763a",
                "deletions": 1,
                "filename": "solr/licenses/avatica-core-1.9.0-SNAPSHOT.jar.sha1",
                "patch": "@@ -1 +0,0 @@\n-bbddcaa253f82976cde4f7db115731e96a05c00a",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/avatica-core-1.9.0-SNAPSHOT.jar.sha1",
                "sha": "574e17b83f97e692e272211334890d68a87746cd",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/avatica-core-1.9.0.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/avatica-core-1.9.0.jar.sha1?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 0,
                "filename": "solr/licenses/avatica-core-1.9.0.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+c16b346eef02495f2f4b429fe04c33e526ec0229",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/avatica-core-1.9.0.jar.sha1",
                "sha": "b44a6158cf7bfb7b3e2feb9e435cb8dde3a7abd0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/calcite-core-1.10.0.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/calcite-core-1.10.0.jar.sha1?ref=3856ce4b5cbedd1c9b6046d7a99206a086ba763a",
                "deletions": 1,
                "filename": "solr/licenses/calcite-core-1.10.0.jar.sha1",
                "patch": "@@ -1 +0,0 @@\n-06550935a70e0d503ae1a11a251066dbb1bc20bb",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/calcite-core-1.10.0.jar.sha1",
                "sha": "9ead56bf2f17f340ef32cd37c5df532dd34385ad",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/calcite-core-1.11.0-SNAPSHOT.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/calcite-core-1.11.0-SNAPSHOT.jar.sha1?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 0,
                "filename": "solr/licenses/calcite-core-1.11.0-SNAPSHOT.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+1f21f343b06236702bb8b5dad167374b7b13768b",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/calcite-core-1.11.0-SNAPSHOT.jar.sha1",
                "sha": "3cb15ddff84a5aebcb0cb628a2f8046ee9df0f97",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/calcite-linq4j-1.10.0.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/calcite-linq4j-1.10.0.jar.sha1?ref=3856ce4b5cbedd1c9b6046d7a99206a086ba763a",
                "deletions": 1,
                "filename": "solr/licenses/calcite-linq4j-1.10.0.jar.sha1",
                "patch": "@@ -1 +0,0 @@\n-cb161081f3cca51d7a2089df746d771a8af2a577",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3856ce4b5cbedd1c9b6046d7a99206a086ba763a/solr/licenses/calcite-linq4j-1.10.0.jar.sha1",
                "sha": "16751a3b363aef3cde6c07a2eec92635a5266bb0",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/calcite-linq4j-1.11.0-SNAPSHOT.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/calcite-linq4j-1.11.0-SNAPSHOT.jar.sha1?ref=28fb5855f4529589ab2a9a19f8ba53ca4d9ac120",
                "deletions": 0,
                "filename": "solr/licenses/calcite-linq4j-1.11.0-SNAPSHOT.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+2be11a01e467b25e6f8925e4dfa94a77ec9746dd",
                "raw_url": "https://github.com/apache/lucene-solr/raw/28fb5855f4529589ab2a9a19f8ba53ca4d9ac120/solr/licenses/calcite-linq4j-1.11.0-SNAPSHOT.jar.sha1",
                "sha": "c1c9b390144a46091016a1fcd7730d27a9adee33",
                "status": "added"
            }
        ],
        "message": "Upgrade Avatica and Calcite. Fix NPE bug",
        "parent": "https://github.com/apache/lucene-solr/commit/3856ce4b5cbedd1c9b6046d7a99206a086ba763a",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSQLHandler.java"
        ]
    },
    "lucene-solr_2991d65": {
        "bug_id": "lucene-solr_2991d65",
        "commit": "https://github.com/apache/lucene-solr/commit/2991d657e449c48d727cd05b5762a4d171fdf101",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/CHANGES.txt",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -65,6 +65,14 @@ Optimizations\n   on Windows if NIOFSDirectory is used, mmapped files are still locked.\n   (Michael Poindexter, Robert Muir, Uwe Schindler)\n \n+======================= Lucene 4.8.0 =======================\n+\n+Bug fixes\n+\n+* LUCENE-5450: Fix getField() NPE issues with SpanOr/SpanNear when they have an \n+  empty list of clauses. This can happen for example,  when a wildcard matches \n+  no terms.  (Tim Allison via Robert Muir)\n+\n ======================= Lucene 4.7.0 =======================\n \n New Features",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/CHANGES.txt",
                "sha": "c56ee4a697770c55922e1f75cbbbc3aeae6d9661",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 2,
                "filename": "lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java",
                "patch": "@@ -64,9 +64,9 @@ public SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder, boolean col\n     this.clauses = new ArrayList<SpanQuery>(clauses.length);\n     for (int i = 0; i < clauses.length; i++) {\n       SpanQuery clause = clauses[i];\n-      if (i == 0) {                               // check field\n+      if (field == null) {                               // check field\n         field = clause.getField();\n-      } else if (!clause.getField().equals(field)) {\n+      } else if (clause.getField() != null && !clause.getField().equals(field)) {\n         throw new IllegalArgumentException(\"Clauses must have same field.\");\n       }\n       this.clauses.add(clause);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanNearQuery.java",
                "sha": "c412f133953afe4c61d2a9c417710197b8cafe3e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 1,
                "filename": "lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java",
                "patch": "@@ -62,7 +62,7 @@ public SpanNotQuery(SpanQuery include, SpanQuery exclude, int pre, int post) {\n     this.pre = (pre >=0) ? pre : 0;\n     this.post = (post >= 0) ? post : 0;\n \n-    if (!include.getField().equals(exclude.getField()))\n+    if (include.getField() != null && exclude.getField() != null && !include.getField().equals(exclude.getField()))\n       throw new IllegalArgumentException(\"Clauses must have same field.\");\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanNotQuery.java",
                "sha": "055ced6b14bf2753735724002efd10b05b1d9881",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 2,
                "filename": "lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java",
                "patch": "@@ -54,7 +54,7 @@ public SpanOrQuery(SpanQuery... clauses) {\n   public final void addClause(SpanQuery clause) {\n     if (field == null) {\n       field = clause.getField();\n-    } else if (!clause.getField().equals(field)) {\n+    } else if (clause.getField() != null && !clause.getField().equals(field)) {\n       throw new IllegalArgumentException(\"Clauses must have same field.\");\n     }\n     this.clauses.add(clause);\n@@ -132,7 +132,6 @@ public boolean equals(Object o) {\n     final SpanOrQuery that = (SpanOrQuery) o;\n \n     if (!clauses.equals(that.clauses)) return false;\n-    if (!clauses.isEmpty() && !field.equals(that.field)) return false;\n \n     return getBoost() == that.getBoost();\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanOrQuery.java",
                "sha": "d4ab76f4f18acc1458a80c0f75a711b6735c565b",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 1,
                "filename": "lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java",
                "patch": "@@ -34,7 +34,11 @@\n    * to search for spans. */\n   public abstract Spans getSpans(AtomicReaderContext context, Bits acceptDocs, Map<Term,TermContext> termContexts) throws IOException;\n \n-  /** Returns the name of the field matched by this query.*/\n+  /** \n+   * Returns the name of the field matched by this query.\n+   * <p>\n+   * Note that this may return null if the query matches no terms.\n+   */\n   public abstract String getField();\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/java/org/apache/lucene/search/spans/SpanQuery.java",
                "sha": "d6176163180b7c7e104570ae834f8736d3a21d73",
                "status": "modified"
            },
            {
                "additions": 131,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/test/org/apache/lucene/search/spans/TestSpanMultiTermQueryWrapper.java",
                "changes": 131,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/spans/TestSpanMultiTermQueryWrapper.java?ref=2991d657e449c48d727cd05b5762a4d171fdf101",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/spans/TestSpanMultiTermQueryWrapper.java",
                "patch": "@@ -24,6 +24,8 @@\n import org.apache.lucene.index.Term;\n import org.apache.lucene.search.FuzzyQuery;\n import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.PrefixQuery;\n+import org.apache.lucene.search.RegexpQuery;\n import org.apache.lucene.search.WildcardQuery;\n import org.apache.lucene.store.Directory;\n import org.apache.lucene.util.LuceneTestCase;\n@@ -95,4 +97,133 @@ public void testFuzzy2() throws Exception {\n     SpanPositionRangeQuery sprq = new SpanPositionRangeQuery(sfq, 0, 100);\n     assertEquals(1, searcher.search(sprq, 10).totalHits);\n   }\n+  public void testNoSuchMultiTermsInNear() throws Exception {\n+    //test to make sure non existent multiterms aren't throwing null pointer exceptions  \n+    FuzzyQuery fuzzyNoSuch = new FuzzyQuery(new Term(\"field\", \"noSuch\"), 1, 0, 1, false);\n+    SpanQuery spanNoSuch = new SpanMultiTermQueryWrapper<FuzzyQuery>(fuzzyNoSuch);\n+    SpanQuery term = new SpanTermQuery(new Term(\"field\", \"brown\"));\n+    SpanQuery near = new SpanNearQuery(new SpanQuery[]{term, spanNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+    //flip order\n+    near = new SpanNearQuery(new SpanQuery[]{spanNoSuch, term}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+    \n+    WildcardQuery wcNoSuch = new WildcardQuery(new Term(\"field\", \"noSuch*\"));\n+    SpanQuery spanWCNoSuch = new SpanMultiTermQueryWrapper<WildcardQuery>(wcNoSuch);\n+    near = new SpanNearQuery(new SpanQuery[]{term, spanWCNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+  \n+    RegexpQuery rgxNoSuch = new RegexpQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanRgxNoSuch = new SpanMultiTermQueryWrapper<RegexpQuery>(rgxNoSuch);\n+    near = new SpanNearQuery(new SpanQuery[]{term, spanRgxNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+    \n+    PrefixQuery prfxNoSuch = new PrefixQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanPrfxNoSuch = new SpanMultiTermQueryWrapper<PrefixQuery>(prfxNoSuch);\n+    near = new SpanNearQuery(new SpanQuery[]{term, spanPrfxNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+\n+    //test single noSuch\n+    near = new SpanNearQuery(new SpanQuery[]{spanPrfxNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+    \n+    //test double noSuch\n+    near = new SpanNearQuery(new SpanQuery[]{spanPrfxNoSuch, spanPrfxNoSuch}, 1, true);\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+\n+  }\n+  \n+  public void testNoSuchMultiTermsInNotNear() throws Exception {\n+    //test to make sure non existent multiterms aren't throwing non-matching field exceptions  \n+    FuzzyQuery fuzzyNoSuch = new FuzzyQuery(new Term(\"field\", \"noSuch\"), 1, 0, 1, false);\n+    SpanQuery spanNoSuch = new SpanMultiTermQueryWrapper<FuzzyQuery>(fuzzyNoSuch);\n+    SpanQuery term = new SpanTermQuery(new Term(\"field\", \"brown\"));\n+    SpanNotQuery notNear = new SpanNotQuery(term, spanNoSuch, 0,0);\n+    assertEquals(1, searcher.search(notNear, 10).totalHits);\n+\n+    //flip\n+    notNear = new SpanNotQuery(spanNoSuch, term, 0,0);\n+    assertEquals(0, searcher.search(notNear, 10).totalHits);\n+    \n+    //both noSuch\n+    notNear = new SpanNotQuery(spanNoSuch, spanNoSuch, 0,0);\n+    assertEquals(0, searcher.search(notNear, 10).totalHits);\n+\n+    WildcardQuery wcNoSuch = new WildcardQuery(new Term(\"field\", \"noSuch*\"));\n+    SpanQuery spanWCNoSuch = new SpanMultiTermQueryWrapper<WildcardQuery>(wcNoSuch);\n+    notNear = new SpanNotQuery(term, spanWCNoSuch, 0,0);\n+    assertEquals(1, searcher.search(notNear, 10).totalHits);\n+  \n+    RegexpQuery rgxNoSuch = new RegexpQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanRgxNoSuch = new SpanMultiTermQueryWrapper<RegexpQuery>(rgxNoSuch);\n+    notNear = new SpanNotQuery(term, spanRgxNoSuch, 1, 1);\n+    assertEquals(1, searcher.search(notNear, 10).totalHits);\n+    \n+    PrefixQuery prfxNoSuch = new PrefixQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanPrfxNoSuch = new SpanMultiTermQueryWrapper<PrefixQuery>(prfxNoSuch);\n+    notNear = new SpanNotQuery(term, spanPrfxNoSuch, 1, 1);\n+    assertEquals(1, searcher.search(notNear, 10).totalHits);\n+    \n+  }\n+  \n+  public void testNoSuchMultiTermsInOr() throws Exception {\n+    //test to make sure non existent multiterms aren't throwing null pointer exceptions  \n+    FuzzyQuery fuzzyNoSuch = new FuzzyQuery(new Term(\"field\", \"noSuch\"), 1, 0, 1, false);\n+    SpanQuery spanNoSuch = new SpanMultiTermQueryWrapper<FuzzyQuery>(fuzzyNoSuch);\n+    SpanQuery term = new SpanTermQuery(new Term(\"field\", \"brown\"));\n+    SpanOrQuery near = new SpanOrQuery(new SpanQuery[]{term, spanNoSuch});\n+    assertEquals(1, searcher.search(near, 10).totalHits);\n+    \n+    //flip\n+    near = new SpanOrQuery(new SpanQuery[]{spanNoSuch, term});\n+    assertEquals(1, searcher.search(near, 10).totalHits);\n+\n+    \n+    WildcardQuery wcNoSuch = new WildcardQuery(new Term(\"field\", \"noSuch*\"));\n+    SpanQuery spanWCNoSuch = new SpanMultiTermQueryWrapper<WildcardQuery>(wcNoSuch);\n+    near = new SpanOrQuery(new SpanQuery[]{term, spanWCNoSuch});\n+    assertEquals(1, searcher.search(near, 10).totalHits);\n+  \n+    RegexpQuery rgxNoSuch = new RegexpQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanRgxNoSuch = new SpanMultiTermQueryWrapper<RegexpQuery>(rgxNoSuch);\n+    near = new SpanOrQuery(new SpanQuery[]{term, spanRgxNoSuch});\n+    assertEquals(1, searcher.search(near, 10).totalHits);\n+    \n+    PrefixQuery prfxNoSuch = new PrefixQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanPrfxNoSuch = new SpanMultiTermQueryWrapper<PrefixQuery>(prfxNoSuch);\n+    near = new SpanOrQuery(new SpanQuery[]{term, spanPrfxNoSuch});\n+    assertEquals(1, searcher.search(near, 10).totalHits);\n+    \n+    near = new SpanOrQuery(new SpanQuery[]{spanPrfxNoSuch});\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+    \n+    near = new SpanOrQuery(new SpanQuery[]{spanPrfxNoSuch, spanPrfxNoSuch});\n+    assertEquals(0, searcher.search(near, 10).totalHits);\n+\n+  }\n+  \n+  \n+  public void testNoSuchMultiTermsInSpanFirst() throws Exception {\n+    //this hasn't been a problem  \n+    FuzzyQuery fuzzyNoSuch = new FuzzyQuery(new Term(\"field\", \"noSuch\"), 1, 0, 1, false);\n+    SpanQuery spanNoSuch = new SpanMultiTermQueryWrapper<FuzzyQuery>(fuzzyNoSuch);\n+    SpanQuery spanFirst = new SpanFirstQuery(spanNoSuch, 10);\n+ \n+    assertEquals(0, searcher.search(spanFirst, 10).totalHits);\n+    \n+    WildcardQuery wcNoSuch = new WildcardQuery(new Term(\"field\", \"noSuch*\"));\n+    SpanQuery spanWCNoSuch = new SpanMultiTermQueryWrapper<WildcardQuery>(wcNoSuch);\n+    spanFirst = new SpanFirstQuery(spanWCNoSuch, 10);\n+    assertEquals(0, searcher.search(spanFirst, 10).totalHits);\n+  \n+    RegexpQuery rgxNoSuch = new RegexpQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanRgxNoSuch = new SpanMultiTermQueryWrapper<RegexpQuery>(rgxNoSuch);\n+    spanFirst = new SpanFirstQuery(spanRgxNoSuch, 10);\n+    assertEquals(0, searcher.search(spanFirst, 10).totalHits);\n+    \n+    PrefixQuery prfxNoSuch = new PrefixQuery(new Term(\"field\", \"noSuch\"));\n+    SpanQuery spanPrfxNoSuch = new SpanMultiTermQueryWrapper<PrefixQuery>(prfxNoSuch);\n+    spanFirst = new SpanFirstQuery(spanPrfxNoSuch, 10);\n+    assertEquals(0, searcher.search(spanFirst, 10).totalHits);\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2991d657e449c48d727cd05b5762a4d171fdf101/lucene/core/src/test/org/apache/lucene/search/spans/TestSpanMultiTermQueryWrapper.java",
                "sha": "4dad29342dce347907b1643f7bca646b3b003f08",
                "status": "modified"
            }
        ],
        "message": "LUCENE-5450: fix getField() NPE issues with span queries that have empty clauses\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1569503 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/e04cf308eaa649cacfc27c45c9caa586121feb6f",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSpanNearQuery.java",
            "TestSpanNotQuery.java",
            "TestSpanOrQuery.java"
        ]
    },
    "lucene-solr_2a074e6": {
        "bug_id": "lucene-solr_2a074e6",
        "commit": "https://github.com/apache/lucene-solr/commit/2a074e6dc1f50f791b58437e2746cf5efdec4979",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2a074e6dc1f50f791b58437e2746cf5efdec4979/client/java/solrj/src/org/apache/solr/client/solrj/SolrQuery.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/client/java/solrj/src/org/apache/solr/client/solrj/SolrQuery.java?ref=2a074e6dc1f50f791b58437e2746cf5efdec4979",
                "deletions": 2,
                "filename": "client/java/solrj/src/org/apache/solr/client/solrj/SolrQuery.java",
                "patch": "@@ -372,7 +372,12 @@ public String getQuery() {\n   }\n \n   public void setRows(Integer rows) {\n-    this.set(CommonParams.ROWS, rows);\n+    if( rows == null ) {\n+      this.remove( CommonParams.ROWS );\n+    }\n+    else {\n+      this.set(CommonParams.ROWS, rows);\n+    }\n   }\n \n   public Integer getRows()\n@@ -390,7 +395,12 @@ public void setShowDebugInfo(boolean showDebugInfo) {\n //  }\n \n   public void setStart(Integer start) {\n-    this.set(CommonParams.START, start);\n+    if( start == null ) {\n+      this.remove( CommonParams.START );\n+    }\n+    else {\n+      this.set(CommonParams.START, start);\n+    }\n   }\n   \n   public Integer getStart()",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2a074e6dc1f50f791b58437e2746cf5efdec4979/client/java/solrj/src/org/apache/solr/client/solrj/SolrQuery.java",
                "sha": "0a4890ad6b058222d16070da1ea29f8974d0ae8c",
                "status": "modified"
            }
        ],
        "message": "let SolrQuery take null start/rows to remove them  (rather then throw NPE)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@609854 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/b80c55ebb40b6b7cc5f60d934a2c84bdc71403ea",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrQueryTest.java"
        ]
    },
    "lucene-solr_2b96b25": {
        "bug_id": "lucene-solr_2b96b25",
        "commit": "https://github.com/apache/lucene-solr/commit/2b96b2504677c0673bbf8300d2217205684056c6",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2b96b2504677c0673bbf8300d2217205684056c6/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=2b96b2504677c0673bbf8300d2217205684056c6",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -130,6 +130,9 @@ New Features\n   Also, the number of stored (failed and successful) responses are now restricted to 10,000 each as a safety net.\n   (Anshum Gupta)\n \n+* SOLR-7639: MoreLikeThis QParser now supports all options provided by the MLT Handler i.e. mintf, mindf,\n+  minwl, maxwl, maxqt, and maxntp.\n+\n Bug Fixes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2b96b2504677c0673bbf8300d2217205684056c6/solr/CHANGES.txt",
                "sha": "a0faec3189c665af14cd7c5264f5f0d34f70b2c6",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java?ref=2b96b2504677c0673bbf8300d2217205684056c6",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "patch": "@@ -53,22 +53,30 @@ public Query parse() {\n     // Do a Real Time Get for the document\n     SolrDocument doc = getDocument(id);\n     if(doc == null) {\n-      new SolrException(\n+      throw new SolrException(\n           SolrException.ErrorCode.BAD_REQUEST, \"Error completing MLT request. Could not fetch \" +\n           \"document with id [\" + id + \"]\");\n     }\n     \n     MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n-    // TODO: Are the mintf and mindf defaults ok at 1/0 ?\n     \n-    mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n+    if(localParams.getInt(\"mintf\") != null)\n+      mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n+\n     mlt.setMinDocFreq(localParams.getInt(\"mindf\", 0));\n+\n     if(localParams.get(\"minwl\") != null)\n       mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n-    \n+\n     if(localParams.get(\"maxwl\") != null)\n       mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n \n+    if(localParams.get(\"maxqt\") != null)\n+      mlt.setMaxWordLen(localParams.getInt(\"maxqt\"));\n+\n+    if(localParams.get(\"maxntp\") != null)\n+      mlt.setMaxWordLen(localParams.getInt(\"maxntp\"));\n+\n     mlt.setAnalyzer(req.getSchema().getIndexAnalyzer());\n \n     String[] qf = localParams.getParams(\"qf\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/java/org/apache/solr/search/mlt/CloudMLTQParser.java",
                "sha": "b853db2d43ba4cc6ebd202e7c3a2e272c924f341",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java?ref=2b96b2504677c0673bbf8300d2217205684056c6",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java",
                "patch": "@@ -59,15 +59,25 @@ public Query parse() {\n           \"document with id [\" + uniqueValue + \"]\");\n       ScoreDoc[] scoreDocs = td.scoreDocs;\n       MoreLikeThis mlt = new MoreLikeThis(req.getSearcher().getIndexReader());\n-      // TODO: Are the mintf and mindf defaults ok at '1' ?\n-      mlt.setMinTermFreq(localParams.getInt(\"mintf\", 1));\n-      mlt.setMinDocFreq(localParams.getInt(\"mindf\", 1));\n+      \n+      if(localParams.getInt(\"mintf\") != null)\n+        mlt.setMinTermFreq(localParams.getInt(\"mintf\"));\n+      \n+      if(localParams.getInt(\"mindf\") != null)\n+      mlt.setMinDocFreq(localParams.getInt(\"mindf\"));\n+      \n       if(localParams.get(\"minwl\") != null)\n         mlt.setMinWordLen(localParams.getInt(\"minwl\"));\n \n       if(localParams.get(\"maxwl\") != null)\n         mlt.setMaxWordLen(localParams.getInt(\"maxwl\"));\n \n+      if(localParams.get(\"maxqt\") != null)\n+        mlt.setMaxWordLen(localParams.getInt(\"maxqt\"));\n+\n+      if(localParams.get(\"maxntp\") != null)\n+        mlt.setMaxWordLen(localParams.getInt(\"maxntp\"));\n+      \n       ArrayList<String> fields = new ArrayList();\n \n       if (qf != null) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/java/org/apache/solr/search/mlt/SimpleMLTQParser.java",
                "sha": "2106b87dcf03a73c30d5b01f77679842986a81ec",
                "status": "modified"
            },
            {
                "additions": 35,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java?ref=2b96b2504677c0673bbf8300d2217205684056c6",
                "deletions": 22,
                "filename": "solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.solr.cloud.AbstractFullDistribZkTestBase;\n import org.apache.solr.common.SolrDocument;\n import org.apache.solr.common.SolrDocumentList;\n+import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.CommonParams;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.junit.Test;\n@@ -99,7 +100,7 @@ public void test() throws Exception {\n     params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}17\");\n     QueryResponse queryResponse = cloudClient.query(params);\n     SolrDocumentList solrDocuments = queryResponse.getResults();\n-    int[] expectedIds = new int[]{17, 13, 14, 20, 22, 15, 16, 24, 18, 23};\n+    int[] expectedIds = new int[]{17, 7, 13, 14, 15, 16, 20, 22, 24, 9};\n     int[] actualIds = new int[10];\n     int i = 0;\n     for (SolrDocument solrDocument : solrDocuments) {\n@@ -108,32 +109,19 @@ public void test() throws Exception {\n     assertArrayEquals(expectedIds, actualIds);\n     \n     params = new ModifiableSolrParams();\n-    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}3\");\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt mindf=0 mintf=1}3\");\n+    params.set(CommonParams.DEBUG, \"true\");\n     queryResponse = queryServer(params);\n     solrDocuments = queryResponse.getResults();\n     expectedIds = new int[]{3, 27, 26, 28};\n-    actualIds = new int[4];\n+    actualIds = new int[solrDocuments.size()];\n     i = 0;\n     for (SolrDocument solrDocument : solrDocuments) {\n       actualIds[i++] =  Integer.valueOf(String.valueOf(solrDocument.getFieldValue(\"id\")));\n     }\n     assertArrayEquals(expectedIds, actualIds);\n \n-    params = new ModifiableSolrParams();\n-    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}20\");\n-    params.set(\"debug\" , \"query\");\n-    queryResponse = queryServer(params);\n-    solrDocuments = queryResponse.getResults();\n-    expectedIds = new int[]{18, 23, 13, 14, 20, 22, 19, 21, 15, 16};\n-    actualIds = new int[10];\n-    i = 0;\n-    for (SolrDocument solrDocument : solrDocuments) {\n-      actualIds[i++] =  Integer.valueOf(String.valueOf(solrDocument.getFieldValue(\"id\")));\n-    }\n-    assertArrayEquals(expectedIds, actualIds);\n-\n-    String expectedQueryString = \"lowerfilt:over lowerfilt:fox lowerfilt:lazy lowerfilt:brown \"\n-        + \"lowerfilt:jumped lowerfilt:red lowerfilt:dogs. lowerfilt:quote lowerfilt:the\";\n+    String expectedQueryString = \"lowerfilt:bmw lowerfilt:usa\";\n     \n     ArrayList<String> actualParsedQueries = (ArrayList<String>) queryResponse\n         .getDebugMap().get(\"parsedquery\");\n@@ -143,26 +131,51 @@ public void test() throws Exception {\n           compareParsedQueryStrings(expectedQueryString,\n               actualParsedQueries.get(counter)));\n     }\n-  \n+\n+    params = new ModifiableSolrParams();\n+    // Test out a high value of df and make sure nothing matches.\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt mindf=20 mintf=1}3\");\n+    params.set(CommonParams.DEBUG, \"true\");\n+    queryResponse = queryServer(params);\n+    solrDocuments = queryResponse.getResults();\n+    assertEquals(\"Expected to match 0 documents with a mindf of 20 but found more\", solrDocuments.size(), 0);\n+\n+    params = new ModifiableSolrParams();\n+    // Test out a high value of wl and make sure nothing matches.\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt minwl=4 mintf=1}3\");\n+    params.set(CommonParams.DEBUG, \"true\");\n+    queryResponse = queryServer(params);\n+    solrDocuments = queryResponse.getResults();\n+    assertEquals(\"Expected to match 0 documents with a minwl of 4 but found more\", solrDocuments.size(), 0);\n+\n+    params = new ModifiableSolrParams();\n+    // Test out a low enough value of minwl and make sure we get the expected matches.\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt minwl=3 mintf=1}3\");\n+    params.set(CommonParams.DEBUG, \"true\");\n+    queryResponse = queryServer(params);\n+    solrDocuments = queryResponse.getResults();\n+    assertEquals(\"Expected to match 4 documents with a minwl of 3 but found more\", solrDocuments.size(), 4);\n+\n     // Assert that {!mlt}id does not throw an exception i.e. implicitly, only fields that are stored + have explicit\n     // analyzer are used for MLT Query construction.\n     params = new ModifiableSolrParams();\n     params.set(CommonParams.Q, \"{!mlt}20\");\n \n     queryResponse = queryServer(params);\n     solrDocuments = queryResponse.getResults();\n-    expectedIds = new int[]{18, 23, 13, 14, 20, 22, 19, 21, 15, 16};\n+    actualIds = new int[solrDocuments.size()];\n+    expectedIds = new int[]{13, 14, 15, 16, 20, 22, 24, 18, 19, 21};\n     i = 0;\n     for (SolrDocument solrDocument : solrDocuments) {\n       actualIds[i++] =  Integer.valueOf(String.valueOf(solrDocument.getFieldValue(\"id\")));\n     }\n     assertArrayEquals(expectedIds, actualIds);\n   }\n   \n-  @Test\n+  @Test(expected=SolrException.class)\n   public void testInvalidDocument() throws IOException {\n     ModifiableSolrParams params = new ModifiableSolrParams();\n-    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}nonexistentdocid\");\n+    params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}999999\");\n     try {\n       cloudClient.query(params);\n       fail(\"The above query is supposed to throw an exception.\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/test/org/apache/solr/search/mlt/CloudMLTQParserTest.java",
                "sha": "0780894ac6127744ce95919281e9a49adc75f651",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/test/org/apache/solr/search/mlt/SimpleMLTQParserTest.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/mlt/SimpleMLTQParserTest.java?ref=2b96b2504677c0673bbf8300d2217205684056c6",
                "deletions": 10,
                "filename": "solr/core/src/test/org/apache/solr/search/mlt/SimpleMLTQParserTest.java",
                "patch": "@@ -69,16 +69,16 @@ public void doTest() throws Exception {\n     ModifiableSolrParams params = new ModifiableSolrParams();\n     params.set(CommonParams.Q, \"{!mlt qf=lowerfilt}17\");\n     assertQ(req(params),\n-        \"//result/doc[1]/int[@name='id'][.='17']\",\n-        \"//result/doc[2]/int[@name='id'][.='13']\",\n-        \"//result/doc[3]/int[@name='id'][.='14']\",\n-        \"//result/doc[4]/int[@name='id'][.='18']\",\n-        \"//result/doc[5]/int[@name='id'][.='20']\",\n-        \"//result/doc[6]/int[@name='id'][.='22']\",\n-        \"//result/doc[7]/int[@name='id'][.='23']\",\n-        \"//result/doc[8]/int[@name='id'][.='9']\",\n-        \"//result/doc[9]/int[@name='id'][.='7']\",\n-        \"//result/doc[10]/int[@name='id'][.='15']\"\n+        \"//result/doc[1]/int[@name='id'][.='13']\",\n+        \"//result/doc[2]/int[@name='id'][.='14']\",\n+        \"//result/doc[3]/int[@name='id'][.='15']\",\n+        \"//result/doc[4]/int[@name='id'][.='16']\",\n+        \"//result/doc[5]/int[@name='id'][.='18']\",\n+        \"//result/doc[6]/int[@name='id'][.='19']\",\n+        \"//result/doc[7]/int[@name='id'][.='20']\",\n+        \"//result/doc[8]/int[@name='id'][.='21']\",\n+        \"//result/doc[9]/int[@name='id'][.='22']\",\n+        \"//result/doc[10]/int[@name='id'][.='23']\"\n         );\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2b96b2504677c0673bbf8300d2217205684056c6/solr/core/src/test/org/apache/solr/search/mlt/SimpleMLTQParserTest.java",
                "sha": "59a136316d4e526022a4923d9fc13d6023000d4d",
                "status": "modified"
            }
        ],
        "message": "SOLR-7639: MoreLikeThis QParser now supports all options provided by the MLT Handler i.e. mintf, mindf, minwl, maxwl, maxqt, and maxntp. This commit also fixes an NPE issue in CloudMLTQParser\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1686123 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/929cb9544db8af673ecc1931fffe5ebdbe5f8c29",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudMLTQParserTest.java",
            "SimpleMLTQParserTest.java"
        ]
    },
    "lucene-solr_2fe64e6": {
        "bug_id": "lucene-solr_2fe64e6",
        "commit": "https://github.com/apache/lucene-solr/commit/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=2fe64e65ac09f28d3e5614d22e4a94e284cdb94e",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -184,6 +184,9 @@ Bug Fixes\n * SOLR-5426: Fixed a bug in ReverseWildCardFilter that could cause \n   InvalidTokenOffsetsException when highlighting. (Uwe Schindler, Arun Kumar, via hossman)\n \n+* SOLR-6175: DebugComponent throws NPE on shard exceptions when using shards.tolerant.\n+  (Tom\u00e1s Fern\u00e1ndez L\u00f6bbe via shalin)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/CHANGES.txt",
                "sha": "2568d616f2f6d0e36a490b89740ac721f68a350c",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java?ref=2fe64e65ac09f28d3e5614d22e4a94e284cdb94e",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "patch": "@@ -206,6 +206,11 @@ public void finishStage(ResponseBuilder rb) {\n \n       for (ShardRequest sreq : rb.finished) {\n         for (ShardResponse srsp : sreq.responses) {\n+          if (srsp.getException() != null) {\n+            // can't expect the debug content if there was an exception for this request\n+            // this should only happen when using shards.tolerant=true\n+            continue;\n+          }\n           NamedList sdebug = (NamedList)srsp.getSolrResponse().getResponse().get(\"debug\");\n           info = (NamedList)merge(sdebug, info, EXCLUDE_SET);\n           if ((sreq.purpose & ShardRequest.PURPOSE_GET_DEBUG) != 0) {\n@@ -257,6 +262,10 @@ public void finishStage(ResponseBuilder rb) {\n \n   private NamedList<String> getTrackResponse(ShardResponse shardResponse) {\n     NamedList<String> namedList = new NamedList<>();\n+    if (shardResponse.getException() != null) {\n+      namedList.add(\"Exception\", shardResponse.getException().getMessage());\n+      return namedList;\n+    }\n     NamedList<Object> responseNL = shardResponse.getSolrResponse().getResponse();\n     @SuppressWarnings(\"unchecked\")\n     NamedList<Object> responseHeader = (NamedList<Object>)responseNL.get(\"responseHeader\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "sha": "6f5f44c1feacbd3cc256ede05f888d836281a8d6",
                "status": "modified"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/lucene-solr/blob/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java?ref=2fe64e65ac09f28d3e5614d22e4a94e284cdb94e",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "patch": "@@ -7,6 +7,7 @@\n import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n+import java.util.Map.Entry;\n import java.util.Set;\n \n import org.apache.commons.io.FileUtils;\n@@ -18,7 +19,9 @@\n import org.apache.solr.client.solrj.impl.HttpSolrServer;\n import org.apache.solr.client.solrj.request.CoreAdminRequest;\n import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.SolrException;\n import org.apache.solr.common.SolrInputDocument;\n+import org.apache.solr.common.params.ShardParams;\n import org.apache.solr.common.util.NamedList;\n import org.junit.AfterClass;\n import org.junit.BeforeClass;\n@@ -96,6 +99,7 @@ public static void destroyThings() throws Exception {\n     collection2 = null;\n     jetty.stop();\n     jetty=null;\n+    resetExceptionIgnores();\n   }\n   \n   @Test\n@@ -367,6 +371,35 @@ public void testCompareWithNonDistributedRequest() throws SolrServerException {\n     assertSameKeys((NamedList<?>)nonDistribResponse.getDebugMap().get(\"timing\"), (NamedList<?>)distribResponse.getDebugMap().get(\"timing\"));\n   }\n   \n+  public void testTolerantSearch() throws SolrServerException {\n+    String badShard = \"[ff01::0083]:3334\";\n+    SolrQuery query = new SolrQuery();\n+    query.setQuery(\"*:*\");\n+    query.set(\"debug\",  \"true\");\n+    query.set(\"distrib\", \"true\");\n+    query.setFields(\"id\", \"text\");\n+    query.set(\"shards\", shard1 + \",\" + shard2 + \",\" + badShard);\n+    try {\n+      ignoreException(\"Server refused connection\");\n+      // verify that the request would fail if shards.tolerant=false\n+      collection1.query(query);\n+      fail(\"Expecting exception\");\n+    } catch (SolrException e) {\n+      //expected\n+    }\n+    query.set(ShardParams.SHARDS_TOLERANT, \"true\");\n+    QueryResponse response = collection1.query(query);\n+    assertTrue((Boolean)response.getResponseHeader().get(\"partialResults\"));\n+    @SuppressWarnings(\"unchecked\")\n+    NamedList<String> badShardTrack = (NamedList<String>) ((NamedList<NamedList<String>>)\n+        ((NamedList<NamedList<NamedList<String>>>)response.getDebugMap().get(\"track\")).get(\"EXECUTE_QUERY\")).get(badShard);\n+    assertEquals(\"Unexpected response size for shard\", 1, badShardTrack.size());\n+    Entry<String, String> exception = badShardTrack.iterator().next();\n+    assertEquals(\"Expected key 'Exception' not found\", \"Exception\", exception.getKey());\n+    assertTrue(\"Unexpected exception message\", exception.getValue().contains(\"Server refused connection\"));\n+    unIgnoreException(\"Server refused connection\");\n+  }\n+  \n   /**\n    * Compares the same section on the two query responses\n    */",
                "raw_url": "https://github.com/apache/lucene-solr/raw/2fe64e65ac09f28d3e5614d22e4a94e284cdb94e/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "sha": "833eb6d4f07ed4191b9df4dcbb99b46a3b9c1cdb",
                "status": "modified"
            }
        ],
        "message": "SOLR-6175: DebugComponent throws NPE on shard exceptions when using shards.tolerant\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1603061 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/565dfc3e1fb7a5e69eafb83e4f301717b42d3bee",
        "repo": "lucene-solr",
        "unit_tests": [
            "DebugComponentTest.java"
        ]
    },
    "lucene-solr_30b3cc8": {
        "bug_id": "lucene-solr_30b3cc8",
        "commit": "https://github.com/apache/lucene-solr/commit/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/CHANGES.txt",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -317,6 +317,11 @@ New Features\n   handler, as long as you also provide a XSL to transform them to a valid\n   Solr input document.  (Upayavira, Uwe Schindler)\n \n+* SOLR-2615: Log individual updates (adds and deletes) at the FINE level\n+  before adding to the index.  Fix a null pointer exception in logging\n+  when there was no unique key. (David Smiley via yonik)\n+\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/CHANGES.txt",
                "sha": "61f80061b297b3f681fc8e85c632803c1d58b44b",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/SolrCore.java?ref=30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "patch": "@@ -659,8 +659,8 @@ private CodecProvider initCodecProvider(SolrConfig solrConfig, IndexSchema schem\n     if (def == null) {\n       // construct the default chain\n       UpdateRequestProcessorFactory[] factories = new UpdateRequestProcessorFactory[]{\n-              new RunUpdateProcessorFactory(),\n-              new LogUpdateProcessorFactory()\n+              new LogUpdateProcessorFactory(),\n+              new RunUpdateProcessorFactory()\n       };\n       def = new UpdateRequestProcessorChain(factories, this);\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "sha": "de6837122c0d8973078d6873753ddb57aafc479e",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java?ref=30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java",
                "patch": "@@ -90,15 +90,15 @@ public String getIndexedId(IndexSchema schema) {\n \n    public String getPrintableId(IndexSchema schema) {\n      SchemaField sf = schema.getUniqueKeyField();\n-     if (indexedId != null) {\n-       return schema.getUniqueKeyField().getType().indexedToReadable(indexedId);\n+     if (indexedId != null && sf != null) {\n+       return sf.getType().indexedToReadable(indexedId);\n      }\n \n      if (doc != null) {\n        return schema.printableUniqueKey(doc);\n      }\n \n-     if (solrDoc != null) {\n+     if (solrDoc != null && sf != null) {\n        SolrInputField field = solrDoc.getField(sf.getName());\n        if (field != null) {\n          return field.getFirstValue().toString();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/AddUpdateCommand.java",
                "sha": "cf6ce93083e39866d65dfd4011c90348ae9a1138",
                "status": "modified"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/lucene-solr/blob/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/processor/LogUpdateProcessorFactory.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/LogUpdateProcessorFactory.java?ref=30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
                "deletions": 14,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/LogUpdateProcessorFactory.java",
                "patch": "@@ -31,12 +31,15 @@\n import org.apache.solr.update.DeleteUpdateCommand;\n import org.apache.solr.update.MergeIndexesCommand;\n import org.apache.solr.update.RollbackUpdateCommand;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * A logging processor.  This keeps track of all commands that have passed through\n- * the chain and prints them on finish();\n+ * the chain and prints them on finish().  At the Debug (FINE) level, a message\n+ * will be logged for each command prior to the next stage in the chain.\n  * \n- * If the Log level is not INFO the processor will not be created or added to the chain\n+ * If the Log level is not >= INFO the processor will not be created or added to the chain.\n  * \n  * @since solr 1.3\n  */\n@@ -54,11 +57,14 @@ public void init( final NamedList args ) {\n \n   @Override\n   public UpdateRequestProcessor getInstance(SolrQueryRequest req, SolrQueryResponse rsp, UpdateRequestProcessor next) {\n-    boolean doLog = LogUpdateProcessor.log.isInfoEnabled();\n+    final Logger logger = LoggerFactory.getLogger(LogUpdateProcessor.class);\n+    boolean doLog = logger.isInfoEnabled();\n     // LogUpdateProcessor.log.error(\"Will Log=\" + doLog);\n     if( doLog ) {\n       // only create the log processor if we will use it\n-      return new LogUpdateProcessor(req, rsp, this, next);\n+      final LogUpdateProcessor processor = new LogUpdateProcessor(req, rsp, this, next);\n+      assert processor.log == logger;\n+      return processor;\n     }\n     return null;\n   }\n@@ -78,6 +84,8 @@ public UpdateRequestProcessor getInstance(SolrQueryRequest req, SolrQueryRespons\n \n   private final int maxNumToLog;\n \n+  private final boolean logDebug = log.isDebugEnabled();//cache to avoid volatile-read\n+\n   public LogUpdateProcessor(SolrQueryRequest req, SolrQueryResponse rsp, LogUpdateProcessorFactory factory, UpdateRequestProcessor next) {\n     super( next );\n     this.req = req;\n@@ -91,8 +99,6 @@ public LogUpdateProcessor(SolrQueryRequest req, SolrQueryResponse rsp, LogUpdate\n   \n   @Override\n   public void processAdd(AddUpdateCommand cmd) throws IOException {\n-    if (next != null) next.processAdd(cmd);\n-\n     // Add a list of added id's to the response\n     if (adds == null) {\n       adds = new ArrayList<String>();\n@@ -102,14 +108,15 @@ public void processAdd(AddUpdateCommand cmd) throws IOException {\n     if (adds.size() < maxNumToLog) {\n       adds.add(cmd.getPrintableId(req.getSchema()));\n     }\n+    if (logDebug) { log.debug(\"add {}\", cmd.getPrintableId(req.getSchema())); }\n \n     numAdds++;\n+\n+    if (next != null) next.processAdd(cmd);\n   }\n \n   @Override\n   public void processDelete( DeleteUpdateCommand cmd ) throws IOException {\n-    if (next != null) next.processDelete(cmd);\n-\n     if (cmd.id != null) {\n       if (deletes == null) {\n         deletes = new ArrayList<String>();\n@@ -118,42 +125,52 @@ public void processDelete( DeleteUpdateCommand cmd ) throws IOException {\n       if (deletes.size() < maxNumToLog) {\n         deletes.add(cmd.id);\n       }\n+      if (logDebug) { log.debug(\"delete {}\", cmd.id); }\n     } else {\n       if (toLog.size() < maxNumToLog) {\n         toLog.add(\"deleteByQuery\", cmd.query);\n       }\n+      if (logDebug) { log.debug(\"deleteByQuery {}\", cmd.query); }\n     }\n     numDeletes++;\n+\n+    if (next != null) next.processDelete(cmd);\n   }\n \n   @Override\n   public void processMergeIndexes(MergeIndexesCommand cmd) throws IOException {\n-    if (next != null) next.processMergeIndexes(cmd);\n-\n     toLog.add(\"mergeIndexes\", cmd.toString());\n+    if (logDebug) { log.debug(\"mergeIndexes {}\",cmd.toString()); }\n+\n+    if (next != null) next.processMergeIndexes(cmd);\n   }\n \n   @Override\n   public void processCommit( CommitUpdateCommand cmd ) throws IOException {\n+    final String msg = cmd.optimize ? \"optimize\" : \"commit\";\n+    toLog.add(msg, \"\");\n+    if (logDebug) { log.debug(msg); }\n+\n     if (next != null) next.processCommit(cmd);\n-    \n-    toLog.add(cmd.optimize ? \"optimize\" : \"commit\", \"\");\n   }\n \n   /**\n    * @since Solr 1.4\n    */\n   @Override\n   public void processRollback( RollbackUpdateCommand cmd ) throws IOException {\n-    if (next != null) next.processRollback(cmd);\n-    \n     toLog.add(\"rollback\", \"\");\n+    if (logDebug) { log.debug(\"rollback\"); }\n+\n+    if (next != null) next.processRollback(cmd);\n   }\n \n \n   @Override\n   public void finish() throws IOException {\n     if (next != null) next.finish();\n+\n+    // LOG A SUMMARY WHEN ALL DONE (INFO LEVEL)\n     \n     // TODO: right now, update requests are logged twice...\n     // this will slow down things compared to Solr 1.2",
                "raw_url": "https://github.com/apache/lucene-solr/raw/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/processor/LogUpdateProcessorFactory.java",
                "sha": "16df29e66b2c7ffb720a266ba0dc8d36bfabed93",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessor.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessor.java?ref=30b3cc881d3ac1e968f8fc1926bfbf12e20871b3",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessor.java",
                "patch": "@@ -41,7 +41,7 @@\n  * @since solr 1.3\n  */\n public abstract class UpdateRequestProcessor {\n-  protected static Logger log = LoggerFactory.getLogger(UpdateRequestProcessor.class);\n+  protected final Logger log = LoggerFactory.getLogger(getClass());\n \n   protected final UpdateRequestProcessor next;\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/30b3cc881d3ac1e968f8fc1926bfbf12e20871b3/solr/core/src/java/org/apache/solr/update/processor/UpdateRequestProcessor.java",
                "sha": "99dff327ca4c21d0d10990252c15f7fdab82c7b0",
                "status": "modified"
            }
        ],
        "message": "SOLR-2615: log individual updates at DEBUG level, fix NPE when no unique key\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1145198 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/582e3c8f26fde04596354a0a3ca54eee5f6ce681",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrCoreTest.java"
        ]
    },
    "lucene-solr_31e3b27": {
        "bug_id": "lucene-solr_31e3b27",
        "commit": "https://github.com/apache/lucene-solr/commit/31e3b272c5611a209f926d3a122dbe03ff71956a",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker.java?ref=31e3b272c5611a209f926d3a122dbe03ff71956a",
                "deletions": 1,
                "filename": "modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker.java",
                "patch": "@@ -28,6 +28,7 @@\n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.index.MultiFields;\n import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n import org.apache.lucene.search.FuzzyTermsEnum;\n import org.apache.lucene.search.BoostAttribute;\n import org.apache.lucene.search.MaxNonCompetitiveBoostAttribute;\n@@ -395,7 +396,11 @@ public void setDistance(StringDistance distance) {\n     AttributeSource atts = new AttributeSource();\n     MaxNonCompetitiveBoostAttribute maxBoostAtt =\n       atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n-    FuzzyTermsEnum e = new FuzzyTermsEnum(MultiFields.getTerms(ir, term.field()).iterator(), atts, term, editDistance, Math.max(minPrefix, editDistance-1));\n+    Terms terms = MultiFields.getTerms(ir, term.field());\n+    if (terms == null) {\n+      return Collections.emptyList();\n+    }\n+    FuzzyTermsEnum e = new FuzzyTermsEnum(terms.iterator(), atts, term, editDistance, Math.max(minPrefix, editDistance-1));\n     final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n     \n     BytesRef queryTerm = new BytesRef(term.text());",
                "raw_url": "https://github.com/apache/lucene-solr/raw/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/java/org/apache/lucene/search/spell/DirectSpellChecker.java",
                "sha": "36804eed92a63cfbe97e6f9b0b9ee32f7aa43905",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/test/org/apache/lucene/search/spell/TestDirectSpellChecker.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/modules/suggest/src/test/org/apache/lucene/search/spell/TestDirectSpellChecker.java?ref=31e3b272c5611a209f926d3a122dbe03ff71956a",
                "deletions": 0,
                "filename": "modules/suggest/src/test/org/apache/lucene/search/spell/TestDirectSpellChecker.java",
                "patch": "@@ -141,4 +141,25 @@ public void testOptions() throws Exception {\n     writer.close();\n     dir.close();\n   }\n+  \n+  public void testBogusField() throws Exception {\n+    DirectSpellChecker spellChecker = new DirectSpellChecker();\n+    Directory dir = newDirectory();\n+    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n+        new MockAnalyzer(random, MockTokenizer.SIMPLE, true));\n+\n+    for (int i = 0; i < 20; i++) {\n+      Document doc = new Document();\n+      doc.add(newField(\"numbers\", English.intToEnglish(i), Field.Store.NO, Field.Index.ANALYZED));\n+      writer.addDocument(doc);\n+    }\n+\n+    IndexReader ir = writer.getReader();\n+\n+    SuggestWord[] similar = spellChecker.suggestSimilar(new Term(\"bogusFieldBogusField\", \"fvie\"), 2, ir, false);\n+    assertEquals(0, similar.length);\n+    ir.close();\n+    writer.close();\n+    dir.close();\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/test/org/apache/lucene/search/spell/TestDirectSpellChecker.java",
                "sha": "6685af41ba302b6844e8e3c422b71cd0f062ef49",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/test/org/apache/lucene/search/spell/TestSpellChecker.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/modules/suggest/src/test/org/apache/lucene/search/spell/TestSpellChecker.java?ref=31e3b272c5611a209f926d3a122dbe03ff71956a",
                "deletions": 0,
                "filename": "modules/suggest/src/test/org/apache/lucene/search/spell/TestSpellChecker.java",
                "patch": "@@ -136,6 +136,20 @@ public void testComparator() throws Exception {\n       compareSP.close();\n     compIdx.close();\n   }\n+  \n+  public void testBogusField() throws Exception {\n+    IndexReader r = IndexReader.open(userindex, true);\n+    Directory compIdx = newDirectory();\n+    SpellChecker compareSP = new SpellCheckerMock(compIdx, new LevensteinDistance(), new SuggestWordFrequencyComparator());\n+    addwords(r, compareSP, \"field3\");\n+\n+    String[] similar = compareSP.suggestSimilar(\"fvie\", 2, r, \"bogusFieldBogusField\", false);\n+    assertEquals(0, similar.length);\n+    r.close();\n+    if (!compareSP.isClosed())\n+      compareSP.close();\n+    compIdx.close();\n+  }\n \n   private void checkCommonSuggestions(IndexReader r) throws IOException {\n     String[] similar = spellChecker.suggestSimilar(\"fvie\", 2);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/31e3b272c5611a209f926d3a122dbe03ff71956a/modules/suggest/src/test/org/apache/lucene/search/spell/TestSpellChecker.java",
                "sha": "8da6cd4466aaf2b58639364af995c59a1f21bae9",
                "status": "modified"
            }
        ],
        "message": "LUCENE-3351: DirectSpellChecker throws NPE if field doesn't exist\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1152669 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/2b7362de2b1522453fe2ae8355108181ffb8a457",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestDirectSpellChecker.java"
        ]
    },
    "lucene-solr_321b292": {
        "bug_id": "lucene-solr_321b292",
        "commit": "https://github.com/apache/lucene-solr/commit/321b292be9ef1ddd344517bf4dc660d78ad95d3f",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/PhrasePrefixQuery.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/PhrasePrefixQuery.java?ref=321b292be9ef1ddd344517bf4dc660d78ad95d3f",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/search/PhrasePrefixQuery.java",
                "patch": "@@ -212,7 +212,10 @@ public Explanation explain(IndexReader reader, int doc)\n       fieldExpl.addDetail(idfExpl);\n \n       Explanation fieldNormExpl = new Explanation();\n-      fieldNormExpl.setValue(Similarity.decodeNorm(reader.norms(field)[doc]));\n+      byte[] fieldNorms = reader.norms(field);\n+      float fieldNorm =\n+        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n+      fieldNormExpl.setValue(fieldNorm);\n       fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n       fieldExpl.addDetail(fieldNormExpl);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/PhrasePrefixQuery.java",
                "sha": "3d481c6df20907634ce7a3e6f3b24f6333c1335e",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/PhraseQuery.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/PhraseQuery.java?ref=321b292be9ef1ddd344517bf4dc660d78ad95d3f",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/search/PhraseQuery.java",
                "patch": "@@ -210,7 +210,10 @@ public Explanation explain(IndexReader reader, int doc)\n       fieldExpl.addDetail(idfExpl);\n \n       Explanation fieldNormExpl = new Explanation();\n-      fieldNormExpl.setValue(Similarity.decodeNorm(reader.norms(field)[doc]));\n+      byte[] fieldNorms = reader.norms(field);\n+      float fieldNorm =\n+        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n+      fieldNormExpl.setValue(fieldNorm);\n       fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n       fieldExpl.addDetail(fieldNormExpl);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/PhraseQuery.java",
                "sha": "4b7bdd2be7a2ffe9480f2a5ce74e406d7ad12cf3",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/TermQuery.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/TermQuery.java?ref=321b292be9ef1ddd344517bf4dc660d78ad95d3f",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/search/TermQuery.java",
                "patch": "@@ -139,7 +139,10 @@ public Explanation explain(IndexReader reader, int doc)\n       fieldExpl.addDetail(idfExpl);\n \n       Explanation fieldNormExpl = new Explanation();\n-      fieldNormExpl.setValue(Similarity.decodeNorm(reader.norms(field)[doc]));\n+      byte[] fieldNorms = reader.norms(field);\n+      float fieldNorm =\n+        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n+      fieldNormExpl.setValue(fieldNorm);\n       fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n       fieldExpl.addDetail(fieldNormExpl);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/321b292be9ef1ddd344517bf4dc660d78ad95d3f/src/java/org/apache/lucene/search/TermQuery.java",
                "sha": "631be64ec2d6f14441fb469da0971ca297eedddc",
                "status": "modified"
            }
        ],
        "message": "Fixed a NPE in Query.explain().\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@150155 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/859e6eee2054c72064e874c6ae7aff7e4abe4129",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestPhrasePrefixQuery.java",
            "TestPhraseQuery.java",
            "TestTermQuery.java"
        ]
    },
    "lucene-solr_328cace": {
        "bug_id": "lucene-solr_328cace",
        "commit": "https://github.com/apache/lucene-solr/commit/328cacec627701087d11aa5b269d0563450a508a",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/328cacec627701087d11aa5b269d0563450a508a/src/java/org/apache/solr/core/SolrCore.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/core/SolrCore.java?ref=328cacec627701087d11aa5b269d0563450a508a",
                "deletions": 2,
                "filename": "src/java/org/apache/solr/core/SolrCore.java",
                "patch": "@@ -357,6 +357,9 @@ void initIndex() {\n       boolean indexExists = dirFile.canRead();\n       boolean firstTime = dirs.add(dirFile.getCanonicalPath());\n       boolean removeLocks = solrConfig.getBool(\"mainIndex/unlockOnStartup\", false);\n+\n+      initDirectoryFactory();\n+\n       if (indexExists && firstTime && removeLocks) {\n         // to remove locks, the directory must already exist... so we create it\n         // if it didn't exist already...\n@@ -378,8 +381,6 @@ void initIndex() {\n         SolrIndexWriter writer = new SolrIndexWriter(\"SolrCore.initIndex\",getIndexDir(), true, schema, solrConfig.mainIndexConfig);\n         writer.close();\n       }\n-      \n-      initDirectoryFactory();\n \n     } catch (IOException e) {\n       throw new RuntimeException(e);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/328cacec627701087d11aa5b269d0563450a508a/src/java/org/apache/solr/core/SolrCore.java",
                "sha": "b7a0c967392489a80564620b005872f8fb2b6567",
                "status": "modified"
            }
        ],
        "message": "SOLR-863 -- Fixing NPE. DirectoryFactory should be created before calling SolrIndexWriter.getDirectory.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@727779 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/82279f712f9c0e919824d6c6f6535a907a282bfa",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrCoreTest.java"
        ]
    },
    "lucene-solr_390fbf2": {
        "bug_id": "lucene-solr_390fbf2",
        "commit": "https://github.com/apache/lucene-solr/commit/390fbf21d2c5fdee1a94247d51722673883328ce",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=390fbf21d2c5fdee1a94247d51722673883328ce",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -481,6 +481,10 @@ Bug fixes\n   files when a mergedSegmentWarmer is set on IndexWriter.  (Mike\n   McCandless)\n \n+* LUCENE-2496: Don't throw NPE if IndexWriter is opened with CREATE on\n+  a prior (corrupt) index missing its segments_N file.  (Mike\n+  McCandless)\n+\n New features\n \n * LUCENE-2128: Parallelized fetching document frequencies during weight",
                "raw_url": "https://github.com/apache/lucene-solr/raw/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/CHANGES.txt",
                "sha": "cf623a3abaeb100ea6290f87605025ba027efc86",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java?ref=390fbf21d2c5fdee1a94247d51722673883328ce",
                "deletions": 9,
                "filename": "lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "patch": "@@ -134,8 +134,10 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n     this.docWriter = docWriter;\n     this.infoStream = infoStream;\n \n+    final String currentSegmentsFile = segmentInfos.getCurrentSegmentFileName();\n+\n     if (infoStream != null)\n-      message(\"init: current segments file is \\\"\" + segmentInfos.getCurrentSegmentFileName() + \"\\\"; deletionPolicy=\" + policy);\n+      message(\"init: current segments file is \\\"\" + currentSegmentsFile + \"\\\"; deletionPolicy=\" + policy);\n \n     this.policy = policy;\n     this.directory = directory;\n@@ -146,7 +148,6 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n     indexFilenameFilter = new IndexFileNameFilter(codecs);\n     \n     CommitPoint currentCommitPoint = null;\n-    boolean seenIndexFiles = false;\n     String[] files = null;\n     try {\n       files = directory.listAll();\n@@ -158,7 +159,6 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n     for (String fileName : files) {\n \n       if ((indexFilenameFilter.accept(null, fileName)) && !fileName.endsWith(\"write.lock\") && !fileName.equals(IndexFileNames.SEGMENTS_GEN)) {\n-        seenIndexFiles = true;\n         \n         // Add this file to refCounts with initial count 0:\n         getRefCount(fileName);\n@@ -201,10 +201,7 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n       }\n     }\n \n-    // If we haven't seen any Lucene files, then currentCommitPoint is expected\n-    // to be null, because it means it's a fresh Directory. Therefore it cannot\n-    // be any NFS cache issues - so just ignore.\n-    if (currentCommitPoint == null && seenIndexFiles) {\n+    if (currentCommitPoint == null && currentSegmentsFile != null) {\n       // We did not in fact see the segments_N file\n       // corresponding to the segmentInfos that was passed\n       // in.  Yet, it must exist, because our caller holds\n@@ -214,7 +211,7 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n       // try now to explicitly open this commit point:\n       SegmentInfos sis = new SegmentInfos();\n       try {\n-        sis.read(directory, segmentInfos.getCurrentSegmentFileName(), codecs);\n+        sis.read(directory, currentSegmentsFile, codecs);\n       } catch (IOException e) {\n         throw new CorruptIndexException(\"failed to locate current segments_N file\");\n       }\n@@ -244,7 +241,7 @@ public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, Segment\n \n     // Finally, give policy a chance to remove things on\n     // startup:\n-    if (seenIndexFiles) {\n+    if (currentSegmentsFile != null) {\n       policy.onInit(commits);\n     }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/src/java/org/apache/lucene/index/IndexFileDeleter.java",
                "sha": "5b5c9d2f800e4feda57adebe7f9da42623c62d10",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/lucene-solr/blob/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java?ref=390fbf21d2c5fdee1a94247d51722673883328ce",
                "deletions": 1,
                "filename": "lucene/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "patch": "@@ -4954,5 +4954,32 @@ public void testEmptyDirRollback() throws Exception {\n     writer.close();\n     assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n   }\n-  \n+\n+  public void testNoSegmentFile() throws IOException {\n+    File tempDir = _TestUtil.getTempDir(\"noSegmentFile\");\n+    try {\n+      Directory dir = FSDirectory.open(tempDir);\n+      dir.setLockFactory(new NoLockFactory());\n+      IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(\n+                                                                 TEST_VERSION_CURRENT, new MockAnalyzer())\n+                                      .setMaxBufferedDocs(2));\n+\n+      Document doc = new Document();\n+      doc.add(new Field(\"c\", \"val\", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));\n+      w.addDocument(doc);\n+      w.addDocument(doc);\n+      String[] files = dir.listAll();\n+      for(String file : files) {\n+        System.out.println(\"file=\" + file);\n+      }\n+      IndexWriter w2 = new IndexWriter(dir, new IndexWriterConfig(\n+                                                                  TEST_VERSION_CURRENT, new MockAnalyzer())\n+                                       .setMaxBufferedDocs(2).setOpenMode(OpenMode.CREATE));\n+\n+      w2.close();\n+      dir.close();\n+    } finally {\n+      _TestUtil.rmDir(tempDir);\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/390fbf21d2c5fdee1a94247d51722673883328ce/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "sha": "a3d12032b1f433f3f10ebc579635054b378bd1a2",
                "status": "modified"
            }
        ],
        "message": "LUCENE-2496: don't throw NPE on trying to CREATE over a corrupt index\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@953628 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/db1cb0bcb5f392a8b017d66c04f9fec567accf2f",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestIndexFileDeleter.java"
        ]
    },
    "lucene-solr_39887b8": {
        "bug_id": "lucene-solr_39887b8",
        "commit": "https://github.com/apache/lucene-solr/commit/39887b86297e36785607f57cfd0e785bcae3c61a",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/39887b86297e36785607f57cfd0e785bcae3c61a/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=39887b86297e36785607f57cfd0e785bcae3c61a",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -275,6 +275,8 @@ Bug Fixes\n \n * SOLR-10083: Fix instanceof check in ConstDoubleSource.equals (Pushkar Raste via Christine Poerschke)\n \n+* SOLR-10190: Fix NPE in CloudSolrClient when reading stale alias (Janosch Woschitz via Tom\u00e1s Fern\u00e1ndez L\u00f6bbe)\n+\n ==================  6.4.1 ==================\n \n Consult the LUCENE_CHANGES.txt file for additional, low level, changes in this release.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/39887b86297e36785607f57cfd0e785bcae3c61a/solr/CHANGES.txt",
                "sha": "2b0044c3f6e134f64d070adc07a619fa3d6d6c40",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/39887b86297e36785607f57cfd0e785bcae3c61a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java?ref=39887b86297e36785607f57cfd0e785bcae3c61a",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "patch": "@@ -1075,6 +1075,9 @@ public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<\n       for (String requestedCollection : requestedCollectionNames) {\n         // track the version of state we're using on the client side using the _stateVer_ param\n         DocCollection coll = getDocCollection(requestedCollection, null);\n+        if (coll == null) {\n+          throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection not found: \" + requestedCollection);\n+        }\n         int collVer = coll.getZNodeVersion();\n         if (coll.getStateFormat()>1) {\n           if(requestedCollections == null) requestedCollections = new ArrayList<>(requestedCollectionNames.size());",
                "raw_url": "https://github.com/apache/lucene-solr/raw/39887b86297e36785607f57cfd0e785bcae3c61a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "sha": "3147d4e50ef481abc2c7c17d02b6b0b42f53cad8",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/39887b86297e36785607f57cfd0e785bcae3c61a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java?ref=39887b86297e36785607f57cfd0e785bcae3c61a",
                "deletions": 0,
                "filename": "solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java",
                "patch": "@@ -146,6 +146,31 @@ public void testOverwriteOption() throws Exception {\n \n   }\n \n+  @Test\n+  public void testHandlingOfStaleAlias() throws Exception {\n+    try (CloudSolrClient client = getCloudSolrClient(cluster.getZkServer().getZkAddress())) {\n+      client.setDefaultCollection(\"misconfigured-alias\");\n+\n+      CollectionAdminRequest.createCollection(\"nemesis\", \"conf\", 2, 1).process(client);\n+      CollectionAdminRequest.createAlias(\"misconfigured-alias\", \"nemesis\").process(client);\n+      CollectionAdminRequest.deleteCollection(\"nemesis\").process(client);\n+\n+      List<SolrInputDocument> docs = new ArrayList<>();\n+\n+      SolrInputDocument doc = new SolrInputDocument();\n+      doc.addField(id, Integer.toString(1));\n+      docs.add(doc);\n+\n+      try {\n+        client.add(docs);\n+        fail(\"Alias points to non-existing collection, add should fail\");\n+      } catch (SolrException e) {\n+        assertEquals(SolrException.ErrorCode.BAD_REQUEST.code, e.code());\n+        assertTrue(\"Unexpected error exception\", e.getMessage().contains(\"Collection not found\"));\n+      }\n+    }\n+  }\n+\n   @Test\n   public void testRouting() throws Exception {\n     ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/39887b86297e36785607f57cfd0e785bcae3c61a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java",
                "sha": "cff5c239ef5f3eedf0845d49fccb255e3ad550d0",
                "status": "modified"
            }
        ],
        "message": "SOLR-10190: Fix NPE in CloudSolrClient when reading stale alias\n\nThis closes #160",
        "parent": "https://github.com/apache/lucene-solr/commit/30125f99daf38c4788a9763a89fddb3730c709af",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudSolrClientTest.java"
        ]
    },
    "lucene-solr_3ab1790": {
        "bug_id": "lucene-solr_3ab1790",
        "commit": "https://github.com/apache/lucene-solr/commit/3ab1790be74bbb6590038632d631c8b86de194c7",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3ab1790be74bbb6590038632d631c8b86de194c7/solr/CHANGES.txt",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=3ab1790be74bbb6590038632d631c8b86de194c7",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -81,6 +81,7 @@ New Features\n   - SOLR-4033: Consistently use the solrconfig.xml lockType everywhere.\n     (Mark Miller, Markus Jelsma)\n   - SOLR-4144: Replication using too much RAM. (yonik, Markus Jelsma)\n+  - SOLR-4187: NPE on Directory release (Mark Miller, Markus Jelsma)\n     \n * SOLR-1972: Add extra statistics to RequestHandlers - 5 & 15-minute reqs/sec\n   rolling averages; median, 75th, 95th, 99th, 99.9th percentile request times",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3ab1790be74bbb6590038632d631c8b86de194c7/solr/CHANGES.txt",
                "sha": "2a8a4b7da09bc8eb5b1ea74ca13f599d0d236135",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3ab1790be74bbb6590038632d631c8b86de194c7/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/SolrCore.java?ref=3ab1790be74bbb6590038632d631c8b86de194c7",
                "deletions": 5,
                "filename": "solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "patch": "@@ -258,11 +258,12 @@ public String getNewIndexDir() {\n     } catch (IOException e) {\n       SolrException.log(log, \"\", e);\n     } finally {\n-    \n-      try {\n-        getDirectoryFactory().release(dir);\n-      } catch (IOException e) {\n-        SolrException.log(log, \"\", e);\n+      if (dir != null) {\n+        try {\n+          getDirectoryFactory().release(dir);\n+        } catch (IOException e) {\n+          SolrException.log(log, \"\", e);\n+        }\n       }\n     }\n     if (!result.equals(lastNewIndexDir)) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3ab1790be74bbb6590038632d631c8b86de194c7/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "sha": "5cb0be38a15e40e3accbed6e39a1a19f6e3fda57",
                "status": "modified"
            }
        ],
        "message": "SOLR-4187: NPE on Directory release \n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1421914 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/96926cf07d27e0a7c1f5e08af96ec526b52c0696",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrCoreTest.java"
        ]
    },
    "lucene-solr_3b07e72": {
        "bug_id": "lucene-solr_3b07e72",
        "commit": "https://github.com/apache/lucene-solr/commit/3b07e7241ebc539c5acdc642f83e174e5bea9744",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=3b07e7241ebc539c5acdc642f83e174e5bea9744",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -443,6 +443,9 @@ Bug Fixes\n \n * SOLR-10763: Admin UI replication tab sometimes empty when failed replications (janhoy, Bojan Vitnik)\n \n+* SOLR-10824: fix NPE ExactSharedStatsCache, fixing maxdocs skew for terms which are absent at one of shards\n+when using one of Exact*StatsCache (Mikhail Khludnev)\n+\n Optimizations\n ----------------------\n * SOLR-10634: JSON Facet API: When a field/terms facet will retrieve all buckets (i.e. limit:-1)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/CHANGES.txt",
                "sha": "77edbe56f0859bca6a2b8bdb25769b1c6f82882b",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/java/org/apache/solr/search/stats/ExactSharedStatsCache.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/stats/ExactSharedStatsCache.java?ref=3b07e7241ebc539c5acdc642f83e174e5bea9744",
                "deletions": 6,
                "filename": "solr/core/src/java/org/apache/solr/search/stats/ExactSharedStatsCache.java",
                "patch": "@@ -16,17 +16,17 @@\n  */\n package org.apache.solr.search.stats;\n \n+import java.lang.invoke.MethodHandles;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n import org.apache.solr.core.PluginInfo;\n import org.apache.solr.handler.component.ResponseBuilder;\n import org.apache.solr.request.SolrQueryRequest;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.lang.invoke.MethodHandles;\n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.concurrent.ConcurrentHashMap;\n-\n \n public class ExactSharedStatsCache extends ExactStatsCache {\n   private static final Logger LOG = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n@@ -73,7 +73,7 @@ protected void addToPerShardTermStats(SolrQueryRequest req, String shard, String\n \n   protected TermStats getPerShardTermStats(SolrQueryRequest req, String t, String shard) {\n     Map<String,TermStats> cache = perShardTermStats.get(shard);\n-    return cache.get(t);\n+    return (cache != null) ? cache.get(t) : null; //Term doesn't exist in shard;\n   }\n \n   protected void addToGlobalColStats(SolrQueryRequest req,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/java/org/apache/solr/search/stats/ExactSharedStatsCache.java",
                "sha": "de4f7ec221faca48a0a252019ff01d415452cf36",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java?ref=3b07e7241ebc539c5acdc642f83e174e5bea9744",
                "deletions": 8,
                "filename": "solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "patch": "@@ -163,30 +163,33 @@ public void returnLocalStats(ResponseBuilder rb, SolrIndexSearcher searcher) {\n       for (Term t : terms) {\n         TermContext termContext = TermContext.build(context, t);\n \n+        if (!colMap.containsKey(t.field())) { // collection stats for this field\n+          colMap.put(t.field(), new CollectionStats(searcher.localCollectionStatistics(t.field())));\n+        }\n+\n         TermStatistics tst = searcher.localTermStatistics(t, termContext);\n         if (tst.docFreq() == 0) { // skip terms that are not present here\n           continue;\n         }\n \n         statsMap.put(t.toString(), new TermStats(t.field(), tst));\n         rb.rsp.add(TERMS_KEY, t.toString());\n-        if (!colMap.containsKey(t.field())) { // collection stats for this field\n-          colMap.put(t.field(), new CollectionStats(searcher.localCollectionStatistics(t.field())));\n-        }\n       }\n-      if (statsMap.size() != 0 && colMap.size() != 0) { //Don't add empty keys\n+      if (statsMap.size() != 0) { //Don't add empty keys\n         String termStatsString = StatsUtil.termStatsMapToString(statsMap);\n         rb.rsp.add(TERM_STATS_KEY, termStatsString);\n-\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"termStats=\" + termStatsString + \", terms=\" + terms + \", numDocs=\" + searcher.maxDoc());\n+        }\n+      }\n+      if (colMap.size() != 0){\n         String colStatsString = StatsUtil.colStatsMapToString(colMap);\n         rb.rsp.add(COL_STATS_KEY, colStatsString);\n-\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"termStats=\" + termStatsString + \", collectionStats=\"\n+          LOG.debug(\"collectionStats=\"\n               + colStatsString + \", terms=\" + terms + \", numDocs=\" + searcher.maxDoc());\n         }\n       }\n-\n     } catch (IOException e) {\n       LOG.error(\"Error collecting local stats, query='\" + q.toString() + \"'\", e);\n       throw new SolrException(ErrorCode.SERVER_ERROR, \"Error collecting local stats.\", e);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "sha": "413584dce199be686c39cc845a38e724eb007e76",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java?ref=3b07e7241ebc539c5acdc642f83e174e5bea9744",
                "deletions": 3,
                "filename": "solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java",
                "patch": "@@ -37,33 +37,44 @@ public void distribTearDown() throws Exception {\n     System.clearProperty(\"solr.statsCache\");\n   }\n \n-  @Test\n+  @Test \n   public void test() throws Exception {\n     del(\"*:*\");\n+    String aDocId=null;\n     for (int i = 0; i < clients.size(); i++) {\n       int shard = i + 1;\n       for (int j = 0; j <= i; j++) {\n-        index_specific(i, id, docId++, \"a_t\", \"one two three\",\n+        int currentId = docId++;\n+        index_specific(i, id,currentId , \"a_t\", \"one two three\",\n             \"shard_i\", shard);\n+        aDocId = rarely() ? currentId+\"\":aDocId;\n       }\n     }\n     commit();\n     handle.clear();\n     handle.put(\"QTime\", SKIPVAL);   \n     handle.put(\"timestamp\", SKIPVAL);\n     \n+    if (aDocId != null) {\n+      dfQuery(\"q\", \"id:\"+aDocId, \"debugQuery\", \"true\", \"fl\", \"*,score\");\n+    }\n     dfQuery(\"q\", \"a_t:one\", \"debugQuery\", \"true\", \"fl\", \"*,score\");\n     \n     // add another document\n     for (int i = 0; i < clients.size(); i++) {\n       int shard = i + 1;\n       for (int j = 0; j <= i; j++) {\n-        index_specific(i, id, docId++, \"a_t\", \"one two three four five\",\n+        int currentId = docId++;\n+        index_specific(i, id, currentId, \"a_t\", \"one two three four five\",\n             \"shard_i\", shard);\n+        aDocId = rarely() ? currentId+\"\":aDocId;\n       }\n     }\n     commit();\n \n+    if (aDocId != null) {\n+      dfQuery(\"q\", \"id:\"+aDocId,\"debugQuery\", \"true\", \"fl\", \"*,score\");\n+    }\n     dfQuery(\"q\", \"a_t:one a_t:four\", \"debugQuery\", \"true\", \"fl\", \"*,score\");\n   }\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3b07e7241ebc539c5acdc642f83e174e5bea9744/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java",
                "sha": "88300baa69b0b75e952f62ae21e03b1b13827f59",
                "status": "modified"
            }
        ],
        "message": "SOLR-10824: fixing NPE ExactSharedStatsCache, avoid maxdocs skew on\nunique terms.",
        "parent": "https://github.com/apache/lucene-solr/commit/e43253312f965ba838d80c2000dee761df1f25f5",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestExactSharedStatsCache.java",
            "TestExactStatsCache.java"
        ]
    },
    "lucene-solr_3ca4fea": {
        "bug_id": "lucene-solr_3ca4fea",
        "commit": "https://github.com/apache/lucene-solr/commit/3ca4fea5786430130f25d180440f765e96ac9c74",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=3ca4fea5786430130f25d180440f765e96ac9c74",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -42,6 +42,9 @@ Bug Fixes\n \n * LUCENE-6662: Fixed potential resource leaks. (Rishabh Patel via Adrien Grand)\n \n+* LUCENE-7340: MemoryIndex.toString() could throw NPE; fixed. Renamed to toStringDebug().\n+  (Daniel Collins, David Smiley)\n+\n Improvements\n \n * LUCENE-7323: Compound file writing now verifies the incoming",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/CHANGES.txt",
                "sha": "24d9f658606d473bad2b21e664c1d5e7d85cccb3",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java?ref=3ca4fea5786430130f25d180440f765e96ac9c74",
                "deletions": 4,
                "filename": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "patch": "@@ -43,10 +43,21 @@\n import org.apache.lucene.search.Sort;\n import org.apache.lucene.search.similarities.Similarity;\n import org.apache.lucene.store.RAMDirectory;\n-import org.apache.lucene.util.*;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.ByteBlockPool;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefArray;\n+import org.apache.lucene.util.BytesRefBuilder;\n+import org.apache.lucene.util.BytesRefHash;\n import org.apache.lucene.util.BytesRefHash.DirectBytesStartArray;\n+import org.apache.lucene.util.Counter;\n+import org.apache.lucene.util.IntBlockPool;\n import org.apache.lucene.util.IntBlockPool.SliceReader;\n import org.apache.lucene.util.IntBlockPool.SliceWriter;\n+import org.apache.lucene.util.RecyclingByteBlockAllocator;\n+import org.apache.lucene.util.RecyclingIntBlockAllocator;\n+import org.apache.lucene.util.StringHelper;\n \n /**\n  * High-performance single-document main memory Apache Lucene fulltext search index. \n@@ -746,13 +757,14 @@ public boolean needsScores() {\n    * Returns a String representation of the index data for debugging purposes.\n    * \n    * @return the string representation\n+   * @lucene.experimental\n    */\n-  @Override\n-  public String toString() {\n+  public String toStringDebug() {\n     StringBuilder result = new StringBuilder(256);\n     int sumPositions = 0;\n     int sumTerms = 0;\n     final BytesRef spare = new BytesRef();\n+    final BytesRefBuilder payloadBuilder = storePayloads ? new BytesRefBuilder() : null;\n     for (Map.Entry<String, Info> entry : fields.entrySet()) {\n       String fieldName = entry.getKey();\n       Info info = entry.getValue();\n@@ -778,9 +790,16 @@ public String toString() {\n               result.append(\", \");\n             }\n           }\n+          if (storePayloads) {\n+            int payloadIndex = postingsReader.readInt();\n+            if (payloadIndex != -1) {\n+                result.append(\", \" + payloadsBytesRefs.get(payloadBuilder, payloadIndex));\n+            }\n+          }\n           result.append(\")\");\n+\n           if (!postingsReader.endOfSlice()) {\n-            result.append(\",\");\n+            result.append(\", \");\n           }\n \n         }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "sha": "cdd53ed9e2f42b81a273c9a80c3cb795c9650faa",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java?ref=3ca4fea5786430130f25d180440f765e96ac9c74",
                "deletions": 0,
                "filename": "lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "patch": "@@ -464,4 +464,26 @@ public void testIndexingPointsAndDocValues() throws Exception {\n     assertEquals(\"term\", leafReader.getBinaryDocValues(\"field\").get(0).utf8ToString());\n   }\n \n+  public void testToStringDebug() {\n+    MemoryIndex mi = new MemoryIndex(true, true);\n+    Analyzer analyzer = new MockPayloadAnalyzer();\n+\n+    mi.addField(\"analyzedField\", \"aa bb aa\", analyzer);\n+\n+    FieldType type = new FieldType();\n+    type.setDimensions(1, 4);\n+    type.setDocValuesType(DocValuesType.BINARY);\n+    type.freeze();\n+    mi.addField(new BinaryPoint(\"pointAndDvField\", \"term\".getBytes(StandardCharsets.UTF_8), type), analyzer);\n+\n+    assertEquals(\"analyzedField:\\n\" +\n+        \"\\t'[61 61]':2: [(0, 0, 2, [70 6f 73 3a 20 30]), (1, 6, 8, [70 6f 73 3a 20 32])]\\n\" +\n+        \"\\t'[62 62]':1: [(1, 3, 5, [70 6f 73 3a 20 31])]\\n\" +\n+        \"\\tterms=2, positions=3\\n\" +\n+        \"pointAndDvField:\\n\" +\n+        \"\\tterms=0, positions=0\\n\" +\n+        \"\\n\" +\n+        \"fields=2, terms=2, positions=3\", mi.toStringDebug());\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3ca4fea5786430130f25d180440f765e96ac9c74/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "sha": "2f95a4e5cca3c2dbb49ab20c14073b720398eaae",
                "status": "modified"
            }
        ],
        "message": "LUCENE-7340: MemoryIndex.toString renamed to toStringDebug; fix NPE",
        "parent": "https://github.com/apache/lucene-solr/commit/503da1fcb9fa96c2ba62e9164ee38011b2e23669",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestMemoryIndex.java"
        ]
    },
    "lucene-solr_3eb663e": {
        "bug_id": "lucene-solr_3eb663e",
        "commit": "https://github.com/apache/lucene-solr/commit/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/contrib/dataimporthandler/CHANGES.txt?ref=3eb663ea10c259f9534a761cf2d0a8959ce1c7ec",
                "deletions": 0,
                "filename": "contrib/dataimporthandler/CHANGES.txt",
                "patch": "@@ -57,6 +57,8 @@ Bug Fixes\n \n * SOLR-1762: DateFormatTransformer does not work correctly with non-default locale dates (tommy chheng via noble)\n \n+* SOLR-1757: DIH multithreading sometimes throws NPE (noble)\n+\n Other Changes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/CHANGES.txt",
                "sha": "709dba9392b4d37d38ebfc33ccce28f36f7e1b68",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java?ref=3eb663ea10c259f9534a761cf2d0a8959ce1c7ec",
                "deletions": 3,
                "filename": "contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "patch": "@@ -345,11 +345,11 @@ EntityRunner createRunner(DataConfig.Entity entity, EntityRunner parent){\n     private DocWrapper docWrapper;\n     private volatile boolean entityInitialized ;\n     String currentProcess;\n-    ThreadLocal<ThreadedEntityProcessorWrapper> currentEntityProcWrapper = new ThreadLocal<ThreadedEntityProcessorWrapper>();\n+    final ThreadLocal<ThreadedEntityProcessorWrapper> currentEntityProcWrapper = new ThreadLocal<ThreadedEntityProcessorWrapper>();\n \n     private ContextImpl context;\n-    EntityRunner parent;\n-    AtomicBoolean entityEnded = new AtomicBoolean(false);\n+    final EntityRunner parent;\n+    final AtomicBoolean entityEnded = new AtomicBoolean(false);\n     private Exception exception;\n \n     public EntityRunner(DataConfig.Entity entity, EntityRunner parent) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "sha": "42423a21e78bf8c2cfd89f5500c9a5baab4feddf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/JdbcDataSource.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/JdbcDataSource.java?ref=3eb663ea10c259f9534a761cf2d0a8959ce1c7ec",
                "deletions": 2,
                "filename": "contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/JdbcDataSource.java",
                "patch": "@@ -126,8 +126,6 @@ else if (\"binary\".equals(t))\n \n     return factory = new Callable<Connection>() {\n       public Connection call() throws Exception {\n-        // Resolve variables again because the variables may have changed\n-        resolveVariables(context, initProps);\n         LOG.info(\"Creating a connection for entity \"\n                 + context.getEntityAttribute(DataImporter.NAME) + \" with URL: \"\n                 + url);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/JdbcDataSource.java",
                "sha": "cb38e480bf01493ad055696ede46beb18fee4410",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/ThreadedEntityProcessorWrapper.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/ThreadedEntityProcessorWrapper.java?ref=3eb663ea10c259f9534a761cf2d0a8959ce1c7ec",
                "deletions": 2,
                "filename": "contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/ThreadedEntityProcessorWrapper.java",
                "patch": "@@ -36,10 +36,10 @@\n public class ThreadedEntityProcessorWrapper extends EntityProcessorWrapper {\n   private static final Logger LOG = LoggerFactory.getLogger(ThreadedEntityProcessorWrapper.class);\n \n-  DocBuilder.EntityRunner entityRunner;\n+  final DocBuilder.EntityRunner entityRunner;\n   /**For each child entity there is one EntityRunner\n    */\n-  Map<DataConfig.Entity ,DocBuilder.EntityRunner> children;\n+  final Map<DataConfig.Entity ,DocBuilder.EntityRunner> children;\n \n   public ThreadedEntityProcessorWrapper(EntityProcessor delegate, DocBuilder docBuilder,\n                                   DocBuilder.EntityRunner entityRunner,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/3eb663ea10c259f9534a761cf2d0a8959ce1c7ec/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/ThreadedEntityProcessorWrapper.java",
                "sha": "692be738163a741e241284ea1977bd56e4c8b019",
                "status": "modified"
            }
        ],
        "message": " SOLR-1757: DIH multithreading sometimes throws NPE.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@907935 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/1dd48e2a78d4d9323a283a6eb1f2520b4d2b6528",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestDocBuilder.java",
            "TestJdbcDataSource.java"
        ]
    },
    "lucene-solr_407080a": {
        "bug_id": "lucene-solr_407080a",
        "commit": "https://github.com/apache/lucene-solr/commit/407080af5bc68c9eb11c05c587368a783ff78d0c",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/407080af5bc68c9eb11c05c587368a783ff78d0c/solr/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=407080af5bc68c9eb11c05c587368a783ff78d0c",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -86,6 +86,10 @@ Bug Fixes\n \n * SOLR-8626: 404 error when clicking nodes in cloud graph view in angular UI. (janhoy, Trey Grainger via shalin)\n \n+* SOLR-9254: GraphTermsQueryQParserPlugin throws NPE when field being search is not present in segment\n+  (Joel Bernstein)\n+\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/407080af5bc68c9eb11c05c587368a783ff78d0c/solr/CHANGES.txt",
                "sha": "7fc6f560309914d5a3a5639f95df8aed9fe0b080",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/407080af5bc68c9eb11c05c587368a783ff78d0c/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java?ref=407080af5bc68c9eb11c05c587368a783ff78d0c",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java",
                "patch": "@@ -40,9 +40,11 @@\n import org.apache.lucene.search.Scorer;\n import org.apache.lucene.search.Weight;\n import org.apache.lucene.util.ArrayUtil;\n+import org.apache.lucene.util.BitDocIdSet;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.BytesRefBuilder;\n import org.apache.lucene.util.DocIdSetBuilder;\n+import org.apache.lucene.util.FixedBitSet;\n import org.apache.solr.common.params.SolrParams;\n import org.apache.solr.request.SolrQueryRequest;\n import org.apache.solr.schema.FieldType;\n@@ -220,6 +222,9 @@ private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n           final LeafReader reader = context.reader();\n           final Fields fields = reader.fields();\n           Terms terms = fields.terms(field);\n+          if(terms == null) {\n+            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n+          }\n           TermsEnum  termsEnum = terms.iterator();\n           PostingsEnum docs = null;\n           DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/407080af5bc68c9eb11c05c587368a783ff78d0c/solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.java",
                "sha": "dfe411a95689c428617767f0fe5338f8faae2523",
                "status": "modified"
            }
        ],
        "message": "SOLR-9254: GraphTermsQueryQParserPlugin throws NPE when field being search is not present in segment",
        "parent": "https://github.com/apache/lucene-solr/commit/ab2348e3efc4cbc9d2d5c1653bfad5e22a5edf74",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestGraphTermsQParserPlugin.java"
        ]
    },
    "lucene-solr_423e469": {
        "bug_id": "lucene-solr_423e469",
        "commit": "https://github.com/apache/lucene-solr/commit/423e469e5f73d04cf757b888dac127a7ae14b054",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/423e469e5f73d04cf757b888dac127a7ae14b054/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=423e469e5f73d04cf757b888dac127a7ae14b054",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -435,6 +435,8 @@ Bug Fixes\n * SOLR-6923: AutoAddReplicas also consults live_nodes to see if a state change has happened.\n   (Varun Thacker via Anshum Gupta)\n \n+* SOLR-6941: DistributedQueue#containsTaskWithRequestId can fail with NPE. (Mark Miller)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/423e469e5f73d04cf757b888dac127a7ae14b054/solr/CHANGES.txt",
                "sha": "2bfc3e29a8c5bcc063492ffe17cfae26f45d1ba3",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/423e469e5f73d04cf757b888dac127a7ae14b054/solr/core/src/java/org/apache/solr/cloud/DistributedQueue.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/DistributedQueue.java?ref=423e469e5f73d04cf757b888dac127a7ae14b054",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/cloud/DistributedQueue.java",
                "patch": "@@ -122,10 +122,13 @@ public boolean containsTaskWithRequestId(String requestId)\n     for (String childName : childNames) {\n       if (childName != null) {\n         try {\n-          ZkNodeProps message = ZkNodeProps.load(zookeeper.getData(dir + \"/\" + childName, null, null, true));\n-          if (message.containsKey(OverseerCollectionProcessor.ASYNC)) {\n-            LOG.info(\">>>> {}\", message.get(OverseerCollectionProcessor.ASYNC));\n-            if(message.get(OverseerCollectionProcessor.ASYNC).equals(requestId)) return true;\n+          byte[] data = zookeeper.getData(dir + \"/\" + childName, null, null, true);\n+          if (data != null) {\n+            ZkNodeProps message = ZkNodeProps.load(data);\n+            if (message.containsKey(OverseerCollectionProcessor.ASYNC)) {\n+              LOG.debug(\">>>> {}\", message.get(OverseerCollectionProcessor.ASYNC));\n+              if(message.get(OverseerCollectionProcessor.ASYNC).equals(requestId)) return true;\n+            }\n           }\n         } catch (KeeperException.NoNodeException e) {\n           // Another client removed the node first, try next",
                "raw_url": "https://github.com/apache/lucene-solr/raw/423e469e5f73d04cf757b888dac127a7ae14b054/solr/core/src/java/org/apache/solr/cloud/DistributedQueue.java",
                "sha": "99d7769bd678b040e0da382979db04719581d038",
                "status": "modified"
            }
        ],
        "message": "SOLR-6941: DistributedQueue#containsTaskWithRequestId can fail with NPE.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1651380 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/1696206de684a6699938ea3d2458e3fa9658f292",
        "repo": "lucene-solr",
        "unit_tests": [
            "DistributedQueueTest.java"
        ]
    },
    "lucene-solr_46cee7f": {
        "bug_id": "lucene-solr_46cee7f",
        "commit": "https://github.com/apache/lucene-solr/commit/46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1",
        "file": [
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java?ref=46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1",
                "deletions": 9,
                "filename": "src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "patch": "@@ -82,6 +82,8 @@\n  * <td>No</td>\n  * </tr>\n  * </table>\n+ * <p>Note that if neither analysis.fieldname and analysis.fieldtype is specified, then the default search field's\n+ * analyzer is used.</p>\n  *\n  * @version $Id$\n  * @since solr 1.4 \n@@ -92,7 +94,7 @@\n    * {@inheritDoc}\n    */\n   protected NamedList doAnalysis(SolrQueryRequest req) throws Exception {\n-    FieldAnalysisRequest analysisRequest = resolveAnalysisRequest(req.getParams());\n+    FieldAnalysisRequest analysisRequest = resolveAnalysisRequest(req);\n     IndexSchema indexSchema = req.getCore().getSchema();\n     return handleAnalysisRequest(analysisRequest, indexSchema);\n   }\n@@ -122,19 +124,26 @@ public String getSource() {\n   /**\n    * Resolves the AnalysisRequest based on the parameters in the given SolrParams.\n    *\n-   * @param solrParams SolrParams taken from request\n+   * @param req the request\n    *\n    * @return AnalysisRequest containing all the information about what needs to be analyzed, and using what\n    *         fields/types\n    */\n-  FieldAnalysisRequest resolveAnalysisRequest(SolrParams solrParams) {\n+  FieldAnalysisRequest resolveAnalysisRequest(SolrQueryRequest req) {\n+    SolrParams solrParams = req.getParams();\n     FieldAnalysisRequest analysisRequest = new FieldAnalysisRequest();\n \n+    boolean useDefaultSearchField = true;\n     if (solrParams.get(AnalysisParams.FIELD_TYPE) != null) {\n       analysisRequest.setFieldTypes(Arrays.asList(solrParams.get(AnalysisParams.FIELD_TYPE).split(\",\")));\n+      useDefaultSearchField = false;\n     }\n     if (solrParams.get(AnalysisParams.FIELD_NAME) != null) {\n       analysisRequest.setFieldNames(Arrays.asList(solrParams.get(AnalysisParams.FIELD_NAME).split(\",\")));\n+      useDefaultSearchField = false;\n+    }\n+    if (useDefaultSearchField)  {\n+      analysisRequest.addFieldName(req.getSchema().getSolrQueryParser(null).getField());\n     }\n     analysisRequest.setQuery(solrParams.get(AnalysisParams.QUERY, solrParams.get(CommonParams.Q)));\n     analysisRequest.setFieldValue(solrParams.get(AnalysisParams.FIELD_VALUE));\n@@ -154,15 +163,19 @@ FieldAnalysisRequest resolveAnalysisRequest(SolrParams solrParams) {\n     NamedList<NamedList> analysisResults = new SimpleOrderedMap<NamedList>();\n \n     NamedList<NamedList> fieldTypeAnalysisResults = new SimpleOrderedMap<NamedList>();\n-    for (String fieldTypeName : request.getFieldTypes()) {\n-      FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n-      fieldTypeAnalysisResults.add(fieldTypeName, analyzeValues(request, fieldType, null));\n+    if (request.getFieldTypes() != null)  {\n+      for (String fieldTypeName : request.getFieldTypes()) {\n+        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n+        fieldTypeAnalysisResults.add(fieldTypeName, analyzeValues(request, fieldType, null));\n+      }\n     }\n \n     NamedList<NamedList> fieldNameAnalysisResults = new SimpleOrderedMap<NamedList>();\n-    for (String fieldName : request.getFieldNames()) {\n-      FieldType fieldType = schema.getFieldType(fieldName);\n-      fieldNameAnalysisResults.add(fieldName, analyzeValues(request, fieldType, fieldName));\n+    if (request.getFieldNames() != null)  {\n+      for (String fieldName : request.getFieldNames()) {\n+        FieldType fieldType = schema.getFieldType(fieldName);\n+        fieldNameAnalysisResults.add(fieldName, analyzeValues(request, fieldType, fieldName));\n+      }\n     }\n \n     analysisResults.add(\"field_types\", fieldTypeAnalysisResults);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "sha": "a5e31b14a96e4bbe782e63db944e2b714e22da8a",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java?ref=46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1",
                "deletions": 6,
                "filename": "src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "patch": "@@ -24,6 +24,7 @@\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.client.solrj.request.FieldAnalysisRequest;\n+import org.apache.solr.request.LocalSolrQueryRequest;\n \n import java.util.List;\n \n@@ -54,7 +55,7 @@ public String getSolrConfigFile() {\n   }\n \n   /**\n-   * Tests the {@link FieldAnalysisRequestHandler#resolveAnalysisRequest(org.apache.solr.common.params.SolrParams)}\n+   * Tests the {@link FieldAnalysisRequestHandler#resolveAnalysisRequest(org.apache.solr.request.SolrQueryRequest)}\n    */\n   public void testResolveAnalysisRequest() throws Exception {\n     ModifiableSolrParams params = new ModifiableSolrParams();\n@@ -63,7 +64,7 @@ public void testResolveAnalysisRequest() throws Exception {\n     params.add(AnalysisParams.FIELD_VALUE, \"the quick red fox jumped over the lazy brown dogs\");\n     params.add(CommonParams.Q, \"fox brown\");\n \n-    FieldAnalysisRequest request = handler.resolveAnalysisRequest(params);\n+    FieldAnalysisRequest request = handler.resolveAnalysisRequest(new LocalSolrQueryRequest(h.getCore(), params));\n     List<String> fieldNames = request.getFieldNames();\n     assertEquals(\"Expecting 2 field names\", 2, fieldNames.size());\n     assertEquals(\"text\", fieldNames.get(0));\n@@ -78,21 +79,21 @@ public void testResolveAnalysisRequest() throws Exception {\n \n     // testing overide of query value using analysis.query param\n     params.add(AnalysisParams.QUERY, \"quick lazy\");\n-    request = handler.resolveAnalysisRequest(params);\n+    request = handler.resolveAnalysisRequest(new LocalSolrQueryRequest(h.getCore(), params));\n     assertEquals(\"quick lazy\", request.getQuery());\n \n     // testing analysis.showmatch param\n     params.add(AnalysisParams.SHOW_MATCH, \"false\");\n-    request = handler.resolveAnalysisRequest(params);\n+    request = handler.resolveAnalysisRequest(new LocalSolrQueryRequest(h.getCore(), params));\n     assertFalse(request.isShowMatch());\n     params.set(AnalysisParams.SHOW_MATCH, \"true\");\n-    request = handler.resolveAnalysisRequest(params);\n+    request = handler.resolveAnalysisRequest(new LocalSolrQueryRequest(h.getCore(), params));\n     assertTrue(request.isShowMatch());\n \n     // testing absence of query value\n     params.remove(CommonParams.Q);\n     params.remove(AnalysisParams.QUERY);\n-    request = handler.resolveAnalysisRequest(params);\n+    request = handler.resolveAnalysisRequest(new LocalSolrQueryRequest(h.getCore(), params));\n     assertNull(request.getQuery());\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/46cee7fa27d2b0ab7d9b4b5a7137978dcef863d1/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "sha": "056233f10d2d1245cf77736df2d888dc4db636b6",
                "status": "modified"
            }
        ],
        "message": "SOLR-1099 follow up -- Fix NPE in FieldAnalysisRequestHandler\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@771099 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/99a48e56045b7e10cfc353b3caee8fd221a874d6",
        "repo": "lucene-solr",
        "unit_tests": [
            "FieldAnalysisRequestHandlerTest.java"
        ]
    },
    "lucene-solr_4b83947": {
        "bug_id": "lucene-solr_4b83947",
        "commit": "https://github.com/apache/lucene-solr/commit/4b83947e1c19b51537d1cf601e9f4defbac214e0",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -272,6 +272,9 @@ Bug Fixes\n \n * SOLR-6357: Allow delete documents by doing a score join query. (Mikhail Khludnev, Timothy Potter)\n \n+* SOLR-7756: ExactStatsCache and LRUStatsCache will throw an NPE when a term is not present on a shard.\n+  (Varun Thacker, Anshum Gupta)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/CHANGES.txt",
                "sha": "848ea5c7968206ef6ee27b3f1f1b3b267fd26d7e",
                "status": "modified"
            },
            {
                "additions": 51,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "changes": 110,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 59,
                "filename": "solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "patch": "@@ -53,9 +53,8 @@\n  * query terms (and collection statistics for term fields).\n  */\n public class ExactStatsCache extends StatsCache {\n-  private static final Logger LOG = LoggerFactory\n-      .getLogger(ExactStatsCache.class);\n-  \n+  private static final Logger LOG = LoggerFactory.getLogger(ExactStatsCache.class);\n+\n   // experimenting with strategy that takes more RAM, but also doesn't share memory\n   // across threads\n   private static final String CURRENT_GLOBAL_COL_STATS = \"org.apache.solr.stats.currentGlobalColStats\";\n@@ -68,18 +67,18 @@ public StatsSource get(SolrQueryRequest req) {\n     Map<String,CollectionStats> currentGlobalColStats = (Map<String,CollectionStats>) req.getContext().get(CURRENT_GLOBAL_COL_STATS);\n     Map<String,TermStats> currentGlobalTermStats = (Map<String,TermStats>) req.getContext().get(CURRENT_GLOBAL_TERM_STATS);\n     if (currentGlobalColStats == null) {\n-     currentGlobalColStats = Collections.emptyMap(); \n+     currentGlobalColStats = Collections.emptyMap();\n     }\n     if (currentGlobalTermStats == null) {\n       currentGlobalTermStats = Collections.emptyMap();\n     }\n     LOG.debug(\"Returning StatsSource. Collection stats={}, Term stats size= {}\", currentGlobalColStats, currentGlobalTermStats.size());\n     return new ExactStatsSource(currentGlobalTermStats, currentGlobalColStats);\n   }\n-  \n+\n   @Override\n   public void init(PluginInfo info) {}\n-  \n+\n   @Override\n   public ShardRequest retrieveStatsRequest(ResponseBuilder rb) {\n     ShardRequest sreq = new ShardRequest();\n@@ -89,43 +88,38 @@ public ShardRequest retrieveStatsRequest(ResponseBuilder rb) {\n     sreq.params.remove(ShardParams.SHARDS);\n     return sreq;\n   }\n-  \n+\n   @Override\n-  public void mergeToGlobalStats(SolrQueryRequest req,\n-      List<ShardResponse> responses) {\n+  public void mergeToGlobalStats(SolrQueryRequest req, List<ShardResponse> responses) {\n     for (ShardResponse r : responses) {\n       LOG.debug(\"Merging to global stats, shard={}, response={}\", r.getShard(), r.getSolrResponse().getResponse());\n       String shard = r.getShard();\n       SolrResponse res = r.getSolrResponse();\n       NamedList<Object> nl = res.getResponse();\n-      \n+\n       // TODO: nl == null if not all shards respond (no server hosting shard)\n       String termStatsString = (String) nl.get(TERM_STATS_KEY);\n-      \n       if (termStatsString != null) {\n         addToPerShardTermStats(req, shard, termStatsString);\n       }\n       List<Object> terms = nl.getAll(TERMS_KEY);\n       if (terms != null) {\n         req.getContext().put(TERMS_KEY, terms);\n       }\n+\n       String colStatsString = (String) nl.get(COL_STATS_KEY);\n-      if (colStatsString != null) {\n-        Map<String,CollectionStats> colStats = StatsUtil\n-            .colStatsMapFromString(colStatsString);\n-        if (colStats != null) {\n-          addToPerShardColStats(req, shard, colStats);\n-        }\n+      Map<String,CollectionStats> colStats = StatsUtil.colStatsMapFromString(colStatsString);\n+      if (colStats != null) {\n+        addToPerShardColStats(req, shard, colStats);\n       }\n     }\n     if (LOG.isDebugEnabled()) printStats(req);\n   }\n \n-  protected void addToPerShardColStats(SolrQueryRequest req, String shard,\n-      Map<String,CollectionStats> colStats) {\n+  protected void addToPerShardColStats(SolrQueryRequest req, String shard, Map<String,CollectionStats> colStats) {\n     Map<String,Map<String,CollectionStats>> perShardColStats = (Map<String,Map<String,CollectionStats>>) req.getContext().get(PER_SHARD_COL_STATS);\n     if (perShardColStats == null) {\n-      perShardColStats = new HashMap<String,Map<String,CollectionStats>>();\n+      perShardColStats = new HashMap<>();\n       req.getContext().put(PER_SHARD_COL_STATS, perShardColStats);\n     }\n     perShardColStats.put(shard, colStats);\n@@ -144,72 +138,72 @@ protected void printStats(SolrQueryRequest req) {\n   }\n \n   protected void addToPerShardTermStats(SolrQueryRequest req, String shard, String termStatsString) {\n-    Map<String,TermStats> termStats = StatsUtil\n-        .termStatsMapFromString(termStatsString);\n+    Map<String,TermStats> termStats = StatsUtil.termStatsMapFromString(termStatsString);\n     if (termStats != null) {\n       Map<String,Map<String,TermStats>> perShardTermStats = (Map<String,Map<String,TermStats>>) req.getContext().get(PER_SHARD_TERM_STATS);\n       if (perShardTermStats == null) {\n-        perShardTermStats = new HashMap<String,Map<String,TermStats>>();\n+        perShardTermStats = new HashMap<>();\n         req.getContext().put(PER_SHARD_TERM_STATS, perShardTermStats);\n       }\n       perShardTermStats.put(shard, termStats);\n     }\n   }\n-  \n+\n   @Override\n   public void returnLocalStats(ResponseBuilder rb, SolrIndexSearcher searcher) {\n     Query q = rb.getQuery();\n     try {\n-      HashSet<Term> terms = new HashSet<Term>();\n+      HashSet<Term> terms = new HashSet<>();\n       searcher.createNormalizedWeight(q, true).extractTerms(terms);\n       IndexReaderContext context = searcher.getTopReaderContext();\n-      HashMap<String,TermStats> statsMap = new HashMap<String,TermStats>();\n-      HashMap<String,CollectionStats> colMap = new HashMap<String,CollectionStats>();\n+      HashMap<String,TermStats> statsMap = new HashMap<>();\n+      HashMap<String,CollectionStats> colMap = new HashMap<>();\n       for (Term t : terms) {\n         TermContext termContext = TermContext.build(context, t);\n-        \n+\n         TermStatistics tst = searcher.localTermStatistics(t, termContext);\n         if (tst.docFreq() == 0) { // skip terms that are not present here\n           continue;\n         }\n-        \n+\n         statsMap.put(t.toString(), new TermStats(t.field(), tst));\n         rb.rsp.add(TERMS_KEY, t.toString());\n         if (!colMap.containsKey(t.field())) { // collection stats for this field\n-          colMap.put(\n-              t.field(),\n-              new CollectionStats(searcher.localCollectionStatistics(t.field())));\n+          colMap.put(t.field(), new CollectionStats(searcher.localCollectionStatistics(t.field())));\n         }\n       }\n-      \n-      String termStatsString = StatsUtil.termStatsMapToString(statsMap);\n-      rb.rsp.add(TERM_STATS_KEY, termStatsString);\n-      String colStatsString = StatsUtil.colStatsMapToString(colMap);\n-      rb.rsp.add(COL_STATS_KEY, colStatsString);\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"termStats=\" + termStatsString + \", collectionStats=\"\n-            + colStatsString + \", terms=\" + terms + \", numDocs=\"\n-            + searcher.maxDoc());\n+      if (statsMap.size() != 0 && colMap.size() != 0) { //Don't add empty keys\n+        String termStatsString = StatsUtil.termStatsMapToString(statsMap);\n+        rb.rsp.add(TERM_STATS_KEY, termStatsString);\n+\n+        String colStatsString = StatsUtil.colStatsMapToString(colMap);\n+        rb.rsp.add(COL_STATS_KEY, colStatsString);\n+\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"termStats=\" + termStatsString + \", collectionStats=\"\n+              + colStatsString + \", terms=\" + terms + \", numDocs=\" + searcher.maxDoc());\n+        }\n       }\n+\n     } catch (IOException e) {\n       LOG.error(\"Error collecting local stats, query='\" + q.toString() + \"'\", e);\n       throw new SolrException(ErrorCode.SERVER_ERROR, \"Error collecting local stats.\", e);\n     }\n   }\n-  \n+\n   @Override\n   public void sendGlobalStats(ResponseBuilder rb, ShardRequest outgoing) {\n     outgoing.purpose |= ShardRequest.PURPOSE_SET_TERM_STATS;\n     ModifiableSolrParams params = outgoing.params;\n     List<String> terms = (List<String>) rb.req.getContext().get(TERMS_KEY);\n     if (terms != null) {\n-      Set<String> fields = new HashSet<String>();\n+      Set<String> fields = new HashSet<>();\n       for (String t : terms) {\n         String[] fv = t.split(\":\");\n         fields.add(fv[0]);\n       }\n-      Map<String,TermStats> globalTermStats = new HashMap<String,TermStats>();\n-      Map<String,CollectionStats> globalColStats = new HashMap<String,CollectionStats>();\n+      Map<String,TermStats> globalTermStats = new HashMap<>();\n+      Map<String,CollectionStats> globalColStats = new HashMap<>();\n       // aggregate collection stats, only for the field in terms\n \n       for (String shard : rb.shards) {\n@@ -266,16 +260,15 @@ protected TermStats getPerShardTermStats(SolrQueryRequest req, String t, String\n       perShardTermStats = Collections.emptyMap();\n     }\n     Map<String,TermStats> cache = perShardTermStats.get(shard);\n-    return cache.get(t);\n+    return (cache != null) ? cache.get(t) : null; //Term doesn't exist in shard\n   }\n-  \n+\n   @Override\n   public void receiveGlobalStats(SolrQueryRequest req) {\n     String globalTermStats = req.getParams().get(TERM_STATS_KEY);\n     String globalColStats = req.getParams().get(COL_STATS_KEY);\n     if (globalColStats != null) {\n-      Map<String,CollectionStats> colStats = StatsUtil\n-          .colStatsMapFromString(globalColStats);\n+      Map<String,CollectionStats> colStats = StatsUtil.colStatsMapFromString(globalColStats);\n       if (colStats != null) {\n         for (Entry<String,CollectionStats> e : colStats.entrySet()) {\n           addToGlobalColStats(req, e);\n@@ -284,8 +277,7 @@ public void receiveGlobalStats(SolrQueryRequest req) {\n     }\n     LOG.debug(\"Global collection stats={}\", globalColStats);\n     if (globalTermStats == null) return;\n-    Map<String,TermStats> termStats = StatsUtil\n-        .termStatsMapFromString(globalTermStats);\n+    Map<String,TermStats> termStats = StatsUtil.termStatsMapFromString(globalTermStats);\n     if (termStats != null) {\n       for (Entry<String,TermStats> e : termStats.entrySet()) {\n         addToGlobalTermStats(req, e);\n@@ -294,10 +286,10 @@ public void receiveGlobalStats(SolrQueryRequest req) {\n   }\n \n   protected void addToGlobalColStats(SolrQueryRequest req,\n-      Entry<String,CollectionStats> e) {\n+                                     Entry<String,CollectionStats> e) {\n     Map<String,CollectionStats> currentGlobalColStats = (Map<String,CollectionStats>) req.getContext().get(CURRENT_GLOBAL_COL_STATS);\n     if (currentGlobalColStats == null) {\n-      currentGlobalColStats = new HashMap<String,CollectionStats>();\n+      currentGlobalColStats = new HashMap<>();\n       req.getContext().put(CURRENT_GLOBAL_COL_STATS, currentGlobalColStats);\n     }\n     currentGlobalColStats.put(e.getKey(), e.getValue());\n@@ -306,22 +298,22 @@ protected void addToGlobalColStats(SolrQueryRequest req,\n   protected void addToGlobalTermStats(SolrQueryRequest req, Entry<String,TermStats> e) {\n     Map<String,TermStats> currentGlobalTermStats = (Map<String,TermStats>) req.getContext().get(CURRENT_GLOBAL_TERM_STATS);\n     if (currentGlobalTermStats == null) {\n-      currentGlobalTermStats = new HashMap<String,TermStats>();\n+      currentGlobalTermStats = new HashMap<>();\n       req.getContext().put(CURRENT_GLOBAL_TERM_STATS, currentGlobalTermStats);\n     }\n     currentGlobalTermStats.put(e.getKey(), e.getValue());\n   }\n-  \n+\n   protected static class ExactStatsSource extends StatsSource {\n     private final Map<String,TermStats> termStatsCache;\n     private final Map<String,CollectionStats> colStatsCache;\n-    \n+\n     public ExactStatsSource(Map<String,TermStats> termStatsCache,\n-        Map<String,CollectionStats> colStatsCache) {\n+                            Map<String,CollectionStats> colStatsCache) {\n       this.termStatsCache = termStatsCache;\n       this.colStatsCache = colStatsCache;\n     }\n-    \n+\n     public TermStatistics termStatistics(SolrIndexSearcher localSearcher, Term term, TermContext context)\n         throws IOException {\n       TermStats termStats = termStatsCache.get(term.toString());\n@@ -335,7 +327,7 @@ public TermStatistics termStatistics(SolrIndexSearcher localSearcher, Term term,\n         return termStats.toTermStatistics();\n       }\n     }\n-    \n+\n     @Override\n     public CollectionStatistics collectionStatistics(SolrIndexSearcher localSearcher, String field)\n         throws IOException {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/ExactStatsCache.java",
                "sha": "84bfd2cccc3c97351ac0458b29fc0bfa6be99cce",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/LRUStatsCache.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/stats/LRUStatsCache.java?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 13,
                "filename": "solr/core/src/java/org/apache/solr/search/stats/LRUStatsCache.java",
                "patch": "@@ -54,8 +54,7 @@\n  * that is updated with the global statistics on every request.\n  */\n public class LRUStatsCache extends ExactStatsCache {\n-  private static final Logger LOG = LoggerFactory\n-      .getLogger(LRUStatsCache.class);\n+  private static final Logger LOG = LoggerFactory.getLogger(LRUStatsCache.class);\n   \n   // local stats obtained from shard servers\n   private final Map<String,SolrCache<String,TermStats>> perShardTermStats = new ConcurrentHashMap<>();\n@@ -88,21 +87,18 @@ protected void addToGlobalTermStats(SolrQueryRequest req, Entry<String,TermStats\n   }\n   \n   @Override\n-  protected void addToPerShardColStats(SolrQueryRequest req, String shard,\n-      Map<String,CollectionStats> colStats) {\n+  protected void addToPerShardColStats(SolrQueryRequest req, String shard, Map<String,CollectionStats> colStats) {\n     perShardColStats.put(shard, colStats);\n   }\n   \n   @Override\n-  protected Map<String,CollectionStats> getPerShardColStats(ResponseBuilder rb,\n-      String shard) {\n+  protected Map<String,CollectionStats> getPerShardColStats(ResponseBuilder rb, String shard) {\n     return perShardColStats.get(shard);\n   }\n   \n   @Override\n   protected void addToPerShardTermStats(SolrQueryRequest req, String shard, String termStatsString) {\n-    Map<String,TermStats> termStats = StatsUtil\n-        .termStatsMapFromString(termStatsString);\n+    Map<String,TermStats> termStats = StatsUtil.termStatsMapFromString(termStatsString);\n     if (termStats != null) {\n       SolrCache<String,TermStats> cache = perShardTermStats.get(shard);\n       if (cache == null) { // initialize\n@@ -119,12 +115,11 @@ protected void addToPerShardTermStats(SolrQueryRequest req, String shard, String\n   @Override\n   protected TermStats getPerShardTermStats(SolrQueryRequest req, String t, String shard) {\n     SolrCache<String,TermStats> cache = perShardTermStats.get(shard);\n-    return cache.get(t);\n+    return (cache != null) ? cache.get(t) : null; //Term doesn't exist in shard\n   }\n   \n   @Override\n-  protected void addToGlobalColStats(SolrQueryRequest req,\n-      Entry<String,CollectionStats> e) {\n+  protected void addToGlobalColStats(SolrQueryRequest req, Entry<String,CollectionStats> e) {\n     currentGlobalColStats.put(e.getKey(), e.getValue());\n   }\n \n@@ -137,8 +132,7 @@ protected void printStats(SolrQueryRequest req) {\n     private final SolrCache<String,TermStats> termStatsCache;\n     private final Map<String,CollectionStats> colStatsCache;\n     \n-    public LRUStatsSource(SolrCache<String,TermStats> termStatsCache,\n-        Map<String,CollectionStats> colStatsCache) {\n+    public LRUStatsSource(SolrCache<String,TermStats> termStatsCache, Map<String,CollectionStats> colStatsCache) {\n       this.termStatsCache = termStatsCache;\n       this.colStatsCache = colStatsCache;\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/LRUStatsCache.java",
                "sha": "631b4137594ee8c9586bb897fc53719cc6281482",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/StatsUtil.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/stats/StatsUtil.java?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/stats/StatsUtil.java",
                "patch": "@@ -195,7 +195,7 @@ public static String colStatsMapToString(Map<String,CollectionStats> stats) {\n     if (data == null || data.trim().length() == 0) {\n       return null;\n     }\n-    Map<String,TermStats> map = new HashMap<String,TermStats>();\n+    Map<String,TermStats> map = new HashMap<>();\n     String[] entries = data.split(\"!\");\n     for (String es : entries) {\n       TermStats termStats = termStatsFromString(es, null);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/java/org/apache/solr/search/stats/StatsUtil.java",
                "sha": "f543c0a2745521d0e5332d2f8041359d8a19b05b",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/test-files/solr/configsets/configset-2/conf/schema.xml",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/configsets/configset-2/conf/schema.xml?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/configsets/configset-2/conf/schema.xml",
                "patch": "@@ -18,8 +18,12 @@\n <schema name=\"minimal\" version=\"1.1\">\n  <types>\n   <fieldType name=\"string\" class=\"solr.StrField\"/>\n+  <fieldType name=\"int\" class=\"solr.TrieIntField\" precisionStep=\"0\" omitNorms=\"true\" positionIncrementGap=\"0\"/>\n  </types>\n  <fields>\n+   <field name=\"id\" type=\"int\" indexed=\"true\" stored=\"true\" multiValued=\"false\" required=\"false\"/>\n+   <field name=\"_root_\" type=\"int\" indexed=\"true\" stored=\"true\" multiValued=\"false\" required=\"false\"/>\n    <dynamicField name=\"*\" type=\"string\" indexed=\"true\" stored=\"true\" />\n  </fields>\n+ <uniqueKey>id</uniqueKey>\n </schema>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/test-files/solr/configsets/configset-2/conf/schema.xml",
                "sha": "78172ef4f10bb56a0ee32e6f1c3d50299ea34168",
                "status": "modified"
            },
            {
                "additions": 213,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java",
                "changes": 213,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java?ref=4b83947e1c19b51537d1cf601e9f4defbac214e0",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java",
                "patch": "@@ -0,0 +1,213 @@\n+package org.apache.solr.search.stats;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import java.io.File;\n+import java.io.IOException;\n+\n+import org.apache.lucene.util.TestUtil;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrClient;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.embedded.JettySolrRunner;\n+import org.apache.solr.client.solrj.impl.HttpSolrClient;\n+import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n+import org.apache.solr.client.solrj.response.CollectionAdminResponse;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.cloud.AbstractDistribZkTestBase;\n+import org.apache.solr.cloud.MiniSolrCloudCluster;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.apache.solr.common.cloud.CompositeIdRouter;\n+import org.apache.solr.common.cloud.ImplicitDocRouter;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.common.params.ShardParams;\n+import org.junit.Test;\n+\n+public class TestDistribIDF extends SolrTestCaseJ4 {\n+\n+  private MiniSolrCloudCluster solrCluster;\n+\n+  @Override\n+  public void setUp() throws Exception {\n+    if (random().nextBoolean()) {\n+      System.setProperty(\"solr.statsCache\", ExactStatsCache.class.getName());\n+    } else {\n+      System.setProperty(\"solr.statsCache\", LRUStatsCache.class.getName());\n+    }\n+\n+    super.setUp();\n+    final File solrXml = getFile(\"solr\").toPath().resolve(\"solr-no-core.xml\").toFile();\n+    solrCluster = new MiniSolrCloudCluster(3, createTempDir().toFile(), solrXml, buildJettyConfig(\"/solr\"));\n+    // set some system properties for use by tests\n+    System.setProperty(\"solr.test.sys.prop1\", \"propone\");\n+    System.setProperty(\"solr.test.sys.prop2\", \"proptwo\");\n+    File configDir = getFile(\"solr\").toPath().resolve(\"collection1/conf\").toFile();\n+    solrCluster.uploadConfigDir(configDir, \"conf1\");\n+    configDir = getFile(\"solr\").toPath().resolve(\"configsets/configset-2/conf\").toFile();\n+    solrCluster.uploadConfigDir(configDir, \"conf2\");\n+  }\n+\n+  @Override\n+  public void tearDown() throws Exception {\n+    solrCluster.shutdown();\n+    System.clearProperty(\"solr.statsCache\");\n+    System.clearProperty(\"solr.test.sys.prop1\");\n+    System.clearProperty(\"solr.test.sys.prop2\");\n+    super.tearDown();\n+  }\n+\n+  @Test\n+  public void testSimpleQuery() throws Exception {\n+    //3 shards. 3rd shard won't have any data.\n+    createCollection(\"onecollection\", \"conf1\", ImplicitDocRouter.NAME);\n+    createCollection(\"onecollection_local\", \"conf2\", ImplicitDocRouter.NAME);\n+\n+    SolrInputDocument doc = new SolrInputDocument();\n+    doc.setField(\"id\", 1);\n+    doc.setField(\"cat\", \"football\");\n+    doc.addField(ShardParams._ROUTE_, \"a\");\n+    solrCluster.getSolrClient().add(\"onecollection\", doc);\n+    solrCluster.getSolrClient().add(\"onecollection_local\", doc);\n+\n+    doc = new SolrInputDocument();\n+    doc.setField(\"id\", 2);\n+    doc.setField(\"cat\", \"football\");\n+    doc.addField(ShardParams._ROUTE_, \"b\");\n+    solrCluster.getSolrClient().add(\"onecollection\", doc);\n+    solrCluster.getSolrClient().add(\"onecollection_local\", doc);\n+\n+    int nDocs = TestUtil.nextInt(random(), 10, 100);\n+    for (int i=0; i<nDocs; i++) {\n+      doc = new SolrInputDocument();\n+      doc.setField(\"id\", 3 + i);\n+      String cat = TestUtil.randomSimpleString(random());\n+      if (!cat.equals(\"football\")) { //Making sure no other document has the query term in it.\n+        doc.setField(\"cat\", cat);\n+        if (rarely()) { //Put most documents in shard b so that 'football' becomes 'rare' in shard b\n+          doc.addField(ShardParams._ROUTE_, \"a\");\n+        } else {\n+          doc.addField(ShardParams._ROUTE_, \"b\");\n+        }\n+        solrCluster.getSolrClient().add(\"onecollection\", doc);\n+        solrCluster.getSolrClient().add(\"onecollection_local\", doc);\n+      }\n+    }\n+\n+    solrCluster.getSolrClient().commit(\"onecollection\");\n+    solrCluster.getSolrClient().commit(\"onecollection_local\");\n+\n+    //Test against all nodes\n+    for (JettySolrRunner jettySolrRunner : solrCluster.getJettySolrRunners()) {\n+      SolrClient solrClient = new HttpSolrClient(jettySolrRunner.getBaseUrl().toString());\n+      SolrClient solrClient_local = new HttpSolrClient(jettySolrRunner.getBaseUrl().toString());\n+\n+      SolrQuery query = new SolrQuery(\"cat:football\");\n+      query.setFields(\"*,score\");\n+      QueryResponse queryResponse = solrClient.query(\"onecollection\", query);\n+      assertEquals(2, queryResponse.getResults().getNumFound());\n+      float score1 = (float) queryResponse.getResults().get(0).get(\"score\");\n+      float score2 = (float) queryResponse.getResults().get(1).get(\"score\");\n+      assertEquals(\"Doc1 score=\" + score1 + \" Doc2 score=\" + score2, 0, Float.compare(score1, score2));\n+\n+      query = new SolrQuery(\"cat:football\");\n+      query.setShowDebugInfo(true);\n+      query.setFields(\"*,score\");\n+      queryResponse = solrClient_local.query(\"onecollection_local\", query);\n+      assertEquals(2, queryResponse.getResults().getNumFound());\n+      assertEquals(2, queryResponse.getResults().get(0).get(\"id\"));\n+      assertEquals(1, queryResponse.getResults().get(1).get(\"id\"));\n+      float score1_local = (float) queryResponse.getResults().get(0).get(\"score\");\n+      float score2_local = (float) queryResponse.getResults().get(1).get(\"score\");\n+      assertEquals(\"Doc1 score=\" + score1_local + \" Doc2 score=\" + score2_local, 1, Float.compare(score1_local, score2_local));\n+    }\n+  }\n+\n+  private void createCollection(String name, String config) throws Exception {\n+    createCollection(name, config, CompositeIdRouter.NAME);\n+  }\n+\n+  private void createCollection(String name, String config, String router) throws Exception {\n+    CollectionAdminResponse response;\n+    if (router.equals(ImplicitDocRouter.NAME)) {\n+      CollectionAdminRequest.Create create = new CollectionAdminRequest.Create();\n+      create.setConfigName(config);\n+      create.setCollectionName(name);\n+      create.setReplicationFactor(1);\n+      create.setMaxShardsPerNode(1);\n+      create.setRouterName(router);\n+      create.setShards(\"a,b,c\");\n+      response = create.process(solrCluster.getSolrClient());\n+    } else {\n+      CollectionAdminRequest.Create create = new CollectionAdminRequest.Create();\n+      create.setConfigName(config);\n+      create.setCollectionName(name);\n+      create.setNumShards(2);\n+      create.setReplicationFactor(1);\n+      create.setMaxShardsPerNode(1);\n+      response = create.process(solrCluster.getSolrClient());\n+    }\n+\n+    if (response.getStatus() != 0 || response.getErrorMessages() != null) {\n+      fail(\"Could not create collection. Response\" + response.toString());\n+    }\n+    ZkStateReader zkStateReader = solrCluster.getSolrClient().getZkStateReader();\n+    AbstractDistribZkTestBase.waitForRecoveriesToFinish(name, zkStateReader, false, true, 100);\n+  }\n+\n+  private void addDocsRandomly() throws IOException, SolrServerException {\n+    SolrInputDocument doc = new SolrInputDocument();\n+    doc.setField(\"id\", 1);\n+    doc.setField(\"cat\", \"football\");\n+    solrCluster.getSolrClient().add(\"collection1\", doc);\n+    solrCluster.getSolrClient().add(\"collection1_local\", doc);\n+\n+    doc = new SolrInputDocument();\n+    doc.setField(\"id\", 2);\n+    doc.setField(\"cat\", \"football\");\n+    solrCluster.getSolrClient().add(\"collection2\", doc);\n+    solrCluster.getSolrClient().add(\"collection2_local\", doc);\n+\n+    int nDocs = TestUtil.nextInt(random(), 10, 100);\n+    int collection1Count = 1;\n+    int collection2Count = 1;\n+    for (int i=0; i<nDocs; i++) {\n+      doc = new SolrInputDocument();\n+      doc.setField(\"id\", 3 + i);\n+      String cat = TestUtil.randomSimpleString(random());\n+      if (!cat.equals(\"football\")) { //Making sure no other document has the query term in it.\n+        doc.setField(\"cat\", cat);\n+        if (rarely()) { //Put most documents in collection2* so that 'football' becomes 'rare' in collection2*\n+          solrCluster.getSolrClient().add(\"collection1\", doc);\n+          solrCluster.getSolrClient().add(\"collection1_local\", doc);\n+          collection1Count++;\n+        } else {\n+          solrCluster.getSolrClient().add(\"collection2\", doc);\n+          solrCluster.getSolrClient().add(\"collection2_local\", doc);\n+          collection2Count++;\n+        }\n+      }\n+    }\n+    log.info(\"numDocs={}. collection1Count={} collection2Count={}\", nDocs, collection1Count, collection2Count);\n+\n+    solrCluster.getSolrClient().commit(\"collection1\");\n+    solrCluster.getSolrClient().commit(\"collection2\");\n+    solrCluster.getSolrClient().commit(\"collection1_local\");\n+    solrCluster.getSolrClient().commit(\"collection2_local\");\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4b83947e1c19b51537d1cf601e9f4defbac214e0/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java",
                "sha": "6af890de44f3be268b65fb63cb519d2f7570e715",
                "status": "added"
            }
        ],
        "message": "SOLR-7756: ExactStatsCache and LRUStatsCache will throw an NPE when a term is not present on a shard\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1694182 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/2de2e0a16f22db7762256a8b26e7eff57190f195",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestExactStatsCache.java",
            "TestLRUStatsCache.java"
        ]
    },
    "lucene-solr_4dd86bf": {
        "bug_id": "lucene-solr_4dd86bf",
        "commit": "https://github.com/apache/lucene-solr/commit/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/CHANGES.txt",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=4dd86bf8ab0b450b63be170836ecb4cca7ed34b1",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -679,6 +679,13 @@ Bug Fixes\n   DocumentAnalysisRequestHandler to respect charset from XML file and only\n   use HTTP header's \"Content-Type\" as a \"hint\". (Uwe Schindler)\n \n+* SOLR-1191: resolve DataImportHandler deltaQuery column against pk when pk\n+  has a prefix (e.g. pk=\"book.id\" deltaQuery=\"select id from ...\"). More\n+  useful error reporting when no match found (previously failed with a\n+  NullPointerException in log and no clear user feedback). (gthb via yonik)\n+\n+\n+\n Other Changes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/CHANGES.txt",
                "sha": "455fd961047f4122a1ebe2db2c35da1fd3d97064",
                "status": "modified"
            },
            {
                "additions": 42,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java?ref=4dd86bf8ab0b450b63be170836ecb4cca7ed34b1",
                "deletions": 3,
                "filename": "solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "patch": "@@ -318,7 +318,11 @@ private void deleteAll(Set<Map<String, Object>> deletedKeys) {\n       String keyName = root.isDocRoot ? root.getPk() : root.getSchemaPk();\n       Object key = map.get(keyName);\n       if(key == null) {\n-        LOG.warn(\"no key was available for deleteted pk query. keyName = \" + keyName);\n+        keyName = findMatchingPkColumn(keyName, map);\n+        key = map.get(keyName);\n+      }\n+      if(key == null) {\n+        LOG.warn(\"no key was available for deleted pk query. keyName = \" + keyName);\n         continue;\n       }\n       writer.deleteDoc(key);\n@@ -816,6 +820,28 @@ private EntityProcessorWrapper getEntityProcessor(DataConfig.Entity entity) {\n     return entity.processor = new EntityProcessorWrapper(entityProcessor, this);\n   }\n \n+  private String findMatchingPkColumn(String pk, Map<String, Object> row) {\n+    if (row.containsKey(pk))\n+      throw new IllegalArgumentException(\n+        String.format(\"deltaQuery returned a row with null for primary key %s\", pk));\n+    String resolvedPk = null;\n+    for (String columnName : row.keySet()) {\n+      if (columnName.endsWith(\".\" + pk) || pk.endsWith(\".\" + columnName)) {\n+        if (resolvedPk != null)\n+          throw new IllegalArgumentException(\n+            String.format(\n+              \"deltaQuery has more than one column (%s and %s) that might resolve to declared primary key pk='%s'\",\n+              resolvedPk, columnName, pk));\n+        resolvedPk = columnName;\n+      }\n+    }\n+    if (resolvedPk == null)\n+      throw new IllegalArgumentException(\n+        String.format(\"deltaQuery has no column to resolve to declared primary key pk='%s'\", pk));\n+    LOG.info(String.format(\"Resolving deltaQuery column '%s' to match entity's declared pk '%s'\", resolvedPk, pk));\n+    return resolvedPk;\n+  }\n+\n   /**\n    * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n    * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n@@ -852,13 +878,20 @@ private EntityProcessorWrapper getEntityProcessor(DataConfig.Entity entity) {\n     Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n     LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n     //get the modified rows in this entity\n+    String pk = entity.getPk();\n     while (true) {\n       Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n \n       if (row == null)\n         break;\n \n-      deltaSet.put(row.get(entity.getPk()).toString(), row);\n+      Object pkValue = row.get(pk);\n+      if (pkValue == null) {\n+        pk = findMatchingPkColumn(pk, row);\n+        pkValue = row.get(pk);\n+      }\n+\n+      deltaSet.put(pkValue.toString(), row);\n       importStatistics.rowsCount.incrementAndGet();\n       // check for abort\n       if (stop.get())\n@@ -873,8 +906,14 @@ private EntityProcessorWrapper getEntityProcessor(DataConfig.Entity entity) {\n \n       deletedSet.add(row);\n       \n+      Object pkValue = row.get(pk);\n+      if (pkValue == null) {\n+        pk = findMatchingPkColumn(pk, row);\n+        pkValue = row.get(pk);\n+      }\n+\n       // Remove deleted rows from the delta rows\n-      String deletedRowPk = row.get(entity.getPk()).toString();\n+      String deletedRowPk = pkValue.toString();\n       if (deltaSet.containsKey(deletedRowPk)) {\n         deltaSet.remove(deletedRowPk);\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder.java",
                "sha": "858d688976ec2c68ef18b595c201a43a3cd3dd2f",
                "status": "modified"
            },
            {
                "additions": 145,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessorDeltaPrefixedPk.java",
                "changes": 145,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessorDeltaPrefixedPk.java?ref=4dd86bf8ab0b450b63be170836ecb4cca7ed34b1",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessorDeltaPrefixedPk.java",
                "patch": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.handler.dataimport;\n+\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.logging.*;\n+\n+/**\n+ * <p>\n+ * Test for SqlEntityProcessorDelta verifying fix for SOLR-1191\n+ * </p>\n+ * \n+ *\n+ * @version $Id$\n+ * @since solr 3.1\n+ */\n+public class TestSqlEntityProcessorDeltaPrefixedPk extends AbstractDataImportHandlerTestCase {\n+  private static final String FULLIMPORT_QUERY = \"select * from x\";\n+\n+  private static final String DELTA_QUERY = \"select id from x where last_modified > NOW\";\n+\n+  private static final String DELETED_PK_QUERY = \"select id from x where last_modified > NOW AND deleted='true'\";\n+\n+  private static final String dataConfig_delta =\n+    \"<dataConfig>\" +\n+    \"  <dataSource  type=\\\"MockDataSource\\\"/>\\n\" +\n+    \"  <document>\\n\" +\n+    \"    <entity name=\\\"x\\\" transformer=\\\"TemplateTransformer\\\" pk=\\\"x.id\\\"\" +\n+    \"            query=\\\"\" + FULLIMPORT_QUERY + \"\\\"\" +\n+    \"            deletedPkQuery=\\\"\" + DELETED_PK_QUERY + \"\\\"\" +\n+    \"            deltaImportQuery=\\\"select * from x where id='${dih.delta.id}'\\\"\" +\n+    \"            deltaQuery=\\\"\" + DELTA_QUERY + \"\\\">\\n\" +\n+    \"      <field column=\\\"id\\\" name=\\\"id\\\"/>\\n\" +\n+    \"      <field column=\\\"desc\\\" name=\\\"desc\\\"/>\\n\" +\n+    \"    </entity>\\n\" +\n+    \"  </document>\\n\" +\n+    \"</dataConfig>\\n\";\n+  \n+  private static final List EMPTY_LIST = Collections.EMPTY_LIST;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    initCore(\"dataimport-solrconfig.xml\", \"dataimport-schema.xml\");\n+  }\n+\n+  @Before @Override\n+  public void setUp() throws Exception {\n+    super.setUp();\n+    clearIndex();\n+    assertU(commit());\n+    //Logger.getLogger(\"\").setLevel(Level.ALL);\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private void add1document() throws Exception {\n+    List row = new ArrayList();\n+    row.add(createMap(\"id\", \"1\", \"desc\", \"bar\"));\n+    MockDataSource.setIterator(FULLIMPORT_QUERY, row.iterator());\n+\n+    runFullImport(dataConfig_delta);\n+\n+    assertQ(req(\"*:* OR add1document\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"id:1\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"desc:bar\"), \"//*[@numFound='1']\");\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"unchecked\")\n+  public void testDeltaImport_deleteResolvesUnprefixedPk() throws Exception {\n+    add1document();\n+    MockDataSource.clearCache();\n+    List deletedRows = new ArrayList();\n+    deletedRows.add(createMap(\"id\", \"1\"));\n+    MockDataSource.setIterator(DELETED_PK_QUERY, deletedRows.iterator());\n+    MockDataSource.setIterator(DELTA_QUERY, EMPTY_LIST.iterator());\n+    runDeltaImport(dataConfig_delta);\n+\n+    assertQ(req(\"*:* OR testDeltaImport_deleteResolvesUnprefixedPk\"), \"//*[@numFound='0']\");\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"unchecked\")\n+  public void testDeltaImport_replace_resolvesUnprefixedPk() throws Exception {\n+    add1document();\n+    MockDataSource.clearCache();\n+    List deltaRows = new ArrayList();\n+    deltaRows.add(createMap(\"id\", \"1\"));\n+    MockDataSource.setIterator(DELTA_QUERY, deltaRows.iterator());\n+    MockDataSource.setIterator(DELETED_PK_QUERY, EMPTY_LIST.iterator());\n+    List rows = new ArrayList();\n+    rows.add(createMap(\"id\", \"1\", \"desc\", \"baz\"));\n+    MockDataSource.setIterator(\"select * from x where id='1'\", rows.iterator());\n+\n+    runDeltaImport(dataConfig_delta);\n+\n+    assertQ(req(\"*:* OR testDeltaImport_replace_resolvesUnprefixedPk\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"id:1\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"desc:bar\"), \"//*[@numFound='0']\");\n+    assertQ(req(\"desc:baz\"), \"//*[@numFound='1']\");\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"unchecked\")\n+  public void testDeltaImport_addResolvesUnprefixedPk() throws Exception {\n+    add1document();\n+    MockDataSource.clearCache();\n+\n+    List deltaRows = new ArrayList();\n+    deltaRows.add(createMap(\"id\", \"2\"));\n+    MockDataSource.setIterator(DELTA_QUERY, deltaRows.iterator());\n+\n+    List rows = new ArrayList();\n+    rows.add(createMap(\"id\", \"2\", \"desc\", \"xyzzy\"));\n+    MockDataSource.setIterator(\"select * from x where id='2'\", rows.iterator());\n+\n+    runDeltaImport(dataConfig_delta);\n+\n+    assertQ(req(\"*:* OR testDeltaImport_addResolvesUnprefixedPk\"), \"//*[@numFound='2']\");\n+    assertQ(req(\"id:1\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"id:2\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"desc:bar\"), \"//*[@numFound='1']\");\n+    assertQ(req(\"desc:xyzzy\"), \"//*[@numFound='1']\");\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4dd86bf8ab0b450b63be170836ecb4cca7ed34b1/solr/contrib/dataimporthandler/src/test/java/org/apache/solr/handler/dataimport/TestSqlEntityProcessorDeltaPrefixedPk.java",
                "sha": "51fc50b9f1a88718a3b339c35e47309a667cc09f",
                "status": "added"
            }
        ],
        "message": "SOLR-1191: fix DIH deltaQyery when pk has prefix, change NPE to better error reporting\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1071435 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/25177837b0c21f4d870eb7fb1830b458bcad8c66",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestDocBuilder.java"
        ]
    },
    "lucene-solr_4f711ca": {
        "bug_id": "lucene-solr_4f711ca",
        "commit": "https://github.com/apache/lucene-solr/commit/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/java/org/apache/solr/core/QuerySenderListener.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/core/QuerySenderListener.java?ref=4f711ca57a1142e01d507b60a6e9e0f3df52d3d5",
                "deletions": 1,
                "filename": "solr/src/java/org/apache/solr/core/QuerySenderListener.java",
                "patch": "@@ -41,7 +41,9 @@ public QuerySenderListener(SolrCore core) {\n   public void newSearcher(SolrIndexSearcher newSearcher, SolrIndexSearcher currentSearcher) {\n     final SolrIndexSearcher searcher = newSearcher;\n     log.info(\"QuerySenderListener sending requests to \" + newSearcher);\n-    for (NamedList nlst : (List<NamedList>)args.get(\"queries\")) {\n+    List<NamedList> allLists = (List<NamedList>)args.get(\"queries\");\n+    if (allLists == null) return;\n+    for (NamedList nlst : allLists) {\n       SolrQueryRequest req = null;\n \n       try {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/java/org/apache/solr/core/QuerySenderListener.java",
                "sha": "d363005df56bb92f57c6e9448409a8c4b6689eed",
                "status": "modified"
            },
            {
                "additions": 79,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/test-files/solr/conf/solrconfig-querysender-noquery.xml",
                "changes": 79,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/test-files/solr/conf/solrconfig-querysender-noquery.xml?ref=4f711ca57a1142e01d507b60a6e9e0f3df52d3d5",
                "deletions": 0,
                "filename": "solr/src/test-files/solr/conf/solrconfig-querysender-noquery.xml",
                "patch": "@@ -0,0 +1,79 @@\n+<?xml version=\"1.0\" ?>\n+\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+\n+<!-- $Id: solrconfig-querysender.xml 1048886 2010-12-14 01:10:52Z hossman $\n+     $Source$\n+     $Name$\n+  -->\n+\n+<config>\n+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>\n+    <!--  The DirectoryFactory to use for indexes.\n+        solr.StandardDirectoryFactory, the default, is filesystem based.\n+        solr.RAMDirectoryFactory is memory based and not persistent. -->\n+  <directoryFactory name=\"DirectoryFactory\" class=\"${solr.directoryFactory:solr.RAMDirectoryFactory}\"/>\n+  \n+  <updateHandler class=\"solr.DirectUpdateHandler2\">\n+    <listener event=\"postCommit\" \n+              class=\"org.apache.solr.core.MockEventListener\" />\n+    <listener event=\"postOptimize\" \n+              class=\"org.apache.solr.core.MockEventListener\" />\n+  </updateHandler>\n+  \n+  <query>\n+  \n+  \n+    <!-- a newSearcher event is fired whenever a new searcher is being prepared\n+         and there is a current searcher handling requests (aka registered). -->\n+    <!-- QuerySenderListener takes an array of NamedList and executes a\n+         local query request for each NamedList in sequence. -->\n+    <listener event=\"newSearcher\" class=\"solr.QuerySenderListener\">\n+      <!--\n+      <arr name=\"queries\">\n+        <lst> <str name=\"q\">solr</str> <str name=\"start\">0</str> <str name=\"rows\">10</str> <str name=\"qt\">mock</str></lst>\n+        <lst> <str name=\"q\">rocks</str> <str name=\"start\">0</str> <str name=\"rows\">10</str> <str name=\"qt\">mock</str></lst>\n+      </arr>\n+      -->\n+    </listener>\n+    <listener event=\"newSearcher\"\n+              class=\"org.apache.solr.core.MockEventListener\" />\n+\n+\n+    <!-- a firstSearcher event is fired whenever a new searcher is being\n+         prepared but there is no current registered searcher to handle\n+         requests or to gain prewarming data from. -->\n+    <listener event=\"firstSearcher\" class=\"solr.QuerySenderListener\">\n+      <!--\n+      <arr name=\"queries\">\n+        <lst> <str name=\"q\">fast_warm</str> <str name=\"start\">0</str> <str name=\"rows\">10</str>\n+          <str name=\"qt\">mock</str>\n+        </lst>\n+      </arr>\n+      -->\n+    </listener>\n+    <listener event=\"firstSearcher\"\n+              class=\"org.apache.solr.core.MockEventListener\" />\n+\n+  \n+  </query>\n+  <requestHandler name=\"mock\" class=\"org.apache.solr.core.MockQuerySenderListenerReqHandler\" default=\"true\">\n+    <!-- default values for query parameters -->\n+\n+  </requestHandler>\n+</config>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/test-files/solr/conf/solrconfig-querysender-noquery.xml",
                "sha": "206350d360313a7309d441b82d000d5b388a8794",
                "status": "added"
            },
            {
                "additions": 90,
                "blob_url": "https://github.com/apache/lucene-solr/blob/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/test/org/apache/solr/core/TestQuerySenderNoQuery.java",
                "changes": 90,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/test/org/apache/solr/core/TestQuerySenderNoQuery.java?ref=4f711ca57a1142e01d507b60a6e9e0f3df52d3d5",
                "deletions": 0,
                "filename": "solr/src/test/org/apache/solr/core/TestQuerySenderNoQuery.java",
                "patch": "@@ -0,0 +1,90 @@\n+package org.apache.solr.core;\n+\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.lucene.store.Directory;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.common.params.EventParams;\n+import org.apache.solr.search.SolrIndexSearcher;\n+import org.apache.solr.search.TestExtendedDismaxParser;\n+import org.apache.solr.util.RefCounted;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public class TestQuerySenderNoQuery extends SolrTestCaseJ4 {\n+\n+  // number of instances configured in the solrconfig.xml\n+  private static final int EXPECTED_MOCK_LISTENER_INSTANCES = 4;\n+\n+  private static int preInitMockListenerCount = 0;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    // record current value prior to core initialization\n+    // so we can verify the correct number of instances later\n+    // NOTE: this won't work properly if concurrent tests run\n+    // in the same VM\n+    preInitMockListenerCount = MockEventListener.getCreateCount();\n+\n+    initCore(\"solrconfig-querysender-noquery.xml\",\"schema.xml\");\n+  }\n+\n+  public void testListenerCreationCounts() {\n+    SolrCore core = h.getCore();\n+\n+    assertEquals(\"Unexpected number of listeners created\",\n+                 EXPECTED_MOCK_LISTENER_INSTANCES,\n+                 MockEventListener.getCreateCount() - preInitMockListenerCount);\n+  }\n+\n+  @Test\n+  public void testRequestHandlerRegistry() {\n+    // property values defined in build.xml\n+    SolrCore core = h.getCore();\n+\n+    assertEquals( 2, core.firstSearcherListeners.size() );\n+    assertEquals( 2, core.newSearcherListeners.size() );\n+  }\n+\n+  // Determine that when the query lists are commented out of both new and\n+  // first searchers in the config, we don't throw an NPE\n+  @Test\n+  public void testSearcherEvents() throws Exception {\n+    SolrCore core = h.getCore();\n+    SolrEventListener newSearcherListener = core.newSearcherListeners.get(0);\n+    assertTrue(\"Not an instance of QuerySenderListener\", newSearcherListener instanceof QuerySenderListener);\n+    QuerySenderListener qsl = (QuerySenderListener) newSearcherListener;\n+\n+    RefCounted<SolrIndexSearcher> currentSearcherRef = core.getSearcher();\n+    SolrIndexSearcher currentSearcher = currentSearcherRef.get();\n+    SolrIndexSearcher dummy = null;\n+    qsl.newSearcher(currentSearcher, dummy);//test first Searcher (since param is null)\n+    MockQuerySenderListenerReqHandler mock = (MockQuerySenderListenerReqHandler) core.getRequestHandler(\"mock\");\n+    assertNotNull(\"Mock is null\", mock);\n+    assertNull(\"Req (firstsearcher) is not null\", mock.req);\n+\n+    Directory dir = currentSearcher.getIndexReader().directory();\n+    SolrIndexSearcher newSearcher = new SolrIndexSearcher(core, core.getSchema(), \"testQuerySenderNoQuery\", dir, true, false);\n+\n+    qsl.newSearcher(newSearcher, currentSearcher); // get newSearcher.\n+    assertNull(\"Req (newsearcher) is not null\", mock.req);\n+    newSearcher.close();\n+    currentSearcherRef.decref();\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/4f711ca57a1142e01d507b60a6e9e0f3df52d3d5/solr/src/test/org/apache/solr/core/TestQuerySenderNoQuery.java",
                "sha": "b23e4bdde5f3185a952de8cc7d917a5a2e7868ed",
                "status": "added"
            }
        ],
        "message": "Solr-2598 (Commenting out the <arr name=\"queries\"> section in firstSearcher generates an NPE)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1137092 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/5083ab7e5d753b0ee912532b62951835bd9484b5",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestQuerySenderListener.java"
        ]
    },
    "lucene-solr_58fe66d": {
        "bug_id": "lucene-solr_58fe66d",
        "commit": "https://github.com/apache/lucene-solr/commit/58fe66dba7c4a49827bb2d20e6f9dc15dc61aff3",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/58fe66dba7c4a49827bb2d20e6f9dc15dc61aff3/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java?ref=58fe66dba7c4a49827bb2d20e6f9dc15dc61aff3",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java",
                "patch": "@@ -850,10 +850,12 @@ private void doFinish() {\n         List<ZkCoreNodeProps> myReplicas = zkController.getZkStateReader().getReplicaProps(collection,\n             cloudDesc.getShardId(), cloudDesc.getCoreNodeName());\n         boolean foundErrorNodeInReplicaList = false;\n-        for (ZkCoreNodeProps replicaProp : myReplicas) {\n-          if (((Replica) replicaProp.getNodeProps()).getName().equals(((Replica)stdNode.getNodeProps().getNodeProps()).getName()))  {\n-            foundErrorNodeInReplicaList = true;\n-            break;\n+        if (myReplicas != null) {\n+          for (ZkCoreNodeProps replicaProp : myReplicas) {\n+            if (((Replica) replicaProp.getNodeProps()).getName().equals(((Replica)stdNode.getNodeProps().getNodeProps()).getName()))  {\n+              foundErrorNodeInReplicaList = true;\n+              break;\n+            }\n           }\n         }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/58fe66dba7c4a49827bb2d20e6f9dc15dc61aff3/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java",
                "sha": "39daf72cb61639beb9fb7ac1a08cebe9e4690339",
                "status": "modified"
            }
        ],
        "message": "SOLR-6530: Protect against NPE when there are no live replicas\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1633276 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/c1bdf27d9751cc37a2c1ad5c136fe04dc2decab8",
        "repo": "lucene-solr",
        "unit_tests": [
            "DistributedUpdateProcessorTest.java"
        ]
    },
    "lucene-solr_592899a": {
        "bug_id": "lucene-solr_592899a",
        "commit": "https://github.com/apache/lucene-solr/commit/592899a419c2a15e75f73e906fa61b7e922c9830",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/592899a419c2a15e75f73e906fa61b7e922c9830/solr/CHANGES.txt",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=592899a419c2a15e75f73e906fa61b7e922c9830",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -207,6 +207,11 @@ Bug Fixes\n \n * SOLR-12594: MetricsHistoryHandler.getOverseerLeader fails when hostname contains hyphen. (ab)\n \n+* SOLR-12615: HashQParserPlugin will no longer throw an NPE if the hash key field is a string when there are documents\n+  with empty values. All documents with empty values ( string , numeric ) will be processed by worker=0\n+  This would fix the NPE when using the search stream with partitionKeys. (Varun Thacker)\n+\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/592899a419c2a15e75f73e906fa61b7e922c9830/solr/CHANGES.txt",
                "sha": "605e8375cb82d4082b0f580d305590e6f5de401e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/592899a419c2a15e75f73e906fa61b7e922c9830/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java?ref=592899a419c2a15e75f73e906fa61b7e922c9830",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java",
                "patch": "@@ -297,7 +297,7 @@ public long hashCode(int doc) throws IOException {\n       if (doc == values.docID()) {\n         ref = values.binaryValue();\n       } else {\n-        ref = null;\n+        ref = new BytesRef(); // EMPTY_BYTES . worker=0 will always process empty values\n       }\n       this.fieldType.indexedToReadable(ref, charsRefBuilder);\n       CharsRef charsRef = charsRefBuilder.get();\n@@ -327,7 +327,7 @@ public long hashCode(int doc) throws IOException {\n       if (valuesDocID == doc) {\n         l = values.longValue();\n       } else {\n-        l = 0;\n+        l = 0; //worker=0 will always process empty values\n       }\n       return Longs.hashCode(l);\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/592899a419c2a15e75f73e906fa61b7e922c9830/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java",
                "sha": "bd8f425f27821b0f1db59eb6f6b0dfa105043519",
                "status": "modified"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/lucene-solr/blob/592899a419c2a15e75f73e906fa61b7e922c9830/solr/core/src/test/org/apache/solr/search/TestHashQParserPlugin.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/TestHashQParserPlugin.java?ref=592899a419c2a15e75f73e906fa61b7e922c9830",
                "deletions": 1,
                "filename": "solr/core/src/test/org/apache/solr/search/TestHashQParserPlugin.java",
                "patch": "@@ -54,6 +54,34 @@ public int getCost(Random random) {\n     }\n   }\n \n+  @Test\n+  public void testHashPartitionWithEmptyValues() throws Exception {\n+\n+    assertU(adoc(\"id\", \"1\", \"a_s\", \"one\", \"a_i\" , \"1\"));\n+    assertU(adoc(\"id\", \"2\", \"a_s\", \"one\", \"a_i\" , \"1\"));\n+    assertU(adoc(\"id\", \"3\"));\n+    assertU(adoc(\"id\", \"4\"));\n+    assertU(commit());\n+\n+    //Test with string hash\n+    ModifiableSolrParams params = new ModifiableSolrParams();\n+    params.add(\"q\", \"*:*\");\n+    params.add(\"fq\", \"{!hash worker=0 workers=1 cost=\"+getCost(random())+\"}\");\n+    params.add(\"partitionKeys\", \"a_s\");\n+    params.add(\"wt\", \"xml\");\n+    String response = h.query(req(params));\n+    h.validateXPath(response, \"//*[@numFound='4']\");\n+\n+    //Test with int hash\n+    params = new ModifiableSolrParams();\n+    params.add(\"q\", \"*:*\");\n+    params.add(\"fq\", \"{!hash worker=0 workers=1 cost=\"+getCost(random())+\"}\");\n+    params.add(\"partitionKeys\", \"a_i\");\n+    params.add(\"wt\", \"xml\");\n+    response = h.query(req(params));\n+    h.validateXPath(response, \"//*[@numFound='4']\");\n+  }\n+\n \n   @Test\n   public void testHashPartition() throws Exception {\n@@ -62,7 +90,7 @@ public void testHashPartition() throws Exception {\n     Random random = random();\n     HashSet<String> set = new HashSet();\n \n-    for(int i=0; i<50; i++) {\n+    for (int i=0; i<50; i++) {\n       int v = random.nextInt(1000000);\n       String val = Integer.toString(v);\n       if(!set.contains(val)){",
                "raw_url": "https://github.com/apache/lucene-solr/raw/592899a419c2a15e75f73e906fa61b7e922c9830/solr/core/src/test/org/apache/solr/search/TestHashQParserPlugin.java",
                "sha": "6f68906604ec1d15ceaba735535655c873c8a0ee",
                "status": "modified"
            }
        ],
        "message": "SOLR-12615: HashQParserPlugin won't throw an NPE for string hash key and documents with empty value",
        "parent": "https://github.com/apache/lucene-solr/commit/b33df4ecff2c138dd248b945833e2e59e4aa0424",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestHashQParserPlugin.java"
        ]
    },
    "lucene-solr_592b47f": {
        "bug_id": "lucene-solr_592b47f",
        "commit": "https://github.com/apache/lucene-solr/commit/592b47f7350ae6a8c6964e69bff4e6de02e1e81c",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/592b47f7350ae6a8c6964e69bff4e6de02e1e81c/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java?ref=592b47f7350ae6a8c6964e69bff4e6de02e1e81c",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java",
                "patch": "@@ -211,7 +211,7 @@ private void extractGroupedInfo( NamedList<Object> info ) {\n             SimpleOrderedMap grpMap = (SimpleOrderedMap) oGrp;\n             Object sGroupValue = grpMap.get( \"groupValue\");\n             SolrDocumentList doclist = (SolrDocumentList) grpMap.get( \"doclist\");\n-            Group group = new Group(sGroupValue.toString(), doclist) ;\n+            Group group = new Group(sGroupValue != null ? sGroupValue.toString() : null, doclist) ;\n             groupedCommand.add(group);\n           }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/592b47f7350ae6a8c6964e69bff4e6de02e1e81c/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java",
                "sha": "6d52482f1d27d6733fb26437db7f360d28c8a29c",
                "status": "modified"
            }
        ],
        "message": "Fixed NPE when group value is null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1154739 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/0bc43983c42b3acea1f1b05fc6eaee2f50e81dd7",
        "repo": "lucene-solr",
        "unit_tests": [
            "QueryResponseTest.java"
        ]
    },
    "lucene-solr_5a69734": {
        "bug_id": "lucene-solr_5a69734",
        "commit": "https://github.com/apache/lucene-solr/commit/5a697344ed1be537ef2acdd18aab653283593370",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5a697344ed1be537ef2acdd18aab653283593370/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=5a697344ed1be537ef2acdd18aab653283593370",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -197,6 +197,8 @@ Bug Fixes\n \n * SOLR-13465: CoreContainer.auditloggerPlugin should be volatile (janhoy, hossman)\n \n+* SOLR-13805: NPE when calling /solr/admin/info/health on standalone solr (Nicholas DiPiazza, shalin)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5a697344ed1be537ef2acdd18aab653283593370/solr/CHANGES.txt",
                "sha": "9ebcc575f81f065d46647dde59d4670a8b964de3",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5a697344ed1be537ef2acdd18aab653283593370/solr/core/src/java/org/apache/solr/handler/admin/HealthCheckHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/HealthCheckHandler.java?ref=5a697344ed1be537ef2acdd18aab653283593370",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/HealthCheckHandler.java",
                "patch": "@@ -66,7 +66,6 @@ public CoreContainer getCoreContainer() {\n   @Override\n   public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception {\n \n-    log.debug(\"Invoked HealthCheckHandler on [{}]\", coreContainer.getZkController().getNodeName());\n     CoreContainer cores = getCoreContainer();\n \n     // Core container should not be null and active (redundant check)\n@@ -79,6 +78,7 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n       rsp.setException(new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Health check is only available when running in SolrCloud mode\"));\n       return;\n     }\n+    log.debug(\"Invoked HealthCheckHandler on [{}]\", coreContainer.getZkController().getNodeName());\n     ZkStateReader zkStateReader = cores.getZkController().getZkStateReader();\n     ClusterState clusterState = zkStateReader.getClusterState();\n     // Check for isConnected and isClosed",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5a697344ed1be537ef2acdd18aab653283593370/solr/core/src/java/org/apache/solr/handler/admin/HealthCheckHandler.java",
                "sha": "cc2a649a0ebf8fa1248ca172d2b10c0fbd1b8729",
                "status": "modified"
            }
        ],
        "message": "SOLR-13805: NPE when calling /solr/admin/info/health on standalone solr",
        "parent": "https://github.com/apache/lucene-solr/commit/936f4b6ee9cd8c7f9a17800aadc8c5a91bdf74f6",
        "repo": "lucene-solr",
        "unit_tests": [
            "HealthCheckHandlerTest.java"
        ]
    },
    "lucene-solr_5ba6c0c": {
        "bug_id": "lucene-solr_5ba6c0c",
        "commit": "https://github.com/apache/lucene-solr/commit/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -135,6 +135,8 @@ Bug Fixes\n \n * SOLR-12013: collections API CUSTERSTATUS command fails when configset missing (Erick Erickson)\n \n+* SOLR-13509: NPE on omitHeader=true  is fixed by sending omitHeader=false to shard searches (Munendra S N, Mikhail Khludnev)\n+\n Other Changes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/CHANGES.txt",
                "sha": "6b677731b9b6219e8a8f0fbee076389dc29727b9",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 15,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "patch": "@@ -849,7 +849,7 @@ protected void mergeIds(ResponseBuilder rb, ShardRequest sreq) {\n           }\n           else {\n             responseHeader = (NamedList<?>)srsp.getSolrResponse().getResponse().get(\"responseHeader\");\n-            final Object rhste = (responseHeader == null ? null : responseHeader.get(SolrQueryResponse.RESPONSE_HEADER_SEGMENT_TERMINATED_EARLY_KEY));\n+            final Object rhste = responseHeader.get(SolrQueryResponse.RESPONSE_HEADER_SEGMENT_TERMINATED_EARLY_KEY);\n             if (rhste != null) {\n               nl.add(SolrQueryResponse.RESPONSE_HEADER_SEGMENT_TERMINATED_EARLY_KEY, rhste);\n             }\n@@ -879,20 +879,16 @@ protected void mergeIds(ResponseBuilder rb, ShardRequest sreq) {\n         }\n \n         final boolean thisResponseIsPartial;\n-        if (responseHeader != null) {\n-          thisResponseIsPartial = Boolean.TRUE.equals(responseHeader.getBooleanArg(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY));\n-          thereArePartialResults |= thisResponseIsPartial;\n-          \n-          if (!Boolean.TRUE.equals(segmentTerminatedEarly)) {\n-            final Object ste = responseHeader.get(SolrQueryResponse.RESPONSE_HEADER_SEGMENT_TERMINATED_EARLY_KEY);\n-            if (Boolean.TRUE.equals(ste)) {\n-              segmentTerminatedEarly = Boolean.TRUE;\n-            } else if (Boolean.FALSE.equals(ste)) {\n-              segmentTerminatedEarly = Boolean.FALSE;\n-            }\n+        thisResponseIsPartial = Boolean.TRUE.equals(responseHeader.getBooleanArg(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY));\n+        thereArePartialResults |= thisResponseIsPartial;\n+        \n+        if (!Boolean.TRUE.equals(segmentTerminatedEarly)) {\n+          final Object ste = responseHeader.get(SolrQueryResponse.RESPONSE_HEADER_SEGMENT_TERMINATED_EARLY_KEY);\n+          if (Boolean.TRUE.equals(ste)) {\n+            segmentTerminatedEarly = Boolean.TRUE;\n+          } else if (Boolean.FALSE.equals(ste)) {\n+            segmentTerminatedEarly = Boolean.FALSE;\n           }\n-        } else {\n-          thisResponseIsPartial = false;\n         }\n         \n         // calculate global maxScore and numDocsFound\n@@ -1185,7 +1181,7 @@ protected void returnFields(ResponseBuilder rb, ShardRequest sreq) {\n         }\n         {\n           NamedList<?> responseHeader = (NamedList<?>)srsp.getSolrResponse().getResponse().get(\"responseHeader\");\n-          if (responseHeader!=null && Boolean.TRUE.equals(responseHeader.getBooleanArg(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY))) {\n+          if (Boolean.TRUE.equals(responseHeader.getBooleanArg(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY))) {\n             rb.rsp.getResponseHeader().asShallowMap()\n                .put(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY, Boolean.TRUE);\n           }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/java/org/apache/solr/handler/component/QueryComponent.java",
                "sha": "868b5c988928fec08bc1750d4575428f1c48dc48",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "patch": "@@ -16,9 +16,6 @@\n  */\n package org.apache.solr.handler.component;\n \n-import static org.apache.solr.common.params.CommonParams.DISTRIB;\n-import static org.apache.solr.common.params.CommonParams.PATH;\n-\n import java.io.PrintWriter;\n import java.io.StringWriter;\n import java.lang.invoke.MethodHandles;\n@@ -56,6 +53,9 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import static org.apache.solr.common.params.CommonParams.DISTRIB;\n+import static org.apache.solr.common.params.CommonParams.PATH;\n+\n \n /**\n  *\n@@ -370,6 +370,7 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n               params.set(ShardParams.IS_SHARD, true);  // a sub (shard) request\n               params.set(ShardParams.SHARDS_PURPOSE, sreq.purpose);\n               params.set(ShardParams.SHARD_URL, shard); // so the shard knows what was asked\n+              params.set(CommonParams.OMIT_HEADER, false);\n               if (rb.requestInfo != null) {\n                 // we could try and detect when this is needed, but it could be tricky\n                 params.set(\"NOW\", Long.toString(rb.requestInfo.getNOW().getTime()));",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "sha": "96c2200db88d6d292427cda89fd09fc986df1e37",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/cloud/CloudExitableDirectoryReaderTest.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/CloudExitableDirectoryReaderTest.java?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 6,
                "filename": "solr/core/src/test/org/apache/solr/cloud/CloudExitableDirectoryReaderTest.java",
                "patch": "@@ -21,13 +21,15 @@\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n \n+import com.carrotsearch.randomizedtesting.annotations.Repeat;\n+import com.codahale.metrics.Metered;\n+import com.codahale.metrics.MetricRegistry;\n import org.apache.lucene.util.TestUtil;\n import org.apache.solr.client.solrj.embedded.JettySolrRunner;\n import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n import org.apache.solr.client.solrj.request.UpdateRequest;\n import org.apache.solr.client.solrj.response.QueryResponse;\n import org.apache.solr.cloud.MiniSolrCloudCluster.JettySolrRunnerWithMetrics;\n-import static org.apache.solr.cloud.TrollingIndexReaderFactory.*;\n import org.apache.solr.common.cloud.DocCollection;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.params.SolrParams;\n@@ -40,9 +42,11 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import com.carrotsearch.randomizedtesting.annotations.Repeat;\n-import com.codahale.metrics.Metered;\n-import com.codahale.metrics.MetricRegistry;\n+import static org.apache.solr.cloud.TrollingIndexReaderFactory.CheckMethodName;\n+import static org.apache.solr.cloud.TrollingIndexReaderFactory.Trap;\n+import static org.apache.solr.cloud.TrollingIndexReaderFactory.catchClass;\n+import static org.apache.solr.cloud.TrollingIndexReaderFactory.catchCount;\n+import static org.apache.solr.cloud.TrollingIndexReaderFactory.catchTrace;\n \n /**\n * Distributed test for {@link org.apache.lucene.index.ExitableDirectoryReader} \n@@ -193,7 +197,7 @@ public void testCreepThenBite() throws Exception {\n         params( \"sort\",\"query($q,1) asc\"),\n         params(\"rows\",\"0\", \"facet\",\"true\", \"facet.method\", \"enum\", \"facet.field\", \"name\"),\n         params(\"rows\",\"0\", \"json.facet\",\"{ ids: { type: range, field : num, start : 1, end : 99, gap : 9 }}\")\n-        }; //add more cases here \n+    }; // add more cases here\n \n     params.add(cases[random().nextInt(cases.length)]);\n     for (; ; creep*=1.5) {\n@@ -218,13 +222,20 @@ public void testCreepThenBite() throws Exception {\n     int numBites = atLeast(100);\n     for(int bite=0; bite<numBites; bite++) {\n       int boundary = random().nextInt(creep);\n+      boolean omitHeader = random().nextBoolean();\n       try(Trap catchCount = catchCount(boundary)){\n+        params.set(\"omitHeader\", \"\" + omitHeader);\n         params.set(\"boundary\", boundary);\n         QueryResponse rsp = cluster.getSolrClient().query(COLLECTION, \n             params);\n         assertEquals(\"\"+rsp, rsp.getStatus(), 0);\n         assertNo500s(\"\"+rsp);\n-        assertEquals(\"\"+creep+\" ticks were sucessful; trying \"+boundary+\" yields \"+rsp, \n+        // without responseHeader, whether the response is partial or not can't be known\n+        // omitHeader=true used in request to ensure that no NPE exceptions are thrown\n+        if (omitHeader) {\n+          continue;\n+        }\n+        assertEquals(\"\" + creep + \" ticks were successful; trying \" + boundary + \" yields \" + rsp,\n             catchCount.hasCaught(), isPartial(rsp));\n       }catch(AssertionError ae) {\n         Trap.dumpLastStackTraces(log);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/cloud/CloudExitableDirectoryReaderTest.java",
                "sha": "e75d7007dd925fbd3d2f7f49b2b105c59b3ab6fe",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 7,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "patch": "@@ -117,6 +117,10 @@ public void testSimpleSearch() throws Exception {\n     query.set(\"distrib\", \"true\");\n     query.setFields(\"id\", \"text\");\n     query.set(\"shards\", shard1 + \",\" + shard2);\n+    \n+    if (random().nextBoolean()) {\n+      query.add(\"omitHeader\", Boolean.toString(random().nextBoolean()));\n+    }\n     QueryResponse response = collection1.query(query);\n     NamedList<Object> track = (NamedList<Object>) response.getDebugMap().get(\"track\");\n     assertNotNull(track);\n@@ -138,13 +142,6 @@ public void testSimpleSearch() throws Exception {\n     assertElementsPresent((NamedList<String>)((NamedList<Object>)track.get(\"GET_FIELDS\")).get(shard2), \n         \"QTime\", \"ElapsedTime\", \"RequestPurpose\", \"NumFound\", \"Response\");\n     \n-    query.add(\"omitHeader\", \"true\");\n-    response = collection1.query(query);\n-    assertNull(\"QTime is not included in the response when omitHeader is set to true\", \n-        ((NamedList<Object>)response.getDebugMap().get(\"track\")).findRecursive(\"EXECUTE_QUERY\", shard1, \"QTime\"));\n-    assertNull(\"QTime is not included in the response when omitHeader is set to true\", \n-        ((NamedList<Object>)response.getDebugMap().get(\"track\")).findRecursive(\"GET_FIELDS\", shard2, \"QTime\"));\n-    \n     query.setQuery(\"id:1\");\n     response = collection1.query(query);\n     track = (NamedList<Object>) response.getDebugMap().get(\"track\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "sha": "ffd62a43775bf2a17ba7928a075b122e944cffba",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java",
                "patch": "@@ -219,6 +219,15 @@ public void testInclude_Lower_Gap2_hardend() throws Exception {\n       }\n     }\n   }\n+\n+  public void testStatsWithOmitHeader() throws Exception {\n+    // SOLR-13509: no NPE should be thrown when only stats are specified with omitHeader=true\n+    SolrQuery solrQuery = new SolrQuery(\"q\", \"*:*\", \"omitHeader\", \"true\",\n+        \"json.facet\", \"{unique_foo:\\\"unique(\" + STR_FIELD+ \")\\\"}\");\n+    final QueryResponse rsp = cluster.getSolrClient().query(solrQuery);\n+    // response shouldn't contain header as omitHeader is set to true\n+    assertNull(rsp.getResponseHeader());\n+  }\n   \n   public void testInclude_Upper() throws Exception {\n     for (boolean doSubFacet : Arrays.asList(false, true)) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java",
                "sha": "b11ff3ec9bba0e77732f6682d3812499586e7500",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/solr-ref-guide/src/common-query-parameters.adoc",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/common-query-parameters.adoc?ref=5ba6c0c7a2ed71fef321abee6b0fee13d93ea183",
                "deletions": 1,
                "filename": "solr/solr-ref-guide/src/common-query-parameters.adoc",
                "patch": "@@ -203,7 +203,27 @@ The default value of this parameter is blank, which causes no extra \"explain inf\n \n == timeAllowed Parameter\n \n-This parameter specifies the amount of time, in milliseconds, allowed for a search to complete. If this time expires before the search is complete, any partial results will be returned, but values such as `numFound`, <<faceting.adoc#faceting,facet>> counts, and result <<the-stats-component.adoc#the-stats-component,stats>> may not be accurate for the entire result set.\n+This parameter specifies the amount of time, in milliseconds, allowed for a search to complete. If this time expires before the search is complete, any partial results will be returned, but values such as `numFound`, <<faceting.adoc#faceting,facet>> counts, and result <<the-stats-component.adoc#the-stats-component,stats>> may not be accurate for the entire result set. In case of expiration, if `omitHeader` isn't set to `true` the response header contains a special flag called `partialResults`.\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+    \"status\": 0,\n+    \"zkConnected\": true,\n+    \"partialResults\": true,\n+    \"QTime\": 20,\n+    \"params\": {\n+      \"q\": \"*:*\"\n+    }\n+  },\n+  \"response\": {\n+    \"numFound\": 77,\n+    \"start\": 0,\n+    \"docs\": [ \"...\" ]\n+  }\n+}\n+----\n \n This value is only checked at the time of:\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ba6c0c7a2ed71fef321abee6b0fee13d93ea183/solr/solr-ref-guide/src/common-query-parameters.adoc",
                "sha": "aeb77df3c0170cbeca958ddf35120415ee2ca18e",
                "status": "modified"
            }
        ],
        "message": "SOLR-13509: add omitHeader=false for shards requests to avoid NPE on partialResuls check",
        "parent": "https://github.com/apache/lucene-solr/commit/608d9134ad519d7067858de489862f2bd9ce0969",
        "repo": "lucene-solr",
        "unit_tests": [
            "SearchHandlerTest.java"
        ]
    },
    "lucene-solr_5e6f22b": {
        "bug_id": "lucene-solr_5e6f22b",
        "commit": "https://github.com/apache/lucene-solr/commit/5e6f22b925add09dc20b7d53bf8f177a582a4ed1",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=5e6f22b925add09dc20b7d53bf8f177a582a4ed1",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -235,6 +235,9 @@ Bug Fixes\n * LUCENE-6998: Fix a couple places to better detect truncated index files\n   as corruption.  (Robert Muir, Mike McCandless)\n \n+* LUCENE-7002: Fixed MultiCollector to not throw a NPE if setScorer is called\n+  after one of the sub collectors is done collecting. (John Wang, Adrien Grand)\n+\n Other\n \n * LUCENE-6924: Upgrade randomizedtesting to 2.3.2. (Dawid Weiss)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/CHANGES.txt",
                "sha": "b729f770f727fe8ee35c7232b836299f50375a9f",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/core/src/java/org/apache/lucene/search/MultiCollector.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/MultiCollector.java?ref=5e6f22b925add09dc20b7d53bf8f177a582a4ed1",
                "deletions": 1,
                "filename": "lucene/core/src/java/org/apache/lucene/search/MultiCollector.java",
                "patch": "@@ -152,7 +152,8 @@ public void setScorer(Scorer scorer) throws IOException {\n       if (cacheScores) {\n         scorer = new ScoreCachingWrappingScorer(scorer);\n       }\n-      for (LeafCollector c : collectors) {\n+      for (int i = 0; i < numCollectors; ++i) {\n+        final LeafCollector c = collectors[i];\n         c.setScorer(scorer);\n       }\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/core/src/java/org/apache/lucene/search/MultiCollector.java",
                "sha": "81cd5942f569b6a28a391b07277ae702eadcc50d",
                "status": "modified"
            },
            {
                "additions": 71,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/core/src/test/org/apache/lucene/search/TestMultiCollector.java",
                "changes": 71,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestMultiCollector.java?ref=5e6f22b925add09dc20b7d53bf8f177a582a4ed1",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestMultiCollector.java",
                "patch": "@@ -19,9 +19,12 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.atomic.AtomicBoolean;\n \n import org.apache.lucene.document.Document;\n import org.apache.lucene.index.IndexReader;\n@@ -63,6 +66,27 @@ public void collect(int doc) throws IOException {\n     \n   }\n \n+  private static class SetScorerCollector extends FilterCollector {\n+\n+    private final AtomicBoolean setScorerCalled;\n+\n+    public SetScorerCollector(Collector in, AtomicBoolean setScorerCalled) {\n+      super(in);\n+      this.setScorerCalled = setScorerCalled;\n+    }\n+\n+    @Override\n+    public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n+      return new FilterLeafCollector(super.getLeafCollector(context)) {\n+        @Override\n+        public void setScorer(Scorer scorer) throws IOException {\n+          super.setScorer(scorer);\n+          setScorerCalled.set(true);\n+        }\n+      };\n+    }\n+  }\n+\n   public void testCollectionTerminatedExceptionHandling() throws IOException {\n     final int iters = atLeast(3);\n     for (int iter = 0; iter < iters; ++iter) {\n@@ -95,4 +119,51 @@ public void testCollectionTerminatedExceptionHandling() throws IOException {\n     }\n   }\n \n+  public void testSetScorerAfterCollectionTerminated() throws IOException {\n+    Collector collector1 = new TotalHitCountCollector();\n+    Collector collector2 = new TotalHitCountCollector();\n+\n+    AtomicBoolean setScorerCalled1 = new AtomicBoolean();\n+    collector1 = new SetScorerCollector(collector1, setScorerCalled1);\n+    \n+    AtomicBoolean setScorerCalled2 = new AtomicBoolean();\n+    collector2 = new SetScorerCollector(collector2, setScorerCalled2);\n+\n+    collector1 = new TerminateAfterCollector(collector1, 1);\n+    collector2 = new TerminateAfterCollector(collector2, 2);\n+\n+    Scorer scorer = new FakeScorer();\n+\n+    List<Collector> collectors = Arrays.asList(collector1, collector2);\n+    Collections.shuffle(collectors, random());\n+    Collector collector = MultiCollector.wrap(collectors);\n+\n+    LeafCollector leafCollector = collector.getLeafCollector(null);\n+    leafCollector.setScorer(scorer);\n+    assertTrue(setScorerCalled1.get());\n+    assertTrue(setScorerCalled2.get());\n+\n+    leafCollector.collect(0);\n+    leafCollector.collect(1);\n+\n+    setScorerCalled1.set(false);\n+    setScorerCalled2.set(false);\n+    leafCollector.setScorer(scorer);\n+    assertFalse(setScorerCalled1.get());\n+    assertTrue(setScorerCalled2.get());\n+\n+    try {\n+      leafCollector.collect(1);\n+      fail();\n+    } catch (CollectionTerminatedException e) {\n+      // expected\n+    }\n+\n+    setScorerCalled1.set(false);\n+    setScorerCalled2.set(false);\n+    leafCollector.setScorer(scorer);\n+    assertFalse(setScorerCalled1.get());\n+    assertFalse(setScorerCalled2.get());\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5e6f22b925add09dc20b7d53bf8f177a582a4ed1/lucene/core/src/test/org/apache/lucene/search/TestMultiCollector.java",
                "sha": "4ef54dac3d15239b9bbdabb3d08a199abc023415",
                "status": "modified"
            }
        ],
        "message": "LUCENE-7002: Fixed MultiCollector to not throw a NPE if setScorer is called after one of the sub collectors is done collecting.",
        "parent": "https://github.com/apache/lucene-solr/commit/23fe5f2dc574f36c17a6308da92858bc0420c1b8",
        "repo": "lucene-solr",
        "unit_tests": [
            "MultiCollectorTest.java",
            "TestMultiCollector.java"
        ]
    },
    "lucene-solr_5ea9310": {
        "bug_id": "lucene-solr_5ea9310",
        "commit": "https://github.com/apache/lucene-solr/commit/5ea93100216dd7e8b05a7ddd0fbc8507b037c4fc",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/5ea93100216dd7e8b05a7ddd0fbc8507b037c4fc/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java?ref=5ea93100216dd7e8b05a7ddd0fbc8507b037c4fc",
                "deletions": 1,
                "filename": "src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "patch": "@@ -293,7 +293,7 @@ private static String getFieldFlags( SchemaField f )\n       f.add( \"schema\", getFieldFlags( sfield ) );\n \n       // If numTerms==0, the call is just asking for a quick field list\n-      if( ttinfo != null ) {\n+      if( ttinfo != null && sfield != null && sfield.indexed() ) {\n         Query q = qp.parse( fieldName+\":[* TO *]\" ); \n         int docCount = searcher.numDocs( q, matchAllDocs );\n         if( docCount > 0 ) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/5ea93100216dd7e8b05a7ddd0fbc8507b037c4fc/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "sha": "1b6ddfc2e0efd76695b282ee6d933c2e750a5023",
                "status": "modified"
            }
        ],
        "message": "only search for fields solr knows about (otherwise you could get NPE for range query) -- also searching for non-indexed fields is useless.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@541824 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/6b26f007b2b2c97b66840b077eb9f6b0af90a0d3",
        "repo": "lucene-solr",
        "unit_tests": [
            "LukeRequestHandlerTest.java"
        ]
    },
    "lucene-solr_612d922": {
        "bug_id": "lucene-solr_612d922",
        "commit": "https://github.com/apache/lucene-solr/commit/612d9227dec4803fd648d605592ff72d9a2a2355",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/612d9227dec4803fd648d605592ff72d9a2a2355/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java?ref=612d9227dec4803fd648d605592ff72d9a2a2355",
                "deletions": 6,
                "filename": "lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "patch": "@@ -195,9 +195,6 @@ protected DocTermOrds(String field, int maxTermDocFreq, int indexIntervalBits) t\n    *  <p><b>NOTE</b>: you must pass the same reader that was\n    *  used when creating this class */\n   public TermsEnum getOrdTermsEnum(AtomicReader reader) throws IOException {\n-    if (termInstances == 0) {\n-      return null;\n-    }\n     if (indexedTermsArray == null) {\n       //System.out.println(\"GET normal enum\");\n       final Fields fields = reader.fields();\n@@ -511,9 +508,9 @@ protected void uninvert(final AtomicReader reader, final BytesRef termPrefix) th\n           break;\n       }\n \n-      if (indexedTerms != null) {\n-        indexedTermsArray = indexedTerms.toArray(new BytesRef[indexedTerms.size()]);\n-      }\n+    }\n+    if (indexedTerms != null) {\n+      indexedTermsArray = indexedTerms.toArray(new BytesRef[indexedTerms.size()]);\n     }\n \n     long endTime = System.currentTimeMillis();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/612d9227dec4803fd648d605592ff72d9a2a2355/lucene/core/src/java/org/apache/lucene/index/DocTermOrds.java",
                "sha": "4b120b6a47e98fc762d4cfca3a829490e3e49f39",
                "status": "modified"
            },
            {
                "additions": 252,
                "blob_url": "https://github.com/apache/lucene-solr/blob/612d9227dec4803fd648d605592ff72d9a2a2355/solr/core/src/test/org/apache/solr/TestRandomFaceting.java",
                "changes": 252,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/TestRandomFaceting.java?ref=612d9227dec4803fd648d605592ff72d9a2a2355",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/TestRandomFaceting.java",
                "patch": "@@ -0,0 +1,252 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr;\n+\n+import org.apache.lucene.search.FieldCache;\n+import org.apache.lucene.util._TestUtil;\n+import org.apache.noggit.JSONUtil;\n+import org.apache.noggit.ObjectBuilder;\n+import org.apache.solr.common.params.ModifiableSolrParams;\n+import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.schema.IndexSchema;\n+import org.apache.solr.schema.SchemaField;\n+import org.apache.solr.util.TestUtils;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.util.*;\n+\n+public class TestRandomFaceting extends SolrTestCaseJ4 {\n+\n+  public static final String FOO_STRING_FIELD = \"foo_s1\";\n+  public static final String SMALL_STRING_FIELD = \"small_s1\";\n+  public static final String SMALL_INT_FIELD = \"small_i\";\n+\n+  @BeforeClass\n+  public static void beforeTests() throws Exception {\n+    initCore(\"solrconfig.xml\",\"schema12.xml\");\n+  }\n+\n+\n+  int indexSize;\n+  List<FldType> types;\n+  Map<Comparable, Doc> model = null;\n+  boolean validateResponses = true;\n+\n+  void init() {\n+    Random rand = random();\n+    clearIndex();\n+    model = null;\n+    indexSize = rand.nextBoolean() ? (rand.nextInt(10) + 1) : (rand.nextInt(100) + 10);\n+\n+    types = new ArrayList<FldType>();\n+    types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n+    types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));\n+    types.add(new FldType(\"foo_i\",ZERO_ONE, new IRange(0,indexSize)));\n+    types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n+    types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n+    types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n+    types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n+    types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n+    types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n+    types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n+    types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n+\n+    types.add(new FldType(\"missing_i\",new IRange(0,0), new IRange(0,100)));\n+    types.add(new FldType(\"missing_is\",new IRange(0,0), new IRange(0,100)));\n+    types.add(new FldType(\"missing_s\",new IRange(0,0), new SVal('a','b',1,1)));\n+    types.add(new FldType(\"missing_ss\",new IRange(0,0), new SVal('a','b',1,1)));\n+\n+    // TODO: doubles, multi-floats, ints with precisionStep>0, booleans\n+  }\n+\n+  void addMoreDocs(int ndocs) throws Exception {\n+    model = indexDocs(types, model, ndocs);\n+  }\n+\n+  void deleteSomeDocs() throws Exception {\n+    Random rand = random();\n+    int percent = rand.nextInt(100);\n+    if (model == null) return;\n+    ArrayList<String> ids = new ArrayList<String>(model.size());\n+    for (Comparable id : model.keySet()) {\n+      if (rand.nextInt(100) < percent) {\n+        ids.add(id.toString());\n+      }\n+    }\n+    if (ids.size() == 0) return;\n+\n+    StringBuffer sb = new StringBuffer(\"id:(\");\n+    for (String id : ids) {\n+      sb.append(id).append(' ');\n+      model.remove(id);\n+    }\n+    sb.append(')');\n+\n+    assertU(delQ(sb.toString()));\n+\n+    if (rand.nextInt(10)==0) {\n+      assertU(optimize());\n+    } else {\n+      assertU(commit(\"softCommit\",\"\"+(rand.nextInt(10)!=0)));\n+    }\n+  }\n+\n+  @Test\n+  public void testRandomFaceting() throws Exception {\n+    try {\n+      Random rand = random();\n+      int iter = atLeast(100);\n+      init();\n+      addMoreDocs(0);\n+\n+      for (int i=0; i<iter; i++) {\n+        doFacetTests();\n+\n+        if (rand.nextInt(100) < 5) {\n+          init();\n+        }\n+\n+        addMoreDocs(rand.nextInt(indexSize) + 1);\n+\n+        if (rand.nextInt(100) < 50) {\n+          deleteSomeDocs();\n+        }\n+      }\n+    } finally {\n+      purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n+    }\n+  }\n+\n+\n+  void doFacetTests() throws Exception {\n+    for (FldType ftype : types) {\n+      doFacetTests(ftype);\n+    }\n+  }\n+\n+\n+  List<String> multiValuedMethods = Arrays.asList(new String[]{\"enum\",\"fc\"});\n+  List<String> singleValuedMethods = Arrays.asList(new String[]{\"enum\",\"fc\",\"fcs\"});\n+\n+\n+  void doFacetTests(FldType ftype) throws Exception {\n+    SolrQueryRequest req = req();\n+    try {\n+      Random rand = random();\n+      boolean validate = validateResponses;\n+      ModifiableSolrParams params = params(\"facet\",\"true\", \"wt\",\"json\", \"indent\",\"true\", \"omitHeader\",\"true\");\n+      params.add(\"q\",\"*:*\", \"rows\",\"0\");  // TODO: select subsets\n+      params.add(\"rows\",\"0\");\n+\n+\n+      SchemaField sf = req.getSchema().getField(ftype.fname);\n+      boolean multiValued = sf.getType().multiValuedFieldCache();\n+\n+      int offset = 0;\n+      if (rand.nextInt(100) < 20) {\n+        if (rand.nextBoolean()) {\n+          offset = rand.nextInt(100) < 10 ? rand.nextInt(indexSize*2) : rand.nextInt(indexSize/3+1);\n+        }\n+        params.add(\"facet.offset\", Integer.toString(offset));\n+      }\n+\n+      int limit = 100;\n+      if (rand.nextInt(100) < 20) {\n+        if (rand.nextBoolean()) {\n+          limit = rand.nextInt(100) < 10 ? rand.nextInt(indexSize/2+1) : rand.nextInt(indexSize*2);\n+        }\n+        params.add(\"facet.limit\", Integer.toString(limit));\n+      }\n+\n+      if (rand.nextBoolean()) {\n+        params.add(\"facet.sort\", rand.nextBoolean() ? \"index\" : \"count\");\n+      }\n+\n+      if ((ftype.vals instanceof SVal) && rand.nextInt(100) < 20) {\n+        // validate = false;\n+        String prefix = ftype.createValue().toString();\n+        if (rand.nextInt(100) < 5) prefix =  _TestUtil.randomUnicodeString(rand);\n+        else if (rand.nextInt(100) < 10) prefix = Character.toString((char)rand.nextInt(256));\n+        else if (prefix.length() > 0) prefix = prefix.substring(0, rand.nextInt(prefix.length()));\n+        params.add(\"facet.prefix\", prefix);\n+      }\n+\n+      if (rand.nextInt(100) < 10) {\n+        params.add(\"facet.mincount\", Integer.toString(rand.nextInt(5)));\n+      }\n+\n+      if (rand.nextInt(100) < 20) {\n+        params.add(\"facet.missing\", \"true\");\n+      }\n+\n+      // TODO: randomly add other facet params\n+      String key = ftype.fname;\n+      String facet_field = ftype.fname;\n+      if (random().nextBoolean()) {\n+        key = \"alternate_key\";\n+        facet_field = \"{!key=\"+key+\"}\"+ftype.fname;\n+      }\n+      params.set(\"facet.field\", facet_field);\n+\n+      List<String> methods = multiValued ? multiValuedMethods : singleValuedMethods;\n+      List<String> responses = new ArrayList<String>(methods.size());\n+      for (String method : methods) {\n+        // params.add(\"facet.field\", \"{!key=\"+method+\"}\" + ftype.fname);\n+        // TODO: allow method to be passed on local params?\n+\n+        params.set(\"facet.method\", method);\n+\n+        // if (random().nextBoolean()) params.set(\"facet.mincount\", \"1\");  // uncomment to test that validation fails\n+\n+        String strResponse = h.query(req(params));\n+        // Object realResponse = ObjectBuilder.fromJSON(strResponse);\n+        // System.out.println(strResponse);\n+\n+        responses.add(strResponse);\n+      }\n+\n+      /**\n+      String strResponse = h.query(req(params));\n+      Object realResponse = ObjectBuilder.fromJSON(strResponse);\n+      **/\n+\n+      if (validate) {\n+        for (int i=1; i<methods.size(); i++) {\n+          String err = JSONTestUtil.match(\"/\", responses.get(i), responses.get(0), 0.0);\n+          if (err != null) {\n+            log.error(\"ERROR: mismatch facet response: \" + err +\n+                \"\\n expected =\" + responses.get(0) +\n+                \"\\n response = \" + responses.get(i) +\n+                \"\\n request = \" + params\n+            );\n+            fail(err);\n+          }\n+        }\n+      }\n+\n+\n+    } finally {\n+      req.close();\n+    }\n+  }\n+\n+}\n+\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/612d9227dec4803fd648d605592ff72d9a2a2355/solr/core/src/test/org/apache/solr/TestRandomFaceting.java",
                "sha": "b4b1fa21489854aa3714eb583829741edd0b7a77",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/612d9227dec4803fd648d605592ff72d9a2a2355/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java?ref=612d9227dec4803fd648d605592ff72d9a2a2355",
                "deletions": 1,
                "filename": "solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java",
                "patch": "@@ -1154,7 +1154,11 @@ public Fld createField() {\n     if (random().nextInt(10)==0) {\n       assertU(optimize());\n     } else {\n-      assertU(commit());\n+      if (random().nextInt(10) == 0) {\n+        assertU(commit());\n+      } else {\n+        assertU(commit(\"softCommit\",\"true\"));\n+      }\n     }\n \n     // merging segments no longer selects just adjacent segments hence ids (doc.order) can be shuffled.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/612d9227dec4803fd648d605592ff72d9a2a2355/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java",
                "sha": "af666e5ed4c35da1566134e057c6dfb73c5a256e",
                "status": "modified"
            }
        ],
        "message": "SOLR-3427: fix NPE in UnInvertedField faceting\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1333125 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/0f7bc01bc585846f17dc5dfa0995f82bcae86ee5",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestDocTermOrds.java",
            "SolrTestCaseJ4Test.java",
            "TestSolrTestCaseJ4.java"
        ]
    },
    "lucene-solr_617028b": {
        "bug_id": "lucene-solr_617028b",
        "commit": "https://github.com/apache/lucene-solr/commit/617028b3c14e4684656ca937125dc06fede1913a",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/617028b3c14e4684656ca937125dc06fede1913a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java?ref=617028b3c14e4684656ca937125dc06fede1913a",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "patch": "@@ -186,7 +186,7 @@ public void process(WatchedEvent event) {\n           if (EventType.None.equals(event.getType())) {\n             return;\n           }\n-          log.info(\"A cluster state change has occurred - updating... ({})\", ZkStateReader.this.clusterState.getLiveNodes().size());\n+          log.info(\"A cluster state change has occurred - updating... ({})\", ZkStateReader.this.clusterState == null ? 0 : ZkStateReader.this.clusterState.getLiveNodes().size());\n           try {\n             \n             // delayed approach",
                "raw_url": "https://github.com/apache/lucene-solr/raw/617028b3c14e4684656ca937125dc06fede1913a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "sha": "05186f6433fa01050f7cfe495a03a50912ec05a1",
                "status": "modified"
            }
        ],
        "message": "avoid possible logging npe in race\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1411932 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/925dcb80bdb4fec19a8569cf42d68e80088b3e4c",
        "repo": "lucene-solr",
        "unit_tests": [
            "ZkStateReaderTest.java"
        ]
    },
    "lucene-solr_645fd55": {
        "bug_id": "lucene-solr_645fd55",
        "commit": "https://github.com/apache/lucene-solr/commit/645fd551f60b23779ff3c09eeedd9a9daf293ab2",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/645fd551f60b23779ff3c09eeedd9a9daf293ab2/src/java/org/apache/solr/spelling/SpellingQueryConverter.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/spelling/SpellingQueryConverter.java?ref=645fd551f60b23779ff3c09eeedd9a9daf293ab2",
                "deletions": 0,
                "filename": "src/java/org/apache/solr/spelling/SpellingQueryConverter.java",
                "patch": "@@ -21,6 +21,7 @@\n import java.io.StringReader;\n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n@@ -38,6 +39,9 @@\n \n \n   public Collection<Token> convert(String original) {\n+    if( original == null ) { // this can happen with q.alt = and no query\n+      return Collections.emptyList();\n+    }\n     Collection<Token> result = new ArrayList<Token>();\n     //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n     Matcher matcher = QUERY_REGEX.matcher(original);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/645fd551f60b23779ff3c09eeedd9a9daf293ab2/src/java/org/apache/solr/spelling/SpellingQueryConverter.java",
                "sha": "000c46e22dad1822a8bb366a5a23b042fe3ccbeb",
                "status": "modified"
            }
        ],
        "message": "SOLR-661 -- fix NPE when there is no query\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@679925 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/22cd8ef46f5ebd8580e398a9c622397438376020",
        "repo": "lucene-solr",
        "unit_tests": [
            "SpellingQueryConverterTest.java"
        ]
    },
    "lucene-solr_64bdf38": {
        "bug_id": "lucene-solr_64bdf38",
        "commit": "https://github.com/apache/lucene-solr/commit/64bdf38619cf04c029532b46ac84c50942317f2b",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/64bdf38619cf04c029532b46ac84c50942317f2b/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java?ref=64bdf38619cf04c029532b46ac84c50942317f2b",
                "deletions": 1,
                "filename": "lucene/src/java/org/apache/lucene/search/AutomatonQuery.java",
                "patch": "@@ -75,7 +75,8 @@ public AutomatonQuery(Term term, Automaton automaton) {\n     MinimizationOperations.minimize(automaton);\n   }\n \n-  private void compileAutomaton() {\n+  private synchronized void compileAutomaton() {\n+    // this method must be synchronized, as setting the three transient fields is not atomic:\n     if (runAutomaton == null) {\n       runAutomaton = new ByteRunAutomaton(automaton);\n       isFinite = SpecialOperations.isFinite(automaton);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/64bdf38619cf04c029532b46ac84c50942317f2b/lucene/src/java/org/apache/lucene/search/AutomatonQuery.java",
                "sha": "0d2d5ee2b20d3401594fccaf8bfaeb7b7ee4ab71",
                "status": "modified"
            }
        ],
        "message": "Make compileAutomaton synchronized, as it can break for queries that are shared constants (like a drop down list in a web interface that provides predefined query constraints. These types of queries are in most places somewhere predefined in your code and then used by different threads/servlets/whatever). As the three transient vars cannot be set atomically, a parallel running thread may see half of the fields assigned and will get NPE).\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@987118 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/cbc4a3a1cf1252569c25909ec58e5e89631e1249",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestAutomatonQuery.java"
        ]
    },
    "lucene-solr_68d16c2": {
        "bug_id": "lucene-solr_68d16c2",
        "commit": "https://github.com/apache/lucene-solr/commit/68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5/lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java?ref=68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5",
                "deletions": 3,
                "filename": "lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java",
                "patch": "@@ -121,9 +121,11 @@ public LeafCollector getLeafCollector(LeafReaderContext context) throws IOExcept\n \n       final LeafFieldComparator[] comparators = queue.getComparators(context);\n       final int[] reverseMul = queue.getReverseMul();\n+      final Sort indexSort = context.reader().getMetaData().getSort();\n       final boolean canEarlyTerminate = trackTotalHits == false &&\n           trackMaxScore == false &&\n-          canEarlyTerminate(sort, context.reader().getMetaData().getSort());\n+          indexSort != null &&\n+          canEarlyTerminate(sort, indexSort);\n       final int initialTotalHits = totalHits;\n \n       return new MultiComparatorLeafCollector(comparators, reverseMul, mayNeedScoresTwice) {\n@@ -212,7 +214,9 @@ public PagingFieldCollector(Sort sort, FieldValueHitQueue<Entry> queue, FieldDoc\n       this.trackTotalHits = trackTotalHits;\n \n       // Must set maxScore to NEG_INF, or otherwise Math.max always returns NaN.\n-      maxScore = Float.NEGATIVE_INFINITY;\n+      if (trackMaxScore) {\n+        maxScore = Float.NEGATIVE_INFINITY;\n+      }\n \n       FieldComparator<?>[] comparators = queue.comparators;\n       // Tell all comparators their top value:\n@@ -227,9 +231,11 @@ public PagingFieldCollector(Sort sort, FieldValueHitQueue<Entry> queue, FieldDoc\n     public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n       docBase = context.docBase;\n       final int afterDoc = after.doc - docBase;\n+      final Sort indexSort = context.reader().getMetaData().getSort();\n       final boolean canEarlyTerminate = trackTotalHits == false &&\n           trackMaxScore == false &&\n-          canEarlyTerminate(sort, context.reader().getMetaData().getSort());\n+          indexSort != null &&\n+          canEarlyTerminate(sort, indexSort);\n       final int initialTotalHits = totalHits;\n       return new MultiComparatorLeafCollector(queue.getComparators(context), queue.getReverseMul(), mayNeedScoresTwice) {\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5/lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java",
                "sha": "3d85277fcb0415e8d2acf67f3c7813c02f71d055",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5/lucene/core/src/test/org/apache/lucene/search/TestTopFieldCollector.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestTopFieldCollector.java?ref=68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestTopFieldCollector.java",
                "patch": "@@ -102,6 +102,31 @@ public void testSortWithoutScoreTracking() throws Exception {\n       assertTrue(Float.isNaN(td.getMaxScore()));\n     }\n   }\n+\n+  public void testSortWithoutTotalHitTracking() throws Exception {\n+    Sort sort = new Sort(SortField.FIELD_DOC);\n+    for(int i = 0; i < 2; i++) {\n+      Query q = new MatchAllDocsQuery();\n+      // check that setting trackTotalHits to false does not throw an NPE because\n+      // the index is not sorted\n+      TopDocsCollector<Entry> tdc;\n+      if (i % 2 == 0) {\n+        tdc =  TopFieldCollector.create(sort, 10, true, false, false, false);\n+      } else {\n+        FieldDoc fieldDoc = new FieldDoc(1, Float.NaN, new Object[] { 1 });\n+        tdc = TopFieldCollector.create(sort, 10, fieldDoc, true, false, false, false);\n+      }\n+\n+      is.search(q, tdc);\n+\n+      TopDocs td = tdc.topDocs();\n+      ScoreDoc[] sd = td.scoreDocs;\n+      for(int j = 0; j < sd.length; j++) {\n+        assertTrue(Float.isNaN(sd[j].score));\n+      }\n+      assertTrue(Float.isNaN(td.getMaxScore()));\n+    }\n+  }\n   \n   public void testSortWithScoreNoMaxScoreTracking() throws Exception {\n     ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/68d16c2a65b4acd0ce1ca543ae53a82e2516f1e5/lucene/core/src/test/org/apache/lucene/search/TestTopFieldCollector.java",
                "sha": "d8363f7cfd8392abdbf385e598c43a7181bce82f",
                "status": "modified"
            }
        ],
        "message": "LUCENE-8082: Fix NPE in TopFieldCollectors that don't track total hit count",
        "parent": "https://github.com/apache/lucene-solr/commit/4fc5a872ded98522dd673de671ad28e1a6f495d7",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestTopFieldCollector.java"
        ]
    },
    "lucene-solr_6abb23b": {
        "bug_id": "lucene-solr_6abb23b",
        "commit": "https://github.com/apache/lucene-solr/commit/6abb23b22b12457f85beae879656a7908ef663cc",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/6abb23b22b12457f85beae879656a7908ef663cc/solr/core/src/java/org/apache/solr/handler/admin/SystemInfoHandler.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/SystemInfoHandler.java?ref=6abb23b22b12457f85beae879656a7908ef663cc",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/SystemInfoHandler.java",
                "patch": "@@ -95,7 +95,8 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n     if (solrCloudMode) {\n       rsp.add(\"zkHost\", getCoreContainer(req, core).getZkController().getZkServerAddress());\n     }\n-    rsp.add( \"solr_home\", cc.getSolrHome());\n+    if (cc != null)\n+      rsp.add( \"solr_home\", cc.getSolrHome());\n     rsp.add( \"lucene\", getLuceneInfo() );\n     rsp.add( \"jvm\", getJvmInfo() );\n     rsp.add( \"system\", getSystemInfo() );",
                "raw_url": "https://github.com/apache/lucene-solr/raw/6abb23b22b12457f85beae879656a7908ef663cc/solr/core/src/java/org/apache/solr/handler/admin/SystemInfoHandler.java",
                "sha": "1bb2a6e61d37c7cad31f68cef26e523578095f2e",
                "status": "modified"
            }
        ],
        "message": "SOLR-3619: Fix NPE during unit tests\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1642017 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/f8cd5c66889664170d8e2e8b6851153b7f67213f",
        "repo": "lucene-solr",
        "unit_tests": [
            "SystemInfoHandlerTest.java"
        ]
    },
    "lucene-solr_6d4867e": {
        "bug_id": "lucene-solr_6d4867e",
        "commit": "https://github.com/apache/lucene-solr/commit/6d4867eca0ac9f562d89ad8ade5c3bb4067f69af",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/6d4867eca0ac9f562d89ad8ade5c3bb4067f69af/solr/src/java/org/apache/solr/handler/CSVRequestHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/handler/CSVRequestHandler.java?ref=6d4867eca0ac9f562d89ad8ade5c3bb4067f69af",
                "deletions": 1,
                "filename": "solr/src/java/org/apache/solr/handler/CSVRequestHandler.java",
                "patch": "@@ -307,7 +307,7 @@ void prepareFields() {\n         String encStr = params.getFieldParam(fname,ENCAPSULATOR);\n         char fenc = encStr==null || encStr.length()==0 ? (char)-2 : encStr.charAt(0);\n         String escStr = params.getFieldParam(fname,ESCAPE);\n-        char fesc = escStr==null || encStr.length()==0 ? CSVStrategy.ESCAPE_DISABLED : escStr.charAt(0);\n+        char fesc = escStr==null || escStr.length()==0 ? CSVStrategy.ESCAPE_DISABLED : escStr.charAt(0);\n \n         CSVStrategy fstrat = new CSVStrategy(fsep,fenc,CSVStrategy.COMMENTS_DISABLED,fesc, false, false, false, false);\n         adders[i] = new CSVLoader.FieldSplitter(fstrat, adders[i]);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/6d4867eca0ac9f562d89ad8ade5c3bb4067f69af/solr/src/java/org/apache/solr/handler/CSVRequestHandler.java",
                "sha": "b46eb41cb9fd6daf52e66fdd250b8ad933dd69cc",
                "status": "modified"
            }
        ],
        "message": "SOLR-2264: CSVRequestHandler can throw NPE when no escape parameter is specified for splitting\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1041963 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/8ec36c3f567662cdc8f16fb0e787d829719f7538",
        "repo": "lucene-solr",
        "unit_tests": [
            "CSVRequestHandlerTest.java"
        ]
    },
    "lucene-solr_6f6a6c2": {
        "bug_id": "lucene-solr_6f6a6c2",
        "commit": "https://github.com/apache/lucene-solr/commit/6f6a6c2b093ed8e3aabc9476afdc2bce569deeda",
        "file": [
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/6f6a6c2b093ed8e3aabc9476afdc2bce569deeda/lucene/src/java/org/apache/lucene/search/SearcherManager.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/java/org/apache/lucene/search/SearcherManager.java?ref=6f6a6c2b093ed8e3aabc9476afdc2bce569deeda",
                "deletions": 1,
                "filename": "lucene/src/java/org/apache/lucene/search/SearcherManager.java",
                "patch": "@@ -159,7 +159,13 @@ public boolean maybeReopen() throws IOException {\n       try {\n         // IR.openIfChanged preserves NRT and applyDeletes\n         // in the newly returned reader:\n-        final IndexReader newReader = IndexReader.openIfChanged(currentSearcher.getIndexReader());\n+        final IndexReader newReader;\n+        final IndexSearcher searcherToReopen = acquire();\n+        try {\n+          newReader = IndexReader.openIfChanged(searcherToReopen.getIndexReader());\n+        } finally {\n+          release(searcherToReopen);\n+        }\n         if (newReader != null) {\n           final IndexSearcher newSearcher = new IndexSearcher(newReader, es);\n           boolean success = false;\n@@ -246,6 +252,10 @@ private void ensureOpen() {\n \n   private synchronized void swapSearcher(IndexSearcher newSearcher) throws IOException {\n     ensureOpen();\n+    // Don't allow un-closing!\n+    if (currentSearcher == null && newSearcher != null) {\n+      throw new AlreadyClosedException(\"this SearcherManager is closed\");\n+    }\n     final IndexSearcher oldSearcher = currentSearcher;\n     currentSearcher = newSearcher;\n     release(oldSearcher);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/6f6a6c2b093ed8e3aabc9476afdc2bce569deeda/lucene/src/java/org/apache/lucene/search/SearcherManager.java",
                "sha": "ee7ff11a6de227a8c3ba8e4c2b9d8f4c92a24c22",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/6f6a6c2b093ed8e3aabc9476afdc2bce569deeda/lucene/src/test/org/apache/lucene/search/TestSearcherManager.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/test/org/apache/lucene/search/TestSearcherManager.java?ref=6f6a6c2b093ed8e3aabc9476afdc2bce569deeda",
                "deletions": 3,
                "filename": "lucene/src/test/org/apache/lucene/search/TestSearcherManager.java",
                "patch": "@@ -237,9 +237,7 @@ public void run() {\n     });\n     thread.start();\n     awaitEnterWarm.await();\n-    for (int i = 0; i < 2; i++) {\n-      searcherManager.close();\n-    }\n+    searcherManager.close();\n     awaitClose.countDown();\n     thread.join();\n     try {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/6f6a6c2b093ed8e3aabc9476afdc2bce569deeda/lucene/src/test/org/apache/lucene/search/TestSearcherManager.java",
                "sha": "47d38c6656e1adee744c483a54d66c2a0fc33fcd",
                "status": "modified"
            }
        ],
        "message": "throw ACE not NPE if you close while maybeReopen runs\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1208525 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/a1aefefdd90d5f48bfe78b06b9fea093db5625e7",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSearcherManager.java"
        ]
    },
    "lucene-solr_6f99196": {
        "bug_id": "lucene-solr_6f99196",
        "commit": "https://github.com/apache/lucene-solr/commit/6f99196e816761706e616325b3b2399867c571cc",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/6f99196e816761706e616325b3b2399867c571cc/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java?ref=6f99196e816761706e616325b3b2399867c571cc",
                "deletions": 6,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "patch": "@@ -986,15 +986,11 @@ public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<\n \n       // if the state was stale, then we retry the request once with new state pulled from Zk\n       if (stateWasStale) {\n-        log.warn(\"Re-trying request to  collection(s) \"+inputCollections+\" after stale state error from server.\");\n+        log.warn(\"Re-trying request to collection(s) \"+inputCollections+\" after stale state error from server.\");\n         resp = requestWithRetryOnStaleState(request, retryCount+1, inputCollections);\n       } else {\n-        if(exc instanceof SolrException) {\n+        if (exc instanceof SolrException || exc instanceof SolrServerException || exc instanceof IOException) {\n           throw exc;\n-        } if (exc instanceof SolrServerException) {\n-          throw (SolrServerException)exc;\n-        } else if (exc instanceof IOException) {\n-          throw (IOException)exc;\n         } else {\n           throw new SolrServerException(rootCause);\n         }\n@@ -1059,6 +1055,9 @@ public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<\n       String shardKeys = reqParams.get(ShardParams._ROUTE_);\n       for (String collectionName : collectionNames) {\n         DocCollection col = getDocCollection(collectionName, null);\n+        if (col == null) {\n+          throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection not found: \" + collectionName);\n+        }\n         Collection<Slice> routeSlices = col.getRouter().getSearchSlices(shardKeys, reqParams , col);\n         ClientUtils.addSlices(slices, collectionName, routeSlices, true);\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/6f99196e816761706e616325b3b2399867c571cc/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "sha": "2432fb22d7e8d586714a6c77a7b161d75d522247",
                "status": "modified"
            }
        ],
        "message": "SOLR-11444: CloudSolrClient could have thrown an NPE if the collection doesn't exist.\nRefactor: Tidy the exception throwing",
        "parent": "https://github.com/apache/lucene-solr/commit/51b2dea68e291141e2bfb98a2e07420a6b5869b2",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudSolrClientTest.java"
        ]
    },
    "lucene-solr_70cfe46": {
        "bug_id": "lucene-solr_70cfe46",
        "commit": "https://github.com/apache/lucene-solr/commit/70cfe46689448e9e7c53ff50572ceadaf03325fc",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/70cfe46689448e9e7c53ff50572ceadaf03325fc/lucene/test-framework/src/java/org/apache/lucene/mockfile/WindowsFS.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/java/org/apache/lucene/mockfile/WindowsFS.java?ref=70cfe46689448e9e7c53ff50572ceadaf03325fc",
                "deletions": 8,
                "filename": "lucene/test-framework/src/java/org/apache/lucene/mockfile/WindowsFS.java",
                "patch": "@@ -138,14 +138,16 @@ public void move(Path source, Path target, CopyOption... options) throws IOExcep\n           // return a different i-node next time we call it with the target path and our onClose method will\n           // trip an assert\n           Map<Path, Integer> map = openFiles.get(key);\n-          Integer v = map.remove(target);\n-          if (v != null) {\n-            Map<Path, Integer> pathIntegerMap = openFiles.computeIfAbsent(newKey, k -> new HashMap<>());\n-            Integer existingValue = pathIntegerMap.getOrDefault(target, 0);\n-            pathIntegerMap.put(target, existingValue + v);\n-          }\n-          if (map.isEmpty()) {\n-            openFiles.remove(key);\n+          if (map != null) {\n+            Integer v = map.remove(target);\n+            if (v != null) {\n+              Map<Path, Integer> pathIntegerMap = openFiles.computeIfAbsent(newKey, k -> new HashMap<>());\n+              Integer existingValue = pathIntegerMap.getOrDefault(target, 0);\n+              pathIntegerMap.put(target, existingValue + v);\n+            }\n+            if (map.isEmpty()) {\n+              openFiles.remove(key);\n+            }\n           }\n         }\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/70cfe46689448e9e7c53ff50572ceadaf03325fc/lucene/test-framework/src/java/org/apache/lucene/mockfile/WindowsFS.java",
                "sha": "28ca3686c06bfcb67e082bedac496db9628630e8",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/70cfe46689448e9e7c53ff50572ceadaf03325fc/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestWindowsFS.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestWindowsFS.java?ref=70cfe46689448e9e7c53ff50572ceadaf03325fc",
                "deletions": 2,
                "filename": "lucene/test-framework/src/test/org/apache/lucene/mockfile/TestWindowsFS.java",
                "patch": "@@ -31,8 +31,6 @@\n import java.util.concurrent.CyclicBarrier;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n-import org.apache.lucene.mockfile.FilterPath;\n-import org.apache.lucene.mockfile.WindowsFS;\n import org.apache.lucene.util.Constants;\n \n /** Basic tests for WindowsFS */\n@@ -155,4 +153,27 @@ public void run() {\n       t.join();\n     }\n   }\n+\n+  public void testMove() throws IOException {\n+    Path dir = wrap(createTempDir());\n+    OutputStream file = Files.newOutputStream(dir.resolve(\"file\"));\n+    file.write(1);\n+    file.close();\n+    Files.move(dir.resolve(\"file\"), dir.resolve(\"target\"));\n+    assertTrue(Files.exists(dir.resolve(\"target\")));\n+    assertFalse(Files.exists(dir.resolve(\"file\")));\n+    try (InputStream stream = Files.newInputStream(dir.resolve(\"target\"))) {\n+      assertEquals(1, stream.read());\n+    }\n+    file = Files.newOutputStream(dir.resolve(\"otherFile\"));\n+    file.write(2);\n+    file.close();\n+\n+    Files.move(dir.resolve(\"otherFile\"), dir.resolve(\"target\"), StandardCopyOption.REPLACE_EXISTING);\n+    assertTrue(Files.exists(dir.resolve(\"target\")));\n+    assertFalse(Files.exists(dir.resolve(\"otherFile\")));\n+    try (InputStream stream = Files.newInputStream(dir.resolve(\"target\"))) {\n+      assertEquals(2, stream.read());\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/70cfe46689448e9e7c53ff50572ceadaf03325fc/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestWindowsFS.java",
                "sha": "dd6c35cee17aff00d2d835544a69ab464384185d",
                "status": "modified"
            }
        ],
        "message": "LUCENE-8320: Fix NPE in WindowsFS if target file exists but isn't open",
        "parent": "https://github.com/apache/lucene-solr/commit/82ad857f1af67c99fd8b979bf5a4c99b32e91f3c",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestWindowsFS.java"
        ]
    },
    "lucene-solr_71a8203": {
        "bug_id": "lucene-solr_71a8203",
        "commit": "https://github.com/apache/lucene-solr/commit/71a8203a063c995cb0a5e3b06773aea6c82ee0d2",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=71a8203a063c995cb0a5e3b06773aea6c82ee0d2",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -170,6 +170,9 @@ Bug Fixes\n * SOLR-3779: DataImportHandler's LineEntityProcessor when used in conjunction \n   with FileListEntityProcessor would only process the first file.\n   (Ahmet Arslan via James Dyer)\n+  \n+* SOLR-3791: CachedSqlEntityProcessor would throw a NullPointerException when \n+  a query returns a row with a NULL key.  (Steffen Moelter via James Dyer)\n \n Other Changes\n ----------------------",
                "raw_url": "https://github.com/apache/lucene-solr/raw/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/CHANGES.txt",
                "sha": "478fabdd75463b164051a2b931c78b528ca21445",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SortedMapBackedCache.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SortedMapBackedCache.java?ref=71a8203a063c995cb0a5e3b06773aea6c82ee0d2",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SortedMapBackedCache.java",
                "patch": "@@ -54,6 +54,10 @@ public void add(Map<String,Object> rec) {\n       }\n       pk = c.iterator().next();\n     }\n+    //Rows with null keys are not added.\n+    if(pk==null) {\n+      return;\n+    }\n     List<Map<String,Object>> thisKeysRecs = theMap.get(pk);\n     if (thisKeysRecs == null) {\n       thisKeysRecs = new ArrayList<Map<String,Object>>();\n@@ -87,6 +91,9 @@ public void close() {\n   public void delete(Object key) {\n     checkOpen(true);\n     checkReadOnly();\n+    if(key==null) {\n+      return;\n+    }\n     theMap.remove(key);\n   }\n   \n@@ -120,6 +127,9 @@ public void flush() {\n   @Override\n   public Iterator<Map<String,Object>> iterator(Object key) {\n     checkOpen(true);\n+    if(key==null) {\n+      return null;\n+    }\n     if(key instanceof Iterable<?>) {\n       List<Map<String,Object>> vals = new ArrayList<Map<String,Object>>();\n       Iterator<?> iter = ((Iterable<?>) key).iterator();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SortedMapBackedCache.java",
                "sha": "109b6d5ba85d59b195c256dc719c8320991803cb",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/lucene-solr/blob/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache.java?ref=71a8203a063c995cb0a5e3b06773aea6c82ee0d2",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.math.BigDecimal;\n import java.util.ArrayList;\n import java.util.HashMap;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n \n@@ -71,6 +72,37 @@ public void testCacheWithOrderedLookup() {\n \t\t\t}\n \t\t}\n \t}\n+\t\n+\t@Test\n+\tpublic void testNullKeys() throws Exception {\n+\t  //A null key should just be ignored, but not throw an exception\n+\t  DIHCache cache = null;\n+\t  try {\n+\t    cache = new SortedMapBackedCache();\n+\t    Map<String, String> cacheProps = new HashMap<String, String>();\n+      cacheProps.put(DIHCacheSupport.CACHE_PRIMARY_KEY, \"a_id\");\n+      cache.open(getContext(cacheProps));\n+      \n+      Map<String,Object> data = new HashMap<String,Object>();\n+      data.put(\"a_id\", null);\n+      data.put(\"bogus\", \"data\");\n+      cache.add(data);\n+      \n+      Iterator<Map<String, Object>> cacheIter = cache.iterator();\n+      while (cacheIter.hasNext()) {\n+        Assert.fail(\"cache should be empty.\");\n+      }\n+      Assert.assertNull(cache.iterator(null));\n+      cache.delete(null);      \n+\t  } catch (Exception e) {\n+\t    throw e;\n+    } finally {\n+      try {\n+        cache.destroy();\n+      } catch (Exception ex) {\n+      }\n+    }\t  \n+\t}\n \n \t@Test\n \tpublic void testCacheReopensWithUpdate() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/71a8203a063c995cb0a5e3b06773aea6c82ee0d2/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSortedMapBackedCache.java",
                "sha": "2cf83f4d81527e6b91cc7d739619228dadc0b61d",
                "status": "modified"
            }
        ],
        "message": "SOLR-3791: CachedSqlEntityProcessor throws NPE when pk column is Null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1384819 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/e312ee6bfa89b0658f86b11c9724e9b9a6d91c04",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSortedMapBackedCache.java"
        ]
    },
    "lucene-solr_751a5c8": {
        "bug_id": "lucene-solr_751a5c8",
        "commit": "https://github.com/apache/lucene-solr/commit/751a5c814cb86ef9739ff7474f5a9ac19ad83d92",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/core/src/test/org/apache/solr/handler/V2ApiIntegrationTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/V2ApiIntegrationTest.java?ref=751a5c814cb86ef9739ff7474f5a9ac19ad83d92",
                "deletions": 7,
                "filename": "solr/core/src/test/org/apache/solr/handler/V2ApiIntegrationTest.java",
                "patch": "@@ -27,6 +27,7 @@\n import org.apache.solr.client.solrj.impl.CloudSolrClient;\n import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n import org.apache.solr.client.solrj.request.V2Request;\n+import org.apache.solr.client.solrj.response.V2Response;\n import org.apache.solr.cloud.SolrCloudTestCase;\n import org.apache.solr.common.params.ModifiableSolrParams;\n import org.apache.solr.common.util.NamedList;\n@@ -49,14 +50,11 @@ public static void createCluster() throws Exception {\n \n   @Test\n   public void testWelcomeMessage() throws Exception {\n-    NamedList res = cluster.getSolrClient().request(\n-        new V2Request.Builder(\"\").build());\n-    NamedList header = (NamedList) res.get(\"responseHeader\");\n-    assertEquals(0, header.get(\"status\"));\n+    V2Response res = new V2Request.Builder(\"\").build().process(cluster.getSolrClient());\n+    assertEquals(0, res.getStatus());\n \n-    res = cluster.getSolrClient().request(new V2Request.Builder(\"/_introspect\").build());\n-    header = (NamedList) res.get(\"responseHeader\");\n-    assertEquals(0, header.get(\"status\"));\n+    res = new V2Request.Builder(\"/_introspect\").build().process(cluster.getSolrClient());\n+    assertEquals(0, res.getStatus());\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/lucene-solr/raw/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/core/src/test/org/apache/solr/handler/V2ApiIntegrationTest.java",
                "sha": "5a8d4820b388db7b781d239b11e5539785521cd2",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/solrj/src/java/org/apache/solr/client/solrj/request/V2Request.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/request/V2Request.java?ref=751a5c814cb86ef9739ff7474f5a9ac19ad83d92",
                "deletions": 4,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/request/V2Request.java",
                "patch": "@@ -28,14 +28,14 @@\n \n import org.apache.solr.client.solrj.SolrClient;\n import org.apache.solr.client.solrj.SolrRequest;\n-import org.apache.solr.client.solrj.SolrResponse;\n+import org.apache.solr.client.solrj.response.V2Response;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.SolrParams;\n import org.apache.solr.common.util.ContentStream;\n import org.apache.solr.common.util.ContentStreamBase;\n import org.apache.solr.common.util.Utils;\n \n-public class V2Request extends SolrRequest {\n+public class V2Request extends SolrRequest<V2Response> {\n   //only for debugging purposes\n   public static final ThreadLocal<AtomicLong> v2Calls = new ThreadLocal<>();\n   static final Pattern COLL_REQ_PATTERN = Pattern.compile(\"/(c|collections)/[^/]+/(?!shards)\");\n@@ -77,8 +77,8 @@ public boolean isPerCollectionRequest() {\n   }\n \n   @Override\n-  protected SolrResponse createResponse(SolrClient client) {\n-    return null;\n+  protected V2Response createResponse(SolrClient client) {\n+    return new V2Response();\n   }\n \n   public static class Builder {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/solrj/src/java/org/apache/solr/client/solrj/request/V2Request.java",
                "sha": "39220d1fa3d248a4ab2894ffb825322cfb4c4d57",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/solrj/src/java/org/apache/solr/client/solrj/response/V2Response.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/response/V2Response.java?ref=751a5c814cb86ef9739ff7474f5a9ac19ad83d92",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/response/V2Response.java",
                "patch": "@@ -0,0 +1,22 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.response;\n+\n+public class V2Response extends SolrResponseBase {\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/751a5c814cb86ef9739ff7474f5a9ac19ad83d92/solr/solrj/src/java/org/apache/solr/client/solrj/response/V2Response.java",
                "sha": "bd9ca9cdd4bed6bec87359cd276858b129f037d1",
                "status": "added"
            }
        ],
        "message": "SOLR-10886: Using V2Request.process(solrClient) method throws NPE if the API returns an error",
        "parent": "https://github.com/apache/lucene-solr/commit/e1d4ec798732b30a3bd87f72beb98465a8735376",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestV2Request.java"
        ]
    },
    "lucene-solr_788d519": {
        "bug_id": "lucene-solr_788d519",
        "commit": "https://github.com/apache/lucene-solr/commit/788d519b89ad485f076f5ed7b79c8a061fa4f1af",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/788d519b89ad485f076f5ed7b79c8a061fa4f1af/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java?ref=788d519b89ad485f076f5ed7b79c8a061fa4f1af",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "patch": "@@ -19,6 +19,7 @@\n \n import org.apache.lucene.index.ExitableDirectoryReader;\n import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrDocumentList;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.SolrException.ErrorCode;\n import org.apache.solr.common.params.CommonParams;\n@@ -244,6 +245,17 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n         }\n       } catch (ExitableDirectoryReader.ExitingReaderException ex) {\n         log.warn( \"Query: \" + req.getParamString() + \"; \" + ex.getMessage());\n+        SolrDocumentList r = (SolrDocumentList) rb.rsp.getValues().get(\"response\");\n+        if(r == null)\n+          r = new SolrDocumentList();\n+        r.setNumFound(0);\n+        rb.rsp.add(\"response\", r);\n+        if(rb.isDebug()) {\n+          NamedList debug = new NamedList();\n+          debug.add(\"explain\", new NamedList());\n+          rb.rsp.add(\"debug\", debug);\n+        }\n+        rb.rsp.getResponseHeader().add(\"partialResults\", Boolean.TRUE);\n       } finally {\n         SolrQueryTimeoutImpl.reset();\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/788d519b89ad485f076f5ed7b79c8a061fa4f1af/solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java",
                "sha": "a72f970d95185bedd7fa6fdd29215952feb681a1",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/788d519b89ad485f076f5ed7b79c8a061fa4f1af/solr/core/src/java/org/apache/solr/search/grouping/distributed/responseprocessor/TopGroupsShardResponseProcessor.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/grouping/distributed/responseprocessor/TopGroupsShardResponseProcessor.java?ref=788d519b89ad485f076f5ed7b79c8a061fa4f1af",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/search/grouping/distributed/responseprocessor/TopGroupsShardResponseProcessor.java",
                "patch": "@@ -120,6 +120,8 @@ public void process(ResponseBuilder rb, ShardRequest shardRequest) {\n         continue; // continue if there was an error and we're tolerant.  \n       }\n       NamedList<NamedList> secondPhaseResult = (NamedList<NamedList>) srsp.getSolrResponse().getResponse().get(\"secondPhase\");\n+      if(secondPhaseResult == null)\n+        continue;\n       Map<String, ?> result = serializer.transformToNative(secondPhaseResult, groupSort, sortWithinGroup, srsp.getShard());\n       int numFound = 0;\n       float maxScore = Float.NaN;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/788d519b89ad485f076f5ed7b79c8a061fa4f1af/solr/core/src/java/org/apache/solr/search/grouping/distributed/responseprocessor/TopGroupsShardResponseProcessor.java",
                "sha": "63fbeb6ceec83c51285b2c424ae540638c92e885",
                "status": "modified"
            }
        ],
        "message": "SOLR-6623: Fixing NPE in StoredFieldsShardResponseProcessor when using timeAllowed\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1633053 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/72df7212369b6694d0102dba7e9c9d9dcb53e77a",
        "repo": "lucene-solr",
        "unit_tests": [
            "SearchHandlerTest.java"
        ]
    },
    "lucene-solr_7a19128": {
        "bug_id": "lucene-solr_7a19128",
        "commit": "https://github.com/apache/lucene-solr/commit/7a19128109d9b40b28a09a59efa718d63f7a31e9",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java?ref=7a19128109d9b40b28a09a59efa718d63f7a31e9",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "patch": "@@ -43,12 +43,12 @@\n    * otherwise we prefer the stored value when we have a choice.\n    */\n   void optimize(SolrDocumentFetcher docFetcher) {\n-    optimize(docFetcher.getAllSingleDV());\n+    optimize(docFetcher.getDvsCanSubstituteStored());\n   }\n \n-  void optimize(Set<String> singleDVs) {\n+  void optimize(Set<String> dvsCanSubstituteStored) {\n     if (storedFields == null) return;\n-    if (!singleDVs.containsAll(storedFields)) return;\n+    if (!dvsCanSubstituteStored.containsAll(storedFields)) return;\n     dvFields.addAll(storedFields);\n     storedFields.clear();\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "sha": "f143b94070842d0778042db4e684a0f90bd9cd21",
                "status": "modified"
            },
            {
                "additions": 130,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/java/org/apache/solr/search/SolrDocumentFetcher.java",
                "changes": 279,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SolrDocumentFetcher.java?ref=7a19128109d9b40b28a09a59efa718d63f7a31e9",
                "deletions": 149,
                "filename": "solr/core/src/java/org/apache/solr/search/SolrDocumentFetcher.java",
                "patch": "@@ -59,10 +59,6 @@\n import org.apache.solr.schema.AbstractEnumField;\n import org.apache.solr.schema.NumberType;\n import org.apache.solr.schema.SchemaField;\n-import org.apache.solr.schema.TrieDateField;\n-import org.apache.solr.schema.TrieDoubleField;\n-import org.apache.solr.schema.TrieFloatField;\n-import org.apache.solr.schema.TrieIntField;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -82,7 +78,7 @@\n \n   private final Set<String> allStored;\n \n-  private final Set<String> allSingleDV;\n+  private final Set<String> dvsCanSubstituteStored;\n \n   /** Contains the names/patterns of all docValues=true,stored=false fields in the schema. */\n   private final Set<String> allNonStoredDVs;\n@@ -112,16 +108,16 @@\n     final Set<String> allNonStoredDVs = new HashSet<>();\n     final Set<String> nonStoredDVsWithoutCopyTargets = new HashSet<>();\n     final Set<String> storedLargeFields = new HashSet<>();\n-    final Set<String> allSingleDVs = new HashSet<>();\n+    final Set<String> dvsCanSubstituteStored = new HashSet<>();\n     final Set<String> allStoreds = new HashSet<>();\n \n     for (FieldInfo fieldInfo : searcher.getFieldInfos()) { // can find materialized dynamic fields, unlike using the Solr IndexSchema.\n       final SchemaField schemaField = searcher.getSchema().getFieldOrNull(fieldInfo.name);\n       if (schemaField == null) {\n         continue;\n       }\n-      if (schemaField.hasDocValues() && !schemaField.multiValued()) {\n-        allSingleDVs.add(fieldInfo.name);\n+      if (canSubstituteDvForStored(fieldInfo, schemaField)) {\n+        dvsCanSubstituteStored.add(fieldInfo.name);\n       }\n       if (schemaField.stored()) {\n         allStoreds.add(fieldInfo.name);\n@@ -144,10 +140,22 @@\n     this.allNonStoredDVs = Collections.unmodifiableSet(allNonStoredDVs);\n     this.nonStoredDVsWithoutCopyTargets = Collections.unmodifiableSet(nonStoredDVsWithoutCopyTargets);\n     this.largeFields = Collections.unmodifiableSet(storedLargeFields);\n-    this.allSingleDV = Collections.unmodifiableSet(allSingleDVs);\n+    this.dvsCanSubstituteStored = Collections.unmodifiableSet(dvsCanSubstituteStored);\n     this.allStored = Collections.unmodifiableSet(allStoreds);\n   }\n \n+  private boolean canSubstituteDvForStored(FieldInfo fieldInfo, SchemaField schemaField) {\n+    if (!schemaField.hasDocValues() || !schemaField.stored()) return false;\n+    if (schemaField.multiValued()) return false;\n+    DocValuesType docValuesType = fieldInfo.getDocValuesType();\n+    NumberType numberType = schemaField.getType().getNumberType();\n+    // can not decode a numeric without knowing its numberType\n+    if (numberType == null && (docValuesType == DocValuesType.SORTED_NUMERIC || docValuesType == DocValuesType.NUMERIC)) {\n+      return false;\n+    }\n+    return true;\n+  }\n+\n   public boolean isLazyFieldLoadingEnabled() {\n     return enableLazyFieldLoading;\n   }\n@@ -416,7 +424,8 @@ public Number numericValue() {\n    * @param docid\n    *          The lucene docid of the document to be populated\n    * @param fields\n-   *          The list of docValues fields to be decorated\n+   *          The fields with docValues to populate the document with.\n+   *          DocValues fields which do not exist or not decodable will be ignored.\n    */\n   public void decorateDocValueFields(@SuppressWarnings(\"rawtypes\") SolrDocumentBase doc, int docid, Set<String> fields)\n       throws IOException {\n@@ -425,153 +434,125 @@ public void decorateDocValueFields(@SuppressWarnings(\"rawtypes\") SolrDocumentBas\n     final int localId = docid - leafContexts.get(subIndex).docBase;\n     final LeafReader leafReader = leafContexts.get(subIndex).reader();\n     for (String fieldName : fields) {\n-      final SchemaField schemaField = searcher.getSchema().getFieldOrNull(fieldName);\n-      if (schemaField == null || !schemaField.hasDocValues()) {\n-        log.warn(\"Couldn't decorate docValues for field: [{}], schemaField: [{}]\", fieldName, schemaField);\n-        continue;\n-      }\n-      FieldInfo fi = searcher.getFieldInfos().fieldInfo(fieldName);\n-      if (fi == null) {\n-        continue; // Searcher doesn't have info about this field, hence ignore it.\n+      Object fieldValue = decodeDVField(localId, leafReader, fieldName);\n+      if (fieldValue != null) {\n+        doc.setField(fieldName, fieldValue);\n       }\n-      doc.remove(fieldName);\n-      final DocValuesType dvType = fi.getDocValuesType();\n-      switch (dvType) {\n-        case NUMERIC:\n-          final NumericDocValues ndv = leafReader.getNumericDocValues(fieldName);\n-          if (ndv == null) {\n-            continue;\n-          }\n-          Long val;\n-          if (ndv.advanceExact(localId)) {\n-            val = ndv.longValue();\n-          } else {\n-            continue;\n-          }\n-          Object newVal = val;\n-          if (schemaField.getType().isPointField()) {\n-            // TODO: Maybe merge PointField with TrieFields here\n-            NumberType type = schemaField.getType().getNumberType();\n-            switch (type) {\n-              case INTEGER:\n-                newVal = val.intValue();\n-                break;\n-              case LONG:\n-                newVal = val.longValue();\n-                break;\n-              case FLOAT:\n-                newVal = Float.intBitsToFloat(val.intValue());\n-                break;\n-              case DOUBLE:\n-                newVal = Double.longBitsToDouble(val);\n-                break;\n-              case DATE:\n-                newVal = new Date(val);\n-                break;\n-              default:\n-                throw new AssertionError(\"Unexpected PointType: \" + type);\n-            }\n-          } else {\n-            if (schemaField.getType() instanceof TrieIntField) {\n-              newVal = val.intValue();\n-            } else if (schemaField.getType() instanceof TrieFloatField) {\n-              newVal = Float.intBitsToFloat(val.intValue());\n-            } else if (schemaField.getType() instanceof TrieDoubleField) {\n-              newVal = Double.longBitsToDouble(val);\n-            } else if (schemaField.getType() instanceof TrieDateField) {\n-              newVal = new Date(val);\n-            } else if (schemaField.getType() instanceof AbstractEnumField) {\n-              newVal = ((AbstractEnumField)schemaField.getType()).getEnumMapping().intValueToStringValue(val.intValue());\n-            }\n-          }\n-          doc.addField(fieldName, newVal);\n-          break;\n-        case BINARY:\n-          BinaryDocValues bdv = leafReader.getBinaryDocValues(fieldName);\n-          if (bdv == null) {\n-            continue;\n-          }\n-          BytesRef value;\n-          if (bdv.advanceExact(localId)) {\n-            value = BytesRef.deepCopyOf(bdv.binaryValue());\n+    }\n+  }\n+\n+  /**\n+   * Decode value from DV field for a document\n+   * @return null if DV field is not exist or can not decodable\n+   */\n+  private Object decodeDVField(int localId, LeafReader leafReader, String fieldName) throws IOException {\n+    final SchemaField schemaField = searcher.getSchema().getFieldOrNull(fieldName);\n+    FieldInfo fi = searcher.getFieldInfos().fieldInfo(fieldName);\n+    if (schemaField == null || !schemaField.hasDocValues() || fi == null) {\n+      return null; // Searcher doesn't have info about this field, hence ignore it.\n+    }\n+\n+    final DocValuesType dvType = fi.getDocValuesType();\n+    switch (dvType) {\n+      case NUMERIC:\n+        final NumericDocValues ndv = leafReader.getNumericDocValues(fieldName);\n+        if (ndv == null) {\n+          return null;\n+        }\n+        if (!ndv.advanceExact(localId)) {\n+          return null;\n+        }\n+        Long val = ndv.longValue();\n+        return decodeNumberFromDV(schemaField, val, false);\n+      case BINARY:\n+        BinaryDocValues bdv = leafReader.getBinaryDocValues(fieldName);\n+        if (bdv != null && bdv.advanceExact(localId)) {\n+          return BytesRef.deepCopyOf(bdv.binaryValue());\n+        }\n+        return null;\n+      case SORTED:\n+        SortedDocValues sdv = leafReader.getSortedDocValues(fieldName);\n+        if (sdv != null && sdv.advanceExact(localId)) {\n+          final BytesRef bRef = sdv.binaryValue();\n+          // Special handling for Boolean fields since they're stored as 'T' and 'F'.\n+          if (schemaField.getType() instanceof BoolField) {\n+            return schemaField.getType().toObject(schemaField, bRef);\n           } else {\n-            continue;\n-          }\n-          doc.addField(fieldName, value);\n-          break;\n-        case SORTED:\n-          SortedDocValues sdv = leafReader.getSortedDocValues(fieldName);\n-          if (sdv == null) {\n-            continue;\n-          }\n-          if (sdv.advanceExact(localId)) {\n-            final BytesRef bRef = sdv.binaryValue();\n-            // Special handling for Boolean fields since they're stored as 'T' and 'F'.\n-            if (schemaField.getType() instanceof BoolField) {\n-              doc.addField(fieldName, schemaField.getType().toObject(schemaField, bRef));\n-            } else {\n-              doc.addField(fieldName, bRef.utf8ToString());\n-            }\n+            return bRef.utf8ToString();\n           }\n-          break;\n-        case SORTED_NUMERIC:\n-          final SortedNumericDocValues numericDv = leafReader.getSortedNumericDocValues(fieldName);\n-          final NumberType type = schemaField.getType().getNumberType();\n-          if (numericDv != null) {\n-            if (numericDv.advance(localId) == localId) {\n-              final List<Object> outValues = new ArrayList<Object>(numericDv.docValueCount());\n-              for (int i = 0; i < numericDv.docValueCount(); i++) {\n-                long number = numericDv.nextValue();\n-                switch (type) {\n-                  case INTEGER:\n-                    final int raw = (int)number;\n-                    if (schemaField.getType() instanceof AbstractEnumField) {\n-                      outValues.add(((AbstractEnumField)schemaField.getType()).getEnumMapping().intValueToStringValue(raw));\n-                    } else {\n-                      outValues.add(raw);\n-                    }\n-                    break;\n-                  case LONG:\n-                    outValues.add(number);\n-                    break;\n-                  case FLOAT:\n-                    outValues.add(NumericUtils.sortableIntToFloat((int)number));\n-                    break;\n-                  case DOUBLE:\n-                    outValues.add(NumericUtils.sortableLongToDouble(number));\n-                    break;\n-                  case DATE:\n-                    outValues.add(new Date(number));\n-                    break;\n-                  default:\n-                    throw new AssertionError(\"Unexpected PointType: \" + type);\n-                }\n-              }\n-              assert outValues.size() > 0;\n-              doc.addField(fieldName, outValues);\n-            }\n+        }\n+        return null;\n+      case SORTED_NUMERIC:\n+        final SortedNumericDocValues numericDv = leafReader.getSortedNumericDocValues(fieldName);\n+        if (numericDv != null && numericDv.advance(localId) == localId) {\n+          final List<Object> outValues = new ArrayList<>(numericDv.docValueCount());\n+          for (int i = 0; i < numericDv.docValueCount(); i++) {\n+            long number = numericDv.nextValue();\n+            Object value = decodeNumberFromDV(schemaField, number, true);\n+            // return immediately if the number is not decodable, hence won't return an empty list.\n+            if (value == null) return null;\n+            else outValues.add(value);\n           }\n-        case SORTED_SET:\n-          final SortedSetDocValues values = leafReader.getSortedSetDocValues(fieldName);\n-          if (values != null && values.getValueCount() > 0) {\n-            if (values.advance(localId) == localId) {\n-              final List<Object> outValues = new LinkedList<>();\n-              for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {\n-                value = values.lookupOrd(ord);\n-                outValues.add(schemaField.getType().toObject(schemaField, value));\n-              }\n-              assert outValues.size() > 0;\n-              doc.addField(fieldName, outValues);\n-            }\n+          assert outValues.size() > 0;\n+          return outValues;\n+        }\n+        return null;\n+      case SORTED_SET:\n+        final SortedSetDocValues values = leafReader.getSortedSetDocValues(fieldName);\n+        if (values != null && values.getValueCount() > 0 && values.advance(localId) == localId) {\n+          final List<Object> outValues = new LinkedList<>();\n+          for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {\n+            BytesRef value = values.lookupOrd(ord);\n+            outValues.add(schemaField.getType().toObject(schemaField, value));\n           }\n-        case NONE:\n-          break;\n-      }\n+          assert outValues.size() > 0;\n+          return outValues;\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Object decodeNumberFromDV(SchemaField schemaField, long value, boolean sortableNumeric) {\n+    if (schemaField.getType().getNumberType() == null) {\n+      log.warn(\"Couldn't decode docValues for field: [{}], schemaField: [{}], numberType is unknown\",\n+          schemaField.getName(), schemaField);\n+      return null;\n+    }\n+\n+    switch (schemaField.getType().getNumberType()) {\n+      case INTEGER:\n+        final int raw = (int)value;\n+        if (schemaField.getType() instanceof AbstractEnumField) {\n+          return ((AbstractEnumField)schemaField.getType()).getEnumMapping().intValueToStringValue(raw);\n+        } else {\n+          return raw;\n+        }\n+      case LONG:\n+        return value;\n+      case FLOAT:\n+        if (sortableNumeric) {\n+          return NumericUtils.sortableIntToFloat((int)value);\n+        } else {\n+          return Float.intBitsToFloat((int)value);\n+        }\n+      case DOUBLE:\n+        if (sortableNumeric) {\n+          return NumericUtils.sortableLongToDouble(value);\n+        } else {\n+          return Double.longBitsToDouble(value);\n+        }\n+      case DATE:\n+        return new Date(value);\n+      default:\n+        // catched all possible values, this line will never be reached\n+        throw new AssertionError();\n     }\n   }\n \n-  public Set<String> getAllSingleDV() {\n-    return allSingleDV;\n+  public Set<String> getDvsCanSubstituteStored() {\n+    return dvsCanSubstituteStored;\n   }\n \n   public Set<String> getAllStored() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/java/org/apache/solr/search/SolrDocumentFetcher.java",
                "sha": "7c71b64929d17f59dd026ee746d32945b7a2dd7d",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/test-files/solr/collection1/conf/schema-spatial.xml",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/schema-spatial.xml?ref=7a19128109d9b40b28a09a59efa718d63f7a31e9",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/schema-spatial.xml",
                "patch": "@@ -85,6 +85,9 @@\n   <field name=\"llp\" type=\"llp\" indexed=\"true\" docValues=\"true\" />\n   <field name=\"llp_idx\" type=\"llp\" indexed=\"true\" docValues=\"false\" />\n   <field name=\"llp_dv\" type=\"llp\" indexed=\"false\" docValues=\"true\" />\n+  <field name=\"llp_1_dv_st\" type=\"llp\" indexed=\"false\" docValues=\"true\" stored=\"true\" multiValued=\"false\"/>\n+  <field name=\"llp_1_dv\" type=\"llp\" indexed=\"false\" docValues=\"true\" stored=\"false\" multiValued=\"false\" useDocValuesAsStored=\"false\"/>\n+  <field name=\"llp_1_dv_dvasst\" type=\"llp\" indexed=\"false\" docValues=\"true\" stored=\"false\" multiValued=\"false\"  useDocValuesAsStored=\"true\"/>\n \n   <dynamicField name=\"bboxD_*\" type=\"bbox\" indexed=\"true\"/>\n   <dynamicField name=\"str_*\" type=\"string\" indexed=\"true\" stored=\"true\"/>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/test-files/solr/collection1/conf/schema-spatial.xml",
                "sha": "d973fb0c14abba0fb6b0579959828424ae0e4bc0",
                "status": "modified"
            },
            {
                "additions": 19,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java?ref=7a19128109d9b40b28a09a59efa718d63f7a31e9",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java",
                "patch": "@@ -117,6 +117,25 @@ public void testRptWithGeometryGeo3dField() throws Exception {\n         \"q\", \"{!cache=false field f=\" + fieldName + \"}Intersects(\" + polygonWKT + \")\",\n         \"sort\", \"id asc\"), \"/response/numFound==2\");\n   }\n+  \n+  @Test\n+  public void testLatLonRetrieval() throws Exception {\n+    assertU(adoc(\"id\", \"0\",\n+        \"llp_1_dv_st\", \"-75,41\",\n+        \"llp_1_dv\", \"-80,20\",\n+        \"llp_1_dv_dvasst\", \"10,-30\"));\n+    assertU(commit());\n+    assertJQ(req(\"q\",\"*:*\", \"fl\",\"*\"),\n+        \"response/docs/[0]/llp_1_dv_st=='-75,41'\",\n+        // Right now we do not support decoding point value from dv field\n+        \"!response/docs/[0]/llp_1_dv=='-80,20'\",\n+        \"!response/docs/[0]/llp_1_dv_dvasst=='10,-30'\");\n+    assertJQ(req(\"q\",\"*:*\", \"fl\",\"llp_1_dv_st, llp_1_dv, llp_1_dv_dvasst\"),\n+        \"response/docs/[0]/llp_1_dv_st=='-75,41'\",\n+        // Even when these fields are specified, we won't return them\n+        \"!response/docs/[0]/llp_1_dv=='-80,20'\",\n+        \"!response/docs/[0]/llp_1_dv_dvasst=='10,-30'\");\n+  }\n \n   private void testRptWithGeometryField(String fieldName) throws Exception {\n     assertU(adoc(\"id\", \"0\", fieldName, \"ENVELOPE(-10, 20, 15, 10)\"));",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7a19128109d9b40b28a09a59efa718d63f7a31e9/solr/core/src/test/org/apache/solr/search/TestSolr4Spatial2.java",
                "sha": "dc21173c1846b8b86d05402c6db5613d2a5f78cf",
                "status": "modified"
            }
        ],
        "message": "SOLR-11532: Solr hits NPE when fl only contains DV fields and any of them is a spatial field",
        "parent": "https://github.com/apache/lucene-solr/commit/401dda7e064b6f621cba405985143724d79620c4",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestRetrieveFieldsOptimizer.java"
        ]
    },
    "lucene-solr_7cdc63f": {
        "bug_id": "lucene-solr_7cdc63f",
        "commit": "https://github.com/apache/lucene-solr/commit/7cdc63f3d4f79e8702f96b617cf7e464fd74766a",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=7cdc63f3d4f79e8702f96b617cf7e464fd74766a",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -282,6 +282,9 @@ Bug Fixes\n * SOLR-7818: Fixed distributed stats to be calculated for all the query terms. Earlier the stats were calculated with\n   the terms that are present in the last shard of a distributed request. (Varun Thacker, Anshum Gupta)\n \n+* SOLR-7866: VersionInfo caused an unhandled NPE when trying to determine the max value for the\n+  version field. (Timothy Potter)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/CHANGES.txt",
                "sha": "d9f777300a3479ffb8345cb2b0b66dff448863b9",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/core/src/java/org/apache/solr/update/VersionInfo.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/VersionInfo.java?ref=7cdc63f3d4f79e8702f96b617cf7e464fd74766a",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/update/VersionInfo.java",
                "patch": "@@ -231,8 +231,9 @@ public Long getMaxVersionFromIndex(SolrIndexSearcher searcher) throws IOExceptio\n     // if indexed, then we have terms to get the max from\n     if (versionField.indexed()) {\n       Terms versionTerms = searcher.getLeafReader().terms(versionFieldName);\n-      if (versionTerms != null) {\n-        maxVersionInIndex = NumericUtils.getMaxLong(versionTerms);\n+      Long max = (versionTerms != null) ? NumericUtils.getMaxLong(versionTerms) : null;\n+      if (max != null) {\n+        maxVersionInIndex = max.longValue();\n         log.info(\"Found MAX value {} from Terms for {} in index\", maxVersionInIndex, versionFieldName);\n       } else {\n         log.info(\"No terms found for {}, cannot seed version bucket highest value from index\", versionFieldName);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/core/src/java/org/apache/solr/update/VersionInfo.java",
                "sha": "54ced7807ac128dad5c7f855c12d1e4ed4ac7d19",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/core/src/test/org/apache/solr/cloud/DistributedVersionInfoTest.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/DistributedVersionInfoTest.java?ref=7cdc63f3d4f79e8702f96b617cf7e464fd74766a",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/cloud/DistributedVersionInfoTest.java",
                "patch": "@@ -88,6 +88,11 @@ protected void testReplicaVersionHandling() throws Exception {\n     List<Replica> notLeaders =\n         ensureAllReplicasAreActive(testCollectionName, shardId, 1, rf, maxWaitSecsToSeeAllActive);\n \n+    // start by reloading the empty collection so we try to calculate the max from an empty index\n+    reloadCollection(leader, testCollectionName);\n+    notLeaders =\n+        ensureAllReplicasAreActive(testCollectionName, shardId, 1, rf, maxWaitSecsToSeeAllActive);\n+\n     sendDoc(1);\n     cloudClient.commit();\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/7cdc63f3d4f79e8702f96b617cf7e464fd74766a/solr/core/src/test/org/apache/solr/cloud/DistributedVersionInfoTest.java",
                "sha": "c08b2472e57dbb1be62cbef177aa199394f2fbf4",
                "status": "modified"
            }
        ],
        "message": "SOLR-7866: Harden code to prevent an unhandled NPE when trying to determine the max value of the version field.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1694385 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/a42e164b3d94edbe55b7599f33d7a85e5ec040ec",
        "repo": "lucene-solr",
        "unit_tests": [
            "VersionInfoTest.java"
        ]
    },
    "lucene-solr_80cce99": {
        "bug_id": "lucene-solr_80cce99",
        "commit": "https://github.com/apache/lucene-solr/commit/80cce99ebc9ced8b6af0af3fa813af8ea4241454",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/80cce99ebc9ced8b6af0af3fa813af8ea4241454/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java?ref=80cce99ebc9ced8b6af0af3fa813af8ea4241454",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "patch": "@@ -23,7 +23,7 @@\n import static org.apache.solr.common.SolrException.ErrorCode.*;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.common.SolrInputDocument;\n-import org.apache.solr.common.cloud.Slice;\n+import org.apache.solr.common.cloud.Replica;\n import org.apache.solr.common.cloud.Slice;\n \n import org.apache.solr.core.CloseHook;\n@@ -469,7 +469,17 @@ private boolean iAmInChargeOfPeriodicDeletes() {\n \n     List<Slice> slices = new ArrayList<Slice>(zk.getClusterState().getActiveSlices(col));\n     Collections.sort(slices, COMPARE_SLICES_BY_NAME);\n-    String leaderInCharge = slices.get(0).getLeader().getName();\n+    if (slices.isEmpty()) {\n+      log.error(\"Collection {} has no active Slices?\", col);\n+      return false;\n+    }\n+    Replica firstSliceLeader = slices.get(0).getLeader();\n+    if (null == firstSliceLeader) {\n+      log.warn(\"Slice in charge of periodic deletes for {} does not currently have a leader\",\n+               col);\n+      return false;\n+    }\n+    String leaderInCharge = firstSliceLeader.getName();\n     String myCoreNodeName = desc.getCoreNodeName();\n     \n     boolean inChargeOfDeletesRightNow = leaderInCharge.equals(myCoreNodeName);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/80cce99ebc9ced8b6af0af3fa813af8ea4241454/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "sha": "a006ebbb2579cd16ddf7290b59dcbf41835a214a",
                "status": "modified"
            }
        ],
        "message": "SOLR-5795: harden leader check to log cleanly (no NPE) in transient situations when there is no leader due to election in progress\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1584097 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/a9e04127dfe52b8ddfb9d24e8da4264e4446936e",
        "repo": "lucene-solr",
        "unit_tests": [
            "DocExpirationUpdateProcessorFactoryTest.java"
        ]
    },
    "lucene-solr_80d436e": {
        "bug_id": "lucene-solr_80d436e",
        "commit": "https://github.com/apache/lucene-solr/commit/80d436e29f477396416aca1d84acd0b01c172c11",
        "file": [
            {
                "additions": 48,
                "blob_url": "https://github.com/apache/lucene-solr/blob/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java",
                "changes": 66,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java?ref=80d436e29f477396416aca1d84acd0b01c172c11",
                "deletions": 18,
                "filename": "solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java",
                "patch": "@@ -18,36 +18,66 @@\n \n import org.junit.BeforeClass;\n import org.junit.Test;\n+import org.w3c.dom.Document;\n+import org.w3c.dom.Element;\n+import org.xml.sax.InputSource;\n+\n+import javax.xml.parsers.DocumentBuilder;\n+import javax.xml.parsers.DocumentBuilderFactory;\n+import javax.xml.transform.Transformer;\n+import javax.xml.transform.TransformerFactory;\n+import javax.xml.transform.dom.DOMSource;\n+import javax.xml.transform.stream.StreamResult;\n+import java.io.StringReader;\n+import java.io.StringWriter;\n \n /**Testcase for TikaEntityProcessor\n  *\n- * @since solr 1.5 \n+ * @since solr 3.1\n  */\n public class TestTikaEntityProcessor extends AbstractDataImportHandlerTestCase {\n+  private String conf =\n+  \"<dataConfig>\" +\n+  \"  <dataSource type=\\\"BinFileDataSource\\\"/>\" +\n+  \"  <document>\" +\n+  \"    <entity processor=\\\"TikaEntityProcessor\\\" url=\\\"\" + getFile(\"solr-word.pdf\").getAbsolutePath() + \"\\\" >\" +\n+  \"      <field column=\\\"Author\\\" meta=\\\"true\\\" name=\\\"author\\\"/>\" +\n+  \"      <field column=\\\"title\\\" meta=\\\"true\\\" name=\\\"title\\\"/>\" +\n+  \"      <field column=\\\"text\\\"/>\" +\n+  \"     </entity>\" +\n+  \"  </document>\" +\n+  \"</dataConfig>\";\n+\n+  private String[] tests = {\n+      \"//*[@numFound='1']\"\n+      ,\"//str[@name='author'][.='Grant Ingersoll']\"\n+      ,\"//str[@name='title'][.='solr-word']\"\n+      ,\"//str[@name='text']\"\n+  };\n+\n+\n   @BeforeClass\n   public static void beforeClass() throws Exception {\n     initCore(\"dataimport-solrconfig.xml\", \"dataimport-schema-no-unique-key.xml\", getFile(\"solr-dihextras\").getAbsolutePath());\n   }\n \n   @Test\n   public void testIndexingWithTikaEntityProcessor() throws Exception {\n-    String conf =\n-            \"<dataConfig>\" +\n-                    \"  <dataSource type=\\\"BinFileDataSource\\\"/>\" +\n-                    \"  <document>\" +\n-                    \"    <entity processor=\\\"TikaEntityProcessor\\\" url=\\\"\" + getFile(\"solr-word.pdf\").getAbsolutePath() + \"\\\" >\" +\n-                    \"      <field column=\\\"Author\\\" meta=\\\"true\\\" name=\\\"author\\\"/>\" +\n-                    \"      <field column=\\\"title\\\" meta=\\\"true\\\" name=\\\"title\\\"/>\" +\n-                    \"      <field column=\\\"text\\\"/>\" +\n-                    \"     </entity>\" +\n-                    \"  </document>\" +\n-                    \"</dataConfig>\";\n     runFullImport(conf);\n-    assertQ(req(\"*:*\")\n-            ,\"//*[@numFound='1']\"\n-            ,\"//str[@name='author'][.='Grant Ingersoll']\"\n-            ,\"//str[@name='title'][.='solr-word']\"\n-            ,\"//str[@name='text']\"\n-            );\n+    assertQ(req(\"*:*\"), tests );\n   }\n+\n+  @Test\n+  public void testIndexingWithTikaEntityProcessorThreaded() throws Exception {\n+    DocumentBuilder builder = DocumentBuilderFactory.newInstance().newDocumentBuilder();\n+    Document doc = builder.parse(new InputSource(new StringReader(conf)));\n+    ((Element) doc.getElementsByTagName(\"entity\").item(0)).setAttribute(\"threads\", \"1\");\n+    Transformer trans = TransformerFactory.newInstance().newTransformer();\n+    StringWriter writer = new StringWriter();\n+    trans.transform(new DOMSource(doc), new StreamResult(writer));\n+\n+    runFullImport(writer.toString());\n+    assertQ(req(\"*:*\"), tests );\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java",
                "sha": "7912c5f92d844d6bd060ce05ec0882a03255c38f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/CHANGES.txt",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/CHANGES.txt?ref=80d436e29f477396416aca1d84acd0b01c172c11",
                "deletions": 0,
                "filename": "solr/contrib/dataimporthandler/CHANGES.txt",
                "patch": "@@ -18,6 +18,7 @@ Bug Fixes\n ----------------------\n * SOLR-2644: When using threads=2 the default logging is set too high (Bill Bell via shalin)\n * SOLR-2492: DIH does not commit if only deletes are processed (James Dyer via shalin)\n+* SOLR-2186: DataImportHandler's multi-threaded option throws NPE (Lance Norskog, Frank Wesemann, shalin)\n \n ==================  3.3.0 ==================\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/CHANGES.txt",
                "sha": "150a15c7e56b9a1036cbb7e6e5479cc1538eea5b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ContextImpl.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ContextImpl.java?ref=80d436e29f477396416aca1d84acd0b01c172c11",
                "deletions": 1,
                "filename": "solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ContextImpl.java",
                "patch": "@@ -33,7 +33,7 @@\n  * @since solr 1.3\n  */\n public class ContextImpl extends Context {\n-  private DataConfig.Entity entity;\n+  protected DataConfig.Entity entity;\n \n   private ContextImpl parent;\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ContextImpl.java",
                "sha": "1b32005ff6902d4840eb64b634e05c17d80bc704",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ThreadedContext.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ThreadedContext.java?ref=80d436e29f477396416aca1d84acd0b01c172c11",
                "deletions": 2,
                "filename": "solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ThreadedContext.java",
                "patch": "@@ -28,7 +28,7 @@\n \n   public ThreadedContext(DocBuilder.EntityRunner entityRunner, DocBuilder docBuilder) {\n     super(entityRunner.entity,\n-            null,//to be fethed realtime\n+            null,//to be fetched realtime\n             null,\n             null,\n             docBuilder.session,\n@@ -75,7 +75,7 @@ private void checkLimited() {\n   @Override\n   public String getResolvedEntityAttribute(String name) {\n     checkLimited();\n-    return super.getResolvedEntityAttribute(name);\n+    return entity == null ? null : getVariableResolver().replaceTokens(entity.allAttributes.get(name));\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/80d436e29f477396416aca1d84acd0b01c172c11/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/ThreadedContext.java",
                "sha": "0386e76f1a67685ee6a02f4f4bd3c26eb175a349",
                "status": "modified"
            }
        ],
        "message": "SOLR-2186 -- DataImportHandler's multi-threaded option throws NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1147023 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/2e14617e19b97f888553d9c27687c76528a46c25",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestContextImpl.java"
        ]
    },
    "lucene-solr_822785a": {
        "bug_id": "lucene-solr_822785a",
        "commit": "https://github.com/apache/lucene-solr/commit/822785a15f27aa9ca8d223199dff975d21737bb8",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -289,6 +289,9 @@ Bug Fixes\n * SOLR-8422: When authentication enabled, requests fail if sent to a node that doesn't host\n   the collection (noble)\n \n+* SOLR-8059: &debug=results for distributed search when distrib.singlePass (sometimes activated\n+  automatically) could result in an NPE. (David Smiley, Markus Jelsma)\n+\n Other Changes\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/CHANGES.txt",
                "sha": "5f92bc7447d5658b7d7ea2c557a2430975efcbd1",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 11,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "patch": "@@ -24,6 +24,7 @@\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n+import java.util.LinkedHashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n@@ -230,13 +231,7 @@ public void finishStage(ResponseBuilder rb) {\n             hasGetDebugResponses = true;\n             if (rb.isDebugResults()) {\n               NamedList sexplain = (NamedList)sdebug.get(\"explain\");\n-              for (int i = 0; i < sexplain.size(); i++) {\n-                String id = sexplain.getName(i);\n-                // TODO: lookup won't work for non-string ids... String vs Float\n-                ShardDoc sdoc = rb.resultIds.get(id);\n-                int idx = sdoc.positionInResponse;\n-                arr[idx] = new NamedList.NamedListEntry<>(id, sexplain.getVal(i));\n-              }\n+              SolrPluginUtils.copyNamedListIntoArrayByDocPosInResponse(sexplain, rb.resultIds, arr);\n             }\n           }\n         }\n@@ -295,7 +290,7 @@ public void finishStage(ResponseBuilder rb) {\n     return namedList;\n   }\n \n-  Object merge(Object source, Object dest, Set<String> exclude) {\n+  protected Object merge(Object source, Object dest, Set<String> exclude) {\n     if (source == null) return dest;\n     if (dest == null) {\n       if (source instanceof NamedList) {\n@@ -306,6 +301,10 @@ Object merge(Object source, Object dest, Set<String> exclude) {\n     } else {\n \n       if (dest instanceof Collection) {\n+        // merge as Set\n+        if (!(dest instanceof Set)) {\n+          dest = new LinkedHashSet<>((Collection<?>) dest);\n+        }\n         if (source instanceof Collection) {\n           ((Collection)dest).addAll((Collection)source);\n         } else {\n@@ -337,7 +336,7 @@ Object merge(Object source, Object dest, Set<String> exclude) {\n       NamedList<Object> dl = (NamedList<Object>)dest;\n       for (int i=0; i<sl.size(); i++) {\n         String skey = sl.getName(i);\n-        if (exclude != null && exclude.contains(skey)) continue;\n+        if (exclude.contains(skey)) continue;\n         Object sval = sl.getVal(i);\n         int didx = -1;\n \n@@ -354,9 +353,9 @@ Object merge(Object source, Object dest, Set<String> exclude) {\n         }\n \n         if (didx == -1) {\n-          tmp.add(skey, merge(sval, null, null));\n+          tmp.add(skey, merge(sval, null, Collections.emptySet()));\n         } else {\n-          dl.setVal(didx, merge(sval, dl.getVal(didx), null));\n+          dl.setVal(didx, merge(sval, dl.getVal(didx), Collections.emptySet()));\n         }\n       }\n       dl.addAll(tmp);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/DebugComponent.java",
                "sha": "21755e1b71fedf4d5b657e70c3fc95a4671be262",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 12,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "patch": "@@ -175,7 +175,7 @@ public void handleResponses(ResponseBuilder rb, ShardRequest sreq) {\n   public void finishStage(ResponseBuilder rb) {\n     if (rb.doHighlights && rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n \n-      Map.Entry<String, Object>[] arr = new NamedList.NamedListEntry[rb.resultIds.size()];\n+      NamedList.NamedListEntry[] arr = new NamedList.NamedListEntry[rb.resultIds.size()];\n \n       // TODO: make a generic routine to do automatic merging of id keyed data\n       for (ShardRequest sreq : rb.finished) {\n@@ -187,21 +187,12 @@ public void finishStage(ResponseBuilder rb) {\n             continue;\n           }\n           NamedList hl = (NamedList)srsp.getSolrResponse().getResponse().get(\"highlighting\");\n-          for (int i=0; i<hl.size(); i++) {\n-            String id = hl.getName(i);\n-            ShardDoc sdoc = rb.resultIds.get(id);\n-            // sdoc maybe null\n-            if (sdoc == null) {\n-                continue;\n-            }\n-            int idx = sdoc.positionInResponse;\n-            arr[idx] = new NamedList.NamedListEntry<>(id, hl.getVal(i));\n-          }\n+          SolrPluginUtils.copyNamedListIntoArrayByDocPosInResponse(hl, rb.resultIds, arr);\n         }\n       }\n \n       // remove nulls in case not all docs were able to be retrieved\n-      rb.rsp.add(\"highlighting\", SolrPluginUtils.removeNulls(arr, new SimpleOrderedMap<Object>()));      \n+      rb.rsp.add(\"highlighting\", SolrPluginUtils.removeNulls(arr, new SimpleOrderedMap<>()));\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/HighlightComponent.java",
                "sha": "4bdcf33845d9dc10094fdc9a2e7fcd5663755839",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/ResponseBuilder.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/ResponseBuilder.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/ResponseBuilder.java",
                "patch": "@@ -251,6 +251,10 @@ public void addMergeStrategy(MergeStrategy mergeStrategy) {\n     return this.mergeStrategies;\n   }\n \n+  public RankQuery getRankQuery() {\n+    return rankQuery;\n+  }\n+\n   public void setRankQuery(RankQuery rankQuery) {\n     this.rankQuery = rankQuery;\n   }\n@@ -428,7 +432,8 @@ public GlobalCollectionStat(int numDocs, Map<String, Long> dfMap) {\n     return cmd;\n   }\n \n-  Query wrap(Query q) {\n+  /** Calls {@link RankQuery#wrap(Query)} if there's a rank query, otherwise just returns the query. */\n+  public Query wrap(Query q) {\n     if(this.rankQuery != null) {\n       return this.rankQuery.wrap(q);\n     } else {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/ResponseBuilder.java",
                "sha": "7bf195dab0641bbf5899e350ea17dc7a2b7df663",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 8,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "patch": "@@ -457,14 +457,7 @@ public void finishStage(ResponseBuilder rb) {\n           }\n \n           // UniqueKey data\n-          for (int i=0; i < nl.size(); i++) {\n-            String key = nl.getName(i);\n-            ShardDoc sdoc = rb.resultIds.get(key);\n-            if (sdoc != null) {// can be null when rb.onePassDistributedQuery\n-              int idx = sdoc.positionInResponse;\n-              arr[idx] = new NamedList.NamedListEntry<>(key, nl.getVal(i));\n-            }\n-          }\n+          SolrPluginUtils.copyNamedListIntoArrayByDocPosInResponse(nl, rb.resultIds, arr);\n         }\n       }\n       // remove nulls in case not all docs were able to be retrieved",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "sha": "53777591ad8a46ae92c46ce65e1a249ad6a323b8",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "patch": "@@ -57,6 +57,7 @@\n import org.apache.solr.core.SolrCore;\n import org.apache.solr.handler.component.HighlightComponent;\n import org.apache.solr.handler.component.ResponseBuilder;\n+import org.apache.solr.handler.component.ShardDoc;\n import org.apache.solr.handler.component.ShardRequest;\n import org.apache.solr.highlight.SolrHighlighter;\n import org.apache.solr.parser.QueryParser;\n@@ -811,6 +812,25 @@ public static CharSequence stripUnbalancedQuotes(CharSequence s) {\n     return dest;\n   }\n \n+  /** Copies the given {@code namedList} assumed to have doc uniqueKey keyed data into {@code destArr}\n+   * at the position of the document in the response.  destArr is assumed to be the same size as\n+   * {@code resultIds} is.  {@code resultIds} comes from {@link ResponseBuilder#resultIds}.  If the doc key\n+   * isn't in {@code resultIds} then it is ignored.\n+   * Note: most likely you will call {@link #removeNulls(Map.Entry[], NamedList)} sometime after calling this. */\n+  public static void copyNamedListIntoArrayByDocPosInResponse(NamedList namedList, Map<Object, ShardDoc> resultIds,\n+                                                              Map.Entry<String, Object>[] destArr) {\n+    assert resultIds.size() == destArr.length;\n+    for (int i = 0; i < namedList.size(); i++) {\n+      String id = namedList.getName(i);\n+      // TODO: lookup won't work for non-string ids... String vs Float\n+      ShardDoc sdoc = resultIds.get(id);\n+      if (sdoc != null) { // maybe null when rb.onePassDistributedQuery\n+        int idx = sdoc.positionInResponse;\n+        destArr[idx] = new NamedList.NamedListEntry<>(id, namedList.getVal(i));\n+      }\n+    }\n+  }\n+\n   /**\n    * A subclass of SolrQueryParser that supports aliasing fields for\n    * constructing DisjunctionMaxQueries.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/java/org/apache/solr/util/SolrPluginUtils.java",
                "sha": "3a180fd14912213e4c51d35a8e41dc3da7310c7e",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java?ref=822785a15f27aa9ca8d223199dff975d21737bb8",
                "deletions": 3,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "patch": "@@ -346,11 +346,17 @@ private void verifyDebugSections(SolrQuery query, SolrClient client) throws Solr\n   \n   public void testCompareWithNonDistributedRequest() throws SolrServerException, IOException {\n     SolrQuery query = new SolrQuery();\n-    query.setQuery(\"id:1\");\n-    query.setFilterQueries(\"id:[0 TO 10]\");\n+    query.setQuery(\"id:1 OR id:2\");\n+    query.setFilterQueries(\"id:[0 TO 10]\", \"id:[0 TO 5]\");\n+    query.setRows(1);\n+    query.setSort(\"id\", SolrQuery.ORDER.asc); // thus only return id:1 since rows 1\n     query.set(\"debug\",  \"true\");\n     query.set(\"distrib\", \"true\");\n-    query.setFields(\"id\", \"text\");\n+    query.setFields(\"id\");\n+    if (random().nextBoolean()) { // can affect rb.onePassDistributedQuery\n+      query.addField(\"text\");\n+    }\n+    query.set(ShardParams.DISTRIB_SINGLE_PASS, random().nextBoolean());\n     query.set(\"shards\", shard1 + \",\" + shard2);\n     QueryResponse distribResponse = collection1.query(query);\n     ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/822785a15f27aa9ca8d223199dff975d21737bb8/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java",
                "sha": "63b131ee966af7ebb688fdcc52d867a793166c42",
                "status": "modified"
            }
        ],
        "message": "SOLR-8059: debug=results&distrib.singlePass=true can NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1721203 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/31db3524141c483e3ae59666cef50d3adf3b3b45",
        "repo": "lucene-solr",
        "unit_tests": [
            "DebugComponentTest.java",
            "ResponseBuilderTest.java",
            "TermVectorComponentTest.java",
            "SolrPluginUtilsTest.java"
        ]
    },
    "lucene-solr_82980ed": {
        "bug_id": "lucene-solr_82980ed",
        "commit": "https://github.com/apache/lucene-solr/commit/82980ed7c4c8a6e482a9c07561628c714b81a2bb",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/82980ed7c4c8a6e482a9c07561628c714b81a2bb/CHANGES.txt",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/CHANGES.txt?ref=82980ed7c4c8a6e482a9c07561628c714b81a2bb",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -228,6 +228,7 @@ Bug fixes\n   replaceInvalidAcronym which defaults to false, the current, incorrect behavior.  Setting\n   this flag to true fixes the problem.  This flag is a temporary fix and is already\n   marked as being deprecated.  3.x will implement the correct approach.  (Shai Erera via Grant Ingersoll)\n+  LUCENE-1140: Fixed NPE caused by 1068 (Alexei Dets via Grant Ingersoll)\n     \n 28. LUCENE-749: ChainedFilter behavior fixed when logic of \n     first filter is ANDNOT.  (Antonio Bruno via Doron Cohen)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/82980ed7c4c8a6e482a9c07561628c714b81a2bb/CHANGES.txt",
                "sha": "75e068ed3c73ba5790d3dcbcc6627714840bf859",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/82980ed7c4c8a6e482a9c07561628c714b81a2bb/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java?ref=82980ed7c4c8a6e482a9c07561628c714b81a2bb",
                "deletions": 0,
                "filename": "src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java",
                "patch": "@@ -85,6 +85,7 @@ public StandardAnalyzer(Reader stopwords) throws IOException {\n    * @deprecated Remove in 3.X and make true the only valid value\n    */\n   public StandardAnalyzer(boolean replaceInvalidAcronym) {\n+    this(STOP_WORDS);\n     this.replaceInvalidAcronym = replaceInvalidAcronym;\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/82980ed7c4c8a6e482a9c07561628c714b81a2bb/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java",
                "sha": "42daad14934e9cc1d83e8c720cc7a574e7ff44f6",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/82980ed7c4c8a6e482a9c07561628c714b81a2bb/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java?ref=82980ed7c4c8a6e482a9c07561628c714b81a2bb",
                "deletions": 0,
                "filename": "src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java",
                "patch": "@@ -120,6 +120,16 @@ public void testCompanyNames() throws Exception {\n     assertAnalyzesTo(a, \"Excite@Home\", new String[]{\"excite@home\"});\n   }\n \n+  public void testLucene1140() throws Exception {\n+    try {\n+      StandardAnalyzer analyzer = new StandardAnalyzer(true);\n+      assertAnalyzesTo(analyzer, \"www.nutch.org.\", new String[]{ \"www.nutch.org\" }, new String[] { \"<HOST>\" });\n+    } catch (NullPointerException e) {\n+      assertTrue(\"Should not throw an NPE and it did\", false);\n+    }\n+\n+  }\n+\n   public void testDomainNames() throws Exception {\n     // domain names\n     assertAnalyzesTo(a, \"www.nutch.org\", new String[]{\"www.nutch.org\"});",
                "raw_url": "https://github.com/apache/lucene-solr/raw/82980ed7c4c8a6e482a9c07561628c714b81a2bb/src/test/org/apache/lucene/analysis/TestStandardAnalyzer.java",
                "sha": "de43d745607fc7052e78fa797287fc0b346d9ce9",
                "status": "modified"
            }
        ],
        "message": "LUCENE-1140 patch to fix StandardAnalyzer stop set NPE and test\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@613282 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/ed9fdba6017351594de9f8e3ded3357c396eb04b",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestStandardAnalyzer.java"
        ]
    },
    "lucene-solr_832dacf": {
        "bug_id": "lucene-solr_832dacf",
        "commit": "https://github.com/apache/lucene-solr/commit/832dacffc8dddfef07456624660118a593f176bd",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/832dacffc8dddfef07456624660118a593f176bd/solr/core/src/java/org/apache/solr/search/SolrCoreParser.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SolrCoreParser.java?ref=832dacffc8dddfef07456624660118a593f176bd",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/search/SolrCoreParser.java",
                "patch": "@@ -43,6 +43,9 @@ public SolrCoreParser(String defaultField, Analyzer analyzer,\n \n   @Override\n   public void init(NamedList initArgs) {\n+    if (initArgs == null || initArgs.size() == 0) {\n+      return;\n+    }\n     final SolrResourceLoader loader;\n     if (req == null) {\n       loader = new SolrResourceLoader();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/832dacffc8dddfef07456624660118a593f176bd/solr/core/src/java/org/apache/solr/search/SolrCoreParser.java",
                "sha": "4857b7534bde6acde95e799a1e830edf69baef2a",
                "status": "modified"
            }
        ],
        "message": "SOLR-9275: fix NPE in SolrCoreParser.init",
        "parent": "https://github.com/apache/lucene-solr/commit/5c4b7173a8535b76a96a32bdba79d8b89be14dc7",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSolrCoreParser.java"
        ]
    },
    "lucene-solr_847a8af": {
        "bug_id": "lucene-solr_847a8af",
        "commit": "https://github.com/apache/lucene-solr/commit/847a8af93b97cfbfc41664c6e3297a4af5c0c012",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AnalysisSPILoader.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AnalysisSPILoader.java?ref=847a8af93b97cfbfc41664c6e3297a4af5c0c012",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AnalysisSPILoader.java",
                "patch": "@@ -21,6 +21,7 @@\n import java.util.Collections;\n import java.util.Locale;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.LinkedHashMap;\n import java.util.Set;\n import java.util.ServiceConfigurationError;\n@@ -54,6 +55,9 @@ public AnalysisSPILoader(Class<S> clazz, String[] suffixes, ClassLoader classloa\n     this.suffixes = suffixes;\n     // if clazz' classloader is not a parent of the given one, we scan clazz's classloader, too:\n     final ClassLoader clazzClassloader = clazz.getClassLoader();\n+    if (classloader == null) {\n+      classloader = clazzClassloader;\n+    }\n     if (clazzClassloader != null && !SPIClassIterator.isParentClassLoader(clazzClassloader, classloader)) {\n       reload(clazzClassloader);\n     }\n@@ -72,6 +76,7 @@ public AnalysisSPILoader(Class<S> clazz, String[] suffixes, ClassLoader classloa\n    * of new service providers on the given classpath/classloader!</em>\n    */\n   public synchronized void reload(ClassLoader classloader) {\n+    Objects.requireNonNull(classloader, \"classloader\");\n     final LinkedHashMap<String,Class<? extends S>> services =\n       new LinkedHashMap<>(this.services);\n     final SPIClassIterator<S> loader = SPIClassIterator.get(clazz, classloader);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AnalysisSPILoader.java",
                "sha": "b41e784de734985334b02fb9fde0eebd2c316197",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java?ref=847a8af93b97cfbfc41664c6e3297a4af5c0c012",
                "deletions": 0,
                "filename": "lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.util.Collections;\n import java.util.Iterator;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.LinkedHashMap;\n import java.util.Set;\n import java.util.ServiceConfigurationError;\n@@ -41,6 +42,9 @@ public NamedSPILoader(Class<S> clazz, ClassLoader classloader) {\n     this.clazz = clazz;\n     // if clazz' classloader is not a parent of the given one, we scan clazz's classloader, too:\n     final ClassLoader clazzClassloader = clazz.getClassLoader();\n+    if (classloader == null) {\n+      classloader = clazzClassloader;\n+    }\n     if (clazzClassloader != null && !SPIClassIterator.isParentClassLoader(clazzClassloader, classloader)) {\n       reload(clazzClassloader);\n     }\n@@ -59,6 +63,7 @@ public NamedSPILoader(Class<S> clazz, ClassLoader classloader) {\n    * of new service providers on the given classpath/classloader!</em>\n    */\n   public void reload(ClassLoader classloader) {\n+    Objects.requireNonNull(classloader, \"classloader\");\n     final LinkedHashMap<String,S> services = new LinkedHashMap<>(this.services);\n     final SPIClassIterator<S> loader = SPIClassIterator.get(clazz, classloader);\n     while (loader.hasNext()) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/core/src/java/org/apache/lucene/util/NamedSPILoader.java",
                "sha": "33f45b27025349648ff36de6496566f0bf5498f8",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/core/src/java/org/apache/lucene/util/SPIClassIterator.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/util/SPIClassIterator.java?ref=847a8af93b97cfbfc41664c6e3297a4af5c0c012",
                "deletions": 1,
                "filename": "lucene/core/src/java/org/apache/lucene/util/SPIClassIterator.java",
                "patch": "@@ -50,7 +50,11 @@\n   \n   /** Creates a new SPI iterator to lookup services of type {@code clazz} using the context classloader. */\n   public static <S> SPIClassIterator<S> get(Class<S> clazz) {\n-    return new SPIClassIterator<>(clazz, Thread.currentThread().getContextClassLoader());\n+    ClassLoader cl = Thread.currentThread().getContextClassLoader();\n+    if (cl == null) {\n+      cl = clazz.getClassLoader();\n+    }\n+    return new SPIClassIterator<>(clazz, cl);\n   }\n   \n   /** Creates a new SPI iterator to lookup services of type {@code clazz} using the given classloader. */",
                "raw_url": "https://github.com/apache/lucene-solr/raw/847a8af93b97cfbfc41664c6e3297a4af5c0c012/lucene/core/src/java/org/apache/lucene/util/SPIClassIterator.java",
                "sha": "6293e45415bc70d7eea10d4920ebb4c00a423c8c",
                "status": "modified"
            }
        ],
        "message": "LUCENE-6921: Prevent NPE if stupid context classloader is null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1718113 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/889bf7f9538c96c2d6637490e581985415f59baa",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestAnalysisSPILoader.java",
            "TestNamedSPILoader.java",
            "TestSPIClassIterator.java"
        ]
    },
    "lucene-solr_85102bd": {
        "bug_id": "lucene-solr_85102bd",
        "commit": "https://github.com/apache/lucene-solr/commit/85102bd84af1bb060166108f4ab4539edeca1e6f",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/85102bd84af1bb060166108f4ab4539edeca1e6f/src/java/org/apache/lucene/search/PhraseQuery.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/PhraseQuery.java?ref=85102bd84af1bb060166108f4ab4539edeca1e6f",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/search/PhraseQuery.java",
                "patch": "@@ -256,7 +256,7 @@ public void extractTerms(Set queryTerms) {\n   /** Prints a user-readable version of this query. */\n   public String toString(String f) {\n     StringBuffer buffer = new StringBuffer();\n-    if (!field.equals(f)) {\n+    if (field != null && !field.equals(f)) {\n       buffer.append(field);\n       buffer.append(\":\");\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/85102bd84af1bb060166108f4ab4539edeca1e6f/src/java/org/apache/lucene/search/PhraseQuery.java",
                "sha": "efcca47e2b2e234547e5442ea0fdc8c4bb0b02a9",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/85102bd84af1bb060166108f4ab4539edeca1e6f/src/test/org/apache/lucene/search/TestPhraseQuery.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/search/TestPhraseQuery.java?ref=85102bd84af1bb060166108f4ab4539edeca1e6f",
                "deletions": 0,
                "filename": "src/test/org/apache/lucene/search/TestPhraseQuery.java",
                "patch": "@@ -544,5 +544,13 @@ public void testPalyndrome3() throws Exception {\n     //assertTrue(\"reversed scores higher in palindrome\",score1+SCORE_COMP_THRESH<score3);\n     //assertEquals(\"ordered or reversed does not matter\",score2, score3, SCORE_COMP_THRESH);\n   }\n+\n+  // LUCENE-1280\n+  public void testEmptyPhraseQuery() throws Throwable {\n+    final PhraseQuery q1 = new PhraseQuery();\n+    final BooleanQuery q2 = new BooleanQuery();\n+    q2.add(new PhraseQuery(), BooleanClause.Occur.MUST);\n+    q2.toString();\n+  }\n   \n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/85102bd84af1bb060166108f4ab4539edeca1e6f/src/test/org/apache/lucene/search/TestPhraseQuery.java",
                "sha": "e5ab3d8cae0dc0b58ed678edb049dad72e7fa65b",
                "status": "modified"
            }
        ],
        "message": "LUCENE-1280: prevent NPE in PhraseQuery.toString() when the PhraseQuery is empty\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@688689 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/3034575f66028527db0f5cec96875bf53baf7e9e",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestPhraseQuery.java"
        ]
    },
    "lucene-solr_85dbdb7": {
        "bug_id": "lucene-solr_85dbdb7",
        "commit": "https://github.com/apache/lucene-solr/commit/85dbdb7659498e8a41653b642dc0c9b0e1f69304",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/85dbdb7659498e8a41653b642dc0c9b0e1f69304/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java?ref=85dbdb7659498e8a41653b642dc0c9b0e1f69304",
                "deletions": 8,
                "filename": "lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "patch": "@@ -1709,17 +1709,19 @@ private static void checkTermRanges(String field, int maxDoc, Terms terms, long\n \n             byte[] globalMinPackedValue = values.getMinPackedValue(fieldInfo.name);\n             long size = values.size(fieldInfo.name);\n-            if (globalMinPackedValue == null && size != 0) {\n-              throw new RuntimeException(\"getMinPackedValue is null points for field \\\"\" + fieldInfo.name + \"\\\" yet size=\" + size);\n-            }\n-            if (globalMinPackedValue.length != packedBytesCount) {\n+            if (globalMinPackedValue == null) {\n+              if (size != 0) {\n+                throw new RuntimeException(\"getMinPackedValue is null points for field \\\"\" + fieldInfo.name + \"\\\" yet size=\" + size);\n+              }\n+            } else if (globalMinPackedValue.length != packedBytesCount) {\n               throw new RuntimeException(\"getMinPackedValue for field \\\"\" + fieldInfo.name + \"\\\" return length=\" + globalMinPackedValue.length + \" array, but should be \" + packedBytesCount);\n             }\n             byte[] globalMaxPackedValue = values.getMaxPackedValue(fieldInfo.name);\n-            if (globalMaxPackedValue == null && size != 0) {\n-              throw new RuntimeException(\"getMaxPackedValue is null points for field \\\"\" + fieldInfo.name + \"\\\" yet size=\" + size);\n-            }\n-            if (globalMaxPackedValue.length != packedBytesCount) {\n+            if (globalMaxPackedValue == null) {\n+              if (size != 0) {\n+                throw new RuntimeException(\"getMaxPackedValue is null points for field \\\"\" + fieldInfo.name + \"\\\" yet size=\" + size);\n+              }\n+            } else if (globalMaxPackedValue.length != packedBytesCount) {\n               throw new RuntimeException(\"getMaxPackedValue for field \\\"\" + fieldInfo.name + \"\\\" return length=\" + globalMaxPackedValue.length + \" array, but should be \" + packedBytesCount);\n             }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/85dbdb7659498e8a41653b642dc0c9b0e1f69304/lucene/core/src/java/org/apache/lucene/index/CheckIndex.java",
                "sha": "db3292486a0c7f3fc4ce93411b51968f0543557a",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/85dbdb7659498e8a41653b642dc0c9b0e1f69304/lucene/core/src/test/org/apache/lucene/index/TestPointValues.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestPointValues.java?ref=85dbdb7659498e8a41653b642dc0c9b0e1f69304",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestPointValues.java",
                "patch": "@@ -34,6 +34,7 @@\n import org.apache.lucene.document.FloatPoint;\n import org.apache.lucene.document.IntPoint;\n import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.document.StringField;\n import org.apache.lucene.index.PointValues.IntersectVisitor;\n import org.apache.lucene.index.PointValues.Relation;\n import org.apache.lucene.index.PointValues;\n@@ -540,4 +541,25 @@ public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n     w.close();\n     dir.close();\n   }\n+\n+  public void testDeleteAllPointDocs() throws Exception {\n+    Directory dir = newDirectory();\n+    IndexWriterConfig iwc = newIndexWriterConfig();\n+    IndexWriter w = new IndexWriter(dir, iwc);\n+    Document doc = new Document();\n+    doc.add(new StringField(\"id\", \"0\", Field.Store.NO));\n+    doc.add(new IntPoint(\"int\", 17));\n+    w.addDocument(doc);\n+    w.addDocument(new Document());\n+    w.commit();\n+\n+    w.deleteDocuments(new Term(\"id\", \"0\"));\n+    \n+    w.forceMerge(1);\n+    DirectoryReader r = w.getReader();\n+    assertEquals(0, r.leaves().get(0).reader().getPointValues().size(\"int\"));\n+    w.close();\n+    r.close();\n+    dir.close();\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/85dbdb7659498e8a41653b642dc0c9b0e1f69304/lucene/core/src/test/org/apache/lucene/index/TestPointValues.java",
                "sha": "506d58cedbb48bd63b97f4156827be779a6a5725",
                "status": "modified"
            }
        ],
        "message": "fix NPE, add test case",
        "parent": "https://github.com/apache/lucene-solr/commit/3c02ab21870c44250a2bc28262726459b220615e",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestCheckIndex.java"
        ]
    },
    "lucene-solr_86039cd": {
        "bug_id": "lucene-solr_86039cd",
        "commit": "https://github.com/apache/lucene-solr/commit/86039cdb361babf39552aac44b9cc789134e2f11",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/86039cdb361babf39552aac44b9cc789134e2f11/src/java/org/apache/lucene/index/SegmentReader.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/SegmentReader.java?ref=86039cdb361babf39552aac44b9cc789134e2f11",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/index/SegmentReader.java",
                "patch": "@@ -106,7 +106,6 @@\n       segment = si.name;\n       this.readBufferSize = readBufferSize;\n       this.dir = dir;\n-      this.origInstance = origInstance;\n \n       boolean success = false;\n \n@@ -144,6 +143,12 @@\n           decRef();\n         }\n       }\n+\n+      // Must assign this at the end -- if we hit an\n+      // exception above core, we don't want to attempt to\n+      // purge the FieldCache (will hit NPE because core is\n+      // not assigned yet).\n+      this.origInstance = origInstance;\n     }\n \n     synchronized TermVectorsReader getTermVectorsReaderOrig() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/86039cdb361babf39552aac44b9cc789134e2f11/src/java/org/apache/lucene/index/SegmentReader.java",
                "sha": "09aa645203061ca69ffdbc44359ebf41558467e4",
                "status": "modified"
            }
        ],
        "message": "LUCENE-2135: don't flush field cache if we hit exception during init (it leads to NPE)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@890439 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/c67b43ef34955bd5218bf87da961171e749a3fec",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSegmentReader.java"
        ]
    },
    "lucene-solr_8643227": {
        "bug_id": "lucene-solr_8643227",
        "commit": "https://github.com/apache/lucene-solr/commit/86432275f6185436b437c6320ba41cac4ed46f95",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/86432275f6185436b437c6320ba41cac4ed46f95/src/java/org/apache/lucene/index/IndexWriter.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/IndexWriter.java?ref=86432275f6185436b437c6320ba41cac4ed46f95",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/index/IndexWriter.java",
                "patch": "@@ -2273,7 +2273,9 @@ else if (next != si.getDocStoreOffset())\n       }\n     } finally {\n       // close readers before we attempt to delete now-obsolete segments\n-      merger.closeReaders();\n+      if (merger != null) {\n+        merger.closeReaders();\n+      }\n     }\n \n     // Give deleter a chance to remove files now.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/86432275f6185436b437c6320ba41cac4ed46f95/src/java/org/apache/lucene/index/IndexWriter.java",
                "sha": "02826ada5905b7c75a6a78bc52ae36c7ea74fc11",
                "status": "modified"
            }
        ],
        "message": "protect object against NPE in finally block, as an NPE here would hide the original exception\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@558160 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/58027a24bb6972e8c173d55dc29e3b274a10d08b",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestIndexWriter.java"
        ]
    },
    "lucene-solr_8808cf5": {
        "bug_id": "lucene-solr_8808cf5",
        "commit": "https://github.com/apache/lucene-solr/commit/8808cf5373522f37bce509729b0b3a7fc9bcbd88",
        "file": [
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8808cf5373522f37bce509729b0b3a7fc9bcbd88/lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java?ref=8808cf5373522f37bce509729b0b3a7fc9bcbd88",
                "deletions": 12,
                "filename": "lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java",
                "patch": "@@ -145,18 +145,19 @@ public SimpleNaiveBayesClassifier(LeafReader leafReader, Analyzer analyzer, Quer\n     List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n \n     Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n-    TermsEnum classesEnum = classes.iterator();\n-    BytesRef next;\n-    String[] tokenizedText = tokenize(inputDocument);\n-    int docsWithClassSize = countDocsWithClass();\n-    while ((next = classesEnum.next()) != null) {\n-      if (next.length > 0) {\n-        Term term = new Term(this.classFieldName, next);\n-        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n-        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n+    if (classes != null) {\n+      TermsEnum classesEnum = classes.iterator();\n+      BytesRef next;\n+      String[] tokenizedText = tokenize(inputDocument);\n+      int docsWithClassSize = countDocsWithClass();\n+      while ((next = classesEnum.next()) != null) {\n+        if (next.length > 0) {\n+          Term term = new Term(this.classFieldName, next);\n+          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n+          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n+        }\n       }\n     }\n-\n     // normalization; the values transforms to a 0-1 range\n     return normClassificationResults(assignedClasses);\n   }\n@@ -168,8 +169,9 @@ public SimpleNaiveBayesClassifier(LeafReader leafReader, Analyzer analyzer, Quer\n    * @throws IOException if accessing to term vectors or search fails\n    */\n   protected int countDocsWithClass() throws IOException {\n-    int docCount = MultiFields.getTerms(this.leafReader, this.classFieldName).getDocCount();\n-    if (docCount == -1) { // in case codec doesn't support getDocCount\n+    Terms terms = MultiFields.getTerms(this.leafReader, this.classFieldName);\n+    int docCount;\n+    if (terms == null || terms.getDocCount() == -1) { // in case codec doesn't support getDocCount\n       TotalHitCountCollector classQueryCountCollector = new TotalHitCountCollector();\n       BooleanQuery.Builder q = new BooleanQuery.Builder();\n       q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, String.valueOf(WildcardQuery.WILDCARD_STRING))), BooleanClause.Occur.MUST));\n@@ -179,6 +181,8 @@ protected int countDocsWithClass() throws IOException {\n       indexSearcher.search(q.build(),\n           classQueryCountCollector);\n       docCount = classQueryCountCollector.getTotalHits();\n+    } else {\n+      docCount = terms.getDocCount();\n     }\n     return docCount;\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8808cf5373522f37bce509729b0b3a7fc9bcbd88/lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier.java",
                "sha": "2514ae1e64409b8ad2ae4b3f758e759406f734c6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8808cf5373522f37bce509729b0b3a7fc9bcbd88/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java?ref=8808cf5373522f37bce509729b0b3a7fc9bcbd88",
                "deletions": 22,
                "filename": "lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "patch": "@@ -168,28 +168,6 @@ private void analyzeSeedDocument(Document inputDocument, Map<String, List<String\n     }\n   }\n \n-  /**\n-   * Counts the number of documents in the index having at least a value for the 'class' field\n-   *\n-   * @return the no. of documents having a value for the 'class' field\n-   * @throws java.io.IOException If accessing to term vectors or search fails\n-   */\n-  protected int countDocsWithClass() throws IOException {\n-    int docCount = MultiFields.getTerms(this.leafReader, this.classFieldName).getDocCount();\n-    if (docCount == -1) { // in case codec doesn't support getDocCount\n-      TotalHitCountCollector classQueryCountCollector = new TotalHitCountCollector();\n-      BooleanQuery.Builder q = new BooleanQuery.Builder();\n-      q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, String.valueOf(WildcardQuery.WILDCARD_STRING))), BooleanClause.Occur.MUST));\n-      if (query != null) {\n-        q.add(query, BooleanClause.Occur.MUST);\n-      }\n-      indexSearcher.search(q.build(),\n-          classQueryCountCollector);\n-      docCount = classQueryCountCollector.getTotalHits();\n-    }\n-    return docCount;\n-  }\n-\n   /**\n    * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n    *",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8808cf5373522f37bce509729b0b3a7fc9bcbd88/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "sha": "2c5a493ed773d16d0af710b09ffcc8900769e377",
                "status": "modified"
            }
        ],
        "message": "LUCENE-7303 - avoid NPE in MultiFields.getTerms(leafReader, classFieldName), removed duplicated code in DocumentSNBC",
        "parent": "https://github.com/apache/lucene-solr/commit/2aabed4ab630a65f514cd536fbf79bb5c0a342c5",
        "repo": "lucene-solr",
        "unit_tests": [
            "SimpleNaiveBayesClassifierTest.java",
            "SimpleNaiveBayesDocumentClassifierTest.java"
        ]
    },
    "lucene-solr_89f6d17": {
        "bug_id": "lucene-solr_89f6d17",
        "commit": "https://github.com/apache/lucene-solr/commit/89f6d170f5db176c81980d58ffe21484885eb464",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/89f6d170f5db176c81980d58ffe21484885eb464/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java?ref=89f6d170f5db176c81980d58ffe21484885eb464",
                "deletions": 7,
                "filename": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "patch": "@@ -1217,7 +1217,7 @@ public SortedSetDocValues getSortedSetDocValues(String field) {\n     @Override\n     public PointValues getPointValues(String fieldName) {\n       Info info = fields.get(fieldName);\n-      if (info.pointValues == null) {\n+      if (info == null || info.pointValues == null) {\n         return null;\n       }\n       return new MemoryIndexPointValues(info);\n@@ -1529,6 +1529,7 @@ public long cost() {\n \n       MemoryIndexPointValues(Info info) {\n         this.info = Objects.requireNonNull(info);\n+        Objects.requireNonNull(info.pointValues, \"Field does not have points\");\n       }\n \n       @Override\n@@ -1548,12 +1549,7 @@ public long estimatePointCount(IntersectVisitor visitor) {\n \n       @Override\n       public byte[] getMinPackedValue() throws IOException {\n-        BytesRef[] values = info.pointValues;\n-        if (values != null) {\n-          return info.minPackedValue;\n-        } else {\n-          return null;\n-        }\n+        return info.minPackedValue;\n       }\n \n       @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/89f6d170f5db176c81980d58ffe21484885eb464/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "sha": "a1f2b0789ee059fb1b6f11c18f7e2a4935175e15",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/89f6d170f5db176c81980d58ffe21484885eb464/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java?ref=89f6d170f5db176c81980d58ffe21484885eb464",
                "deletions": 0,
                "filename": "lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "patch": "@@ -40,6 +40,7 @@\n import org.apache.lucene.document.SortedDocValuesField;\n import org.apache.lucene.document.SortedNumericDocValuesField;\n import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.document.StoredField;\n import org.apache.lucene.document.StringField;\n import org.apache.lucene.document.TextField;\n import org.apache.lucene.index.BinaryDocValues;\n@@ -422,6 +423,17 @@ public void testPointValues() throws Exception {\n     }\n   }\n \n+  public void testMissingPoints() throws IOException {\n+    Document doc = new Document();\n+    doc.add(new StoredField(\"field\", 42));\n+    MemoryIndex mi = MemoryIndex.fromDocument(doc, analyzer);\n+    IndexSearcher indexSearcher = mi.createSearcher();\n+    // field that exists but does not have points\n+    assertNull(indexSearcher.getIndexReader().leaves().get(0).reader().getPointValues(\"field\"));\n+    // field that does not exist\n+    assertNull(indexSearcher.getIndexReader().leaves().get(0).reader().getPointValues(\"some_missing_field\"));\n+  }\n+\n   public void testPointValuesDoNotAffectPositionsOrOffset() throws Exception {\n     MemoryIndex mi = new MemoryIndex(true, true);\n     mi.addField(new TextField(\"text\", \"quick brown fox\", Field.Store.NO), analyzer);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/89f6d170f5db176c81980d58ffe21484885eb464/lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndex.java",
                "sha": "1e20f30509b669ab86c271c2dc2b7bed0a03494a",
                "status": "modified"
            }
        ],
        "message": "LUCENE-7783: Fix NPE when getting points on a non-existing field.",
        "parent": "https://github.com/apache/lucene-solr/commit/1d74134500d236bdc501e9100ac5c48c732d054d",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestMemoryIndex.java"
        ]
    },
    "lucene-solr_8a641eb": {
        "bug_id": "lucene-solr_8a641eb",
        "commit": "https://github.com/apache/lucene-solr/commit/8a641eb4f7fe24af90042dbe7065065a297622bf",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/BooleanQuery.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/BooleanQuery.java?ref=8a641eb4f7fe24af90042dbe7065065a297622bf",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/search/BooleanQuery.java",
                "patch": "@@ -294,7 +294,9 @@ public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder, boolean topSc\n         BooleanClause c = (BooleanClause) cIter.next();\n         Scorer subScorer = w.scorer(reader, true, false);\n         if (subScorer == null) {\n-          return null;\n+          if (c.isRequired()) {\n+            return null;\n+          }\n         } else if (c.isRequired()) {\n           required.add(subScorer);\n         } else if (c.isProhibited()) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/BooleanQuery.java",
                "sha": "6f6673cb760b3486da80dfd789a2a1165f3bfa5e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java?ref=8a641eb4f7fe24af90042dbe7065065a297622bf",
                "deletions": 3,
                "filename": "src/java/org/apache/lucene/search/DisjunctionMaxQuery.java",
                "patch": "@@ -134,9 +134,7 @@ public Scorer scorer(IndexReader reader, boolean scoreDocsInOrder,\n       for (Iterator iter = weights.iterator(); iter.hasNext();) {\n         QueryWeight w = (QueryWeight) iter.next();\n         Scorer subScorer = w.scorer(reader, true, false);\n-        if (subScorer == null) {\n-          return null;\n-        } else if (subScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n+        if (subScorer != null && subScorer.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n           scorers[idx++] = subScorer;\n         }\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/DisjunctionMaxQuery.java",
                "sha": "3a0969e365213375cfaed7ca7a7e00613c08a467",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/IndexSearcher.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/search/IndexSearcher.java?ref=8a641eb4f7fe24af90042dbe7065065a297622bf",
                "deletions": 2,
                "filename": "src/java/org/apache/lucene/search/IndexSearcher.java",
                "patch": "@@ -219,7 +219,9 @@ public TopFieldDocs search(QueryWeight weight, Filter filter, final int nDocs,\n       hcw.setNextReader(reader, 0);\n       if (filter == null) {\n         Scorer scorer = weight.scorer(reader, true, true);\n-        scorer.score(hcw);\n+        if (scorer != null) {\n+          scorer.score(hcw);\n+        }\n       } else {\n         searchWithFilter(reader, weight, filter, hcw);\n       }\n@@ -239,7 +241,9 @@ public void search(QueryWeight weight, Filter filter, Collector collector)\n       for (int i = 0; i < subReaders.length; i++) { // search each subreader\n         collector.setNextReader(subReaders[i], docStarts[i]);\n         Scorer scorer = weight.scorer(subReaders[i], !collector.acceptsDocsOutOfOrder(), true);\n-        scorer.score(collector);\n+        if (scorer != null) {\n+          scorer.score(collector);\n+        }\n       }\n     } else {\n       for (int i = 0; i < subReaders.length; i++) { // search each subreader",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8a641eb4f7fe24af90042dbe7065065a297622bf/src/java/org/apache/lucene/search/IndexSearcher.java",
                "sha": "203f524fb24fd5b2407fe58fa14110bb0aae3cf7",
                "status": "modified"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/lucene-solr/blob/8a641eb4f7fe24af90042dbe7065065a297622bf/src/test/org/apache/lucene/search/TestBooleanQuery.java",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/search/TestBooleanQuery.java?ref=8a641eb4f7fe24af90042dbe7065065a297622bf",
                "deletions": 1,
                "filename": "src/test/org/apache/lucene/search/TestBooleanQuery.java",
                "patch": "@@ -16,7 +16,13 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.analysis.WhitespaceAnalyzer;\n+import org.apache.lucene.store.MockRAMDirectory;\n+import org.apache.lucene.store.Directory;\n import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.index.Term;\n \n@@ -50,5 +56,32 @@ public void testException() {\n       // okay\n     }\n   }\n+\n+  // LUCENE-1630\n+  public void testNullOrSubScorer() throws Throwable {\n+    Directory dir = new MockRAMDirectory();\n+    IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);\n+    Document doc = new Document();\n+    doc.add(new Field(\"field\", \"a b c d\", Field.Store.NO, Field.Index.ANALYZED));\n+    w.addDocument(doc);\n+    IndexReader r = w.getReader();\n+    IndexSearcher s = new IndexSearcher(r);\n+    BooleanQuery q = new BooleanQuery();\n+    q.add(new TermQuery(new Term(\"field\", \"a\")), BooleanClause.Occur.SHOULD);\n+\n+    // PhraseQuery w/ no terms added returns a null scorer\n+    PhraseQuery pq = new PhraseQuery();\n+    q.add(pq, BooleanClause.Occur.SHOULD);\n+    assertEquals(1, s.search(q, 10).totalHits);\n+\n+    DisjunctionMaxQuery dmq = new DisjunctionMaxQuery(1.0f);\n+    dmq.add(new TermQuery(new Term(\"field\", \"a\")));\n+    dmq.add(pq);\n+    assertEquals(1, s.search(dmq, 10).totalHits);\n+    \n+    r.close();\n+    w.close();\n+    dir.close();\n+  }\n   \n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/8a641eb4f7fe24af90042dbe7065065a297622bf/src/test/org/apache/lucene/search/TestBooleanQuery.java",
                "sha": "e452a75af1f7a7f690008167625556b791570d17",
                "status": "modified"
            }
        ],
        "message": "LUCENE-1630: fix NPEs\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@788802 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/890d53acfb1d2cd362abea9d5541aae071b7c466",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestBooleanQuery.java",
            "TestDisjunctionMaxQuery.java",
            "TestIndexSearcher.java"
        ]
    },
    "lucene-solr_911ee1d": {
        "bug_id": "lucene-solr_911ee1d",
        "commit": "https://github.com/apache/lucene-solr/commit/911ee1dcd3435269e6f3970d3754aee4ab91e725",
        "file": [
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 5,
                "filename": "solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java",
                "patch": "@@ -1163,7 +1163,7 @@ private void migrateKey(ClusterState clusterState, DocCollection sourceCollectio\n       Map<String, RoutingRule> rules = zkStateReader.getClusterState().getSlice(sourceCollection.getName(), sourceSlice.getName()).getRoutingRules();\n       if (rules != null) {\n         RoutingRule rule = rules.get(splitKey);\n-        if (rule.getRouteRanges().contains(splitRange)) {\n+        if (rule != null && rule.getRouteRanges().contains(splitRange)) {\n           added = true;\n           break;\n         }\n@@ -1179,13 +1179,13 @@ private void migrateKey(ClusterState clusterState, DocCollection sourceCollectio\n     Replica sourceLeader = sourceSlice.getLeader();\n \n     // create a temporary collection with just one node on the shard leader\n-    String sourceLeaderUrl = zkStateReader.getZkClient().getBaseUrlForNodeName(sourceLeader.getNodeName());\n-    if (sourceLeaderUrl.startsWith(\"http://\")) sourceLeaderUrl = sourceLeaderUrl.substring(7);\n+    String configName = zkStateReader.readConfigName(sourceCollection.getName());\n     Map<String, Object> props = ZkNodeProps.makeMap(\n         QUEUE_OPERATION, CREATECOLLECTION,\n         \"name\", tempSourceCollectionName,\n         REPLICATION_FACTOR, 1,\n         NUM_SLICES, 1,\n+        COLL_CONF, configName,\n         CREATE_NODE_SET, sourceLeader.getNodeName());\n     log.info(\"Creating temporary collection: \" + props);\n     createCollection(clusterState, new ZkNodeProps(props), results);\n@@ -1194,6 +1194,23 @@ private void migrateKey(ClusterState clusterState, DocCollection sourceCollectio\n     Slice tempSourceSlice = clusterState.getCollection(tempSourceCollectionName).getSlices().iterator().next();\n     Replica tempSourceLeader = clusterState.getLeader(tempSourceCollectionName, tempSourceSlice.getName());\n \n+    String tempCollectionReplica1 = tempSourceCollectionName + \"_\" + tempSourceSlice.getName() + \"_replica1\";\n+    String coreNodeName = waitForCoreNodeName(clusterState.getCollection(tempSourceCollectionName),\n+        zkStateReader.getZkClient().getBaseUrlForNodeName(sourceLeader.getNodeName()), tempCollectionReplica1);\n+    // wait for the replicas to be seen as active on temp source leader\n+    log.info(\"Asking source leader to wait for: \" + tempCollectionReplica1 + \" to be alive on: \" + sourceLeader.getNodeName());\n+    CoreAdminRequest.WaitForState cmd = new CoreAdminRequest.WaitForState();\n+    cmd.setCoreName(tempCollectionReplica1);\n+    cmd.setNodeName(sourceLeader.getNodeName());\n+    cmd.setCoreNodeName(coreNodeName);\n+    cmd.setState(ZkStateReader.ACTIVE);\n+    cmd.setCheckLive(true);\n+    cmd.setOnlyIfLeader(true);\n+    sendShardRequest(tempSourceLeader.getNodeName(), new ModifiableSolrParams(cmd.getParams()));\n+\n+    collectShardResponses(results, true,\n+        \"MIGRATE failed to create temp collection leader or timed out waiting for it to come up\");\n+\n     log.info(\"Asking source leader to split index\");\n     params = new ModifiableSolrParams();\n     params.set(CoreAdminParams.ACTION, CoreAdminAction.SPLIT.toString());\n@@ -1215,11 +1232,11 @@ private void migrateKey(ClusterState clusterState, DocCollection sourceCollectio\n     params.set(CoreAdminParams.SHARD, tempSourceSlice.getName());\n     sendShardRequest(targetLeader.getNodeName(), params);\n \n-    String coreNodeName = waitForCoreNodeName(clusterState.getCollection(tempSourceCollectionName),\n+    coreNodeName = waitForCoreNodeName(clusterState.getCollection(tempSourceCollectionName),\n         zkStateReader.getZkClient().getBaseUrlForNodeName(targetLeader.getNodeName()), tempCollectionReplica2);\n     // wait for the replicas to be seen as active on temp source leader\n     log.info(\"Asking temp source leader to wait for: \" + tempCollectionReplica2 + \" to be alive on: \" + targetLeader.getNodeName());\n-    CoreAdminRequest.WaitForState cmd = new CoreAdminRequest.WaitForState();\n+    cmd = new CoreAdminRequest.WaitForState();\n     cmd.setCoreName(tempSourceLeader.getStr(\"core\"));\n     cmd.setNodeName(targetLeader.getNodeName());\n     cmd.setCoreNodeName(coreNodeName);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java",
                "sha": "c0c7a93601b0a7979dcf2fb32dd861ece2b9b380",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/ZkController.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 29,
                "filename": "solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                "patch": "@@ -733,35 +733,6 @@ public boolean pathExists(String path) throws KeeperException,\n     return zkClient.exists(path, true);\n   }\n \n-  /**\n-   * Returns config value\n-   */\n-  public String readConfigName(String collection) throws KeeperException,\n-      InterruptedException {\n-\n-    String configName = null;\n-\n-    String path = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + collection;\n-    if (log.isInfoEnabled()) {\n-      log.info(\"Load collection config from:\" + path);\n-    }\n-    byte[] data = zkClient.getData(path, null, null, true);\n-    \n-    if(data != null) {\n-      ZkNodeProps props = ZkNodeProps.load(data);\n-      configName = props.getStr(CONFIGNAME_PROP);\n-    }\n-    \n-    if (configName != null && !zkClient.exists(CONFIGS_ZKNODE + \"/\" + configName, true)) {\n-      log.error(\"Specified config does not exist in ZooKeeper:\" + configName);\n-      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,\n-          \"Specified config does not exist in ZooKeeper:\" + configName);\n-    }\n-\n-    return configName;\n-  }\n-\n-\n \n   /**\n    * Register shard with ZooKeeper.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/cloud/ZkController.java",
                "sha": "ee2a8e2956a5c689b62f98a78618b59d2d1ea06d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/CoreContainer.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "patch": "@@ -676,7 +676,7 @@ public void reload(String name) {\n             String collection = cd.getCloudDescriptor().getCollectionName();\n             zkSys.getZkController().createCollectionZkNode(cd.getCloudDescriptor());\n \n-            String zkConfigName = zkSys.getZkController().readConfigName(collection);\n+            String zkConfigName = zkSys.getZkController().getZkStateReader().readConfigName(collection);\n             if (zkConfigName == null) {\n               log.error(\"Could not find config name for collection:\" + collection);\n               throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/core/CoreContainer.java",
                "sha": "9aaabfb75912e982e5eeedaf8af05a2269327ee0",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/core/ZkContainer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/ZkContainer.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/core/ZkContainer.java",
                "patch": "@@ -220,7 +220,7 @@ SolrCore createFromZk(String instanceDir, CoreDescriptor dcore, SolrResourceLoad\n       String collection = dcore.getCloudDescriptor().getCollectionName();\n       zkController.createCollectionZkNode(dcore.getCloudDescriptor());\n       \n-      zkConfigName = zkController.readConfigName(collection);\n+      zkConfigName = zkController.getZkStateReader().readConfigName(collection);\n       if (zkConfigName == null) {\n         log.error(\"Could not find config name for collection:\" + collection);\n         throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/core/ZkContainer.java",
                "sha": "e61487aebccfd950accc57c9a15c7c50a9fc5dbe",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java",
                "patch": "@@ -208,7 +208,7 @@ public void inform(SolrCore core) {\n         ZkController zkController = core.getCoreDescriptor().getCoreContainer().getZkController();\n         if (zkController != null) {\n           // TODO : shouldn't have to keep reading the config name when it has been read before\n-          exists = zkController.configFileExists(zkController.readConfigName(core.getCoreDescriptor().getCloudDescriptor().getCollectionName()), f);\n+          exists = zkController.configFileExists(zkController.getZkStateReader().readConfigName(core.getCoreDescriptor().getCloudDescriptor().getCollectionName()), f);\n         } else {\n           File fC = new File(core.getResourceLoader().getConfigDir(), f);\n           File fD = new File(core.getDataDir(), f);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/java/org/apache/solr/handler/component/QueryElevationComponent.java",
                "sha": "b0caa898c287f68fe0eaeba6b9c55e625e3b73e4",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/test/org/apache/solr/cloud/ZkControllerTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/ZkControllerTest.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 1,
                "filename": "solr/core/src/test/org/apache/solr/cloud/ZkControllerTest.java",
                "patch": "@@ -188,7 +188,7 @@ public void testReadConfigName() throws Exception {\n             }\n           });\n       try {\n-        String configName = zkController.readConfigName(COLLECTION_NAME);\n+        String configName = zkController.getZkStateReader().readConfigName(COLLECTION_NAME);\n         assertEquals(configName, actualConfigName);\n       } finally {\n         zkController.close();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/core/src/test/org/apache/solr/cloud/ZkControllerTest.java",
                "sha": "3352e22ab86cd3cb6f91155f64f2c72ed33727d9",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/lucene-solr/blob/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java?ref=911ee1dcd3435269e6f3970d3754aee4ab91e725",
                "deletions": 0,
                "filename": "solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "patch": "@@ -74,6 +74,9 @@\n   public static final String ACTIVE = \"active\";\n   public static final String DOWN = \"down\";\n   public static final String SYNC = \"sync\";\n+\n+  public static final String CONFIGS_ZKNODE = \"/configs\";\n+  public final static String CONFIGNAME_PROP=\"configName\";\n   \n   private volatile ClusterState clusterState;\n \n@@ -115,6 +118,35 @@ public static Object fromJSON(byte[] utf8) {\n     }\n   }\n \n+  /**\n+   * Returns config value\n+   * @param collection\n+   */\n+  public String readConfigName(String collection) throws KeeperException,\n+      InterruptedException {\n+\n+    String configName = null;\n+\n+    String path = COLLECTIONS_ZKNODE + \"/\" + collection;\n+    if (log.isInfoEnabled()) {\n+      log.info(\"Load collection config from:\" + path);\n+    }\n+    byte[] data = zkClient.getData(path, null, null, true);\n+\n+    if(data != null) {\n+      ZkNodeProps props = ZkNodeProps.load(data);\n+      configName = props.getStr(CONFIGNAME_PROP);\n+    }\n+\n+    if (configName != null && !zkClient.exists(CONFIGS_ZKNODE + \"/\" + configName, true)) {\n+      log.error(\"Specified config does not exist in ZooKeeper:\" + configName);\n+      throw new ZooKeeperException(ErrorCode.SERVER_ERROR,\n+          \"Specified config does not exist in ZooKeeper:\" + configName);\n+    }\n+\n+    return configName;\n+  }\n+\n \n   private static class ZKTF implements ThreadFactory {\n     private static ThreadGroup tg = new ThreadGroup(\"ZkStateReader\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/911ee1dcd3435269e6f3970d3754aee4ab91e725/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java",
                "sha": "35bc01e7d042ccb05043d7037ee9f1c3855202a6",
                "status": "modified"
            }
        ],
        "message": "SOLR-5308: Use source collection's configName to create temp collection. Fixed NPE routing rule wait loop. Wait for temp collection leader to be active before splitting the source index.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1544414 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/0971bc8f219b7e558efe659f0af77c163d96a019",
        "repo": "lucene-solr",
        "unit_tests": [
            "ZkControllerTest.java",
            "TestCoreContainer.java",
            "QueryElevationComponentTest.java",
            "ZkStateReaderTest.java"
        ]
    },
    "lucene-solr_93ba7da": {
        "bug_id": "lucene-solr_93ba7da",
        "commit": "https://github.com/apache/lucene-solr/commit/93ba7da65f5836d18ed933907c897d958aaa2b63",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/93ba7da65f5836d18ed933907c897d958aaa2b63/solr/core/src/java/org/apache/solr/client/solrj/embedded/JettySolrRunner.java",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/client/solrj/embedded/JettySolrRunner.java?ref=93ba7da65f5836d18ed933907c897d958aaa2b63",
                "deletions": 23,
                "filename": "solr/core/src/java/org/apache/solr/client/solrj/embedded/JettySolrRunner.java",
                "patch": "@@ -148,10 +148,6 @@ public void destroy() {\n     }\n   }\n \n-\n-\n-\n-\n   public JettySolrRunner(String solrHome, String context, int port) {\n     this.init(solrHome, context, port, true);\n     this.name = \"jetty-\" + JETTY_ID_COUNTER.incrementAndGet();\n@@ -218,11 +214,19 @@ public JettySolrRunner(String solrHome, String context, int port,\n   \n   private void init(String solrHome, String context, int port, boolean stopAtShutdown) {\n     this.context = context;\n-\n     this.solrHome = solrHome;\n     this.stopAtShutdown = stopAtShutdown;\n \n     System.setProperty(\"solr.solr.home\", solrHome);\n+    \n+    QueuedThreadPool qtp = new QueuedThreadPool();\n+    qtp.setMaxThreads(10000);\n+    qtp.setIdleTimeout((int) TimeUnit.SECONDS.toMillis(5));\n+    qtp.setStopTimeout((int) TimeUnit.MINUTES.toMillis(1));\n+    server = new Server(qtp);\n+    server.manage(qtp);\n+    server.setStopAtShutdown(stopAtShutdown);\n+    \n     if (System.getProperty(\"jetty.testMode\") != null) {\n       // if this property is true, then jetty will be configured to use SSL\n       // leveraging the same system properties as java to specify\n@@ -237,15 +241,6 @@ private void init(String solrHome, String context, int port, boolean stopAtShutd\n       final SslContextFactory sslcontext = new SslContextFactory(false);\n       sslInit(useSsl, sslcontext);\n \n-      QueuedThreadPool qtp = new QueuedThreadPool();\n-      qtp.setMaxThreads(10000);\n-      qtp.setIdleTimeout((int) TimeUnit.SECONDS.toMillis(5));\n-      qtp.setStopTimeout((int) TimeUnit.MINUTES.toMillis(1));\n-\n-      server = new Server(qtp);\n-      server.setStopAtShutdown(stopAtShutdown);\n-      server.manage(qtp);\n-\n       ServerConnector connector;\n       if (useSsl) {\n         HttpConfiguration configuration = new HttpConfiguration();\n@@ -273,15 +268,7 @@ private void init(String solrHome, String context, int port, boolean stopAtShutd\n     } else {\n       ServerConnector connector = new ServerConnector(server, new HttpConnectionFactory());\n       connector.setPort(port);\n-\n-      QueuedThreadPool qtp = new QueuedThreadPool();\n-      qtp.setMaxThreads(10000);\n-      qtp.setIdleTimeout((int) TimeUnit.SECONDS.toMillis(5));\n-      qtp.setStopTimeout((int) TimeUnit.SECONDS.toMillis(1));\n-\n-      server = new Server(qtp);\n-      server.setStopAtShutdown(stopAtShutdown);\n-      server.manage(qtp);\n+      server.setConnectors(new Connector[] {connector});\n     }\n \n     // Initialize the servlets",
                "raw_url": "https://github.com/apache/lucene-solr/raw/93ba7da65f5836d18ed933907c897d958aaa2b63/solr/core/src/java/org/apache/solr/client/solrj/embedded/JettySolrRunner.java",
                "sha": "5e6b34e4470560b7148d1c3a6fbc6a9ec218f557",
                "status": "modified"
            }
        ],
        "message": "SOLR-4839: Avoid NPE when jetty.testMode=false\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1657495 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/118a8263781b35015cc56222c5d74f81ff412284",
        "repo": "lucene-solr",
        "unit_tests": [
            "JettySolrRunnerTest.java",
            "TestJettySolrRunner.java"
        ]
    },
    "lucene-solr_95968c6": {
        "bug_id": "lucene-solr_95968c6",
        "commit": "https://github.com/apache/lucene-solr/commit/95968c69fd3acdbd276a6785732458e7595bebae",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/lucene/ivy-versions.properties",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/ivy-versions.properties?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 2,
                "filename": "lucene/ivy-versions.properties",
                "patch": "@@ -40,6 +40,7 @@ com.sun.jersey.version = 1.9\n /com.sun.mail/javax.mail = 1.5.1\n \n /com.tdunning/t-digest = 3.1\n+/com.vaadin.external.google/android-json = 0.0.20131108.vaadin1\n /commons-beanutils/commons-beanutils = 1.8.3\n /commons-cli/commons-cli = 1.2\n /commons-codec/commons-codec = 1.10\n@@ -145,7 +146,7 @@ org.apache.hadoop.version = 2.7.2\n /org.apache.htrace/htrace-core = 3.2.0-incubating\n \n # The httpcore version is often different from the httpclient and httpmime versions,\n-# so the httpcore version value should not share the same symbolic name with them.  \n+# so the httpcore version value should not share the same symbolic name with them.\n /org.apache.httpcomponents/httpclient = 4.4.1\n /org.apache.httpcomponents/httpcore = 4.4.1\n /org.apache.httpcomponents/httpmime = 4.4.1\n@@ -187,6 +188,11 @@ org.apache.uima.version = 2.3.1\n /org.apache.velocity/velocity-tools = 2.0\n /org.apache.xmlbeans/xmlbeans = 2.6.0\n /org.apache.zookeeper/zookeeper = 3.4.10\n+\n+# v1.6.0-alpha.3 of asciidoctor-ant includes asciidoctorj-pdf 1.5.0-alpha.15,\n+# which is the same as asciidoctor-pdf 1.5.0-alpha.15\n+/org.asciidoctor/asciidoctor-ant = 1.6.0-alpha.3\n+\n /org.aspectj/aspectjrt = 1.8.0\n \n org.bouncycastle.version = 1.45\n@@ -236,6 +242,8 @@ org.gagravarr.vorbis.java.version = 0.8\n /org.gagravarr/vorbis-java-core = ${org.gagravarr.vorbis.java.version}\n /org.gagravarr/vorbis-java-tika = ${org.gagravarr.vorbis.java.version}\n \n+/org.jsoup/jsoup = 1.8.2\n+\n /org.locationtech.spatial4j/spatial4j = 0.6\n \n /org.mockito/mockito-core = 2.6.2\n@@ -262,6 +270,7 @@ org.slf4j.version = 1.7.7\n /org.slf4j/jul-to-slf4j = ${org.slf4j.version}\n /org.slf4j/slf4j-api = ${org.slf4j.version}\n /org.slf4j/slf4j-log4j12 = ${org.slf4j.version}\n+/org.slf4j/slf4j-simple = ${org.slf4j.version}\n \n /org.tukaani/xz = 1.5\n /rome/rome = 1.0\n@@ -270,4 +279,3 @@ ua.net.nlp.morfologik-ukrainian-search.version = 3.7.5\n /ua.net.nlp/morfologik-ukrainian-search = ${ua.net.nlp.morfologik-ukrainian-search.version}\n \n /xerces/xercesImpl = 2.9.1\n-",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/lucene/ivy-versions.properties",
                "sha": "3a1efbb665b200de4d02e125825704b4f13e135a",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/build.xml",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/build.xml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/build.xml",
                "patch": "@@ -656,6 +656,9 @@\n      <ant dir=\"test-framework\" target=\"resolve\" inheritall=\"false\">\n          <propertyset refid=\"uptodate.and.compiled.properties\"/>\n       </ant>\n+     <ant dir=\"solr-ref-guide\" target=\"resolve\" inheritall=\"false\">\n+         <propertyset refid=\"uptodate.and.compiled.properties\"/>\n+      </ant>\n      <contrib-crawl target=\"resolve\"/>\n     </sequential>\n   </target>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/build.xml",
                "sha": "5048f1dfd723af40a5ca372bc8ab66f3750bfd35",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-0.0.20131108.vaadin1.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/android-json-0.0.20131108.vaadin1.jar.sha1?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/android-json-0.0.20131108.vaadin1.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+fa26d351fe62a6a17f5cda1287c1c6110dec413f",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-0.0.20131108.vaadin1.jar.sha1",
                "sha": "99a9d8e79aaa2974ff01e5e7ee9f13b9d80082ae",
                "status": "added"
            },
            {
                "additions": 202,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-LICENSE-ASL.txt",
                "changes": 202,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/android-json-LICENSE-ASL.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/android-json-LICENSE-ASL.txt",
                "patch": "@@ -0,0 +1,202 @@\n+\n+                                 Apache License\n+                           Version 2.0, January 2004\n+                        http://www.apache.org/licenses/\n+\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n+\n+   1. Definitions.\n+\n+      \"License\" shall mean the terms and conditions for use, reproduction,\n+      and distribution as defined by Sections 1 through 9 of this document.\n+\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\n+      the copyright owner that is granting the License.\n+\n+      \"Legal Entity\" shall mean the union of the acting entity and all\n+      other entities that control, are controlled by, or are under common\n+      control with that entity. For the purposes of this definition,\n+      \"control\" means (i) the power, direct or indirect, to cause the\n+      direction or management of such entity, whether by contract or\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n+      outstanding shares, or (iii) beneficial ownership of such entity.\n+\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n+      exercising permissions granted by this License.\n+\n+      \"Source\" form shall mean the preferred form for making modifications,\n+      including but not limited to software source code, documentation\n+      source, and configuration files.\n+\n+      \"Object\" form shall mean any form resulting from mechanical\n+      transformation or translation of a Source form, including but\n+      not limited to compiled object code, generated documentation,\n+      and conversions to other media types.\n+\n+      \"Work\" shall mean the work of authorship, whether in Source or\n+      Object form, made available under the License, as indicated by a\n+      copyright notice that is included in or attached to the work\n+      (an example is provided in the Appendix below).\n+\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\n+      form, that is based on (or derived from) the Work and for which the\n+      editorial revisions, annotations, elaborations, or other modifications\n+      represent, as a whole, an original work of authorship. For the purposes\n+      of this License, Derivative Works shall not include works that remain\n+      separable from, or merely link (or bind by name) to the interfaces of,\n+      the Work and Derivative Works thereof.\n+\n+      \"Contribution\" shall mean any work of authorship, including\n+      the original version of the Work and any modifications or additions\n+      to that Work or Derivative Works thereof, that is intentionally\n+      submitted to Licensor for inclusion in the Work by the copyright owner\n+      or by an individual or Legal Entity authorized to submit on behalf of\n+      the copyright owner. For the purposes of this definition, \"submitted\"\n+      means any form of electronic, verbal, or written communication sent\n+      to the Licensor or its representatives, including but not limited to\n+      communication on electronic mailing lists, source code control systems,\n+      and issue tracking systems that are managed by, or on behalf of, the\n+      Licensor for the purpose of discussing and improving the Work, but\n+      excluding communication that is conspicuously marked or otherwise\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\n+\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n+      on behalf of whom a Contribution has been received by Licensor and\n+      subsequently incorporated within the Work.\n+\n+   2. Grant of Copyright License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      copyright license to reproduce, prepare Derivative Works of,\n+      publicly display, publicly perform, sublicense, and distribute the\n+      Work and such Derivative Works in Source or Object form.\n+\n+   3. Grant of Patent License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      (except as stated in this section) patent license to make, have made,\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\n+      where such license applies only to those patent claims licensable\n+      by such Contributor that are necessarily infringed by their\n+      Contribution(s) alone or by combination of their Contribution(s)\n+      with the Work to which such Contribution(s) was submitted. If You\n+      institute patent litigation against any entity (including a\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\n+      or a Contribution incorporated within the Work constitutes direct\n+      or contributory patent infringement, then any patent licenses\n+      granted to You under this License for that Work shall terminate\n+      as of the date such litigation is filed.\n+\n+   4. Redistribution. You may reproduce and distribute copies of the\n+      Work or Derivative Works thereof in any medium, with or without\n+      modifications, and in Source or Object form, provided that You\n+      meet the following conditions:\n+\n+      (a) You must give any other recipients of the Work or\n+          Derivative Works a copy of this License; and\n+\n+      (b) You must cause any modified files to carry prominent notices\n+          stating that You changed the files; and\n+\n+      (c) You must retain, in the Source form of any Derivative Works\n+          that You distribute, all copyright, patent, trademark, and\n+          attribution notices from the Source form of the Work,\n+          excluding those notices that do not pertain to any part of\n+          the Derivative Works; and\n+\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\n+          distribution, then any Derivative Works that You distribute must\n+          include a readable copy of the attribution notices contained\n+          within such NOTICE file, excluding those notices that do not\n+          pertain to any part of the Derivative Works, in at least one\n+          of the following places: within a NOTICE text file distributed\n+          as part of the Derivative Works; within the Source form or\n+          documentation, if provided along with the Derivative Works; or,\n+          within a display generated by the Derivative Works, if and\n+          wherever such third-party notices normally appear. The contents\n+          of the NOTICE file are for informational purposes only and\n+          do not modify the License. You may add Your own attribution\n+          notices within Derivative Works that You distribute, alongside\n+          or as an addendum to the NOTICE text from the Work, provided\n+          that such additional attribution notices cannot be construed\n+          as modifying the License.\n+\n+      You may add Your own copyright statement to Your modifications and\n+      may provide additional or different license terms and conditions\n+      for use, reproduction, or distribution of Your modifications, or\n+      for any such Derivative Works as a whole, provided Your use,\n+      reproduction, and distribution of the Work otherwise complies with\n+      the conditions stated in this License.\n+\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\n+      any Contribution intentionally submitted for inclusion in the Work\n+      by You to the Licensor shall be under the terms and conditions of\n+      this License, without any additional terms or conditions.\n+      Notwithstanding the above, nothing herein shall supersede or modify\n+      the terms of any separate license agreement you may have executed\n+      with Licensor regarding such Contributions.\n+\n+   6. Trademarks. This License does not grant permission to use the trade\n+      names, trademarks, service marks, or product names of the Licensor,\n+      except as required for reasonable and customary use in describing the\n+      origin of the Work and reproducing the content of the NOTICE file.\n+\n+   7. Disclaimer of Warranty. Unless required by applicable law or\n+      agreed to in writing, Licensor provides the Work (and each\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n+      implied, including, without limitation, any warranties or conditions\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\n+      appropriateness of using or redistributing the Work and assume any\n+      risks associated with Your exercise of permissions under this License.\n+\n+   8. Limitation of Liability. In no event and under no legal theory,\n+      whether in tort (including negligence), contract, or otherwise,\n+      unless required by applicable law (such as deliberate and grossly\n+      negligent acts) or agreed to in writing, shall any Contributor be\n+      liable to You for damages, including any direct, indirect, special,\n+      incidental, or consequential damages of any character arising as a\n+      result of this License or out of the use or inability to use the\n+      Work (including but not limited to damages for loss of goodwill,\n+      work stoppage, computer failure or malfunction, or any and all\n+      other commercial damages or losses), even if such Contributor\n+      has been advised of the possibility of such damages.\n+\n+   9. Accepting Warranty or Additional Liability. While redistributing\n+      the Work or Derivative Works thereof, You may choose to offer,\n+      and charge a fee for, acceptance of support, warranty, indemnity,\n+      or other liability obligations and/or rights consistent with this\n+      License. However, in accepting such obligations, You may act only\n+      on Your own behalf and on Your sole responsibility, not on behalf\n+      of any other Contributor, and only if You agree to indemnify,\n+      defend, and hold each Contributor harmless for any liability\n+      incurred by, or claims asserted against, such Contributor by reason\n+      of your accepting any such warranty or additional liability.\n+\n+   END OF TERMS AND CONDITIONS\n+\n+   APPENDIX: How to apply the Apache License to your work.\n+\n+      To apply the Apache License to your work, attach the following\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\n+      replaced with your own identifying information. (Don't include\n+      the brackets!)  The text should be enclosed in the appropriate\n+      comment syntax for the file format. We also recommend that a\n+      file or class name and description of purpose be included on the\n+      same \"printed page\" as the copyright notice for easier\n+      identification within third-party archives.\n+\n+   Copyright [yyyy] [name of copyright owner]\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-LICENSE-ASL.txt",
                "sha": "d645695673349e3947e8e5ae42332d0ac3164cd7",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-NOTICE.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/android-json-NOTICE.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/android-json-NOTICE.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/android-json-NOTICE.txt",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-1.6.0-alpha.3.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/asciidoctor-ant-1.6.0-alpha.3.jar.sha1?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/asciidoctor-ant-1.6.0-alpha.3.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+a7068544963ed46839c8352eddd87271fa93b967",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-1.6.0-alpha.3.jar.sha1",
                "sha": "805ef3b643663d6316ec67fa9a74bd20bb86f404",
                "status": "added"
            },
            {
                "additions": 202,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-LICENSE-ASL.txt",
                "changes": 202,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/asciidoctor-ant-LICENSE-ASL.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/asciidoctor-ant-LICENSE-ASL.txt",
                "patch": "@@ -0,0 +1,202 @@\n+\n+                                 Apache License\n+                           Version 2.0, January 2004\n+                        http://www.apache.org/licenses/\n+\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n+\n+   1. Definitions.\n+\n+      \"License\" shall mean the terms and conditions for use, reproduction,\n+      and distribution as defined by Sections 1 through 9 of this document.\n+\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\n+      the copyright owner that is granting the License.\n+\n+      \"Legal Entity\" shall mean the union of the acting entity and all\n+      other entities that control, are controlled by, or are under common\n+      control with that entity. For the purposes of this definition,\n+      \"control\" means (i) the power, direct or indirect, to cause the\n+      direction or management of such entity, whether by contract or\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n+      outstanding shares, or (iii) beneficial ownership of such entity.\n+\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n+      exercising permissions granted by this License.\n+\n+      \"Source\" form shall mean the preferred form for making modifications,\n+      including but not limited to software source code, documentation\n+      source, and configuration files.\n+\n+      \"Object\" form shall mean any form resulting from mechanical\n+      transformation or translation of a Source form, including but\n+      not limited to compiled object code, generated documentation,\n+      and conversions to other media types.\n+\n+      \"Work\" shall mean the work of authorship, whether in Source or\n+      Object form, made available under the License, as indicated by a\n+      copyright notice that is included in or attached to the work\n+      (an example is provided in the Appendix below).\n+\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\n+      form, that is based on (or derived from) the Work and for which the\n+      editorial revisions, annotations, elaborations, or other modifications\n+      represent, as a whole, an original work of authorship. For the purposes\n+      of this License, Derivative Works shall not include works that remain\n+      separable from, or merely link (or bind by name) to the interfaces of,\n+      the Work and Derivative Works thereof.\n+\n+      \"Contribution\" shall mean any work of authorship, including\n+      the original version of the Work and any modifications or additions\n+      to that Work or Derivative Works thereof, that is intentionally\n+      submitted to Licensor for inclusion in the Work by the copyright owner\n+      or by an individual or Legal Entity authorized to submit on behalf of\n+      the copyright owner. For the purposes of this definition, \"submitted\"\n+      means any form of electronic, verbal, or written communication sent\n+      to the Licensor or its representatives, including but not limited to\n+      communication on electronic mailing lists, source code control systems,\n+      and issue tracking systems that are managed by, or on behalf of, the\n+      Licensor for the purpose of discussing and improving the Work, but\n+      excluding communication that is conspicuously marked or otherwise\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\n+\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n+      on behalf of whom a Contribution has been received by Licensor and\n+      subsequently incorporated within the Work.\n+\n+   2. Grant of Copyright License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      copyright license to reproduce, prepare Derivative Works of,\n+      publicly display, publicly perform, sublicense, and distribute the\n+      Work and such Derivative Works in Source or Object form.\n+\n+   3. Grant of Patent License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      (except as stated in this section) patent license to make, have made,\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\n+      where such license applies only to those patent claims licensable\n+      by such Contributor that are necessarily infringed by their\n+      Contribution(s) alone or by combination of their Contribution(s)\n+      with the Work to which such Contribution(s) was submitted. If You\n+      institute patent litigation against any entity (including a\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\n+      or a Contribution incorporated within the Work constitutes direct\n+      or contributory patent infringement, then any patent licenses\n+      granted to You under this License for that Work shall terminate\n+      as of the date such litigation is filed.\n+\n+   4. Redistribution. You may reproduce and distribute copies of the\n+      Work or Derivative Works thereof in any medium, with or without\n+      modifications, and in Source or Object form, provided that You\n+      meet the following conditions:\n+\n+      (a) You must give any other recipients of the Work or\n+          Derivative Works a copy of this License; and\n+\n+      (b) You must cause any modified files to carry prominent notices\n+          stating that You changed the files; and\n+\n+      (c) You must retain, in the Source form of any Derivative Works\n+          that You distribute, all copyright, patent, trademark, and\n+          attribution notices from the Source form of the Work,\n+          excluding those notices that do not pertain to any part of\n+          the Derivative Works; and\n+\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\n+          distribution, then any Derivative Works that You distribute must\n+          include a readable copy of the attribution notices contained\n+          within such NOTICE file, excluding those notices that do not\n+          pertain to any part of the Derivative Works, in at least one\n+          of the following places: within a NOTICE text file distributed\n+          as part of the Derivative Works; within the Source form or\n+          documentation, if provided along with the Derivative Works; or,\n+          within a display generated by the Derivative Works, if and\n+          wherever such third-party notices normally appear. The contents\n+          of the NOTICE file are for informational purposes only and\n+          do not modify the License. You may add Your own attribution\n+          notices within Derivative Works that You distribute, alongside\n+          or as an addendum to the NOTICE text from the Work, provided\n+          that such additional attribution notices cannot be construed\n+          as modifying the License.\n+\n+      You may add Your own copyright statement to Your modifications and\n+      may provide additional or different license terms and conditions\n+      for use, reproduction, or distribution of Your modifications, or\n+      for any such Derivative Works as a whole, provided Your use,\n+      reproduction, and distribution of the Work otherwise complies with\n+      the conditions stated in this License.\n+\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\n+      any Contribution intentionally submitted for inclusion in the Work\n+      by You to the Licensor shall be under the terms and conditions of\n+      this License, without any additional terms or conditions.\n+      Notwithstanding the above, nothing herein shall supersede or modify\n+      the terms of any separate license agreement you may have executed\n+      with Licensor regarding such Contributions.\n+\n+   6. Trademarks. This License does not grant permission to use the trade\n+      names, trademarks, service marks, or product names of the Licensor,\n+      except as required for reasonable and customary use in describing the\n+      origin of the Work and reproducing the content of the NOTICE file.\n+\n+   7. Disclaimer of Warranty. Unless required by applicable law or\n+      agreed to in writing, Licensor provides the Work (and each\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n+      implied, including, without limitation, any warranties or conditions\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\n+      appropriateness of using or redistributing the Work and assume any\n+      risks associated with Your exercise of permissions under this License.\n+\n+   8. Limitation of Liability. In no event and under no legal theory,\n+      whether in tort (including negligence), contract, or otherwise,\n+      unless required by applicable law (such as deliberate and grossly\n+      negligent acts) or agreed to in writing, shall any Contributor be\n+      liable to You for damages, including any direct, indirect, special,\n+      incidental, or consequential damages of any character arising as a\n+      result of this License or out of the use or inability to use the\n+      Work (including but not limited to damages for loss of goodwill,\n+      work stoppage, computer failure or malfunction, or any and all\n+      other commercial damages or losses), even if such Contributor\n+      has been advised of the possibility of such damages.\n+\n+   9. Accepting Warranty or Additional Liability. While redistributing\n+      the Work or Derivative Works thereof, You may choose to offer,\n+      and charge a fee for, acceptance of support, warranty, indemnity,\n+      or other liability obligations and/or rights consistent with this\n+      License. However, in accepting such obligations, You may act only\n+      on Your own behalf and on Your sole responsibility, not on behalf\n+      of any other Contributor, and only if You agree to indemnify,\n+      defend, and hold each Contributor harmless for any liability\n+      incurred by, or claims asserted against, such Contributor by reason\n+      of your accepting any such warranty or additional liability.\n+\n+   END OF TERMS AND CONDITIONS\n+\n+   APPENDIX: How to apply the Apache License to your work.\n+\n+      To apply the Apache License to your work, attach the following\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\n+      replaced with your own identifying information. (Don't include\n+      the brackets!)  The text should be enclosed in the appropriate\n+      comment syntax for the file format. We also recommend that a\n+      file or class name and description of purpose be included on the\n+      same \"printed page\" as the copyright notice for easier\n+      identification within third-party archives.\n+\n+   Copyright [yyyy] [name of copyright owner]\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-LICENSE-ASL.txt",
                "sha": "d645695673349e3947e8e5ae42332d0ac3164cd7",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-NOTICE.txt",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/asciidoctor-ant-NOTICE.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/asciidoctor-ant-NOTICE.txt",
                "patch": "@@ -0,0 +1,5 @@\n+Apache [asciidoctor-ant]\n+Copyright [2013] The Apache Software Foundation\n+\n+This product includes software developed at\n+The Apache Software Foundation (http://www.apache.org/).\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/asciidoctor-ant-NOTICE.txt",
                "sha": "4cec1354d758281f17d5cee7a9726e913df5ecca",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/jsoup-1.8.2.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/jsoup-1.8.2.jar.sha1?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/jsoup-1.8.2.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+64238922c4006c3d0a9951c4c03983ecc6a1e1a0",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/jsoup-1.8.2.jar.sha1",
                "sha": "cdb9ca65e2e1bef35619c3fec2b1274b62b3a018",
                "status": "added"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/jsoup-LICENSE-MIT.txt",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/jsoup-LICENSE-MIT.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/jsoup-LICENSE-MIT.txt",
                "patch": "@@ -0,0 +1,21 @@\n+The MIT License\n+\n+\u00a9 2009-2017, Jonathan Hedley <jonathan@hedley.net>\n+\n+Permission is hereby granted, free of charge, to any person obtaining a copy\n+of this software and associated documentation files (the \"Software\"), to deal\n+in the Software without restriction, including without limitation the rights\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+copies of the Software, and to permit persons to whom the Software is\n+furnished to do so, subject to the following conditions:\n+\n+The above copyright notice and this permission notice shall be included in\n+all copies or substantial portions of the Software.\n+\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n+THE SOFTWARE.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/jsoup-LICENSE-MIT.txt",
                "sha": "ab9f00b3594522846b351120352e86b7438d5d37",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/slf4j-simple-1.7.7.jar.sha1",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/licenses/slf4j-simple-1.7.7.jar.sha1?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/licenses/slf4j-simple-1.7.7.jar.sha1",
                "patch": "@@ -0,0 +1 @@\n+8095d0b9f7e0a9cd79a663c740e0f8fb31d0e2c8",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/licenses/slf4j-simple-1.7.7.jar.sha1",
                "sha": "2da962e14ae1b392043fcb8189ce281657cf8a7d",
                "status": "added"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/README.adoc",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/README.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/README.adoc",
                "patch": "@@ -0,0 +1,27 @@\n+= Solr Ref Guide\n+\n+This is the source for the Solr Reference Guide.\n+\n+Raw content is stored in Asciidoc (`.adoc`) formated files in the `src/` directory.\n+\n+These files are processed with AsciiDoctor in 2 different ways:\n+\n+* Via 'Jekyll' to build an HTML browsable version of the Ref Guide\n+** Prerequisites: `Ruby` and the following gems must be installed:\n+*** `jekyll`\n+*** `jekyll-asciidoc`\n+*** `pygments.rb`\n+* Via `asciidoctor-ant` to build the officially released PDF version of the Ref Guide\n+** Prerequisites: None (except for those required to use the Lucene/Solr build: Java, Ant)\n+\n+For details on building the ref guide, see `ant -p`.\n+\n+Key directories to be aware of:\n+\n+* `src` - where all human edited `*.adoc` files realted to the Guide live, as well as various configuration, theme, and template files.\n+* `tools` - custom Java code for parsing metadata in our `src/*.adoc` files to produce some `_data/` files for site & pdf navigation purposes.\n+* `../build/solr-ref-guide/content` - a copy of the `src` dir generated by ant where:\n+** `*.template` files are processed to replace ant properties with their runtime values\n+** some `../build/solr-ref-guide/content/_data` files are generated by our java tools based header attributes from each of the `*.adoc` files\n+* `../build/solr-ref-guide/html-site` - HTML generated version of the ref guide\n+* `../build/solr-ref-guide/apache-solr-ref-guide-X.Y.pdf` - PDF generated version of the ref guide",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/README.adoc",
                "sha": "80b99f646eca14d0320f265fc5c69e6ffcdc472e",
                "status": "added"
            },
            {
                "additions": 204,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/build.xml",
                "changes": 204,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/build.xml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/build.xml",
                "patch": "@@ -0,0 +1,204 @@\n+<?xml version=\"1.0\"?>\n+<!--\n+   Licensed to the Apache Software Foundation (ASF) under one\n+   or more contributor license agreements.  See the NOTICE file\n+   distributed with this work for additional information\n+   regarding copyright ownership.  The ASF licenses this file\n+   to you under the Apache License, Version 2.0 (the\n+   \"License\"); you may not use this file except in compliance\n+   with the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing,\n+   software distributed under the License is distributed on an\n+   \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+   KIND, either express or implied.  See the License for the\n+   specific language governing permissions and limitations\n+   under the License.\n+-->\n+<project name=\"solr-ref-guide\" default=\"default\" xmlns:asciidoctor=\"antlib:org.asciidoctor.ant\" >\n+\n+  <import file=\"../common-build.xml\"/>\n+\n+  <!-- properties to use in our docs -->\n+  <loadresource property=\"solr-docs-version\">\n+    <propertyresource name=\"version.base\"/>\n+    <filterchain>\n+      <tokenfilter>\n+        <filetokenizer/>\n+        <replaceregex pattern=\"^(\\d+\\.\\d+)(|\\..*)$\" replace=\"\\1\" flags=\"s\"/>\n+      </tokenfilter>\n+    </filterchain>\n+  </loadresource>\n+  <loadresource property=\"solr-docs-version-path\">\n+    <propertyresource name=\"solr-docs-version\"/>\n+    <filterchain>\n+      <tokenfilter>\n+        <filetokenizer/>\n+        <replaceregex pattern=\"^(\\d+)\\.(\\d+)(|\\..*)$\" replace=\"\\1_\\2_0\" flags=\"s\"/>\n+      </tokenfilter>\n+    </filterchain>\n+  </loadresource>\n+  <property name=\"solr-javadocs\" value=\"https://lucene.apache.org/solr/${solr-docs-version-path}/\" />\n+  <property name=\"lucene-javadocs\" value=\"https://lucene.apache.org/core/${solr-docs-version-path}/\" />\n+\n+  <property name=\"build.content.dir\" location=\"${build.dir}/content\" />\n+  <property name=\"main-page\" value=\"index\" />\n+  <property name=\"pdf-filename\" value=\"apache-solr-ref-guide-${solr-docs-version}.pdf\" />\n+\n+  <!-- ====== TOOLS FOR GENERATING/VALIDATING BITS OF THE SITE / PDF ======= -->\n+  <property name=\"tools-jar-name\" value=\"solr-ref-guide-tools.jar\" />\n+  <path id=\"tools-compile-classpath\">\n+    <fileset dir=\"lib\">\n+      <include name=\"**/*.jar\"/>\n+      <exclude name=\"**/${tools-jar-name}\" />\n+    </fileset>\n+  </path>\n+  <path id=\"tools-run-classpath\">\n+    <fileset dir=\"lib\">\n+      <include name=\"**/*.jar\"/>\n+    </fileset>\n+    <fileset dir=\"${build.dir}\">\n+      <include name=\"**/*.jar\"/>\n+    </fileset>\n+  </path>\n+\n+  <target name=\"clean\">\n+    <delete dir=\"${build.dir}\"/>\n+  </target>\n+\n+  <target name=\"build-tools-jar\" depends=\"resolve\" description=\"Builds the custom java tools use use for generating some data files from page metdata\">\n+    <mkdir dir=\"${build.dir}/classes\"/>\n+    <javac debug=\"yes\"\n+           debuglevel=\"source,lines,vars\"\n+           destdir=\"${build.dir}/classes\"\n+           includeantruntime=\"false\">\n+      <compilerarg value=\"-Xlint:all\"/>\n+      <classpath refid=\"tools-compile-classpath\"/>\n+      <src path=\"tools/\"/>\n+    </javac>\n+    <jar destfile=\"${build.dir}/${tools-jar-name}\">\n+      <fileset dir=\"${build.dir}/classes\"\n+               includes=\"**/*.class\"/>\n+    </jar>\n+  </target>\n+\n+  <target name=\"build-init\" description=\"Prepares the build's 'content' dir, copying over src files and transforming *.template files in the process\">\n+    <delete dir=\"${build.content.dir}\" />\n+    <mkdir dir=\"${build.content.dir}\" />\n+    <echo>Copying all non template files from src ...</echo>\n+    <copy todir=\"${build.content.dir}\">\n+      <fileset dir=\"src\">\n+        <exclude name=\"**/*.template\"/>\n+      </fileset>\n+    </copy>\n+    <echo>Copy (w/prop replacement) any template files from src...</echo>\n+    <copy todir=\"${build.content.dir}\">\n+      <fileset dir=\"src\">\n+        <include name=\"**/*.template\"/>\n+      </fileset>\n+      <mapper type=\"glob\" from=\"*.template\" to=\"*\"/>\n+      <filterchain>\n+        <expandproperties/>\n+      </filterchain>\n+    </copy>\n+  </target>\n+\n+  <target name=\"build-nav-data-files\" depends=\"build-init,build-tools-jar\" description=\"creates nav based data files needed by both the html and pdf artifacts\">\n+    <mkdir dir=\"${build.content.dir}/_data\"/>\n+    <java classname=\"BuildNavAndPDFBody\"\n+          failonerror=\"true\"\n+          fork=\"true\">\n+      <classpath refid=\"tools-run-classpath\"/>\n+      <arg value=\"${build.content.dir}\"/>\n+      <arg value=\"${main-page}\"/>\n+    </java>\n+  </target>\n+\n+  <target name=\"check-links-and-anchors\" depends=\"build-init,build-tools-jar\" description=\"Parse the HTML site files to check for problematic links or anchors\">\n+    <java classname=\"CheckLinksAndAnchors\"\n+          failonerror=\"true\"\n+          fork=\"true\">\n+      <classpath refid=\"tools-run-classpath\"/>\n+      <arg value=\"${build.dir}/html-site\"/>\n+    </java>\n+  </target>\n+\n+  <!-- ====== PDF Build ======= -->\n+  <target name=\"build-pdf\" depends=\"-build-raw-pdf,-reduce-pdf-size\" description=\"Builds a PDF\">\n+    <echo>Finished Building ${build.dir}/${pdf-filename}</echo>\n+  </target>\n+  <target name=\"-build-raw-pdf\"\n+          depends=\"build-nav-data-files,resolve\">\n+    <mkdir dir=\"${build.dir}/pdf-tmp\"/>\n+    <taskdef uri=\"antlib:org.asciidoctor.ant\" resource=\"org/asciidoctor/ant/antlib.xml\"\n+             classpathref=\"tools-run-classpath\"/>\n+    <asciidoctor:convert\n+                 sourceDirectory=\"${build.content.dir}/pdf\"\n+                 sourceDocumentName=\"SolrRefGuide-all.adoc\"\n+                 baseDir=\"${build.content.dir}\"\n+                 outputDirectory=\"${build.dir}/pdf-tmp\"\n+                 backend=\"pdf\"\n+                 extensions=\"adoc\"\n+                 sourceHighlighter=\"coderay\"\n+                 imagesDir=\"${build.content.dir}\"\n+                 doctype=\"book\"\n+                 safemode=\"unsafe\">\n+      <attribute key=\"icons\" value=\"font\" />\n+      <attribute key=\"icon-set\" value=\"fa\" />\n+      <attribute key=\"pdf-stylesDir\" value=\"./pdf/themes\"/>\n+      <attribute key=\"pdf-style\" value=\"refguide\"/>\n+      <attribute key=\"pdf-fontsDir\" value=\"./fonts\"/>\n+      <attribute key=\"figure-caption!\" value='' />\n+      <attribute key=\"idprefix\" value='' />\n+      <attribute key=\"idseparator\" value='-' />\n+      <!-- attributes used in adoc files -->\n+      <!-- NOTE: If you add any attributes here for use in adoc files, you almost certainly need to also add\n+           them to the _config.yml.template file for building the jekyll site as well\n+      -->\n+      <attribute key=\"solr-docs-version\" value=\"${solr-docs-version}\" />\n+      <attribute key=\"solr-javadocs\" value=\"${solr-javadocs}\" />\n+      <attribute key=\"lucene-javadocs\" value=\"${lucene-javadocs}\" />\n+      <attribute key=\"build-date\" value=\"${DSTAMP}\" />\n+      <attribute key=\"build-year\" value=\"${current.year}\" />\n+    </asciidoctor:convert>\n+    <move file=\"${build.dir}/pdf-tmp/SolrRefGuide-all.pdf\" tofile=\"${build.dir}/pdf-tmp/RAW-${pdf-filename}\" />\n+  </target>\n+  <target name=\"-reduce-pdf-size\" depends=\"build-init,build-tools-jar\">\n+    <java classname=\"ReducePDFSize\"\n+          failonerror=\"true\"\n+          fork=\"true\">\n+      <classpath refid=\"tools-run-classpath\"/>\n+      <arg value=\"${build.dir}/pdf-tmp/RAW-${pdf-filename}\"/>\n+      <arg value=\"${build.dir}/${pdf-filename}\"/>\n+    </java>\n+  </target>\n+\n+\n+\n+  <!-- ======= HTML Site Build =======\n+       Builds site with Jekyll.\n+       This (for now) assumes that Jekyll (http://jekyllrb.com) is installed locally. -->\n+  <target name=\"build-site\"\n+          depends=\"-build-site,check-links-and-anchors\"\n+          description=\"Builds an HTML Site w/Jekyll and verifies the anchors+links are valid\" >\n+    <echo>Ready to browse site: ${build.dir}/html-site/${main-page}.html</echo>\n+  </target>\n+  <target name=\"-build-site\"\n+          depends=\"build-init,build-nav-data-files\"\n+          description=\"Builds an HTML Site w/Jekyll\">\n+    <echo>Running Jekyll...</echo>\n+    <exec executable=\"jekyll\" dir=\"${build.content.dir}\">\n+      <arg value=\"build\"/>\n+    </exec>\n+  </target>\n+\n+  <target name=\"default\"\n+          description=\"Builds both a PDF and HTML versions of the ref guide\"\n+          depends=\"build-pdf,build-site\">\n+    <echo>PDF: ${build.dir}/${pdf-filename}</echo>\n+    <echo>SITE: ${build.dir}/html-site/${main-page}.html</echo>\n+  </target>\n+\n+</project>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/build.xml",
                "sha": "a23bac8574075d5e40646eacc3a37241bbcdf9a2",
                "status": "added"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/ivy.xml",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/ivy.xml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/ivy.xml",
                "patch": "@@ -0,0 +1,34 @@\n+<!--\n+   Licensed to the Apache Software Foundation (ASF) under one\n+   or more contributor license agreements.  See the NOTICE file\n+   distributed with this work for additional information\n+   regarding copyright ownership.  The ASF licenses this file\n+   to you under the Apache License, Version 2.0 (the\n+   \"License\"); you may not use this file except in compliance\n+   with the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing,\n+   software distributed under the License is distributed on an\n+   \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+   KIND, either express or implied.  See the License for the\n+   specific language governing permissions and limitations\n+   under the License.    \n+-->\n+<ivy-module version=\"2.0\">\n+  <info organisation=\"org.apache.solr\" module=\"ref-guide-tools\"/>\n+  <configurations defaultconfmapping=\"compile->master\">\n+    <conf name=\"compile\" transitive=\"false\" />\n+  </configurations>\n+  <dependencies>\n+    <dependency org=\"org.asciidoctor\" name=\"asciidoctor-ant\" rev=\"${/org.asciidoctor/asciidoctor-ant}\" conf=\"compile\" />\n+    <dependency org=\"com.vaadin.external.google\" name=\"android-json\" rev=\"${/com.vaadin.external.google/android-json}\" conf=\"compile\" />\n+    <dependency org=\"org.jsoup\" name=\"jsoup\" rev=\"${/org.jsoup/jsoup}\" conf=\"compile\" />\n+    <dependency org=\"org.apache.pdfbox\" name=\"pdfbox\" rev=\"${/org.apache.pdfbox/pdfbox}\" conf=\"compile\"/>\n+    <dependency org=\"org.slf4j\" name=\"jcl-over-slf4j\" rev=\"${/org.slf4j/jcl-over-slf4j}\" conf=\"compile\"/>\n+    <dependency org=\"org.slf4j\" name=\"slf4j-api\" rev=\"${/org.slf4j/slf4j-api}\" conf=\"compile\"/>\n+    <dependency org=\"org.slf4j\" name=\"slf4j-simple\" rev=\"${/org.slf4j/slf4j-simple}\" conf=\"compile\"/>\n+    <dependency org=\"log4j\" name=\"log4j\" rev=\"${/log4j/log4j}\" conf=\"compile\"/>\n+  </dependencies>\n+</ivy-module>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/ivy.xml",
                "sha": "adefe2ced54a49953084bd5895d11badf7a27347",
                "status": "added"
            },
            {
                "additions": 223,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/asciidoc-syntax.adoc",
                "changes": 223,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/meta-docs/asciidoc-syntax.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/meta-docs/asciidoc-syntax.adoc",
                "patch": "@@ -0,0 +1,223 @@\n+= Asciidoc syntax\n+:toc:\n+\n+The definitive manual on Asciidoc syntax is in the http://asciidoctor.org/docs/user-manual/[Asciidoctor User Manual]. To help people get started, however, here is a simpler cheat sheet.\n+\n+== Basic syntax\n+\n+=== Bold\n+\n+Put asterisks around text to make it *bold*.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#bold-and-italic\n+\n+=== Italics\n+\n+Use underlines on either side of a string to put text into _italics_.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#bold-and-italic\n+\n+=== Headings\n+\n+Equal signs (`=`) are used for heading levels. Each equal sign is a level. Each page can *only* have one top level. Levels should be appropriately nested.\n+\n+Validation occurs to ensure that level 3s are preceded by level 2s, level 4s are preceded by level 3s, etc. Including out-of-sequence heading levels (such as a level 3 then a level 5) will not fail the build, but will produce an error.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#sections\n+\n+=== Code Examples\n+\n+Use backticks ``` for text that should be monospaced, such as a code or class name in the body of a paragraph.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#mono\n+\n+Longer code examples can be separated from text with `source` blocks. These allow defining the syntax being used so the code is properly highlighted.\n+\n+[source]\n+.Example Source Block\n+----\n+[source,xml]\n+    <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" />\n+----\n+\n+If your code block will include line breaks, put 4 hyphens (`----`) before and after the entire block.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#source-code-blocks\n+\n+=== Block Titles\n+\n+Titles can be added to most blocks (images, source blocks, tables, etc.) by simply prefacing the title with a period (`.`). For example, to add a title to the source block example above:\n+\n+[source]\n+----\n+[source,xml]\n+.Example ID field\n+    <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" />\n+----\n+\n+== Links\n+\n+=== Link to Sites on the Internet\n+When converting content to HTML or PDF, Asciidoctor will automatically render many link types (such as `http:` and `mailto:`) without any additional syntax.\n+\n+However, you can add a name to a link by adding the URI followed by square brackets:\n+\n+[source]\n+http://lucene.apache.org/solr[Solr Website]\n+\n+=== Link to Other Pages/Sections of the Guide\n+A warning up front, linking to other pages can be a little bit painful.\n+\n+To link to an anchor (or heading) on the _same page_, you can simply use double angle brackets (`<< >>`) around the anchor/heading/section name. Note that any heading (aka section title) that starts with equal signs is automatically an anchor.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#internal-cross-references\n+\n+To link to another page or even a heading on _another page_, you use a similar syntax, but you must refer to the full filename and refer to the section title you want to link to by changing it to lower case and including hyphens between each word.\n+\n+For example, if I want to link from one page to the Schema API page's section \"Modify the Schema\", I need to create a link that looks like this:\n+\n+[source]\n+For more information about modifying the schema with the API, see the section <<schema-api.adoc#modify-the-schema>>.\n+\n+You can add text to appear by adding it after the file name and section reference, as in:\n+\n+[source]\n+<<schema-api.adoc#modify-the-schema,Modify the Schema>>\n+\n+More info: http://asciidoctor.org/docs/user-manual/#inter-document-cross-references\n+\n+== Item Lists\n+\n+Asciidoc supports three types of lists:\n+\n+* Unordered lists\n+* Ordered lists\n+* Labeled lists\n+\n+Each type of list can be mixed with the other types. So, you could have an ordered list inside a labeled list if necessary.\n+\n+=== Unordered Lists\n+Simple bulleted lists need each line to start with an asterisk (`*`). It should be the first character of the line, and be followed by a space.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#unordered-lists\n+\n+=== Ordered Lists\n+Numbered lists need each line to start with a period (`.`). It should be the first character of the line, and be followed by a space.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#ordered-lists\n+\n+=== Labeled Lists\n+These are like question & answer lists or glossary definitions. Each line should start with the list item followed by double colons (`::`), then a space or new line.\n+\n+Labeled lists can be nested by adding an additional colon (such as `:::`, etc.).\n+\n+More info: http://asciidoctor.org/docs/user-manual/#labeled-list\n+\n+== Images\n+\n+There are two ways to include an image: inline or as a block.\n+\n+Inline images are those where text will flow around the image. Block images are those that appear on their own line, set off from any other text on the page.\n+\n+Both approaches use the `image` tag before the image filename, but the number of colons after `image` define if it is inline or a block. Inline images use one colon (`image:`), while block images use two colons (`image::`).\n+\n+Block images automatically include a caption label and a number (such as `Figure 1`). If a block image includes a title, it will be included as the text of the caption.\n+\n+Optional attributes allow you to set the alt text, the size of the image, if it should be a link, float and alignment.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#images\n+\n+== Tables\n+\n+Tables can be complex, but it is pretty easy to make a basic table that fits most needs.\n+\n+=== Basic Tables\n+The basic structure of a table is similar to Markdown, with pipes (`|`) delimiting columns between rows:\n+\n+[source]\n+----\n+|===\n+| col 1 row 1 | col 2 row 1|\n+| col 1 row 2 | col 2 row 2|\n+|===\n+----\n+\n+Note the use of `|===` at the start and end. For basic tables that's not exactly required, but it does help to delimit the start and end of the table in case you accidentally introduce (or maybe prefer) spaces between the rows.\n+\n+=== Header Rows\n+To add a header to a table, you need only set the `header` attribute at the start of the table:\n+\n+[source]\n+----\n+[options=\"header\"]\n+|===\n+| header col 1 | header col 2|\n+| col 1 row 1 | col 2 row 1|\n+| col 1 row 2 | col 2 row 2|\n+|===\n+----\n+\n+=== Defining Column Styles\n+If you need to define specific styles to all rows in a column, you can do so with the attributes.\n+\n+This example will center all content in all rows:\n+\n+[source]\n+----\n+[cols=\"2*^\" options=\"header\"]\n+|===\n+| header col 1 | header col 2|\n+| col 1 row 1 | col 2 row 1|\n+| col 1 row 2 | col 2 row 2|\n+|===\n+----\n+\n+Alignments or any other styles can be applied only to a specific column. For example, this would only center the last column of the table:\n+\n+[source]\n+----\n+[cols=\"2*,^\" options=\"header\"]\n+|===\n+| header col 1 | header col 2|\n+| col 1 row 1 | col 2 row 1|\n+| col 1 row 2 | col 2 row 2|\n+|===\n+----\n+\n+Many more examples of formatting:\n+\n+* Columns: http://asciidoctor.org/docs/user-manual/#cols-format\n+* Cells: http://asciidoctor.org/docs/user-manual/#cell\n+\n+=== More Options\n+\n+Tables can also be given footer rows, borders, and captions. CSV or DSV can be used instead of formatting the data in pipes.\n+\n+More info: http://asciidoctor.org/docs/user-manual/#tables\n+\n+== Admonitions (Notes, Warnings)\n+\n+Asciidoc supports several types of callout boxes, called \"admonitions\":\n+\n+* NOTE\n+* TIP\n+* IMPORTANT\n+* CAUTION\n+* WARNING\n+\n+It is enough to start a paragraph with one of these words followed by a colon (such as `NOTE:`). When it is converted to HTML or PDF, those sections will be formatted properly - indented from the main text and showing an icon inline.\n+\n+You can add titles to admonitions by making it an admonition block. The structure of an admonition block is like this:\n+\n+[source]\n+----\n+[NOTE]\n+.Title of Note\n+====\n+Text of note\n+====\n+----\n+\n+In this example, the type of admonition is included in square brackets (`[NOTE]`), and the title is prefixed with a period. Four equal signs give the start and end points of the note text (which can include new lines, lists, etc.).\n+\n+More info: http://asciidoctor.org/docs/user-manual/#admonition",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/asciidoc-syntax.adoc",
                "sha": "3f0eb742ecdc734bacc4b8182f2e7e671719aac3",
                "status": "added"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/editing-tools.adoc",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/meta-docs/editing-tools.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/meta-docs/editing-tools.adoc",
                "patch": "@@ -0,0 +1,23 @@\n+= Tools for Working with Asciidoc Format\n+\n+== Asciidoc vs Asciidoctor\n+\n+The Solr Ref Guide is written in _Asciidoc_ format. This format is generally considered an extension of Markdown, because it has support for tables of contents, better table support, and other features that make it more appropriate for writing technical documentation.\n+\n+We are using a version of the Asciidoc syntax along with tools from an open source project called https://asciidoctor.org[Asciidoctor]. This provides full support for the Asciidoc syntax, but replaces the original Python processor with one written in Ruby. There is a Java implementation, known as https://github.com/asciidoctor/asciidoctorj[AsciidoctorJ]. Further extensions from the original Asciidoc project include support for font-based icons and UI elements.\n+\n+== Helpful Tools\n+\n+You can write Asciidoc without any special tools. It's simply text, with familiar syntax for bold (`*`) and italics (`_`).\n+\n+Having some tools in your editor is helpful, though.\n+\n+=== Doc Preview\n+\n+This allows you to see your document in something close to what it might appear like when output to HTML.\n+\n+The following information is from http://asciidoctor.org/docs/editing-asciidoc-with-live-preview.\n+\n+* Atom has AsciiDoc Preview, which gives you a panel that updates as you type. There are also a couple of other plugins to support Asciidoc format and auto-complete.\n+* There is a Live Preview browser plugin for Chrome, Firefox and Opera which allow you to open your Asciidoc page in the browser. It will also update as you type.\n+* There is also an Intellij IDEA plugin to support Asciidoc format.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/editing-tools.adoc",
                "sha": "46a82ecd9484889c3b35d48d2b52a0eb8b86b454",
                "status": "added"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/jekyll.adoc",
                "changes": 61,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/meta-docs/jekyll.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/meta-docs/jekyll.adoc",
                "patch": "@@ -0,0 +1,61 @@\n+= Working with Jekyll\n+:toc:\n+\n+The Solr Ref Guide uses Jekyll to build the HTML version of the site.\n+\n+== What is Jekyll?\n+\n+Jekyll is a static site generator, meaning that it takes some set of documents and produces HTML pages. It allows for templating of the pages, so each page has the same look and feel without having to code headers, footers, logos, etc., into every page.\n+\n+Jekyll is an open source project written in Ruby, online at https://jekyllrb.com/.\n+\n+== Jekyll-Asciidoctor Plugin\n+We use a plugin for Jekyll from the Asciidoctor project to integrate Jekyll with Asciidoc formatted content. The source for the plugin is available at https://github.com/asciidoctor/jekyll-asciidoc.\n+\n+This plugin allows us to use Asciidoctor-style variables with Jekyll, instead of having to maintain two sets of the same variables (one for HTML version and another for PDF version).\n+\n+== Jekyll Basics\n+\n+The following sections describe the main features of Jekyll that you will encounter while working with the Solr Ref Guide.\n+\n+=== _config.yml\n+\n+The `_config.yml` is a global configuration file that drives many of the options used when building the site (particularly in our use of Jekyll).\n+\n+We have templatized `_config.yml` so in our use of Jekyll you will find it as `solr-ref-guide/_config.yml.template`. This allows us to define some variables during the build, and use common Lucene/Solr build parameters (such as versions, etc.).\n+\n+=== Front Matter\n+\n+Front matter for Jekyll is like a header that defines the title of the page, and any other variables that may be helpful or even required when rendering the page.\n+\n+Every document that will be converted to HTML *must* include at least the page title at the top of the page.\n+\n+The Solr Ref Guide uses the front matter to define the \"short name\" and permanent URL of a page, and to define the children of a page. The list of children is used to build the site navigation menu that appears to the left of each page's content.\n+\n+Many guides to Jekyll also say that defining the layout in the front matter is required. However, since we only have one layout for all pages, we have defined this as a default.\n+\n+=== Layouts\n+\n+Layouts define the \"look and feel\" of each page.\n+\n+Jekyll uses Liquid for page templates.\n+\n+For our implementation of Jekyll, layouts are found in `solr-ref-guide/src/_layouts`\n+\n+=== Includes\n+\n+Include files are usually small files that are pulled into a layout when a page is being built. They are Liquid templates that define an area of the page. This allows flexibility across layouts - all pages can have the same header without duplicating code, but different pages could have different menu options.\n+\n+Include files that we use define the top navigation, the page header, the page footer, and tables of contents.\n+\n+For our implementation of Jekyll, include files are found in `solr-ref-guide/src/_includes`.\n+\n+=== Data Files\n+\n+Data files include data such as lists, that should be included in each page. The left-hand navigation is an example of a data file.\n+\n+For our implementation of Jekyll, data files are found in `solr-ref-guide/src/_data`.\n+\n+== Building the HTML Site\n+\n+An Ant target `build-site` will build the full HTML site. This target builds the navigation for the left-hand menu, and converts all `.adoc` files to `.html`, including navigation and inter-document links.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/jekyll.adoc",
                "sha": "e1ba1292920ac0d553b19506d00445f04a0edf9e",
                "status": "added"
            },
            {
                "additions": 131,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/pdf.adoc",
                "changes": 131,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/meta-docs/pdf.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/meta-docs/pdf.adoc",
                "patch": "@@ -0,0 +1,131 @@\n+= Generating PDF\n+\n+The main published artifact of the Solr Reference Guide is a PDF document.\n+\n+The PDF version of the Ref Guide uses `asciidoctor-pdf` (indirectly) to convert the `.adoc` files to PDF.\n+\n+In order for all of the various files to be converted into a single, large, PDF file, another `.adoc` file must be created.\n+\n+== About asciidoctor-pdf\n+\n+Our PDF build process uses the https://github.com/asciidoctor/asciidoctor-ant[`asciidoctor-ant`] project to integrate Asciidoctor.\n+\n+The `asciidoctor-ant` project is really an Ant wrapper around https://github.com/asciidoctor/asciidoctorj[`asciidoctorj`]. This is a Java binding of several Asciidoctor projects that produces a .jar that includes Asciidoctor, Asciidoctor PDF and Asciidoctor EPub.\n+\n+Since it is a binding for the Ruby implementations of these three projects, they each work the same way they would if we were using the Ruby versions.\n+\n+== Configuring the PDF Theme\n+\n+Nearly all of the styling and layout of the PDF is controlled by a single YAML file that is called a theme.\n+\n+See the section <<Modifying the Theme>> for information on how to update the theme.\n+\n+=== Declaring the Theme to Use\n+\n+Our theme is `refguide-theme.yml`, found in `solr/solr-ref-guide/pdf/themes`.\n+\n+New themes must be named to include `-theme.yml` at the end. They must also be in proper YAML format.\n+\n+The theme to use when generating the PDF is defined with the `pdf-style` attribute. Only the first part of the file name is used. So, a theme file named `refguide-theme.yml` is selected by defining `pdf-style=refguide`.\n+\n+In the section <<Asciidoctor PDF Attributes>> below, we can see how we've declared this in our Ant target.\n+\n+=== Modifying the Theme\n+\n+All of the styling capabilities are described in the https://github.com/asciidoctor/asciidoctor-pdf/blob/master/docs/theming-guide.adoc[Asciidoctor PDF Theming Guide].\n+\n+== About the Uber-Document\n+\n+In order for all of the files in `.adoc` format to be compiled into a single PDF, we need to give the process one `.adoc` file (an \"uber-document\") that includes all of the content we want in the PDF. In other words, there is no command that says \"take all the files in this directory and make one PDF\".\n+\n+Asciidoctor has a nice feature called the _include directive_, which allows you to insert content from another file into the current file (more details in the http://asciidoctor.org/docs/user-manual/#include-directive[Asciidoctor documentation]).\n+\n+We wanted to make sure we didn't add to the burden of maintaining the PDF by asking everyone to update the uber-document or trying to institute some sort of check on if all the pages are included and in the right place in the hierarchy. Instead, the uber-document is build programmatically at build time.\n+\n+The uber-document is found in `solr/solr-ref-guide/src/pdf/SolrRefGuide-all.adoc`. This document is very simple - it includes only the Apache license statement and a single `include` directive to another file:\n+\n+[source]\n+\\include::_data/pdf-main-body.adoc[]\n+\n+The Ant target `build-pdf` includes a dependency on another target, `build-nav-data-files`. This target looks at each document and builds the `pdf-main-body.adoc` file with the proper hierarchy of all pages.\n+\n+NOTE: You will not see the `pdf-main-body.adoc` in `solr/solr-ref-guide/src/_data` directory. This file exists only once it has been built, and it is placed in the build directory, at `solr/solr-ref-guide/build/content_data`.\n+\n+== Configuring the build-pdf Ant Target\n+\n+Since most of the styling and layout is defined by the theme, the options that must be configured in the Ant target relate to where to find referenced files, font directories, image directories, and similar top-level document settings.\n+\n+There are two types of settings at work in our Ant target. First are the settings which are part of the `asciidoctor-ant` jar. Second, we are able to declare any Asciidoctor PDF attribute (setting) that we want to apply to the entire PDF.\n+\n+Our Ant target (`build-pdf`) uses the following settings:\n+\n+[source,xml]\n+----\n+<asciidoctor:convert\n+             sourceDirectory=\"${build.content.dir}/pdf\"\n+             sourceDocumentName=\"SolrRefGuide-all.adoc\"\n+             baseDir=\"${build.content.dir}\"\n+             outputDirectory=\"${build.dir}\"\n+             backend=\"pdf\"\n+             extensions=\"adoc\"\n+             sourceHighlighter=\"coderay\"\n+             embedAssets=\"true\"\n+             imagesDir=\"${build.content.dir}\"\n+             doctype=\"book\"\n+             safemode=\"unsafe\">\n+  <attribute key=\"icons\" value=\"font\" />\n+  <attribute key=\"icon-set\" value=\"fa\" />\n+  <attribute key=\"pdf-stylesDir\" value=\"./pdf/themes\"/>\n+  <attribute key=\"pdf-style\" value=\"refguide\"/>\n+  <attribute key=\"pdf-fontsDir\" value=\"./pdf/fonts\"/>\n+  <attribute key=\"pagenums\" value='' />\n+  <attribute key=\"figure-caption!\" value='' />\n+  <attribute key=\"idprefix\" value='' />\n+  <attribute key=\"idseparator\" value='-' />\n+  <!-- attributes used in adoc files -->\n+  <!-- NOTE: If you add any attributes here for use in adoc files, you almost certainly need to also add\n+      them to the _config.yml.template file for building the jekyll site as well\n+  -->\n+  <attribute key=\"solr-docs-version\" value=\"${solr-docs-version}\" />\n+  <attribute key=\"solr-javadocs\" value=\"${solr-javadocs}\" />\n+  <attribute key=\"lucene-javadocs\" value=\"${lucene-javadocs}\" />\n+  <attribute key=\"build-date\" value=\"${DSTAMP}\" />\n+  <attribute key=\"build-year\" value=\"${current.year}\" />\n+</asciidoctor:convert>\n+----\n+\n+There are a lot of options here. Note that some include the `<attribute>` tag and some do not. Those that do not are options provided by `asciidoctor-ant` so don't need any special syntax. The options with the `<attribute>` tag are not provided by `asciidoctor-ant` but are supported by `asciidoctor-pdf` so will be applied when the target is run. A few of these are custom variables that we have defined ourselves.\n+\n+=== Asciidoctor Ant Attributes\n+\n+`sourceDirectory=\"${build.content.dir}/pdf\"`:: Defines where to find the source file to build the PDF. The variable is declared earlier in `build.xml`.\n+`sourceDocumentName=\"SolrRefGuide-all.adoc\"`:: The source file name, which in our case will be built as described in the section <<Creating the Uber-Document>>.\n+`baseDir=\"${build.content.dir}\"`:: The root path for any included files.\n+`outputDirectory=\"${build.dir}\"`:: Defines where the resulting PDF file should go. In this case, the\n+`backend=\"pdf\"`:: The output format. The `asciidoctor-ant` jar is also capable of outputting DocBook format, so we must declare we want a PDF.\n+`extensions=\"adoc\"`:: The file extensions to allow for the source document.\n+`sourceHighlighter=\"coderay\"`:: The library to use for syntax highlighting source code.\n+`imagesDir=\"${build.content.dir}\"`:: The directory to use to find images referenced in the documents.\n+`doctype=\"book\"`:: Adds support for book-style format and sections, such as a preface, colophon, glossary, index, etc.\n+`safemode=\"unsafe\">`:: Allows including resources that are external to the parent directory of the source file. For example, source examples could be pulled from Solr's source code instead of copied to documentation. This setting allows that to happen.\n+\n+=== Asciidoctor PDF Attributes\n+\n+`<attribute key=\"icons\" value=\"font\" />`:: The style of icons.\n+`<attribute key=\"icon-set\" value=\"fa\" />`:: The icon set to use. We use the Font Awesome font set.\n+`<attribute key=\"pdf-stylesDir\" value=\"./pdf/themes\"/>`:: The directory to find PDF themes. See the section <<Configuring the PDF Theme>> for more details on themes.\n+`<attribute key=\"pdf-style\" value=\"refguide\"/>`:: The theme to use. The theme must be saved in the directory referenced with the `pdf-stylesDir` attribute, and must be named `<pdf-style>-theme.yml`.\n+`<attribute key=\"pdf-fontsDir\" value=\"./pdf/fonts\"/>`:: The directory where to find fonts declared in the theme.\n+`<attribute key=\"figure-caption!\" value='' />`:: Sets caption labels and numbers (such as \"Figure 1\") to block images. The exclamation at the end of this setting in our config _disables_ figure captioning.\n+`<attribute key=\"idprefix\" value='' />`:: Sets the prefix for auto-generated section IDs, such as those from headings in a page. In our config, this is effectively \"null\", so auto-generated section IDs do not have any prefix.\n+`<attribute key=\"idseparator\" value='-' />`:: Sets the separator between words in auto-generated section IDs to a hyphen (`-`).\n+\n+=== Custom Attributes\n+\n+These attributes use variables that are inserted by Ant during the PDF creation process. This allows us to pull from standard Lucene/Solr build files, and not have to update several places for any release. The Ant build process updates the `_config.yml` file from the `_config.yml.template`, then these attributes pull the proper value from that file.\n+\n+`<attribute key=\"solr-docs-version\" value=\"${solr-docs-version}\" />`:: Sets the version to the current release version.\n+`<attribute key=\"solr-javadocs\" value=\"${solr-javadocs}\" />`:: Sets the path for Solr javadoc links to include the right path for the current release version.\n+`<attribute key=\"lucene-javadocs\" value=\"${lucene-javadocs}\" />`:: Sets the path for Lucene javadoc links to the right path for the current release version.\n+`<attribute key=\"build-date\" value=\"${DSTAMP}\" />`:: Sets the date of the build to add the date to the footer of each page of the PDF.\n+`<attribute key=\"build-year\" value=\"${current.year}\" />`:: Sets the year of the build to add the date to the copyright notice.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/pdf.adoc",
                "sha": "74921be91a6bbd6c8a52c304e6bdb95dd35b885c",
                "status": "added"
            },
            {
                "additions": 196,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/publish.adoc",
                "changes": 196,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/meta-docs/publish.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/meta-docs/publish.adoc",
                "patch": "@@ -0,0 +1,196 @@\n+= Publication Process\n+:toc:\n+\n+== About the Formats\n+\n+The Solr Ref Guide is published in two formats: PDF and HTML.\n+\n+The PDF version is the *official* release, and requires a vote before release. See <<Publishing PDF Version>> for details on how to generate the PDF and hold a vote.\n+\n+The HTML version is considered a \"convenience\" version, and does not require a vote. See <<Publishing HTML Version>> for details on how to publish the HTML.\n+\n+It's strongly preferred that both PDF and HTML versions are available during the vote for the PDF. However, since the HTML version is not an official release, it is more of an unwritten rule to publish the HTML at the same time as producing a release candidate for the PDF.\n+\n+== Publishing PDF Version\n+The PDF version of the Solr Reference Guide is the *official* version. As such, it is voted on by the community before release, and is treated as an official artifact of the Lucene/Solr project.\n+\n+=== Generate the PDF\n+\n+No local dependencies are required to build the PDF. The Ant target will download the jars and other items it requires.\n+\n+The build process generates the PDF, including the page hierarchy, and then runs an optimization script on the PDF to make it smaller.\n+\n+To build the PDF:\n+\n+. Run `ant build-pdf`\n+. The resulting PDF will be in `solr/build/solr-ref-guide`.\n+\n+=== Prerequisites\n+\n+* You have checked out the Lucene/Solr source code on the machine you will be doing the release from. You will need scripts in the `dev-tools` directory.\n+* You have generated a GPG key. See the Apache documentation on https://www.apache.org/dev/release-signing.html#generate[generating a code signing key].\n+* You have Python 3 installed. This is needed to poll the mirrors after release to be sure it's propagated enough to make the announcement.\n+\n+=== Prepare and Upload Release Candidate\n+\n+The `dist/dev` Subversion repository includes a directory for the Solr Ref Guide at https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/[`lucene/solr/ref-guide`] which can host the release candidate (RC) during the VOTE stage of the process.\n+\n+These steps walk through checking out this directory and uploading the Guide to it.\n+\n+. Checkout the directory: `svn co https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide solr-ref-guide-rc`\n+* If you have already checked out this directory, you can simply update it: `svn update solr-ref-guide-rc`\n+. Change directories so `solr-ref-guide-rc` is your working directory (`cd solr-ref-guide-rc`).\n+\n+IMPORTANT: The next step requires that you have already generated your GPG keys. Your GPG passphrase will be required.\n+\n+[start=3]\n+. Run the Prep Ref Guide script to prepare the RC. This script ensures proper naming of the PDF file, generates `.sha1` and `.asc` files and creates the proper RC sub-directories under `solr-ref-guide-rc`.\n+.. The structure of the input is: `prep-solr-ref-guide-rc.sh <path/PDFfilename> <Solrversion-RC#> GPGkey`.\n+.. From the `solr-ref-guide-rc` directory, it will look something like this:\n++\n+[source,bash]\n+----\n+$ ~/lucene-source/dev-tools/scripts/prep-solr-ref-guide-rc.sh apache-solr-ref-guide-7.0.pdf 7.0-RC0\n+\n++ mkdir apache-solr-ref-guide-7.0-RC0\n++ mv apache-solr-ref-guide-7.0.pdf apache-solr-ref-guide-7.0-RC0/apache-solr-ref-guide-7.0.pdf\n++ cd apache-solr-ref-guide-7.0-RC0\n++ sha1sum apache-solr-ref-guide-7.0.pdf\n++ gpg -u DEADBEEF --armor --output apache-solr-ref-guide-7.0.pdf.asc --detach-sig apache-solr-ref-guide-7.0.pdf\n+\n+You need a passphrase to unlock the secret key for\n+user: \"Your Name <you@apache.org>\"\n+4096-bit RSA key, ID DEADBEEF, created 1969-07-04\n+----\n++\n+. Add and commit the new release candidate to the `dist/dev` with these steps:\n+.. `svn add apache-solr-ref-guide-7.0-RC0`\n+.. `svn commit -m \"7.0 ref guide RC0\"`\n+\n+=== Hold a VOTE\n+Votes must be sent to the lucene-dev mailing list (`dev@lucene.apache.org`).\n+\n+. Send an email to `dev@lucene.apache.org` with subject, \"VOTE: Release Apache Solr Ref Guide for Solr X.Y\".\n+. The body of the email should include the full URL of the RC directory in the `dist/dev` repo. Such as: https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-7.0-RC0\n+. You can add your own +1 to the vote announcement email.\n+. If there are issues that need to be resolved, you can start the process over, using RC1, RC2, etc., as needed.\n+\n+Ideally, the HTML version will also be available for voters to evaluate, see the section <<Publishing HTML Version>> below for details of how to do that.\n+\n+=== Publish to Production & Archive Old Versions\n+\n+Once at least three PMC members have voted for release (see https://www.apache.org/foundation/voting.html#ReleaseVotes[Apache Voting Process] for details on the rules for votes), the release candidate can be released.\n+\n+. Use the Publish Solr Ref Guide script (`publish-solr-ref-guide.sh`) to generate the proper SVN commands to be run to execute a remote move of the RC files to the final `dist/releases` repository.\n+.. The script takes only the version and _RC number that passed the vote_ as inputs, such as `7.0-RC0`.\n+.. The input and output of the script will look like this:\n++\n+[source,bash]\n+----\n+$ ~/lucene-source/dev-tools/scripts/publish-solr-ref-guide-rc.sh X.Y-RCZ\n+\n+## Run the following commands when ready...\n+svn move -m 'publishing apache-solr-ref-guide-X.Y-RCZ' https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RCZ/apache-solr-ref-guide-X.Y.pdf https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RCZ/apache-solr-ref-guide-X.Y.pdf.asc https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RCZ/apache-solr-ref-guide-X.Y.pdf.sha1 https://dist.apache.org/repos/dist/release/lucene/solr/ref-guide/\n+\n+svn rm -m 'cleaning up apache-solr-ref-guide-X.Y-RCZ' https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RCZ\n+----\n+[start=2]\n+. The release should propagate to as many mirrors as possible before announcing the release, generally 24 hours is long enough. Use the Poll Mirrors script (`poll-mirrors.py`) to check the status:\n++\n+[source,bash]\n+python3 -u ~/lucene-source/dev-tools/scripts/poll-mirrors.py -details -p lucene/solr/ref-guide/apache-solr-ref-guide-X.Y.pdf\n+\n+* This script requires Python 3 to be installed on your machine.\n+* If you have over 85% of the mirrors with the file, it's OK to go ahead with the announcement.\n+. You may get an automated email about updating the ASF release repository; you can safely ignore this email.\n+. The `dist/releases` repo is only meant to keep the latest releases. Shortly after new releases are mirrored, they are copied to `archive.apache.org`, so older releases can safely be deleted from `dist/releases` since they have been backed up in the archives.\n+.. Run the Archive Ref Guide script (`archive-solr-ref-guide.sh`) using the X.Y version of the Ref Guide that has just been published. Older RCs will also be removed.\n+.. Again, this script doesn't do any direct removal of files, it only outputs SVN commands for you to copy and paste:\n++\n+[source,bash]\n+----\n+$ ~/lucene-source/dev-tools/scripts/archive-solr-ref-guide.sh X.Y\n+## Run the following commands when ready...\n+\n+# Delete old releases\n+svn rm -m 'removing archived ref guide files prior to X.Y' https://dist.apache.org/repos/dist/release/lucene/solr/ref-guide/apache-solr-ref-guide-A.B.pdf https://dist.apache.org/repos/dist/release/lucene/solr/ref-guide/apache-solr-ref-guide-A.B.pdf.asc https://dist.apache.org/repos/dist/release/lucene/solr/ref-guide/apache-solr-ref-guide-A.B.pdf.sha1\n+\n+# Delete old RC files\n+svn rm -m 'cleaning up old RCs now that X.Y has been released' https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RC0/ https://dist.apache.org/repos/dist/dev/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y-RC1/\n+----\n+\n+=== Announce the Release\n+\n+Announce the availability of the new Ref Guide on `solr-user@lucene.apache.org` and CC `general@lucene.apache.org` and `announce@apache.org`.\n+\n+WARNING: You must send the announcement email from your @apache.org email address or announce@apache will reject it.\n+\n+Always use the link to the download redirector for the announcement, as it will automatically direct users to the closest mirror for download: `https://www.apache.org/dyn/closer.cgi/lucene/solr/ref-guide/apache-solr-ref-guide-X.Y.pdf`.\n+\n+You could also include a link to the HTML version in your announcement, if the publication process for that has finished.\n+\n+== Publishing HTML Version\n+The steps to publish the Guide differ depending on if it is the first time the Guide has been published or if it is an update to an already published Guide.\n+\n+=== Building the HTML Version\n+\n+If you have the required dependencies on your local machine, you can build the HTML version with `ant build-site`. The dependencies are listed in `solr-ref-guide/README.adoc`.\n+\n+//TODO update Jenkins link\n+If you do not have the required dependencies, and don't choose to install them, you can download the files from the Jenkins (https://builds.apache.org/job/Solr-reference-guide-jira-SOLR-10290/lastSuccessfulBuild/artifact/solr/build/solr-ref-guide/html-site/[Solr Reference Guide job]).\n+\n+=== Publish a New Guide\n+// A lot of this was copied from https://wiki.apache.org/lucene-java/ReleaseTodo#Website_.2B-.3D_javadocs. See that section for explanations for why some steps are required.\n+\n+==== Step 1: Update extpaths.txt in CMS Staging\n+\n+. Checkout CMS trunk:\n++\n+[source,bash]\n+svn co --depth=immediates https://svn.apache.org/repos/asf/lucene/cms/trunk/content website-source\n++\n+* If you already have this repo checked out, you can simply `svn up website-source` to update to the latest revision.\n+. `cd website-source`\n+. Add Guide branch dir: `echo solr/guide/X_Y_Z >> extpaths.txt`\n+. Commit changes:\n++\n+[source,bash]\n+svn commit -m \"Update CMS production sync exceptions for X_Y_Z Guide\" extpaths.txt\n+\n+==== Step 2: Push Guide to Website Production\n+\n+Go to the checkout directory where you have built the Guide and push the documentation via subversion import. You must push it to the path you just added to `extpaths.txt`, so if the path you added was `solr/guide/6.5`, you'll use the path as shown in the below example:\n+\n+[source,bash]\n+svn -m \"Add Ref Guide for Solr 6.5\" import <checkoutroot>/solr/build/solr-ref-guide/html-site https://svn.apache.org/repos/infra/websites/production/lucene/content/solr/guide/6_5\n+\n+Confirm you can browse to these URLs manually, and especially that solr javadocs link back to lucene's correctly. Example:\n+https://lucene.apache.org/solr/guide/6_5\n+\n+==== Step 3: Push Staging extpaths.txt to Production\n+\n+The `extpaths.txt` works by listing paths that should be ignored when the CMS syncs the staging and production repositories. Publishing staging to production will only succeed if the paths listed in `extpaths.txt` exist in production. At the same time, if a path exists in production but not in staging it will be deleted unless it is defined in `extpaths.txt`. After pushing the content to production, check that the `extpaths.txt` in production includes the proper path to ensure that the Guide is not deleted incorrectly. If it does not exist in production, try to publish the site again to make sure it is updated.\n+\n+Production URL: https://lucene.apache.org/extpaths.txt\n+\n+==== Update Ref Guide Landing Page\n+\n+Update the landing page at https://lucene.apache.org/solr/guide to link to the newest version.\n+\n+You can use the CMS system for this since it is a small change, or you can edit the file locally and commit it to the staging repo.\n+\n+=== Update a Published Guide\n+\n+If you need to re-publish an existing online copy of the Guide, you will need to checkout the directory in production website repository and overwrite the existing files:\n+\n+. Build the new HTML files locally (`ant clean build-site`), or download them from Jenkins.\n+. Checkout the directory you need to update from the production repo: `svn co https://svn.apache.org/repos/infra/websites/production/lucene/content/solr/guide/<dir>`.\n+* This command checks out the Guide version directory into a local subdirectory with the same name as the version (such as \"6_5\"). You can provide a better name locally if you prefer by adding it to the end of the command shown above.\n+* Don't shortcut this and download the whole production website. It will take an incredibly long time and that will feel like _forever_.\n+. Copy the files from the build location to the checked out Guide directory. For example, if we needed to replace the current Guide for Solr 6.5, we'd do `cp -r <checkoutroot>/solr/build/html-site 6_5/.`\n+. Use `svn status` to see the files modified.\n+. If there are any pages added or deleted, use `svn add <file>` or `svn rm <file>` as needed.\n+. Commit the changes: `svn commit -m \"Update production 6.5 Ref Guide\"`\n+\n+// TODO:\n+// - figure out if redirects in .htaccess require any work here (probably)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/meta-docs/publish.adoc",
                "sha": "5a8fccb1cbad405a31d76147877442940c62ed42",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/.gitignore",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/.gitignore?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/.gitignore",
                "patch": "@@ -0,0 +1,3 @@\n+_site\n+.sass-cache\n+.jekyll-metadata",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/.gitignore",
                "sha": "45c150536e5f3888554c294f27539c5d41072467",
                "status": "added"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/404.md",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/404.md?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/404.md",
                "patch": "@@ -0,0 +1,6 @@\n+---\n+title: \"Page Not Found\"\n+search: exclude\n+---  \n+\n+Sorry, but the page you were trying to view does not exist. Try searching for it or looking at the URL to see if it looks correct.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/404.md",
                "sha": "a7b58c002144f895fc745d766a0f17938797a265",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/README.md",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/README.md?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/README.md",
                "patch": "@@ -0,0 +1,3 @@\n+## Jekyll Documentation theme\n+\n+Build the site to see the instructions for using it. Or just go here: [http://idratherbewriting.com/documentation-theme-jekyll/](http://idratherbewriting.com/documentation-theme-jekyll/)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/README.md",
                "sha": "20d66e37b3993f3a168e8654290c28f4ba0dcf15",
                "status": "added"
            },
            {
                "additions": 99,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_config.yml.template",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_config.yml.template?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_config.yml.template",
                "patch": "@@ -0,0 +1,99 @@\n+#\n+#\n+#\n+# NOTE: Ant converts _config.yml.template into create _config.yml and performs ant property substitution.\n+#\n+#\n+#\n+\n+# Gems that are included for building the site. jekyll-asciidoc allows Jekyll to use Asciidoctor for variables and settings\n+gems: [jekyll-asciidoc]\n+\n+destination: ../html-site\n+\n+# this property is useful for conditional filtering of content that is separate from the PDF.\n+output: web\n+\n+# this appears on the top navigation bar next to the home button\n+topnav_title: Solr Ref Guide\n+\n+# this appears in the html browser tab for the site title (seen mostly by search engines, not users)\n+site_title: Apache Solr Reference Guide\n+\n+# this appears in the footer\n+company_name: Apache Software Foundation\n+\n+\n+# the preview server used. Leave as is.\n+host: 127.0.0.1\n+\n+# the port where the preview is rendered. You can leave this as is unless you have other Jekyll builds using this same port that might cause conflicts. in that case, use another port such as 4006.\n+port: 4015\n+\n+# these are the files and directories that jekyll will exclude from the build\n+exclude:\n+  - .idea/\n+  - .gitignore\n+  - pdf/\n+\n+# if you uncomment the next line, the Feedback link gets removed\n+feedback_disable: true\n+\n+# used as a contact email for the Feedback link in the top navigation bar\n+# feedback_email: an_email@apache.org\n+\n+# if you uncomment the next line, it changes the Feedback text\n+# feedback_text: \"Need help?\"\n+\n+# if you uncomment the next line, it changes where the feedback link points to\n+# feedback_link: \"http://helpy.io/\"\n+\n+# these are defaults used for the frontmatter for these file types\n+defaults:\n+  -\n+    scope:\n+      path: \"\"\n+      type: \"pages\"\n+    values:\n+      layout: \"page\"\n+      search: true\n+\n+  -\n+    scope:\n+      path: \"\"\n+      type: \"posts\"\n+    values:\n+      layout: \"post\"\n+      search: true\n+\n+\n+# the description is used in the feed.xml file\n+description: \"The Apache Solr Reference Guide is the official documentation for the Apache Solr project.\"\n+\n+# needed for sitemap.xml and feed.xml files\n+url: https://home.apache.org/~ctargett/RefGuidePOC/jekyll-full\n+\n+# Asciidoc settings - disabled so we can use asciidoctor instead\n+asciidoc: {}\n+\n+# Custom Attributes for use in our templates & adoc files.\n+#\n+# Declared as a YAML reference so we can refer to them via site.solr-attributes.foo in liquid templates,\n+# in addition to using them below in our asciidoctor attribute configurations\n+# (see https://github.com/asciidoctor/jekyll-asciidoc/issues/137)\n+#\n+# NOTE: If you add any attributes here for use in adoc files, you almost certainly need to also add\n+# them to the <asciidoctor:convert/> ant task for building the PDF as well.\n+solr-attributes: &solr-attributes-ref\n+  solr-docs-version: \"${solr-docs-version}\"\n+  solr-javadocs: \"${solr-javadocs}\"\n+  lucene-javadocs: \"${lucene-javadocs}\"\n+  build-date: \"${DSTAMP}\"\n+  build-year: \"${current.year}\"\n+\n+asciidoctor:\n+  attributes:\n+    <<: *solr-attributes-ref\n+    icons: \"font\"\n+    source-highlighter: \"pygments\"\n+    pygments-css: \"style\"",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_config.yml.template",
                "sha": "c1e92717693c1213411c21392dc9e30146a08f6a",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_data/strings.yml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_data/strings.yml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_data/strings.yml",
                "patch": "@@ -0,0 +1,5 @@\n+\n+\n+# placed here for translation purposes\n+search_placeholder_text: search...\n+search_no_results_text: No results found.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_data/strings.yml",
                "sha": "d7c13924f5a4449e8ae141e188d605f817501abe",
                "status": "added"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_data/tags.yml",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_data/tags.yml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_data/tags.yml",
                "patch": "@@ -0,0 +1,7 @@\n+allowed-tags:\n+  - getting_started\n+  - content_types\n+  - troubleshooting\n+  - analysis\n+  - languages\n+  - scaling",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_data/tags.yml",
                "sha": "c4029ba414bfaf54bcb9c53bf3e6729b945d5818",
                "status": "added"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/archive.html",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/archive.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/archive.html",
                "patch": "@@ -0,0 +1,15 @@\n+---\n+layout: default\n+type: archive\n+---\n+\n+<div class=\"post-header\">\n+  <h1 class=\"post-title-main\">{{ page.title }}</h1>\n+</div>\n+<div class=\"post-content\">\n+\n+{{ content }}\n+</div>\n+\n+ \n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/archive.html",
                "sha": "275850c9cb34cb40f29f042bdcd43164aa537bc8",
                "status": "added"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/feedback.html",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/feedback.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/feedback.html",
                "patch": "@@ -0,0 +1,16 @@\n+<!-- Send feedback function -->\n+<script>\n+function SendLinkByMail(href) {\n+var subject= \"{{site.site_title}} feedback\";\n+var body = \"I have some feedback about the {{page.title}} page: \";\n+body += window.location.href;\n+body += \"\";\n+var uri = \"mailto:{{site.feedback_email}}?subject=\";\n+uri += encodeURIComponent(subject);\n+uri += \"&body=\";\n+uri += encodeURIComponent(body);\n+window.location.href = uri;\n+}\n+</script>\n+\n+<li><a href=\"{% if site.feedback_link %}{{site.feedback_link}}{% else %}javascript:(function()%7BSendLinkByMail()%3B%7D)()%3B{% endif %}\" target=\"_blank\">{% if site.feedback_link == null %}<i class=\"fa fa-envelope-o\"></i>{% endif %} {% if site.feedback_text %}{{site.feedback_text}}{% else %}Feedback{% endif %}</a></li>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/feedback.html",
                "sha": "bcd5fbc209d92389966ed8d725083ee81b510e46",
                "status": "added"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/footer.html",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/footer.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/footer.html",
                "patch": "@@ -0,0 +1,9 @@\n+<footer>\n+            <div class=\"row\">\n+                <div class=\"col-lg-12 footer\">\n+               &copy;{{ site.solr-attributes.build-year }} {{site.company_name}}. All rights reserved. <br />\n+{% if page.last_updated %}<p>Page last updated:</span> {{page.last_updated}}<br/>{% endif %} Site last generated: {{ site.solr-attributes.build-date }} <br />\n+<p><img src=\"{{ \"solr-sunOnly-small.png\" }}\" alt=\"Apache Solr\"/></p>\n+                </div>\n+            </div>\n+</footer>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/footer.html",
                "sha": "c22f239545e041b330229e93e13a06ab9666942d",
                "status": "added"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/google_analytics.html",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/google_analytics.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/google_analytics.html",
                "patch": "@@ -0,0 +1,6 @@\n+<!-- the google_analytics_id gets auto inserted from the config file -->\n+\n+{% if site.google_analytics %}\n+\n+<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','{{site.google_analytics}}','auto');ga('require','displayfeatures');ga('send','pageview');</script>\n+{% endif %}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/google_analytics.html",
                "sha": "56b2ee88c5d18b8a3785221c0e541ee0d9eab604",
                "status": "added"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/head.html",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/head.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/head.html",
                "patch": "@@ -0,0 +1,34 @@\n+<meta charset=\"utf-8\">\n+<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n+<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n+<meta name=\"description\" content=\"{% if page.description %}{{ page.description | strip_html | strip_newlines | truncate: 160 }}{% endif %}\">\n+<meta name=\"keywords\" content=\"{{page.tags}}{% if page.tags %}, {% endif %} {{page.keywords}}\">\n+<title>{{ page.title }} | {{ site.site_title }}</title>\n+\n+<link rel=\"stylesheet\" type=\"text/css\" href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css\">\n+<!--<link rel=\"stylesheet\" type=\"text/css\" href=\"css/bootstrap.min.css\">-->\n+<link rel=\"stylesheet\" href=\"{{ \"css/lavish-bootstrap.css\" }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"css/customstyles.css\" }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"css/theme-solr.css\" }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"css/ref-guide.css\" }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"css/comments.css\" }}\">\n+\n+<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js\"></script>\n+<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js\"></script>\n+<script src=\"{{ \"js/jquery.navgoco.min.js\" }}\"></script>\n+\n+<script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js\"></script>\n+<script src=\"https://cdnjs.cloudflare.com/ajax/libs/anchor-js/2.0.0/anchor.min.js\"></script>\n+<script src=\"{{ \"js/toc.js\" }}\"></script>\n+<script src=\"{{ \"js/customscripts.js\" }}\"></script>\n+\n+<link rel=\"shortcut icon\" href=\"{{ \"images/favicon.ico\"  }}\">\n+\n+<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->\n+<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->\n+<!--[if lt IE 9]>\n+<script src=\"https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js\"></script>\n+<script src=\"https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js\"></script>\n+<![endif]-->\n+\n+<link rel=\"alternate\" type=\"application/rss+xml\" title=\"{{ site.site_title }}\" href=\"{{ \"/feed.xml\" | prepend: site.url }}\">",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/head.html",
                "sha": "03b0db8c29938a8176c82f750ee119e92f3f15a4",
                "status": "added"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/head_print.html",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/head_print.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/head_print.html",
                "patch": "@@ -0,0 +1,33 @@\n+<meta charset=\"utf-8\">\n+<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n+<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n+<meta name=\"description\" content=\"{% if page.summary %}{{ page.summary | strip_html | strip_newlines | truncate: 160 }}{% endif %}\">\n+<meta name=\"keywords\" content=\"{{page.tags}}{% if page.tags %}, {% endif %} {{page.keywords}}\">\n+<title>{% if page.homepage == true %} {{site.homepage_title}} {% elsif page.title %}{{ page.title }}{% endif %}  | {{ site.site_title }}</title>\n+\n+\n+<link rel=\"stylesheet\" href=\"{{ \"/css/syntax.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/font-awesome.min.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/bootstrap.min.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/modern-business.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/lavish-bootstrap.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/customstyles.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/theme-green.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/syntax.css\" | prepend: site.baseurl | prepend: site.url }}\">\n+<link rel=\"stylesheet\" href=\"{{ \"/css/printstyles.css\" | prepend: site.baseurl }}\">\n+\n+<script>\n+    Prince.addScriptFunc(\"datestamp\", function() {\n+        return \"PDF last generated: {{ site.time | date: '%B %d, %Y' }}\";\n+    });\n+</script>\n+\n+<script>\n+    Prince.addScriptFunc(\"guideName\", function() {\n+        return \"{{site.print_title}} User Guide\";\n+    });\n+</script>\n+\n+\n+\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/head_print.html",
                "sha": "8f10c28f8608abca13c2caf4d7adab7b8e4eaf5a",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/image.html",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/image.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/image.html",
                "patch": "@@ -0,0 +1 @@\n+<figure>{% if {{include.url}} %}<a class=\"no_icon\" target=\"_blank\" href=\"{{include.url}}\">{% endif %}<img class=\"docimage\" src=\"images/{{include.file}}\" alt=\"{{include.alt}}\" {% if {{include.max-width}} %}style=\"max-width: {{include.max-width}}px\"{% endif %} />{% if {{include.url}} %}</a>{% endif %}{% if {{include.caption}} %}<figcaption>{{include.caption}}</figcaption></figure>{% endif %}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/image.html",
                "sha": "ad129725ccf777d4a8c874035c4e54c1d3e3fa87",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/inline_image.html",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/inline_image.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/inline_image.html",
                "patch": "@@ -0,0 +1 @@\n+<img class=\"inline\" src=\"images/{{include.file}}\" alt=\"{{include.alt}}\" />",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/inline_image.html",
                "sha": "1e7fd187cb76b860117114ba75fee1fa5afc8372",
                "status": "added"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/links.html",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/links.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/links.html",
                "patch": "@@ -0,0 +1,44 @@\n+{% comment %}Get links from each sidebar, as listed in the _config.yml file under sidebars{% endcomment %}\n+\n+{% for sidebar in site.sidebars %}\n+{% for entry in site.data.sidebars[sidebar].entries %}\n+{% for folder in entry.folders %}\n+{% for folderitem in folder.folderitems %}\n+{% if folderitem.url contains \"html#\" %}\n+[{{folderitem.url | remove: \"/\" }}]: {{folderitem.url | remove: \"/\"}}\n+{% else %}\n+[{{folderitem.url | remove: \"/\"  | remove: \".html\"}}]: {{folderitem.url | remove: \"/\"}}\n+{% endif %}\n+{% for subfolders in folderitem.subfolders %}\n+{% for subfolderitem in subfolders.subfolderitems %}\n+[{{subfolderitem.url | remove: \"/\"  | remove: \".html\"}}]: {{subfolderitem.url | remove: \"/\"}}\n+{% endfor %}\n+{% endfor %}\n+{% endfor %}\n+{% endfor %}\n+{% endfor %}\n+{% endfor %}\n+\n+\n+{% comment %} Get links from topnav {% endcomment %}\n+\n+{% for entry in site.data.topnav.topnav %}\n+{% for item in entry.items %}\n+{% if item.external_url == null %}\n+[{{item.url | remove: \"/\" | remove: \".html\"}}]: {{item.url | remove: \"/\"}}\n+{% endif %}\n+{% endfor %}\n+{% endfor %}\n+\n+{% comment %}Get links from topnav dropdowns {% endcomment %}\n+\n+{% for entry in site.data.topnav.topnav_dropdowns %}\n+{% for folder in entry.folders %}\n+{% for folderitem in folder.folderitems %}\n+{% if folderitem.external_url == null %}\n+[{{folderitem.url | remove: \"/\"  | remove: \".html\"}}]: {{folderitem.url | remove: \"/\"}}\n+{% endif %}\n+{% endfor %}\n+{% endfor %}\n+{% endfor %}\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/links.html",
                "sha": "4f99e9422ef76cd6bd5f6bd0536b32b2c22b209e",
                "status": "added"
            },
            {
                "additions": 59,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/sidebar.html",
                "changes": 59,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/sidebar.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/sidebar.html",
                "patch": "@@ -0,0 +1,59 @@\n+{% assign sidebar = site.data.sidebar %}\n+\n+<ul id=\"mysidebar\" class=\"nav\">\n+  <li class=\"sidebarTitle\">{{sidebar.title}} <!-- TODO: version from site.data --></li>\n+  {% for level1item in sidebar.kids %}\n+  <li class=\"sb-level1\">\n+    <a href=\"{{level1item.url | remove: \"/\"}}\">{{ level1item.title }}</a>\n+    {% if level1item.kids.size > 0 %}\n+    <ul>\n+      {% for level2item in level1item.kids %}\n+      <li class=\"sb-level2\">\n+        <a href=\"{{ level2item.url | remove: \"/\" }}\">{{ level2item.title }}</a>\n+        {% if level2item.kids.size > 0 %}\n+        <ul>\n+          {% for level3item in level2item.kids %}\n+          <li class=\"sb-level3\">\n+            <a href=\"{{ level3item.url | remove: \"/\" }}\">{{ level3item.title }}</a>\n+            {% if level3item.kids.size > 0 %}\n+            <ul>\n+              {% for level4item in level3item.kids %}\n+              <li class=\"sb-level4\">\n+                <a href=\"{{ level4item.url | remove: \"/\" }}\">{{ level4item.title }}</a>\n+                {% comment %}\n+                <!-- NOTE: adding addiional levels here will also require additional changes to \n+                     ref-guide.css in order to indent them properly\n+                  -->\n+                {% endcomment %}\n+              </li>\n+              {% endfor %}\n+            </ul>\n+            {% endif %}\n+          </li>\n+          {% endfor %}\n+        </ul>\n+        {% endif %}\n+      </li>\n+      {% endfor %}\n+    </ul>\n+    {% endif %}\n+  </li>\n+  {% endfor %}\n+</ul>\n+{% comment %}\n+<!-- if you aren't using the accordion, uncomment this block:\n+     <p class=\"external\">\n+       <a href=\"#\" id=\"collapseAll\">Collapse All</a> | <a href=\"#\" id=\"expandAll\">Expand All</a>\n+     </p>\n+     -->\n+{% endcomment %}\n+\n+<!-- set the 'active' class on the current page and ancestors -->\n+<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->\n+<script>$(\"#mysidebar a[href='{{ page.shortname }}.html']\").parents('li').toggleClass(\"active\", true);</script>\n+<!-- set the 'current' class on the current page and 'current-tree' on the current page + it's ancestors -->\n+<!-- this can let us do css highlighting of the current page in the sidebar even if/when the user clicks around in the sidebar causing other sidebar elements to be 'active' -->\n+<script>\n+  $(\"#mysidebar a[href='{{ page.shortname }}.html']\").parent('li').toggleClass(\"current\", true);\n+  $(\"#mysidebar a[href='{{ page.shortname }}.html']\").parents('li').toggleClass(\"current-tree\", true);\n+</script>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/sidebar.html",
                "sha": "4b4124c8f9bb445593e3cf5eeecbc6607c057f4e",
                "status": "added"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/taglogic.html",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/taglogic.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/taglogic.html",
                "patch": "@@ -0,0 +1,22 @@\n+<p>The following pages and posts are tagged with <button type=\"button\" style=\"cursor: default\" class=\"btn btn-default navbar-btn\">{{page.tagName}}</button></p>\n+<table><thead><tr><th>Title</th><th>Type</th><th>Excerpt</th></tr></thead>\n+    <tbody>\n+    {% assign thisTag = page.tagName %}\n+  {% for page in site.pages %}\n+    {% for tag in page.tags %}\n+        {% if tag == thisTag %}\n+\n+        <tr><td><a href=\"{{ page.url | remove: \"/\" }}\">{{page.title}}</a></td>\n+            <td><span class=\"label label-default\">Page</span></td>\n+          <td>{% if page.description %}\n+                {{ page.description | strip_html | strip_newlines | truncate: 160 }}\n+             {% else %}\n+               {{ page.content | truncatewords: 50 | strip_html }}\n+             {% endif %}</td>\n+        </tr>\n+        {% endif %}\n+     {% endfor %}\n+   {% endfor %}\n+\n+   </tbody>\n+</table>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/taglogic.html",
                "sha": "35efc5a821b535dc3106be1d7e14761d08043a23",
                "status": "added"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/toc.html",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/toc.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/toc.html",
                "patch": "@@ -0,0 +1,21 @@\n+\n+<!-- this handles the automatic toc. use ## for subheads to auto-generate the on-page minitoc. if you use html tags, you must supply an ID for the heading element in order for it to appear in the minitoc. -->\n+<script>\n+$( document ).ready(function() {\n+  // Handler for .ready() called.\n+\n+$('#toc').toc({ minimumHeaders: 2, listType: 'ul', showSpeed: 0, headers: 'h2,h3' });\n+\n+/* this offset helps account for the space taken up by the floating toolbar. */\n+$('#toc').on('click', 'a', function() {\n+  var target = $(this.getAttribute('href'))\n+    , scroll_target = target.offset().top\n+\n+  $(window).scrollTop(scroll_target - 10);\n+  return false\n+})\n+\n+});\n+</script>\n+\n+<div id=\"toc\"></div>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/toc.html",
                "sha": "14f74e0b63314ad2487384c48be231e54e1f3704",
                "status": "added"
            },
            {
                "additions": 63,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/topnav.html",
                "changes": 63,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_includes/topnav.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_includes/topnav.html",
                "patch": "@@ -0,0 +1,63 @@\n+<!-- Navigation -->\n+<nav class=\"navbar navbar-inverse navbar-fixed-top\">\n+    <div class=\"container topnavlinks\">\n+        <div class=\"navbar-header\">\n+            <button type=\"button\" class=\"navbar-toggle\" data-toggle=\"collapse\" data-target=\"#bs-example-navbar-collapse-1\">\n+                <span class=\"sr-only\">Toggle navigation</span>\n+                <span class=\"icon-bar\"></span>\n+                <span class=\"icon-bar\"></span>\n+                <span class=\"icon-bar\"></span>\n+            </button>\n+            <a class=\"fa fa-home fa-lg navbar-brand\" href=\"index.html\">&nbsp;<span class=\"projectTitle\"> {{site.topnav_title}} {{ site.solr-attributes.solr-docs-version }}</span></a>\n+        </div>\n+        <div class=\"collapse navbar-collapse\" id=\"bs-example-navbar-collapse-1\">\n+            <ul class=\"nav navbar-nav navbar-right\">\n+                <!-- Link to Solr website -->\n+                <li><a href=\"https://lucene.apache.org/solr/news\" target=\"_blank\">Solr News</a></li>\n+                <!-- Other Guide Formats dropdown -->\n+                <li class=\"dropdown\">\n+                    <a href=\"#\" class=\"dropdown-toggle\" data-toggle=\"dropdown\">Other Formats<b class=\"caret\"></b></a>\n+                    <ul class=\"dropdown-menu\">\n+                       <li><a href=\"https://www.apache.org/dyn/closer.cgi/lucene/solr/ref-guide\" target=\"_blank\">PDF for Latest Release</a></li>\n+                       <li><a href=\"https://archive.apache.org/dist/lucene/solr/ref-guide/\" target=\"_blank\">Archived PDFs</a></li>\n+                       <li><a href=\"https://lucene.apache.org/solr/guide/\" target=\"_blank\">Other Versions Online</a></li>\n+                    </ul>\n+                </li>\n+                <!-- Solr Resources dropdown -->\n+                <li class=\"dropdown\">\n+                    <a href=\"#\" class=\"dropdown-toggle\" data-toggle=\"dropdown\">Solr Resources<b class=\"caret\"></b></a>\n+                    <ul class=\"dropdown-menu\">\n+                       <li><a href=\"{{site.solr-attributes.solr-javadocs}}/solr-core/index.html\" target=\"_blank\">Solr Javadocs</a></li>\n+                       <li><a href=\"https://git1-us-west.apache.org/repos/asf?p=lucene-solr.git\" target=\"_blank\">Lucene/Solr Source Code</a></li>\n+                       <li><a href=\"https://lucene.apache.org/solr/resources.html#community\" target=\"_blank\">Solr Community Links</a></li>\n+                    </ul>\n+                </li>\n+                {% if site.feedback_disable == null or site.feedback_disable == false %}\n+                   {% include feedback.html %}\n+                {% endif %}\n+                <!--comment out this block if you want to hide search-->\n+                <li>\n+                    <!--start search-->\n+                    <div id=\"search-demo-container\">\n+                        <input type=\"text\" id=\"search-input\" placeholder=\"{{site.data.strings.search_placeholder_text}}\">\n+                        <ul id=\"results-container\"></ul>\n+                    </div>\n+                    <script src=\"{{ \"js/jekyll-search.js\"}}\" type=\"text/javascript\"></script>\n+                    <script type=\"text/javascript\">\n+                            SimpleJekyllSearch.init({\n+                                searchInput: document.getElementById('search-input'),\n+                                resultsContainer: document.getElementById('results-container'),\n+                                dataSource: '{{ \"search.json\" }}',\n+                                searchResultTemplate: '<li><a href=\"{url}\" title=\"{{page.title | replace: \"'\", \"\\\"}}\">{title}</a></li>',\n+                    noResultsText: '{{site.data.strings.search_no_results_text}}',\n+                            limit: 10,\n+                            fuzzy: true,\n+                    })\n+                    </script>\n+                    <!--end search-->\n+                </li>\n+            </ul>\n+        </div>\n+        </div>\n+        <!-- /.container -->\n+</nav>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_includes/topnav.html",
                "sha": "677f850fb49d84cf15b008558ebfa142ef70dc8d",
                "status": "added"
            },
            {
                "additions": 55,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/default.html",
                "changes": 55,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/default.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/default.html",
                "patch": "@@ -0,0 +1,55 @@\n+<!DOCTYPE html>\n+<head>\n+    {% include head.html %}\n+    <script>\n+        $(document).ready(function() {\n+            // Initialize navgoco with default options\n+            $(\"#mysidebar\").navgoco({\n+                caretHtml: '',\n+                accordion: true,\n+                openClass: 'active', // open\n+                save: false, // we do *NOT* want cookies used to save the current stage of the sidebar\n+                             // instead the code in sidebar.html will ensure that the current page\n+                             // (and it's ancestors) are \"active\" on page load\n+                slide: {\n+                    duration: 400,\n+                    easing: 'swing'\n+                }\n+            });\n+\n+            $(\"#collapseAll\").click(function(e) {\n+                e.preventDefault();\n+                $(\"#mysidebar\").navgoco('toggle', false);\n+            });\n+\n+            $(\"#expandAll\").click(function(e) {\n+                e.preventDefault();\n+                $(\"#mysidebar\").navgoco('toggle', true);\n+            });\n+\n+        });\n+\n+    </script>\n+</head>\n+<body id=\"{{ page.shortname }}\">\n+{% include topnav.html %}\n+<!-- Page Content -->\n+<div class=\"container\">\n+  <div class=\"col-lg-12\">&nbsp;</div>\n+  <!-- Content Row -->\n+  <div class=\"row\">\n+    <!-- Sidebar Column -->\n+    <div class=\"col-md-3\">\n+      {% include sidebar.html %}\n+    </div>\n+    <!-- Content Column -->\n+    <div class=\"col-md-9\">\n+      {{content}}\n+    </div>\n+    <!-- /.row -->\n+  </div>\n+  <!-- /.container -->\n+</div>\n+\n+</body>\n+</html>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/default.html",
                "sha": "aa4601f1fa10e3fac1bcae0561857571e846788c",
                "status": "added"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/default_print.html",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/default_print.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/default_print.html",
                "patch": "@@ -0,0 +1,25 @@\n+<!DOCTYPE html>\n+<html lang=\"en\">\n+<html>\n+<head>\n+    {% include head_print.html %}\n+\n+\n+</head>\n+\n+<body class=\"{% if page.type == \"title\"%}title{% elsif page.type == \"frontmatter\" %}frontmatter{% elsif page.type == \"first_page\" %}first_page{% endif %} print\">\n+\n+<!-- Page Content -->\n+<div class=\"container\">\n+    <!-- Content Column -->\n+    <div class=\"col-md-9\">\n+\n+        {{content}}\n+    </div>\n+\n+</div>    <!-- /.container -->\n+\n+</body>\n+\n+</html>\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/default_print.html",
                "sha": "4bf619b4735e2f1861c88c8fbb6e44941dcbf7e5",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/none.html",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/none.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/none.html",
                "patch": "@@ -0,0 +1,3 @@\n+---\n+---\n+{{content}}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/none.html",
                "sha": "60887a9201d77967970d81e9d1813785df2eb83e",
                "status": "added"
            },
            {
                "additions": 80,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/page.html",
                "changes": 80,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/page.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/page.html",
                "patch": "@@ -0,0 +1,80 @@\n+---\n+layout: default\n+---\n+\n+<div class=\"post-header\">\n+   <h1 class=\"post-title-main\">{{ page.title }}</h1>\n+</div>\n+\n+<!-- This adds a workflow map, to a page\n+     See http://idratherbewriting.com/documentation-theme-jekyll/mydoc_workflow_maps.html\n+     Leaving it here commented out in case we want to implement this in the future\n+{% if page.simple_map == true %}\n+<script>\n+    $(document).ready ( function(){\n+        $('.box{{page.box_number}}').addClass('active');\n+    });\n+</script>\n+{% include custom/{{page.map_name}}.html %}\n+{% elsif page.complex_map == true %}\n+<script>\n+    $(document).ready ( function(){\n+        $('.modalButton{{page.box_number}}').addClass('active');\n+    });\n+</script>\n+{% include custom/{{page.map_name}}.html %}\n+{% endif %} -->\n+\n+<div class=\"post-content\">\n+\n+   {% if page.summary %}\n+    <div class=\"summary\">{{ page.summary }}</div>\n+   {% endif %}\n+\n+    {% unless page.toc == false %}\n+    {% include toc.html %}\n+    {% endunless %}\n+\n+<div class=\"main-content\">\n+  {{content}}\n+</div>\n+\n+<!-- Adds tags, if any -->\n+    <div class=\"tags\">\n+        {% if page.tags != null %}\n+        <b>Tags: </b>\n+        {% assign projectTags = site.data.tags.allowed-tags %}\n+        {% for tag in page.tags %}\n+        {% if projectTags contains tag %}\n+        <a href=\"{{ \"tag-\" | append: tag | append: \".html\" }}\" class=\"btn btn-default navbar-btn cursorNorm\" role=\"button\">{{page.tagName}}{{tag}}</a>\n+        {% endif %}\n+        {% endfor %}\n+        {% endif %}\n+    </div>\n+\n+<!-- Adds nav links on each page -->\n+    {% assign scrollnav = site.data.scrollnav[page.shortname] %}\n+    {% if scrollnav %}\n+    <div class=\"scrollnav\">\n+      {% if scrollnav.prev %}\n+      <a class=\"btn btn-primary prev\" href=\"{{ scrollnav.prev.url }}\">{{ scrollnav.prev.title }}</a>\n+      {% endif %}\n+      {% if scrollnav.next %}\n+      <a class=\"btn btn-primary next\" href=\"{{ scrollnav.next.url }}\">{{ scrollnav.next.title }}</a>\n+      {% endif %}\n+    </div>\n+    {% endif %}\n+\n+</div>\n+\n+<!-- Adds comments from Apache's Comment system -->\n+\n+<div id=\"comments_thread\">\n+</div>\n+<script type=\"text/javascript\" src=\"https://comments.apache.org/show_comments.lua?site=solr-refguide&style=css/comments.css&page={{ page.shortname }}\" async=\"true\">\n+</script>\n+<noscript>\n+<iframe width=\"100%\" height=\"500\" src=\"https://comments.apache.org/iframe.lua?site=solr-refguide&style=css/comments.css&page={{ page.shortname }}\"></iframe>\n+</noscript>\n+\n+{% include footer.html %}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/page.html",
                "sha": "20758daff8376ba03acb560783463978e363cb30",
                "status": "added"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/page_print.html",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/page_print.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/page_print.html",
                "patch": "@@ -0,0 +1,15 @@\n+---\n+layout: default_print\n+comments: true\n+---\n+<div class=\"post-header\">\n+    <h1 class=\"post-title-main\" id=\"{{page.permalink | replace: '/', '' }}\">{{ page.title }}</h1>\n+</div>\n+\n+<div class=\"post-content\">\n+\n+    {% if page.summary %}\n+    <div class=\"summary\">{{page.summary}}</div>\n+    {% endif %}\n+    {{ content }}\n+</div>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/page_print.html",
                "sha": "9e04604a9cdf27419160baa50ec60bcc79d640b9",
                "status": "added"
            },
            {
                "additions": 41,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/post.html",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/_layouts/post.html?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/_layouts/post.html",
                "patch": "@@ -0,0 +1,41 @@\n+---\n+layout: default\n+---\n+<article class=\"post\" itemscope itemtype=\"http://schema.org/BlogPosting\">\n+\n+    <header class=\"post-header\">\n+        <h1 class=\"post-title\" itemprop=\"name headline\">{{ page.title }}</h1>\n+        <p class=\"post-meta\"><time datetime=\"{{ page.date | date_to_xmlschema }}\" itemprop=\"datePublished\">{{ page.date | date: \"%b %-d, %Y\" }}</time> {% if page.author %}<span itemprop=\"author\" itemscope itemtype=\"http://schema.org/Person\"><span itemprop=\"name\">/ {{ page.author }}</span></span>{% endif %}{% if page.tags != null %}/\n+            {% assign projectTags = site.data.tags.allowed-tags %}\n+            {% for tag in page.tags %}\n+            {% if projectTags contains tag %}\n+            <a href=\"{{ \"../tag_\" | append: tag | append: \".html\" }}\">{{tag}}</a>{% unless forloop.last %}, {% endunless%}\n+            {% endif %}\n+            {% endfor %}\n+            {% endif %}\n+\n+        </p>\n+\n+\n+    </header>\n+\n+    <div class=\"post-content\" itemprop=\"articleBody\">\n+\n+        {% if page.summary %}\n+        <div class=\"summary\">{{page.summary}}</div>\n+        {% endif %}\n+\n+        {{ content }}\n+    </div>\n+\n+\n+\n+</article>\n+\n+{% if site.disqus %}\n+{% include disqus.html %}\n+{% endif %}\n+\n+{{site.data.alerts.hr_shaded}}\n+\n+{% include footer.html %}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/_layouts/post.html",
                "sha": "d1ba8f195d9da853d5b77156f99c0ad1dc083f53",
                "status": "added"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/a-quick-overview.adoc",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/a-quick-overview.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/a-quick-overview.adoc",
                "patch": "@@ -0,0 +1,33 @@\n+= A Quick Overview\n+:page-shortname: a-quick-overview\n+:page-permalink: a-quick-overview.html\n+\n+Having had some fun with Solr, you will now learn about all the cool things it can do.\n+\n+Here is a example of how Solr might be integrated into an application:\n+\n+.Solr integration with applications\n+image::images/a-quick-overview/sample-client-app-arch.png[image,width=500,height=379]\n+\n+In the scenario above, Solr runs along side other server applications. For example, an online store application would provide a user interface, a shopping cart, and a way to make purchases for end users; while an inventory management application would allow store employees to edit product information. The product metadata would be kept in some kind of database, as well as in Solr.\n+\n+Solr makes it easy to add the capability to search through the online store through the following steps:\n+\n+. Define a _schema_. The schema tells Solr about the contents of documents it will be indexing. In the online store example, the schema would define fields for the product name, description, price, manufacturer, and so on. Solr's schema is powerful and flexible and allows you to tailor Solr's behavior to your application. See <<documents-fields-and-schema-design.adoc#documents-fields-and-schema-design,Documents, Fields, and Schema Design>> for all the details.\n+. Deploy Solr.\n+. Feed Solr documents for which your users will search.\n+. Expose search functionality in your application.\n+\n+Because Solr is based on open standards, it is highly extensible. Solr queries are RESTful, which means, in essence, that a query is a simple HTTP request URL and the response is a structured document: mainly XML, but it could also be JSON, CSV, or some other format. This means that a wide variety of clients will be able to use Solr, from other web applications to browser clients, rich client applications, and mobile devices. Any platform capable of HTTP can talk to Solr. See <<client-apis.adoc#client-apis,Client APIs>> for details on client APIs.\n+\n+Solr is based on the Apache Lucene project, a high-performance, full-featured search engine. Solr offers support for the simplest keyword searching through to complex queries on multiple fields and faceted search results. <<searching.adoc#searching,Searching>> has more information about searching and queries.\n+\n+If Solr's capabilities are not impressive enough, its ability to handle very high-volume applications should do the trick.\n+\n+A relatively common scenario is that you have so much data, or so many queries, that a single Solr server is unable to handle your entire workload. In this case, you can scale up the capabilities of your application using <<solrcloud.adoc#solrcloud,SolrCloud>> to better distribute the data, and the processing of requests, across many servers. Multiple options can be mixed and matched depending on the type of scalability you need.\n+\n+For example: \"Sharding\" is a scaling technique in which a collection is split into multiple logical pieces called \"shards\" in order to scale up the number of documents in a collection beyond what could physically fit on a single server. Incoming queries are distributed to every shard in the collection, which respond with merged results. Another technique available is to increase the \"Replication Factor\" of your collection, which allows you to add servers with additional copies of your collection to handle higher concurrent query load by spreading the requests around to multiple machines. Sharding and Replication are not mutually exclusive, and together make Solr an extremely powerful and scalable platform.\n+\n+Best of all, this talk about high-volume applications is not just hypothetical: some of the famous Internet sites that use Solr today are Macy's, EBay, and Zappo's.\n+\n+For more information, take a look at https://wiki.apache.org/solr/PublicServers.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/a-quick-overview.adoc",
                "sha": "b87d091ff79b642a6f1c5a47031dda0e1fdcf013",
                "status": "added"
            },
            {
                "additions": 54,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/a-step-closer.adoc",
                "changes": 54,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/a-step-closer.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/a-step-closer.adoc",
                "patch": "@@ -0,0 +1,54 @@\n+= A Step Closer\n+:page-shortname: a-step-closer\n+:page-permalink: a-step-closer.html\n+\n+You already have some idea of Solr's schema. This section describes Solr's home directory and other configuration options.\n+\n+When Solr runs in an application server, it needs access to a home directory. The home directory contains important configuration information and is the place where Solr will store its index. The layout of the home directory will look a little different when you are running Solr in standalone mode vs when you are running in SolrCloud mode.\n+\n+The crucial parts of the Solr home directory are shown in these examples:\n+\n+.Standalone Mode\n+[source,plain]\n+----\n+<solr-home-directory>/\n+   solr.xml\n+   core_name1/\n+      core.properties\n+      conf/\n+         solrconfig.xml\n+         managed-schema\n+      data/\n+   core_name2/\n+      core.properties\n+      conf/\n+         solrconfig.xml\n+         managed-schema\n+      data/\n+----\n+\n+.SolrCloud Mode\n+[source,plain]\n+----\n+<solr-home-directory>/\n+   solr.xml\n+   core_name1/\n+      core.properties\n+      data/\n+   core_name2/\n+      core.properties\n+      data/\n+----\n+\n+You may see other files, but the main ones you need to know are:\n+\n+* `solr.xml` specifies configuration options for your Solr server instance. For more information on `solr.xml` see <<solr-cores-and-solr-xml.adoc#solr-cores-and-solr-xml,Solr Cores and solr.xml>>.\n+* Per Solr Core:\n+** `core.properties` defines specific properties for each core such as its name, the collection the core belongs to, the location of the schema, and other parameters. For more details on `core.properties`, see the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>>.\n+** `solrconfig.xml` controls high-level behavior. You can, for example, specify an alternate location for the data directory. For more information on `solrconfig.xml`, see <<configuring-solrconfig-xml.adoc#configuring-solrconfig-xml,Configuring solrconfig.xml>>.\n+** `managed-schema` (or `schema.xml` instead) describes the documents you will ask Solr to index. The Schema define a document as a collection of fields. You get to define both the field types and the fields themselves. Field type definitions are powerful and include information about how Solr processes incoming field values and query values. For more information on Solr Schemas, see <<documents-fields-and-schema-design.adoc#documents-fields-and-schema-design,Documents, Fields, and Schema Design>> and the <<schema-api.adoc#schema-api,Schema API>>.\n+** `data/` The directory containing the low level index files.\n+\n+Note that the SolrCloud example does not include a `conf` directory for each Solr Core (so there is no `solrconfig.xml` or Schema file). This is because the configuration files usually found in the `conf` directory are stored in ZooKeeper so they can be propagated across the cluster.\n+\n+If you are using SolrCloud with the embedded ZooKeeper instance, you may also see `zoo.cfg` and `zoo.data` which are ZooKeeper configuration and data files. However, if you are running your own ZooKeeper ensemble, you would supply your own ZooKeeper configuration file when you start it and the copies in Solr would be unused. For more information about ZooKeeper and SolrCloud, see the section <<solrcloud.adoc#solrcloud,SolrCloud>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/a-step-closer.adoc",
                "sha": "f74d214145d8758f280b34939f3a61460ae0bb29",
                "status": "added"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-filters.adoc",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/about-filters.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/about-filters.adoc",
                "patch": "@@ -0,0 +1,29 @@\n+= About Filters\n+:page-shortname: about-filters\n+:page-permalink: about-filters.html\n+\n+Like <<tokenizers.adoc#tokenizers,tokenizers>>, <<filter-descriptions.adoc#filter-descriptions,filters>> consume input and produce a stream of tokens. Filters also derive from `org.apache.lucene.analysis.TokenStream`. Unlike tokenizers, a filter's input is another TokenStream. The job of a filter is usually easier than that of a tokenizer since in most cases a filter looks at each token in the stream sequentially and decides whether to pass it along, replace it or discard it.\n+\n+A filter may also do more complex analysis by looking ahead to consider multiple tokens at once, although this is less common. One hypothetical use for such a filter might be to normalize state names that would be tokenized as two words. For example, the single token \"california\" would be replaced with \"CA\", while the token pair \"rhode\" followed by \"island\" would become the single token \"RI\".\n+\n+Because filters consume one `TokenStream` and produce a new `TokenStream`, they can be chained one after another indefinitely. Each filter in the chain in turn processes the tokens produced by its predecessor. The order in which you specify the filters is therefore significant. Typically, the most general filtering is done first, and later filtering stages are more specialized.\n+\n+[source,xml]\n+----\n+<fieldType name=\"text\" class=\"solr.TextField\">\n+  <analyzer>\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.StandardFilterFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+    <filter class=\"solr.EnglishPorterFilterFactory\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+This example starts with Solr's standard tokenizer, which breaks the field's text into tokens. Those tokens then pass through Solr's standard filter, which removes dots from acronyms, and performs a few other common operations. All the tokens are then set to lowercase, which will facilitate case-insensitive matching at query time.\n+\n+The last filter in the above example is a stemmer filter that uses the Porter stemming algorithm. A stemmer is basically a set of mapping rules that maps the various forms of a word back to the base, or _stem_, word from which they derive. For example, in English the words \"hugs\", \"hugging\" and \"hugged\" are all forms of the stem word \"hug\". The stemmer will replace all of these terms with \"hug\", which is what will be indexed. This means that a query for \"hug\" will match the term \"hugged\", but not \"huge\".\n+\n+Conversely, applying a stemmer to your query terms will allow queries containing non stem terms, like \"hugging\", to match documents with different variations of the same stem word, such as \"hugged\". This works because both the indexer and the query will map to the same stem (\"hug\").\n+\n+Word stemming is, obviously, very language specific. Solr includes several language-specific stemmers created by the http://snowball.tartarus.org/[Snowball] generator that are based on the Porter stemming algorithm. The generic Snowball Porter Stemmer Filter can be used to configure any of these language stemmers. Solr also includes a convenience wrapper for the English Snowball stemmer. There are also several purpose-built stemmers for non-English languages. These stemmers are described in <<language-analysis.adoc#language-analysis,Language Analysis>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-filters.adoc",
                "sha": "84e3b95b44898a02ece975618a1c3c1a9b97011d",
                "status": "added"
            },
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-this-guide.adoc",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/about-this-guide.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/about-this-guide.adoc",
                "patch": "@@ -0,0 +1,57 @@\n+= About This Guide\n+:page-shortname: about-this-guide\n+:page-permalink: about-this-guide.html\n+\n+This guide describes all of the important features and functions of Apache Solr.\n+\n+Solr is free to download from http://lucene.apache.org/solr/.\n+\n+Designed to provide high-level documentation, this guide is intended to be more encyclopedic and less of a cookbook. It is structured to address a broad spectrum of needs, ranging from new developers getting started to well-experienced developers extending their application or troubleshooting. It will be of use at any point in the application life cycle, for whenever you need authoritative information about Solr.\n+\n+The material as presented assumes that you are familiar with some basic search concepts and that you can read XML. It does not assume that you are a Java programmer, although knowledge of Java is helpful when working directly with Lucene or when developing custom extensions to a Lucene/Solr installation.\n+\n+[[AboutThisGuide-SpecialInlineNotes]]\n+== Special Inline Notes\n+\n+Special notes are included throughout these pages. There are several types of notes:\n+\n+Information blocks::\n++\n+NOTE: These provide additional information that's useful for you to know.\n+\n+Important::\n++\n+IMPORTANT: These provide information that is critical for you to know.\n+\n+Tip::\n++\n+TIP: These provide helpful tips.\n+\n+Caution::\n++\n+CAUTION: These provide details on scenarios or configurations you should be careful with.\n+\n+Warning::\n++\n+WARNING: These are meant to warn you from a possibly dangerous change or action.\n+\n+\n+[[AboutThisGuide-HostsandPortExamples]]\n+== Hosts and Port Examples\n+\n+The default port when running Solr is 8983. The samples, URLs and screenshots in this guide may show different ports, because the port number that Solr uses is configurable. If you have not customized your installation of Solr, please make sure that you use port 8983 when following the examples, or configure your own installation to use the port numbers shown in the examples. For information about configuring port numbers, see the section <<managing-solr.adoc#managing-solr,Managing Solr>>.\n+\n+Similarly, URL examples use 'localhost' throughout; if you are accessing Solr from a location remote to the server hosting Solr, replace 'localhost' with the proper domain or IP where Solr is running.\n+\n+For example, we might provide a sample query like:\n+\n+`\\http://localhost:8983/solr/gettingstarted/select?q=brown+cow`\n+\n+There are several items in this URL you might need to change locally. First, if your server is running at \"www.example.com\", you'll replace \"localhost\" with the proper domain. If you aren't using port 8983, you'll replace that also. Finally, you'll want to replace \"gettingstarted\" (the collection or core name) with the proper one in use in your implementation. The URL would then become:\n+\n+`\\http://www.example.com/solr/mycollection/select?q=brown+cow`\n+\n+[[AboutThisGuide-Paths]]\n+== Paths\n+\n+Path information is given relative to `solr.home`, which is the location under the main Solr installation where Solr's collections and their `conf` and `data` directories are stored. When running the various examples mentioned through out this tutorial (i.e., `bin/solr -e techproducts`) the `solr.home` will be a sub-directory of `example/` created for you automatically.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-this-guide.adoc",
                "sha": "a9d1564c5e0f468fa727a8de89aaa21a2b06e888",
                "status": "added"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-tokenizers.adoc",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/about-tokenizers.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/about-tokenizers.adoc",
                "patch": "@@ -0,0 +1,31 @@\n+= About Tokenizers\n+:page-shortname: about-tokenizers\n+:page-permalink: about-tokenizers.html\n+\n+The job of a <<tokenizers.adoc#tokenizers,tokenizer>> is to break up a stream of text into tokens, where each token is (usually) a sub-sequence of the characters in the text. An analyzer is aware of the field it is configured for, but a tokenizer is not. Tokenizers read from a character stream (a Reader) and produce a sequence of Token objects (a TokenStream).\n+\n+Characters in the input stream may be discarded, such as whitespace or other delimiters. They may also be added to or replaced, such as mapping aliases or abbreviations to normalized forms. A token contains various metadata in addition to its text value, such as the location at which the token occurs in the field. Because a tokenizer may produce tokens that diverge from the input text, you should not assume that the text of the token is the same text that occurs in the field, or that its length is the same as the original text. It's also possible for more than one token to have the same position or refer to the same offset in the original text. Keep this in mind if you use token metadata for things like highlighting search results in the field text.\n+\n+[source,xml]\n+----\n+<fieldType name=\"text\" class=\"solr.TextField\">\n+  <analyzer>\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+The class named in the tokenizer element is not the actual tokenizer, but rather a class that implements the `TokenizerFactory` API. This factory class will be called upon to create new tokenizer instances as needed. Objects created by the factory must derive from `Tokenizer`, which indicates that they produce sequences of tokens. If the tokenizer produces tokens that are usable as is, it may be the only component of the analyzer. Otherwise, the tokenizer's output tokens will serve as input to the first filter stage in the pipeline.\n+\n+A `TypeTokenFilterFactory` is available that creates a `TypeTokenFilter` that filters tokens based on their TypeAttribute, which is set in `factory.getStopTypes`.\n+\n+For a complete list of the available TokenFilters, see the section <<tokenizers.adoc#tokenizers,Tokenizers>>.\n+\n+[[AboutTokenizers-WhenTouseaCharFiltervs.aTokenFilter]]\n+== When To use a CharFilter vs. a TokenFilter\n+\n+There are several pairs of CharFilters and TokenFilters that have related (ie: `MappingCharFilter` and `ASCIIFoldingFilter`) or nearly identical (ie: `PatternReplaceCharFilterFactory` and `PatternReplaceFilterFactory`) functionality and it may not always be obvious which is the best choice.\n+\n+The decision about which to use depends largely on which Tokenizer you are using, and whether you need to preprocess the stream of characters.\n+\n+For example, suppose you have a tokenizer such as `StandardTokenizer` and although you are pretty happy with how it works overall, you want to customize how some specific characters behave. You could modify the rules and re-build your own tokenizer with JFlex, but it might be easier to simply map some of the characters before tokenization with a `CharFilter`.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/about-tokenizers.adoc",
                "sha": "4dec7cf82fb79fd44dfa9a1907d2427a41f2f5b4",
                "status": "added"
            },
            {
                "additions": 156,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/adding-custom-plugins-in-solrcloud-mode.adoc",
                "changes": 156,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/adding-custom-plugins-in-solrcloud-mode.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/adding-custom-plugins-in-solrcloud-mode.adoc",
                "patch": "@@ -0,0 +1,156 @@\n+= Adding Custom Plugins in SolrCloud Mode\n+:page-shortname: adding-custom-plugins-in-solrcloud-mode\n+:page-permalink: adding-custom-plugins-in-solrcloud-mode.html\n+\n+In SolrCloud mode, custom plugins need to be shared across all nodes of the cluster.\n+\n+When running Solr in SolrCloud mode and you want to use custom code (such as custom analyzers, tokenizers, query parsers, and other plugins), it can be cumbersome to add jars to the classpath on all nodes in your cluster. Using the <<blob-store-api.adoc#blob-store-api,Blob Store API>> and special commands with the <<config-api.adoc#config-api,Config API>>, you can upload jars to a special system-level collection and dynamically load plugins from them at runtime with out needing to restart any nodes.\n+\n+.This Feature is Disabled By Default\n+[IMPORTANT]\n+====\n+In addition to requiring that Solr by running in <<solrcloud.adoc#solrcloud,SolrCloud>> mode, this feature is also disabled by default unless all Solr nodes are run with the `-Denable.runtime.lib=true` option on startup.\n+\n+Before enabling this feature, users should carefully consider the issues discussed in the <<Securing Runtime Libraries>> section below.\n+====\n+\n+[[AddingCustomPluginsinSolrCloudMode-UploadingJarFiles]]\n+== Uploading Jar Files\n+\n+The first step is to use the <<blob-store-api.adoc#blob-store-api,Blob Store API>> to upload your jar files. This will to put your jars in the `.system` collection and distribute them across your SolrCloud nodes. These jars are added to a separate classloader and only accessible to components that are configured with the property `runtimeLib=true`. These components are loaded lazily because the `.system` collection may not be loaded when a particular core is loaded.\n+\n+[[AddingCustomPluginsinSolrCloudMode-ConfigAPICommandstouseJarsasRuntimeLibraries]]\n+== Config API Commands to use Jars as Runtime Libraries\n+\n+The runtime library feature uses a special set of commands for the <<config-api.adoc#config-api,Config API>> to add, update, or remove jar files currently available in the blob store to the list of runtime libraries.\n+\n+The following commands are used to manage runtime libs:\n+\n+* `add-runtimelib`\n+* `update-runtimelib`\n+* `delete-runtimelib`\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json' -d '{\n+   \"add-runtimelib\": { \"name\":\"jarblobname\", \"version\":2 },\n+   \"update-runtimelib\": { \"name\":\"jarblobname\", \"version\":3 },\n+   \"delete-runtimelib\": \"jarblobname\"\n+}'\n+----\n+\n+The name to use is the name of the blob that you specified when you uploaded your jar to the blob store. You should also include the version of the jar found in the blob store that you want to use. These details are added to `configoverlay.json`.\n+\n+The default `SolrResourceLoader` does not have visibility to the jars that have been defined as runtime libraries. There is a classloader that can access these jars which is made available only to those components which are specially annotated.\n+\n+Every pluggable component can have an optional extra attribute called `runtimeLib=true`, which means that the components are not loaded at core load time. Instead, they will be loaded on demand. If all the dependent jars are not available when the component is loaded, an error is thrown.\n+\n+This example shows creating a ValueSourceParser using a jar that has been loaded to the Blob store.\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json' -d '{\n+  \"create-valuesourceparser\": {\n+    \"name\": \"nvl\",\n+    \"runtimeLib\": true,\n+    \"class\": \"solr.org.apache.solr.search.function.NvlValueSourceParser,\n+    \"nvlFloatValue\": 0.0 }\n+}'\n+----\n+\n+[[AddingCustomPluginsinSolrCloudMode-SecuringRuntimeLibraries]]\n+== Securing Runtime Libraries\n+\n+A drawback of this feature is that it could be used to load malicious executable code into the system. However, it is possible to restrict the system to load only trusted jars using http://en.wikipedia.org/wiki/Public_key_infrastructure[PKI] to verify that the executables loaded into the system are trustworthy.\n+\n+The following steps will allow you enable security for this feature. The instructions assume you have started all your Solr nodes with the `-Denable.runtime.lib=true`.\n+\n+[[Step1_GenerateanRSAPrivateKey]]\n+=== Step 1: Generate an RSA Private Key\n+\n+The first step is to generate an RSA private key. The example below uses a 512-bit key, but you should use the strength appropriate to your needs.\n+\n+[source,bash]\n+----\n+$ openssl genrsa -out priv_key.pem 512\n+----\n+\n+[[Step2_OutputthePublicKey]]\n+=== Step 2: Output the Public Key\n+\n+The public portion of the key should be output in DER format so Java can read it.\n+\n+[source,bash]\n+----\n+$ openssl rsa -in priv_key.pem -pubout -outform DER -out pub_key.der\n+----\n+\n+[[Step3_LoadtheKeytoZooKeeper]]\n+=== Step 3: Load the Key to ZooKeeper\n+\n+The `.der` files that are output from Step 2 should then be loaded to ZooKeeper under a node `/keys/exe` so they are available throughout every node. You can load any number of public keys to that node and all are valid. If a key is removed from the directory, the signatures of that key will cease to be valid. So, before removing the a key, make sure to update your runtime library configurations with valid signatures with the `update-runtimelib` command.\n+\n+At the current time, you can only use the ZooKeeper `zkCli.sh` (or `zkCli.cmd` on Windows) script to issue these commands (the Solr version has the same name, but is not the same). If you have your own ZooKeeper ensemble running already, you can find the script in `$ZK_INSTALL/bin/zkCli.sh` (or `zkCli.cmd` if you are using Windows).\n+\n+NOTE: If you are running the embedded ZooKeeper that is included with Solr, you *do not* have this script already; in order to use it, you will need to download a copy of ZooKeeper v3.4.6 from http://zookeeper.apache.org/. Don't worry about configuring the download, you're just trying to get the command line utility script. When you start the script, you will connect to the embedded ZooKeeper.\n+\n+To load the keys, you will need to connect to ZooKeeper with `zkCli.sh`, create the directories, and then create the key file, as in the following example.\n+\n+[source,bash]\n+----\n+# Connect to ZooKeeper\n+# Replace the server location below with the correct ZooKeeper connect string for your installation.\n+$ .bin/zkCli.sh -server localhost:9983\n+\n+# After connection, you will interact with the ZK prompt.\n+# Create the directories\n+[zk: localhost:9983(CONNECTED) 5] create /keys\n+[zk: localhost:9983(CONNECTED) 5] create /keys/exe\n+\n+# Now create the public key file in ZooKeeper\n+# The second path is the path to the .der file on your local machine\n+[zk: localhost:9983(CONNECTED) 5] create /keys/exe/pub_key.der /myLocal/pathTo/pub_key.der\n+----\n+\n+After this, any attempt to load a jar will fail. All your jars must be signed with one of your private keys for Solr to trust it. The process to sign your jars and use the signature is outlined in Steps 4-6.\n+\n+[[Step4_SignthejarFile]]\n+=== Step 4: Sign the jar File\n+\n+Next you need to sign the sha1 digest of your jar file and get the base64 string.\n+\n+[source,bash]\n+----\n+$ openssl dgst -sha1 -sign priv_key.pem myjar.jar | openssl enc -base64\n+----\n+\n+The output of this step will be a string that you will need to add the jar to your classpath in Step 6 below.\n+\n+[[Step5_LoadthejartotheBlobStore]]\n+=== Step 5: Load the jar to the Blob Store\n+\n+Load your jar to the Blob store, using the <<blob-store-api.adoc#blob-store-api,Blob Store API>>. This step does not require a signature; you will need the signature in Step 6 to add it to your classpath.\n+\n+[source,bash]\n+----\n+curl -X POST -H 'Content-Type: application/octet-stream' --data-binary @{filename}\n+http://localhost:8983/solr/.system/blob/{blobname}\n+----\n+\n+The blob name that you give the jar file in this step will be used as the name in the next step.\n+\n+[[Step6_AddthejartotheClasspath]]\n+=== Step 6: Add the jar to the Classpath\n+\n+Finally, add the jar to the classpath using the Config API as detailed above. In this step, you will need to provide the signature of the jar that you got in Step 4.\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json'  -d '{\n+  \"add-runtimelib\": {\n+    \"name\":\"blobname\",\n+    \"version\":2,\n+    \"sig\":\"mW1Gwtz2QazjfVdrLFHfbGwcr8xzFYgUOLu68LHqWRDvLG0uLcy1McQ+AzVmeZFBf1yLPDEHBWJb5KXr8bdbHN/\n+           PYgUB1nsr9pk4EFyD9KfJ8TqeH/ijQ9waa/vjqyiKEI9U550EtSzruLVZ32wJ7smvV0fj2YYhrUaaPzOn9g0=\" }\n+}'\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/adding-custom-plugins-in-solrcloud-mode.adoc",
                "sha": "4c6a04de9bee0bd8e7d84a7f14e645ce06d19361",
                "status": "added"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/analysis-screen.adoc",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/analysis-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/analysis-screen.adoc",
                "patch": "@@ -0,0 +1,17 @@\n+= Analysis Screen\n+:page-shortname: analysis-screen\n+:page-permalink: analysis-screen.html\n+\n+The Analysis screen lets you inspect how data will be handled according to the field, field type and dynamic field configurations found in your Schema. You can analyze how content would be handled during indexing or during query processing and view the results separately or at the same time. Ideally, you would want content to be handled consistently, and this screen allows you to validate the settings in the field type or field analysis chains.\n+\n+Enter content in one or both boxes at the top of the screen, and then choose the field or field type definitions to use for analysis.\n+\n+image::images/analysis-screen/analysis_normal.png[image,height=400]\n+\n+If you click the *Verbose Output* check box, you see more information, including more details on the transformations to the input (such as, convert to lower case, strip extra characters, etc.) including the raw bytes, type and detailed position information at each stage. The information displayed will vary depending on the settings of the field or field type. Each step of the process is displayed in a separate section, with an abbreviation for the tokenizer or filter that is applied in that step. Hover or click on the abbreviation, and you'll see the name and path of the tokenizer or filter.\n+\n+image::images/analysis-screen/analysis_verbose.png[image,height=400]\n+\n+In the example screenshot above, several transformations are applied to the input \"Running is a sport.\" The words \"is\" and \"a\" have been removed and the word \"running\" has been changed to its basic form, \"run\". This is because we are using the field type `text_en` in this scenario, which is configured to remove stop words (small words that usually do not provide a great deal of context) and \"stem\" terms when possible to find more possible matches (this is particularly helpful with plural forms of words). If you click the question mark next to the *Analyze Fieldname/Field Type* pull-down menu, the <<schema-browser-screen.adoc#schema-browser-screen,Schema Browser window>> will open, showing you the settings for the field specified.\n+\n+The section <<understanding-analyzers-tokenizers-and-filters.adoc#understanding-analyzers-tokenizers-and-filters,Understanding Analyzers, Tokenizers, and Filters>> describes in detail what each option is and how it may transform your data and the section <<running-your-analyzer.adoc#running-your-analyzer,Running Your Analyzer>> has specific examples for using the Analysis screen.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/analysis-screen.adoc",
                "sha": "29102063229d1e4dad921f79e220e40332ae1700",
                "status": "added"
            },
            {
                "additions": 103,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/analyzers.adoc",
                "changes": 103,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/analyzers.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/analyzers.adoc",
                "patch": "@@ -0,0 +1,103 @@\n+= Analyzers\n+:page-shortname: analyzers\n+:page-permalink: analyzers.html\n+\n+An analyzer examines the text of fields and generates a token stream.\n+\n+Analyzers are specified as a child of the `<fieldType>` element in the `schema.xml` configuration file (in the same `conf/` directory as `solrconfig.xml`).\n+\n+In normal usage, only fields of type `solr.TextField` will specify an analyzer. The simplest way to configure an analyzer is with a single `<analyzer>` element whose class attribute is a fully qualified Java class name. The named class must derive from `org.apache.lucene.analysis.Analyzer`. For example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"nametext\" class=\"solr.TextField\">\n+  <analyzer class=\"org.apache.lucene.analysis.core.WhitespaceAnalyzer\"/>\n+</fieldType>\n+----\n+\n+In this case a single class, `WhitespaceAnalyzer`, is responsible for analyzing the content of the named text field and emitting the corresponding tokens. For simple cases, such as plain English prose, a single analyzer class like this may be sufficient. But it's often necessary to do more complex analysis of the field content.\n+\n+Even the most complex analysis requirements can usually be decomposed into a series of discrete, relatively simple processing steps. As you will soon discover, the Solr distribution comes with a large selection of tokenizers and filters that covers most scenarios you are likely to encounter. Setting up an analyzer chain is very straightforward; you specify a simple `<analyzer>` element (no class attribute) with child elements that name factory classes for the tokenizer and filters to use, in the order you want them to run.\n+\n+For example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"nametext\" class=\"solr.TextField\">\n+  <analyzer>\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.StandardFilterFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+    <filter class=\"solr.StopFilterFactory\"/>\n+    <filter class=\"solr.EnglishPorterFilterFactory\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+Note that classes in the `org.apache.solr.analysis` package may be referred to here with the shorthand `solr.` prefix.\n+\n+In this case, no Analyzer class was specified on the `<analyzer>` element. Rather, a sequence of more specialized classes are wired together and collectively act as the Analyzer for the field. The text of the field is passed to the first item in the list (`solr.StandardTokenizerFactory`), and the tokens that emerge from the last one (`solr.EnglishPorterFilterFactory`) are the terms that are used for indexing or querying any fields that use the \"nametext\" `fieldType`.\n+\n+.Field Values versus Indexed Terms\n+[IMPORTANT]\n+====\n+The output of an Analyzer affects the _terms_ indexed in a given field (and the terms used when parsing queries against those fields) but it has no impact on the _stored_ value for the fields. For example: an analyzer might split \"Brown Cow\" into two indexed terms \"brown\" and \"cow\", but the stored value will still be a single String: \"Brown Cow\"\n+====\n+\n+[[Analyzers-AnalysisPhases]]\n+== Analysis Phases\n+\n+Analysis takes place in two contexts. At index time, when a field is being created, the token stream that results from analysis is added to an index and defines the set of terms (including positions, sizes, and so on) for the field. At query time, the values being searched for are analyzed and the terms that result are matched against those that are stored in the field's index.\n+\n+In many cases, the same analysis should be applied to both phases. This is desirable when you want to query for exact string matches, possibly with case-insensitivity, for example. In other cases, you may want to apply slightly different analysis steps during indexing than those used at query time.\n+\n+If you provide a simple `<analyzer>` definition for a field type, as in the examples above, then it will be used for both indexing and queries. If you want distinct analyzers for each phase, you may include two `<analyzer>` definitions distinguished with a type attribute. For example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"nametext\" class=\"solr.TextField\">\n+  <analyzer type=\"index\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+    <filter class=\"solr.KeepWordFilterFactory\" words=\"keepwords.txt\"/>\n+    <filter class=\"solr.SynonymFilterFactory\" synonyms=\"syns.txt\"/>\n+  </analyzer>\n+  <analyzer type=\"query\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+In this theoretical example, at index time the text is tokenized, the tokens are set to lowercase, any that are not listed in `keepwords.txt` are discarded and those that remain are mapped to alternate values as defined by the synonym rules in the file `syns.txt`. This essentially builds an index from a restricted set of possible values and then normalizes them to values that may not even occur in the original text.\n+\n+At query time, the only normalization that happens is to convert the query terms to lowercase. The filtering and mapping steps that occur at index time are not applied to the query terms. Queries must then, in this example, be very precise, using only the normalized terms that were stored at index time.\n+\n+[[Analyzers-AnalysisforMulti-TermExpansion]]\n+=== Analysis for Multi-Term Expansion\n+\n+In some types of queries (ie: Prefix, Wildcard, Regex, etc...) the input provided by the user is not natural language intended for Analysis. Things like Synonyms or Stop word filtering do not work in a logical way in these types of Queries.\n+\n+The analysis factories that _can_ work in these types of queries (such as Lowercasing, or Normalizing Factories) are known as {lucene-javadocs}/analyzers-common/org/apache/lucene/analysis/util/MultiTermAwareComponent.html[`MultiTermAwareComponents`]. When Solr needs to perform analysis for a query that results in Multi-Term expansion, only the `MultiTermAwareComponents` used in the `query` analyzer are used, Factory that is not Multi-Term aware will be skipped.\n+\n+For most use cases, this provides the best possible behavior, but if you wish for absolute control over the analysis performed on these types of queries, you may explicitly define a `multiterm` analyzer to use, such as in the following example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"nametext\" class=\"solr.TextField\">\n+  <analyzer type=\"index\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+    <filter class=\"solr.KeepWordFilterFactory\" words=\"keepwords.txt\"/>\n+    <filter class=\"solr.SynonymFilterFactory\" synonyms=\"syns.txt\"/>\n+  </analyzer>\n+  <analyzer type=\"query\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  </analyzer>\n+  <!-- No analysis at all when doing queries that involved Multi-Term expansion -->\n+  <analyzer type=\"multiterm\">\n+    <tokenizer class=\"solr.KeywordTokenizerFactory\" />\n+  </analyzer>\n+</fieldType>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/analyzers.adoc",
                "sha": "675373798007a6120ad68b9ff6663bfe0f873be3",
                "status": "added"
            },
            {
                "additions": 170,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/authentication-and-authorization-plugins.adoc",
                "changes": 170,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/authentication-and-authorization-plugins.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/authentication-and-authorization-plugins.adoc",
                "patch": "@@ -0,0 +1,170 @@\n+= Authentication and Authorization Plugins\n+:page-shortname: authentication-and-authorization-plugins\n+:page-permalink: authentication-and-authorization-plugins.html\n+:page-children: basic-authentication-plugin, hadoop-authentication-plugin, kerberos-authentication-plugin, rule-based-authorization-plugin\n+\n+Solr has security frameworks for supporting authentication and authorization of users. This allows for verifying a user's identity and for restricting access to resources in a Solr cluster.\n+\n+Solr includes some plugins out of the box, and additional plugins can be developed using the authentication and authorization frameworks described below.\n+\n+All authentication and authorization plugins can work with Solr whether they are running in SolrCloud mode or standalone mode. All authentication and authorization configuration, including users and permission rules, are stored in a file named `security.json`. When using Solr in standalone mode, this file must be in the `$SOLR_HOME` directory (usually `server/solr`). When using SolrCloud, this file must be located in ZooKeeper.\n+\n+The following section describes how to enable plugins with `security.json` and place them in the proper locations for your mode of operation.\n+\n+[[AuthenticationandAuthorizationPlugins-EnablePluginswithsecurity.json]]\n+== Enable Plugins with security.json\n+\n+All of the information required to initialize either type of security plugin is stored in a `security.json` file. This file contains 2 sections, one each for authentication and authorization.\n+\n+.Sample security.json\n+[source,json]\n+----\n+{\n+  \"authentication\" : {\n+    \"class\": \"class.that.implements.authentication\"\n+  },\n+  \"authorization\": {\n+    \"class\": \"class.that.implements.authorization\"\n+  }\n+}\n+----\n+\n+The `/security.json` file needs to be in the proper location before a Solr instance comes up so Solr starts with the security plugin enabled. See the section <<AuthenticationandAuthorizationPlugins-Usingsecurity.jsonwithSolr,Using security.json with Solr>> below for information on how to do this.\n+\n+Depending on the plugin(s) in use, other information will be stored in `security.json` such as user information or rules to create roles and permissions. This information is added through the APIs for each plugin provided by Solr, or, in the case of a custom plugin, the approach designed by you.\n+\n+Here is a more detailed `security.json` example. In this, the Basic authentication and rule-based authorization plugins are enabled, and some data has been added:\n+\n+[source,json]\n+----\n+{\n+\"authentication\":{\n+   \"class\":\"solr.BasicAuthPlugin\",\n+   \"credentials\":{\"solr\":\"IV0EHq1OnNrj6gvRCwvFwTrZ1+z1oBbnQdiVC3otuq0= Ndd7LKvVBAaZIF0QAVi1ekCfAJXr1GGfLtRUXhgrF8c=\"}\n+},\n+\"authorization\":{\n+   \"class\":\"solr.RuleBasedAuthorizationPlugin\",\n+   \"permissions\":[{\"name\":\"security-edit\",\n+      \"role\":\"admin\"}],\n+   \"user-role\":{\"solr\":\"admin\"}\n+}}\n+----\n+\n+[[AuthenticationandAuthorizationPlugins-Usingsecurity.jsonwithSolr]]\n+== Using security.json with Solr\n+\n+[[AuthenticationandAuthorizationPlugins-InSolrCloudmode]]\n+=== In SolrCloud Mode\n+\n+While configuring Solr to use an authentication or authorization plugin, you will need to upload a `security.json` file to ZooKeeper. The following command writes the file as it uploads it - you could also upload a file that you have already created locally.\n+\n+[source,bash]\n+----\n+>server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd put /security.json\n+  '{\"authentication\": {\"class\": \"org.apache.solr.security.KerberosPlugin\"}}'\n+----\n+\n+Note that this example defines the `KerberosPlugin` for authentication. You will want to modify this section as appropriate for the plugin you are using.\n+\n+This example also defines `security.json` on the command line, but you can also define a file locally and upload it to ZooKeeper.\n+\n+[WARNING]\n+====\n+Depending on the authentication and authorization plugin that you use, you may have user information stored in `security.json`. If so, we highly recommend that you implement access control in your ZooKeeper nodes. Information about how to enable this is available in the section <<zookeeper-access-control.adoc#zookeeper-access-control,ZooKeeper Access Control>>.\n+====\n+\n+Once `security.json` has been uploaded to ZooKeeper, you should use the appropriate APIs for the plugins you're using to update it. You can edit it manually, but you must take care to remove any version data so it will be properly updated across all ZooKeeper nodes. The version data is found at the end of the `security.json` file, and will appear as the letter \"v\" followed by a number, such as `{\"v\":138}`.\n+\n+[[AuthenticationandAuthorizationPlugins-InStandaloneMode]]\n+=== In Standalone Mode\n+\n+When running Solr in standalone mode, you need to create the `security.json` file and put it in the `$SOLR_HOME` directory for your installation (this is the same place you have located `solr.xml` and is usually `server/solr`).\n+\n+If you are using <<legacy-scaling-and-distribution.adoc#legacy-scaling-and-distribution,Legacy Scaling and Distribution>>, you will need to place `security.json` on each node of the cluster.\n+\n+You can use the authentication and authorization APIs, but if you are using the legacy scaling model, you will need to make the same API requests on each node separately. You can also edit `security.json` by hand if you prefer.\n+\n+[[AuthenticationandAuthorizationPlugins-Authentication]]\n+== Authentication\n+\n+Authentication plugins help in securing the endpoints of Solr by authenticating incoming requests. A custom plugin can be implemented by extending the AuthenticationPlugin class.\n+\n+An authentication plugin consists of two parts:\n+\n+. Server-side component, which intercepts and authenticates incoming requests to Solr using a mechanism defined in the plugin, such as Kerberos, Basic Auth or others.\n+. Client-side component, i.e., an extension of `HttpClientConfigurer`, which enables a SolrJ client to make requests to a secure Solr instance using the authentication mechanism which the server understands.\n+\n+[[AuthenticationandAuthorizationPlugins-EnablingaPlugin]]\n+=== Enabling a Plugin\n+\n+* Specify the authentication plugin in `/security.json` as in this example:\n++\n+[source,json]\n+----\n+{\n+  \"authentication\": {\n+    \"class\": \"class.that.implements.authentication\",\n+    \"other_data\" : \"...\"}\n+}\n+----\n+* All of the content in the authentication block of `security.json` would be passed on as a map to the plugin during initialization.\n+* An authentication plugin can also be used with a standalone Solr instance by passing in `-DauthenticationPlugin=<plugin class name>` during startup.\n+\n+[[AuthenticationandAuthorizationPlugins-AvailableAuthenticationPlugins]]\n+=== Available Authentication Plugins\n+\n+Solr has the following implementations of authentication plugins:\n+\n+* <<kerberos-authentication-plugin.adoc#kerberos-authentication-plugin,Kerberos Authentication Plugin>>\n+* <<basic-authentication-plugin.adoc#basic-authentication-plugin,Basic Authentication Plugin>>\n+* <<hadoop-authentication-plugin.adoc#hadoop-authentication-plugin,Hadoop Authentication Plugin>>\n+\n+[[AuthenticationandAuthorizationPlugins-Authorization]]\n+== Authorization\n+\n+An authorization plugin can be written for Solr by extending the {solr-javadocs}/solr-core/org/apache/solr/security/AuthorizationPlugin.html[AuthorizationPlugin] interface.\n+\n+[[AuthenticationandAuthorizationPlugins-LoadingaCustomPlugin]]\n+=== Loading a Custom Plugin\n+\n+* Make sure that the plugin implementation is in the classpath.\n+* The plugin can then be initialized by specifying the same in `security.json` in the following manner:\n+\n+[source,json]\n+----\n+{\n+  \"authorization\": {\n+    \"class\": \"org.apache.solr.security.MockAuthorizationPlugin\",\n+    \"other_data\" : \"...\"}\n+}\n+----\n+\n+All of the content in the `authorization` block of `security.json` would be passed on as a map to the plugin during initialization.\n+\n+[IMPORTANT]\n+====\n+The authorization plugin is only supported in SolrCloud mode. Also, reloading the plugin isn't yet supported and requires a restart of the Solr installation (meaning, the JVM should be restarted, not simply a core reload).\n+====\n+\n+[[AuthenticationandAuthorizationPlugins-AvailableAuthorizationPlugins]]\n+=== Available Authorization Plugins\n+\n+Solr has one implementation of an authorization plugin:\n+\n+* <<rule-based-authorization-plugin.adoc#rule-based-authorization-plugin,Rule-Based Authorization Plugin>>\n+\n+[[AuthenticationandAuthorizationPlugins-PKISecuringInter-NodeRequests]]\n+\n+[[AuthenticationandAuthorizationPlugins-PKI]]\n+== Securing Inter-Node Requests\n+\n+There are a lot of requests that originate from the Solr nodes itself. For example, requests from overseer to nodes, recovery threads, etc. Each Authentication plugin declares whether it is capable of securing inter-node requests or not. If not, Solr will fall back to using a special internode authentication mechanism where each Solr node is a super user and is fully trusted by other Solr nodes, described below.\n+\n+[[AuthenticationandAuthorizationPlugins-PKIAuthenticationPlugin]]\n+=== PKIAuthenticationPlugin\n+\n+The PKIAuthenticationPlugin is used when there is any request going on between two Solr nodes, and the configured Authentication plugin does not wish to handle inter-node security.\n+\n+For each outgoing request `PKIAuthenticationPlugin` adds a special header `'SolrAuth'` which carries the timestamp and principal encrypted using the private key of that node. The public key is exposed through an API so that any node can read it whenever it needs it. Any node who gets the request with that header, would get the public key from the sender and decrypt the information. If it is able to decrypt the data, the request trusted. It is invalid if the timestamp is more than 5 secs old. This assumes that the clocks of different nodes in the cluster are synchronized.\n+\n+The timeout is configurable through a system property called `pkiauth.ttl`. For example, if you wish to bump up the time-to-live to 10 seconds (10000 milliseconds), start each node with a property `'-Dpkiauth.ttl=10000'`.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/authentication-and-authorization-plugins.adoc",
                "sha": "2db6fee11edc0130e1698cf44094583d3f3541d7",
                "status": "added"
            },
            {
                "additions": 140,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/basic-authentication-plugin.adoc",
                "changes": 140,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/basic-authentication-plugin.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/basic-authentication-plugin.adoc",
                "patch": "@@ -0,0 +1,140 @@\n+= Basic Authentication Plugin\n+:page-shortname: basic-authentication-plugin\n+:page-permalink: basic-authentication-plugin.html\n+\n+Solr can support Basic authentication for users with the use of the BasicAuthPlugin.\n+\n+An authorization plugin is also available to configure Solr with permissions to perform various activities in the system. The authorization plugin is described in the section <<rule-based-authorization-plugin.adoc#rule-based-authorization-plugin,Rule-Based Authorization Plugin>>.\n+\n+[[BasicAuthenticationPlugin-EnableBasicAuthentication]]\n+== Enable Basic Authentication\n+\n+To use Basic authentication, you must first create a `security.json` file. This file and where to put it is described in detail in the section <<authentication-and-authorization-plugins.adoc#AuthenticationandAuthorizationPlugins-EnablePluginswithsecurity.json,Enable Plugins with security.json>>.\n+\n+For Basic authentication, the `security.json` file must have an `authentication` part which defines the class being used for authentication. Usernames and passwords (as a sha256(password+salt) hash) could be added when the file is created, or can be added later with the Basic authentication API, described below.\n+\n+The `authorization` part is not related to Basic authentication, but is a separate authorization plugin designed to support fine-grained user access control. For more information, see the section <<rule-based-authorization-plugin.adoc#rule-based-authorization-plugin,Rule-Based Authorization Plugin>>.\n+\n+An example `security.json` showing both sections is shown below to show how these plugins can work together:\n+\n+[source,json]\n+----\n+{\n+\"authentication\":{\n+   \"blockUnknown\": true,\n+   \"class\":\"solr.BasicAuthPlugin\",\n+   \"credentials\":{\"solr\":\"IV0EHq1OnNrj6gvRCwvFwTrZ1+z1oBbnQdiVC3otuq0= Ndd7LKvVBAaZIF0QAVi1ekCfAJXr1GGfLtRUXhgrF8c=\"}\n+},\n+\"authorization\":{\n+   \"class\":\"solr.RuleBasedAuthorizationPlugin\",\n+   \"permissions\":[{\"name\":\"security-edit\",\n+      \"role\":\"admin\"}],\n+   \"user-role\":{\"solr\":\"admin\"}\n+}}\n+----\n+\n+There are several things defined in this file:\n+\n+* Basic authentication and rule-based authorization plugins are enabled.\n+* A user called 'solr', with a password `'SolrRocks'` has been defined.\n+* The parameter `\"blockUnknown\": true` means that unauthenticated requests are not allowed to pass through.\n+* The 'admin' role has been defined, and it has permission to edit security settings.\n+* The 'solr' user has been defined to the 'admin' role.\n+\n+Save your settings to a file called `security.json` locally. If you are using Solr in standalone mode, you should put this file in `$SOLR_HOME`.\n+\n+If `blockUnknown` does not appear in the `security.json` file, it will default to `false`. This has the effect of not requiring authentication at all. In some cases, you may want this; for example, if you want to have `security.json` in place but aren't ready to enable authentication. However, you will want to ensure that this parameter is set to `true` in order for authentication to be truly enabled in your system.\n+\n+If you are using SolrCloud, you must upload `security.json` to ZooKeeper. You can use this example command, ensuring that the ZooKeeper port is correct:\n+\n+[source,bash]\n+----\n+bin/solr zk cp file:path_to_local_security.json zk:/security.json -z localhost:9983\n+----\n+\n+[[BasicAuthenticationPlugin-Caveats]]\n+=== Caveats\n+\n+There are a few things to keep in mind when using the Basic authentication plugin.\n+\n+* Credentials are sent in plain text by default. It's recommended to use SSL for communication when Basic authentication is enabled, as described in the section <<enabling-ssl.adoc#enabling-ssl,Enabling SSL>>.\n+* A user who has access to write permissions to `security.json` will be able to modify all the permissions and how users have been assigned permissions. Special care should be taken to only grant access to editing security to appropriate users.\n+* Your network should, of course, be secure. Even with Basic authentication enabled, you should not unnecessarily expose Solr to the outside world.\n+\n+[[BasicAuthenticationPlugin-EditingAuthenticationPluginConfiguration]]\n+== Editing Authentication Plugin Configuration\n+\n+An Authentication API allows modifying user IDs and passwords. The API provides an endpoint with specific commands to set user details or delete a user.\n+\n+[[BasicAuthenticationPlugin-APIEntryPoint]]\n+=== API Entry Point\n+\n+`admin/authentication`\n+\n+This endpoint is not collection-specific, so users are created for the entire Solr cluster. If users need to be restricted to a specific collection, that can be done with the authorization rules.\n+\n+[[BasicAuthenticationPlugin-AddaUserorEditaPassword]]\n+=== Add a User or Edit a Password\n+\n+The `set-user` command allows you to add users and change their passwords. For example, the following defines two users and their passwords:\n+\n+[source,bash]\n+----\n+curl --user solr:SolrRocks http://localhost:8983/solr/admin/authentication -H 'Content-type:application/json' -d '{\n+  \"set-user\": {\"tom\" : \"TomIsCool\" ,\n+               \"harry\":\"HarrysSecret\"}}'\n+----\n+\n+[[BasicAuthenticationPlugin-DeleteaUser]]\n+=== Delete a User\n+\n+The `delete-user` command allows you to remove a user. The user password does not need to be sent to remove a user. In the following example, we've asked that user IDs 'tom' and 'harry' be removed from the system.\n+\n+[source,bash]\n+----\n+curl --user solr:SolrRocks http://localhost:8983/solr/admin/authentication -H 'Content-type:application/json' -d  '{\n+ \"delete-user\": [\"tom\",\"harry\"]}'\n+----\n+\n+[[BasicAuthenticationPlugin-Setaproperty]]\n+=== Set a property\n+\n+Set arbitrary properties for authentication plugin. The only supported property is `'blockUnknown'`\n+\n+[source,bash]\n+----\n+curl --user solr:SolrRocks http://localhost:8983/solr/admin/authentication -H 'Content-type:application/json' -d  '{\n+ \"set-property\": {\"blockUnknown\":false}}'\n+----\n+\n+[[BasicAuthenticationPlugin-UsingBasicAuthwithSolrJ]]\n+=== Using BasicAuth with SolrJ\n+\n+In SolrJ, the basic authentication credentials need to be set for each request as in this example:\n+\n+[source,java]\n+----\n+SolrRequest req ;//create a new request object\n+req.setBasicAuthCredentials(userName, password);\n+solrClient.request(req);\n+----\n+\n+Query example:\n+\n+[source,java]\n+----\n+QueryRequest req = new QueryRequest(new SolrQuery(\"*:*\"));\n+req.setBasicAuthCredentials(userName, password);\n+QueryResponse rsp = req.process(solrClient);\n+----\n+\n+[[BasicAuthenticationPlugin-UsingCommandLinescriptswithBasicAuth]]\n+=== Using Command Line scripts with BasicAuth\n+\n+Add the following line to the `solr.in.sh` or `solr.in.cmd` file. This example tells the `bin/solr` command line to to use \"basic\" as the type of authentication, and to pass credentials with the user-name \"solr\" and password \"SolrRocks\":\n+\n+[source,bash]\n+----\n+SOLR_AUTH_TYPE=\"basic\"\n+SOLR_AUTHENTICATION_OPTS=\"-Dbasicauth=solr:SolrRocks\"\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/basic-authentication-plugin.adoc",
                "sha": "592da1bef1fc42167e988696c5fbb817d22cadd1",
                "status": "added"
            },
            {
                "additions": 135,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/blob-store-api.adoc",
                "changes": 135,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/blob-store-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/blob-store-api.adoc",
                "patch": "@@ -0,0 +1,135 @@\n+= Blob Store API\n+:page-shortname: blob-store-api\n+:page-permalink: blob-store-api.html\n+\n+The Blob Store REST API provides REST methods to store, retrieve or list files in a Lucene index.\n+\n+It can be used to upload a jar file which contains standard solr components such as RequestHandlers, SearchComponents, or other custom code you have written for Solr. Schema components _do not_ yet support the Blob Store.\n+\n+When using the blob store, note that the API does not delete or overwrite a previous object if a new one is uploaded with the same name. It always adds a new version of the blob to the index. Deletes can be performed with standard REST delete commands.\n+\n+*The blob store is only available when running in SolrCloud mode.* Solr in standalone mode does not support use of a blob store.\n+\n+The blob store API is implemented as a requestHandler. A special collection named \".system\" is used to store the blobs. This collection can be created in advance, but if it does not exist it will be created automatically.\n+\n+[[BlobStoreAPI-Aboutthe.systemCollection]]\n+== About the .system Collection\n+\n+Before uploading blobs to the blob store, a special collection must be created and it must be named `.system`. Solr will automatically create this collection if it does not already exist, but you can also create it manually if you choose.\n+\n+The BlobHandler is automatically registered in the .system collection. The `solrconfig.xml`, Schema, and other configuration files for the collection are automatically provided by the system and don't need to be defined specifically.\n+\n+If you do not use the `-shards` or `-replicationFactor` options, then defaults of numShards=1 and replicationFactor=3 (or maximum nodes in the cluster) will be used.\n+\n+You can create the `.system` collection with the <<collections-api.adoc#collections-api,Collections API>>, as in this example:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/admin/collections?action=CREATE&name=.system&replicationFactor=2\n+----\n+\n+IMPORTANT: The `bin/solr` script cannot be used to create the `.system` collection.\n+\n+[[BlobStoreAPI-UploadFilestoBlobStore]]\n+== Upload Files to Blob Store\n+\n+After the `.system` collection has been created, files can be uploaded to the blob store with a request similar to the following:\n+\n+[source,bash]\n+----\n+curl -X POST -H 'Content-Type: application/octet-stream' --data-binary @{filename} http://localhost:8983/solr/.system/blob/{blobname}\n+----\n+\n+For example, to upload a file named \"test1.jar\" as a blob named \"test\", you would make a POST request like:\n+\n+[source,bash]\n+----\n+curl -X POST -H 'Content-Type: application/octet-stream' --data-binary @test1.jar http://localhost:8983/solr/.system/blob/test\n+----\n+\n+A GET request will return the list of blobs and other details:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/.system/blob?omitHeader=true\n+----\n+\n+Output:\n+\n+[source,json]\n+----\n+{\n+  \"response\":{\"numFound\":1,\"start\":0,\"docs\":[\n+      {\n+        \"id\":\"test/1\",\n+        \"md5\":\"20ff915fa3f5a5d66216081ae705c41b\",\n+        \"blobName\":\"test\",\n+        \"version\":1,\n+        \"timestamp\":\"2015-02-04T16:45:48.374Z\",\n+        \"size\":13108}]\n+  }\n+}\n+----\n+\n+Details on individual blobs can be accessed with a request similar to:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/.system/blob/{blobname}\n+----\n+\n+For example, this request will return only the blob named 'test':\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/.system/blob/test?omitHeader=true\n+----\n+\n+Output:\n+\n+[source,json]\n+----\n+{\n+  \"response\":{\"numFound\":1,\"start\":0,\"docs\":[\n+      {\n+        \"id\":\"test/1\",\n+        \"md5\":\"20ff915fa3f5a5d66216081ae705c41b\",\n+        \"blobName\":\"test\",\n+        \"version\":1,\n+        \"timestamp\":\"2015-02-04T16:45:48.374Z\",\n+        \"size\":13108}]\n+  }\n+}\n+----\n+\n+The filestream response writer can return a particular version of a blob for download, as in:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/.system/blob/{blobname}/{version}?wt=filestream > {outputfilename}\n+----\n+\n+For the latest version of a blob, the \\{version} can be omitted,\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/.system/blob/{blobname}?wt=filestream > {outputfilename}\n+----\n+\n+[[BlobStoreAPI-UseaBlobinaHandlerorComponent]]\n+== Use a Blob in a Handler or Component\n+\n+To use the blob as the class for a request handler or search component, you create a request handler in `solrconfig.xml` as usual. You will need to define the following parameters:\n+\n+`class`:: the fully qualified class name. For example, if you created a new request handler class called CRUDHandler, you would enter `org.apache.solr.core.CRUDHandler`.\n+`runtimeLib`:: Set to true to require that this component should be loaded from the classloader that loads the runtime jars.\n+\n+For example, to use a blob named test, you would configure `solrconfig.xml` like this:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/myhandler\" class=\"org.apache.solr.core.myHandler\" runtimeLib=\"true\" version=\"1\">\n+</requestHandler>\n+----\n+\n+If there are parameters available in the custom handler, you can define them in the same way as any other request handler definition.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/blob-store-api.adoc",
                "sha": "8e23ed9d7bea65828620490c729d1527cae33e37",
                "status": "added"
            },
            {
                "additions": 99,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/blockjoin-faceting.adoc",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/blockjoin-faceting.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/blockjoin-faceting.adoc",
                "patch": "@@ -0,0 +1,99 @@\n+= BlockJoin Faceting\n+:page-shortname: blockjoin-faceting\n+:page-permalink: blockjoin-faceting.html\n+\n+BlockJoin facets allow you to aggregate children facet counts by their parents.\n+\n+It is a common requirement that if a parent document has several children documents, all of them need to increment facet value count only once. This functionality is provided by `BlockJoinDocSetFacetComponent`, and `BlockJoinFacetComponent` just an alias for compatibility.\n+\n+CAUTION: This component is considered experimental, and must be explicitly enabled for a request handler in `solrconfig.xml`, in the same way as any other <<requesthandlers-and-searchcomponents-in-solrconfig.adoc#requesthandlers-and-searchcomponents-in-solrconfig,search component>>.\n+\n+This example shows how you could add this search components to `solrconfig.xml` and define it in request handler:\n+\n+[source,xml]\n+----\n+  <searchComponent name=\"bjqFacetComponent\" class=\"org.apache.solr.search.join.BlockJoinDocSetFacetComponent\"/>\n+\n+   <requestHandler name=\"/bjqfacet\" class=\"org.apache.solr.handler.component.SearchHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"shards.qt\">/bjqfacet</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>bjqFacetComponent</str>\n+    </arr>\n+  </requestHandler>\n+----\n+\n+This component can be added into any search request handler. This component work with distributed search in SolrCloud mode.\n+\n+Documents should be added in children-parent blocks as described in <<uploading-data-with-index-handlers.adoc#UploadingDatawithIndexHandlers-NestedChildDocuments,indexing nested child documents>>. Examples:\n+\n+.Sample document\n+[source,xml]\n+----\n+<add>\n+  <doc>\n+    <field name=\"id\">1</field>\n+    <field name=\"type_s\">parent</field>\n+    <doc>\n+      <field name=\"id\">11</field>\n+      <field name=\"COLOR_s\">Red</field>\n+      <field name=\"SIZE_s\">XL</field>\n+      <field name=\"PRICE_i\">6</field>\n+    </doc>\n+    <doc>\n+      <field name=\"id\">12</field>\n+      <field name=\"COLOR_s\">Red</field>\n+      <field name=\"SIZE_s\">XL</field>\n+      <field name=\"PRICE_i\">7</field>\n+    </doc>\n+    <doc>\n+      <field name=\"id\">13</field>\n+      <field name=\"COLOR_s\">Blue</field>\n+      <field name=\"SIZE_s\">L</field>\n+      <field name=\"PRICE_i\">5</field>\n+    </doc>\n+  </doc>\n+  <doc>\n+    <field name=\"id\">2</field>\n+    <field name=\"type_s\">parent</field>\n+    <doc>\n+      <field name=\"id\">21</field>\n+      <field name=\"COLOR_s\">Blue</field>\n+      <field name=\"SIZE_s\">XL</field>\n+      <field name=\"PRICE_i\">6</field>\n+    </doc>\n+    <doc>\n+      <field name=\"id\">22</field>\n+      <field name=\"COLOR_s\">Blue</field>\n+      <field name=\"SIZE_s\">XL</field>\n+      <field name=\"PRICE_i\">7</field>\n+    </doc>\n+    <doc>\n+      <field name=\"id\">23</field>\n+      <field name=\"COLOR_s\">Red</field>\n+      <field name=\"SIZE_s\">L</field>\n+      <field name=\"PRICE_i\">5</field>\n+    </doc>\n+  </doc>\n+</add>\n+----\n+\n+Queries are constructed the same way as for a <<other-parsers.adoc#OtherParsers-BlockJoinQueryParsers,Parent Block Join query>>. For example:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/bjqfacet?q={!parent which=type_s:parent}SIZE_s:XL&child.facet.field=COLOR_s\n+----\n+\n+As a result we should have facets for Red(1) and Blue(1), because matches on children `id=11` and `id=12` are aggregated into single hit into parent with `id=1`. The key components of the request are:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|URL Part | Meaning\n+|`/bjqfacet` |The name of the request handler that has been defined with one of block join facet components enabled.\n+|`q={!parent ...}..` |The mandatory parent query as a main query. The parent query could also be a subordinate clause in a more complex query.\n+|`child.facet.field=...` |The child document field, which might be repeated many times with several fields, as necessary.\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/blockjoin-faceting.adoc",
                "sha": "05194dec4d231903770b56fae8e00760414ebfd8",
                "status": "added"
            },
            {
                "additions": 159,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/charfilterfactories.adoc",
                "changes": 159,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/charfilterfactories.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/charfilterfactories.adoc",
                "patch": "@@ -0,0 +1,159 @@\n+= CharFilterFactories\n+:page-shortname: charfilterfactories\n+:page-permalink: charfilterfactories.html\n+\n+CharFilter is a component that pre-processes input characters.\n+\n+CharFilters can be chained like Token Filters and placed in front of a Tokenizer. CharFilters can add, change, or remove characters while preserving the original character offsets to support features like highlighting.\n+\n+[[CharFilterFactories-solr.MappingCharFilterFactory]]\n+== solr.MappingCharFilterFactory\n+\n+This filter creates `org.apache.lucene.analysis.MappingCharFilter`, which can be used for changing one string to another (for example, for normalizing `\u00e9` to `e`.).\n+\n+This filter requires specifying a `mapping` argument, which is the path and name of a file containing the mappings to perform.\n+\n+Example:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <charFilter class=\"solr.MappingCharFilterFactory\" mapping=\"mapping-FoldToASCII.txt\"/>\n+  <tokenizer ...>\n+  [...]\n+</analyzer>\n+----\n+\n+Mapping file syntax:\n+\n+* Comment lines beginning with a hash mark (`#`), as well as blank lines, are ignored.\n+* Each non-comment, non-blank line consists of a mapping of the form: `\"source\" => \"target\"`\n+** Double-quoted source string, optional whitespace, an arrow (`=>`), optional whitespace, double-quoted target string.\n+* Trailing comments on mapping lines are not allowed.\n+* The source string must contain at least one character, but the target string may be empty.\n+* The following character escape sequences are recognized within source and target strings:\n++\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n++\n+[cols=\"20,30,20,30\",options=\"header\"]\n+|===\n+|Escape Sequence |Resulting Character (http://www.ecma-international.org/publications/standards/Ecma-048.htm[ECMA-48] alias) |Unicode Character |Example Mapping Line\n+|`\\\\` |`\\` |U+005C |`\"\\\\\" => \"/\"`\n+|`\\\"` |`\"` |U+0022 |`\"\\\"and\\\"\" => \"'and'\"`\n+|`\\b` |backspace (BS) |U+0008 |`\"\\b\" => \" \"`\n+|`\\t` |tab (HT) |U+0009 |`\"\\t\" => \",\"`\n+|`\\n` |newline (LF) |U+000A |`\"\\n\" => \"<br>\"`\n+|`\\f` |form feed (FF) |U+000C |`\"\\f\" => \"\\n\"`\n+|`\\r` |carriage return (CR) |U+000D |`\"\\r\" => \"/carriage-return/\"`\n+|`\\uXXXX` |Unicode char referenced by the 4 hex digits |U+XXXX |`\"\\uFEFF\" => \"\"`\n+|===\n+** A backslash followed by any other character is interpreted as if the character were present without the backslash.\n+\n+[[CharFilterFactories-solr.HTMLStripCharFilterFactory]]\n+== solr.HTMLStripCharFilterFactory\n+\n+This filter creates `org.apache.solr.analysis.HTMLStripCharFilter`. This CharFilter strips HTML from the input stream and passes the result to another CharFilter or a Tokenizer.\n+\n+This filter:\n+\n+* Removes HTML/XML tags while preserving other content.\n+* Removes attributes within tags and supports optional attribute quoting.\n+* Removes XML processing instructions, such as: <?foo bar?>\n+* Removes XML comments.\n+* Removes XML elements starting with <!>.\n+* Removes contents of <script> and <style> elements.\n+* Handles XML comments inside these elements (normal comment processing will not always work).\n+* Replaces numeric character entities references like `&#65`; or `&#x7f`; with the corresponding character.\n+* The terminating ';' is optional if the entity reference at the end of the input; otherwise the terminating ';' is mandatory, to avoid false matches on something like \"Alpha&Omega Corp\".\n+* Replaces all named character entity references with the corresponding character.\n+* `&nbsp`; is replaced with a space instead of the 0xa0 character.\n+* Newlines are substituted for block-level elements.\n+* <CDATA> sections are recognized.\n+* Inline tags, such as `<b>`, `<i>`, or `<span>` will be removed.\n+* Uppercase character entities like `quot`, `gt`, `lt` and `amp` are recognized and handled as lowercase.\n+\n+TIP: The input need not be an HTML document. The filter removes only constructs that look like HTML. If the input doesn't include anything that looks like HTML, the filter won't remove any input.\n+\n+The table below presents examples of HTML stripping.\n+\n+[width=\"100%\",options=\"header\",]\n+|===\n+|Input |Output\n+|`my <a href=\"www.foo.bar\">link</a>` |my link\n+|`<br>hello<!--comment-->` |hello\n+|`hello<script><!-- f('<!--internal--></script>'); --></script>` |hello\n+|`if a<b then print a;` |if a<b then print a;\n+|`hello <td height=22 nowrap align=\"left\">` |hello\n+|`a<b &#65 Alpha&Omega \u03a9` |a<b A Alpha&Omega \u03a9\n+|===\n+\n+Example:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <charFilter class=\"solr.HTMLStripCharFilterFactory\"/>\n+  <tokenizer ...>\n+  [...]\n+</analyzer>\n+----\n+\n+[[CharFilterFactories-solr.ICUNormalizer2CharFilterFactory]]\n+== solr.ICUNormalizer2CharFilterFactory\n+\n+This filter performs pre-tokenization Unicode normalization using http://site.icu-project.org[ICU4J].\n+\n+Arguments:\n+\n+`name`:: A http://unicode.org/reports/tr15/[Unicode Normalization Form], one of `nfc`, `nfkc`, `nfkc_cf`. Default is `nfkc_cf`.\n+\n+`mode`:: Either `compose` or `decompose`. Default is `compose`. Use `decompose` with `name=\"nfc\"` or `name=\"nfkc\"` to get NFD or NFKD, respectively.\n+\n+`filter`:: A http://www.icu-project.org/apiref/icu4j/com/ibm/icu/text/UnicodeSet.html[UnicodeSet] pattern. Codepoints outside the set are always left unchanged. Default is `[]` (the null set, no filtering - all codepoints are subject to normalization).\n+\n+Example:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <charFilter class=\"solr.ICUNormalizer2CharFilterFactory\"/>\n+  <tokenizer ...>\n+  [...]\n+</analyzer>\n+----\n+\n+[[CharFilterFactories-solr.PatternReplaceCharFilterFactory]]\n+== solr.PatternReplaceCharFilterFactory\n+\n+This filter uses http://www.regular-expressions.info/reference.html[regular expressions] to replace or change character patterns.\n+\n+Arguments:\n+\n+`pattern`:: the regular expression pattern to apply to the incoming text.\n+\n+`replacement`:: the text to use to replace matching patterns.\n+\n+You can configure this filter in `schema.xml` like this:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <charFilter class=\"solr.PatternReplaceCharFilterFactory\"\n+             pattern=\"([nN][oO]\\.)\\s*(\\d+)\" replacement=\"$1$2\"/>\n+  <tokenizer ...>\n+  [...]\n+</analyzer>\n+----\n+\n+The table below presents examples of regex-based pattern replacement:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,20,10,20,30\",options=\"header\"]\n+|===\n+|Input |Pattern |Replacement |Output |Description\n+|see-ing looking |`(\\w+)(ing)` |`$1` |see-ing look |Removes \"ing\" from the end of word.\n+|see-ing looking |`(\\w+)ing` |`$1` |see-ing look |Same as above. 2nd parentheses can be omitted.\n+|No.1 NO. no. 543 |`[nN][oO]\\.\\s*(\\d+)` |`#$1` |#1 NO. #543 |Replace some string literals\n+|abc=1234=5678 |`(\\w+)=(\\d+)=(\\d+)` |`$3=$1=$2` |5678=abc=1234 |Change the order of the groups.\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/charfilterfactories.adoc",
                "sha": "20ff949169c1580cf7a91e2d910ab7342e7083cb",
                "status": "added"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/choosing-an-output-format.adoc",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/choosing-an-output-format.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/choosing-an-output-format.adoc",
                "patch": "@@ -0,0 +1,9 @@\n+= Choosing an Output Format\n+:page-shortname: choosing-an-output-format\n+:page-permalink: choosing-an-output-format.html\n+\n+Many programming environments are able to send HTTP requests and retrieve responses. Parsing the responses is a slightly more thorny problem. Fortunately, Solr makes it easy to choose an output format that will be easy to handle on the client side.\n+\n+Specify a response format using the `wt` parameter in a query. The available response formats are documented in <<response-writers.adoc#response-writers,Response Writers>>.\n+\n+Most client APIs hide this detail for you, so for many types of client applications, you won't ever have to specify a `wt` parameter. In JavaScript, however, the interface to Solr is a little closer to the metal, so you will need to add this parameter yourself.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/choosing-an-output-format.adoc",
                "sha": "133bed866b653592d28a6928fce702675c5e29bb",
                "status": "added"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/client-api-lineup.adoc",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/client-api-lineup.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/client-api-lineup.adoc",
                "patch": "@@ -0,0 +1,29 @@\n+= Client API Lineup\n+:page-shortname: client-api-lineup\n+:page-permalink: client-api-lineup.html\n+\n+The Solr Wiki contains a list of client APIs at http://wiki.apache.org/solr/IntegratingSolr.\n+\n+Here is the list of client APIs, current at this writing (November 2011):\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,20,60\",options=\"header\"]\n+|===\n+|Name |Environment |URL\n+|SolRuby |Ruby |https://github.com/rsolr/rsolr\n+|DelSolr |Ruby |https://github.com/avvo/delsolr\n+|acts_as_solr |Rails |http://acts-as-solr.rubyforge.org/, http://rubyforge.org/projects/background-solr/\n+|Flare |Rails |http://wiki.apache.org/solr/Flare\n+|SolPHP |PHP |http://wiki.apache.org/solr/SolPHP\n+|SolrJ |Java |http://wiki.apache.org/solr/SolJava\n+|Python API |Python |http://wiki.apache.org/solr/SolPython\n+|PySolr |Python |http://code.google.com/p/pysolr/\n+|SolPerl |Perl |http://wiki.apache.org/solr/SolPerl\n+|Solr.pm |Perl |http://search.cpan.org/~garafola/Solr-0.03/lib/Solr.pm\n+|SolrForrest |Forrest/Cocoon |http://wiki.apache.org/solr/SolrForrest\n+|SolrSharp |C# |http://www.codeplex.com/solrsharp\n+|SolColdfusion |ColdFusion |http://solcoldfusion.riaforge.org/\n+|SolrNet |.NET |https://github.com/mausch/SolrNet\n+|AJAX Solr |AJAX |http://github.com/evolvingweb/ajax-solr/wiki\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/client-api-lineup.adoc",
                "sha": "06014e006f7b88becddd2a95da3a429c195ab2f7",
                "status": "added"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/client-apis.adoc",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/client-apis.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/client-apis.adoc",
                "patch": "@@ -0,0 +1,22 @@\n+= Client APIs\n+:page-shortname: client-apis\n+:page-permalink: client-apis.html\n+:page-children: introduction-to-client-apis, choosing-an-output-format, client-api-lineup, using-javascript, using-python, using-solrj, using-solr-from-ruby\n+\n+This section discusses the available client APIs for Solr. It covers the following topics:\n+\n+<<introduction-to-client-apis.adoc#introduction-to-client-apis,Introduction to Client APIs>>: A conceptual overview of Solr client APIs.\n+\n+<<choosing-an-output-format.adoc#choosing-an-output-format,Choosing an Output Format>>: Information about choosing a response format in Solr.\n+\n+<<using-javascript.adoc#using-javascript,Using JavaScript>>: Explains why a client API is not needed for JavaScript responses.\n+\n+<<using-python.adoc#using-python,Using Python>>: Information about Python and JSON responses.\n+\n+<<client-api-lineup.adoc#client-api-lineup,Client API Lineup>>: A list of all Solr Client APIs, with links.\n+\n+<<using-solrj.adoc#using-solrj,Using SolrJ>>: Detailed information about SolrJ, an API for working with Java applications.\n+\n+<<using-solr-from-ruby.adoc#using-solr-from-ruby,Using Solr From Ruby>>: Detailed information about using Solr with Ruby applications.\n+\n+<<mbean-request-handler.adoc#mbean-request-handler,MBean Request Handler>>: Describes the MBean request handler for programmatic access to Solr server statistics and information.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/client-apis.adoc",
                "sha": "92725201b7feeb531cc32714246fae220f00b8b6",
                "status": "added"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/cloud-screens.adoc",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/cloud-screens.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/cloud-screens.adoc",
                "patch": "@@ -0,0 +1,29 @@\n+= Cloud Screens\n+:page-shortname: cloud-screens\n+:page-permalink: cloud-screens.html\n+\n+When running in <<solrcloud.adoc#solrcloud,SolrCloud>> mode, a \"Cloud\" option will appear in the Admin UI between <<logging.adoc#logging,Logging>> and <<collections-core-admin.adoc#collections-core-admin,Collections/Core Admin>>.\n+\n+This screen provides status information about each collection & node in your cluster, as well as access to the low level data being stored in <<using-zookeeper-to-manage-configuration-files.adoc#using-zookeeper-to-manage-configuration-files,Zookeeper>>.\n+\n+.Only Visible When using SolrCloud\n+[NOTE]\n+====\n+The \"Cloud\" menu option is only available on Solr instances running in <<getting-started-with-solrcloud.adoc#getting-started-with-solrcloud,SolrCloud mode>>. Single node or master/slave replication instances of Solr will not display this option.\n+====\n+\n+Click on the Cloud option in the left-hand navigation, and a small sub-menu appears with options called \"Tree\", \"Graph\", \"Graph (Radial)\" and \"Dump\". The default view (\"Graph\") shows a graph of each collection, the shards that make up those collections, and the addresses of each replica for each shard.\n+\n+This example shows the very simple two-node cluster created using the `bin/solr -e cloud -noprompt` example command. In addition to the 2 shard, 2 replica \"gettingstarted\" collection, there is an additional \"films\" collection consisting of a single shard/replica:\n+\n+image::images/cloud-screens/cloud-graph.png[image,width=512,height=250]\n+\n+The \"Graph (Radial)\" option provides a different visual view of each node. Using the same example cluster, the radial graph view looks like:\n+\n+image::images/cloud-screens/cloud-radial.png[image,width=478,height=250]\n+\n+The \"Tree\" option shows a directory structure of the data in ZooKeeper, including cluster wide information regarding the `live_nodes` and `overseer` status, as well as collection specific information such as the `state.json`, current shard leaders, and configuration files in use. In this example, we see the `state.json` file definition for the \"films\" collection:\n+\n+image::images/cloud-screens/cloud-tree.png[image,width=487,height=250]\n+\n+The final option is \"Dump\", which returns a JSON document containing all nodes, their contents and their children (recursively). This can be used to export a snapshot of all the data that Solr has kept inside ZooKeeper and can aid in debugging SolrCloud problems.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/cloud-screens.adoc",
                "sha": "927faeddb0255a5dd463e926d86cca9ced110d85",
                "status": "added"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/codec-factory.adoc",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/codec-factory.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/codec-factory.adoc",
                "patch": "@@ -0,0 +1,21 @@\n+= Codec Factory\n+:page-shortname: codec-factory\n+:page-permalink: codec-factory.html\n+\n+A `codecFactory` can be specified in `solrconfig.xml` to determine which Lucene {lucene-javadocs}/core/org/apache/lucene/codecs/Codec.html[`Codec`] is used when writing the index to disk.\n+\n+If not specified, Lucene's default codec is implicitly used, but a {solr-javadocs}/solr-core/org/apache/solr/core/SchemaCodecFactory.html[`solr.SchemaCodecFactory`] is also available which supports 2 key features:\n+\n+* Schema based per-fieldtype configuration for `docValuesFormat` and `postingsFormat` - see the <<field-type-definitions-and-properties.adoc#field-type-properties,Field Type Properties>> section for more details.\n+* A `compressionMode` option:\n+** `BEST_SPEED` (default) is optimized for search speed performance\n+** `BEST_COMPRESSION` is optimized for disk space usage\n+\n+Example:\n+\n+[source,xml]\n+----\n+<codecFactory class=\"solr.SchemaCodecFactory\">\n+  <str name=\"compressionMode\">BEST_COMPRESSION</str>\n+</codecFactory>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/codec-factory.adoc",
                "sha": "2e8078880c29ae8c8a9f4d481ba2fb3b452eb5bf",
                "status": "added"
            },
            {
                "additions": 133,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collapse-and-expand-results.adoc",
                "changes": 133,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/collapse-and-expand-results.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/collapse-and-expand-results.adoc",
                "patch": "@@ -0,0 +1,133 @@\n+= Collapse and Expand Results\n+:page-shortname: collapse-and-expand-results\n+:page-permalink: collapse-and-expand-results.html\n+\n+The Collapsing query parser and the Expand component combine to form an approach to grouping documents for field collapsing in search results.\n+\n+The Collapsing query parser groups documents (collapsing the result set) according to your parameters, while the Expand component provides access to documents in the collapsed group for use in results display or other processing by a client application. Collapse & Expand can together do what the older <<result-grouping.adoc#result-grouping,Result Grouping>> (`group=true`) does for _most_ use-cases but not all. Generally, you should prefer Collapse & Expand.\n+\n+[IMPORTANT]\n+====\n+In order to use these features with SolrCloud, the documents must be located on the same shard. To ensure document co-location, you can define the `router.name` parameter as `compositeId` when creating the collection. For more information on this option, see the section <<shards-and-indexing-data-in-solrcloud.adoc#ShardsandIndexingDatainSolrCloud-DocumentRouting,Document Routing>>.\n+====\n+\n+[[CollapseandExpandResults-CollapsingQueryParser]]\n+== Collapsing Query Parser\n+\n+The `CollapsingQParser` is really a _post filter_ that provides more performant field collapsing than Solr's standard approach when the number of distinct groups in the result set is high. This parser collapses the result set to a single document per group before it forwards the result set to the rest of the search components. So all downstream components (faceting, highlighting, etc...) will work with the collapsed result set.\n+\n+The CollapsingQParser accepts the following local parameters:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,60,20\",options=\"header\"]\n+|===\n+|Parameter |Description |Default\n+|field |The field that is being collapsed on. The field must be a single valued String, Int or Float |none\n+|min \\| max a|\n+Selects the group head document for each group based on which document has the min or max value of the specified numeric field or <<function-queries.adoc#function-queries,function query>>.\n+\n+At most only one of the min, max, or sort (see below) parameters may be specified.\n+\n+If none are specified, the group head document of each group will be selected based on the highest scoring document in that group. |none\n+|sort a|\n+Selects the group head document for each group based on which document comes first according to the specified <<common-query-parameters.adoc#CommonQueryParameters-ThesortParameter,sort string>>.\n+\n+At most only one of the min, max, (see above) or sort parameters may be specified.\n+\n+If none are specified, the group head document of each group will be selected based on the highest scoring document in that group. |none\n+|nullPolicy a|\n+There are three null policies:\n+\n+* *ignore*: removes documents with a null value in the collapse field. This is the default.\n+* *expand*: treats each document with a null value in the collapse field as a separate group.\n+* *collapse*: collapses all documents with a null value into a single group using either highest score, or minimum/maximum.\n+\n+ |ignore\n+|hint |Currently there is only one hint available: `top_fc`, which stands for top level FieldCache. The `top_fc` hint is only available when collapsing on String fields. `top_fc` usually provides the best query time speed but takes the longest to warm on startup or following a commit. `top_fc` will also result in having the collapsed field cached in memory twice if it's used for faceting or sorting. For very high cardinality (high distinct count) fields, `top_fc` may not fare so well. |none\n+|size |Sets the initial size of the collapse data structures when collapsing on a *numeric field only*. The data structures used for collapsing grow dynamically when collapsing on numeric fields. Setting the size above the number of results expected in the result set will eliminate the resizing cost. |100,000\n+|===\n+\n+*Sample Syntax:*\n+\n+Collapse on `group_field` selecting the document in each group with the highest scoring document:\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field}\n+----\n+\n+Collapse on `group_field` selecting the document in each group with the minimum value of `numeric_field`:\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field min=numeric_field}\n+----\n+\n+Collapse on `group_field` selecting the document in each group with the maximum value of `numeric_field`:\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field max=numeric_field}\n+----\n+\n+Collapse on `group_field` selecting the document in each group with the maximum value of a function. Note that the *cscore()* function can be used with the min/max options to use the score of the current document being collapsed.\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field max=sum(cscore(),numeric_field)}\n+----\n+\n+Collapse on `group_field` with a null policy so that all docs that do not have a value in the `group_field` will be treated as a single group. For each group, the selected document will be based first on a `numeric_field`, but ties will be broken by score:\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field nullPolicy=collapse sort='numeric_field asc, score desc'}\n+----\n+\n+Collapse on `group_field` with a hint to use the top level field cache:\n+\n+[source,text]\n+----\n+fq={!collapse field=group_field hint=top_fc}\n+----\n+\n+The CollapsingQParserPlugin fully supports the QueryElevationComponent.\n+\n+[[CollapseandExpandResults-ExpandComponent]]\n+== Expand Component\n+\n+The ExpandComponent can be used to expand the groups that were collapsed by the http://heliosearch.org/the-collapsingqparserplugin-solrs-new-high-performance-field-collapsing-postfilter/[CollapsingQParserPlugin].\n+\n+Example usage with the CollapsingQParserPlugin:\n+\n+[source,text]\n+----\n+q=foo&fq={!collapse field=ISBN}\n+----\n+\n+In the query above, the CollapsingQParserPlugin will collapse the search results on the _ISBN_ field. The main search results will contain the highest ranking document from each book.\n+\n+The ExpandComponent can now be used to expand the results so you can see the documents grouped by ISBN. For example:\n+\n+[source,text]\n+----\n+q=foo&fq={!collapse field=ISBN}&expand=true\n+----\n+\n+The \u201cexpand=true\u201d parameter turns on the ExpandComponent. The ExpandComponent adds a new section to the search output labeled \u201cexpanded\u201d.\n+\n+Inside the expanded section there is a _map_ with each group head pointing to the expanded documents that are within the group. As applications iterate the main collapsed result set, they can access the _expanded_ map to retrieve the expanded groups.\n+\n+The ExpandComponent has the following parameters:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,60,20\",options=\"header\"]\n+|===\n+|Parameter |Description |Default\n+|expand.sort |Orders the documents within the expanded groups |score desc\n+|expand.rows |The number of rows to display in each group |5\n+|expand.q |Overrides the main q parameter, determines which documents to include in the main group. |main q\n+|expand.fq |Overrides main fq's, determines which documents to include in the main group. |main fq's\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collapse-and-expand-results.adoc",
                "sha": "481d61ccf41d42f40f410aeb5fd5b93db76b024a",
                "status": "added"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collection-specific-tools.adoc",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/collection-specific-tools.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/collection-specific-tools.adoc",
                "patch": "@@ -0,0 +1,30 @@\n+= Collection-Specific Tools\n+:page-shortname: collection-specific-tools\n+:page-permalink: collection-specific-tools.html\n+:page-children: analysis-screen, dataimport-screen, documents-screen, files-screen, query-screen, stream-screen, schema-browser-screen\n+\n+In the left-hand navigation bar, you will see a pull-down menu titled \"Collection Selector\" that can be used to access collection specific administration screens.\n+\n+.Only Visible When Using SolrCloud\n+[NOTE]\n+====\n+The \"Collection Selector\" pull-down menu is only available on Solr instances running in <<solrcloud.adoc#solrcloud,SolrCloud mode>>.\n+\n+Single node or master/slave replication instances of Solr will not display this menu, instead the Collection specific UI pages described in this section will be available in the <<core-specific-tools.adoc#core-specific-tools,Core Selector pull-down menu>>.\n+====\n+\n+Clicking on the Collection Selector pull-down menu will show a list of the collections in your Solr cluster, with a search box that can be used to find a specific collection by name. When you select a collection from the pull-down, the main display of the page will display some basic metadata about the collection, and a secondary menu will appear in the left nav with links to additional collection specific administration screens.\n+\n+image::images/collection-specific-tools/collection_dashboard.png[image,width=482,height=250]\n+\n+The collection-specific UI screens are listed below, with a link to the section of this guide to find out more:\n+\n+// TODO: SOLR-10655 BEGIN: refactor this into a 'collection-screens-list.include.adoc' file for reuse\n+* <<analysis-screen.adoc#analysis-screen,Analysis>> - lets you analyze the data found in specific fields.\n+* <<dataimport-screen.adoc#dataimport-screen,Dataimport>> - shows you information about the current status of the Data Import Handler.\n+* <<documents-screen.adoc#documents-screen,Documents>> - provides a simple form allowing you to execute various Solr indexing commands directly from the browser.\n+* <<files-screen.adoc#files-screen,Files>> - shows the current core configuration files such as `solrconfig.xml`.\n+* <<query-screen.adoc#query-screen,Query>> - lets you submit a structured query about various elements of a core.\n+* <<stream-screen.adoc#stream-screen,Stream>> - allows you to submit streaming expressions and see results and parsing explanations.\n+* <<schema-browser-screen.adoc#schema-browser-screen,Schema Browser>> - displays schema data in a browser window.\n+// TODO: SOLR-10655 END",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collection-specific-tools.adoc",
                "sha": "b94572a4073f918e80cf95ec0f0e0238723a9111",
                "status": "added"
            },
            {
                "additions": 1889,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collections-api.adoc",
                "changes": 1889,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/collections-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/collections-api.adoc",
                "patch": "@@ -0,0 +1,1889 @@\n+= Collections API\n+:page-shortname: collections-api\n+:page-permalink: collections-api.html\n+\n+The Collections API is used to enable you to create, remove, or reload collections, but in the context of SolrCloud you can also use it to create collections with a specific number of shards and replicas.\n+\n+[[CollectionsAPI-create]]\n+== CREATE: Create a Collection\n+\n+`/admin/collections?action=CREATE&name=_name_&numShards=_number_&replicationFactor=_number_&maxShardsPerNode=_number_&createNodeSet=_nodelist_&collection.configName=_configname_`\n+\n+[[CollectionsAPI-Input]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,15,40\",options=\"header\"]\n+|===\n+|Key |Type |Required |Default |Description\n+|name |string |Yes | |The name of the collection to be created.\n+|router.name |string |No |compositeId |The router name that will be used. The router defines how documents will be distributed among the shards. Possible values are *implicit* or *compositeId*.\n+\n+The 'implicit' router does not automatically route documents to different shards. Whichever shard you indicate on the indexing request (or within each document) will be used as the destination for those documents.\n+\n+The 'compositeId' router hashes the value in the uniqueKey field and looks up that hash in the collection's clusterstate to determine which shard will receive the document, with the additional ability to manually direct the routing.\n+\n+When using the 'implicit' router, the `shards` parameter is required. When using the 'compositeId' router, the `numShards` parameter is required.\n+\n+For more information, see also the section <<shards-and-indexing-data-in-solrcloud.adoc#ShardsandIndexingDatainSolrCloud-DocumentRouting,Document Routing>>.\n+|numShards |integer |No |empty |The number of shards to be created as part of the collection. This is a required parameter when using the 'compositeId' router.\n+|shards |string |No |empty |A comma separated list of shard names, e.g., shard-x,shard-y,shard-z. This is a required parameter when using the 'implicit' router.\n+|replicationFactor |integer |No |1 |The number of replicas to be created for each shard.\n+|maxShardsPerNode |integer |No |1 |When creating collections, the shards and/or replicas are spread across all available (i.e., live) nodes, and two replicas of the same shard will never be on the same node. If a node is not live when the CREATE operation is called, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining `maxShardsPerNode` sets a limit on the number of replicas CREATE will spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all.\n+|createNodeSet |string |No | |Allows defining the nodes to spread the new collection across. If not provided, the CREATE operation will create shard-replica spread across all live Solr nodes. The format is a comma-separated list of node_names, such as `localhost:8983_solr,` `localhost:8984_solr,` `localhost:8985_solr`. Alternatively, use the special value of `EMPTY` to initially create no shard-replica within the new collection and then later use the <<CollectionsAPI-addreplica,ADDREPLICA>> operation to add shard-replica when and where required.\n+|createNodeSet.shuffle |boolean |No |true a|\n+Controls wether or not the shard-replicas created for this collection will be assigned to the nodes specified by the createNodeSet in a sequential manner, or if the list of nodes should be shuffled prior to creating individual replicas. A 'false' value makes the results of a collection creation predictible and gives more exact control over the location of the individual shard-replicas, but 'true' can be a better choice for ensuring replicas are distributed evenly across nodes.\n+\n+Ignored if createNodeSet is not also specified.\n+\n+|collection.configName |string |No |empty |Defines the name of the configurations (which must already be stored in ZooKeeper) to use for this collection. If not provided, Solr will default to the collection name as the configuration name.\n+|router.field |string |No |empty |If this field is specified, the router will look at the value of the field in an input document to compute the hash and identify a shard instead of looking at the `uniqueKey` field. If the field specified is null in the document, the document will be rejected. Please note that <<realtime-get.adoc#realtime-get,RealTime Get>> or retrieval by id would also require the parameter `\\_route_` (or `shard.keys`) to avoid a distributed search.\n+|property._name_=_value_ |string |No | |Set core property _name_ to _value_. See the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>> for details on supported properties and values.\n+|autoAddReplicas |boolean |No |false |When set to true, enables auto addition of replicas on shared file systems. See the section <<running-solr-on-hdfs.adoc#RunningSolronHDFS-AutomaticallyAddReplicasinSolrCloud,autoAddReplicas Settings>> for more details on settings and overrides.\n+|async |string |No | |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|rule |string |No | |Replica placement rules. See the section <<rule-based-replica-placement.adoc#rule-based-replica-placement,Rule-based Replica Placement>> for details.\n+|snitch |string |No | |Details of the snitch provider. See the section <<rule-based-replica-placement.adoc#rule-based-replica-placement,Rule-based Replica Placement>> for details.\n+|===\n+\n+[[CollectionsAPI-Output]]\n+=== Output\n+\n+The response will include the status of the request and the new core names. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=CREATE&name=newCollection&numShards=2&replicationFactor=1\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">3764</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">3450</int>\n+      </lst>\n+      <str name=\"core\">newCollection_shard1_replica1</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">3597</int>\n+      </lst>\n+      <str name=\"core\">newCollection_shard2_replica1</str>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-modifycollection]]\n+== MODIFYCOLLECTION: Modify Attributes of a Collection\n+\n+`/admin/collections?action=MODIFYCOLLECTION&collection=_<collection-name>&<attribute-name>=<attribute-value>&<another-attribute-name>=<another-value>_`\n+\n+It's possible to edit multiple attributes at a time. Changing these values only updates the z-node on Zookeeper, they do not change the topology of the collection. For instance, increasing replicationFactor will _not_ automatically add more replicas to the collection but _will_ allow more ADDREPLICA commands to succeed.\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection to be modified.\n+|<attribute-name> |string |Yes a|\n+Key-value pairs of attribute names and attribute values.\n+\n+The attributes that can be modified are:\n+\n+* maxShardsPerNode\n+* replicationFactor\n+* autoAddReplicas\n+* collection.configName\n+* rule\n+* snitch\n+\n+See the <<CollectionsAPI-create,CREATE>> section above for details on these attributes.\n+\n+|===\n+\n+[[CollectionsAPI-reload]]\n+== RELOAD: Reload a Collection\n+\n+`/admin/collections?action=RELOAD&name=_name_`\n+\n+The RELOAD action is used when you have changed a configuration in ZooKeeper.\n+\n+[[CollectionsAPI-Input.1]]\n+=== Input\n+\n+*Query Parameters*\n+\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|name |string |Yes |The name of the collection to reload.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.1]]\n+=== Output\n+\n+The response will include the status of the request and the cores that were reloaded. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.1]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=RELOAD&name=newCollection\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1551</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst name=\"10.0.1.6:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">761</int>\n+      </lst>\n+    </lst>\n+    <lst name=\"10.0.1.4:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1527</int>\n+      </lst>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-splitshard]]\n+== SPLITSHARD: Split a Shard\n+\n+`/admin/collections?action=SPLITSHARD&collection=_name_&shard=_shardID_`\n+\n+Splitting a shard will take an existing shard and break it into two pieces which are written to disk as two (new) shards. The original shard will continue to contain the same data as-is but it will start re-routing requests to the new shards. The new shards will have as many replicas as the original shard. A soft commit is automatically issued after splitting a shard so that documents are made visible on sub-shards. An explicit commit (hard or soft) is not necessary after a split operation because the index is automatically persisted to disk during the split operation.\n+\n+This command allows for seamless splitting and requires no downtime. A shard being split will continue to accept query and indexing requests and will automatically start routing them to the new shards once this operation is complete. This command can only be used for SolrCloud collections created with `numShards` parameter, meaning collections which rely on Solr's hash-based routing mechanism.\n+\n+The split is performed by dividing the original shard's hash range into two equal partitions and dividing up the documents in the original shard according to the new sub-ranges.\n+\n+One can also specify an optional `ranges` parameter to divide the original shard's hash range into arbitrary hash range intervals specified in hexadecimal. For example, if the original hash range is 0-1500 then adding the parameter: ranges=0-1f4,1f5-3e8,3e9-5dc will divide the original shard into three shards with hash range 0-500, 501-1000 and 1001-1500 respectively.\n+\n+Another optional parameter `split.key` can be used to split a shard using a route key such that all documents of the specified route key end up in a single dedicated sub-shard. Providing the 'shard' parameter is not required in this case because the route key is enough to figure out the right shard. A route key which spans more than one shard is not supported. For example, suppose `split.key=A!` hashes to the range 12-15 and belongs to shard 'shard1' with range 0-20 then splitting by this route key would yield three sub-shards with ranges 0-11, 12-15 and 16-20. Note that the sub-shard with the hash range of the route key may also contain documents for other route keys whose hash ranges overlap.\n+\n+Shard splitting can be a long running process. In order to avoid timeouts, you should run this as an <<CollectionsAPI-async,asynchronous call>>.\n+\n+[[CollectionsAPI-Input.2]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection that includes the shard to be split.\n+|shard |string |Yes |The name of the shard to be split.\n+|ranges |string |No |A comma-separated list of hash ranges in hexadecimal, such as `ranges=0-1f4,1f5-3e8,3e9-5dc`.\n+|split.key |string |No |The key to use for splitting the index.\n+|property._name_=_value_ |string |No |Set core property _name_ to _value_. See the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>> for details on supported properties and values.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>\n+|===\n+\n+[[CollectionsAPI-Output.2]]\n+=== Output\n+\n+The output will include the status of the request and the new shard names, which will use the original shard as their basis, adding an underscore and a number. For example, \"shard1\" will become \"shard1_0\" and \"shard1_1\". If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.2]]\n+=== Examples\n+\n+*Input*\n+\n+Split shard1 of the \"anotherCollection\" collection.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=SPLITSHARD&collection=anotherCollection&shard=shard1\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">6120</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">3673</int>\n+      </lst>\n+      <str name=\"core\">anotherCollection_shard1_1_replica1</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">3681</int>\n+      </lst>\n+      <str name=\"core\">anotherCollection_shard1_0_replica1</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">6008</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">6007</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">71</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">0</int>\n+      </lst>\n+      <str name=\"core\">anotherCollection_shard1_1_replica1</str>\n+      <str name=\"status\">EMPTY_BUFFER</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">0</int>\n+      </lst>\n+      <str name=\"core\">anotherCollection_shard1_0_replica1</str>\n+      <str name=\"status\">EMPTY_BUFFER</str>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-createshard]]\n+== CREATESHARD: Create a Shard\n+\n+Shards can only created with this API for collections that use the 'implicit' router. Use SPLITSHARD for collections using the 'compositeId' router. A new shard with a name can be created for an existing 'implicit' collection.\n+\n+`/admin/collections?action=CREATESHARD&shard=_shardName_&collection=_name_`\n+\n+[[CollectionsAPI-Input.3]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection that includes the shard that will be splitted.\n+|shard |string |Yes |The name of the shard to be created.\n+|createNodeSet |string |No |Allows defining the nodes to spread the new collection across. If not provided, the CREATE operation will create shard-replica spread across all live Solr nodes. The format is a comma-separated list of node_names, such as `localhost:8983_solr,` `localhost:8984_solr,` `localhost:8985_solr`.\n+|property._name_=_value_ |string |No |Set core property _name_ to _value_. See the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>> for details on supported properties and values.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.3]]\n+=== Output\n+\n+The output will include the status of the request. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.3]]\n+=== Examples\n+\n+*Input*\n+\n+Create 'shard-z' for the \"anImplicitCollection\" collection.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=CREATESHARD&collection=anImplicitCollection&shard=shard-z\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">558</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-deleteshard]]\n+== DELETESHARD: Delete a Shard\n+\n+Deleting a shard will unload all replicas of the shard, remove them from `clusterstate.json`, and (by default) delete the instanceDir and dataDir for each replica. It will only remove shards that are inactive, or which have no range given for custom sharding.\n+\n+`/admin/collections?action=DELETESHARD&shard=_shardID_&collection=_name_`\n+\n+[[CollectionsAPI-Input.4]]\n+=== Input\n+\n+*Query Parameters*\n+\n+[cols=\",,,\",options=\"header\",]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection that includes the shard to be deleted.\n+|shard |string |Yes |The name of the shard to be deleted.\n+|deleteInstanceDir |boolean |No |By default Solr will delete the entire instanceDir of each replica that is deleted. Set this to `false` to prevent the instance directory from being deleted.\n+|deleteDataDir |boolean |No |By default Solr will delete the dataDir of each replica that is deleted. Set this to `false` to prevent the data directory from being deleted.\n+|deleteIndex |boolean |No |By default Solr will delete the index of each replica that is deleted. Set this to `false` to prevent the index directory from being deleted.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.4]]\n+=== Output\n+\n+The output will include the status of the request. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.4]]\n+=== Examples\n+\n+*Input*\n+\n+Delete 'shard1' of the \"anotherCollection\" collection.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETESHARD&collection=anotherCollection&shard=shard1\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">558</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst name=\"10.0.1.4:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">27</int>\n+      </lst>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-createalias]]\n+== CREATEALIAS: Create or Modify an Alias for a Collection\n+\n+The `CREATEALIAS` action will create a new alias pointing to one or more collections. If an alias by the same name already exists, this action will replace the existing alias, effectively acting like an atomic \"MOVE\" command.\n+\n+`/admin/collections?action=CREATEALIAS&name=_name_&collections=_collectionlist_`\n+\n+[[CollectionsAPI-Input.5]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|name |string |Yes |The alias name to be created.\n+|collections |string |Yes |The list of collections to be aliased, separated by commas. They must already exist in the cluster.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.5]]\n+=== Output\n+\n+The output will simply be a responseHeader with details of the time it took to process the request. To confirm the creation of the alias, you can look in the Solr Admin UI, under the Cloud section and find the `aliases.json` file.\n+\n+[[CollectionsAPI-Examples.5]]\n+=== Examples\n+\n+*Input*\n+\n+Create an alias named \"testalias\" and link it to the collections named \"anotherCollection\" and \"testCollection\".\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=CREATEALIAS&name=testalias&collections=anotherCollection,testCollection\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">122</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-deletealias]]\n+== DELETEALIAS: Delete a Collection Alias\n+\n+`/admin/collections?action=DELETEALIAS&name=_name_`\n+\n+[[CollectionsAPI-Input.6]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|name |string |Yes |The name of the alias to delete.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.6]]\n+=== Output\n+\n+The output will simply be a responseHeader with details of the time it took to process the request. To confirm the removal of the alias, you can look in the Solr Admin UI, under the Cloud section, and find the `aliases.json` file.\n+\n+[[CollectionsAPI-Examples.6]]\n+=== Examples\n+\n+*Input*\n+\n+Remove the alias named \"testalias\".\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETEALIAS&name=testalias\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">117</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-delete]]\n+== DELETE: Delete a Collection\n+\n+`/admin/collections?action=DELETE&name=_collection_`\n+\n+[[CollectionsAPI-Input.7]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|name |string |Yes |The name of the collection to delete.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.7]]\n+=== Output\n+\n+The response will include the status of the request and the cores that were deleted. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.7]]\n+=== Examples\n+\n+*Input*\n+\n+Delete the collection named \"newCollection\".\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETE&name=newCollection\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">603</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst name=\"10.0.1.6:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">19</int>\n+      </lst>\n+    </lst>\n+    <lst name=\"10.0.1.4:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">67</int>\n+      </lst>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-deletereplica]]\n+== DELETEREPLICA: Delete a Replica\n+\n+Delete a named replica from the specified collection and shard. If the corresponding core is up and running the core is unloaded, the entry is removed from the clusterstate, and (by default) delete the instanceDir and dataDir. If the node/core is down, the entry is taken off the clusterstate and if the core comes up later it is automatically unregistered.\n+\n+`/admin/collections?action=DELETEREPLICA&collection=_collection_&shard=_shard_&replica=_replica_`\n+\n+[[CollectionsAPI-Input.8]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection.\n+|shard |string |Yes |The name of the shard that includes the replica to be removed.\n+|replica |string |No |The name of the replica to remove. Not required if `count` is used instead.\n+|count |integer |No |The number of replicas to remove. If the requested number exceeds the number of replicas, no replicas will be deleted. If there is only one replica, it will not be removed. This parameter is not required if `replica` is used instead.\n+|deleteInstanceDir |boolean |No |By default Solr will delete the entire instanceDir of the replica that is deleted. Set this to `false` to prevent the instance directory from being deleted.\n+|deleteDataDir |boolean |No |By default Solr will delete the dataDir of the replica that is deleted. Set this to `false` to prevent the data directory from being deleted.\n+|deleteIndex |boolean |No |By default Solr will delete the index of the replica that is deleted. Set this to `false` to prevent the index directory from being deleted.\n+|onlyIfDown |boolean |No |When set to 'true' will not take any action if the replica is active. Default 'false'\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Examples.8]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETEREPLICA&collection=test2&shard=shard2&replica=core_node3\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">110</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-addreplica]]\n+== ADDREPLICA: Add Replica\n+\n+Add a replica to a shard in a collection. The node name can be specified if the replica is to be created in a specific node.\n+\n+`/admin/collections?action=ADDREPLICA&collection=_collection_&shard=_shard_&node=_nodeName_`\n+\n+[[CollectionsAPI-Input.9]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection.\n+|shard |string |Yes* a|\n+The name of the shard to which replica is to be added.\n+\n+If shard is not specified, then _route_ must be.\n+\n+|_route_ |string |No* a|\n+If the exact shard name is not known, users may pass the _route_ value and the system would identify the name of the shard.\n+\n+Ignored if the shard param is also specified.\n+\n+|node |string |No |The name of the node where the replica should be created\n+|instanceDir |string |No |The instanceDir for the core that will be created\n+|dataDir |string |No |The directory in which the core should be created\n+|property._name_=_value_ |string |No |Set core property _name_ to _value_. See <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>>.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>\n+|===\n+\n+[[CollectionsAPI-Examples.9]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICA&collection=test2&shard=shard2&node=192.167.1.2:8983_solr\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">3764</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">3450</int>\n+      </lst>\n+      <str name=\"core\">test2_shard2_replica4</str>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-clusterprop]]\n+== CLUSTERPROP: Cluster Properties\n+\n+Add, edit or delete a cluster-wide property.\n+\n+`/admin/collections?action=CLUSTERPROP&name=_propertyName_&val=_propertyValue_`\n+\n+[[CollectionsAPI-Input.10]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|name |string |Yes |The name of the property. The supported properties names are `urlScheme` and `autoAddReplicas and location`. Other names are rejected with an error.\n+|val |string |Yes |The value of the property. If the value is empty or null, the property is unset.\n+|===\n+\n+[[CollectionsAPI-Output.8]]\n+=== Output\n+\n+The response will include the status of the request and the properties that were updated or removed. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.10]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=CLUSTERPROP&name=urlScheme&val=https\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">0</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-migrate]]\n+== MIGRATE: Migrate Documents to Another Collection\n+\n+`/admin/collections?action=MIGRATE&collection=_name_&split.key=_key1!_&target.collection=_target_collection_&forward.timeout=60`\n+\n+The MIGRATE command is used to migrate all documents having the given routing key to another collection. The source collection will continue to have the same data as-is but it will start re-routing write requests to the target collection for the number of seconds specified by the forward.timeout parameter. It is the responsibility of the user to switch to the target collection for reads and writes after the \u2018migrate\u2019 command completes.\n+\n+The routing key specified by the `split.key` parameter may span multiple shards on both the source and the target collections. The migration is performed shard-by-shard in a single thread. One or more temporary collections may be created by this command during the \u2018migrate\u2019 process but they are cleaned up at the end automatically.\n+\n+This is a long running operation and therefore using the `async` parameter is highly recommended. If the async parameter is not specified then the operation is synchronous by default and keeping a large read timeout on the invocation is advised. Even with a large read timeout, the request may still timeout due to inherent limitations of the Collection APIs but that doesn\u2019t necessarily mean that the operation has failed. Users should check logs, cluster state, source and target collections before invoking the operation again.\n+\n+This command works only with collections having the compositeId router. The target collection must not receive any writes during the time the migrate command is running otherwise some writes may be lost.\n+\n+Please note that the migrate API does not perform any de-duplication on the documents so if the target collection contains documents with the same uniqueKey as the documents being migrated then the target collection will end up with duplicate documents.\n+\n+[[CollectionsAPI-Input.11]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the source collection from which documents will be split.\n+|target.collection |string |Yes |The name of the target collection to which documents will be migrated.\n+|split.key |string |Yes |The routing key prefix. For example, if uniqueKey is a!123, then you would use `split.key=a!`.\n+|forward.timeout |int |No |The timeout, in seconds, until which write requests made to the source collection for the given `split.key` will be forwarded to the target shard. The default is 60 seconds.\n+|property._name_=_value_ |string |No |Set core property _name_ to _value_. See the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>> for details on supported properties and values.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-Output.9]]\n+=== Output\n+\n+The response will include the status of the request.\n+\n+[[CollectionsAPI-Examples.11]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=MIGRATE&collection=test1&split.key=a!&target.collection=test2\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">19014</int>\n+  </lst>\n+  <lst name=\"success\">\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1</int>\n+      </lst>\n+      <str name=\"core\">test2_shard1_0_replica1</str>\n+      <str name=\"status\">BUFFERING</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">2479</int>\n+      </lst>\n+      <str name=\"core\">split_shard1_0_temp_shard1_0_shard1_replica1</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1002</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">21</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1655</int>\n+      </lst>\n+      <str name=\"core\">split_shard1_0_temp_shard1_0_shard1_replica2</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">4006</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">17</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1</int>\n+      </lst>\n+      <str name=\"core\">test2_shard1_0_replica1</str>\n+      <str name=\"status\">EMPTY_BUFFER</str>\n+    </lst>\n+    <lst name=\"192.168.43.52:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">31</int>\n+      </lst>\n+    </lst>\n+    <lst name=\"192.168.43.52:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">31</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1</int>\n+      </lst>\n+      <str name=\"core\">test2_shard1_1_replica1</str>\n+      <str name=\"status\">BUFFERING</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1742</int>\n+      </lst>\n+      <str name=\"core\">split_shard1_1_temp_shard1_1_shard1_replica1</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1002</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">15</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1917</int>\n+      </lst>\n+      <str name=\"core\">split_shard1_1_temp_shard1_1_shard1_replica2</str>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">5007</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">8</int>\n+      </lst>\n+    </lst>\n+    <lst>\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">1</int>\n+      </lst>\n+      <str name=\"core\">test2_shard1_1_replica1</str>\n+      <str name=\"status\">EMPTY_BUFFER</str>\n+    </lst>\n+    <lst name=\"192.168.43.52:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">30</int>\n+      </lst>\n+    </lst>\n+    <lst name=\"192.168.43.52:8983_solr\">\n+      <lst name=\"responseHeader\">\n+        <int name=\"status\">0</int>\n+        <int name=\"QTime\">30</int>\n+      </lst>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-addrole]]\n+== ADDROLE: Add a Role\n+\n+`/admin/collections?action=ADDROLE&role=_roleName_&node=_nodeName_`\n+\n+Assign a role to a given node in the cluster. The only supported role as of 4.7 is 'overseer'. Use this API to dedicate a particular node as Overseer. Invoke it multiple times to add more nodes. This is useful in large clusters where an Overseer is likely to get overloaded. If available, one among the list of nodes which are assigned the 'overseer' role would become the overseer. The system would assign the role to any other node if none of the designated nodes are up and running.\n+\n+[[CollectionsAPI-Input.12]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|role |string |Yes |The name of the role. The only supported role as of now is _overseer_.\n+|node |string |Yes |The name of the node. It is possible to assign a role even before that node is started.\n+|===\n+\n+[[CollectionsAPI-Output.10]]\n+=== Output\n+\n+The response will include the status of the request and the properties that were updated or removed. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.12]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=ADDROLE&role=overseer&node=192.167.1.2:8983_solr\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">0</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-removerole]]\n+== REMOVEROLE: Remove Role\n+\n+Remove an assigned role. This API is used to undo the roles assigned using ADDROLE operation\n+\n+`/admin/collections?action=REMOVEROLE&role=_roleName_&node=_nodeName_`\n+\n+[[CollectionsAPI-Input.13]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|role |string |Yes |The name of the role. The only supported role as of now is _overseer_.\n+|node |string |Yes |The name of the node.\n+|===\n+\n+[[CollectionsAPI-Output.11]]\n+=== Output\n+\n+The response will include the status of the request and the properties that were updated or removed. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.13]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=REMOVEROLE&role=overseer&node=192.167.1.2:8983_solr\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">0</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-overseerstatus]]\n+== OVERSEERSTATUS: Overseer Status and Statistics\n+\n+Returns the current status of the overseer, performance statistics of various overseer APIs, and the last 10 failures per operation type.\n+\n+`/admin/collections?action=OVERSEERSTATUS`\n+\n+[[CollectionsAPI-Examples.14]]\n+=== Examples\n+\n+*Input:*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=OVERSEERSTATUS&wt=json\n+----\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":33},\n+  \"leader\":\"127.0.1.1:8983_solr\",\n+  \"overseer_queue_size\":0,\n+  \"overseer_work_queue_size\":0,\n+  \"overseer_collection_queue_size\":2,\n+  \"overseer_operations\":[\n+    \"createcollection\",{\n+      \"requests\":2,\n+      \"errors\":0,\n+      \"avgRequestsPerSecond\":0.7467088842794136,\n+      \"5minRateRequestsPerSecond\":7.525069023276674,\n+      \"15minRateRequestsPerSecond\":10.271274280947182,\n+      \"avgTimePerRequest\":0.5050685,\n+      \"medianRequestTime\":0.5050685,\n+      \"75thPcRequestTime\":0.519016,\n+      \"95thPcRequestTime\":0.519016,\n+      \"99thPcRequestTime\":0.519016,\n+      \"999thPcRequestTime\":0.519016},\n+    \"removeshard\",{\n+      \"...\"\n+  }],\n+  \"collection_operations\":[\n+    \"splitshard\",{\n+      \"requests\":1,\n+      \"errors\":1,\n+      \"recent_failures\":[{\n+          \"request\":{\n+            \"operation\":\"splitshard\",\n+            \"shard\":\"shard2\",\n+            \"collection\":\"example1\"},\n+          \"response\":[\n+            \"Operation splitshard caused exception:\",\"org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: No shard with the specified name exists: shard2\",\n+            \"exception\",{\n+              \"msg\":\"No shard with the specified name exists: shard2\",\n+              \"rspCode\":400}]}],\n+      \"avgRequestsPerSecond\":0.8198143044809885,\n+      \"5minRateRequestsPerSecond\":8.043840552427673,\n+      \"15minRateRequestsPerSecond\":10.502079828515368,\n+      \"avgTimePerRequest\":2952.7164175,\n+      \"medianRequestTime\":2952.7164175000003,\n+      \"75thPcRequestTime\":5904.384052,\n+      \"95thPcRequestTime\":5904.384052,\n+      \"99thPcRequestTime\":5904.384052,\n+      \"999thPcRequestTime\":5904.384052},\n+    \"...\"\n+  ],\n+  \"overseer_queue\":[\n+    \"...\"\n+  ],\n+  \"...\"\n+ }\n+----\n+\n+[[CollectionsAPI-clusterstatus]]\n+== CLUSTERSTATUS: Cluster Status\n+\n+Fetch the cluster status including collections, shards, replicas, configuration name as well as collection aliases and cluster properties.\n+\n+`/admin/collections?action=CLUSTERSTATUS`\n+\n+[[CollectionsAPI-Input.14]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |No |The collection name for which information is requested. If omitted, information on all collections in the cluster will be returned.\n+|shard |string |No |The shard(s) for which information is requested. Multiple shard names can be specified as a comma separated list.\n+|_route_ |string |No |This can be used if you need the details of the shard where a particular document belongs to and you don't know which shard it falls under.\n+|===\n+\n+[[CollectionsAPI-Output.12]]\n+=== Output\n+\n+The response will include the status of the request and the status of the cluster.\n+\n+[[CollectionsAPI-Examples.15]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=clusterstatus&wt=json\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":333},\n+  \"cluster\":{\n+    \"collections\":{\n+      \"collection1\":{\n+        \"shards\":{\n+          \"shard1\":{\n+            \"range\":\"80000000-ffffffff\",\n+            \"state\":\"active\",\n+            \"replicas\":{\n+              \"core_node1\":{\n+                \"state\":\"active\",\n+                \"core\":\"collection1\",\n+                \"node_name\":\"127.0.1.1:8983_solr\",\n+                \"base_url\":\"http://127.0.1.1:8983/solr\",\n+                \"leader\":\"true\"},\n+              \"core_node3\":{\n+                \"state\":\"active\",\n+                \"core\":\"collection1\",\n+                \"node_name\":\"127.0.1.1:8900_solr\",\n+                \"base_url\":\"http://127.0.1.1:8900/solr\"}}},\n+          \"shard2\":{\n+            \"range\":\"0-7fffffff\",\n+            \"state\":\"active\",\n+            \"replicas\":{\n+              \"core_node2\":{\n+                \"state\":\"active\",\n+                \"core\":\"collection1\",\n+                \"node_name\":\"127.0.1.1:7574_solr\",\n+                \"base_url\":\"http://127.0.1.1:7574/solr\",\n+                \"leader\":\"true\"},\n+              \"core_node4\":{\n+                \"state\":\"active\",\n+                \"core\":\"collection1\",\n+                \"node_name\":\"127.0.1.1:7500_solr\",\n+                \"base_url\":\"http://127.0.1.1:7500/solr\"}}}},\n+        \"maxShardsPerNode\":\"1\",\n+        \"router\":{\"name\":\"compositeId\"},\n+        \"replicationFactor\":\"1\",\n+        \"znodeVersion\": 11,\n+        \"autoCreated\":\"true\",\n+        \"configName\" : \"my_config\",\n+        \"aliases\":[\"both_collections\"]\n+      },\n+      \"collection2\":{\n+        \"...\"\n+      }\n+    },\n+    \"aliases\":{ \"both_collections\":\"collection1,collection2\" },\n+    \"roles\":{\n+      \"overseer\":[\n+        \"127.0.1.1:8983_solr\",\n+        \"127.0.1.1:7574_solr\"]\n+    },\n+    \"live_nodes\":[\n+      \"127.0.1.1:7574_solr\",\n+      \"127.0.1.1:7500_solr\",\n+      \"127.0.1.1:8983_solr\",\n+      \"127.0.1.1:8900_solr\"]\n+  }\n+}\n+----\n+\n+[[CollectionsAPI-requeststatus]]\n+== REQUESTSTATUS: Request Status of an Async Call\n+\n+Request the status and response of an already submitted <<CollectionsAPI-async,Asynchronous Collection API>> (below) call. This call is also used to clear up the stored statuses.\n+\n+`/admin/collections?action=REQUESTSTATUS&requestid=_request-id_`\n+\n+[[CollectionsAPI-Input.15]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|requestid |string |Yes |The user defined request-id for the request. This can be used to track the status of the submitted asynchronous task.\n+|===\n+\n+[[CollectionsAPI-Examples.16]]\n+=== Examples\n+\n+*Input: Valid Request Status*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=REQUESTSTATUS&requestid=1000\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1</int>\n+  </lst>\n+  <lst name=\"status\">\n+    <str name=\"state\">completed</str>\n+    <str name=\"msg\">found 1000 in completed tasks</str>\n+  </lst>\n+</response>\n+----\n+\n+*Input: Invalid RequestId*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=REQUESTSTATUS&requestid=1004\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1</int>\n+  </lst>\n+  <lst name=\"status\">\n+    <str name=\"state\">notfound</str>\n+    <str name=\"msg\">Did not find taskid [1004] in any tasks queue</str>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-deletestatus]]\n+== DELETESTATUS: Delete Status\n+\n+Delete the stored response of an already failed or completed <<CollectionsAPI-async,Asynchronous Collection API>> call.\n+\n+`/admin/collections?action=DELETESTATUS&requestid=_request-id_`\n+\n+[[CollectionsAPI-Input.16]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|requestid |string |No |The request-id of the async call we need to clear the stored response for.\n+|flush |boolean |No |Set to true to clear all stored completed and failed async request responses.\n+|===\n+\n+[[CollectionsAPI-Examples.17]]\n+=== Examples\n+\n+*Input: Valid Request Status*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETESTATUS&requestid=foo\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1</int>\n+  </lst>\n+  <str name=\"status\">successfully removed stored response for [foo]</str>\n+</response>\n+----\n+\n+*Input: Invalid RequestId*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETESTATUS&requestid=bar\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1</int>\n+  </lst>\n+  <str name=\"status\">[bar] not found in stored responses</str>\n+</response>\n+----\n+\n+*Input: Clear all the stored statuses*\n+\n+[source\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETESTATUS&flush=true\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">1</int>\n+  </lst>\n+  <str name=\"status\"> successfully cleared stored collection api responses </str>\n+</response>\n+----\n+\n+[[CollectionsAPI-list]]\n+== LIST: List Collections\n+\n+Fetch the names of the collections in the cluster.\n+\n+`/admin/collections?action=LIST`\n+\n+[[CollectionsAPI-Example]]\n+=== Example\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=LIST&wt=json\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":2011},\n+  \"collections\":[\"collection1\",\n+    \"example1\",\n+    \"example2\"]}\n+----\n+\n+[[CollectionsAPI-addreplicaprop]]\n+== ADDREPLICAPROP: Add Replica Property\n+\n+Assign an arbitrary property to a particular replica and give it the value specified. If the property already exists, it will be overwritten with the new value.\n+\n+`/admin/collections?action=ADDREPLICAPROP&collection=collectionName&shard=shardName&replica=replicaName&property=propertyName&property.value=value`\n+\n+[[CollectionsAPI-Input.17]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection this replica belongs to.\n+|shard |string |Yes |The name of the shard the replica belongs to.\n+|replica |string |Yes |The replica, e.g. core_node1.\n+|property |string |Yes a|\n+The property to add. Note: this will have the literal 'property.' prepended to distinguish it from system-maintained properties. So these two forms are equivalent:\n+\n+`property=special`\n+\n+and\n+\n+`property=property.special`\n+\n+There is one pre-defined property \"preferredLeader\" for which shardUnique is forced to 'true' and an error returned if shardUnique is explicitly set to 'false'. PreferredLeader is a boolean property, any value assigned that is not equal (case insensitive) to 'true' will be interpreted as 'false' for preferredLeader.\n+|property.value |string |Yes |The value to assign to the property.\n+|shardUnique (1) |Boolean |No |default: false. If true, then setting this property in one replica will remove the property from all other replicas in that shard.\n+|===\n+\n+[[CollectionsAPI-Output.13]]\n+=== Output\n+\n+The response will include the status of the request. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.18]]\n+=== Examples\n+\n+*Input*\n+\n+This command would set the preferredLeader (`property.preferredLeader`) to true on core_node1, and remove that property from any other replica in the shard.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICAPROP&shard=shard1&collection=collection1&replica=core_node1&property=preferredLeader&property.value=true\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">46</int>\n+  </lst>\n+</response>\n+----\n+\n+*Input*\n+\n+This pair of commands will set the \"testprop\" (`property.testprop`) to 'value1' and 'value2' respectively for two nodes in the same shard.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICAPROP&shard=shard1&collection=collection1&replica=core_node1&property=testprop&property.value=value1\n+\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICAPROP&shard=shard1&collection=collection1&replica=core_node3&property=property.testprop&property.value=value2\n+----\n+\n+*Input*\n+\n+This pair of commands would result in core_node_3 having the testprop (`property.testprop`) value set because the second command specifies `shardUnique=true`, which would cause the property to be removed from core_node_1.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICAPROP&shard=shard1&collection=collection1&replica=core_node1&property=testprop&property.value=value1\n+\n+http://localhost:8983/solr/admin/collections?action=ADDREPLICAPROP&shard=shard1&collection=collection1&replica=core_node3&property=testprop&property.value=value2&shardUnique=true\n+----\n+\n+[[CollectionsAPI-deletereplicaprop]]\n+== DELETEREPLICAPROP: Delete Replica Property\n+\n+Deletes an arbitrary property from a particular replica.\n+\n+`/admin/collections?action=DELETEREPLICAPROP&collection=collectionName&shard=_shardName_&replica=_replicaName_&property=_propertyName_`\n+\n+[[CollectionsAPI-Input.18]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection this replica belongs to\n+|shard |string |Yes |The name of the shard the replica belongs to.\n+|replica |string |Yes |The replica, e.g. core_node1.\n+|property |string |Yes a|\n+The property to add. Note: this will have the literal 'property.' prepended to distinguish it from system-maintained properties. So these two forms are equivalent:\n+\n+`property=special`\n+\n+and\n+\n+`property=property.special`\n+\n+|===\n+\n+[[CollectionsAPI-Output.14]]\n+=== Output\n+\n+The response will include the status of the request. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.19]]\n+=== Examples\n+\n+*Input*\n+\n+This command would delete the preferredLeader (`property.preferredLeader`) from core_node1.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=DELETEREPLICAPROP&shard=shard1&collection=collection1&replica=core_node1&property=preferredLeader\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">9</int>\n+  </lst>\n+</response>\n+----\n+\n+[[CollectionsAPI-balanceshardunique]]\n+== BALANCESHARDUNIQUE: Balance a Property Across Nodes\n+\n+`/admin/collections?action=BALANCESHARDUNIQUE&collection=_collectionName_&property=_propertyName_`\n+\n+Insures that a particular property is distributed evenly amongst the physical nodes that make up a collection. If the property already exists on a replica, every effort is made to leave it there. If the property is *not* on any replica on a shard, one is chosen and the property is added.\n+\n+[[CollectionsAPI-Input.19]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection to balance the property in.\n+|property |string |Yes |The property to balance. The literal \"property.\" is prepended to this property if not specified explicitly.\n+|onlyactivenodes |boolean |No |Defaults to true. Normally, the property is instantiated on active nodes only. If this parameter is specified as \"false\", then inactive nodes are also included for distribution.\n+|shardUnique |boolean |No |Something of a safety valve. There is one pre-defined property (preferredLeader) that defaults this value to \"true\". For all other properties that are balanced, this must be set to \"true\" or an error message is returned.\n+|===\n+\n+[[CollectionsAPI-Output.15]]\n+=== Output\n+\n+The response will include the status of the request. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.20]]\n+=== Examples\n+\n+*Input*\n+\n+Either of these commands would put the \"preferredLeader\" property on one replica in every shard in the \"collection1\" collection.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=BALANCESHARDUNIQUE&collection=collection1&property=preferredLeader\n+\n+http://localhost:8983/solr/admin/collections?action=BALANCESHARDUNIQUE&collection=collection1&property=property.preferredLeader\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">9</int>\n+  </lst>\n+</response>\n+----\n+\n+Examining the clusterstate after issuing this call should show exactly one replica in each shard that has this property.\n+\n+[[CollectionsAPI-rebalanceleaders]]\n+== REBALANCELEADERS: Rebalance Leaders\n+\n+Reassign leaders in a collection according to the preferredLeader property across active nodes.\n+\n+`/admin/collections?action=REBALANCELEADERS&collection=collectionName`\n+\n+Assigns leaders in a collection according to the preferredLeader property on active nodes. This command should be run after the preferredLeader property has been assigned via the BALANCESHARDUNIQUE or ADDREPLICAPROP commands. NOTE: it is not _required_ that all shards in a collection have a preferredLeader property. Rebalancing will only attempt to reassign leadership to those replicas that have the preferredLeader property set to \"true\" _and_ are not currently the shard leader _and_ are currently active.\n+\n+[[CollectionsAPI-Input.20]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection to rebalance preferredLeaders on.\n+|maxAtOnce |string |No |The maximum number of reassignments to have queue up at once. Values <=0 are use the default value Integer.MAX_VALUE. When this number is reached, the process waits for one or more leaders to be successfully assigned before adding more to the queue.\n+|maxWaitSeconds |string |No |Defaults to 60. This is the timeout value when waiting for leaders to be reassigned. NOTE: if maxAtOnce is less than the number of reassignments that will take place, this is the maximum interval that any _single_ wait for at least one reassignment. For example, if 10 reassignments are to take place and maxAtOnce is 1 and maxWaitSeconds is 60, the upper bound on the time that the command may wait is 10 minutes.\n+|===\n+\n+[[CollectionsAPI-Output.16]]\n+=== Output\n+\n+The response will include the status of the request. If the status is anything other than \"0\", an error message will explain why the request failed.\n+\n+[[CollectionsAPI-Examples.21]]\n+=== Examples\n+\n+*Input*\n+\n+Either of these commands would cause all the active replicas that had the \"preferredLeader\" property set and were _not_ already the preferred leader to become leaders.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=REBALANCELEADERS&collection=collection1\n+http://localhost:8983/solr/admin/collections?action=REBALANCELEADERS&collection=collection1&maxAtOnce=5&maxWaitSeconds=30\n+----\n+\n+*Output*\n+\n+In this example, two replicas in the \"alreadyLeaders\" section already had the leader assigned to the same node as the preferredLeader property so no action was taken. The replica in the \"inactivePreferreds\" section had the preferredLeader property set but the node was down and no action was taken. The three nodes in the \"successes\" section were made leaders because they had the preferredLeader property set but were not leaders and they were active.\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">123</int>\n+  </lst>\n+  <lst name=\"alreadyLeaders\">\n+    <lst name=\"core_node1\">\n+      <str name=\"status\">success</str>\n+      <str name=\"msg\">Already leader</str>\n+      <str name=\"nodeName\">192.168.1.167:7400_solr</str>\n+    </lst>\n+    <lst name=\"core_node17\">\n+      <str name=\"status\">success</str>\n+      <str name=\"msg\">Already leader</str>\n+      <str name=\"nodeName\">192.168.1.167:7600_solr</str>\n+    </lst>\n+  </lst>\n+  <lst name=\"inactivePreferreds\">\n+    <lst name=\"core_node4\">\n+      <str name=\"status\">skipped</str>\n+      <str name=\"msg\">Node is a referredLeader, but it's inactive. Skipping</str>\n+      <str name=\"nodeName\">192.168.1.167:7500_solr</str>\n+    </lst>\n+  </lst>\n+  <lst name=\"successes\">\n+    <lst name=\"_collection1_shard3_replica1\">\n+      <str name=\"status\">success</str>\n+      <str name=\"msg\">\n+        Assigned 'Collection: 'collection1', Shard: 'shard3', Core: 'collection1_shard3_replica1', BaseUrl:\n+        'http://192.168.1.167:8983/solr'' to be leader\n+      </str>\n+    </lst>\n+    <lst name=\"_collection1_shard5_replica3\">\n+      <str name=\"status\">success</str>\n+      <str name=\"msg\">\n+        Assigned 'Collection: 'collection1', Shard: 'shard5', Core: 'collection1_shard5_replica3', BaseUrl:\n+        'http://192.168.1.167:7200/solr'' to be leader\n+      </str>\n+    </lst>\n+    <lst name=\"_collection1_shard4_replica2\">\n+      <str name=\"status\">success</str>\n+      <str name=\"msg\">\n+        Assigned 'Collection: 'collection1', Shard: 'shard4', Core: 'collection1_shard4_replica2', BaseUrl:\n+        'http://192.168.1.167:7300/solr'' to be leader\n+      </str>\n+    </lst>\n+  </lst>\n+</response>\n+----\n+\n+Examining the clusterstate after issuing this call should show that every live node that has the \"preferredLeader\" property should also have the \"leader\" property set to _true_.\n+\n+\n+[[CollectionsAPI-FORCELEADER_ForceShardLeader]]\n+\n+[[CollectionsAPI-forceleader]]\n+== FORCELEADER: Force Shard Leader\n+\n+In the unlikely event of a shard losing its leader, this command can be invoked to force the election of a new leader\n+\n+`/admin/collections?action=FORCELEADER&collection=<collectionName>&shard=<shardName>`\n+\n+[[CollectionsAPI-Input.21]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection\n+|shard |string |Yes |The name of the shard\n+|===\n+\n+[IMPORTANT]\n+====\n+This is an expert level command, and should be invoked only when regular leader election is not working. This may potentially lead to loss of data in the event that the new leader doesn't have certain updates, possibly recent ones, which were acknowledged by the old leader before going down.\n+====\n+\n+[[CollectionsAPI-migratestateformat]]\n+== MIGRATESTATEFORMAT: Migrate Cluster State\n+\n+A expert level utility API to move a collection from shared `clusterstate.json` zookeeper node (created with `stateFormat=1`, the default in all Solr releases prior to 5.0) to the per-collection `state.json` stored in ZooKeeper (created with `stateFormat=2`, the current default) seamlessly without any application down-time.\n+\n+`/admin/collections?action=MIGRATESTATEFORMAT&collection=<collection_name>`\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection to be migrated from `clusterstate.json` to its own `state.json` zookeeper node\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+This API is useful in migrating any collections created prior to Solr 5.0 to the more scalable cluster state format now used by default. If a collection was created in any Solr 5.x version or higher, then executing this command is not necessary.\n+\n+[[CollectionsAPI-backup]]\n+== BACKUP: Backup Collection\n+\n+Backup Solr collections and it's associated configurations to a shared filesystem - for example a Network File System\n+\n+`/admin/collections?action=BACKUP&name=myBackupName&collection=myCollectionName&location=/path/to/my/shared/drive`\n+\n+The backup command will backup Solr indexes and configurations for a specified collection. The backup command takes one copy from each shard for the indexes. For configurations it backs up the configSet that was associated with the collection and metadata.\n+\n+[[CollectionsAPI-Input.22]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The name of the collection that needs to be backed up\n+|location |string |No |The location on the shared drive for the backup command to write to. Alternately it can be set as a <<CollectionsAPI-clusterprop,cluster property>>\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>\n+|repository |string |No |The name of the repository to be used for the backup. If no repository is specified then the local filesystem repository will be used automatically.\n+|===\n+\n+[[CollectionsAPI-restore]]\n+== RESTORE: Restore Collection\n+\n+Restores Solr indexes and associated configurations.\n+\n+`/admin/collections?action=RESTORE&name=myBackupName&location=/path/to/my/shared/drive&collection=myRestoredCollectionName`\n+\n+The restore operation will create a collection with the specified name in the collection parameter. You cannot restore into the same collection the backup was taken from and the target collection should not be present at the time the API is called as Solr will create it for you.\n+\n+The collection created will be of the same number of shards and replicas as the original collection, preserving routing information, etc. Optionally, you can override some parameters documented below. While restoring, if a configSet with the same name exists in ZooKeeper then Solr will reuse that, or else it will upload the backed up configSet in ZooKeeper and use that.\n+\n+You can use the collection <<CollectionsAPI-createalias,alias>> API to make sure client's don't need to change the endpoint to query or index against the newly restored collection.\n+\n+[[CollectionsAPI-Input.23]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection |string |Yes |The collection where the indexes will be restored into.\n+|location |string |No |The location on the shared drive for the restore command to read from. Alternately it can be set as a <<CollectionsAPI-clusterprop,cluster property>>.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|repository |string |No |The name of the repository to be used for the backup. If no repository is specified then the local filesystem repository will be used automatically.\n+|===\n+\n+Additionally, there are several parameters that can be overridden:\n+\n+*Override Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|collection.configName |String |No |Defines the name of the configurations to use for this collection. These must already be stored in ZooKeeper. If not provided, Solr will default to the collection name as the configuration name.\n+|replicationFactor |Integer |No |The number of replicas to be created for each shard.\n+|maxShardsPerNode |Integer |No |When creating collections, the shards and/or replicas are spread across all available (i.e., live) nodes, and two replicas of the same shard will never be on the same node. If a node is not live when the CREATE operation is called, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining `maxShardsPerNode` sets a limit on the number of replicas CREATE will spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all.\n+|autoAddReplicas |Boolean |No |When set to true, enables auto addition of replicas on shared file systems. See the section <<running-solr-on-hdfs.adoc#RunningSolronHDFS-AutomaticallyAddReplicasinSolrCloud,Automatically Add Replicas in SolrCloud>> for more details on settings and overrides.\n+|property._name_=_value_ |String |No |Set core property _name_ to _value_. See the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>> for details on supported properties and values.\n+|===\n+\n+[[CollectionsAPI-deletenode]]\n+== DELETENODE: Delete Replicas in a Node\n+\n+Deletes all replicas of all collections in that node. Please note that the node itself will remain as a live node after this operation.\n+\n+`/admin/collections?action=DELETENODE&node=nodeName`\n+\n+[[CollectionsAPI-Input.24]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|node |string |Yes |The node to be cleaned up\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[[CollectionsAPI-replacenode]]\n+== REPLACENODE: Move All Replicas in a Node to Another\n+\n+This command recreates replicas in the source node to the target node. After each replica is copied, the replicas in the source node are deleted.\n+\n+`/admin/collections?action=REPLACENODE&source=_source-node_&target=_target-node_`\n+\n+[[CollectionsAPI-Input.25]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,55\",options=\"header\"]\n+|===\n+|Key |Type |Required |Description\n+|source |string |Yes |The source node from which the replicas need to be copied from\n+|target |string |Yes |The target node\n+|parallel |boolean |No |default=false. if this flag is set to true, all replicas are created inseparatee threads. Keep in mind that this can lead to very high network and disk I/O if the replicas have very large indices.\n+|async |string |No |Request ID to track this action which will be <<CollectionsAPI-async,processed asynchronously>>.\n+|===\n+\n+[IMPORTANT]\n+====\n+This operation does not hold necessary locks on the replicas that belong to on the source node. So don't perform other collection operations in this period.\n+====\n+\n+[[CollectionsAPI-async]]\n+== Asynchronous Calls\n+\n+Since some collection API calls can be long running tasks e.g. Shard Split, you can optionally have the calls run asynchronously. Specifying `async=<request-id>` enables you to make an asynchronous call, the status of which can be requested using the <<CollectionsAPI-requeststatus,REQUESTSTATUS>> call at any time.\n+\n+As of now, REQUESTSTATUS does not automatically clean up the tracking data structures, meaning the status of completed or failed tasks stays stored in ZooKeeper unless cleared manually. DELETESTATUS can be used to clear the stored statuses. However, there is a limit of 10,000 on the number of async call responses stored in a cluster.\n+\n+[[CollectionsAPI-Example.1]]\n+=== Example\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/collections?action=SPLITSHARD&collection=collection1&shard=shard1&async=1000\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">99</int>\n+  </lst>\n+  <str name=\"requestid\">1000</str>\n+</response>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collections-api.adoc",
                "sha": "90866600c811d5509865768a0aa2c0a143cc8bb1",
                "status": "added"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collections-core-admin.adoc",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/collections-core-admin.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/collections-core-admin.adoc",
                "patch": "@@ -0,0 +1,25 @@\n+= Collections / Core Admin\n+:page-shortname: collections-core-admin\n+:page-permalink: collections-core-admin.html\n+\n+The Collections screen provides some basic functionality for managing your Collections, powered by the <<collections-api.adoc#collections-api,Collections API>>.\n+\n+[NOTE]\n+====\n+If you are running a single node Solr instance, you will not see a Collections option in the left nav menu of the Admin UI.\n+\n+You will instead see a \"Core Admin\" screen that supports some comparable Core level information & manipulation via the <<coreadmin-api.adoc#coreadmin-api,CoreAdmin API>> instead.\n+====\n+\n+The main display of this page provides a list of collections that exist in your cluster. Clicking on a collection name provides some basic metadata about how the collection is defined, and its current shards & replicas, with options for adding and deleting individual replicas.\n+\n+The buttons at the top of the screen let you make various collection level changes to your cluster, from add new collections or aliases to reloading or deleting a single collection.\n+\n+image::images/collections-core-admin/collection-admin.png[image,width=653,height=250]\n+\n+\n+Replicas can be deleted by clicking the red \"X\" next to the replica name.\n+\n+If the shard is inactive, for example after a <<collections-api.adoc#CollectionsAPI-splitshard,SPLITSHARD action>>, an option to delete the shard will appear as a red \"X\" next to the shard name.\n+\n+image::images/collections-core-admin/DeleteShard.png[image,width=486,height=250]",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/collections-core-admin.adoc",
                "sha": "fc753545b65f44c427669d8e326fc15c91d60495",
                "status": "added"
            },
            {
                "additions": 19,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/combining-distribution-and-replication.adoc",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/combining-distribution-and-replication.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/combining-distribution-and-replication.adoc",
                "patch": "@@ -0,0 +1,19 @@\n+= Combining Distribution and Replication\n+:page-shortname: combining-distribution-and-replication\n+:page-permalink: combining-distribution-and-replication.html\n+\n+When your index is too large for a single machine and you have a query volume that single shards cannot keep up with, it's time to replicate each shard in your distributed search setup.\n+\n+The idea is to combine distributed search with replication. As shown in the figure below, a combined distributed-replication configuration features a master server for each shard and then 1-_n_ slaves that are replicated from the master. As in a standard replicated configuration, the master server handles updates and optimizations without adversely affecting query handling performance.\n+\n+Query requests should be load balanced across each of the shard slaves. This gives you both increased query handling capacity and fail-over backup if a server goes down.\n+\n+.A Solr configuration combining both replication and master-slave distribution.\n+image::images/combining-distribution-and-replication/worddav4101c16174820e932b44baa22abcfcd1.png[image,width=312,height=344]\n+\n+\n+None of the master shards in this configuration know about each other. You index to each master, the index is replicated to each slave, and then searches are distributed across the slaves, using one slave from each master/slave shard.\n+\n+For high availability you can use a load balancer to set up a virtual IP for each shard's set of slaves. If you are new to load balancing, HAProxy (http://haproxy.1wt.eu/) is a good open source software load-balancer. If a slave server goes down, a good load-balancer will detect the failure using some technique (generally a heartbeat system), and forward all requests to the remaining live slaves that served with the failed slave. A single virtual IP should then be set up so that requests can hit a single IP, and get load balanced to each of the virtual IPs for the search slaves.\n+\n+With this configuration you will have a fully load balanced, search-side fault-tolerant system (Solr does not yet support fault-tolerant indexing). Incoming searches will be handed off to one of the functioning slaves, then the slave will distribute the search request across a slave for each of the shards in your configuration. The slave will issue a request to each of the virtual IPs for each shard, and the load balancer will choose one of the available slaves. Finally, the results will be combined into a single results set and returned. If any of the slaves go down, they will be taken out of rotation and the remaining slaves will be used. If a shard master goes down, searches can still be served from the slaves until you have corrected the problem and put the master back into production.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/combining-distribution-and-replication.adoc",
                "sha": "cff045de67514b737f857d29f52e49452bfbc698",
                "status": "added"
            },
            {
                "additions": 120,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/command-line-utilities.adoc",
                "changes": 120,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/command-line-utilities.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/command-line-utilities.adoc",
                "patch": "@@ -0,0 +1,120 @@\n+= Command Line Utilities\n+:page-shortname: command-line-utilities\n+:page-permalink: command-line-utilities.html\n+\n+Solr's Administration page (found by default at `\\http://hostname:8983/solr/`), provides a section with menu items for monitoring indexing and performance statistics.\n+\n+This pag also includes information about index distribution and replication, and information on all threads running in the JVM at the time.\n+\n+There is also a section where you can run queries, and an assistance area.\n+\n+In addition, SolrCloud provides its own administration page (found at http://localhost:8983/solr/#/~cloud), as well as a few tools available via a ZooKeeper Command Line Utility (CLI). The CLI scripts found in `server/scripts/cloud-scripts` let you upload configuration information to ZooKeeper, in the same two ways that were shown in the examples in <<parameter-reference.adoc#parameter-reference,Parameter Reference>>. It also provides a few other commands that let you link collection sets to collections, make ZooKeeper paths or clear them, and download configurations from ZooKeeper to the local filesystem.\n+\n+.Solr's zkcli.sh vs ZooKeeper's zkCli.sh vs Solr Start Script\n+[IMPORTANT]\n+====\n+The `zkcli.sh` provided by Solr is not the same as the https://zookeeper.apache.org/doc/trunk/zookeeperStarted.html#sc_ConnectingToZooKeeper[`zkCli.sh` included in ZooKeeper distributions].\n+\n+ZooKeeper's `zkCli.sh` provides a completely general, application-agnostic shell for manipulating data in ZooKeeper. Solr's `zkcli.sh` \u2013 discussed in this section \u2013 is specific to Solr, and has command line arguments specific to dealing with Solr data in ZooKeeper.\n+\n+Many of the functions provided by the zkCli.sh script are also provided by the <<solr-control-script-reference.adoc#solr-control-script-reference,Solr Control Script Reference>>, which may be more familiar as the start script ZooKeeper maintenance commands are very similar to Unix commands.\n+====\n+\n+[[CommandLineUtilities-UsingSolr_sZooKeeperCLI]]\n+== Using Solr's ZooKeeper CLI\n+\n+Both `zkcli.sh` (for Unix environments) and `zkcli.bat` (for Windows environments) support the following command line options:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"10,30,60\",options=\"header\"]\n+|===\n+|Short |Parameter Usage |Meaning\n+| |`-cmd <arg>` |CLI Command to be executed: `bootstrap`, `upconfig`, `downconfig`, `linkconfig`, `makepath`, `get`, `getfile`, `put`, `putfile`, `list`, `clear` or `clusterprop`. This parameter is **mandatory**.\n+|`-z` |`-zkhost <locations>` |ZooKeeper host address. This parameter is *mandatory* for all CLI commands.\n+|`-c` |`-collection <name>` |For `linkconfig`: name of the collection.\n+|`-d` |`-confdir <path>` |For `upconfig`: a directory of configuration files. For downconfig: the destination of files pulled from ZooKeeper\n+|`-h` |`-help` |Display help text.\n+|`-n` |`-confname <arg>` |For `upconfig`, `linkconfig`, `downconfig`: name of the configuration set.\n+|`-r` |`-runzk <port>` |Run ZooKeeper internally by passing the Solr run port; only for clusters on one machine.\n+|`-s` |`-solrhome <path>` |For `bootstrap` or when using `-runzk`: the *mandatory* solrhome location.\n+| |`-name <name>` |For `clusterprop`: the *mandatory* cluster property name.\n+| |`-val <value>` |For `clusterprop`: the cluster property value. If not specified, *null* will be used as value.\n+|===\n+\n+The short form parameter options may be specified with a single dash (eg: `-c mycollection`).\n+\n+The long form parameter options may be specified using either a single dash (eg: `-collection mycollection`) or a double dash (eg: `--collection mycollection`)\n+\n+[[CommandLineUtilities-ZooKeeperCLIExamples]]\n+== ZooKeeper CLI Examples\n+\n+Below are some examples of using the `zkcli.sh` CLI which assume you have already started the SolrCloud example (`bin/solr -e cloud -noprompt`)\n+\n+If you are on Windows machine, simply replace `zkcli.sh` with `zkcli.bat` in these examples.\n+\n+[[CommandLineUtilities-Uploadaconfigurationdirectory]]\n+=== Upload a configuration directory\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:9983 -cmd upconfig -confname my_new_config -confdir server/solr/configsets/basic_configs/conf\n+----\n+\n+[[CommandLineUtilities-BootstrapZooKeeperfromexistingSOLR_HOME]]\n+=== Bootstrap ZooKeeper from existing SOLR_HOME\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:2181 -cmd bootstrap -solrhome /var/solr/data\n+----\n+\n+.Bootstrap with chroot\n+[NOTE]\n+====\n+Using the boostrap command with a zookeeper chroot in the -zkhost parameter, e.g. `-zkhost 127.0.0.1:2181/solr`, will automatically create the chroot path before uploading the configs.\n+====\n+\n+[[CommandLineUtilities-PutarbitrarydataintoanewZooKeeperfile]]\n+=== Put arbitrary data into a new ZooKeeper file\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:9983 -cmd put /my_zk_file.txt 'some data'\n+----\n+\n+[[CommandLineUtilities-PutalocalfileintoanewZooKeeperfile]]\n+=== Put a local file into a new ZooKeeper file\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:9983 -cmd putfile /my_zk_file.txt /tmp/my_local_file.txt\n+----\n+\n+[[CommandLineUtilities-Linkacollectiontoaconfigurationset]]\n+=== Link a collection to a configuration set\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:9983 -cmd linkconfig -collection gettingstarted -confname my_new_config\n+----\n+\n+[[CommandLineUtilities-CreateanewZooKeeperpath]]\n+=== Create a new ZooKeeper path\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:2181 -cmd makepath /solr\n+----\n+\n+This can be useful to create a chroot path in ZooKeeper before first cluster start.\n+\n+[[CommandLineUtilities-Setaclusterproperty]]\n+=== Set a cluster property\n+\n+This command will add or modify a single cluster property in `clusterprops.json`. Use this command instead of the usual getfile -> edit -> putfile cycle. Unlike the CLUSTERPROP REST API, this command does *not* require a running Solr cluster.\n+\n+[source,bash]\n+----\n+./server/scripts/cloud-scripts/zkcli.sh -zkhost 127.0.0.1:2181 -cmd clusterprop -name urlScheme -val https\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/command-line-utilities.adoc",
                "sha": "78118c88425b4737b6822ca7ffbc84bd72e826ba",
                "status": "added"
            },
            {
                "additions": 365,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/common-query-parameters.adoc",
                "changes": 365,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/common-query-parameters.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/common-query-parameters.adoc",
                "patch": "@@ -0,0 +1,365 @@\n+= Common Query Parameters\n+:page-shortname: common-query-parameters\n+:page-permalink: common-query-parameters.html\n+\n+Several query parsers share supported query parameters.\n+\n+The table below summarizes Solr's common query parameters, which are supported by the <<requesthandlers-and-searchcomponents-in-solrconfig#RequestHandlersandSearchComponentsinSolrConfig-SearchHandlers,Search RequestHandlers>>\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Parameter |Description\n+|<<CommonQueryParameters-ThedefTypeParameter,defType>> |Selects the query parser to be used to process the query.\n+|<<CommonQueryParameters-ThesortParameter,sort>> |Sorts the response to a query in either ascending or descending order based on the response's score or another specified characteristic.\n+|<<CommonQueryParameters-ThestartParameter,start>> |Specifies an offset (by default, 0) into the responses at which Solr should begin displaying content.\n+|<<CommonQueryParameters-TherowsParameter,rows>> |Controls how many rows of responses are displayed at a time (default value: 10)\n+|<<CommonQueryParameters-Thefq_FilterQuery_Parameter,fq>> |Applies a filter query to the search results.\n+|<<CommonQueryParameters-Thefl_FieldList_Parameter,fl>> |Limits the information included in a query response to a specified list of fields. The fields need to either be `stored=\"true\"` or `docValues=\"true\"`\n+|<<CommonQueryParameters-ThedebugParameter,debug>> |Request additional debugging information in the response. Specifying the `debug=timing` parameter returns just the timing information; specifying the `debug=results` parameter returns \"explain\" information for each of the documents returned; specifying the `debug=query parameter` returns all of the debug information.\n+|<<CommonQueryParameters-TheexplainOtherParameter,explainOther>> |Allows clients to specify a Lucene query to identify a set of documents. If non-blank, the explain info of each document which matches this query, relative to the main query (specified by the q parameter) will be returned along with the rest of the debugging information.\n+|<<CommonQueryParameters-ThetimeAllowedParameter,timeAllowed>> |Defines the time allowed for the query to be processed. If the time elapses before the query response is complete, partial information may be returned.\n+|<<CommonQueryParameters-ThesegmentTerminateEarlyParameter,segmentTerminateEarly>> |Indicates that, if possible, Solr should stop collecting documents from each individual (sorted) segment once it can determine that any subsequent documents in that segment will not be candidates for the `rows` being returned. The default is false.\n+|<<CommonQueryParameters-TheomitHeaderParameter,omitHeader>> |Excludes the header from the returned results, if set to true. The header contains information about the request, such as the time the request took to complete. The default is false.\n+|<<CommonQueryParameters-ThewtParameter,wt>> |Specifies the Response Writer to be used to format the query response.\n+|<<CommonQueryParameters-ThelogParamsListParameter,logParamsList>> |By default, Solr logs all parameters. Set this parameter to restrict which parameters are logged. Valid entries are the parameters to be logged, separated by commas (i.e., `logParamsList=param1,param2`). An empty list will log no parameters, so if logging all parameters is desired, do not define this additional parameter at all.\n+|<<CommonQueryParameters-TheechoParamsParameter,echoParams>> |The response header can include parameters sent with the query request. This parameter controls what is contained in that section of the response header. Valid values are `none`, `all`, and `explicit`. The default value is `explicit.`\n+|===\n+\n+The following sections describe these parameters in detail.\n+\n+[[CommonQueryParameters-ThedefTypeParameter]]\n+== The `defType` Parameter\n+\n+The defType parameter selects the query parser that Solr should use to process the main query parameter (`q`) in the request. For example:\n+\n+`defType=dismax`\n+\n+If no defType param is specified, then by default, the <<the-standard-query-parser.adoc#the-standard-query-parser,The Standard Query Parser>> is used. (eg: `defType=lucene`)\n+\n+[[CommonQueryParameters-ThesortParameter]]\n+== The `sort` Parameter\n+\n+The `sort` parameter arranges search results in either ascending (`asc`) or descending (`desc`) order. The parameter can be used with either numerical or alphabetical content. The directions can be entered in either all lowercase or all uppercase letters (i.e., both `asc` or `ASC`).\n+\n+Solr can sort query responses according to document scores or the value of any field with a single value that is either indexed or uses <<docvalues.adoc#docvalues,DocValues>> (that is, any field whose attributes in the Schema include `multiValued=\"false\"` and either `docValues=\"true\"` or `indexed=\"true\"` \u2013 if the field does not have DocValues enabled, the indexed terms are used to build them on the fly at runtime), provided that:\n+\n+* the field is non-tokenized (that is, the field has no analyzer and its contents have been parsed into tokens, which would make the sorting inconsistent), or\n+\n+* the field uses an analyzer (such as the KeywordTokenizer) that produces only a single term.\n+\n+If you want to be able to sort on a field whose contents you want to tokenize to facilitate searching, <<copying-fields.adoc#copying-fields,use a `copyField` directive>> in the the Schema to clone the field. Then search on the field and sort on its clone.\n+\n+The table explains how Solr responds to various settings of the `sort` parameter.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Example |Result\n+| |If the sort parameter is omitted, sorting is performed as though the parameter were set to score `desc`.\n+|score desc |Sorts in descending order from the highest score to the lowest score.\n+|price asc |Sorts in ascending order of the price field\n+|inStock desc, price asc |Sorts by the contents of the `inStock` field in descending order, then within those results sorts in ascending order by the contents of the price field.\n+|===\n+\n+Regarding the sort parameter's arguments:\n+\n+* A sort ordering must include a field name (or `score` as a pseudo field), followed by whitespace (escaped as + or `%20` in URL strings), followed by a sort direction (`asc` or `desc`).\n+\n+* Multiple sort orderings can be separated by a comma, using this syntax: `sort=<field name>+<direction>,<field name>+<direction>],...`\n+** When more than one sort criteria is provided, the second entry will only be used if the first entry results in a tie. If there is a third entry, it will only be used if the first AND second entries are tied. This pattern continues with further entries.\n+\n+[[CommonQueryParameters-ThestartParameter]]\n+== The `start` Parameter\n+\n+When specified, the `start` parameter specifies an offset into a query's result set and instructs Solr to begin displaying results from this offset.\n+\n+The default value is \"0\". In other words, by default, Solr returns results without an offset, beginning where the results themselves begin.\n+\n+Setting the `start` parameter to some other number, such as 3, causes Solr to skip over the preceding records and start at the document identified by the offset.\n+\n+You can use the `start` parameter this way for paging. For example, if the `rows` parameter is set to 10, you could display three successive pages of results by setting start to 0, then re-issuing the same query and setting start to 10, then issuing the query again and setting start to 20.\n+\n+[[CommonQueryParameters-TherowsParameter]]\n+== The `rows` Parameter\n+\n+You can use the rows parameter to paginate results from a query. The parameter specifies the maximum number of documents from the complete result set that Solr should return to the client at one time.\n+\n+The default value is 10. That is, by default, Solr returns 10 documents at a time in response to a query.\n+\n+[[CommonQueryParameters-Thefq_FilterQuery_Parameter]]\n+== The `fq` (Filter Query) Parameter\n+\n+The `fq` parameter defines a query that can be used to restrict the superset of documents that can be returned, without influencing score. It can be very useful for speeding up complex queries, since the queries specified with `fq` are cached independently of the main query. When a later query uses the same filter, there's a cache hit, and filter results are returned quickly from the cache.\n+\n+When using the `fq` parameter, keep in mind the following:\n+\n+* The `fq` parameter can be specified multiple times in a query. Documents will only be included in the result if they are in the intersection of the document sets resulting from each instance of the parameter. In the example below, only documents which have a popularity greater then 10 and have a section of 0 will match.\n++\n+[source,text]\n+----\n+fq=popularity:[10 TO *]&fq=section:0\n+----\n+\n+* Filter queries can involve complicated Boolean queries. The above example could also be written as a single `fq` with two mandatory clauses like so:\n++\n+[source,text]\n+----\n+fq=+popularity:[10 TO *] +section:0\n+----\n+\n+* The document sets from each filter query are cached independently. Thus, concerning the previous examples: use a single `fq` containing two mandatory clauses if those clauses appear together often, and use two separate `fq` parameters if they are relatively independent. (To learn about tuning cache sizes and making sure a filter cache actually exists, see <<the-well-configured-solr-instance.adoc#the-well-configured-solr-instance,The Well-Configured Solr Instance>>.)\n+* It is also possible to use <<the-standard-query-parser.adoc#TheStandardQueryParser-DifferencesbetweenLuceneQueryParserandtheSolrStandardQueryParser,filter(condition) syntax>> inside the `fq` to cache clauses individually and - among other things - to achieve union of cached filter queries.\n+\n+* As with all parameters: special characters in an URL need to be properly escaped and encoded as hex values. Online tools are available to help you with URL-encoding. For example: http://meyerweb.com/eric/tools/dencoder/.\n+\n+[[CommonQueryParameters-Thefl_FieldList_Parameter]]\n+== The `fl` (Field List) Parameter\n+\n+The `fl` parameter limits the information included in a query response to a specified list of fields. The fields need to either be `stored=\"true\"` or `docValues=\"true\"``.`\n+\n+The field list can be specified as a space-separated or comma-separated list of field names. The string \"score\" can be used to indicate that the score of each document for the particular query should be returned as a field. The wildcard character `*` selects all the fields in the document which are either `stored=\"true\"` or `docValues=\"true\"` and `useDocValuesAsStored=\"true\"` (which is the default when docValues are enabled). You can also add pseudo-fields, functions and transformers to the field list request.\n+\n+This table shows some basic examples of how to use `fl`:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Field List |Result\n+|id name price |Return only the id, name, and price fields.\n+|id,name,price |Return only the id, name, and price fields.\n+|id name, price |Return only the id, name, and price fields.\n+|id score |Return the id field and the score.\n+|* |Return all the `stored` fields in each document, as well as any `docValues` fields that have `useDocValuesAsStored=\"true\"`. This is the default value of the fl parameter.\n+|* score |Return all the fields in each document, along with each field's score.\n+|*,dv_field_name |Return all the `stored` fields in each document, and any `docValues` fields that have `useDocValuesAsStored=\"true`\" and the docValues from dv_field_name even if it has `useDocValuesAsStored=\"false`\"\n+|===\n+\n+[[CommonQueryParameters-FunctionValues]]\n+=== Function Values\n+\n+<<function-queries.adoc#function-queries,Functions>> can be computed for each document in the result and returned as a pseudo-field:\n+\n+[source,text]\n+----\n+fl=id,title,product(price,popularity)\n+----\n+\n+[[CommonQueryParameters-DocumentTransformers]]\n+=== Document Transformers\n+\n+<<transforming-result-documents.adoc#transforming-result-documents,Document Transformers>> can be used to modify the information returned about each documents in the results of a query:\n+\n+[source,text]\n+----\n+fl=id,title,[explain]\n+----\n+\n+[[CommonQueryParameters-FieldNameAliases]]\n+=== Field Name Aliases\n+\n+You can change the key used to in the response for a field, function, or transformer by prefixing it with a `_\"displayName_:`\". For example:\n+\n+[source,text]\n+----\n+fl=id,sales_price:price,secret_sauce:prod(price,popularity),why_score:[explain style=nl]\n+----\n+\n+[source,json]\n+----\n+{\n+\"response\": {\n+    \"numFound\": 2,\n+    \"start\": 0,\n+    \"docs\": [{\n+        \"id\": \"6H500F0\",\n+        \"secret_sauce\": 2100.0,\n+        \"sales_price\": 350.0,\n+        \"why_score\": {\n+            \"match\": true,\n+            \"value\": 1.052226,\n+            \"description\": \"weight(features:cache in 2) [DefaultSimilarity], result of:\",\n+            \"details\": [{\n+                \"...\"\n+}]}}]}}\n+----\n+\n+[[CommonQueryParameters-ThedebugParameter]]\n+== The `debug` Parameter\n+\n+The `debug` parameter can be specified multiple times and supports the following arguments:\n+\n+* `debug=query`: return debug information about the query only.\n+* `debug=timing`: return debug information about how long the query took to process.\n+* `debug=results`: return debug information about the score results (also known as \"explain\").\n+** By default, score explanations are returned as large string values, using newlines and tab indenting for structure & readability, but an additional `debug.explain.structured=true` parameter may be specified to return this information as nested data structures native to the response format requested by `wt`.\n+* `debug=all`: return all available debug information about the request request. (alternatively usage: `debug=true`)\n+\n+For backwards compatibility with older versions of Solr, `debugQuery=true` may instead be specified as an alternative way to indicate `debug=all`\n+\n+The default behavior is not to include debugging information.\n+\n+[[CommonQueryParameters-TheexplainOtherParameter]]\n+== The `explainOther` Parameter\n+\n+The `explainOther` parameter specifies a Lucene query in order to identify a set of documents. If this parameter is included and is set to a non-blank value, the query will return debugging information, along with the \"explain info\" of each document that matches the Lucene query, relative to the main query (which is specified by the q parameter). For example:\n+\n+[source,text]\n+----\n+q=supervillians&debugQuery=on&explainOther=id:juggernaut\n+----\n+\n+The query above allows you to examine the scoring explain info of the top matching documents, compare it to the explain info for documents matching `id:juggernaut`, and determine why the rankings are not as you expect.\n+\n+The default value of this parameter is blank, which causes no extra \"explain info\" to be returned.\n+\n+[[CommonQueryParameters-ThetimeAllowedParameter]]\n+== The `timeAllowed` Parameter\n+\n+This parameter specifies the amount of time, in milliseconds, allowed for a search to complete. If this time expires before the search is complete, any partial results will be returned, but values such as `numFound`, <<faceting.adoc#faceting,facet>> counts, and result <<the-stats-component.adoc#the-stats-component,stats>> may not be accurate for the entire result set.\n+\n+This value is only checked at the time of:\n+\n+1.  Query Expansion, and\n+2.  Document collection\n+\n+As this check is periodically performed, the actual time for which a request can be processed before it is aborted would be marginally greater than or equal to the value of `timeAllowed`. If the request consumes more time in other stages, e.g., custom components, etc., this parameter is not expected to abort the request.\n+\n+[[CommonQueryParameters-ThesegmentTerminateEarlyParameter]]\n+== The `segmentTerminateEarly` Parameter\n+\n+This parameter may be set to either true or false.\n+\n+If set to true, and if <<indexconfig-in-solrconfig.adoc#IndexConfiginSolrConfig-mergePolicyFactory,the mergePolicyFactory>> for this collection is a {solr-javadocs}/solr-core/org/apache/solr/index/SortingMergePolicyFactory.html[`SortingMergePolicyFactory`] which uses a `sort` option which is compatible with <<CommonQueryParameters-ThesortParameter,the sort parameter>> specified for this query, then Solr will attempt to use an {lucene-javadocs}/core/org/apache/lucene/search/EarlyTerminatingSortingCollector.html[`EarlyTerminatingSortingCollector`].\n+\n+If early termination is used, a `segmentTerminatedEarly` header will be included in the `responseHeader`.\n+\n+Similar to using <<CommonQueryParameters-ThetimeAllowedParameter,the `timeAllowed `Parameter>>, when early segment termination happens values such as `numFound`, <<faceting.adoc#faceting,Facet>> counts, and result <<the-stats-component.adoc#the-stats-component,Stats>> may not be accurate for the entire result set.\n+\n+The default value of this parameter is false.\n+\n+[[CommonQueryParameters-TheomitHeaderParameter]]\n+== The `omitHeader` Parameter\n+\n+This parameter may be set to either true or false.\n+\n+If set to true, this parameter excludes the header from the returned results. The header contains information about the request, such as the time it took to complete. The default value for this parameter is false.\n+\n+[[CommonQueryParameters-ThewtParameter]]\n+== The `wt` Parameter\n+\n+The `wt` parameter selects the Response Writer that Solr should use to format the query's response. For detailed descriptions of Response Writers, see <<response-writers.adoc#response-writers,Response Writers>>.\n+\n+[[CommonQueryParameters-Thecache_falseParameter]]\n+== The `cache=false` Parameter\n+\n+Solr caches the results of all queries and filter queries by default. To disable result caching, set the `cache=false` parameter.\n+\n+You can also use the `cost` option to control the order in which non-cached filter queries are evaluated. This allows you to order less expensive non-cached filters before expensive non-cached filters.\n+\n+For very high cost filters, if `cache=false` and `cost>=100` and the query implements the `PostFilter` interface, a Collector will be requested from that query and used to filter documents after they have matched the main query and all other filter queries. There can be multiple post filters; they are also ordered by cost.\n+\n+For example:\n+// TODO: fix this, it looks horrible (CT)\n+[source,text]\n+----\n+// normal function range query used as a filter, all matching documents\n+// generated up front and cached\n+fq={!frange l=10 u=100}mul(popularity,price)\n+\n+// function range query run in parallel with the main query like a traditional\n+// lucene filter\n+fq={!frange l=10 u=100 cache=false}mul(popularity,price)\n+\n+// function range query checked after each document that already matches the query\n+// and all other filters.  Good for really expensive function queries.\n+fq={!frange l=10 u=100 cache=false cost=100}mul(popularity,price)\n+----\n+\n+[[CommonQueryParameters-ThelogParamsListParameter]]\n+== The `logParamsList` Parameter\n+\n+By default, Solr logs all parameters of requests. Set this parameter to restrict which parameters of a request are logged. This may help control logging to only those parameters considered important to your organization.\n+\n+For example, you could define this like:\n+\n+`logParamsList=q,fq`\n+\n+And only the 'q' and 'fq' parameters will be logged.\n+\n+If no parameters should be logged, you can send `logParamsList` as empty (i.e., `logParamsList=`).\n+\n+[TIP]\n+====\n+This parameter does not only apply to query requests, but to any kind of request to Solr.\n+====\n+\n+[[CommonQueryParameters-TheechoParamsParameter]]\n+== The `echoParams` Parameter\n+\n+The `echoParams` parameter controls what information about request parameters is included in the response header.\n+\n+The table explains how Solr responds to various settings of the `echoParams` parameter:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Value |Meaning\n+|explicit |This is the default value. Only parameters included in the actual request, plus the `_` parameter (which is a 64-bit numeric timestamp) will be added to the params section of the response header.\n+|all |Include all request parameters that contributed to the query. This will include everything defined in the request handler definition found in `solrconfig.xml` as well as parameters included with the request, plus the `_` parameter. If a parameter is included in the request handler definition AND the request, it will appear multiple times in the response header.\n+|none |Entirely removes the \"params\" section of the response header. No information about the request parameters will be available in the response.\n+|===\n+\n+Here is an example of a JSON response where the echoParams parameter was not included, so the default of `explicit` is active. The request URL that created this response included three parameters - `q`, `wt`, and `indent`:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+    \"status\": 0,\n+    \"QTime\": 0,\n+    \"params\": {\n+      \"q\": \"solr\",\n+      \"indent\": \"true\",\n+      \"wt\": \"json\",\n+      \"_\": \"1458227751857\"\n+    }\n+  },\n+  \"response\": {\n+    \"numFound\": 0,\n+    \"start\": 0,\n+    \"docs\": []\n+  }\n+}\n+----\n+\n+This is what happens if a similar request is sent that adds `echoParams=all` to the three parameters used in the previous example:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+    \"status\": 0,\n+    \"QTime\": 0,\n+    \"params\": {\n+      \"q\": \"solr\",\n+      \"df\": \"text\",\n+      \"preferLocalShards\": \"false\",\n+      \"indent\": \"true\",\n+      \"echoParams\": \"all\",\n+      \"rows\": \"10\",\n+      \"wt\": \"json\",\n+      \"_\": \"1458228887287\"\n+    }\n+  },\n+  \"response\": {\n+    \"numFound\": 0,\n+    \"start\": 0,\n+    \"docs\": []\n+  }\n+}\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/common-query-parameters.adoc",
                "sha": "248d540cb4834c8adb64d247cf287362c760f185",
                "status": "added"
            },
            {
                "additions": 521,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/config-api.adoc",
                "changes": 521,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/config-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/config-api.adoc",
                "patch": "@@ -0,0 +1,521 @@\n+= Config API\n+:page-shortname: config-api\n+:page-permalink: config-api.html\n+\n+The Config API enables manipulating various aspects of your `solrconfig.xml` using REST-like API calls.\n+\n+This feature is enabled by default and works similarly in both SolrCloud and standalone mode. Many commonly edited properties (such as cache sizes and commit settings) and request handler definitions can be changed with this API.\n+\n+When using this API, `solrconfig.xml` is not changed. Instead, all edited configuration is stored in a file called `configoverlay.json`. The values in `configoverlay.json` override the values in `solrconfig.xml`.\n+\n+[[ConfigAPI-APIEntryPoints]]\n+== API Entry Points\n+\n+* `/config`: retrieve or modify the config. GET to retrieve and POST for executing commands\n+* `/config/overlay`: retrieve the details in the `configoverlay.json` alone\n+* `/config/params` : allows creating parameter sets that can override or take the place of parameters defined in `solrconfig.xml`. See the <<request-parameters-api.adoc#request-parameters-api,Request Parameters API>> section for more details.\n+\n+[[ConfigAPI-Retrievingtheconfig]]\n+== Retrieving the config\n+\n+All configuration items, can be retrieved by sending a GET request to the `/config` endpoint - the results will be the effective configuration resulting from merging settings in `configoverlay.json` with those in `solrconfig.xml`:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config\n+----\n+\n+To restrict the returned results to a top level section, e.g. `query`, `requestHandler` or `updateHandler`, append the name of the section to the `/config` endpoint following a slash. E.g. to retrieve configuration for all request handlers:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config/requestHandler\n+----\n+\n+To further restrict returned results to a single component within a top level section, use the `componentName` request param, e.g. to return configuration for the `/select` request handler:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config/requestHandler?componentName=/select\n+----\n+\n+[[ConfigAPI-Commandstomodifytheconfig]]\n+== Commands to modify the config\n+\n+This API uses specific commands to tell Solr what property or type of property to add to `configoverlay.json`. The commands are passed as part of the data sent with the request.\n+\n+The config commands are categorized into 3 different sections which manipulate various data structures in `solrconfig.xml`. Each of these is described below.\n+\n+* <<ConfigAPI-CommandsforCommonProperties,Common Properties>>\n+* <<ConfigAPI-CommandsforCustomHandlersandLocalComponents,Components>>\n+* <<ConfigAPI-CommandsforUser-DefinedProperties,User-defined properties>>\n+\n+[[ConfigAPI-CommandsforCommonProperties]]\n+=== Commands for Common Properties\n+\n+The common properties are those that are frequently need to be customized in a Solr instance. They are manipulated with two commands:\n+\n+* `set-property`: Set a well known property. The names of the properties are predefined and fixed. If the property has already been set, this command will overwrite the previous setting.\n+* `unset-property`: Remove a property set using the `set-property` command.\n+\n+The properties that are configured with these commands are predefined and listed below. The names of these properties are derived from their XML paths as found in `solrconfig.xml`.\n+\n+* `updateHandler.autoCommit.maxDocs`\n+* `updateHandler.autoCommit.maxTime`\n+* `updateHandler.autoCommit.openSearcher`\n+* `updateHandler.autoSoftCommit.maxDocs`\n+* `updateHandler.autoSoftCommit.maxTime`\n+* `updateHandler.commitWithin.softCommit`\n+* `updateHandler.indexWriter.closeWaitsForMerges`\n+* `query.filterCache.class`\n+* `query.filterCache.size`\n+* `query.filterCache.initialSize`\n+* `query.filterCache.autowarmCount`\n+* `query.filterCache.regenerator`\n+* `query.queryResultCache.class`\n+* `query.queryResultCache.size`\n+* `query.queryResultCache.initialSize`\n+* `query.queryResultCache.autowarmCount`\n+* `query.queryResultCache.regenerator`\n+* `query.documentCache.class`\n+* `query.documentCache.size`\n+* `query.documentCache.initialSize`\n+* `query.documentCache.autowarmCount`\n+\n+* `query.documentCache.regenerator`\n+* `query.fieldValueCache.class`\n+* `query.fieldValueCache.size`\n+* `query.fieldValueCache.initialSize`\n+* `query.fieldValueCache.autowarmCount`\n+* `query.fieldValueCache.regenerator`\n+* `query.useFilterForSortedQuery`\n+* `query.queryResultWindowSize`\n+* `query.queryResultMaxDocCached`\n+* `query.enableLazyFieldLoading`\n+* `query.boolToFilterOptimizer`\n+* `query.maxBooleanClauses`\n+* `jmx.agentId`\n+* `jmx.serviceUrl`\n+* `jmx.rootName`\n+* `requestDispatcher.handleSelect`\n+* `requestDispatcher.requestParsers.multipartUploadLimitInKB`\n+* `requestDispatcher.requestParsers.formdataUploadLimitInKB`\n+* `requestDispatcher.requestParsers.enableRemoteStreaming`\n+* `requestDispatcher.requestParsers.addHttpRequestToContext`\n+\n+[[ConfigAPI-CommandsforCustomHandlersandLocalComponents]]\n+=== Commands for Custom Handlers and Local Components\n+\n+Custom request handlers, search components, and other types of localized Solr components (such as custom query parsers, update processors, etc.) can be added, updated and deleted with specific commands for the component being modified.\n+\n+The syntax is similar in each case: `add-<component-name>`, `update-<component-name>`, and `delete-<component-name>`. The command name is not case sensitive, so `Add-RequestHandler`, `ADD-REQUESTHANDLER` and `add-requesthandler` are all equivalent.\n+\n+In each case, `add-` commands add the new configuration to `configoverlay.json`, which will override any other settings for the component in `solrconfig.xml`; `update-` commands overwrite an existing setting in `configoverlay.json`; and `delete-` commands remove the setting from `configoverlay.json`.\n+\n+Settings removed from `configoverlay.json` are not removed from `solrconfig.xml`.\n+\n+The full list of available commands follows below:\n+\n+[[ConfigAPI-GeneralPurposeCommands]]\n+==== General Purpose Commands\n+\n+These commands are the most commonly used:\n+\n+* `add-requesthandler`\n+* `update-requesthandler`\n+* `delete-requesthandler`\n+* `add-searchcomponent`\n+* `update-searchcomponent`\n+* `delete-searchcomponent`\n+* `add-initparams`\n+* `update-initparams`\n+* `delete-initparams`\n+* `add-queryresponsewriter`\n+* `update-queryresponsewriter`\n+* `delete-queryresponsewriter`\n+\n+[[ConfigAPI-AdvancedCommands]]\n+==== Advanced Commands\n+\n+These commands allow registering more advanced customizations to Solr:\n+\n+* `add-queryparser`\n+* `update-queryparser`\n+* `delete-queryparser`\n+* `add-valuesourceparser`\n+* `update-valuesourceparser`\n+* `delete-valuesourceparser`\n+* `add-transformer`\n+* `update-transformer`\n+* `delete-transformer`\n+* `add-updateprocessor`\n+* `update-updateprocessor`\n+* `delete-updateprocessor`\n+\n+* `add-queryconverter`\n+* `update-queryconverter`\n+* `delete-queryconverter`\n+* `add-listener`\n+* `update-listener`\n+* `delete-listener`\n+* `add-runtimelib`\n+* `update-runtimelib`\n+* `delete-runtimelib`\n+\n+See the section <<ConfigAPI-CreatingandUpdatingRequestHandlers,Creating and Updating Request Handlers>> below for examples of using these commands.\n+\n+[[ConfigAPI-Whatabout_updateRequestProcessorChain_]]\n+==== What about updateRequestProcessorChain?\n+\n+The Config API does not let you create or edit `updateRequestProcessorChain` elements. However, it is possible to create `updateProcessor` entries and can use them by name to create a chain.\n+\n+example:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json' -d '{\n+\"add-updateprocessor\" : { \"name\" : \"firstFld\",\n+                          \"class\": \"solr.FirstFieldValueUpdateProcessorFactory\",\n+                          \"fieldName\":\"test_s\"}}'\n+----\n+\n+You can use this directly in your request by adding a parameter in the `updateRequestProcessorChain` for the specific update processor called `processor=firstFld`.\n+\n+[[ConfigAPI-CommandsforUser-DefinedProperties]]\n+=== Commands for User-Defined Properties\n+\n+Solr lets users templatize the `solrconfig.xml` using the place holder format `${variable_name:default_val}`. You could set the values using system properties, for example, `-Dvariable_name= my_customvalue`. The same can be achieved during runtime using these commands:\n+\n+* `set-user-property`: Set a user-defined property. If the property has already been set, this command will overwrite the previous setting.\n+* `unset-user-property`: Remove a user-defined property.\n+\n+The structure of the request is similar to the structure of requests using other commands, in the format of `\"command\":{\"variable_name\":\"property_value\"}`. You can add more than one variable at a time if necessary.\n+\n+For more information about user-defined properties, see the section <<configuring-solrconfig-xml.adoc#Configuringsolrconfig.xml-Userdefinedpropertiesfromcore.properties,User defined properties from core.properties>>.\n+\n+See also the section <<ConfigAPI-CreatingandUpdatingUser-DefinedProperties,Creating and Updating User-Defined Properties>> below for examples of how to use this type of command.\n+\n+[[ConfigAPI-HowtoMapsolrconfig.xmlPropertiestoJSON]]\n+== How to Map `solrconfig.xml` Properties to JSON\n+\n+By using this API, you will be generating JSON representations of properties defined in `solrconfig.xml`. To understand how properties should be represented with the API, let's take a look at a few examples.\n+\n+Here is what a request handler looks like in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/query\" class=\"solr.SearchHandler\">\n+  <lst name=\"defaults\">\n+    <str name=\"echoParams\">explicit</str>\n+    <str name=\"wt\">json</str>\n+    <str name=\"indent\">true</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+The same request handler defined with the Config API would look like this:\n+\n+[source,json]\n+----\n+{\n+  \"add-requesthandler\":{\n+    \"name\":\"/query\",\n+    \"class\":\"solr.SearchHandler\",\n+    \"defaults\":{\n+      \"echoParams\":\"explicit\",\n+      \"wt\":\"json\",\n+      \"indent\":true\n+    }\n+  }\n+}\n+----\n+\n+The QueryElevationComponent searchComponent in `solrconfig.xml` looks like this:\n+\n+[source,xml]\n+----\n+<searchComponent name=\"elevator\" class=\"solr.QueryElevationComponent\" >\n+  <str name=\"queryFieldType\">string</str>\n+  <str name=\"config-file\">elevate.xml</str>\n+</searchComponent>\n+----\n+\n+And the same searchComponent with the Config API:\n+\n+[source,json]\n+----\n+{\n+  \"add-searchcomponent\":{\n+    \"name\":\"elevator\",\n+    \"class\":\"QueryElevationComponent\",\n+    \"queryFieldType\":\"string\",\n+    \"config-file\":\"elevate.xml\"\n+  }\n+}\n+----\n+\n+Removing the searchComponent with the Config API:\n+\n+[source,json]\n+----\n+{\n+  \"delete-searchcomponent\":\"elevator\"\n+}\n+----\n+\n+A simple highlighter looks like this in `solrconfig.xml` (example has been truncated for space):\n+\n+[source,xml]\n+----\n+<searchComponent class=\"solr.HighlightComponent\" name=\"highlight\">\n+    <highlighting>\n+      <fragmenter name=\"gap\"\n+                  default=\"true\"\n+                  class=\"solr.highlight.GapFragmenter\">\n+        <lst name=\"defaults\">\n+          <int name=\"hl.fragsize\">100</int>\n+        </lst>\n+      </fragmenter>\n+\n+      <formatter name=\"html\"\n+                 default=\"true\"\n+                 class=\"solr.highlight.HtmlFormatter\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.simple.pre\"><![CDATA[<em>]]></str>\n+          <str name=\"hl.simple.post\"><![CDATA[</em>]]></str>\n+        </lst>\n+      </formatter>\n+\n+      <encoder name=\"html\" class=\"solr.highlight.HtmlEncoder\" />\n+...\n+    </highlighting>\n+----\n+\n+The same highlighter with the Config API:\n+\n+[source,json]\n+----\n+{\n+    \"add-searchcomponent\": {\n+        \"name\": \"highlight\",\n+        \"class\": \"solr.HighlightComponent\",\n+        \"\": {\n+            \"gap\": {\n+                \"default\": \"true\",\n+                \"name\": \"gap\",\n+                \"class\": \"solr.highlight.GapFragmenter\",\n+                \"defaults\": {\n+                    \"hl.fragsize\": 100\n+                }\n+            }\n+        },\n+        \"html\": [{\n+            \"default\": \"true\",\n+            \"name\": \"html\",\n+            \"class\": \"solr.highlight.HtmlFormatter\",\n+            \"defaults\": {\n+                \"hl.simple.pre\": \"before-\",\n+                \"hl.simple.post\": \"-after\"\n+            }\n+        }, {\n+            \"name\": \"html\",\n+            \"class\": \"solr.highlight.HtmlEncoder\"\n+        }]\n+    }\n+}\n+----\n+\n+Set autoCommit properties in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<autoCommit>\n+  <maxTime>15000</maxTime>\n+  <openSearcher>false</openSearcher>\n+</autoCommit>\n+----\n+\n+Define the same properties with the Config API:\n+\n+[source,json]\n+----\n+{\n+  \"set-property\": {\n+    \"updateHandler.autoCommit.maxTime\":15000,\n+    \"updateHandler.autoCommit.openSearcher\":false\n+  }\n+}\n+----\n+\n+[[ConfigAPI-NameComponentsfortheConfigAPI]]\n+=== Name Components for the Config API\n+\n+The Config API always allows changing the configuration of any component by name. However, some configurations such as `listener` or `initParams` do not require a name in `solrconfig.xml`. In order to be able to `update` and `delete` of the same item in `configoverlay.json`, the name attribute becomes mandatory.\n+\n+[[ConfigAPI-Examples]]\n+== Examples\n+\n+[[ConfigAPI-CreatingandUpdatingCommonProperties]]\n+=== Creating and Updating Common Properties\n+\n+This change sets the `query.filterCache.autowarmCount` to 1000 items and unsets the `query.filterCache.size`.\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json' -d'{\n+    \"set-property\" : {\"query.filterCache.autowarmCount\":1000},\n+    \"unset-property\" :\"query.filterCache.size\"}'\n+----\n+\n+Using the `/config/overlay` endpoint, you can verify the changes with a request like this:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/gettingstarted/config/overlay?omitHeader=true\n+----\n+\n+And you should get a response like this:\n+\n+[source,json]\n+----\n+{\n+  \"overlay\":{\n+    \"znodeVersion\":1,\n+    \"props\":{\"query\":{\"filterCache\":{\n+          \"autowarmCount\":1000,\n+          \"size\":25}}}}}\n+----\n+\n+[[ConfigAPI-CreatingandUpdatingRequestHandlers]]\n+=== Creating and Updating Request Handlers\n+\n+To create a request handler, we can use the `add-requesthandler` command:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json'  -d '{\n+  \"add-requesthandler\" : {\n+    \"name\": \"/mypath\",\n+    \"class\":\"solr.DumpRequestHandler\",\n+    \"defaults\":{ \"x\":\"y\" ,\"a\":\"b\", \"wt\":\"json\", \"indent\":true },\n+    \"useParams\":\"x\"\n+  }\n+}'\n+----\n+\n+Make a call to the new request handler to check if it is registered:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/mypath?omitHeader=true\n+----\n+\n+And you should see the following as output:\n+\n+[source,json]\n+----\n+{\n+  \"params\":{\n+    \"indent\":\"true\",\n+    \"a\":\"b\",\n+    \"x\":\"y\",\n+    \"wt\":\"json\"},\n+  \"context\":{\n+    \"webapp\":\"/solr\",\n+    \"path\":\"/mypath\",\n+    \"httpMethod\":\"GET\"}}\n+----\n+\n+To update a request handler, you should use the `update-requesthandler` command :\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json'  -d '{\n+  \"update-requesthandler\": {\n+    \"name\": \"/mypath\",\n+    \"class\":\"solr.DumpRequestHandler\",\n+    \"defaults\": {\"x\":\"new value for X\", \"wt\":\"json\", \"indent\":true},\n+    \"useParams\":\"x\"\n+  }\n+}'\n+----\n+\n+As another example, we'll create another request handler, this time adding the 'terms' component as part of the definition:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H 'Content-type:application/json' -d '{\n+  \"add-requesthandler\": {\n+    \"name\": \"/myterms\",\n+    \"class\":\"solr.SearchHandler\",\n+    \"defaults\": {\"terms\":true, \"distrib\":false},\n+    \"components\": [ \"terms\" ]\n+  }\n+}'\n+----\n+\n+[[ConfigAPI-CreatingandUpdatingUser-DefinedProperties]]\n+=== Creating and Updating User-Defined Properties\n+\n+This command sets a user property.\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H'Content-type:application/json' -d '{\n+    \"set-user-property\" : {\"variable_name\":\"some_value\"}}'\n+----\n+\n+Again, we can use the `/config/overlay` endpoint to verify the changes have been made:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config/overlay?omitHeader=true\n+----\n+\n+And we would expect to see output like this:\n+\n+[source,json]\n+----\n+{\"overlay\":{\n+   \"znodeVersion\":5,\n+   \"userProps\":{\n+     \"variable_name\":\"some_value\"}}\n+}\n+----\n+\n+To unset the variable, issue a command like this:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H'Content-type:application/json' -d '{\"unset-user-property\" : \"variable_name\"}'\n+----\n+\n+[[ConfigAPI-HowItWorks]]\n+== How It Works\n+\n+Every core watches the ZooKeeper directory for the configset being used with that core. In standalone mode, however, there is no watch (because ZooKeeper is not running). If there are multiple cores in the same node using the same configset, only one ZooKeeper watch is used. For instance, if the configset 'myconf' is used by a core, the node would watch `/configs/myconf`. Every write operation performed through the API would 'touch' the directory (sets an empty byte[] to trigger watches) and all watchers are notified. Every core would check if the Schema file, `solrconfig.xml` or `configoverlay.json` is modified by comparing the `znode` versions and if modified, the core is reloaded.\n+\n+If `params.json` is modified, the params object is just updated without a core reload (see the section <<request-parameters-api.adoc#request-parameters-api,Request Parameters API>> for more information about `params.json`).\n+\n+[[ConfigAPI-EmptyCommand]]\n+=== Empty Command\n+\n+If an empty command is sent to the `/config` endpoint, the watch is triggered on all cores using this configset. For example:\n+\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/techproducts/config -H'Content-type:application/json' -d '{}'\n+----\n+\n+Directly editing any files without 'touching' the directory *will not* make it visible to all nodes.\n+\n+It is possible for components to watch for the configset 'touch' events by registering a listener using `SolrCore#registerConfListener()` .\n+\n+[[ConfigAPI-ListeningtoconfigChanges]]\n+=== Listening to config Changes\n+\n+Any component can register a listener using:\n+\n+`SolrCore#addConfListener(Runnable listener)`\n+\n+to get notified for config changes. This is not very useful if the files modified result in core reloads (i.e., `configoverlay.xml` or Schema). Components can use this to reload the files they are interested in.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/config-api.adoc",
                "sha": "146d55cdde89b83061e470e054bee85757775267",
                "status": "added"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/config-sets.adoc",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/config-sets.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/config-sets.adoc",
                "patch": "@@ -0,0 +1,26 @@\n+= Config Sets\n+:page-shortname: config-sets\n+:page-permalink: config-sets.html\n+\n+On a multicore Solr instance, you may find that you want to share configuration between a number of different cores. You can achieve this using named configsets, which are essentially shared configuration directories stored under a configurable configset base directory.\n+\n+To create a configset, simply add a new directory under the configset base directory. The configset will be identified by the name of this directory. Then into this copy the config directory you want to share. The structure should look something like this:\n+\n+[source,bash]\n+----\n+/<configSetBaseDir>\n+    /configset1\n+        /conf\n+            /managed-schema\n+            /solrconfig.xml\n+    /configset2\n+        /conf\n+            /managed-schema\n+            /solrconfig.xml\n+----\n+\n+The default base directory is `$SOLR_HOME/configsets`, and it can be configured in `solr.xml`.\n+\n+To create a new core using a configset, pass `configSet` as one of the core properties. For example, if you do this via the core admin API:\n+\n+`\\http://localhost:8983/admin/cores?action=CREATE&name=mycore&instanceDir=path/to/instance&configSet=configset2`",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/config-sets.adoc",
                "sha": "3c67e7e7f2ce24389406ce1e6dd069cf60715b2d",
                "status": "added"
            },
            {
                "additions": 155,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configsets-api.adoc",
                "changes": 155,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/configsets-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/configsets-api.adoc",
                "patch": "@@ -0,0 +1,155 @@\n+= ConfigSets API\n+:page-shortname: configsets-api\n+:page-permalink: configsets-api.html\n+\n+The ConfigSets API enables you to create, delete, and otherwise manage ConfigSets.\n+\n+To use a ConfigSet created with this API as the configuration for a collection, use the <<collections-api.adoc#collections-api,Collections API>>.\n+\n+This API can only be used with Solr running in SolrCloud mode. If you are not running Solr in SolrCloud mode but would still like to use shared configurations, please see the section <<config-sets.adoc#config-sets,Config Sets>>.\n+\n+[[ConfigSetsAPI-APIEntryPoints]]\n+== API Entry Points\n+\n+The base URL for all API calls is `\\http://<hostname>:<port>/solr`.\n+\n+* `/admin/configs?action=CREATE`: <<ConfigSetsAPI-create,create>> a ConfigSet, based on an existing ConfigSet\n+* `/admin/configs?action=DELETE`: <<ConfigSetsAPI-delete,delete>> a ConfigSet\n+* `/admin/configs?action=LIST`: <<ConfigSetsAPI-list,list>> all ConfigSets\n+\n+[[ConfigSetsAPI-createCreateaConfigSet]]\n+\n+[[ConfigSetsAPI-create]]\n+== Create a ConfigSet\n+\n+`/admin/configs?action=CREATE&name=_name_&baseConfigSet=_baseConfigSet_`\n+\n+Create a ConfigSet, based on an existing ConfigSet.\n+\n+[[ConfigSetsAPI-Input]]\n+=== Input\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,15,40\",options=\"header\"]\n+|===\n+|Key |Type |Required |Default |Description\n+|name |String |Yes | |ConfigSet to be created\n+|baseConfigSet |String |Yes | |ConfigSet to copy as a base\n+|configSetProp._name=value_ |String |No | |ConfigSet property from base to override\n+|===\n+\n+[[ConfigSetsAPI-Output]]\n+=== Output\n+\n+*Output Content*\n+\n+The output will include the status of the request. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[ConfigSetsAPI-Examples]]\n+=== Examples\n+\n+*Input*\n+\n+Create a ConfigSet named 'myConfigSet' based on a 'predefinedTemplate' ConfigSet, overriding the immutable property to false.\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/configs?action=CREATE&name=myConfigSet&baseConfigSet=predefinedTemplate&configSetProp.immutable=false\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">323</int>\n+  </lst>\n+</response>\n+----\n+\n+[[ConfigSetsAPI-deleteDeleteaConfigSet]]\n+\n+[[ConfigSetsAPI-delete]]\n+== Delete a ConfigSet\n+\n+`/admin/configs?action=DELETE&name=_name_`\n+\n+Delete a ConfigSet\n+\n+[[ConfigSetsAPI-Input.1]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,10,15,40\",options=\"header\"]\n+|===\n+|Key |Type |Required |Default |Description\n+|name |String |Yes | |ConfigSet to be deleted\n+|===\n+\n+[[ConfigSetsAPI-Output.1]]\n+=== Output\n+\n+*Output Content*\n+\n+The output will include the status of the request. If the status is anything other than \"success\", an error message will explain why the request failed.\n+\n+[[ConfigSetsAPI-Examples.1]]\n+=== Examples\n+\n+*Input*\n+\n+Delete ConfigSet 'myConfigSet'\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/configs?action=DELETE&name=myConfigSet\n+----\n+\n+*Output*\n+\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">170</int>\n+  </lst>\n+</response>\n+----\n+\n+[[ConfigSetsAPI-listListConfigSets]]\n+\n+[[ConfigSetsAPI-list]]\n+== List ConfigSets\n+\n+`/admin/configs?action=LIST`\n+\n+Fetch the names of the ConfigSets in the cluster.\n+\n+[[ConfigSetsAPI-Examples.2]]\n+=== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/admin/configs?action=LIST&wt=json\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":203},\n+  \"configSets\":[\"myConfigSet1\",\n+    \"myConfig2\"]}\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configsets-api.adoc",
                "sha": "505fcbe58e1a4c6c7b938385c28dd422ef9913dd",
                "status": "added"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuration-apis.adoc",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/configuration-apis.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/configuration-apis.adoc",
                "patch": "@@ -0,0 +1,11 @@\n+= Configuration APIs\n+:page-shortname: configuration-apis\n+:page-permalink: configuration-apis.html\n+:page-children: blob-store-api, config-api, request-parameters-api, managed-resources\n+\n+Solr includes several APIs that can be used to modify settings in `solrconfig.xml`.\n+\n+* <<blob-store-api.adoc#blob-store-api,Blob Store API>>\n+* <<config-api.adoc#config-api,Config API>>\n+* <<request-parameters-api.adoc#request-parameters-api,Request Parameters API>>\n+* <<managed-resources.adoc#managed-resources,Managed Resources>>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuration-apis.adoc",
                "sha": "dcbcbe107573ab3443177583932ae15800237c9c",
                "status": "added"
            },
            {
                "additions": 110,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuring-logging.adoc",
                "changes": 110,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/configuring-logging.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/configuring-logging.adoc",
                "patch": "@@ -0,0 +1,110 @@\n+= Configuring Logging\n+:page-shortname: configuring-logging\n+:page-permalink: configuring-logging.html\n+\n+Solr logs are a key way to know what's happening in the system. There are several ways to adjust the default logging configuration.\n+\n+[IMPORTANT]\n+====\n+In addition to the logging options described below, there is a way to configure which request parameters (such as parameters sent as part of queries) are logged with an additional request parameter called `logParamsList`. See the section on <<common-query-parameters.adoc#CommonQueryParameters-ThelogParamsListParameter,Common Query Parameters>> for more information.\n+====\n+\n+[[ConfiguringLogging-TemporaryLoggingSettings]]\n+== Temporary Logging Settings\n+\n+You can control the amount of logging output in Solr by using the Admin Web interface. Select the *LOGGING* link. Note that this page only lets you change settings in the running system and is not saved for the next run. (For more information about the Admin Web interface, see <<using-the-solr-administration-user-interface.adoc#using-the-solr-administration-user-interface,Using the Solr Administration User Interface>>.)\n+\n+.The Logging Screen\n+image::images/logging/logging.png[image]\n+\n+This part of the Admin Web interface allows you to set the logging level for many different log categories. Fortunately, any categories that are *unset* will have the logging level of its parent. This makes it possible to change many categories at once by adjusting the logging level of their parent.\n+\n+When you select **Level**, you see the following menu:\n+\n+.The Log Level Menu\n+image::images/logging/level_menu.png[image,width=1159,height=577]\n+\n+Directories are shown with their current logging levels. The Log Level Menu floats over these. To set a log level for a particular directory, select it and click the appropriate log level button.\n+\n+Log levels settings are as follows:\n+\n+[width=\"100%\",options=\"header\",]\n+|===\n+|Level |Result\n+|FINEST |Reports everything.\n+|FINE |Reports everything but the least important messages.\n+|CONFIG |Reports configuration errors.\n+|INFO |Reports everything but normal status.\n+|WARN |Reports all warnings.\n+|SEVERE |Reports only the most severe warnings.\n+|OFF |Turns off logging.\n+|UNSET |Removes the previous log setting.\n+|===\n+\n+Multiple settings at one time are allowed.\n+\n+[[ConfiguringLogging-LoglevelAPI]]\n+=== Log level API\n+\n+There is also a way of sending REST commands to the logging endpoint to do the same. Example:\n+\n+[source,bash]\n+----\n+# Set the root logger to level WARN\n+curl -s http://localhost:8983/solr/admin/info/logging --data-binary \"set=root:WARN&wt=json\"\n+----\n+\n+[[ConfiguringLogging-ChoosingLogLevelatStartup]]\n+== Choosing Log Level at Startup\n+\n+You can temporarily choose a different logging level as you start Solr. There are two ways:\n+\n+The first way is to set the `SOLR_LOG_LEVEL` environment variable before you start Solr, or place the same variable in `bin/solr.in.sh` or `bin/solr.in.cmd`. The variable must contain an uppercase string with a supported log level (see above).\n+\n+The second way is to start Solr with the -v or -q options, see <<solr-control-script-reference.adoc#solr-control-script-reference,Solr Control Script Reference>> for details. Examples:\n+\n+[source,bash]\n+----\n+# Start with verbose (DEBUG) looging\n+bin/solr start -f -v\n+# Start with quiet (WARN) logging\n+bin/solr start -f -q\n+----\n+\n+[[ConfiguringLogging-PermanentLoggingSettings]]\n+== Permanent Logging Settings\n+\n+Solr uses http://logging.apache.org/log4j/1.2/[Log4J version 1.2] for logging which is configured using `server/resources/log4j.properties`. Take a moment to inspect the contents of the `log4j.properties` file so that you are familiar with its structure. By default, Solr log messages will be written to `SOLR_LOGS_DIR/solr.log`.\n+\n+When you're ready to deploy Solr in production, set the variable `SOLR_LOGS_DIR` to the location where you want Solr to write log files, such as `/var/solr/logs`. You may also want to tweak `log4j.properties`. Note that if you installed Solr as a service using the instructions provided in <<taking-solr-to-production.adoc#taking-solr-to-production,Taking Solr to Production>>, then see `/var/solr/log4j.properties` instead of the default `server/resources` version.\n+\n+When starting Solr in the foreground (`-f` option), all logs will be sent to the console, in addition to `solr.log`. When starting Solr in the background, it will write all `stdout` and `stderr` output to a log file in `solr-<port>-console.log`, and automatically disable the CONSOLE logger configured in `log4j.properties`, having the same effect as if you removed the CONSOLE appender from the rootLogger manually.\n+\n+Also, in `log4j.properties` the default log rotation size threshold of 4MB is most likely too small for production servers and should be increased to a larger value (such as 100MB or more).\n+\n+[source,text]\n+----\n+log4j.appender.file.MaxFileSize=100MB\n+----\n+\n+Java Garbage Collection logs are rotated by the JVM when size hits 20M, for a max of 9 generations. Old GC logs are moved to `SOLR_LOGS_DIR/archived`. These settings can only be changed by editing the start scripts.\n+\n+On every startup of Solr, the start script will clean up old logs and rotate the main `solr.log` file. If you changed the `log4j.appender.file.MaxBackupIndex` setting in `log4j.properties`, you also need to change the corresponding setting `-rotate_solr_logs 9` in the start script.\n+\n+You can disable the automatic log rotation at startup by changing the setting `SOLR_LOG_PRESTART_ROTATION` found in `bin/solr.in.sh` or `bin/solr.in.cmd` to false.\n+\n+[[ConfiguringLogging-LoggingSlowQueries]]\n+== Logging Slow Queries\n+\n+For high-volume search applications, logging every query can generate a large amount of logs and, depending on the volume, potentially impact performance. If you mine these logs for additional insights into your application, then logging every query request may be useful.\n+\n+On the other hand, if you're only concerned about warnings and error messages related to requests, then you can set the log verbosity to WARN. However, this poses a potential problem in that you won't know if any queries are slow, as slow queries are still logged at the INFO level.\n+\n+Solr provides a way to set your log verbosity threshold to WARN and be able to set a latency threshold above which a request is considered \"slow\" and log that request at the WARN level to help you identify slow queries in your application. To enable this behavior, configure the `<slowQueryThresholdMillis>` element in the *query* section of solrconfig.xml:\n+\n+[source,xml]\n+----\n+<slowQueryThresholdMillis>1000</slowQueryThresholdMillis>\n+----\n+\n+Any queries that take longer than the specified threshold will be logged as \"slow\" queries at the WARN level.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuring-logging.adoc",
                "sha": "47fe649e310a9e23511252a09328f4c932dcb26d",
                "status": "added"
            },
            {
                "additions": 155,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuring-solrconfig-xml.adoc",
                "changes": 155,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/configuring-solrconfig-xml.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/configuring-solrconfig-xml.adoc",
                "patch": "@@ -0,0 +1,155 @@\n+= Configuring solrconfig.xml\n+:page-shortname: configuring-solrconfig-xml\n+:page-permalink: configuring-solrconfig-xml.html\n+:page-children: datadir-and-directoryfactory-in-solrconfig, lib-directives-in-solrconfig, schema-factory-definition-in-solrconfig, indexconfig-in-solrconfig, requesthandlers-and-searchcomponents-in-solrconfig, initparams-in-solrconfig, updatehandlers-in-solrconfig, query-settings-in-solrconfig, requestdispatcher-in-solrconfig, update-request-processors, codec-factory\n+\n+The `solrconfig.xml` file is the configuration file with the most parameters affecting Solr itself.\n+\n+While configuring Solr, you'll work with `solrconfig.xml` often, either directly or via the <<config-api.adoc#config-api,Config API>> to create \"configuration overlays\" (`configoverlay.json`) to override the values in `solrconfig.xml`.\n+\n+In `solrconfig.xml`, you configure important features such as:\n+\n+* request handlers, which process the requests to Solr, such as requests to add documents to the index or requests to return results for a query\n+\n+* listeners, processes that \"listen\" for particular query-related events; listeners can be used to trigger the execution of special code, such as invoking some common queries to warm-up caches\n+\n+* the Request Dispatcher for managing HTTP communications\n+\n+* the Admin Web interface\n+\n+* parameters related to replication and duplication (these parameters are covered in detail in <<legacy-scaling-and-distribution.adoc#legacy-scaling-and-distribution,Legacy Scaling and Distribution>>)\n+\n+The `solrconfig.xml` file is located in the `conf/` directory for each collection. Several well-commented example files can be found in the `server/solr/configsets/` directories demonstrating best practices for many different types of installations.\n+\n+We've covered the options in the following sections:\n+\n+* <<datadir-and-directoryfactory-in-solrconfig.adoc#datadir-and-directoryfactory-in-solrconfig,DataDir and DirectoryFactory in SolrConfig>>\n+* <<lib-directives-in-solrconfig.adoc#lib-directives-in-solrconfig,Lib Directives in SolrConfig>>\n+* <<schema-factory-definition-in-solrconfig.adoc#schema-factory-definition-in-solrconfig,Schema Factory Definition in SolrConfig>>\n+* <<indexconfig-in-solrconfig.adoc#indexconfig-in-solrconfig,IndexConfig in SolrConfig>>\n+* <<requesthandlers-and-searchcomponents-in-solrconfig.adoc#requesthandlers-and-searchcomponents-in-solrconfig,RequestHandlers and SearchComponents in SolrConfig>>\n+* <<initparams-in-solrconfig.adoc#initparams-in-solrconfig,InitParams in SolrConfig>>\n+* <<updatehandlers-in-solrconfig.adoc#updatehandlers-in-solrconfig,UpdateHandlers in SolrConfig>>\n+* <<query-settings-in-solrconfig.adoc#query-settings-in-solrconfig,Query Settings in SolrConfig>>\n+* <<requestdispatcher-in-solrconfig.adoc#requestdispatcher-in-solrconfig,RequestDispatcher in SolrConfig>>\n+* <<update-request-processors.adoc#update-request-processors,Update Request Processors>>\n+* <<codec-factory.adoc#codec-factory,Codec Factory>>\n+\n+[[Configuringsolrconfig.xml-SubstitutingPropertiesinSolrConfigFiles]]\n+== Substituting Properties in Solr Config Files\n+\n+Solr supports variable substitution of property values in config files, which allows runtime specification of various configuration options in `solrconfig.xml`. The syntax is `${propertyname[:option default value]`}. This allows defining a default that can be overridden when Solr is launched. If a default value is not specified, then the property _must_ be specified at runtime or the configuration file will generate an error when parsed.\n+\n+There are multiple methods for specifying properties that can be used in configuration files. Of those below, strongly consider \"config overlay\" as the preferred approach, as it stays local to the config set and because it's easy to modify.\n+\n+[[Configuringsolrconfig.xml-JVMSystemProperties]]\n+=== JVM System Properties\n+\n+Any JVM System properties, usually specified using the `-D` flag when starting the JVM, can be used as variables in any XML configuration file in Solr.\n+\n+For example, in the sample `solrconfig.xml` files, you will see this value which defines the locking type to use:\n+\n+[source,xml]\n+----\n+<lockType>${solr.lock.type:native}</lockType>\n+----\n+\n+Which means the lock type defaults to \"native\" but when starting Solr, you could override this using a JVM system property by launching the Solr it with:\n+\n+[source,bash]\n+----\n+bin/solr start -Dsolr.lock.type=none\n+----\n+\n+In general, any Java system property that you want to set can be passed through the `bin/solr` script using the standard `-Dproperty=value` syntax. Alternatively, you can add common system properties to the `SOLR_OPTS` environment variable defined in the Solr include file (`bin/solr.in.sh` or `bin/solr.in.cmd`). For more information about how the Solr include file works, refer to: <<taking-solr-to-production.adoc#taking-solr-to-production,Taking Solr to Production>>.\n+\n+[[Configuringsolrconfig.xml-ConfigAPI]]\n+=== Config API\n+\n+The <<config-api.adoc#config-api,Config API>> allows you to use an API to modify Solr's configuration, specifically user defined properties. Changes made with this API are stored in a file named `configoverlay.json`. This file should only be edited with the API, but will look like this example:\n+\n+[source,json]\n+----\n+{\"userProps\":{\n+    \"dih.db.url\":\"jdbc:oracle:thin:@localhost:1521\",\n+    \"dih.db.user\":\"username\",\n+    \"dih.db.pass\":\"password\"}}\n+----\n+\n+For more details, see the section <<config-api.adoc#config-api,Config API>>.\n+\n+[[Configuringsolrconfig.xml-solrcore.properties]]\n+=== solrcore.properties\n+\n+If the configuration directory for a Solr core contains a file named `solrcore.properties` that file can contain any arbitrary user defined property names and values using the Java standard https://en.wikipedia.org/wiki/.properties[properties file format], and those properties can be used as variables in the XML configuration files for that Solr core.\n+\n+For example, the following `solrcore.properties` file could be created in the `conf/` directory of a collection using one of the example configurations, to override the lockType used.\n+\n+[source,bash]\n+----\n+#conf/solrcore.properties\n+solr.lock.type=none\n+----\n+\n+.Deprecation\n+[WARNING]\n+====\n+`solrcore.properties` won't work in SolrCloud mode (it is not read from ZooKeeper). This feature is likely to be removed in the future. Instead, use another mechanism like a config overlay.\n+====\n+\n+[IMPORTANT]\n+====\n+\n+The path and name of the `solrcore.properties` file can be overridden using the `properties` property in <<defining-core-properties.adoc#defining-core-properties,`core.properties`>>.\n+\n+====\n+\n+[[Configuringsolrconfig.xml-Userdefinedpropertiesfromcore.properties]]\n+=== User-Defined Properties in `core.properties`\n+\n+Every Solr core has a `core.properties` file, automatically created when using the APIs. When you create a SolrCloud collection, you can pass through custom parameters to go into each core.properties that will be created, by prefixing the parameter name with \"property.\" as a URL parameter. Example:\n+\n+http://localhost:8983/solr/admin/collections?action=CREATE&name=gettingstarted&numShards=1&property.my.custom.prop=edismax\n+\n+That would create a `core.properties` file that has at least the following properties (others omitted for brevity):\n+\n+[source,bash]\n+----\n+#core.properties\n+name=gettingstarted\n+my.custom.prop=edismax\n+----\n+\n+The `my.custom.prop` property can then be used as a variable, such as in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/select\">\n+  <lst name=\"defaults\">\n+    <str name=\"defType\">${my.custom.prop}</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+[[Configuringsolrconfig.xml-ImplicitCoreProperties]]\n+=== Implicit Core Properties\n+\n+Several attributes of a Solr core are available as \"implicit\" properties that can be used in variable substitution, independent of where or how they underlying value is initialized. For example: regardless of whether the name for a particular Solr core is explicitly configured in `core.properties` or inferred from the name of the instance directory, the implicit property `solr.core.name` is available for use as a variable in that core's configuration file...\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/select\">\n+  <lst name=\"defaults\">\n+    <str name=\"collection_name\">${solr.core.name}</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+All implicit properties use the `solr.core.` name prefix, and reflect the runtime value of the equivalent <<defining-core-properties.adoc#defining-core-properties,`core.properties` property>>:\n+\n+* `solr.core.name`\n+* `solr.core.config`\n+* `solr.core.schema`\n+* `solr.core.dataDir`\n+* `solr.core.transient`\n+* `solr.core.loadOnStartup`",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/configuring-solrconfig-xml.adoc",
                "sha": "4c2b88cd8dbfdbae84ce644fee7488f50bd5fa0a",
                "status": "added"
            },
            {
                "additions": 48,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/content-streams.adoc",
                "changes": 48,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/content-streams.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/content-streams.adoc",
                "patch": "@@ -0,0 +1,48 @@\n+= Content Streams\n+:page-shortname: content-streams\n+:page-permalink: content-streams.html\n+\n+Content streams are bulk data passed with a request to Solr.\n+\n+When Solr RequestHandlers are accessed using path based URLs, the `SolrQueryRequest` object containing the parameters of the request may also contain a list of ContentStreams containing bulk data for the request. (The name SolrQueryRequest is a bit misleading: it is involved in all requests, regardless of whether it is a query request or an update request.)\n+\n+[[ContentStreams-StreamSources]]\n+== Stream Sources\n+\n+Currently request handlers can get content streams in a variety of ways:\n+\n+* For multipart file uploads, each file is passed as a stream.\n+* For POST requests where the content-type is not `application/x-www-form-urlencoded`, the raw POST body is passed as a stream. The full POST body is parsed as parameters and included in the Solr parameters.\n+* The contents of parameter `stream.body` is passed as a stream.\n+* If remote streaming is enabled and URL content is called for during request handling, the contents of each `stream.url` and `stream.file` parameters are fetched and passed as a stream.\n+\n+By default, curl sends a `contentType=\"application/x-www-form-urlencoded\"` header. If you need to test a SolrContentHeader content stream, you will need to set the content type with curl's `-H` flag.\n+\n+[[ContentStreams-RemoteStreaming]]\n+== RemoteStreaming\n+\n+Remote streaming lets you send the contents of a URL as a stream to a given SolrRequestHandler. You could use remote streaming to send a remote or local file to an update plugin.\n+\n+For convenience, remote streaming is enabled in most of the example `solrconfig.xml` files included with Solr, however it is not recommended in a production situation without additional security between you and untrusted remote clients.\n+\n+[source,xml]\n+----\n+    <!-- *** WARNING ***\n+         The settings below authorize Solr to fetch remote files, You\n+         should make sure your system has some authentication before\n+         using enableRemoteStreaming=\"true\"\n+      -->\n+    <requestParsers enableRemoteStreaming=\"true\" />\n+----\n+\n+The default behavior, when `enableRemoteStreaming` is not specified in `solrconfig.xml` is to _not_ allow remote streaming (i.e., `enableRemoteStreaming=\"false\"`).\n+\n+[IMPORTANT]\n+====\n+If you `enableRemoteStreaming=\"true\"` is used, be aware that this allows _anyone_ to send a request to any URL or local file. If <<ContentStreams-DebuggingRequests,DumpRequestHandler>> is enabled, it will allow anyone to view any file on your system.\n+====\n+\n+[[ContentStreams-DebuggingRequests]]\n+== Debugging Requests\n+\n+The implicit \"dump\" RequestHandler (see <<implicit-requesthandlers.adoc#implicit-requesthandlers,Implicit RequestHandlers>>) simply outputs the contents of the SolrQueryRequest using the specified writer type `wt`. This is a useful tool to help understand what streams are available to the RequestHandlers.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/content-streams.adoc",
                "sha": "f26467a80f6e34ac38cd2829e3b46decc266e662",
                "status": "added"
            },
            {
                "additions": 40,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/copying-fields.adoc",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/copying-fields.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/copying-fields.adoc",
                "patch": "@@ -0,0 +1,40 @@\n+= Copying Fields\n+:page-shortname: copying-fields\n+:page-permalink: copying-fields.html\n+\n+You might want to interpret some document fields in more than one way. Solr has a mechanism for making copies of fields so that you can apply several distinct field types to a single piece of incoming information.\n+\n+The name of the field you want to copy is the _source_, and the name of the copy is the _destination_. In `schema.xml`, it's very simple to make copies of fields:\n+\n+[source,xml]\n+----\n+<copyField source=\"cat\" dest=\"text\" maxChars=\"30000\" />\n+----\n+\n+In this example, we want Solr to copy the `cat` field to a field named `text`. Fields are copied before <<understanding-analyzers-tokenizers-and-filters.adoc#understanding-analyzers-tokenizers-and-filters,analysis>> is done, meaning you can have two fields with identical original content, but which use different analysis chains and are stored in the index differently.\n+\n+In the example above, if the `text` destination field has data of its own in the input documents, the contents of the `cat` field will be added as additional values \u2013 just as if all of the values had originally been specified by the client. Remember to configure your fields as `multivalued=\"true\"` if they will ultimately get multiple values (either from a multivalued source or from multiple `copyField` directives).\n+\n+A common usage for this functionality is to create a single \"search\" field that will serve as the default query field when users or clients do not specify a field to query. For example, `title`, `author`, `keywords`, and `body` may all be fields that should be searched by default, with copy field rules for each field to copy to a `catchall` field (for example, it could be named anything). Later you can set a rule in `solrconfig.xml` to search the `catchall` field by default. One caveat to this is your index will grow when using copy fields. However, whether this becomes problematic for you and the final size will depend on the number of fields being copied, the number of destination fields being copied to, the analysis in use, and the available disk space.\n+\n+The `maxChars` parameter, an `int` parameter, establishes an upper limit for the number of characters to be copied from the source value when constructing the value added to the destination field. This limit is useful for situations in which you want to copy some data from the source field, but also control the size of index files.\n+\n+Both the source and the destination of `copyField` can contain either leading or trailing asterisks, which will match anything. For example, the following line will copy the contents of all incoming fields that match the wildcard pattern `*_t` to the text field.:\n+\n+[source,xml]\n+----\n+<copyField source=\"*_t\" dest=\"text\" maxChars=\"25000\" />\n+----\n+\n+[IMPORTANT]\n+====\n+The `copyField` command can use a wildcard (*) character in the `dest` parameter only if the `source` parameter contains one as well. `copyField` uses the matching glob from the source field for the `dest` field name into which the source content is copied.\n+====\n+\n+Copying is done at the stream source level and no copy feeds into another copy. This means that copy fields cannot be chained i.e. _you cannot_ copy from `here` to `there` and then from `there` to `elsewhere`. However, the same source field can be copied to multiple destination fields:\n+\n+[source,xml]\n+----\n+<copyField source=\"here\" dest=\"there\"/>\n+<copyField source=\"here\" dest=\"elsewhere\"/>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/copying-fields.adoc",
                "sha": "af02df039571e085e83991fa0064b0fc7d55df1e",
                "status": "added"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/core-specific-tools.adoc",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/core-specific-tools.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/core-specific-tools.adoc",
                "patch": "@@ -0,0 +1,36 @@\n+= Core-Specific Tools\n+:page-shortname: core-specific-tools\n+:page-permalink: core-specific-tools.html\n+:page-children: ping, plugins-stats-screen, replication-screen, segments-info\n+\n+The Core-Specific tools are a group of UI screens that allow you to see core-level information.\n+\n+In the left-hand navigation bar, you will see a pull-down menu titled \"Core Selector\". Clicking on the menu will show a list of Solr cores hosted on this Solr node, with a search box that can be used to find a specific core by name.\n+\n+When you select a core from the pull-down, the main display of the page will show some basic metadata about the core, and a secondary menu will appear in the left nav with links to additional core specific administration screens.\n+\n+You can also define a configuration file called `admin-extra.html` that includes links or other information you would like to display in the \"Admin Extra\" part of this main screen.\n+\n+.Core overview screen\n+image::images/core-specific-tools/core_dashboard.png[image,width=515,height=250]\n+\n+The core-specific UI screens are listed below, with a link to the section of this guide to find out more:\n+\n+// TODO: SOLR-10655 BEGIN: refactor this into a 'core-screens-list.include.adoc' file for reuse\n+* <<ping.adoc#ping,Ping>> - lets you ping a named core and determine whether the core is active.\n+* <<plugins-stats-screen.adoc#plugins-stats-screen,Plugins/Stats>> - shows statistics for plugins and other installed components.\n+* <<replication-screen.adoc#replication-screen,Replication>> - shows you the current replication status for the core, and lets you enable/disable replication.\n+* <<segments-info.adoc#segments-info,Segments Info>> - Provides a visualization of the underlying Lucene index segments.\n+// TODO: SOLR-10655 END\n+\n+If you are running a single node instance of Solr, additional UI screens normally displayed on a per-collection bases will also be listed:\n+\n+// TODO: SOLR-10655 BEGIN: refactor this into a 'collection-screens-list.include.adoc' file for reuse\n+* <<analysis-screen.adoc#analysis-screen,Analysis>> - lets you analyze the data found in specific fields.\n+* <<dataimport-screen.adoc#dataimport-screen,Dataimport>> - shows you information about the current status of the Data Import Handler.\n+* <<documents-screen.adoc#documents-screen,Documents>> - provides a simple form allowing you to execute various Solr indexing commands directly from the browser.\n+* <<files-screen.adoc#files-screen,Files>> - shows the current core configuration files such as `solrconfig.xml`.\n+* <<query-screen.adoc#query-screen,Query>> - lets you submit a structured query about various elements of a core.\n+* <<stream-screen.adoc#stream-screen,Stream>> - allows you to submit streaming expressions and see results and parsing explanations.\n+* <<schema-browser-screen.adoc#schema-browser-screen,Schema Browser>> - displays schema data in a browser window.\n+// TODO: SOLR-10655 END",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/core-specific-tools.adoc",
                "sha": "54144c53825a7a07e7f01894bf58437b1c0af92e",
                "status": "added"
            },
            {
                "additions": 353,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/coreadmin-api.adoc",
                "changes": 353,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/coreadmin-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/coreadmin-api.adoc",
                "patch": "@@ -0,0 +1,353 @@\n+= CoreAdmin API\n+:page-shortname: coreadmin-api\n+:page-permalink: coreadmin-api.html\n+\n+The Core Admin API is primarily used under the covers by the <<collections-api.adoc#collections-api,Collections API>> when running a <<solrcloud.adoc#solrcloud,SolrCloud>> cluster.\n+\n+SolrCloud users should not typically use the CoreAdmin API directly, but the API may be useful for users of single-node or master/slave Solr installations for core maintenance operations.\n+\n+The CoreAdmin API is implemented by the CoreAdminHandler, which is a special purpose <<requesthandlers-and-searchcomponents-in-solrconfig.adoc#requesthandlers-and-searchcomponents-in-solrconfig,request handler>> that is used to manage Solr cores. Unlike other request handlers, the CoreAdminHandler is not attached to a single core. Instead, there is a single instance of the CoreAdminHandler in each Solr node that manages all the cores running in that node and is accessible at the `/solr/admin/cores` path.\n+\n+CoreAdmin actions can be executed by via HTTP requests that specify an `action` request parameter, with additional action specific arguments provided as additional parameters.\n+\n+All action names are uppercase, and are defined in depth in the sections below.\n+\n+[[CoreAdminAPI-STATUS]]\n+== STATUS\n+\n+The `STATUS` action returns the status of all running Solr cores, or status for only the named core.\n+\n+`admin/cores?action=STATUS&core=_core-name_`\n+\n+[[CoreAdminAPI-Input]]\n+=== *Input*\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |No | |The name of a core, as listed in the \"name\" attribute of a `<core>` element in `solr.xml`.\n+|indexInfo |boolean |No |true |If **false**, information about the index will not be returned with a core STATUS request. In Solr implementations with a large number of cores (i.e., more than hundreds), retrieving the index information for each core can take a lot of time and isn't always required.\n+|===\n+\n+[[CoreAdminAPI-CREATE]]\n+== CREATE\n+\n+The `CREATE` action creates a new core and registers it.\n+\n+If a Solr core with the given name already exists, it will continue to handle requests while the new core is initializing. When the new core is ready, it will take new requests and the old core will be unloaded.\n+\n+`admin/cores?action=CREATE&name=_core-name_&instanceDir=_path/to/dir_&config=solrconfig.xml&dataDir=data`\n+\n+Note that this command is the only one of the Core Admin API commands that *does not* support the `core` parameter. Instead, the `name` parameter is required, as shown below.\n+\n+.CREATE must be able to find a configuration!\n+[WARNING]\n+====\n+Your CREATE call must be able to find a configuration, or it will not succeed.\n+\n+When you are running SolrCloud and create a new core for a collection, the configuration will be inherited from the collection. Each collection is linked to a configName, which is stored in the ZooKeeper database. This satisfies the config requirement. There is something to note, though \u2013 if you're running SolrCloud, you should *NOT* be using the CoreAdmin API at all. Use the Collections API.\n+\n+When you are not running SolrCloud, if you have <<config-sets.adoc#config-sets,Config Sets>> defined, you can use the configSet parameter as documented below. If there are no config sets, then the instanceDir specified in the CREATE call must already exist, and it must contain a `conf` directory which in turn must contain `solrconfig.xml`, your schema, which is usually named either `managed-schema` or `schema.xml`, and any files referenced by those configs.\n+\n+The config and schema filenames can be specified with the config and schema parameters, but these are expert options. One thing you could do to avoid creating the conf directory is use config and schema parameters that point at absolute paths, but this can lead to confusing configurations unless you fully understand what you are doing.\n+====\n+\n+.CREATE and the core.properties file\n+[IMPORTANT]\n+====\n+The core.properties file is built as part of the CREATE command. If you create a core.properties file yourself in a core directory and then try to use CREATE to add that core to Solr, you will get an error telling you that another core is already defined there. The core.properties file must NOT exist before calling the CoreAdmin API with the CREATE command.\n+====\n+\n+[[CoreAdminAPI-Input.1]]\n+=== *Input*\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|name |string |Yes |N/A |The name of the new core. Same as \"name\" on the `<core>` element.\n+|instanceDir |string |No |The value specified for \"name\" parameter |The directory where files for this SolrCore should be stored. Same as `instanceDir` on the `<core>` element.\n+|config |string |No | |Name of the config file (i.e., `solrconfig.xml`) relative to `instanceDir`.\n+|schema |string |No | |Name of the schema file to use for the core. Please note that if you are using a \"managed schema\" (the default behavior) then any value for this property which does not match the effective `managedSchemaResourceName` will be read once, backed up, and converted for managed schema use. See <<schema-factory-definition-in-solrconfig.adoc#schema-factory-definition-in-solrconfig,Schema Factory Definition in SolrConfig>> for details.\n+|dataDir |string |No | |Name of the data directory relative to `instanceDir`.\n+|configSet |string |No | |Name of the configset to use for this core. For more information, see the section <<config-sets.adoc#config-sets,Config Sets>>.\n+|collection |string |No | |The name of the collection to which this core belongs. The default is the name of the core. `collection.<param>=<value>` causes a property of `<param>=<value>` to be set if a new collection is being created. Use `collection.configName=<configname>` to point to the configuration for a new collection.\n+|shard |string |No | |The shard id this core represents. Normally you want to be auto-assigned a shard id.\n+|property.__name__=__value__ |string |No | |Sets the core property _name_ to __value__. See the section on defining <<defining-core-properties.adoc#Definingcore.properties-core.properties_files,core.properties file contents>>.\n+|async |string |No | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+Use `collection.configName=<configname>` to point to the config for a new collection.\n+\n+[[CoreAdminAPI-Example]]\n+=== Example\n+\n+`\\http://localhost:8983/solr/admin/cores?action=CREATE&name=my_core&collection=my_collection&shard=shard2`\n+\n+[WARNING]\n+====\n+While it's possible to create a core for a non-existent collection, this approach is not supported and not recommended. Always create a collection using the <<collections-api.adoc#collections-api,Collections API>> before creating a core directly for it.\n+====\n+\n+[[CoreAdminAPI-RELOAD]]\n+== RELOAD\n+\n+The RELOAD action loads a new core from the configuration of an existing, registered Solr core. While the new core is initializing, the existing one will continue to handle requests. When the new Solr core is ready, it takes over and the old core is unloaded.\n+\n+`admin/cores?action=RELOAD&core=_core-name_`\n+\n+This is useful when you've made changes to a Solr core's configuration on disk, such as adding new field definitions. Calling the RELOAD action lets you apply the new configuration without having to restart the Web container.\n+\n+[IMPORTANT]\n+====\n+RELOAD performs \"live\" reloads of SolrCore, reusing some existing objects. Some configuration options, such as the `dataDir` location and `IndexWriter`-related settings in `solrconfig.xml` can not be changed and made active with a simple RELOAD action.\n+====\n+\n+[[CoreAdminAPI-Input.2]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes |N/A |The name of the core, as listed in the \"name\" attribute of a `<core>` element in `solr.xml`.\n+|===\n+\n+[[CoreAdminAPI-RENAME]]\n+== RENAME\n+\n+The `RENAME` action changes the name of a Solr core.\n+\n+`admin/cores?action=RENAME&core=_core-name_&other=_other-core-name_`\n+\n+[[CoreAdminAPI-Input.3]]\n+=== Input\n+\n+**Query Parameters**\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of the Solr core to be renamed.\n+|other |string |Yes | |The new name for the Solr core. If the persistent attribute of `<solr>` is `true`, the new name will be written to `solr.xml` as the `name` attribute of the `<core>` attribute.\n+|async |string |No | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+[[CoreAdminAPI-SWAP]]\n+== SWAP\n+\n+`SWAP` atomically swaps the names used to access two existing Solr cores. This can be used to swap new content into production. The prior core remains available and can be swapped back, if necessary. Each core will be known by the name of the other, after the swap.\n+\n+`admin/cores?action=SWAP&core=_core-name_&other=_other-core-name_`\n+\n+[IMPORTANT]\n+====\n+\n+Do not use `SWAP` with a SolrCloud node. It is not supported and can result in the core being unusable.\n+\n+====\n+\n+[[CoreAdminAPI-Input.4]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of one of the cores to be swapped.\n+|other |string |Yes | |The name of one of the cores to be swapped.\n+|async |string |No | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+[[CoreAdminAPI-UNLOAD]]\n+== UNLOAD\n+\n+The `UNLOAD` action removes a core from Solr. Active requests will continue to be processed, but no new requests will be sent to the named core. If a core is registered under more than one name, only the given name is removed.\n+\n+`admin/cores?action=UNLOAD&core=_core-name_`\n+\n+The `UNLOAD` action requires a parameter (`core`) identifying the core to be removed. If the persistent attribute of `<solr>` is set to `true`, the `<core>` element with this `name` attribute will be removed from `solr.xml`.\n+\n+[IMPORTANT]\n+====\n+Unloading all cores in a SolrCloud collection causes the removal of that collection's metadata from ZooKeeper.\n+====\n+\n+[[CoreAdminAPI-Input.5]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of one of the cores to be removed.\n+|deleteIndex |boolean |No |false |If true, will remove the index when unloading the core.\n+|deleteDataDir |boolean |No |false |If true, removes the `data` directory and all sub-directories.\n+|deleteInstanceDir |boolean |No |false |If true, removes everything related to the core, including the index directory, configuration files and other related files.\n+|async |string |No | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+[[CoreAdminAPI-MERGEINDEXES]]\n+== MERGEINDEXES\n+\n+The `MERGEINDEXES` action merges one or more indexes to another index. The indexes must have completed commits, and should be locked against writes until the merge is complete or the resulting merged index may become corrupted. The target core index must already exist and have a compatible schema with the one or more indexes that will be merged to it. Another commit on the target core should also be performed after the merge is complete.\n+\n+`admin/cores?action=MERGEINDEXES&core=_new-core-name_&indexDir=_path/to/core1/data/index_&indexDir=_path/to/core2/data/index_`\n+\n+In this example, we use the `indexDir` parameter to define the index locations of the source cores. The `core` parameter defines the target index. A benefit of this approach is that we can merge any Lucene-based index that may not be associated with a Solr core.\n+\n+Alternatively, we can instead use a `srcCore` parameter, as in this example:\n+\n+`admin/cores?action=mergeindexes&core=_new-core-name_&srcCore=_core1-name_&srcCore=_core2-name_`\n+\n+This approach allows us to define cores that may not have an index path that is on the same physical server as the target core. However, we can only use Solr cores as the source indexes. Another benefit of this approach is that we don't have as high a risk for corruption if writes occur in parallel with the source index.\n+\n+We can make this call run asynchronously by specifying the `async` parameter and passing a request-id. This id can then be used to check the status of the already submitted task using the REQUESTSTATUS API.\n+\n+[[CoreAdminAPI-Input.6]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of the target core/index.\n+|indexDir |string | | |Multi-valued, directories that would be merged.\n+|srcCore |string | | |Multi-valued, source cores that would be merged.\n+|async |string | | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+[[CoreAdminAPI-SPLIT]]\n+== SPLIT\n+\n+The `SPLIT` action splits an index into two or more indexes. The index being split can continue to handle requests. The split pieces can be placed into a specified directory on the server's filesystem or it can be merged into running Solr cores.\n+\n+The `SPLIT` action supports five parameters, which are described in the table below.\n+\n+[[CoreAdminAPI-Input.7]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of the core to be split.\n+|path |string | | |Multi-valued, the directory path in which a piece of the index will be written.\n+|targetCore |string | | |Multi-valued, the target Solr core to which a piece of the index will be merged\n+|ranges |string |No | |A comma-separated list of hash ranges in hexadecimal format\n+|split.key |string |No | |The key to be used for splitting the index\n+|async |string |No | |Request ID to track this action which will be processed asynchronously\n+|===\n+\n+[IMPORTANT]\n+====\n+Either `path` or `targetCore` parameter must be specified but not both. The ranges and split.key parameters are optional and only one of the two should be specified, if at all required.\n+====\n+\n+[[CoreAdminAPI-Examples]]\n+=== Examples\n+\n+The `core` index will be split into as many pieces as the number of `path` or `targetCore` parameters.\n+\n+==== Usage with two `targetCore` parameters:\n+\n+`\\http://localhost:8983/solr/admin/cores?action=SPLIT&core=core0&targetCore=core1&targetCore=core2`\n+\n+Here the `core` index will be split into two pieces and merged into the two `targetCore` indexes.\n+\n+==== Usage with two `path` parameters:\n+\n+`\\http://localhost:8983/solr/admin/cores?action=SPLIT&core=core0&path=/path/to/index/1&path=/path/to/index/2`\n+\n+The `core` index will be split into two pieces and written into the two directory paths specified.\n+\n+==== Usage with the `split.key` parameter:\n+\n+`\\http://localhost:8983/solr/admin/cores?action=SPLIT&core=core0&targetCore=core1&split.key=A!`\n+\n+Here all documents having the same route key as the `split.key` i.e. 'A!' will be split from the `core` index and written to the `targetCore`.\n+\n+==== Usage with `ranges` parameter:\n+\n+`\\http://localhost:8983/solr/admin/cores?action=SPLIT&core=core0&targetCore=core1&targetCore=core2&targetCore=core3&ranges=0-1f4,1f5-3e8,3e9-5dc`\n+\n+This example uses the `ranges` parameter with hash ranges 0-500, 501-1000 and 1001-1500 specified in hexadecimal. Here the index will be split into three pieces with each targetCore receiving documents matching the hash ranges specified i.e. core1 will get documents with hash range 0-500, core2 will receive documents with hash range 501-1000 and finally, core3 will receive documents with hash range 1001-1500. At least one hash range must be specified. Please note that using a single hash range equal to a route key's hash range is NOT equivalent to using the `split.key` parameter because multiple route keys can hash to the same range.\n+\n+The `targetCore` must already exist and must have a compatible schema with the `core` index. A commit is automatically called on the `core` index before it is split.\n+\n+This command is used as part of the <<collections-api.adoc#CollectionsAPI-splitshard,SPLITSHARD>> command but it can be used for non-cloud Solr cores as well. When used against a non-cloud core without `split.key` parameter, this action will split the source index and distribute its documents alternately so that each split piece contains an equal number of documents. If the `split.key` parameter is specified then only documents having the same route key will be split from the source index.\n+\n+[[CoreAdminAPI-REQUESTSTATUS]]\n+== REQUESTSTATUS\n+\n+Request the status of an already submitted asynchronous CoreAdmin API call.\n+\n+`admin/cores?action=REQUESTSTATUS&requestid=_id_`\n+\n+[[CoreAdminAPI-Input.8]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|requestid |string |Yes | |The user defined request-id for the Asynchronous request.\n+|===\n+\n+The call below will return the status of an already submitted Asynchronous CoreAdmin call.\n+\n+`\\http://localhost:8983/solr/admin/cores?action=REQUESTSTATUS&requestid=1`\n+\n+[[CoreAdminAPI-REQUESTRECOVERY]]\n+== REQUESTRECOVERY\n+\n+The `REQUESTRECOVERY` action manually asks a core to recover by synching with the leader. This should be considered an \"expert\" level command and should be used in situations where the node (SorlCloud replica) is unable to become active automatically.\n+\n+`admin/cores?action=REQUESTRECOVERY&core=_core-name_`\n+\n+[[CoreAdminAPI-Input.9]]\n+=== Input\n+\n+*Query Parameters*\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,10,10,10,55\",options=\"header\"]\n+|===\n+|Parameter |Type |Required |Default |Description\n+|core |string |Yes | |The name of the core to re-sync.\n+|===\n+\n+[[CoreAdminAPI-Examples.1]]\n+=== Examples\n+\n+`\\http://localhost:8981/solr/admin/cores?action=REQUESTRECOVERY&core=gettingstarted_shard1_replica1`\n+\n+The core to specify can be found by expanding the appropriate ZooKeeper node via the admin UI.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/coreadmin-api.adoc",
                "sha": "4cd71470355914bcf184c84f2676fe1c8596d406",
                "status": "added"
            },
            {
                "additions": 761,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/cross-data-center-replication-cdcr.adoc",
                "changes": 761,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/cross-data-center-replication-cdcr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/cross-data-center-replication-cdcr.adoc",
                "patch": "@@ -0,0 +1,761 @@\n+= Cross Data Center Replication (CDCR)\n+:page-shortname: cross-data-center-replication-cdcr\n+:page-permalink: cross-data-center-replication-cdcr.html\n+\n+Cross Data Center Replication (CDCR) allows you to create multiple SolrCloud data centers and keep them in sync in case they are needed at a future time.\n+\n+The <<solrcloud.adoc#solrcloud,SolrCloud>> architecture is not particularly well suited for situations where a single SolrCloud cluster consists of nodes in separated data clusters connected by an expensive pipe. The root problem is that SolrCloud is designed to support <<near-real-time-searching.adoc#near-real-time-searching,Near Real Time Searching>> by immediately forwarding updates between nodes in the cluster on a per-shard basis. \"CDCR\" features exist to help mitigate the risk of an entire data center outage.\n+\n+== What is CDCR?\n+\n+CDCR supports replicating data from one data center to multiple data centers. The initial version of the solution supports an active-passive scenario where data updates are replicated from a Source data center to one or more target data centers.\n+\n+The target data center(s) will not propagate updates such as adds, updates, or deletes to the source data center and updates should _not_ be sent to any of the target data center(s).\n+\n+Source and target data centers can serve search queries when CDCR is operating. The target data centers will have slightly stale views of the corpus due to propagation delays, but this is minimal (perhaps a few seconds).\n+\n+Data changes on the source data center are replicated to the target data center only after they are persisted to disk. The data changes can be replicated in near real-time (with a small delay) or could be scheduled to be sent in intervals to the target data center. This solution pre-supposes that the source and target data centers begin with the same documents indexed. Of course the indexes may be empty to start.\n+\n+Each shard leader in the source data center will be responsible for replicating its updates to the corresponding leader in the target data center. When receiving updates from the source data center, shard leaders in the target data center will replicate the changes to their own replicas.\n+\n+This replication model is designed to tolerate some degradation in connectivity, accommodate limited bandwidth, and support batch updates to optimize communication.\n+\n+Replication supports both a new empty index and pre-built indexes. In the scenario where the replication is set up on a pre-built index, CDCR will ensure consistency of the replication of the updates, but cannot ensure consistency on the full index. Therefore any index created before CDCR was set up will have to be replicated by other means (described in the section <<Initial Startup>>) so source and target indexes are fully consistent.\n+\n+The active-passive nature of the initial implementation implies a \"push\" model from the source collection to the target collection. Therefore, the source configuration must be able to \"see\" the ZooKeeper ensemble in the target cluster. The ZooKeeper ensemble is provided configured in the Source's `solrconfig.xml` file.\n+\n+CDCR is configured to replicate from collections in the source cluster to collections in the target cluster on a collection-by-collection basis. Since CDCR is configured in `solrconfig.xml` (on both source and target clusters), the settings can be tailored for the needs of each collection.\n+\n+CDCR can be configured to replicate from one collection to a second collection _within the same cluster_. That is a specialized scenario not covered in this document.\n+\n+[glossary]\n+== CDCR Glossary\n+\n+Terms used in this document include:\n+\n+[glossary]\n+Node:: A JVM instance running Solr; a server.\n+Cluster:: A set of Solr nodes managed as a single unit by a ZooKeeper ensemble, hosting one or more Collections.\n+Data Center:: A group of networked servers hosting a Solr cluster. In this document, the terms _Cluster_ and _Data Center_ are interchangeable as we assume that each Solr cluster is hosted in a different group of networked servers.\n+Shard:: A sub-index of a single logical collection. This may be spread across multiple nodes of the cluster. Each shard can have as many replicas as needed.\n+Leader:: Each shard has one node identified as its leader. All the writes for documents belonging to a shard are routed through the leader.\n+Replica:: A copy of a shard for use in failover or load balancing. Replicas comprising a shard can either be leaders or non-leaders.\n+Follower:: A convenience term for a replica that is _not_ the leader of a shard.\n+Collection:: Multiple documents that make up one logical index. A cluster can have multiple collections.\n+Updates Log:: An append-only log of write operations maintained by each node.\n+\n+== CDCR Architecture\n+\n+Here is a picture of the data flow.\n+\n+.CDCR Data Flow\n+image::images/cross-data-center-replication-cdcr-/CDCR_arch.png[image,width=700,height=525]\n+\n+Updates and deletes are first written to the Source cluster, then forwarded to the Target cluster. The data flow sequence is:\n+\n+. A shard leader receives a new data update that is processed by its update processor chain.\n+. The data update is first applied to the local index.\n+. Upon successful application of the data update on the local index, the data update is added to the Updates Log queue.\n+. After the data update is persisted to disk, the data update is sent to the replicas within the data center.\n+. After Step 4 is successful, CDCR reads the data update from the Updates Log and pushes it to the corresponding collection in the target data center. This is necessary in order to ensure consistency between the Source and target data centers.\n+. The leader on the target data center writes the data locally and forwards it to all its followers.\n+\n+Steps 1, 2, 3 and 4 are performed synchronously by SolrCloud; Step 5 is performed asynchronously by a background thread. Given that CDCR replication is performed asynchronously, it becomes possible to push batch updates in order to minimize network communication overhead. Also, if CDCR is unable to push the update at a given time, for example, due to a degradation in connectivity, it can retry later without any impact on the source data center.\n+\n+One implication of the architecture is that the leaders in the source cluster must be able to \"see\" the leaders in the target cluster. Since leaders may change, this effectively means that all nodes in the source cluster must be able to \"see\" all Solr nodes in the target cluster so firewalls, ACL rules, etc. must be configured with care.\n+\n+The current design works most robustly if both the Source and target clusters have the same number of shards. There is no requirement that the shards in the Source and target collection have the same number of replicas.\n+\n+Having different numbers of shards on the Source and target cluster is possible, but is also an \"expert\" configuration as that option imposes certain constraints and is not recommended. Most of the scenarios where having differing numbers of shards are contemplated are better accomplished by hosting multiple shards on each target Solr instance.\n+\n+== Major Components of CDCR\n+\n+There are a number of key features and components in CDCR\u2019s architecture:\n+\n+=== CDCR Configuration\n+\n+In order to configure CDCR, the Source data center requires the host address of the ZooKeeper cluster associated with the target data center. The ZooKeeper host address is the only information needed by CDCR to instantiate the communication with the target Solr cluster. The CDCR configuration file on the source cluster will therefore contain a list of ZooKeeper hosts. The CDCR configuration file might also contain secondary/optional configuration, such as the number of CDC Replicator threads, batch updates related settings, etc.\n+\n+=== CDCR Initialization\n+\n+CDCR supports incremental updates to either new or existing collections. CDCR may not be able to keep up with very high volume updates, especially if there are significant communications latencies due to a slow \"pipe\" between the data centers. Some scenarios:\n+\n+* There is an initial bulk load of a corpus followed by lower volume incremental updates. In this case, one can do the initial bulk load and then enable CDCR. See the section <<Initial Startup>> for more information.\n+* The index is being built up from scratch, without a significant initial bulk load. CDCR can be set up on empty collections and keep them synchronized from the start.\n+* The index is always being updated at a volume too high for CDCR to keep up. This is especially possible in situations where the connection between the Source and target data centers is poor. This scenario is unsuitable for CDCR in its current form.\n+\n+=== Inter-Data Center Communication\n+\n+Communication between data centers will be achieved through HTTP and the Solr REST API using the SolrJ client. The SolrJ client will be instantiated with the ZooKeeper host of the target data center. SolrJ will manage the shard leader discovery process.\n+\n+=== Updates Tracking & Pushing\n+\n+CDCR replicates data updates from the source to the target data center by leveraging the Updates Log.\n+\n+A background thread regularly checks the Updates Log for new entries, and then forwards them to the target data center. The thread therefore needs to keep a checkpoint in the form of a pointer to the last update successfully processed in the Updates Log. Upon acknowledgement from the target data center that updates have been successfully processed, the Updates Log pointer is updated to reflect the current checkpoint.\n+\n+This pointer must be synchronized across all the replicas. In the case where the leader goes down and a new leader is elected, the new leader will be able to resume replication from the last update by using this synchronized pointer. The strategy to synchronize such a pointer across replicas will be explained next.\n+\n+If for some reason, the target data center is offline or fails to process the updates, the thread will periodically try to contact the target data center and push the updates.\n+\n+=== Synchronization of Update Checkpoints\n+\n+A reliable synchronization of the update checkpoints between the shard leader and shard replicas is critical to avoid introducing inconsistency between the Source and target data centers. Another important requirement is that the synchronization must be performed with minimal network traffic to maximize scalability.\n+\n+In order to achieve this, the strategy is to:\n+\n+* Uniquely identify each update operation. This unique identifier will serve as pointer.\n+* Rely on two storages: an ephemeral storage on the Source shard leader, and a persistent storage on the target cluster.\n+\n+The shard leader in the source cluster will be in charge of generating a unique identifier for each update operation, and will keep a copy of the identifier of the last processed updates in memory. The identifier will be sent to the target cluster as part of the update request. On the target data center side, the shard leader will receive the update request, store it along with the unique identifier in the Updates Log, and replicate it to the other shards.\n+\n+SolrCloud already provides a unique identifier for each update operation, i.e., a \u201cversion\u201d number. This version number is generated using a time-based lmport clock which is incremented for each update operation sent. This provides an \u201chappened-before\u201d ordering of the update operations that will be leveraged in (1) the initialization of the update checkpoint on the source cluster, and in (2) the maintenance strategy of the Updates Log.\n+\n+The persistent storage on the target cluster is used only during the election of a new shard leader on the Source cluster. If a shard leader goes down on the source cluster and a new leader is elected, the new leader will contact the target cluster to retrieve the last update checkpoint and instantiate its ephemeral pointer. On such a request, the target cluster will retrieve the latest identifier received across all the shards, and send it back to the source cluster. To retrieve the latest identifier, every shard leader will look up the identifier of the first entry in its Update Logs and send it back to a coordinator. The coordinator will have to select the highest among them.\n+\n+This strategy does not require any additional network traffic and ensures reliable pointer synchronization. Consistency is principally achieved by leveraging SolrCloud. The update workflow of SolrCloud ensures that every update is applied to the leader but also to any of the replicas. If the leader goes down, a new leader is elected. During the leader election, a synchronization is performed between the new leader and the other replicas. As a result, this ensures that the new leader has a consistent Update Logs with the previous leader. Having a consistent Updates Log means that:\n+\n+* On the source cluster, the update checkpoint can be reused by the new leader.\n+* On the target cluster, the update checkpoint will be consistent between the previous and new leader. This ensures the correctness of the update checkpoint sent by a newly elected leader from the target cluster.\n+\n+=== Maintenance of Updates Log\n+\n+The CDCR replication logic requires modification to the maintenance logic of the Updates Log on the source data center. Initially, the Updates Log acts as a fixed size queue, limited to 100 update entries. In the CDCR scenario, the Update Logs must act as a queue of variable size as they need to keep track of all the updates up through the last processed update by the target data center. Entries in the Update Logs are removed only when all pointers (one pointer per target data center) are after them.\n+\n+If the communication with one of the target data center is slow, the Updates Log on the source data center can grow to a substantial size. In such a scenario, it is necessary for the Updates Log to be able to efficiently find a given update operation given its identifier. Given that its identifier is an incremental number, it is possible to implement an efficient search strategy. Each transaction log file contains as part of its filename the version number of the first element. This is used to quickly traverse all the transaction log files and find the transaction log file containing one specific version number.\n+\n+\n+[[CrossDataCenterReplication_CDCR_-Monitoring]]\n+=== Monitoring\n+\n+CDCR provides the following monitoring capabilities over the replication operations:\n+\n+* Monitoring of the outgoing and incoming replications, with information such as the Source and target nodes, their status, etc.\n+* Statistics about the replication, with information such as operations (add/delete) per second, number of documents in the queue, etc.\n+\n+Information about the lifecycle and statistics will be provided on a per-shard basis by the CDC Replicator thread. The CDCR API can then aggregate this information an a collection level.\n+\n+=== CDC Replicator\n+\n+The CDC Replicator is a background thread that is responsible for replicating updates from a Source data center to one or more target data centers. It is responsible in providing monitoring information on a per-shard basis. As there can be a large number of collections and shards in a cluster, we will use a fixed-size pool of CDC Replicator threads that will be shared across shards.\n+\n+\n+[[CrossDataCenterReplication_CDCR_-Limitations]]\n+=== Limitations\n+\n+The current design of CDCR has some limitations. CDCR will continue to evolve over time and many of these limitations will be addressed. Among them are:\n+\n+* CDCR is unlikely to be satisfactory for bulk-load situations where the update rate is high, especially if the bandwidth between the Source and target clusters is restricted. In this scenario, the initial bulk load should be performed, the Source and target data centers synchronized and CDCR be utilized for incremental updates.\n+* CDCR is currently only active-passive; data is pushed from the Source cluster to the target cluster. There is active work being done in this area in the 6x code line to remove this limitation.\n+* CDCR works most robustly with the same number of shards in the Source and target collection. The shards in the two collections may have different numbers of replicas.\n+\n+\n+[[CrossDataCenterReplication_CDCR_-Configuration]]\n+== Configuration\n+\n+The source and target configurations differ in the case of the data centers being in separate clusters. \"Cluster\" here means separate ZooKeeper ensembles controlling disjoint Solr instances. Whether these data centers are physically separated or not is immaterial for this discussion.\n+\n+\n+[[CrossDataCenterReplication_CDCR_-SourceConfiguration]]\n+=== Source Configuration\n+\n+Here is a sample of a source configuration file, a section in `solrconfig.xml`. The presence of the <replica> section causes CDCR to use this cluster as the Source and should not be present in the target collections in the cluster-to-cluster case. Details about each setting are after the two examples:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/cdcr\" class=\"solr.CdcrRequestHandler\">\n+  <lst name=\"replica\">\n+    <str name=\"zkHost\">10.240.18.211:2181</str>\n+    <str name=\"source\">collection1</str>\n+    <str name=\"target\">collection1</str>\n+  </lst>\n+\n+  <lst name=\"replicator\">\n+    <str name=\"threadPoolSize\">8</str>\n+    <str name=\"schedule\">1000</str>\n+    <str name=\"batchSize\">128</str>\n+  </lst>\n+\n+  <lst name=\"updateLogSynchronizer\">\n+    <str name=\"schedule\">1000</str>\n+  </lst>\n+</requestHandler>\n+\n+<!-- Modify the <updateLog> section of your existing <updateHandler>\n+     in your config as below -->\n+<updateHandler class=\"solr.DirectUpdateHandler2\">\n+  <updateLog class=\"solr.CdcrUpdateLog\">\n+    <str name=\"dir\">${solr.ulog.dir:}</str>\n+    <!--Any parameters from the original <updateLog> section -->\n+  </updateLog>\n+</updateHandler>\n+----\n+\n+\n+[[CrossDataCenterReplication_CDCR_-TargetConfiguration]]\n+=== Target Configuration\n+\n+Here is a typical target configuration.\n+\n+Target instance must configure an update processor chain that is specific to CDCR. The update processor chain must include the *CdcrUpdateProcessorFactory*. The task of this processor is to ensure that the version numbers attached to update requests coming from a CDCR source SolrCloud are reused and not overwritten by the target. A properly configured Target configuration looks similar to this.\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/cdcr\" class=\"solr.CdcrRequestHandler\">\n+  <lst name=\"buffer\">\n+    <str name=\"defaultState\">disabled</str>\n+  </lst>\n+</requestHandler>\n+\n+<requestHandler name=\"/update\" class=\"solr.UpdateRequestHandler\">\n+  <lst name=\"defaults\">\n+    <str name=\"update.chain\">cdcr-processor-chain</str>\n+  </lst>\n+</requestHandler>\n+\n+<updateRequestProcessorChain name=\"cdcr-processor-chain\">\n+  <processor class=\"solr.CdcrUpdateProcessorFactory\"/>\n+  <processor class=\"solr.RunUpdateProcessorFactory\"/>\n+</updateRequestProcessorChain>\n+\n+<!-- Modify the <updateLog> section of your existing <updateHandler> in your\n+    config as below -->\n+<updateHandler class=\"solr.DirectUpdateHandler2\">\n+  <updateLog class=\"solr.CdcrUpdateLog\">\n+    <str name=\"dir\">${solr.ulog.dir:}</str>\n+    <!--Any parameters from the original <updateLog> section -->\n+  </updateLog>\n+</updateHandler>\n+----\n+\n+=== Configuration Details\n+\n+The configuration details, defaults and options are as follows:\n+\n+==== The Replica Element\n+\n+CDCR can be configured to forward update requests to one or more replicas. A replica is defined with a \u201creplica\u201d list as follows:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,10,15,55\",options=\"header\"]\n+|===\n+|Parameter |Required |Default |Description\n+|zkHost |Yes |none |The host address for ZooKeeper of the target SolrCloud. Usually this is a comma-separated list of addresses to each node in the target ZooKeeper ensemble.\n+|Source |Yes |none |The name of the collection on the Source SolrCloud to be replicated.\n+|Target |Yes |none |The name of the collection on the target SolrCloud to which updates will be forwarded.\n+|===\n+\n+==== The Replicator Element\n+\n+The CDC Replicator is the component in charge of forwarding updates to the replicas. The replicator will monitor the update logs of the Source collection and will forward any new updates to the target collection.\n+\n+The replicator uses a fixed thread pool to forward updates to multiple replicas in parallel. If more than one replica is configured, one thread will forward a batch of updates from one replica at a time in a round-robin fashion. The replicator can be configured with a \u201creplicator\u201d list as follows:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,10,15,55\",options=\"header\"]\n+|===\n+|Parameter |Required |Default |Description\n+|threadPoolSize |No |2 |The number of threads to use for forwarding updates. One thread per replica is recommended.\n+|schedule |No |10 |The delay in milliseconds for the monitoring the update log(s).\n+|batchSize |No |128 |The number of updates to send in one batch. The optimal size depends on the size of the documents. Large batches of large documents can increase your memory usage significantly.\n+|===\n+\n+==== The updateLogSynchronizer Element\n+\n+Expert: Non-leader nodes need to synchronize their update logs with their leader node from time to time in order to clean deprecated transaction log files. By default, such a synchronization process is performed every minute. The schedule of the synchronization can be modified with a \u201cupdateLogSynchronizer\u201d list as follows:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,10,15,55\",options=\"header\"]\n+|===\n+|Parameter |Required |Default |Description\n+|schedule |No |60000 |The delay in milliseconds for synchronizing the updates log.\n+|===\n+\n+==== The Buffer Element\n+\n+CDCR is configured by default to buffer any new incoming updates. When buffering updates, the updates log will store all the updates indefinitely. Replicas do not need to buffer updates, and it is recommended to disable buffer on the target SolrCloud. The buffer can be disabled at startup with a \u201cbuffer\u201d list and the parameter \u201cdefaultState\u201d as follows:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,10,15,55\",options=\"header\"]\n+|===\n+|Parameter |Required |Default |Description\n+|defaultState |No |enabled |The state of the buffer at startup.\n+|===\n+\n+== CDCR API\n+\n+The CDCR API is used to control and monitor the replication process. Control actions are performed at a collection level, i.e., by using the following base URL for API calls: `\\http://localhost:8983/solr/<collection>`.\n+\n+Monitor actions are performed at a core level, i.e., by using the following base URL for API calls: `\\http://localhost:8983/solr/<collection>`.\n+\n+Currently, none of the CDCR API calls have parameters.\n+\n+\n+=== API Entry Points (Control)\n+\n+* `<collection>/cdcr?action=STATUS`: <<CrossDataCenterReplication_CDCR_-STATUS,Returns the current state>> of CDCR.\n+* `<collection>/cdcr?action=START`: <<CrossDataCenterReplication_CDCR_-START,Starts CDCR>> replication\n+* `<collection>/cdcr?action=STOP`: <<CrossDataCenterReplication_CDCR_-STOP,Stops CDCR>> replication.\n+* `<collection>/cdcr?action=ENABLEBUFFER`: <<CrossDataCenterReplication_CDCR_-ENABLEBUFFER,Enables the buffering>> of updates.\n+* `<collection>/cdcr?action=DISABLEBUFFER`: <<CrossDataCenterReplication_CDCR_-DISABLEBUFFER,Disables the buffering>> of updates.\n+\n+\n+=== API Entry Points (Monitoring)\n+\n+* `core/cdcr?action=QUEUES`: <<CrossDataCenterReplication_CDCR_-QUEUES,Fetches statistics about the queue>> for each replica and about the update logs.\n+* `core/cdcr?action=OPS`: <<CrossDataCenterReplication_CDCR_-OPS,Fetches statistics about the replication performance>> (operations per second) for each replica.\n+* `core/cdcr?action=ERRORS`: <<CrossDataCenterReplication_CDCR_-ERRORS,Fetches statistics and other information about replication errors>> for each replica.\n+\n+=== Control Commands\n+\n+[[CrossDataCenterReplication_CDCR_-STATUS]]\n+==== STATUS\n+\n+`/collection/cdcr?action=STATUS`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters to this command.\n+\n+===== Output\n+\n+*Output Content*\n+\n+The current state of the CDCR, which includes the state of the replication process and the state of the buffer.\n+\n+[[cdcr_examples]]\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<collection_name>/cdcr?action=STATUS\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+  \"status\": 0,\n+  \"QTime\": 0\n+  },\n+  \"status\": {\n+  \"process\": \"stopped\",\n+  \"buffer\": \"enabled\"\n+  }\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-ENABLEBUFFER]]\n+==== ENABLEBUFFER\n+\n+`/collection/cdcr?action=ENABLEBUFFER`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters to this command.\n+\n+===== Output\n+\n+*Output Content*\n+\n+The status of the process and an indication of whether the buffer is enabled\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<collection_name>/cdcr?action=ENABLEBUFFER\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+  \"status\": 0,\n+  \"QTime\": 0\n+  },\n+  \"status\": {\n+  \"process\": \"started\",\n+  \"buffer\": \"enabled\"\n+  }\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-DISABLEBUFFER]]\n+==== DISABLEBUFFER\n+\n+`/collection/cdcr?action=DISABLEBUFFER`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters to this command\n+\n+===== Output\n+\n+*Output Content:* The status of CDCR and an indication that the buffer is disabled.\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://host:8983/solr/<collection_name>/cdcr?action=DISABLEBUFFER\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+  \"status\": 0,\n+  \"QTime\": 0\n+  },\n+  \"status\": {\n+  \"process\": \"started\",\n+  \"buffer\": \"disabled\"\n+  }\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-START]]\n+==== START\n+\n+`/collection/cdcr?action=START`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters for this action\n+\n+===== Output\n+\n+*Output Content:* Confirmation that CDCR is started and the status of buffering\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+http://host:8983/solr/<collection_name>/cdcr?action=START\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+  \"status\": 0,\n+  \"QTime\": 0\n+  },\n+  \"status\": {\n+  \"process\": \"started\",\n+  \"buffer\": \"enabled\"\n+  }\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-STOP]]\n+==== STOP\n+\n+`/collection/cdcr?action=STOP`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters for this command.\n+\n+===== Output\n+\n+*Output Content:* The status of CDCR, including the confirmation that CDCR is stopped\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<collection_name>/cdcr?action=STOP\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\": {\n+  \"status\": 0,\n+  \"QTime\": 0\n+  },\n+  \"status\": {\n+  \"process\": \"stopped\",\n+  \"buffer\": \"enabled\"\n+  }\n+}\n+----\n+\n+\n+[[CrossDataCenterReplication_CDCR_-Monitoringcommands]]\n+=== Monitoring commands\n+\n+[[CrossDataCenterReplication_CDCR_-QUEUES]]\n+==== QUEUES\n+\n+`/core/cdcr?action=QUEUES`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters for this command\n+\n+===== Output\n+\n+*Output Content*\n+\n+The output is composed of a list \u201cqueues\u201d which contains a list of (ZooKeeper) target hosts, themselves containing a list of target collections. For each collection, the current size of the queue and the timestamp of the last update operation successfully processed is provided. The timestamp of the update operation is the original timestamp, i.e., the time this operation was processed on the Source SolrCloud. This allows an estimate the latency of the replication process.\n+\n+The \u201cqueues\u201d object also contains information about the updates log, such as the size (in bytes) of the updates log on disk (\u201ctlogTotalSize\u201d), the number of transaction log files (\u201ctlogTotalCount\u201d) and the status of the updates log synchronizer (\u201cupdateLogSynchronizer\u201d).\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<replica_name>/cdcr?action=QUEUES\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\": 0,\n+    \"QTime\": 1\n+  },\n+  \"queues\":{\n+    \"127.0.0.1: 40342/solr\":{\n+    \"Target_collection\":{\n+        \"queueSize\": 104,\n+        \"lastTimestamp\": \"2014-12-02T10:32:15.879Z\"\n+      }\n+    }\n+  },\n+  \"tlogTotalSize\":3817,\n+  \"tlogTotalCount\":1,\n+  \"updateLogSynchronizer\": \"stopped\"\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-OPS]]\n+==== OPS\n+\n+`/core/cdcr?action=OPS`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters for this command.\n+\n+===== Output\n+\n+*Output Content:* The output is composed of a list \u201coperationsPerSecond\u201d which contains a list of (ZooKeeper) target hosts, themselves containing a list of target collections. For each collection, the average number of processed operations per second since the start of the replication process is provided. The operations are further broken down into two groups: add and delete operations.\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<collection_name>/cdcr?action=OPS\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":1\n+  },\n+  \"operationsPerSecond\":{\n+    \"127.0.0.1: 59661/solr\":{\n+      \"Target_collection\":{\n+          \"all\": 297.102944952749052,\n+          \"adds\": 297.102944952749052,\n+          \"deletes\": 0.0\n+      }\n+    }\n+  }\n+}\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-ERRORS]]\n+==== ERRORS\n+\n+`/core/cdcr?action=ERRORS`\n+\n+===== Input\n+\n+*Query Parameters:* There are no parameters for this command.\n+\n+===== Output\n+\n+*Output Content:* The output is composed of a list \u201cerrors\u201d which contains a list of (ZooKeeper) target hosts, themselves containing a list of target collections. For each collection, information about errors encountered during the replication is provided, such as the number of consecutive errors encountered by the replicator thread, the number of bad requests or internal errors since the start of the replication process, and a list of the last errors encountered ordered by timestamp.\n+\n+===== Examples\n+\n+*Input*\n+\n+[source,text]\n+----\n+ http://host:8983/solr/<collection_name>/cdcr?action=ERRORS\n+----\n+\n+*Output*\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":2\n+  },\n+  \"errors\": {\n+    \"127.0.0.1: 36872/solr\":{\n+      \"Target_collection\":{\n+        \"consecutiveErrors\":3,\n+        \"bad_request\":0,\n+        \"internal\":3,\n+        \"last\":{\n+          \"2014-12-02T11:04:42.523Z\":\"internal\",\n+          \"2014-12-02T11:04:39.223Z\":\"internal\",\n+          \"2014-12-02T11:04:38.22Z\":\"internal\"\n+        }\n+      }\n+    }\n+  }\n+}\n+----\n+\n+== Initial Startup\n+\n+This is a general approach for initializing CDCR in a production environment based upon an approach taken by the initial working installation of CDCR and generously contributed to illustrate a \"real world\" scenario.\n+\n+* Customer uses the CDCR approach to keep a remote disaster-recovery instance available for production backup. This is an active-passive solution.\n+* Customer has 26 clouds with 200 million assets per cloud (15GB indexes). Total document count is over 4.8 billion.\n+** Source and target clouds were synched in 2-3 hour maintenance windows to establish the base index for the targets.\n+\n+As usual, it is good to start small. Sync a single cloud and monitor for a period of time before doing the others. You may need to adjust your settings several times before finding the right balance.\n+\n+* Before starting, stop or pause the indexers. This is best done during a small maintenance window.\n+* Stop the SolrCloud instances at the Source\n+* Include the CDCR request handler configuration in `solrconfig.xml` as in the below example.\n++\n+[source,xml]\n+----\n+<requestHandler name=\"/cdcr\" class=\"solr.CdcrRequestHandler\">\n+    <lst name=\"replica\">\n+      <str name=\"zkHost\">${TargetZk}</str>\n+      <str name=\"Source\">${SourceCollection}</str>\n+      <str name=\"Target\">${TargetCollection}</str>\n+    </lst>\n+    <lst name=\"replicator\">\n+      <str name=\"threadPoolSize\">8</str>\n+      <str name=\"schedule\">10</str>\n+      <str name=\"batchSize\">2000</str>\n+    </lst>\n+    <lst name=\"updateLogSynchronizer\">\n+      <str name=\"schedule\">1000</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <updateRequestProcessorChain name=\"cdcr-processor-chain\">\n+    <processor class=\"solr.CdcrUpdateProcessorFactory\" />\n+    <processor class=\"solr.RunUpdateProcessorFactory\" />\n+  </updateRequestProcessorChain>\n+----\n++\n+* Upload the modified `solrconfig.xml` to ZooKeeper on both Source and Target\n+* Sync the index directories from the Source collection to target collection across to the corresponding shard nodes. `rsync` works well for this.\n++\n+For example, if there are 2 shards on collection1 with 2 replicas for each shard, copy the corresponding index directories from\n++\n+[width=\"75%\",cols=\"45,10,45\"]\n+|===\n+|shard1replica1Source |to |shard1replica1Target\n+|shard1replica2Source |to |shard1replica2Target\n+|shard2replica1Source |to |shard2replica1Target\n+|shard2replica2Source |to |shard2replica2Target\n+|===\n++\n+* Start the ZooKeeper on the Target (DR) side\n+* Start the SolrCloud on the Target (DR) side\n+* Start the ZooKeeper on the Source side\n+* Start the SolrCloud on the Source side. As a general rule, the Target (DR) side of the SolrCloud should be started before the Source side.\n+* Activate the CDCR on Source instance using the CDCR API: `\\http://host:port/solr/collection_name/cdcr?action=START`\n++\n+[source,text]\n+http://host:port/solr/<collection_name>/cdcr?action=START\n++\n+* There is no need to run the /cdcr?action=START command on the Target\n+* Disable the buffer on the Target\n++\n+[source,text]\n+http://host:port/solr/collection_name/cdcr?action=DISABLEBUFFER\n++\n+* Renable indexing\n+\n+[[CrossDataCenterReplication_CDCR_-Monitoring.1]]\n+== Monitoring\n+\n+.  Network and disk space monitoring are essential. Ensure that the system has plenty of available storage to queue up changes if there is a disconnect between the Source and Target. A network outage between the two data centers can cause your disk usage to grow.\n+..  Tip: Set a monitor for your disks to send alerts when the disk gets over a certain percentage (e.g., 70%)\n+..  Tip: Run a test. With moderate indexing, how long can the system queue changes before you run out of disk space?\n+.  Create a simple way to check the counts between the Source and the Target.\n+..  Keep in mind that if indexing is running, the Source and Target may not match document for document. Set an alert to fire if the difference is greater than some percentage of the overall cloud size.\n+\n+== ZooKeeper Settings\n+\n+With CDCR, the target ZooKeepers will have connections from the Target clouds and the Source clouds. You may need to increase the `maxClientCnxns` setting in `zoo.cfg`.\n+\n+[source,text]\n+----\n+## set numbers of connection to 200 from client\n+## is maxClientCnxns=0 that means no limit\n+maxClientCnxns=800\n+----\n+\n+== Upgrading and Patching Production\n+\n+When rolling in upgrades to your indexer or application, you should shutdown the Source (production) and the Target (DR). Depending on your setup, you may want to pause/stop indexing. Deploy the release or patch and renable indexing. Then start the Target (DR).\n+\n+* There is no need to reissue the DISABLEBUFFERS or START commands. These are persisted.\n+* After starting the Target, run a simple test. Add a test document to each of the Source clouds. Then check for it on the Target.\n+\n+[source,bash]\n+----\n+#send to the Source\n+curl http://<Source>/solr/cloud1/update -H 'Content-type:application/json' -d '[{\"SKU\":\"ABC\"}]'\n+\n+#check the Target\n+curl \"http://<Target>:8983/solr/<collection_name>/select?q=SKU:ABC&wt=json&indent=true\"\n+----\n+\n+[[CrossDataCenterReplication_CDCR_-Limitations.1]]\n+== Limitations\n+\n+* Running CDCR with the indexes on HDFS is not currently supported, see: https://issues.apache.org/jira/browse/SOLR-9861[Solr CDCR over HDFS].",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/cross-data-center-replication-cdcr.adoc",
                "sha": "35098841039998eb853493210df32f07a6db55e2",
                "status": "added"
            },
            {
                "additions": 164,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/comments.css",
                "changes": 164,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/comments.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/comments.css",
                "patch": "@@ -0,0 +1,164 @@\n+/* ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * comments.css\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ */\n+\n+#comments_thread a:link {\n+    color: #5A88B5;\n+    background-color: inherit;\n+}\n+\n+#comments_thread a:visited {\n+    color: #5A88B5;\n+    background-color: inherit;\n+}\n+\n+#comments_thread a:link:hover,\n+#comments_thread a:link:active,\n+#comments_thread a:visited:hover,\n+#comments_thread a:visited:active {\n+    color: #0073c7;\n+    background-color: #f0f0f0;\n+}\n+\n+\n+/* in general */\n+#comments_thread p {\n+    line-height: 1.3em;\n+    color: #003;\n+}\n+\n+#comments_thread h4 {\n+   font-size: 14px;\n+}\n+\n+.apaste_menu {\n+        float: right;\n+        margin-right: 10px;\n+        width: 80px;\n+}\n+\n+.apaste_comment {\n+  background: #FEFEFE;\n+  border: 1px solid #AAA;\n+  border-radius: 2px;\n+  display: block;\n+  white-space: pre-wrap;\n+  font-weight: normal;\n+  padding-left: 20px;\n+  padding-right: 20px;\n+  padding-bottom: 16px;\n+  padding-top: 5px;\n+  margin: 15px;\n+  font-size: 13px\n+}\n+.comment_header {\n+    color: #000000;\n+    border-radius: 3px;\n+    border: 1px solid #999;\n+    min-height: 24px;\n+    text-indent: 5px;\n+    font-size: 12pt;\n+    background: #ffe9a3; /* Old browsers */\n+    background: -moz-linear-gradient(top, #ffe9a3 0%, #ffd08a 32%, #ff9d57 69%, #ff833d 100%); /* FF3.6-15 */\n+    background: -webkit-linear-gradient(top, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* Chrome10-25,Safari5.1-6 */\n+    background: linear-gradient(to bottom, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* W3C, IE10+, FF16+, Chrome26+, Opera12+, Safari7+ */\n+}\n+\n+.comment_header_verified {\n+    color: #000000;\n+    border-radius: 3px;\n+    border: 1px solid #999;\n+    min-height: 24px;\n+    text-indent: 5px;\n+    font-size: 12pt;\n+    background: #ffe9a3; /* Old browsers */\n+    background: -moz-linear-gradient(top, #ffe9a3 0%, #ffd08a 32%, #ff9d57 69%, #ff833d 100%); /* FF3.6-15 */\n+    background: -webkit-linear-gradient(top, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* Chrome10-25,Safari5.1-6 */\n+    background: linear-gradient(to bottom, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* W3C, IE10+, FF16+, Chrome26+, Opera12+, Safari7+ */\n+}\n+\n+.comment_header_sticky {\n+    color: #000000;\n+    border-radius: 3px;\n+    border: 1px solid #999;\n+    min-height: 24px;\n+    text-indent: 5px;\n+    font-size: 12pt;\n+    background: #ffe9a3; /* Old browsers */\n+    background: -moz-linear-gradient(top, #ffe9a3 0%, #ffd08a 32%, #ff9d57 69%, #ff833d 100%); /* FF3.6-15 */\n+    background: -webkit-linear-gradient(top, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* Chrome10-25,Safari5.1-6 */\n+    background: linear-gradient(to bottom, #ffe9a3 0%,#ffd08a 32%,#ff9d57 69%,#ff833d 100%); /* W3C, IE10+, FF16+, Chrome26+, Opera12+, Safari7+ */\n+}\n+\n+.comment_header img {\n+    padding-top: 3px;\n+    padding-bottom: 2px;\n+}\n+\n+.comment_header_verified img {\n+    padding-top: 3px;\n+    padding-bottom: 2px;\n+}\n+\n+.comment_header_sticky img {\n+    padding-top: 3px;\n+    padding-bottom: 2px;\n+}\n+\n+.apaste_comment img {\n+/*    border-radius: 5px;*/\n+    border: none;\n+}\n+\n+.apaste_comment_selected {background: #F8F4E9;}\n+.apaste_comment_notapproved {background: #F8E0E0;}\n+.apaste_comment_resolved {background: #FAFCFA;}\n+.apaste_comment_sticky {background: #FFFFF6;}\n+.apaste_comment_verified {background: #FAFBFA;}\n+\n+.apaste_comment_invalid {\n+  color: #999;\n+  background: #F8F8F8;\n+}\n+\n+\n+.apaste_comment textarea {\n+  width: 480px;\n+  height: 180px;\n+}\n+\n+#apaste {\n+  margin: 5px;\n+  font-weight: normal;\n+  font-size: 14px;\n+  color: #024;\n+\n+}\n+#apaste .section {\n+  padding: 20px;\n+  padding-left: 80px;\n+}\n+\n+.notapproved {\n+  background-color: #FEE;\n+  padding: 5px;\n+}\n+\n+#comments_thread textarea{\n+    background-color: #ffffff;\n+    width: auto;\n+    border: 1px solid #1c1c1c;\n+    border-radius: 3px;\n+    box-shadow: 0pt 1px 3px rgba(0, 0, 0, 0.16) inset;\n+    position: relative;\n+}\n+\n+.apaste_honeypot {\n+  display: none;\n+}\n+\n+//* Remove external link icons when they appear in comments *//\n+a[href^=\"http://\"]:after,\n+a[href^=\"https://\"]:after {\n+   content: none !important;\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/comments.css",
                "sha": "1292d23ebb72fdfefad59d367b2e541e7fe47c2e",
                "status": "added"
            },
            {
                "additions": 869,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/customstyles.css",
                "changes": 869,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/customstyles.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/customstyles.css",
                "patch": "@@ -0,0 +1,869 @@\n+\n+.gi-2x{font-size: 2em;}\n+.gi-3x{font-size: 3em;}\n+.gi-4x{font-size: 4em;}\n+.gi-5x{font-size: 5em;}\n+\n+.breadcrumb > .active {color: #777 !important;}\n+\n+.post-content img {\n+    margin: 12px 0 3px 0;\n+    width: auto;\n+    height: auto;\n+    max-width: 100%;\n+    max-height: 100%;\n+}\n+\n+.post-content ol li, .post-content ul li {\n+    margin: 10px 0;\n+}\n+\n+.pageSummary {\n+    font-size:13px;\n+    display:block;\n+    margin-bottom:15px;\n+    padding-left:20px;\n+}\n+\n+.post-summary {\n+    margin-bottom:12px;\n+}\n+\n+.bs-example{\n+    margin: 20px;\n+}\n+\n+.breadcrumb li {\n+    color: gray;\n+}\n+\n+caption {\n+    padding-top: 8px;\n+    padding-bottom: 8px;\n+    color: #777;\n+    text-align: left;\n+}\n+\n+p.external a {\n+    text-align:right;\n+    font-size:12px;\n+    color: #0088cc;\n+    display:inline;\n+}\n+\n+#definition-box-container div a.active {\n+    font-weight: bold;\n+}\n+p.post-meta {font-size: 80%; color: #777;}\n+\n+.entry-date{font-size:14px;font-size:0.875rem;line-height:1.71429;margin-bottom:0;text-transform:uppercase;}\n+\n+/* search area */\n+#search-demo-container ul#results-container {\n+    list-style: none;\n+    font-size: 12px;\n+    background-color: white;\n+    position: absolute;\n+    top: 40px; /* if you change anything about the nav, you'll prob. need to reset the top and left values here.*/\n+    left: 20px;\n+    z-index: -1;\n+    width:223px;\n+    border-left: 1px solid #dedede;\n+    box-shadow: 2px 3px 2px #dedede;\n+}\n+\n+/* make room for the nav bar */\n+h1[id],\n+h2[id],\n+h3[id],\n+h4[id],\n+h5[id],\n+h6[id],\n+dt[id]{\n+padding-top: 60px;\n+margin-top: -40px\n+}\n+\n+ul#results-container a {\n+    background-color: transparent;\n+}\n+\n+ul#results-container a:hover {\n+    color: black;\n+}\n+\n+\n+#search-demo-container a:hover {\n+    color: black;\n+}\n+#search-input {\n+    padding: .5em;\n+    margin-left:20px;\n+    width:20em;\n+    font-size: 0.8em;\n+    -webkit-box-sizing: border-box;\n+    -moz-box-sizing: border-box;\n+    box-sizing: border-box;\n+    float: right;\n+    margin-top:10px;\n+}\n+/* end search */\n+\n+.filter-options {\n+    margin-bottom: 20px;\n+}\n+.filter-options button {\n+    margin: 3px;\n+}\n+\n+\n+\n+li.dropdownActive a {\n+    font-weight: bold;\n+}\n+\n+\n+.post-content a.fa-rss {\n+    color: orange;\n+}\n+\n+\n+.navbar-inverse .navbar-nav > li > a {\n+    background-color: transparent;\n+    margin-top:10px;\n+}\n+\n+.post-content .rssfeedLink {\n+    color: #248EC2;\n+}\n+\n+footer {\n+    font-size: smaller;\n+}\n+\n+/* FAQ page */\n+#accordion .panel-heading {\n+    font-size: 12px;\n+}\n+\n+a.accordion-toggle, a.accordion-collapsed {\n+    font-size: 14px;\n+    text-decoration: none;\n+}\n+\n+/* navgoco sidebar styles (customized) */\n+.nav, .nav ul, .nav li {\n+    list-style: none;\n+}\n+\n+.nav ul {\n+    padding: 0;\n+    /*margin: 0 0 0 18px;*/\n+    margin:0;\n+}\n+\n+.nav {\n+    /* padding: 4px;*/\n+    padding:0;\n+    margin: 0;\n+}\n+\n+.nav > li {\n+    margin: 1px 0;\n+}\n+\n+.nav > li li {\n+    margin: 2px 0;\n+}\n+\n+.nav a {\n+    color: #333;\n+    display: block;\n+    outline: none;\n+    text-decoration: none;\n+}\n+\n+.nav li > a > span {\n+    float: right;\n+    font-size: 19px;\n+    font-weight: bolder;\n+}\n+\n+\n+.nav li > a > span:after {\n+    content: '\\25be';\n+}\n+.nav li.open > a > span:after {\n+    content: '\\25b4';\n+}\n+\n+.nav a:hover, .nav a:focus, .nav li.active > a {\n+    background-color: #8D8D8D;\n+    color: #f5f5f5;\n+}\n+\n+.nav > li.active > a  {\n+background-color: #347DBE;\n+}\n+\n+.nav li a {\n+    line-height: 18px;\n+    padding: 2px 10px;\n+    background-color: #f1f1f1;\n+}\n+\n+.nav > li > a {\n+    line-height: 20px;\n+    padding: 4px 10px;\n+}\n+\n+ul#mysidebar {\n+    border-radius:0;\n+}\n+\n+ul.nav li ul {\n+   font-size: 10pt;\n+}\n+\n+.nav ul li a {\n+    background-color: #FAFAFA;\n+}\n+\n+.nav li a {\n+    padding-right:10px;\n+}\n+\n+.nav li a:hover {\n+    background-color: #8D8D8D;\n+}\n+\n+.nav ul li a {\n+    border-top:1px solid whitesmoke;\n+    padding-left:10px;\n+}\n+/* end sidebar */\n+\n+.navbar-inverse .navbar-nav > .active > a, .navbar-inverse .navbar-nav > .active > a:hover, .navbar-inverse .navbar-nav > .active > a:focus {\n+    border-radius:5px;\n+}\n+\n+.navbar-inverse .navbar-nav>.open>a, .navbar-inverse .navbar-nav>.open>a:focus, .navbar-inverse .navbar-nav>.open>a:hover {\n+    border-radius: 5px;\n+}\n+\n+.footer {\n+    text-align: right;\n+}\n+\n+.footerMeta {\n+    background-color: whitesmoke;\n+    padding: 10px;\n+    max-width: 250px;\n+    border-radius: 5px;\n+    margin-top: 50px;\n+    font-style:italic;\n+    font-size:12px;\n+}\n+\n+img.screenshotSmall {\n+    max-width: 300px;\n+}\n+\n+\n+dl dt p {\n+    margin-left:20px;\n+}\n+\n+\n+dl dd {\n+    margin-top:10px;\n+    margin-bottom:10px;\n+}\n+\n+dl.dl-horizontal dd {\n+    padding-top: 20px;\n+}\n+\n+figcaption {\n+\n+    padding-bottom:12px;\n+    padding-top:6px;\n+    max-width: 90%;\n+    margin-bottom:20px;\n+    font-style: italic;\n+    color: gray;\n+\n+}\n+\n+.testing {\n+    color: orange;\n+}\n+\n+.preference {\n+    color: red;\n+}\n+\n+\n+table.dataTable thead {\n+    background-color: #444;\n+}\n+\n+section table tr.success {\n+    background-color: #dff0d8 !important;\n+}\n+\n+table tr.info {\n+    background-color: #d9edf7 !important;\n+}\n+\n+section table tr.warning, table tr.testing, table tr.testing > td.sorting_1  {\n+    background-color: #fcf8e3 !important;\n+}\n+section table tr.danger, table tr.preference, table tr.preference > td.sorting_1  {\n+    background-color: #f2dede !important;\n+}\n+\n+.orange {\n+    color: orange;\n+}\n+\n+table.profile thead tr th {\n+    background-color: #248ec2;\n+}\n+\n+table.request thead tr th {\n+    background-color: #ED1951;\n+}\n+\n+.audienceLabel {\n+    margin: 10px;\n+    float: right;\n+    border:1px solid #dedede;\n+    padding:7px;\n+}\n+\n+.prefaceAudienceLabel {\n+    color: gray;\n+    text-align: center;\n+    margin:5px;\n+}\n+span.myLabel {\n+    padding-left:10px;\n+    padding-right:10px;\n+}\n+\n+button.cursorNorm {\n+    cursor: default;\n+}\n+\n+a.dropdown-toggle, .navbar-inverse .navbar-nav > li > a  {\n+    margin-left: 10px;\n+}\n+\n+hr.faded {\n+    border: 0;\n+    height: 1px;\n+    background-image: -webkit-linear-gradient(left, rgba(0,0,0,0), rgba(0,0,0,0.75), rgba(0,0,0,0));\n+    background-image:    -moz-linear-gradient(left, rgba(0,0,0,0), rgba(0,0,0,0.75), rgba(0,0,0,0));\n+    background-image:     -ms-linear-gradient(left, rgba(0,0,0,0), rgba(0,0,0,0.75), rgba(0,0,0,0));\n+    background-image:      -o-linear-gradient(left, rgba(0,0,0,0), rgba(0,0,0,0.75), rgba(0,0,0,0));\n+}\n+\n+hr.shaded {\n+    height: 12px;\n+    border: 0;\n+    box-shadow: inset 0 6px 6px -6px rgba(0,0,0,0.5);\n+    margin-top: 70px;\n+    background: white;\n+    width: 100%;\n+    margin-bottom: 10px;\n+}\n+\n+.fa-6x{font-size:900%;}\n+.fa-7x{font-size:1100%;}\n+.fa-8x{font-size:1300%;}\n+.fa-9x{font-size:1500%;}\n+.fa-10x{font-size:1700%;}\n+\n+i.border {\n+    padding: 10px 20px;\n+    background-color: whitesmoke;\n+}\n+\n+a[data-toggle] {\n+    color: #248EC2;\n+}\n+\n+.summary {\n+    font-size:120%;\n+    color: #808080;\n+    margin:20px 0 20px 0;\n+    border-left: 5px solid #ED1951;\n+    padding-left: 10px;\n+\n+}\n+\n+.summary:before {\n+    content: \"Summary: \";\n+    font-weight: bold;\n+}\n+\n+\n+a.fa.fa-envelope-o.mailto {\n+    font-weight: 600;\n+}\n+\n+.nav-tabs > li.active > a, .nav-tabs > li.active > a:hover, .nav-tabs > li.active > a:focus {\n+    background-color: #248ec2;\n+    color: white;\n+}\n+\n+ol li ol li {list-style-type: lower-alpha;}\n+ol li ul li {list-style-type: disc;}\n+\n+li img {clear:both; }\n+\n+div#toc ul li ul li {\n+    list-style-type: none;\n+    margin: 5px 0 0 0;\n+}\n+\n+.tab-content {\n+    padding: 15px;\n+    background-color: #FAFAFA;\n+}\n+\n+span.tagTitle {font-weight: 500;}\n+\n+li.activeSeries {\n+    font-weight: bold;\n+}\n+\n+.seriesContext .dropdown-menu li.active {\n+    font-weight: bold;\n+    margin-left: 43px;\n+    font-size:18px;\n+}\n+\n+div.tags {padding: 10px 5px;}\n+\n+.tabLabel {\n+    font-weight: normal;\n+}\n+\n+hr {\n+    border: 0;\n+    border-bottom: 1px dashed #ccc;\n+    background: #999;\n+    margin: 30px 0;\n+    width: 90%;\n+    margin-left: auto;\n+    margin-right: auto;\n+}\n+\n+button.cursorNorm {\n+    cursor: pointer;\n+}\n+\n+span.otherProgrammingLanguages {\n+    font-style: normal;\n+}\n+\n+a[data-toggle=\"tooltip\"] {\n+    color: #649345;\n+    font-style: italic;\n+    cursor: default;\n+}\n+\n+.seriesNext, .seriesContext {\n+    margin-top: 15px;\n+    margin-bottom: 15px;\n+}\n+\n+.seriescontext ol li {\n+    list-style-type: upper-roman;\n+}\n+\n+ol.series li {\n+    list-style-type: decimal;\n+    margin-left: 40px;\n+    padding-left: 0;\n+}\n+\n+.siteTagline {\n+    font-size: 200%;\n+    font-weight: bold;\n+    color: silver;\n+    font-family: monospace;\n+    text-align: center;\n+    line-height: 10px;\n+    margin: 20px 0;\n+    display: block;\n+}\n+\n+.versionTagline {\n+    text-align: center;\n+    margin-bottom: 20px;\n+    font-family: courier;\n+    color: silver;\n+    color: #444;\n+    display:block;\n+}\n+\n+#mysidebar .nav ul {\n+    background-color: #FAFAFA;\n+}\n+.nav ul.series li {\n+    list-style: decimal;\n+    font-size:12px;\n+}\n+\n+.nav ul.series li a:hover {\n+    background-color: gray;\n+}\n+.nav ul.series {\n+    padding-left: 30px;\n+}\n+\n+.nav ul.series {\n+    background-color: #FAFAFA;\n+}\n+\n+/*\n+a.dropdown-toggle.otherProgLangs {\n+    color: #f7e68f !important;\n+}\n+*/\n+\n+span.muted {color: #666;}\n+\n+table code {background-color: transparent;}\n+\n+.highlight .err {\n+    color: #a61717;\n+    background-color: transparent !important;\n+}\n+\n+#json-box-container pre {\n+    margin: 0;\n+}\n+\n+.video-js {\n+    margin: 30px 0;\n+}\n+\n+video {\n+    display: block;\n+    margin: 30px 0;\n+    border: 1px solid #c0c0c0;\n+}\n+\n+\n+p.required, p.dataType {display: block; color: #c0c0c0; font-size: 80%; margin-left:4px;}\n+\n+dd {margin-left:20px;}\n+\n+.post-content img.inline {\n+    margin:0;\n+    margin-bottom:6px;\n+}\n+.panel-heading {\n+    font-weight: bold;\n+}\n+\n+a.accordion-toggle {\n+    font-style: normal;\n+}\n+\n+span.red {\n+    color: red;\n+    font-family: Monaco, Menlo, Consolas, \"Courier New\", monospace;\n+}\n+\n+h3.codeExplanation {\n+    font-size:18px;\n+    font-style:normal;\n+    color: black;\n+    line-height: 24px;\n+}\n+\n+span.soft {\n+    color: #c0c0c0;\n+}\n+\n+.githubEditButton {\n+    margin-bottom:7px;\n+}\n+\n+.endpoint {\n+    padding: 15px;\n+    background-color: #f0f0f0;\n+    font-family: courier;\n+    font-size: 110%;\n+    margin: 20px 0;\n+    color: #444;\n+}\n+\n+.parameter {\n+    font-family: courier;\n+    color: red !important;\n+}\n+\n+.formBoundary {\n+    border: 1px solid gray;\n+    padding: 15px;\n+    margin: 15px 0;\n+    background-color: whitesmoke;\n+}\n+\n+@media (max-width: 767px) {\n+    .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {\n+        color: #444;\n+    }\n+}\n+\n+@media (max-width: 990px) {\n+    #mysidebar {\n+        position: relative;\n+    }\n+}\n+\n+@media (min-width: 1000px) {\n+\n+    ul#mysidebar {\n+        width: 225px;\n+    }\n+}\n+\n+@media (max-width: 900px) {\n+\n+    ul#mysidebar {\n+        max-width: 100%;\n+    }\n+}\n+\n+.col-md-9 img {\n+    max-width: 100%;\n+    max-height: 100%;\n+}\n+\n+.videoThumbs img {\n+    float: left;\n+    margin:15px 15px 15px 0;\n+    box-shadow: 2px 2px 1px #f0f0f0;\n+    border: 1px solid #dedede;\n+}\n+\n+@media only screen and (min-width: 900px)\n+{.col-md-9 img {\n+        max-width: 700px;\n+        max-height: 700px;\n+    }\n+}\n+\n+@media only screen and (min-device-width: 900px)\n+{.col-md-9 img {\n+        max-width: 700px;\n+        max-height: 700px;\n+    }\n+}\n+*:hover > .anchorjs-link {\n+    transition: color .25s linear;\n+    text-decoration: none;\n+}\n+\n+.kbCaption {\n+    color: white;\n+    background-color: #444;\n+    padding:10px;\n+}\n+\n+.btn-default {\n+    margin-bottom: 10px;\n+}\n+\n+/* algolia search */\n+\n+.search {\n+    text-align: left;\n+}\n+.search input {\n+    font-size: 20px;\n+    width: 300px;\n+}\n+.results {\n+    margin: auto;\n+    text-align: left;\n+}\n+.results ul {\n+    list-style-type: none;\n+    padding: 0;\n+}\n+\n+/* algolia */\n+\n+div.results {\n+    position: absolute;\n+    background-color: white;\n+    width: 100%;\n+}\n+\n+.post-meta {\n+    font-size: 14px;\n+    color: #828282;\n+}\n+\n+.post-link {\n+    font-size: 22px;\n+}\n+\n+.post-list p {\n+    margin: 10px 0;\n+}\n+\n+time {\n+    margin-right: 10px;\n+}\n+\n+p.post-meta time {\n+    margin-right: 0;\n+}\n+\n+span.label.label-default {\n+    background-color: gray;\n+}\n+\n+span.label.label-primary {\n+    background-color: #f0ad4e;\n+}\n+.col-lg-12 .nav li a {background-color: white}\n+\n+a code {\n+    color: ##2156a5;\n+}\n+\n+table th code {\n+    color: white;\n+}\n+\n+ol li ul li ol li {\n+    list-style: decimal;\n+}\n+\n+ol li ul li ol li ul li{\n+    list-style: disc;\n+}\n+\n+\n+.box {\n+    padding: 10px;\n+    border: 1px solid #888;\n+    box-shadow: 2px 2px 4px #dedede;\n+    width: 100px;\n+    height: 80px;\n+    background-color: #f5f5f5;\n+    font-family: Arial;\n+    font-size: 12px;\n+    hyphens: auto;\n+    float: left;\n+}\n+\n+.box:hover {\n+    background-color: #f0f0f0;\n+}\n+\n+#userMap {\n+    overflow-x: auto;\n+    overflow-y: auto;\n+    padding: 20px;\n+    min-width: 770px;\n+}\n+\n+#userMap .active {\n+    background-color: #d6f5d6;\n+    border:1px solid #555;\n+    font-weight: bold;\n+}\n+\n+h2.userMapTitle {\n+    font-family: Arial;\n+}\n+\n+#userMap a:hover {\n+    text-decoration: none;\n+  }\n+\n+div.arrow {\n+    max-width: 50px;\n+    margin-left: 15px;\n+    margin-right: 15px;\n+    font-size: 20px;\n+}\n+\n+#userMap div.arrow, #userMap div.content {\n+    float: left;\n+}\n+\n+.clearfix {\n+    clear: both;\n+}\n+\n+\n+#userMap div.arrow {\n+    position: relative;\n+    top: 30px;\n+}\n+\n+.box1 {\n+    margin-left:0;\n+}\n+\n+button.btn.btn-default.btn-lg.modalButton1 {\n+    margin-left: -20px;\n+}\n+\n+div.box.box1 {\n+    margin-left: -20px;\n+}\n+\n+#userMap .btn-lg {\n+    width: 100px;\n+    height: 80px;\n+\n+}\n+\n+#userMap .complexArrow {\n+    font-size: 22px;\n+    margin: 0 10px;\n+}\n+\n+\n+#userMap .btn-lg .active {\n+    background-color: #d6f5d6;\n+}\n+\n+#userMap .btn-lg  {\n+        white-space: pre-wrap;       /* css-3 */\n+        white-space: -moz-pre-wrap;  /* Mozilla, since 1999 */\n+        white-space: -pre-wrap;      /* Opera 4-6 */\n+        white-space: -o-pre-wrap;    /* Opera 7 */\n+        word-wrap: break-word;       /* Internet Explorer 5.5+ */\n+        font-size: 14px;\n+    }\n+\n+/*\n+ * Let's target IE to respect aspect ratios and sizes for img tags containing SVG files\n+ *\n+ * [1] IE9\n+ * [2] IE10+\n+ */\n+/* 1 */\n+.ie9 img[src$=\".svg\"] {\n+    width: 100%;\n+}\n+/* 2 */\n+@media screen and (-ms-high-contrast: active), (-ms-high-contrast: none) {\n+    img[src$=\".svg\"] {\n+        width: 100%;\n+    }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/customstyles.css",
                "sha": "057cd86e3dd58d271abbcbd1fba079f85e6804c1",
                "status": "added"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/font-awesome.min.css",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/font-awesome.min.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/font-awesome.min.css",
                "patch": "@@ -0,0 +1,4 @@\n+/*!\n+ *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome\n+ *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)\n+ */@font-face{font-family:'FontAwesome';src:url('../fonts/fontawesome/fontawesome-webfont.eot?v=4.2.0');src:url('../fonts/fontawesome/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'),url('../fonts/fontawesome/fontawesome-webfont.woff?v=4.2.0') format('woff'),url('../fonts/fontawesome/fontawesome-webfont.ttf?v=4.2.0') format('truetype'),url('../fonts/fontawesome/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');font-weight:normal;font-style:normal}.fa{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.fa-lg{font-size:1.33333333em;line-height:.75em;vertical-align:-15%}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-fw{width:1.28571429em;text-align:center}.fa-ul{padding-left:0;margin-left:2.14285714em;list-style-type:none}.fa-ul>li{position:relative}.fa-li{position:absolute;left:-2.14285714em;width:2.14285714em;top:.14285714em;text-align:center}.fa-li.fa-lg{left:-1.85714286em}.fa-border{padding:.2em .25em .15em;border:solid .08em #eee;border-radius:.1em}.pull-right{float:right}.pull-left{float:left}.fa.pull-left{margin-right:.3em}.fa.pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}100%{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}100%{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}.fa-rotate-90{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=1);-webkit-transform:rotate(90deg);-ms-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=2);-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=3);-webkit-transform:rotate(270deg);-ms-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);-webkit-transform:scale(-1, 1);-ms-transform:scale(-1, 1);transform:scale(-1, 1)}.fa-flip-vertical{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);-webkit-transform:scale(1, -1);-ms-transform:scale(1, -1);transform:scale(1, -1)}:root .fa-rotate-90,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-flip-horizontal,:root .fa-flip-vertical{filter:none}.fa-stack{position:relative;display:inline-block;width:2em;height:2em;line-height:2em;vertical-align:middle}.fa-stack-1x,.fa-stack-2x{position:absolute;left:0;width:100%;text-align:center}.fa-stack-1x{line-height:inherit}.fa-stack-2x{font-size:2em}.fa-inverse{color:#fff}.fa-glass:before{content:\"\\f000\"}.fa-music:before{content:\"\\f001\"}.fa-search:before{content:\"\\f002\"}.fa-envelope-o:before{content:\"\\f003\"}.fa-heart:before{content:\"\\f004\"}.fa-star:before{content:\"\\f005\"}.fa-star-o:before{content:\"\\f006\"}.fa-user:before{content:\"\\f007\"}.fa-film:before{content:\"\\f008\"}.fa-th-large:before{content:\"\\f009\"}.fa-th:before{content:\"\\f00a\"}.fa-th-list:before{content:\"\\f00b\"}.fa-check:before{content:\"\\f00c\"}.fa-remove:before,.fa-close:before,.fa-times:before{content:\"\\f00d\"}.fa-search-plus:before{content:\"\\f00e\"}.fa-search-minus:before{content:\"\\f010\"}.fa-power-off:before{content:\"\\f011\"}.fa-signal:before{content:\"\\f012\"}.fa-gear:before,.fa-cog:before{content:\"\\f013\"}.fa-trash-o:before{content:\"\\f014\"}.fa-home:before{content:\"\\f015\"}.fa-file-o:before{content:\"\\f016\"}.fa-clock-o:before{content:\"\\f017\"}.fa-road:before{content:\"\\f018\"}.fa-download:before{content:\"\\f019\"}.fa-arrow-circle-o-down:before{content:\"\\f01a\"}.fa-arrow-circle-o-up:before{content:\"\\f01b\"}.fa-inbox:before{content:\"\\f01c\"}.fa-play-circle-o:before{content:\"\\f01d\"}.fa-rotate-right:before,.fa-repeat:before{content:\"\\f01e\"}.fa-refresh:before{content:\"\\f021\"}.fa-list-alt:before{content:\"\\f022\"}.fa-lock:before{content:\"\\f023\"}.fa-flag:before{content:\"\\f024\"}.fa-headphones:before{content:\"\\f025\"}.fa-volume-off:before{content:\"\\f026\"}.fa-volume-down:before{content:\"\\f027\"}.fa-volume-up:before{content:\"\\f028\"}.fa-qrcode:before{content:\"\\f029\"}.fa-barcode:before{content:\"\\f02a\"}.fa-tag:before{content:\"\\f02b\"}.fa-tags:before{content:\"\\f02c\"}.fa-book:before{content:\"\\f02d\"}.fa-bookmark:before{content:\"\\f02e\"}.fa-print:before{content:\"\\f02f\"}.fa-camera:before{content:\"\\f030\"}.fa-font:before{content:\"\\f031\"}.fa-bold:before{content:\"\\f032\"}.fa-italic:before{content:\"\\f033\"}.fa-text-height:before{content:\"\\f034\"}.fa-text-width:before{content:\"\\f035\"}.fa-align-left:before{content:\"\\f036\"}.fa-align-center:before{content:\"\\f037\"}.fa-align-right:before{content:\"\\f038\"}.fa-align-justify:before{content:\"\\f039\"}.fa-list:before{content:\"\\f03a\"}.fa-dedent:before,.fa-outdent:before{content:\"\\f03b\"}.fa-indent:before{content:\"\\f03c\"}.fa-video-camera:before{content:\"\\f03d\"}.fa-photo:before,.fa-image:before,.fa-picture-o:before{content:\"\\f03e\"}.fa-pencil:before{content:\"\\f040\"}.fa-map-marker:before{content:\"\\f041\"}.fa-adjust:before{content:\"\\f042\"}.fa-tint:before{content:\"\\f043\"}.fa-edit:before,.fa-pencil-square-o:before{content:\"\\f044\"}.fa-share-square-o:before{content:\"\\f045\"}.fa-check-square-o:before{content:\"\\f046\"}.fa-arrows:before{content:\"\\f047\"}.fa-step-backward:before{content:\"\\f048\"}.fa-fast-backward:before{content:\"\\f049\"}.fa-backward:before{content:\"\\f04a\"}.fa-play:before{content:\"\\f04b\"}.fa-pause:before{content:\"\\f04c\"}.fa-stop:before{content:\"\\f04d\"}.fa-forward:before{content:\"\\f04e\"}.fa-fast-forward:before{content:\"\\f050\"}.fa-step-forward:before{content:\"\\f051\"}.fa-eject:before{content:\"\\f052\"}.fa-chevron-left:before{content:\"\\f053\"}.fa-chevron-right:before{content:\"\\f054\"}.fa-plus-circle:before{content:\"\\f055\"}.fa-minus-circle:before{content:\"\\f056\"}.fa-times-circle:before{content:\"\\f057\"}.fa-check-circle:before{content:\"\\f058\"}.fa-question-circle:before{content:\"\\f059\"}.fa-info-circle:before{content:\"\\f05a\"}.fa-crosshairs:before{content:\"\\f05b\"}.fa-times-circle-o:before{content:\"\\f05c\"}.fa-check-circle-o:before{content:\"\\f05d\"}.fa-ban:before{content:\"\\f05e\"}.fa-arrow-left:before{content:\"\\f060\"}.fa-arrow-right:before{content:\"\\f061\"}.fa-arrow-up:before{content:\"\\f062\"}.fa-arrow-down:before{content:\"\\f063\"}.fa-mail-forward:before,.fa-share:before{content:\"\\f064\"}.fa-expand:before{content:\"\\f065\"}.fa-compress:before{content:\"\\f066\"}.fa-plus:before{content:\"\\f067\"}.fa-minus:before{content:\"\\f068\"}.fa-asterisk:before{content:\"\\f069\"}.fa-exclamation-circle:before{content:\"\\f06a\"}.fa-gift:before{content:\"\\f06b\"}.fa-leaf:before{content:\"\\f06c\"}.fa-fire:before{content:\"\\f06d\"}.fa-eye:before{content:\"\\f06e\"}.fa-eye-slash:before{content:\"\\f070\"}.fa-warning:before,.fa-exclamation-triangle:before{content:\"\\f071\"}.fa-plane:before{content:\"\\f072\"}.fa-calendar:before{content:\"\\f073\"}.fa-random:before{content:\"\\f074\"}.fa-comment:before{content:\"\\f075\"}.fa-magnet:before{content:\"\\f076\"}.fa-chevron-up:before{content:\"\\f077\"}.fa-chevron-down:before{content:\"\\f078\"}.fa-retweet:before{content:\"\\f079\"}.fa-shopping-cart:before{content:\"\\f07a\"}.fa-folder:before{content:\"\\f07b\"}.fa-folder-open:before{content:\"\\f07c\"}.fa-arrows-v:before{content:\"\\f07d\"}.fa-arrows-h:before{content:\"\\f07e\"}.fa-bar-chart-o:before,.fa-bar-chart:before{content:\"\\f080\"}.fa-twitter-square:before{content:\"\\f081\"}.fa-facebook-square:before{content:\"\\f082\"}.fa-camera-retro:before{content:\"\\f083\"}.fa-key:before{content:\"\\f084\"}.fa-gears:before,.fa-cogs:before{content:\"\\f085\"}.fa-comments:before{content:\"\\f086\"}.fa-thumbs-o-up:before{content:\"\\f087\"}.fa-thumbs-o-down:before{content:\"\\f088\"}.fa-star-half:before{content:\"\\f089\"}.fa-heart-o:before{content:\"\\f08a\"}.fa-sign-out:before{content:\"\\f08b\"}.fa-linkedin-square:before{content:\"\\f08c\"}.fa-thumb-tack:before{content:\"\\f08d\"}.fa-external-link:before{content:\"\\f08e\"}.fa-sign-in:before{content:\"\\f090\"}.fa-trophy:before{content:\"\\f091\"}.fa-github-square:before{content:\"\\f092\"}.fa-upload:before{content:\"\\f093\"}.fa-lemon-o:before{content:\"\\f094\"}.fa-phone:before{content:\"\\f095\"}.fa-square-o:before{content:\"\\f096\"}.fa-bookmark-o:before{content:\"\\f097\"}.fa-phone-square:before{content:\"\\f098\"}.fa-twitter:before{content:\"\\f099\"}.fa-facebook:before{content:\"\\f09a\"}.fa-github:before{content:\"\\f09b\"}.fa-unlock:before{content:\"\\f09c\"}.fa-credit-card:before{content:\"\\f09d\"}.fa-rss:before{content:\"\\f09e\"}.fa-hdd-o:before{content:\"\\f0a0\"}.fa-bullhorn:before{content:\"\\f0a1\"}.fa-bell:before{content:\"\\f0f3\"}.fa-certificate:before{content:\"\\f0a3\"}.fa-hand-o-right:before{content:\"\\f0a4\"}.fa-hand-o-left:before{content:\"\\f0a5\"}.fa-hand-o-up:before{content:\"\\f0a6\"}.fa-hand-o-down:before{content:\"\\f0a7\"}.fa-arrow-circle-left:before{content:\"\\f0a8\"}.fa-arrow-circle-right:before{content:\"\\f0a9\"}.fa-arrow-circle-up:before{content:\"\\f0aa\"}.fa-arrow-circle-down:before{content:\"\\f0ab\"}.fa-globe:before{content:\"\\f0ac\"}.fa-wrench:before{content:\"\\f0ad\"}.fa-tasks:before{content:\"\\f0ae\"}.fa-filter:before{content:\"\\f0b0\"}.fa-briefcase:before{content:\"\\f0b1\"}.fa-arrows-alt:before{content:\"\\f0b2\"}.fa-group:before,.fa-users:before{content:\"\\f0c0\"}.fa-chain:before,.fa-link:before{content:\"\\f0c1\"}.fa-cloud:before{content:\"\\f0c2\"}.fa-flask:before{content:\"\\f0c3\"}.fa-cut:before,.fa-scissors:before{content:\"\\f0c4\"}.fa-copy:before,.fa-files-o:before{content:\"\\f0c5\"}.fa-paperclip:before{content:\"\\f0c6\"}.fa-save:before,.fa-floppy-o:before{content:\"\\f0c7\"}.fa-square:before{content:\"\\f0c8\"}.fa-navicon:before,.fa-reorder:before,.fa-bars:before{content:\"\\f0c9\"}.fa-list-ul:before{content:\"\\f0ca\"}.fa-list-ol:before{content:\"\\f0cb\"}.fa-strikethrough:before{content:\"\\f0cc\"}.fa-underline:before{content:\"\\f0cd\"}.fa-table:before{content:\"\\f0ce\"}.fa-magic:before{content:\"\\f0d0\"}.fa-truck:before{content:\"\\f0d1\"}.fa-pinterest:before{content:\"\\f0d2\"}.fa-pinterest-square:before{content:\"\\f0d3\"}.fa-google-plus-square:before{content:\"\\f0d4\"}.fa-google-plus:before{content:\"\\f0d5\"}.fa-money:before{content:\"\\f0d6\"}.fa-caret-down:before{content:\"\\f0d7\"}.fa-caret-up:before{content:\"\\f0d8\"}.fa-caret-left:before{content:\"\\f0d9\"}.fa-caret-right:before{content:\"\\f0da\"}.fa-columns:before{content:\"\\f0db\"}.fa-unsorted:before,.fa-sort:before{content:\"\\f0dc\"}.fa-sort-down:before,.fa-sort-desc:before{content:\"\\f0dd\"}.fa-sort-up:before,.fa-sort-asc:before{content:\"\\f0de\"}.fa-envelope:before{content:\"\\f0e0\"}.fa-linkedin:before{content:\"\\f0e1\"}.fa-rotate-left:before,.fa-undo:before{content:\"\\f0e2\"}.fa-legal:before,.fa-gavel:before{content:\"\\f0e3\"}.fa-dashboard:before,.fa-tachometer:before{content:\"\\f0e4\"}.fa-comment-o:before{content:\"\\f0e5\"}.fa-comments-o:before{content:\"\\f0e6\"}.fa-flash:before,.fa-bolt:before{content:\"\\f0e7\"}.fa-sitemap:before{content:\"\\f0e8\"}.fa-umbrella:before{content:\"\\f0e9\"}.fa-paste:before,.fa-clipboard:before{content:\"\\f0ea\"}.fa-lightbulb-o:before{content:\"\\f0eb\"}.fa-exchange:before{content:\"\\f0ec\"}.fa-cloud-download:before{content:\"\\f0ed\"}.fa-cloud-upload:before{content:\"\\f0ee\"}.fa-user-md:before{content:\"\\f0f0\"}.fa-stethoscope:before{content:\"\\f0f1\"}.fa-suitcase:before{content:\"\\f0f2\"}.fa-bell-o:before{content:\"\\f0a2\"}.fa-coffee:before{content:\"\\f0f4\"}.fa-cutlery:before{content:\"\\f0f5\"}.fa-file-text-o:before{content:\"\\f0f6\"}.fa-building-o:before{content:\"\\f0f7\"}.fa-hospital-o:before{content:\"\\f0f8\"}.fa-ambulance:before{content:\"\\f0f9\"}.fa-medkit:before{content:\"\\f0fa\"}.fa-fighter-jet:before{content:\"\\f0fb\"}.fa-beer:before{content:\"\\f0fc\"}.fa-h-square:before{content:\"\\f0fd\"}.fa-plus-square:before{content:\"\\f0fe\"}.fa-angle-double-left:before{content:\"\\f100\"}.fa-angle-double-right:before{content:\"\\f101\"}.fa-angle-double-up:before{content:\"\\f102\"}.fa-angle-double-down:before{content:\"\\f103\"}.fa-angle-left:before{content:\"\\f104\"}.fa-angle-right:before{content:\"\\f105\"}.fa-angle-up:before{content:\"\\f106\"}.fa-angle-down:before{content:\"\\f107\"}.fa-desktop:before{content:\"\\f108\"}.fa-laptop:before{content:\"\\f109\"}.fa-tablet:before{content:\"\\f10a\"}.fa-mobile-phone:before,.fa-mobile:before{content:\"\\f10b\"}.fa-circle-o:before{content:\"\\f10c\"}.fa-quote-left:before{content:\"\\f10d\"}.fa-quote-right:before{content:\"\\f10e\"}.fa-spinner:before{content:\"\\f110\"}.fa-circle:before{content:\"\\f111\"}.fa-mail-reply:before,.fa-reply:before{content:\"\\f112\"}.fa-github-alt:before{content:\"\\f113\"}.fa-folder-o:before{content:\"\\f114\"}.fa-folder-open-o:before{content:\"\\f115\"}.fa-smile-o:before{content:\"\\f118\"}.fa-frown-o:before{content:\"\\f119\"}.fa-meh-o:before{content:\"\\f11a\"}.fa-gamepad:before{content:\"\\f11b\"}.fa-keyboard-o:before{content:\"\\f11c\"}.fa-flag-o:before{content:\"\\f11d\"}.fa-flag-checkered:before{content:\"\\f11e\"}.fa-terminal:before{content:\"\\f120\"}.fa-code:before{content:\"\\f121\"}.fa-mail-reply-all:before,.fa-reply-all:before{content:\"\\f122\"}.fa-star-half-empty:before,.fa-star-half-full:before,.fa-star-half-o:before{content:\"\\f123\"}.fa-location-arrow:before{content:\"\\f124\"}.fa-crop:before{content:\"\\f125\"}.fa-code-fork:before{content:\"\\f126\"}.fa-unlink:before,.fa-chain-broken:before{content:\"\\f127\"}.fa-question:before{content:\"\\f128\"}.fa-info:before{content:\"\\f129\"}.fa-exclamation:before{content:\"\\f12a\"}.fa-superscript:before{content:\"\\f12b\"}.fa-subscript:before{content:\"\\f12c\"}.fa-eraser:before{content:\"\\f12d\"}.fa-puzzle-piece:before{content:\"\\f12e\"}.fa-microphone:before{content:\"\\f130\"}.fa-microphone-slash:before{content:\"\\f131\"}.fa-shield:before{content:\"\\f132\"}.fa-calendar-o:before{content:\"\\f133\"}.fa-fire-extinguisher:before{content:\"\\f134\"}.fa-rocket:before{content:\"\\f135\"}.fa-maxcdn:before{content:\"\\f136\"}.fa-chevron-circle-left:before{content:\"\\f137\"}.fa-chevron-circle-right:before{content:\"\\f138\"}.fa-chevron-circle-up:before{content:\"\\f139\"}.fa-chevron-circle-down:before{content:\"\\f13a\"}.fa-html5:before{content:\"\\f13b\"}.fa-css3:before{content:\"\\f13c\"}.fa-anchor:before{content:\"\\f13d\"}.fa-unlock-alt:before{content:\"\\f13e\"}.fa-bullseye:before{content:\"\\f140\"}.fa-ellipsis-h:before{content:\"\\f141\"}.fa-ellipsis-v:before{content:\"\\f142\"}.fa-rss-square:before{content:\"\\f143\"}.fa-play-circle:before{content:\"\\f144\"}.fa-ticket:before{content:\"\\f145\"}.fa-minus-square:before{content:\"\\f146\"}.fa-minus-square-o:before{content:\"\\f147\"}.fa-level-up:before{content:\"\\f148\"}.fa-level-down:before{content:\"\\f149\"}.fa-check-square:before{content:\"\\f14a\"}.fa-pencil-square:before{content:\"\\f14b\"}.fa-external-link-square:before{content:\"\\f14c\"}.fa-share-square:before{content:\"\\f14d\"}.fa-compass:before{content:\"\\f14e\"}.fa-toggle-down:before,.fa-caret-square-o-down:before{content:\"\\f150\"}.fa-toggle-up:before,.fa-caret-square-o-up:before{content:\"\\f151\"}.fa-toggle-right:before,.fa-caret-square-o-right:before{content:\"\\f152\"}.fa-euro:before,.fa-eur:before{content:\"\\f153\"}.fa-gbp:before{content:\"\\f154\"}.fa-dollar:before,.fa-usd:before{content:\"\\f155\"}.fa-rupee:before,.fa-inr:before{content:\"\\f156\"}.fa-cny:before,.fa-rmb:before,.fa-yen:before,.fa-jpy:before{content:\"\\f157\"}.fa-ruble:before,.fa-rouble:before,.fa-rub:before{content:\"\\f158\"}.fa-won:before,.fa-krw:before{content:\"\\f159\"}.fa-bitcoin:before,.fa-btc:before{content:\"\\f15a\"}.fa-file:before{content:\"\\f15b\"}.fa-file-text:before{content:\"\\f15c\"}.fa-sort-alpha-asc:before{content:\"\\f15d\"}.fa-sort-alpha-desc:before{content:\"\\f15e\"}.fa-sort-amount-asc:before{content:\"\\f160\"}.fa-sort-amount-desc:before{content:\"\\f161\"}.fa-sort-numeric-asc:before{content:\"\\f162\"}.fa-sort-numeric-desc:before{content:\"\\f163\"}.fa-thumbs-up:before{content:\"\\f164\"}.fa-thumbs-down:before{content:\"\\f165\"}.fa-youtube-square:before{content:\"\\f166\"}.fa-youtube:before{content:\"\\f167\"}.fa-xing:before{content:\"\\f168\"}.fa-xing-square:before{content:\"\\f169\"}.fa-youtube-play:before{content:\"\\f16a\"}.fa-dropbox:before{content:\"\\f16b\"}.fa-stack-overflow:before{content:\"\\f16c\"}.fa-instagram:before{content:\"\\f16d\"}.fa-flickr:before{content:\"\\f16e\"}.fa-adn:before{content:\"\\f170\"}.fa-bitbucket:before{content:\"\\f171\"}.fa-bitbucket-square:before{content:\"\\f172\"}.fa-tumblr:before{content:\"\\f173\"}.fa-tumblr-square:before{content:\"\\f174\"}.fa-long-arrow-down:before{content:\"\\f175\"}.fa-long-arrow-up:before{content:\"\\f176\"}.fa-long-arrow-left:before{content:\"\\f177\"}.fa-long-arrow-right:before{content:\"\\f178\"}.fa-apple:before{content:\"\\f179\"}.fa-windows:before{content:\"\\f17a\"}.fa-android:before{content:\"\\f17b\"}.fa-linux:before{content:\"\\f17c\"}.fa-dribbble:before{content:\"\\f17d\"}.fa-skype:before{content:\"\\f17e\"}.fa-foursquare:before{content:\"\\f180\"}.fa-trello:before{content:\"\\f181\"}.fa-female:before{content:\"\\f182\"}.fa-male:before{content:\"\\f183\"}.fa-gittip:before{content:\"\\f184\"}.fa-sun-o:before{content:\"\\f185\"}.fa-moon-o:before{content:\"\\f186\"}.fa-archive:before{content:\"\\f187\"}.fa-bug:before{content:\"\\f188\"}.fa-vk:before{content:\"\\f189\"}.fa-weibo:before{content:\"\\f18a\"}.fa-renren:before{content:\"\\f18b\"}.fa-pagelines:before{content:\"\\f18c\"}.fa-stack-exchange:before{content:\"\\f18d\"}.fa-arrow-circle-o-right:before{content:\"\\f18e\"}.fa-arrow-circle-o-left:before{content:\"\\f190\"}.fa-toggle-left:before,.fa-caret-square-o-left:before{content:\"\\f191\"}.fa-dot-circle-o:before{content:\"\\f192\"}.fa-wheelchair:before{content:\"\\f193\"}.fa-vimeo-square:before{content:\"\\f194\"}.fa-turkish-lira:before,.fa-try:before{content:\"\\f195\"}.fa-plus-square-o:before{content:\"\\f196\"}.fa-space-shuttle:before{content:\"\\f197\"}.fa-slack:before{content:\"\\f198\"}.fa-envelope-square:before{content:\"\\f199\"}.fa-wordpress:before{content:\"\\f19a\"}.fa-openid:before{content:\"\\f19b\"}.fa-institution:before,.fa-bank:before,.fa-university:before{content:\"\\f19c\"}.fa-mortar-board:before,.fa-graduation-cap:before{content:\"\\f19d\"}.fa-yahoo:before{content:\"\\f19e\"}.fa-google:before{content:\"\\f1a0\"}.fa-reddit:before{content:\"\\f1a1\"}.fa-reddit-square:before{content:\"\\f1a2\"}.fa-stumbleupon-circle:before{content:\"\\f1a3\"}.fa-stumbleupon:before{content:\"\\f1a4\"}.fa-delicious:before{content:\"\\f1a5\"}.fa-digg:before{content:\"\\f1a6\"}.fa-pied-piper:before{content:\"\\f1a7\"}.fa-pied-piper-alt:before{content:\"\\f1a8\"}.fa-drupal:before{content:\"\\f1a9\"}.fa-joomla:before{content:\"\\f1aa\"}.fa-language:before{content:\"\\f1ab\"}.fa-fax:before{content:\"\\f1ac\"}.fa-building:before{content:\"\\f1ad\"}.fa-child:before{content:\"\\f1ae\"}.fa-paw:before{content:\"\\f1b0\"}.fa-spoon:before{content:\"\\f1b1\"}.fa-cube:before{content:\"\\f1b2\"}.fa-cubes:before{content:\"\\f1b3\"}.fa-behance:before{content:\"\\f1b4\"}.fa-behance-square:before{content:\"\\f1b5\"}.fa-steam:before{content:\"\\f1b6\"}.fa-steam-square:before{content:\"\\f1b7\"}.fa-recycle:before{content:\"\\f1b8\"}.fa-automobile:before,.fa-car:before{content:\"\\f1b9\"}.fa-cab:before,.fa-taxi:before{content:\"\\f1ba\"}.fa-tree:before{content:\"\\f1bb\"}.fa-spotify:before{content:\"\\f1bc\"}.fa-deviantart:before{content:\"\\f1bd\"}.fa-soundcloud:before{content:\"\\f1be\"}.fa-database:before{content:\"\\f1c0\"}.fa-file-pdf-o:before{content:\"\\f1c1\"}.fa-file-word-o:before{content:\"\\f1c2\"}.fa-file-excel-o:before{content:\"\\f1c3\"}.fa-file-powerpoint-o:before{content:\"\\f1c4\"}.fa-file-photo-o:before,.fa-file-picture-o:before,.fa-file-image-o:before{content:\"\\f1c5\"}.fa-file-zip-o:before,.fa-file-archive-o:before{content:\"\\f1c6\"}.fa-file-sound-o:before,.fa-file-audio-o:before{content:\"\\f1c7\"}.fa-file-movie-o:before,.fa-file-video-o:before{content:\"\\f1c8\"}.fa-file-code-o:before{content:\"\\f1c9\"}.fa-vine:before{content:\"\\f1ca\"}.fa-codepen:before{content:\"\\f1cb\"}.fa-jsfiddle:before{content:\"\\f1cc\"}.fa-life-bouy:before,.fa-life-buoy:before,.fa-life-saver:before,.fa-support:before,.fa-life-ring:before{content:\"\\f1cd\"}.fa-circle-o-notch:before{content:\"\\f1ce\"}.fa-ra:before,.fa-rebel:before{content:\"\\f1d0\"}.fa-ge:before,.fa-empire:before{content:\"\\f1d1\"}.fa-git-square:before{content:\"\\f1d2\"}.fa-git:before{content:\"\\f1d3\"}.fa-hacker-news:before{content:\"\\f1d4\"}.fa-tencent-weibo:before{content:\"\\f1d5\"}.fa-qq:before{content:\"\\f1d6\"}.fa-wechat:before,.fa-weixin:before{content:\"\\f1d7\"}.fa-send:before,.fa-paper-plane:before{content:\"\\f1d8\"}.fa-send-o:before,.fa-paper-plane-o:before{content:\"\\f1d9\"}.fa-history:before{content:\"\\f1da\"}.fa-circle-thin:before{content:\"\\f1db\"}.fa-header:before{content:\"\\f1dc\"}.fa-paragraph:before{content:\"\\f1dd\"}.fa-sliders:before{content:\"\\f1de\"}.fa-share-alt:before{content:\"\\f1e0\"}.fa-share-alt-square:before{content:\"\\f1e1\"}.fa-bomb:before{content:\"\\f1e2\"}.fa-soccer-ball-o:before,.fa-futbol-o:before{content:\"\\f1e3\"}.fa-tty:before{content:\"\\f1e4\"}.fa-binoculars:before{content:\"\\f1e5\"}.fa-plug:before{content:\"\\f1e6\"}.fa-slideshare:before{content:\"\\f1e7\"}.fa-twitch:before{content:\"\\f1e8\"}.fa-yelp:before{content:\"\\f1e9\"}.fa-newspaper-o:before{content:\"\\f1ea\"}.fa-wifi:before{content:\"\\f1eb\"}.fa-calculator:before{content:\"\\f1ec\"}.fa-paypal:before{content:\"\\f1ed\"}.fa-google-wallet:before{content:\"\\f1ee\"}.fa-cc-visa:before{content:\"\\f1f0\"}.fa-cc-mastercard:before{content:\"\\f1f1\"}.fa-cc-discover:before{content:\"\\f1f2\"}.fa-cc-amex:before{content:\"\\f1f3\"}.fa-cc-paypal:before{content:\"\\f1f4\"}.fa-cc-stripe:before{content:\"\\f1f5\"}.fa-bell-slash:before{content:\"\\f1f6\"}.fa-bell-slash-o:before{content:\"\\f1f7\"}.fa-trash:before{content:\"\\f1f8\"}.fa-copyright:before{content:\"\\f1f9\"}.fa-at:before{content:\"\\f1fa\"}.fa-eyedropper:before{content:\"\\f1fb\"}.fa-paint-brush:before{content:\"\\f1fc\"}.fa-birthday-cake:before{content:\"\\f1fd\"}.fa-area-chart:before{content:\"\\f1fe\"}.fa-pie-chart:before{content:\"\\f200\"}.fa-line-chart:before{content:\"\\f201\"}.fa-lastfm:before{content:\"\\f202\"}.fa-lastfm-square:before{content:\"\\f203\"}.fa-toggle-off:before{content:\"\\f204\"}.fa-toggle-on:before{content:\"\\f205\"}.fa-bicycle:before{content:\"\\f206\"}.fa-bus:before{content:\"\\f207\"}.fa-ioxhost:before{content:\"\\f208\"}.fa-angellist:before{content:\"\\f209\"}.fa-cc:before{content:\"\\f20a\"}.fa-shekel:before,.fa-sheqel:before,.fa-ils:before{content:\"\\f20b\"}.fa-meanpath:before{content:\"\\f20c\"}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/font-awesome.min.css",
                "sha": "3ec79c55f2b09fa625fc7b12fa38e9e0b19c9c5d",
                "status": "added"
            },
            {
                "additions": 5420,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/lavish-bootstrap.css",
                "changes": 5420,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/lavish-bootstrap.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/lavish-bootstrap.css",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/lavish-bootstrap.css",
                "sha": "e4c7395358afceaa90e10ce806ff7f5edaa403a8",
                "status": "added"
            },
            {
                "additions": 160,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/printstyles.css",
                "changes": 160,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/printstyles.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/printstyles.css",
                "patch": "@@ -0,0 +1,160 @@\n+\n+/*body.print .container {max-width: 650px;}*/\n+\n+body {\n+    font-size:14px;\n+}\n+.nav ul li a {border-top:0px; background-color:transparent; color: #808080; }\n+#navig a[href] {color: #595959 !important;}\n+table .table {max-width:650px;}\n+\n+#navig li.sectionHead {font-weight: bold; font-size: 18px; color: #595959 !important; }\n+#navig li {font-weight: normal; }\n+\n+#navig a[href]::after { content: leader(\".\") target-counter(attr(href), page); }\n+\n+a[href]::after {\n+    content: \" (page \" target-counter(attr(href), page) \")\"\n+}\n+\n+a[href^=\"http:\"]::after, a[href^=\"https:\"]::after {\n+    content: \" (\" attr(href) \")\";\n+}\n+\n+a[href] {\n+    color: blue !important;\n+}\n+a[href*=\"mailto\"]::after, a[data-toggle=\"tooltip\"]::after, a[href].noCrossRef::after {\n+    content: \"\";\n+}\n+\n+\n+@page {\n+    margin: 60pt 90pt 60pt 90pt;\n+    font-family: sans-serif;\n+    font-style:none;\n+    color: gray;\n+\n+}\n+\n+.printTitle {\n+    line-height:30pt;\n+    font-size:27pt;\n+    font-weight: bold;\n+    letter-spacing: -.5px;\n+    margin-bottom:25px;\n+}\n+\n+.printSubtitle {\n+    font-size: 19pt;\n+    color: #cccccc !important;\n+    front-family: \"Grotesque MT Light\";\n+    line-height: 22pt;\n+    letter-spacing: -.5px;\n+    margin-bottom:20px;\n+}\n+.printTitleArea hr {\n+    color: #999999 !important;\n+    height: 2px;\n+    width: 100%;\n+}\n+\n+.printTitleImage {\n+    max-width:300px;\n+    margin-bottom:200px;\n+}\n+\n+\n+.printTitleImage {\n+    max-width: 250px;\n+}\n+\n+#navig {\n+    /*page-break-before: always;*/\n+}\n+\n+.copyrightBoilerplate {\n+    page-break-before:always;\n+    font-size:14px;\n+}\n+\n+.lastGeneratedDate {\n+    font-style: italic;\n+    font-size:14px;\n+    color: gray;\n+}\n+\n+.alert a {\n+    text-decoration: none !important;\n+}\n+\n+\n+body.title { page: title }\n+\n+@page title {\n+    @top-left {\n+        content: \" \";\n+    }\n+    @top-right {\n+        content: \" \"\n+    }\n+    @bottom-right {\n+        content: \" \";\n+    }\n+    @bottom-left {\n+        content: \" \";\n+    }\n+}\n+\n+body.frontmatter { page: frontmatter }\n+body.frontmatter {counter-reset: page 1}\n+\n+\n+@page frontmatter {\n+    @top-left {\n+        content: prince-script(guideName);\n+    }\n+    @top-right {\n+        content: prince-script(datestamp);\n+    }\n+    @bottom-right {\n+        content: counter(page, lower-roman);\n+    }\n+    @bottom-left {\n+        content: \"youremail@domain.com\";   }\n+}\n+\n+body.first_page {counter-reset: page 1}\n+\n+h1 { string-set: doctitle content() }\n+\n+@page {\n+    @top-left {\n+        content: string(doctitle);\n+        font-size: 11px;\n+        font-style: italic;\n+    }\n+    @top-right {\n+        content: prince-script(datestamp);\n+        font-size: 11px;\n+    }\n+\n+    @bottom-right {\n+        content: \"Page \" counter(page);\n+        font-size: 11px;\n+    }\n+    @bottom-left {\n+        content: prince-script(guideName);\n+        font-size: 11px;\n+    }\n+}\n+.alert {\n+    background-color: #fafafa !important;\n+    border-color: #dedede !important;\n+    color: black;\n+}\n+\n+pre {\n+    background-color: #fafafa;\n+}\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/printstyles.css",
                "sha": "5e55e576519c19407cf0e8611af16b845da42851",
                "status": "added"
            },
            {
                "additions": 2822,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/ref-guide.css",
                "changes": 2822,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/ref-guide.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/ref-guide.css",
                "patch": "@@ -0,0 +1,2822 @@\n+/* Load Noto Sans for body and header text */\n+@font-face\n+{\n+    font-family: 'Noto Sans';\n+    src: url(../fonts/Noto_Sans/NotoSans-Regular.ttf);\n+}\n+\n+@font-face\n+{\n+    font-weight: bold;\n+    font-family: 'Noto Sans';\n+    src: url(../fonts/Noto_Sans/NotoSans-Bold.ttf);\n+}\n+\n+/* Load Inconsolata for monospace */\n+@font-face {\n+   font-family: 'Inconsolata';\n+   src: url(../fonts/Inconsolata/Inconsolata-Regular.ttf);\n+}\n+\n+@font-face {\n+   font-weight: bold;\n+   font-family: 'Inconsolata';\n+   src: url(../fonts/Inconsolata/Inconsolata-Bold.ttf);\n+}\n+\n+article,\n+aside,\n+details,\n+figcaption,\n+figure,\n+footer,\n+header,\n+hgroup,\n+main,\n+nav,\n+section,\n+summary\n+{\n+    display: block;\n+}\n+\n+audio,\n+canvas,\n+video\n+{\n+    display: inline-block;\n+}\n+\n+audio:not([controls])\n+{\n+    display: none;\n+    height: 0;\n+}\n+\n+[hidden],\n+template\n+{\n+    display: none;\n+}\n+\n+script\n+{\n+    display: none!important;\n+}\n+\n+html\n+{\n+    font-family: 'Noto Sans', sans-serif;\n+    -ms-text-size-adjust: 100%;\n+    -webkit-text-size-adjust: 100%;\n+}\n+\n+body\n+{\n+    margin: 0;\n+}\n+\n+a\n+{\n+    background: transparent;\n+}\n+\n+a:focus\n+{\n+    outline: thin dotted;\n+   outline-offset: -2px;\n+}\n+\n+a:active,\n+a:hover\n+{\n+    outline: 0;\n+}\n+\n+/* this part adds an icon after external links, using FontAwesome */\n+a[href^=\"http://\"]:after,\n+a[href^=\"https://\"]:after {\n+    content: \"\\f08e\";\n+    font-family: FontAwesome;\n+    font-weight: normal;\n+    font-style: normal;\n+    display: inline-block;\n+    text-decoration: none;\n+    padding-left: 3px;\n+    font-size: 12pt;\n+}\n+\n+/* Strip the outbound icon when this class is present */\n+a[href].noCrossRef::after,\n+a.no_icon:after\n+ {\n+    content:\"\" !important;\n+    padding-left: 0;\n+}\n+\n+/* indent extra nav levels\n+   TODO: is there any easy way to do this that just incrementally applies to anything below sb-level2?\n+         ...w/o assuming sb-level4 is as deep as we go?\n+*/\n+ul#mysidebar li.sb-level3 a {\n+   padding-left: 20px;\n+}\n+ul#mysidebar li.sb-level4 a {\n+   padding-left: 40px;\n+}\n+/* we can style the 'current-tree' hierarchy in the sidebar independently of the 'active' page as\n+   the user clicks around expanding/collapsing the nav menus w/o clicking a link to load a diff page\n+\n+   For now:\n+    - the 'current' page title is always bolder if 'active' (ie: visible)\n+    - if the 'current' page is not 'active'/visible, then the closest ancestor that *is* 'active'/visible\n+      will be bolded -- reminding the reader what section of the doc they are currently in.\n+*/\n+ul#mysidebar li.current-tree > a {\n+    font-weight: bolder;\n+}\n+ul#mysidebar li.current-tree.active > a {\n+    font-weight: inherit;\n+}\n+ul#mysidebar li.current.active > a {\n+    font-weight: bolder;\n+}\n+\n+\n+abbr[title]\n+{\n+    border-bottom: 1px dotted;\n+}\n+\n+b,\n+strong\n+{\n+    font-weight: bold;\n+}\n+\n+dfn\n+{\n+    font-style: italic;\n+}\n+\n+hr\n+{\n+    -moz-box-sizing: content-box;\n+         box-sizing: content-box;\n+    height: 0;\n+}\n+\n+mark\n+{\n+    background: #ff0;\n+    color: #000;\n+}\n+\n+code,\n+kbd,\n+pre,\n+samp\n+{\n+    font-size: 1em;\n+    font-family: 'Inconsolata', monospace;\n+}\n+\n+pre\n+{\n+    white-space: pre-wrap;\n+}\n+\n+q\n+{\n+    quotes: '\\201C' '\\201D' '\\2018' '\\2019';\n+}\n+\n+small\n+{\n+    font-size: 80%;\n+   line-height: inherit;\n+}\n+\n+sub,\n+sup\n+{\n+    position: relative;\n+    vertical-align: baseline;\n+    font-size: 75%;\n+    line-height: 0;\n+}\n+\n+sup\n+{\n+    top: -.5em;\n+}\n+\n+sub\n+{\n+    bottom: -.25em;\n+}\n+\n+img\n+{\n+    border: 0;\n+}\n+\n+svg:not(:root)\n+{\n+    overflow: hidden;\n+}\n+\n+figure\n+{\n+    margin: 0;\n+}\n+\n+fieldset\n+{\n+    margin: 0 2px;\n+    padding: .35em .625em .75em;\n+    border: 1px solid silver;\n+}\n+\n+legend\n+{\n+    padding: 0;\n+    border: 0;\n+}\n+\n+button,\n+input,\n+select,\n+textarea\n+{\n+    margin: 0;\n+    font-size: 100%;\n+    font-family: inherit;\n+}\n+\n+button,\n+input\n+{\n+    line-height: normal;\n+}\n+\n+button,\n+select\n+{\n+    text-transform: none;\n+}\n+\n+button,\n+html input[type='button'],\n+input[type='reset'],\n+input[type='submit']\n+{\n+    cursor: pointer;\n+\n+    -webkit-appearance: button;\n+}\n+\n+button[disabled],\n+html input[disabled]\n+{\n+    cursor: default;\n+}\n+\n+input[type='checkbox'],\n+input[type='radio']\n+{\n+    box-sizing: border-box;\n+    padding: 0;\n+}\n+\n+input[type='search']\n+{\n+    -webkit-box-sizing: content-box;\n+       -moz-box-sizing: content-box;\n+            box-sizing: content-box;\n+\n+    -webkit-appearance: textfield;\n+}\n+\n+input[type='search']::-webkit-search-cancel-button,\n+input[type='search']::-webkit-search-decoration\n+{\n+    -webkit-appearance: none;\n+}\n+\n+button::-moz-focus-inner,\n+input::-moz-focus-inner\n+{\n+    padding: 0;\n+    border: 0;\n+}\n+\n+textarea\n+{\n+    overflow: auto;\n+    vertical-align: top;\n+}\n+\n+table\n+{\n+    border-spacing: 0;\n+    border-collapse: collapse;\n+}\n+\n+*,\n+*:after,\n+*:before\n+{\n+    -webkit-box-sizing: border-box;\n+       -moz-box-sizing: border-box;\n+            box-sizing: border-box;\n+}\n+\n+body,\n+html\n+{\n+    font-size: 100%;\n+}\n+\n+body\n+{\n+    position: relative;\n+    margin: 0;\n+    padding: 0;\n+    background: #fff;\n+    color: rgba(0,0,0,.8);\n+    font-weight: 400;\n+    font-style: normal;\n+    line-height: 1;\n+    cursor: auto;\n+}\n+\n+a:hover\n+{\n+    cursor: pointer;\n+}\n+\n+embed,\n+img,\n+object\n+{\n+    max-width: 100%;\n+    height: auto;\n+}\n+\n+embed,\n+object\n+{\n+    height: 100%;\n+}\n+\n+img\n+{\n+    -ms-interpolation-mode: bicubic;\n+}\n+\n+#map_canvas embed,\n+#map_canvas img,\n+#map_canvas object,\n+.map_canvas embed,\n+.map_canvas img,\n+.map_canvas object\n+{\n+    max-width: none!important;\n+}\n+\n+.left\n+{\n+    float: left!important;\n+}\n+\n+.right\n+{\n+    float: right!important;\n+}\n+\n+.text-left\n+{\n+    text-align: left!important;\n+}\n+\n+.text-right\n+{\n+    text-align: right!important;\n+}\n+\n+.text-center\n+{\n+    text-align: center!important;\n+}\n+\n+.text-justify\n+{\n+    text-align: justify!important;\n+}\n+\n+.hide\n+{\n+    display: none;\n+}\n+\n+.antialiased,\n+body\n+{\n+    -webkit-font-smoothing: antialiased;\n+}\n+\n+img\n+{\n+    display: inline-block;\n+    vertical-align: middle;\n+}\n+\n+textarea\n+{\n+    min-height: 50px;\n+    height: auto;\n+}\n+\n+select\n+{\n+    width: 100%;\n+}\n+\n+#preamble > .sectionbody > .paragraph:first-of-type p,\n+.paragraph.lead > p,\n+p.lead\n+{\n+    font-size: 1.21875em;\n+    line-height: 1.6;\n+}\n+\n+.admonitionblock td.content > .title,\n+.audioblock > .title,\n+.dlist > .title,\n+.exampleblock > .title,\n+.hdlist > .title,\n+.imageblock > .title,\n+.listingblock > .title,\n+.literalblock > .title,\n+.olist > .title,\n+.openblock > .title,\n+.paragraph > .title,\n+.qlist > .title,\n+.quoteblock > .title,\n+.stemblock > .title,\n+.subheader,\n+.ulist > .title,\n+.verseblock > .title,\n+.videoblock > .title,\n+table.tableblock > .title\n+{\n+    margin-top: 0;\n+    margin-bottom: .25em;\n+    color: #7a2518;\n+    font-weight: 400;\n+    line-height: 1.45;\n+}\n+\n+#toctitle,\n+.sidebarblock > .content > .title,\n+blockquote,\n+dd,\n+div,\n+dl,\n+dt,\n+form,\n+li,\n+ol,\n+p,\n+pre,\n+td,\n+th,\n+ul\n+{\n+    margin: 0;\n+    padding: 0;\n+    direction: ltr;\n+}\n+\n+a\n+{\n+    color: #2156a5;\n+    text-decoration: underline;\n+    line-height: inherit;\n+}\n+\n+a:focus,\n+a:hover\n+{\n+    color: #1d4b8f;\n+}\n+\n+a img\n+{\n+    border: none;\n+}\n+\n+p\n+{\n+    margin-bottom: 1.25em;\n+    font-weight: 400;\n+    font-size: 1em;\n+    font-family: inherit;\n+    line-height: 1.6;\n+}\n+\n+p aside\n+{\n+    font-style: italic;\n+    font-size: .875em;\n+    line-height: 1.35;\n+}\n+\n+#toctitle,\n+.sidebarblock > .content > .title,\n+h1,\n+h2,\n+h3,\n+h4,\n+h5,\n+h6\n+{\n+    color: #d9411e;\n+    font-weight: 300;\n+    font-style: normal;\n+    font-family: 'Noto Sans', sans-serif;\n+   margin: 40px 0 0 0;\n+   padding: 0;\n+   direction: ltr;\n+   word-spacing: -.05em;\n+   line-height: 1.2;\n+   letter-spacing: -.01em;\n+    page-break-after: avoid;\n+}\n+\n+#toctitle small,\n+.sidebarblock > .content > .title small,\n+h1 small,\n+h2 small,\n+h3 small,\n+h4 small,\n+h5 small,\n+h6 small\n+{\n+    color: #e99b8f;\n+    font-size: 60%;\n+    line-height: 0;\n+}\n+\n+/* Pad the page title and sidebar header */\n+h1.post-title-main,\n+li.sidebarTitle {\n+  padding-top: 20px;\n+}\n+\n+h1\n+{\n+    font-size: 2.125em;\n+}\n+\n+h2\n+{\n+    font-size: 1.6875em;\n+}\n+\n+#toctitle,\n+.sidebarblock > .content > .title,\n+h3\n+{\n+    font-size: 1.375em;\n+}\n+\n+h4,\n+h5\n+{\n+    font-size: 1.125em;\n+}\n+\n+h6\n+{\n+    font-size: 1em;\n+}\n+\n+hr\n+{\n+    clear: both;\n+    margin: 1.25em 0 1.1875em;\n+    height: 0;\n+    border: solid #ddddd8;\n+    border-width: 1px 0 0;\n+}\n+\n+em,\n+i\n+{\n+    font-style: italic;\n+    line-height: inherit;\n+}\n+\n+b,\n+strong\n+{\n+    font-weight: bold;\n+    line-height: inherit;\n+}\n+\n+code\n+{\n+    color: rgba(0,0,0,.9);\n+    font-weight: 400;\n+    font-family: 'Inconsolata', monospace;\n+}\n+\n+dl,\n+ol,\n+ul\n+{\n+    margin-bottom: 1.25em;\n+    list-style-position: outside;\n+    font-size: 1em;\n+    font-family: inherit;\n+    line-height: 1.6;\n+}\n+\n+ol,\n+ol.no-bullet,\n+ul,\n+ul.no-bullet\n+{\n+    margin-left: 1.5em;\n+}\n+\n+ul li ol,\n+ul li ul\n+{\n+    margin-bottom: 0;\n+    margin-left: 1.25em;\n+    font-size: 1em;\n+}\n+\n+ul.circle li ul,\n+ul.disc li ul,\n+ul.square li ul\n+{\n+    list-style: inherit;\n+}\n+\n+ul.square\n+{\n+    list-style-type: square;\n+}\n+\n+ul.circle\n+{\n+    list-style-type: circle;\n+}\n+\n+ul.disc\n+{\n+    list-style-type: disc;\n+}\n+\n+ul.no-bullet\n+{\n+    list-style: none;\n+}\n+\n+ol li ol,\n+ol li ul\n+{\n+    margin-bottom: 0;\n+    margin-left: 1.25em;\n+}\n+\n+dl dt\n+{\n+    margin-bottom: .3125em;\n+    font-weight: bold;\n+}\n+\n+dl dd\n+{\n+    margin-bottom: 1.25em;\n+}\n+\n+abbr,\n+acronym\n+{\n+    border-bottom: 1px dotted #ddd;\n+    color: rgba(0,0,0,.8);\n+    text-transform: uppercase;\n+    font-size: 90%;\n+    cursor: help;\n+}\n+\n+abbr\n+{\n+    text-transform: none;\n+}\n+\n+blockquote\n+{\n+    margin: 0 0 1.25em;\n+    padding: .5625em 1.25em 0 1.1875em;\n+    border-left: 1px solid #ddd;\n+}\n+\n+blockquote cite\n+{\n+    display: block;\n+    color: rgba(0,0,0,.6);\n+    font-size: .9375em;\n+}\n+\n+blockquote cite:before\n+{\n+    content: '\\2014 \\0020';\n+}\n+\n+blockquote cite a,\n+blockquote cite a:visited\n+{\n+    color: rgba(0,0,0,.6);\n+}\n+\n+blockquote,\n+blockquote p\n+{\n+    color: rgba(0,0,0,.85);\n+    line-height: 1.6;\n+}\n+\n+@media only screen\n+       and (min-width : 768px)\n+{\n+    #toctitle,\n+    .sidebarblock > .content > .title,\n+    h1,\n+    h2,\n+    h3,\n+    h4,\n+    h5,\n+    h6\n+    {\n+        line-height: 1.2;\n+    }\n+\n+    h1\n+    {\n+        font-size: 2.75em;\n+    }\n+\n+    h2\n+    {\n+        font-size: 2.3125em;\n+    }\n+\n+    #toctitle,\n+    .sidebarblock > .content > .title,\n+    h3\n+    {\n+        font-size: 1.6875em;\n+    }\n+\n+    h4\n+    {\n+        font-size: 1.4375em;\n+    }\n+}\n+\n+table\n+{\n+    margin-bottom: 1.25em;\n+    border: solid 1px #dedede;\n+    background: #fff;\n+}\n+\n+table tfoot,\n+table thead\n+{\n+    background: #f7f8f7;\n+    font-weight: bold;\n+}\n+\n+table tfoot tr td,\n+table tfoot tr th,\n+table thead tr td,\n+table thead tr th\n+{\n+    padding: .5em .625em .625em;\n+    color: rgba(0,0,0,.8);\n+    text-align: left;\n+    font-size: inherit;\n+}\n+\n+table tr td,\n+table tr th\n+{\n+    padding: .5625em .625em;\n+    color: rgba(0,0,0,.8);\n+    font-size: inherit;\n+}\n+\n+table tr.alt,\n+table tr.even,\n+table tr:nth-of-type(even)\n+{\n+    background: #f8f8f7;\n+}\n+\n+table tbody tr td,\n+table tfoot tr td,\n+table tfoot tr th,\n+table thead tr th,\n+table tr td\n+{\n+    display: table-cell;\n+    line-height: 1.6;\n+}\n+\n+#toctitle strong,\n+.sidebarblock > .content > .title strong,\n+h1 strong,\n+h2 strong,\n+h3 strong,\n+h4 strong,\n+h5 strong,\n+h6 strong\n+{\n+    font-weight: 400;\n+}\n+\n+.clearfix:after,\n+.clearfix:before,\n+.float-group:after,\n+.float-group:before\n+{\n+    display: table;\n+    content: ' ';\n+}\n+\n+.clearfix:after,\n+.float-group:after\n+{\n+    clear: both;\n+}\n+\n+*:not(pre) > code\n+{\n+    padding: .1em .5ex;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+    background-color: #f7f7f8;\n+    word-spacing: -.15em;\n+    letter-spacing: 0;\n+    font-style: normal!important;\n+    font-size: 1em;\n+    line-height: 1.45;\n+}\n+\n+pre,\n+pre > code\n+{\n+    color: rgba(0,0,0,.9);\n+    font-weight: 400;\n+    font-family: 'Inconsolata', monospace;\n+    line-height: 1.45;\n+   white-space: pre-wrap;\n+}\n+\n+.keyseq\n+{\n+    color: rgba(51,51,51,.8);\n+}\n+\n+kbd\n+{\n+    display: inline-block;\n+    margin: -.15em .15em 0 .15em;\n+    padding: .2em .6em .2em .5em;\n+    border: 1px solid #ccc;\n+    -webkit-border-radius: 3px;\n+            border-radius: 3px;\n+    background-color: #f7f7f7;\n+    -webkit-box-shadow: 0 1px 0 rgba(0,0,0,.2),\n+    0 0 0 .1em white inset;\n+            box-shadow: 0 1px 0 rgba(0,0,0,.2),\n+    0 0 0 .1em #fff inset;\n+    color: rgba(0,0,0,.8);\n+    vertical-align: middle;\n+    white-space: nowrap;\n+    font-size: .75em;\n+    line-height: 1.4;\n+}\n+\n+.keyseq kbd:first-child\n+{\n+    margin-left: 0;\n+}\n+\n+.keyseq kbd:last-child\n+{\n+    margin-right: 0;\n+}\n+\n+.menu,\n+.menuseq\n+{\n+    color: rgba(0,0,0,.8);\n+}\n+\n+b.button:after,\n+b.button:before\n+{\n+    position: relative;\n+    top: -1px;\n+    font-weight: 400;\n+}\n+\n+b.button:before\n+{\n+    padding: 0 3px 0 2px;\n+    content: '[';\n+}\n+\n+b.button:after\n+{\n+    padding: 0 2px 0 3px;\n+    content: ']';\n+}\n+\n+p a > code:hover\n+{\n+    color: rgba(0,0,0,.9);\n+}\n+\n+#content,\n+#footer,\n+#footnotes,\n+#header\n+{\n+    margin: 0 auto 0 auto;\n+    max-width: 62.5em;\n+    width: 100%;\n+}\n+\n+#content:after,\n+#content:before,\n+#footer:after,\n+#footer:before,\n+#footnotes:after,\n+#footnotes:before,\n+#header:after,\n+#header:before\n+{\n+    display: table;\n+    content: ' ';\n+}\n+\n+#content:after,\n+#footer:after,\n+#footnotes:after,\n+#header:after\n+{\n+    clear: both;\n+}\n+\n+#content\n+{\n+    margin-top: 1.25em;\n+}\n+\n+#content:before\n+{\n+    content: none;\n+}\n+\n+span.projectTitle\n+{\n+    font-weight: bold;\n+    font-family: 'Noto Sans', sans-serif;\n+    font-size: 14pt;\n+}\n+\n+#header > h1:first-child\n+{\n+    margin-top: 2.25rem;\n+    margin-bottom: 0;\n+    color: rgba(0,0,0,.85);\n+}\n+\n+#header > h1:first-child + #toc\n+{\n+    margin-top: 8px;\n+    border-top: 1px solid #ddddd8;\n+}\n+\n+#header > h1:only-child,\n+body.toc2 #header > h1:nth-last-child(2)\n+{\n+    padding-bottom: 8px;\n+    border-bottom: 1px solid #ddddd8;\n+}\n+\n+#header .details\n+{\n+    display: -ms-flexbox;\n+    display: -webkit-flex;\n+    display:         flex;\n+    padding-top: .25em;\n+    padding-bottom: .25em;\n+    padding-left: .25em;\n+    border-bottom: 1px solid #ddddd8;\n+    color: rgba(0,0,0,.6);\n+    line-height: 1.45;\n+}\n+\n+#header .details span:first-child\n+{\n+    margin-left: -.125em;\n+}\n+\n+#header .details span.email a\n+{\n+    color: rgba(0,0,0,.85);\n+}\n+\n+#header .details br\n+{\n+    display: none;\n+}\n+\n+#header .details br + span:before\n+{\n+    content: '\\00a0\\2013\\00a0';\n+}\n+\n+#header .details br + span.author:before\n+{\n+    color: rgba(0,0,0,.85);\n+    content: '\\00a0\\22c5\\00a0';\n+}\n+\n+#header .details br + span#revremark:before\n+{\n+    content: '\\00a0|\\00a0';\n+}\n+\n+#header #revnumber\n+{\n+    text-transform: capitalize;\n+}\n+\n+#header #revnumber:after\n+{\n+    content: '\\00a0';\n+}\n+\n+#content > h1:first-child:not([class])\n+{\n+    margin-top: 0;\n+    margin-bottom: 1.25rem;\n+    padding-top: 1rem;\n+    padding-bottom: 8px;\n+    border-bottom: 1px solid #ddddd8;\n+    color: rgba(0,0,0,.85);\n+}\n+\n+#toc\n+{\n+    padding-bottom: .5em;\n+    border-bottom: 1px solid #efefed;\n+}\n+\n+#toc > ul\n+{\n+    margin-left: .125em;\n+}\n+\n+#toc ul.sectlevel0 > li > a\n+{\n+    font-weight: bold;\n+}\n+\n+#toc ul.sectlevel0 ul.sectlevel1\n+{\n+    margin: .5em 0;\n+}\n+\n+#toc ul\n+{\n+    list-style-type: none;\n+    font-family: 'Noto Sans', sans-serif;\n+}\n+\n+#toc a\n+{\n+    text-decoration: none;\n+}\n+\n+#toc a:active\n+{\n+    text-decoration: underline;\n+}\n+\n+#toctitle\n+{\n+    color: #7a2518;\n+    font-size: 1.2em;\n+}\n+\n+div#toc ul li {\n+    margin: 8px 0 8px 22px;\n+    list-style: square;\n+    line-height: 1.25;\n+}\n+\n+div#toc ul {\n+    background-color: whitesmoke;\n+    padding: 5px;\n+    border-radius: 5px;\n+    max-width: 300px;\n+    color: gray;\n+}\n+\n+div#toc ul li ul {\n+    padding-left:8px;\n+\n+}\n+\n+div#toc ul li ul li::before {\n+    content: \"\u2013  \";\n+}\n+\n+div#toc >ul::before {\n+    content: \"On this Page\";\n+    font-weight: bold;\n+    color: #555;\n+    text-align:center;\n+    margin-left:auto;\n+    margin-right:auto;\n+    width:70px;\n+    padding-top:20px;\n+    padding-bottom:20px;\n+    padding-left:10px;\n+}\n+\n+@media only screen\n+       and (min-width : 768px)\n+{\n+    #toctitle\n+    {\n+        font-size: 1.375em;\n+    }\n+\n+    body.toc2\n+    {\n+        padding-right: 0;\n+        padding-left: 15em;\n+    }\n+\n+    #toc.toc2\n+    {\n+        position: fixed;\n+        top: 0;\n+        left: 0;\n+        z-index: 1000;\n+        overflow: auto;\n+        margin-top: 0!important;\n+        padding: 1.25em 1em;\n+        width: 15em;\n+        height: 100%;\n+        border-top-width: 0!important;\n+        border-right: 1px solid #efefed;\n+        border-bottom-width: 0!important;\n+        background-color: #f8f8f7;\n+    }\n+\n+    #toc.toc2 #toctitle\n+    {\n+        margin-top: 0;\n+        font-size: 1.2em;\n+    }\n+\n+    #toc.toc2 > ul\n+    {\n+        margin-bottom: 0;\n+        font-size: .9em;\n+    }\n+\n+    #toc.toc2 ul ul\n+    {\n+        margin-left: 0;\n+        padding-left: 1em;\n+    }\n+\n+    #toc.toc2 ul.sectlevel0 ul.sectlevel1\n+    {\n+        margin-top: .5em;\n+        margin-bottom: .5em;\n+        padding-left: 0;\n+    }\n+\n+    body.toc2.toc-right\n+    {\n+        padding-right: 15em;\n+        padding-left: 0;\n+    }\n+\n+    body.toc2.toc-right #toc.toc2\n+    {\n+        right: 0;\n+        left: auto;\n+        border-right-width: 0;\n+        border-left: 1px solid #efefed;\n+    }\n+}\n+\n+@media only screen\n+       and (min-width : 1280px)\n+{\n+    body.toc2\n+    {\n+        padding-right: 0;\n+        padding-left: 20em;\n+    }\n+\n+    #toc.toc2\n+    {\n+        width: 20em;\n+    }\n+\n+    #toc.toc2 #toctitle\n+    {\n+        font-size: 1.375em;\n+    }\n+\n+    #toc.toc2 > ul\n+    {\n+        font-size: .95em;\n+    }\n+\n+    #toc.toc2 ul ul\n+    {\n+        padding-left: 1.25em;\n+    }\n+\n+    body.toc2.toc-right\n+    {\n+        padding-right: 20em;\n+        padding-left: 0;\n+    }\n+}\n+\n+#content #toc\n+{\n+    margin-bottom: 1.25em;\n+    padding: 1.25em;\n+    border-width: 1px;\n+    border-style: solid;\n+    border-color: #e0e0dc;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+    background: #f8f8f7;\n+}\n+\n+#content #toc > :first-child\n+{\n+    margin-top: 0;\n+}\n+\n+#content #toc > :last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+#footer\n+{\n+    margin: 30px 0;\n+    padding: 1.25em;\n+    max-width: 100%;\n+    background-color: none;\n+}\n+\n+#footer-text\n+{\n+    color: rgba(255,255,255,.8);\n+    line-height: 1.44;\n+}\n+\n+.sect1\n+{\n+    padding-bottom: .625em;\n+}\n+\n+@media only screen\n+       and (min-width : 768px)\n+{\n+    .sect1\n+    {\n+        padding-bottom: 1.25em;\n+    }\n+}\n+\n+.sect1 + .sect1\n+{\n+    border-top: 1px solid #efefed;\n+}\n+\n+#content h1 > a.anchor,\n+#toctitle > a.anchor,\n+.sidebarblock > .content > .title > a.anchor,\n+h2 > a.anchor,\n+h3 > a.anchor,\n+h4 > a.anchor,\n+h5 > a.anchor,\n+h6 > a.anchor\n+{\n+    position: absolute;\n+    z-index: 1001;\n+    display: block;\n+    visibility: hidden;\n+    margin-left: -1.5ex;\n+    width: 1.5ex;\n+    text-align: center;\n+    text-decoration: none!important;\n+    font-weight: 400;\n+}\n+\n+#content h1 > a.anchor:before,\n+#toctitle > a.anchor:before,\n+.sidebarblock > .content > .title > a.anchor:before,\n+h2 > a.anchor:before,\n+h3 > a.anchor:before,\n+h4 > a.anchor:before,\n+h5 > a.anchor:before,\n+h6 > a.anchor:before\n+{\n+    display: block;\n+    padding-top: .1em;\n+    content: '\\00A7';\n+    font-size: .85em;\n+}\n+\n+#content h1:hover > a.anchor,\n+#content h1 > a.anchor:hover,\n+#toctitle:hover > a.anchor,\n+#toctitle > a.anchor:hover,\n+.sidebarblock > .content > .title:hover > a.anchor,\n+.sidebarblock > .content > .title > a.anchor:hover,\n+h2:hover > a.anchor,\n+h2 > a.anchor:hover,\n+h3:hover > a.anchor,\n+h3 > a.anchor:hover,\n+h4:hover > a.anchor,\n+h4 > a.anchor:hover,\n+h5:hover > a.anchor,\n+h5 > a.anchor:hover,\n+h6:hover > a.anchor,\n+h6 > a.anchor:hover\n+{\n+    visibility: visible;\n+}\n+\n+#content h1 > a.link,\n+#toctitle > a.link,\n+.sidebarblock > .content > .title > a.link,\n+h2 > a.link,\n+h3 > a.link,\n+h4 > a.link,\n+h5 > a.link,\n+h6 > a.link\n+{\n+    color: #d9411e;\n+    text-decoration: none;\n+}\n+\n+#content h1 > a.link:hover,\n+#toctitle > a.link:hover,\n+.sidebarblock > .content > .title > a.link:hover,\n+h2 > a.link:hover,\n+h3 > a.link:hover,\n+h4 > a.link:hover,\n+h5 > a.link:hover,\n+h6 > a.link:hover\n+{\n+    color: #a53221;\n+}\n+\n+.audioblock,\n+.imageblock,\n+.listingblock,\n+.literalblock,\n+.stemblock,\n+.videoblock\n+{\n+    margin-bottom: 1.25em;\n+}\n+\n+\n+\n+table.tableblock > caption.title\n+{\n+    overflow: visible;\n+    max-width: 0;\n+    white-space: nowrap;\n+}\n+\n+#preamble > .sectionbody > .paragraph:first-of-type p,\n+.paragraph.lead > p\n+{\n+    color: rgba(0,0,0,.85);\n+}\n+\n+table.tableblock #preamble > .sectionbody > .paragraph:first-of-type p\n+{\n+    font-size: inherit;\n+}\n+\n+.admonitionblock > table\n+{\n+    width: 100%;\n+    border: 0;\n+    border-collapse: separate;\n+    background: none;\n+}\n+\n+.admonitionblock > table td.icon\n+{\n+    width: 80px;\n+    text-align: center;\n+}\n+\n+.admonitionblock > table td.icon img\n+{\n+    max-width: none;\n+}\n+\n+.admonitionblock > table td.icon .title\n+{\n+    text-transform: uppercase;\n+    font-weight: bold;\n+    font-family: 'Noto Sans', sans-serif;\n+}\n+\n+.admonitionblock > table td.content\n+{\n+    padding-right: 1.25em;\n+    padding-left: 1.125em;\n+    border-left: 1px solid #ddddd8;\n+    color: rgba(0,0,0,.6);\n+}\n+\n+.admonitionblock > table td.content > :last-child > :last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+.exampleblock > .content\n+{\n+    margin-bottom: 1.25em;\n+    padding: 1.25em;\n+    border-width: 1px;\n+    border-style: solid;\n+    border-color: #e6e6e6;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+    background: #fff;\n+}\n+\n+.exampleblock > .content > :first-child\n+{\n+    margin-top: 0;\n+}\n+\n+.exampleblock > .content > :last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+.sidebarblock\n+{\n+    margin-bottom: 1.25em;\n+    padding: 1.25em;\n+    border-width: 1px;\n+    border-style: solid;\n+    border-color: #e0e0dc;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+    background: #f8f8f7;\n+}\n+\n+.sidebarblock > :first-child\n+{\n+    margin-top: 0;\n+}\n+\n+.sidebarblock > :last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+.sidebarblock > .content > .title\n+{\n+    margin-top: 0;\n+    color: #7a2518;\n+    text-align: center;\n+}\n+\n+.exampleblock > .content > :last-child>:last-child,\n+.exampleblock > .content .olist > ol > li:last-child>:last-child,\n+.exampleblock > .content .qlist > ol > li:last-child>:last-child,\n+.exampleblock > .content .ulist > ul > li:last-child>:last-child,\n+.sidebarblock > .content > :last-child>:last-child,\n+.sidebarblock > .content .olist > ol > li:last-child>:last-child,\n+.sidebarblock > .content .qlist > ol > li:last-child>:last-child,\n+.sidebarblock > .content .ulist > ul > li:last-child>:last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+.listingblock pre,\n+.listingblock pre.CodeRay,\n+.listingblock pre.prettyprint,\n+.listingblock pre:not(.highlight),\n+.listingblock pre[class='highlight'],\n+.listingblock pre[class^='highlight '],\n+.literalblock pre\n+{\n+    background: #f7f7f8;\n+}\n+\n+.sidebarblock .listingblock pre.CodeRay,\n+.sidebarblock .listingblock pre.prettyprint,\n+.sidebarblock .listingblock pre:not(.highlight),\n+.sidebarblock .listingblock pre[class='highlight'],\n+.sidebarblock .listingblock pre[class^='highlight '],\n+.sidebarblock .literalblock pre\n+{\n+    background: #f7f7f8;\n+}\n+\n+.listingblock pre,\n+.listingblock pre[class],\n+.literalblock pre,\n+.literalblock pre[class]\n+{\n+    padding: 1em;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+    word-wrap: break-word;\n+    font-size: .8125em;\n+}\n+\n+.listingblock pre.nowrap,\n+.listingblock pre[class].nowrap,\n+.literalblock pre.nowrap,\n+.literalblock pre[class].nowrap\n+{\n+    overflow-x: auto;\n+    white-space: pre;\n+    word-wrap: normal;\n+}\n+\n+@media only screen\n+       and (min-width : 768px)\n+{\n+    .listingblock pre,\n+    .listingblock pre[class],\n+    .literalblock pre,\n+    .literalblock pre[class]\n+    {\n+        font-size: .90625em;\n+    }\n+}\n+\n+@media only screen\n+       and (min-width : 1280px)\n+{\n+    .listingblock pre,\n+    .listingblock pre[class],\n+    .literalblock pre,\n+    .literalblock pre[class]\n+    {\n+        font-size: 1em;\n+    }\n+}\n+\n+.literalblock.output pre\n+{\n+    background-color: rgba(0,0,0,.9);\n+    color: #f7f7f8;\n+}\n+\n+.listingblock pre.highlightjs\n+{\n+    padding: 0;\n+}\n+\n+.listingblock pre.highlightjs > code\n+{\n+    padding: 1em;\n+    -webkit-border-radius: 4px;\n+            border-radius: 4px;\n+}\n+\n+.listingblock pre.prettyprint\n+{\n+    border-width: 0;\n+}\n+\n+.listingblock > .content\n+{\n+    position: relative;\n+}\n+\n+.listingblock code[data-lang]:before\n+{\n+    position: absolute;\n+    top: .425rem;\n+    right: .5rem;\n+    display: none;\n+    color: #999;\n+    content: attr(data-lang);\n+    text-transform: uppercase;\n+    font-size: .75em;\n+    line-height: 1;\n+}\n+\n+.listingblock:hover code[data-lang]:before\n+{\n+    display: block;\n+}\n+\n+.listingblock.terminal pre .command:before\n+{\n+    padding-right: .5em;\n+    color: #999;\n+    content: attr(data-prompt);\n+}\n+\n+.listingblock.terminal pre .command:not([data-prompt]):before\n+{\n+    content: '$';\n+}\n+\n+table.pyhltable\n+{\n+    margin-bottom: 0;\n+    border: 0;\n+    border-collapse: separate;\n+    background: none;\n+}\n+\n+table.pyhltable td\n+{\n+    padding-top: 0;\n+    padding-bottom: 0;\n+    vertical-align: top;\n+}\n+\n+table.pyhltable td.code\n+{\n+    padding-right: 0;\n+    padding-left: .75em;\n+}\n+\n+pre.pygments .lineno,\n+table.pyhltable td:not(.code)\n+{\n+    padding-right: .5em;\n+    padding-left: 0;\n+    border-right: 1px solid #ddddd8;\n+    color: #999;\n+}\n+\n+pre.pygments .lineno\n+{\n+    display: inline-block;\n+    margin-right: .25em;\n+}\n+\n+table.pyhltable .linenodiv\n+{\n+    padding-right: 0!important;\n+    background: none!important;\n+}\n+\n+.quoteblock\n+{\n+    display: table;\n+    margin: 0 1em 1.25em 1.5em;\n+}\n+\n+.quoteblock > .title\n+{\n+    margin-bottom: .75em;\n+    margin-left: -1.5em;\n+}\n+\n+.quoteblock blockquote,\n+.quoteblock blockquote p\n+{\n+    color: rgba(0,0,0,.85);\n+    text-align: justify;\n+    word-spacing: .1em;\n+    letter-spacing: 0;\n+    font-style: italic;\n+    font-size: 1.15rem;\n+    line-height: 1.75;\n+}\n+\n+.quoteblock blockquote\n+{\n+    margin: 0;\n+    padding: 0;\n+    border: 0;\n+}\n+\n+.quoteblock blockquote:before\n+{\n+    float: left;\n+    margin-left: -.6em;\n+    color: #7a2518;\n+    content: '\\201c';\n+    text-shadow: 0 1px 2px rgba(0,0,0,.1);\n+    font-weight: bold;\n+    font-size: 2.75em;\n+    line-height: .6em;\n+}\n+\n+.quoteblock blockquote > .paragraph:last-child p\n+{\n+    margin-bottom: 0;\n+}\n+\n+.quoteblock .attribution\n+{\n+    margin-top: .5em;\n+    margin-right: .5ex;\n+    text-align: right;\n+}\n+\n+.quoteblock .quoteblock\n+{\n+    margin-right: 0;\n+    margin-left: 0;\n+    padding: .5em 0;\n+    border-left: 3px solid rgba(0,0,0,.6);\n+}\n+\n+.quoteblock .quoteblock blockquote\n+{\n+    padding: 0 0 0 .75em;\n+}\n+\n+.quoteblock .quoteblock blockquote:before\n+{\n+    display: none;\n+}\n+\n+.verseblock\n+{\n+    margin: 0 1em 1.25em 1em;\n+}\n+\n+.verseblock pre\n+{\n+    color: rgba(0,0,0,.85);\n+    font-weight: 300;\n+    font-size: 1.15rem;\n+    font-family: 'Noto Sans', sans-serif;\n+}\n+\n+.verseblock pre strong\n+{\n+    font-weight: 400;\n+}\n+\n+.verseblock .attribution\n+{\n+    margin-top: 1.25rem;\n+    margin-left: .5ex;\n+}\n+\n+.quoteblock .attribution,\n+.verseblock .attribution\n+{\n+    font-style: italic;\n+    font-size: .9375em;\n+    line-height: 1.45;\n+}\n+\n+.quoteblock .attribution br,\n+.verseblock .attribution br\n+{\n+    display: none;\n+}\n+\n+.quoteblock .attribution cite,\n+.verseblock .attribution cite\n+{\n+    display: block;\n+    color: rgba(0,0,0,.6);\n+    letter-spacing: -.05em;\n+}\n+\n+.quoteblock.abstract\n+{\n+    display: block;\n+    margin: 0 0 1.25em 0;\n+}\n+\n+.quoteblock.abstract blockquote,\n+.quoteblock.abstract blockquote p\n+{\n+    text-align: left;\n+    word-spacing: 0;\n+}\n+\n+.quoteblock.abstract blockquote:before,\n+.quoteblock.abstract blockquote p:first-of-type:before\n+{\n+    display: none;\n+}\n+\n+table.tableblock\n+{\n+    max-width: 100%;\n+    border-collapse: separate;\n+}\n+\n+table.tableblock td > .paragraph:last-child p > p:last-child,\n+table.tableblock td > p:last-child,\n+table.tableblock th > p:last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+table.spread\n+{\n+    width: 100%;\n+}\n+\n+table.tableblock,\n+td.tableblock,\n+th.tableblock\n+{\n+    border: 0 solid #dedede;\n+}\n+\n+table.grid-all td.tableblock,\n+table.grid-all th.tableblock\n+{\n+    border-width: 0 1px 1px 0;\n+}\n+\n+table.grid-all tfoot > tr > td.tableblock,\n+table.grid-all tfoot > tr > th.tableblock\n+{\n+    border-width: 1px 1px 0 0;\n+}\n+\n+table.grid-cols td.tableblock,\n+table.grid-cols th.tableblock\n+{\n+    border-width: 0 1px 0 0;\n+}\n+\n+table.grid-all * > tr > .tableblock:last-child,\n+table.grid-cols * > tr > .tableblock:last-child\n+{\n+    border-right-width: 0;\n+}\n+\n+table.grid-rows td.tableblock,\n+table.grid-rows th.tableblock\n+{\n+    border-width: 0 0 1px 0;\n+}\n+\n+table.grid-all tbody > tr:last-child > td.tableblock,\n+table.grid-all tbody > tr:last-child > th.tableblock,\n+table.grid-all thead:last-child > tr > th.tableblock,\n+table.grid-rows tbody > tr:last-child > td.tableblock,\n+table.grid-rows tbody > tr:last-child > th.tableblock,\n+table.grid-rows thead:last-child > tr > th.tableblock\n+{\n+    border-bottom-width: 0;\n+}\n+\n+table.grid-rows tfoot > tr > td.tableblock,\n+table.grid-rows tfoot > tr > th.tableblock\n+{\n+    border-width: 1px 0 0 0;\n+}\n+\n+table.frame-all\n+{\n+    border-width: 1px;\n+}\n+\n+table.frame-sides\n+{\n+    border-width: 0 1px;\n+}\n+\n+table.frame-topbot\n+{\n+    border-width: 1px 0;\n+}\n+\n+td.halign-left,\n+th.halign-left\n+{\n+    text-align: left;\n+}\n+\n+td.halign-right,\n+th.halign-right\n+{\n+    text-align: right;\n+}\n+\n+td.halign-center,\n+th.halign-center\n+{\n+    text-align: center;\n+}\n+\n+td.valign-top,\n+th.valign-top\n+{\n+    vertical-align: top;\n+}\n+\n+td.valign-bottom,\n+th.valign-bottom\n+{\n+    vertical-align: bottom;\n+}\n+\n+td.valign-middle,\n+th.valign-middle\n+{\n+    vertical-align: middle;\n+}\n+\n+table tfoot th,\n+table thead th\n+{\n+    font-weight: bold;\n+}\n+\n+tbody tr th\n+{\n+    display: table-cell;\n+    background: #f7f8f7;\n+    line-height: 1.6;\n+}\n+\n+tbody tr th,\n+tbody tr th p,\n+tfoot tr th,\n+tfoot tr th p\n+{\n+    color: rgba(0,0,0,.8);\n+    font-weight: bold;\n+}\n+\n+p.tableblock > code:only-child\n+{\n+    padding: 0;\n+    background: none;\n+}\n+\n+td > div.verse\n+{\n+    white-space: pre;\n+}\n+\n+ol\n+{\n+    margin-left: 1.75em;\n+}\n+\n+ul li ol\n+{\n+    margin-left: 1.5em;\n+}\n+\n+dl dd\n+{\n+    margin-left: 1.125em;\n+}\n+\n+dl dd:last-child,\n+dl dd:last-child > :last-child\n+{\n+    margin-bottom: 0;\n+}\n+\n+.olist .olist,\n+.olist .ulist,\n+.ulist .olist,\n+.ulist .ulist,\n+ol > li p,\n+ol dd,\n+ul > li p,\n+ul dd\n+{\n+    margin-bottom: .625em;\n+}\n+\n+ol.unnumbered,\n+ul.checklist,\n+ul.none,\n+ul.unstyled\n+{\n+    list-style-type: none;\n+}\n+\n+ol.unnumbered,\n+ul.checklist,\n+ul.unstyled\n+{\n+    margin-left: .625em;\n+}\n+\n+ul.checklist li > p:first-child > .fa-check-square-o:first-child,\n+ul.checklist li > p:first-child > input[type='checkbox']:first-child\n+{\n+    margin-right: .25em;\n+}\n+\n+ul.checklist li > p:first-child > input[type='checkbox']:first-child\n+{\n+    position: relative;\n+    top: 1px;\n+}\n+\n+ul.inline\n+{\n+    margin: 0 auto .625em auto;\n+    margin-right: 0;\n+    margin-left: -1.375em;\n+    padding: 0;\n+}\n+\n+ul.inline > li\n+{\n+    display: block;\n+    float: left;\n+    margin-left: 1.375em;\n+    list-style: none;\n+}\n+\n+ul.inline > li > *\n+{\n+    display: block;\n+}\n+\n+.unstyled dl dt\n+{\n+    font-weight: 400;\n+    font-style: normal;\n+}\n+\n+ol.arabic\n+{\n+    list-style-type: decimal;\n+}\n+\n+ol.decimal\n+{\n+    list-style-type: decimal-leading-zero;\n+}\n+\n+ol.loweralpha\n+{\n+    list-style-type: lower-alpha;\n+}\n+\n+ol.upperalpha\n+{\n+    list-style-type: upper-alpha;\n+}\n+\n+ol.lowerroman\n+{\n+    list-style-type: lower-roman;\n+}\n+\n+ol.upperroman\n+{\n+    list-style-type: upper-roman;\n+}\n+\n+ol.lowergreek\n+{\n+    list-style-type: lower-greek;\n+}\n+\n+.colist > table,\n+.hdlist > table\n+{\n+    border: 0;\n+    background: none;\n+}\n+\n+.colist > table > tbody>tr,\n+.hdlist > table > tbody > tr\n+{\n+    background: none;\n+}\n+\n+td.hdlist1\n+{\n+    padding-right: .75em;\n+    font-weight: bold;\n+}\n+\n+td.hdlist1,\n+td.hdlist2\n+{\n+    vertical-align: top;\n+}\n+\n+.listingblock + .colist,\n+.literalblock + .colist\n+{\n+    margin-top: -.5em;\n+}\n+\n+.colist > table tr > td:first-of-type\n+{\n+    padding: 0 .75em;\n+    line-height: 1;\n+}\n+\n+.colist > table tr > td:last-of-type\n+{\n+    padding: .25em 0;\n+}\n+\n+.th,\n+.thumb\n+{\n+    display: inline-block;\n+    border: solid 4px #fff;\n+    -webkit-box-shadow: 0 0 0 1px #ddd;\n+            box-shadow: 0 0 0 1px #ddd;\n+    line-height: 0;\n+}\n+\n+.imageblock.left,\n+.imageblock[style*='float: left']\n+{\n+    margin: .25em .625em 1.25em 0;\n+}\n+\n+.imageblock.right,\n+.imageblock[style*='float: right']\n+{\n+    margin: .25em 0 1.25em .625em;\n+}\n+\n+.imageblock > .title\n+{\n+    margin-bottom: 0;\n+}\n+\n+.imageblock.th,\n+.imageblock.thumb\n+{\n+    border-width: 6px;\n+}\n+\n+.imageblock.th > .title,\n+.imageblock.thumb > .title\n+{\n+    padding: 0 .125em;\n+}\n+\n+.image.left,\n+.image.right\n+{\n+    display: inline-block;\n+    margin-top: .25em;\n+    margin-bottom: .25em;\n+    line-height: 0;\n+}\n+\n+.image.left\n+{\n+    margin-right: .625em;\n+}\n+\n+.image.right\n+{\n+    margin-left: .625em;\n+}\n+\n+a.image\n+{\n+    text-decoration: none;\n+}\n+\n+span.footnote,\n+span.footnoteref\n+{\n+    vertical-align: super;\n+    font-size: .875em;\n+}\n+\n+span.footnote a,\n+span.footnoteref a\n+{\n+    text-decoration: none;\n+}\n+\n+span.footnote a:active,\n+span.footnoteref a:active\n+{\n+    text-decoration: underline;\n+}\n+\n+#footnotes\n+{\n+    margin-bottom: .625em;\n+    padding-top: .75em;\n+    padding-bottom: .75em;\n+}\n+\n+#footnotes hr\n+{\n+    margin: -.25em 0 .75em 0;\n+    min-width: 6.25em;\n+    width: 20%;\n+    border-width: 1px 0 0 0;\n+}\n+\n+#footnotes .footnote\n+{\n+    margin-bottom: .2em;\n+    margin-left: 1.2em;\n+    padding: 0 .375em;\n+    text-indent: -1.2em;\n+    font-size: .875em;\n+    line-height: 1.3;\n+}\n+\n+#footnotes .footnote a:first-of-type\n+{\n+    text-decoration: none;\n+    font-weight: bold;\n+}\n+\n+#footnotes .footnote:last-of-type\n+{\n+    margin-bottom: 0;\n+}\n+\n+#content #footnotes\n+{\n+    margin-top: -.625em;\n+    margin-bottom: 0;\n+    padding: .75em 0;\n+}\n+\n+.gist .file-data > table\n+{\n+    margin-bottom: 0;\n+    width: 100%;\n+    border: 0;\n+    background: #fff;\n+}\n+\n+.gist .file-data > table td.line-data\n+{\n+    width: 99%;\n+}\n+\n+div.unbreakable\n+{\n+    page-break-inside: avoid;\n+}\n+\n+.big\n+{\n+    font-size: larger;\n+}\n+\n+.small\n+{\n+    font-size: smaller;\n+}\n+\n+.underline\n+{\n+    text-decoration: underline;\n+}\n+\n+.overline\n+{\n+    text-decoration: overline;\n+}\n+\n+.line-through\n+{\n+    text-decoration: line-through;\n+}\n+\n+.aqua\n+{\n+    color: #00bfbf;\n+}\n+\n+.aqua-background\n+{\n+    background-color: #00fafa;\n+}\n+\n+.black\n+{\n+    color: #000;\n+}\n+\n+.black-background\n+{\n+    background-color: #000;\n+}\n+\n+.blue\n+{\n+    color: #0000bf;\n+}\n+\n+.blue-background\n+{\n+    background-color: #0000fa;\n+}\n+\n+.fuchsia\n+{\n+    color: #bf00bf;\n+}\n+\n+.fuchsia-background\n+{\n+    background-color: #fa00fa;\n+}\n+\n+.gray\n+{\n+    color: #606060;\n+}\n+\n+.gray-background\n+{\n+    background-color: #7d7d7d;\n+}\n+\n+.green\n+{\n+    color: #006000;\n+}\n+\n+.green-background\n+{\n+    background-color: #007d00;\n+}\n+\n+.lime\n+{\n+    color: #00bf00;\n+}\n+\n+.lime-background\n+{\n+    background-color: #00fa00;\n+}\n+\n+.maroon\n+{\n+    color: #600000;\n+}\n+\n+.maroon-background\n+{\n+    background-color: #7d0000;\n+}\n+\n+.navy\n+{\n+    color: #000060;\n+}\n+\n+.navy-background\n+{\n+    background-color: #00007d;\n+}\n+\n+.olive\n+{\n+    color: #606000;\n+}\n+\n+.olive-background\n+{\n+    background-color: #7d7d00;\n+}\n+\n+.purple\n+{\n+    color: #600060;\n+}\n+\n+.purple-background\n+{\n+    background-color: #7d007d;\n+}\n+\n+.red\n+{\n+    color: #bf0000;\n+}\n+\n+.red-background\n+{\n+    background-color: #fa0000;\n+}\n+\n+.silver\n+{\n+    color: #909090;\n+}\n+\n+.silver-background\n+{\n+    background-color: #bcbcbc;\n+}\n+\n+.teal\n+{\n+    color: #006060;\n+}\n+\n+.teal-background\n+{\n+    background-color: #007d7d;\n+}\n+\n+.white\n+{\n+    color: #bfbfbf;\n+}\n+\n+.white-background\n+{\n+    background-color: #fafafa;\n+}\n+\n+.yellow\n+{\n+    color: #bfbf00;\n+}\n+\n+.yellow-background\n+{\n+    background-color: #fafa00;\n+}\n+\n+span.icon > .fa\n+{\n+    cursor: default;\n+}\n+\n+\n+.admonitionblock td.icon [class^='fa icon-']\n+{\n+    text-shadow: 1px 1px 2px rgba(0,0,0,.5);\n+    font-size: 2.5em;\n+    cursor: default;\n+}\n+\n+/* font awesome icon info-circle: http://fontawesome.io/icon/info-circle/ */\n+.admonitionblock td.icon .icon-note:before\n+{\n+    color: #19407c;\n+    content: '\\f05a';\n+}\n+\n+/* font awesome icon lightbulb-o: http://fontawesome.io/icon/lightbulb-o/ */\n+.admonitionblock td.icon .icon-tip:before\n+{\n+    color: #428b30;\n+    content: '\\f0eb';\n+    text-shadow: 1px 1px 2px rgba(155,155,0,.8);\n+}\n+\n+/* font awesome icon exclamation-triangle: http://fontawesome.io/icon/exclamation-triangle/ */\n+.admonitionblock td.icon .icon-warning:before\n+{\n+    color: #bf0000;\n+    content: '\\f071';\n+}\n+\n+/* font awesome icon fire: http://fontawesome.io/icon/fire/ */\n+.admonitionblock td.icon .icon-caution:before\n+{\n+    color: #bf6900;\n+    content: '\\f06d';\n+}\n+\n+/* font awesome icon bolt: http://fontawesome.io/icon/bolt/ */\n+.admonitionblock td.icon .icon-important:before\n+{\n+    color: #eeea74;\n+    content: '\\f0e7';\n+}\n+\n+.conum[data-value]\n+{\n+    display: inline-block;\n+    width: 1.67em;\n+    height: 1.67em;\n+    -webkit-border-radius: 100px;\n+            border-radius: 100px;\n+    background-color: rgba(0,0,0,.8);\n+    color: #fff!important;\n+    text-align: center;\n+    font-weight: bold;\n+    font-style: normal;\n+    font-size: .75em;\n+    font-family: 'Noto Sans', sans-serif;\n+    line-height: 1.67em;\n+}\n+\n+.conum[data-value] *\n+{\n+    color: #fff!important;\n+}\n+\n+.conum[data-value] + b\n+{\n+    display: none;\n+}\n+\n+.conum[data-value]:after\n+{\n+    content: attr(data-value);\n+}\n+\n+pre .conum[data-value]\n+{\n+    position: relative;\n+    top: -.125em;\n+}\n+\n+b.conum *\n+{\n+    color: inherit!important;\n+}\n+\n+.conum:not([data-value]):empty\n+{\n+    display: none;\n+}\n+\n+\n+p,\n+td.content\n+{\n+    letter-spacing: -.01em;\n+}\n+\n+p strong,\n+td.content strong\n+{\n+    letter-spacing: -.005em;\n+}\n+\n+blockquote,\n+dt,\n+p,\n+td.content\n+{\n+    font-size: 1.0625rem;\n+}\n+\n+p\n+{\n+    margin-bottom: 1.25rem;\n+}\n+\n+.sidebarblock dt,\n+.sidebarblock p,\n+.sidebarblock td.content,\n+p.tableblock\n+{\n+    font-size: 1em;\n+}\n+\n+.exampleblock > .content\n+{\n+    border-color: #e0e0dc;\n+    background-color: #fffef7;\n+    -webkit-box-shadow: 0 1px 4px #e0e0dc;\n+            box-shadow: 0 1px 4px #e0e0dc;\n+}\n+\n+.print-only\n+{\n+    display: none!important;\n+}\n+\n+@media print\n+{\n+    @page\n+    {\n+        margin: 1.25cm .75cm;\n+    }\n+\n+    *\n+    {\n+        -webkit-box-shadow: none!important;\n+                box-shadow: none!important;\n+        text-shadow: none!important;\n+    }\n+\n+    a\n+    {\n+        color: inherit!important;\n+        text-decoration: underline!important;\n+    }\n+\n+    a.bare,\n+    a[href^='#'],\n+    a[href^='mailto:']\n+    {\n+        text-decoration: none!important;\n+    }\n+\n+    a[href^='http:']:not(.bare):after,\n+    a[href^='https:']:not(.bare):after\n+    {\n+        display: inline-block;\n+        padding-left: .25em;\n+        content: '(' attr(href) ')';\n+        font-size: .875em;\n+    }\n+\n+    abbr[title]:after\n+    {\n+        content: ' (' attr(title) ')';\n+    }\n+\n+    blockquote,\n+    img,\n+    pre,\n+    tr\n+    {\n+        page-break-inside: avoid;\n+    }\n+\n+    thead\n+    {\n+        display: table-header-group;\n+    }\n+\n+    img\n+    {\n+        max-width: 100%!important;\n+    }\n+\n+    blockquote,\n+    dt,\n+    p,\n+    td.content\n+    {\n+        font-size: 1em;\n+        orphans: 3;\n+        widows: 3;\n+    }\n+\n+    #toc,\n+    .exampleblock > .content,\n+    .sidebarblock\n+    {\n+        background: none!important;\n+    }\n+\n+    #toc\n+    {\n+        padding-bottom: 0!important;\n+        border-bottom: 1px solid #ddddd8!important;\n+    }\n+\n+    .sect1\n+    {\n+        padding-bottom: 0!important;\n+    }\n+\n+    .sect1 + .sect1\n+    {\n+        border: 0!important;\n+    }\n+\n+    #header > h1:first-child\n+    {\n+        margin-top: 1.25rem;\n+    }\n+\n+    body.book #header\n+    {\n+        text-align: center;\n+    }\n+\n+    body.book #header > h1:first-child\n+    {\n+        margin: 2.5em 0 1em 0;\n+        border: 0!important;\n+    }\n+\n+    body.book #header .details\n+    {\n+        display: block;\n+        padding: 0!important;\n+        border: 0!important;\n+    }\n+\n+    body.book #header .details span:first-child\n+    {\n+        margin-left: 0!important;\n+    }\n+\n+    body.book #header .details br\n+    {\n+        display: block;\n+    }\n+\n+    body.book #header .details br + span:before\n+    {\n+        content: none!important;\n+    }\n+\n+    body.book #toc\n+    {\n+        margin: 0!important;\n+        padding: 0!important;\n+        border: 0!important;\n+        text-align: left!important;\n+    }\n+\n+    body.book #preamble,\n+    body.book #toc,\n+    body.book .sect1 > h2,\n+    body.book h1.sect0\n+    {\n+        page-break-before: always;\n+    }\n+\n+    .listingblock code[data-lang]:before\n+    {\n+        display: block;\n+    }\n+\n+    #footer\n+    {\n+        padding: 0 .9375em;\n+        background: none!important;\n+    }\n+\n+    #footer-text\n+    {\n+        color: rgba(0,0,0,.6)!important;\n+        font-size: .9em;\n+    }\n+\n+    .hide-on-print\n+    {\n+        display: none!important;\n+    }\n+\n+    .print-only\n+    {\n+        display: block!important;\n+    }\n+\n+    .hide-for-print\n+    {\n+        display: none!important;\n+    }\n+\n+    .show-for-print\n+    {\n+        display: inherit!important;\n+    }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/ref-guide.css",
                "sha": "100266b7c65671b3624c73de707ff2deec639182",
                "status": "added"
            },
            {
                "additions": 127,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/theme-solr.css",
                "changes": 127,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/css/theme-solr.css?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/css/theme-solr.css",
                "patch": "@@ -0,0 +1,127 @@\n+.summary {\n+    color: #808080;\n+    border-left: 5px solid #d9411e;\n+    font-size:16px;\n+}\n+\n+.nav-tabs > li.active > a, .nav-tabs > li.active > a:hover, .nav-tabs > li.active > a:focus {\n+    background-color: #FF833D;\n+    color: white;\n+}\n+\n+.nav > li.active > a {\n+    background-color: #262130;\n+}\n+\n+.nav > li > a:hover {\n+    background-color: #FF833D;\n+}\n+\n+div.navbar-collapse .dropdown-menu > li > a:hover {\n+    background-color: #D9411E;\n+}\n+\n+.nav li.thirdlevel > a {\n+    background-color: #FAFAFA !important;\n+    color: #FF833D;\n+    font-weight: bold;\n+}\n+\n+a[data-toggle=\"tooltip\"] {\n+    color: #649345;\n+    font-style: italic;\n+    cursor: default;\n+}\n+\n+.navbar-inverse {\n+    background-color: #D9411E;\n+    border-color: #015CAE;\n+}\n+\n+.navbar-inverse .navbar-nav > .open > a, .navbar-inverse .navbar-nav > .open > a:hover, .navbar-inverse .navbar-nav > .open > a:focus {\n+    color: #015CAE;\n+}\n+\n+.navbar-inverse .navbar-nav > .open > a, .navbar-inverse .navbar-nav > .open > a:hover, .navbar-inverse .navbar-nav > .open > a:focus {\n+    background-color: #015CAE;\n+    color: #ffffff;\n+}\n+\n+/* not sure if using this ...*/\n+.navbar-inverse .navbar-collapse, .navbar-inverse .navbar-form {\n+    border-color: #248ec2 !important;\n+}\n+\n+/* Used for nav buttons */\n+.btn-primary {\n+    color: #ffffff;\n+    background-color: #0A7C38;\n+    border-color: #E6E7E8;\n+}\n+\n+.navbar-inverse .navbar-nav > .active > a, .navbar-inverse .navbar-nav > .active > a:hover, .navbar-inverse .navbar-nav > .active > a:focus {\n+    background-color: #D9411E;\n+}\n+\n+/* Used for nav buttons */\n+.btn-primary:hover,\n+.btn-primary:focus,\n+.btn-primary:active,\n+.btn-primary.active,\n+.open .dropdown-toggle.btn-primary {\n+    background-color: #305CB3;\n+    border-color: #E6E7E8;\n+}\n+\n+.printTitle {\n+    color: #015CAE !important;\n+}\n+\n+body.print h1 {color: #015CAE !important; font-size:28px !important;}\n+body.print h2 {color: #595959 !important; font-size:20px !important;}\n+body.print h3 {color: #E50E51 !important; font-size:14px !important;}\n+body.print h4 {color: #679DCE !important; font-size:14px; font-style: italic !important;}\n+\n+.anchorjs-link:hover {\n+    color: #216f9b;\n+}\n+\n+div.sidebarTitle {\n+    color: #015CAE;\n+}\n+\n+li.sidebarTitle {\n+    margin-top:40px;\n+    font-weight:normal;\n+    font-size:120%;\n+    color: #262130;\n+    margin-bottom:10px;\n+    margin-left: 5px;\n+\n+}\n+.scrollnav {\n+    font-size: larger;\n+    /* why do we need both of these??? */\n+    padding-bottom: 1em;\n+    margin-bottom: 2em;\n+}\n+.scrollnav .prev {\n+    text-align: left;\n+    float: left;\n+    font-size: inherit;\n+}\n+.scrollnav .prev:before {\n+    padding-right: 0.5em;\n+    content: \"\\25C0 \";\n+    display: inline-block; /* text-decoration: none doesn't work, but this does */\n+}\n+.scrollnav .next {\n+    text-align: right;\n+    float: right;\n+    font-size: inherit;\n+}\n+.scrollnav .next:after {\n+    padding-left: 0.5em;\n+    content: \" \\25B6\";\n+    display: inline-block; /* text-decoration: none doesn't work, but this does */\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/css/theme-solr.css",
                "sha": "ae0d6bf2f2f7a829694781106a7f7547410cae35",
                "status": "added"
            },
            {
                "additions": 45,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/datadir-and-directoryfactory-in-solrconfig.adoc",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/datadir-and-directoryfactory-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/datadir-and-directoryfactory-in-solrconfig.adoc",
                "patch": "@@ -0,0 +1,45 @@\n+= DataDir and DirectoryFactory in SolrConfig\n+:page-shortname: datadir-and-directoryfactory-in-solrconfig\n+:page-permalink: datadir-and-directoryfactory-in-solrconfig.html\n+\n+Where and how Solr stores its indexes are configurable options.\n+\n+== Specifying a Location for Index Data with the `dataDir` Parameter\n+\n+By default, Solr stores its index data in a directory called `/data` under the core's instance directory (`instanceDir`). If you would like to specify a different directory for storing index data, you can configure the `dataDir` in the `core.properties` file for the core, or use the `<dataDir>` parameter in the `solrconfig.xml` file. You can specify another directory either with an absolute path or a pathname relative to the instanceDir of the SolrCore. For example:\n+\n+[source,xml]\n+----\n+<dataDir>/solr/data/${solr.core.name}</dataDir>\n+----\n+\n+The `${solr.core.name}` substitution will cause the name of the current core to be substituted, which results in each core's data being kept in a separate subdirectory.\n+\n+If you are using replication to replicate the Solr index (as described in <<legacy-scaling-and-distribution.adoc#legacy-scaling-and-distribution,Legacy Scaling and Distribution>>), then the `<dataDir>` directory should correspond to the index directory used in the replication configuration.\n+\n+[[DataDirandDirectoryFactoryinSolrConfig-SpecifyingtheDirectoryFactoryForYourIndex]]\n+== Specifying the DirectoryFactory For Your Index\n+\n+The default {solr-javadocs}/solr-core/org/apache/solr/core/StandardDirectoryFactory.html[`solr.StandardDirectoryFactory`] is filesystem based, and tries to pick the best implementation for the current JVM and platform. You can force a particular implementation and/or config options by specifying {solr-javadocs}/solr-core/org/apache/solr/core/MMapDirectoryFactory.html[`solr.MMapDirectoryFactory`], {solr-javadocs}/solr-core/org/apache/solr/core/NIOFSDirectoryFactory.html[`solr.NIOFSDirectoryFactory`], or {solr-javadocs}/solr-core/org/apache/solr/core/SimpleFSDirectoryFactory.html[`solr.SimpleFSDirectoryFactory`].\n+\n+[source,xml]\n+----\n+<directoryFactory name=\"DirectoryFactory\"\n+                  class=\"solr.MMapDirectoryFactory\">\n+  <bool name=\"preload\">true</bool>\n+</directoryFactory>\n+----\n+\n+The {solr-javadocs}/solr-core/org/apache/solr/core/RAMDirectoryFactory.html[`solr.RAMDirectoryFactory`] is memory based, not persistent, and does not work with replication. Use this DirectoryFactory to store your index in RAM.\n+\n+[source,xml]\n+----\n+<directoryFactory class=\"org.apache.solr.core.RAMDirectoryFactory\"/>\n+----\n+\n+[NOTE]\n+====\n+\n+If you are using Hadoop and would like to store your indexes in HDFS, you should use the {solr-javadocs}/solr-core/org/apache/solr/core/HdfsDirectoryFactory.html[`solr.HdfsDirectoryFactory`] instead of either of the above implementations. For more details, see the section <<running-solr-on-hdfs.adoc#running-solr-on-hdfs,Running Solr on HDFS>>.\n+\n+====",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/datadir-and-directoryfactory-in-solrconfig.adoc",
                "sha": "e2a847fb3891a2aad993b1ea15cbe80ffd18d233",
                "status": "added"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/dataimport-screen.adoc",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/dataimport-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/dataimport-screen.adoc",
                "patch": "@@ -0,0 +1,13 @@\n+= Dataimport Screen\n+:page-shortname: dataimport-screen\n+:page-permalink: dataimport-screen.html\n+\n+The Dataimport screen shows the configuration of the DataImportHandler (DIH) and allows you start, and monitor the status of, import commands as defined by the options selected on the screen and defined in the configuration file.\n+\n+.The Dataimport Screen\n+image::images/dataimport-screen/dataimport.png[image,width=485,height=250]\n+\n+\n+This screen also lets you adjust various options to control how the data is imported to Solr, and view the data import configuration file that controls the import.\n+\n+For more information about data importing with DIH, see the section on <<uploading-structured-data-store-data-with-the-data-import-handler.adoc#uploading-structured-data-store-data-with-the-data-import-handler,Uploading Structured Data Store Data with the Data Import Handler>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/dataimport-screen.adoc",
                "sha": "a90923e30fa36b02d4ec45d1c93ca2a265fdabf1",
                "status": "added"
            },
            {
                "additions": 100,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/de-duplication.adoc",
                "changes": 100,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/de-duplication.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/de-duplication.adoc",
                "patch": "@@ -0,0 +1,100 @@\n+= De-Duplication\n+:page-shortname: de-duplication\n+:page-permalink: de-duplication.html\n+\n+If duplicate, or near-duplicate documents are a concern in your index, de-duplication may be worth implementing.\n+\n+Preventing duplicate or near duplicate documents from entering an index or tagging documents with a signature/fingerprint for duplicate field collapsing can be efficiently achieved with a low collision or fuzzy hash algorithm. Solr natively supports de-duplication techniques of this type via the `Signature` class and allows for the easy addition of new hash/signature implementations. A Signature can be implemented several ways:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Method |Description\n+|MD5Signature |128-bit hash used for exact duplicate detection.\n+|Lookup3Signature |64-bit hash used for exact duplicate detection. This is much faster than MD5 and smaller to index.\n+|http://wiki.apache.org/solr/TextProfileSignature[TextProfileSignature] |Fuzzy hashing implementation from Apache Nutch for near duplicate detection. It's tunable but works best on longer text.\n+|===\n+\n+Other, more sophisticated algorithms for fuzzy/near hashing can be added later.\n+\n+[IMPORTANT]\n+====\n+Adding in the de-duplication process will change the `allowDups` setting so that it applies to an update term (with `signatureField` in this case) rather than the unique field Term.\n+\n+Of course the `signatureField` could be the unique field, but generally you want the unique field to be unique. When a document is added, a signature will automatically be generated and attached to the document in the specified `signatureField`.\n+====\n+\n+[[De-Duplication-ConfigurationOptions]]\n+== Configuration Options\n+\n+There are two places in Solr to configure de-duplication: in `solrconfig.xml` and in `schema.xml`.\n+\n+[[De-Duplication-Insolrconfig.xml]]\n+=== In `solrconfig.xml`\n+\n+The `SignatureUpdateProcessorFactory` has to be registered in `solrconfig.xml` as part of an <<update-request-processors.adoc#update-request-processors,Update Request Processor Chain>>, as in this example:\n+\n+[source,xml]\n+----\n+<updateRequestProcessorChain name=\"dedupe\">\n+  <processor class=\"solr.processor.SignatureUpdateProcessorFactory\">\n+    <bool name=\"enabled\">true</bool>\n+    <str name=\"signatureField\">id</str>\n+    <bool name=\"overwriteDupes\">false</bool>\n+    <str name=\"fields\">name,features,cat</str>\n+    <str name=\"signatureClass\">solr.processor.Lookup3Signature</str>\n+  </processor>\n+  <processor class=\"solr.LogUpdateProcessorFactory\" />\n+  <processor class=\"solr.RunUpdateProcessorFactory\" />\n+</updateRequestProcessorChain>\n+----\n+\n+The `SignatureUpdateProcessorFactory` takes several properties:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,30,50\",options=\"header\"]\n+|===\n+|Parameter |Default |Description\n+|signatureClass |`org.apache.solr.update.processor.Lookup3Signature` a|\n+A Signature implementation for generating a signature hash. The full classpath of the implementation must be specified. The available options are described above, the associated classpaths to use are:\n+\n+* `org.apache.solr.update.processor.Lookup3Signature`\n+* `org.apache.solr.update.processor.MD5Signature`\n+* `org.apache.solr.update.process.TextProfileSignature`\n+\n+|fields |all fields |The fields to use to generate the signature hash in a comma separated list. By default, all fields on the document will be used.\n+|signatureField |signatureField |The name of the field used to hold the fingerprint/signature. The field should be defined in schema.xml.\n+|enabled |true |Enable/disable de-duplication processing.\n+|overwriteDupes |true |If true, when a document exists that already matches this signature, it will be overwritten.\n+|===\n+\n+[[De-Duplication-Inschema.xml]]\n+=== In `schema.xml`\n+\n+If you are using a separate field for storing the signature, you must have it indexed:\n+\n+[source,xml]\n+----\n+<field name=\"signatureField\" type=\"string\" stored=\"true\" indexed=\"true\" multiValued=\"false\" />\n+----\n+\n+Be sure to change your update handlers to use the defined chain, as below:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/update\" class=\"solr.UpdateRequestHandler\" >\n+  <lst name=\"defaults\">\n+    <str name=\"update.chain\">dedupe</str>\n+  </lst>\n+...\n+</requestHandler>\n+----\n+\n+This example assumes you have other sections of your request handler defined.\n+\n+[TIP]\n+====\n+The update processor can also be specified per request with a parameter of `update.chain=dedupe`.\n+====",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/de-duplication.adoc",
                "sha": "60d3b5874e010a5a6a652278f8d5e7dc04a506ee",
                "status": "added"
            },
            {
                "additions": 79,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/defining-core-properties.adoc",
                "changes": 79,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/defining-core-properties.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/defining-core-properties.adoc",
                "patch": "@@ -0,0 +1,79 @@\n+= Defining core.properties\n+:page-shortname: defining-core-properties\n+:page-permalink: defining-core-properties.html\n+\n+Core discovery means that creating a core is as simple as a `core.properties` file located on disk.\n+\n+The `core.properties` file is a simple Java Properties file where each line is just a key=value pair, e.g., `name=core1`. Notice that no quotes are required.\n+\n+A minimal `core.properties` file looks like the example below. However, it can also be empty, see information on placement of `core.properties` below.\n+\n+[source,bash]\n+----\n+name=my_core_name\n+----\n+\n+[[Definingcore.properties-Placementofcore.properties]]\n+== Placement of core.properties\n+\n+Solr cores are configured by placing a file named `core.properties` in a sub-directory under `solr.home`. There are no a-priori limits to the depth of the tree, nor are there limits to the number of cores that can be defined. Cores may be anywhere in the tree with the exception that cores may _not_ be defined under an existing core. That is, the following is not allowed:\n+\n+[source,text]\n+----\n+./cores/core1/core.properties\n+./cores/core1/coremore/core5/core.properties\n+----\n+\n+In this example, the enumeration will stop at \"core1\".\n+\n+The following is legal:\n+\n+[source,text]\n+----\n+./cores/somecores/core1/core.properties\n+./cores/somecores/core2/core.properties\n+./cores/othercores/core3/core.properties\n+./cores/extracores/deepertree/core4/core.properties\n+----\n+\n+It is possible to segment Solr into multiple cores, each with its own configuration and indices. Cores may be dedicated to a single application or to very different ones, but all are administered through a common administration interface. You can create new Solr cores on the fly, shutdown cores, even replace one running core with another, all without ever stopping or restarting Solr.\n+\n+Your `core.properties` file can be empty if necessary. Suppose `core.properties` is located in `./cores/core1` (relative to `solr_home`) but is empty. In this case, the core name is assumed to be \"core1\". The instanceDir will be the folder containing `core.properties` (i.e., `./cores/core1`). The dataDir will be `../cores/core1/data`, etc.\n+\n+[NOTE]\n+====\n+You can run Solr without configuring any cores.\n+====\n+\n+[[Definingcore.properties-Definingcore.propertiesFiles]]\n+== Defining core.properties Files\n+\n+[[Definingcore.properties-core.properties_files]]\n+\n+The minimal `core.properties` file is an empty file, in which case all of the properties are defaulted appropriately.\n+\n+Java properties files allow the hash (`#`) or bang (`!`) characters to specify comment-to-end-of-line.\n+\n+This table defines the recognized properties:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"25,75\",options=\"header\"]\n+|===\n+|Property |Description\n+|`name` |The name of the SolrCore. You'll use this name to reference the SolrCore when running commands with the CoreAdminHandler.\n+|`config` |The configuration file name for a given core. The default is `solrconfig.xml`.\n+|`schema` |The schema file name for a given core. The default is `schema.xml` but please note that if you are using a \"managed schema\" (the default behavior) then any value for this property which does not match the effective `managedSchemaResourceName` will be read once, backed up, and converted for managed schema use. See <<schema-factory-definition-in-solrconfig.adoc#schema-factory-definition-in-solrconfig,Schema Factory Definition in SolrConfig>> for details.\n+|`dataDir` |The core's data directory (where indexes are stored) as either an absolute pathname, or a path relative to the value of `instanceDir`. This is `data` by default.\n+|`configSet` |The name of a defined configset, if desired, to use to configure the core (see the <<config-sets.adoc#config-sets,Config Sets>> for more details).\n+|`properties` |The name of the properties file for this core. The value can be an absolute pathname or a path relative to the value of `instanceDir`.\n+|`transient` |If *true*, the core can be unloaded if Solr reaches the `transientCacheSize`. The default if not specified is *false*. Cores are unloaded in order of least recently used first. _Setting to *true* is not recommended in SolrCloud mode._\n+|`loadOnStartup` |If *true*, the default if it is not specified, the core will loaded when Solr starts. _Setting to *false* is not recommended in SolrCloud mode._\n+|`coreNodeName` |Used only in SolrCloud, this is a unique identifier for the node hosting this replica. By default a coreNodeName is generated automatically, but setting this attribute explicitly allows you to manually assign a new core to replace an existing replica. For example: when replacing a machine that has had a hardware failure by restoring from backups on a new machine with a new hostname or port..\n+|`ulogDir` |The absolute or relative directory for the update log for this core (SolrCloud).\n+|`shard` |The shard to assign this core to (SolrCloud).\n+|`collection` |The name of the collection this core is part of (SolrCloud).\n+|`roles` |Future param for SolrCloud or a way for users to mark nodes for their own use.\n+|===\n+\n+Additional \"user defined\" properties may be specified for use as variables. For more information on how to define local properties, see the section <<configuring-solrconfig-xml.adoc#Configuringsolrconfig.xml-SubstitutingPropertiesinSolrConfigFiles,Substituting Properties in Solr Config Files>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/defining-core-properties.adoc",
                "sha": "051583898fd1d818f41f3595493927365c7e6dec",
                "status": "added"
            },
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/defining-fields.adoc",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/defining-fields.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/defining-fields.adoc",
                "patch": "@@ -0,0 +1,57 @@\n+= Defining Fields\n+:page-shortname: defining-fields\n+:page-permalink: defining-fields.html\n+\n+Fields are defined in the fields element of `schema.xml`. Once you have the field types set up, defining the fields themselves is simple.\n+\n+[[DefiningFields-Example]]\n+== Example\n+\n+The following example defines a field named `price` with a type named `float` and a default value of `0.0`; the `indexed` and `stored` properties are explicitly set to `true`, while any other properties specified on the `float` field type are inherited.\n+\n+[source,xml]\n+----\n+<field name=\"price\" type=\"float\" default=\"0.0\" indexed=\"true\" stored=\"true\"/>\n+----\n+\n+[[DefiningFields-FieldProperties]]\n+== Field Properties\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Property |Description\n+|name |The name of the field. Field names should consist of alphanumeric or underscore characters only and not start with a digit. This is not currently strictly enforced, but other field names will not have first class support from all components and back compatibility is not guaranteed. Names with both leading and trailing underscores (e.g., `\\_version_`) are reserved. Every field must have a `name`.\n+|type |The name of the `fieldType` for this field. This will be found in the `name` attribute on the `fieldType` definition. Every field must have a `type`.\n+|default |A default value that will be added automatically to any document that does not have a value in this field when it is indexed. If this property is not specified, there is no default.\n+|===\n+\n+[[DefiningFields-OptionalFieldTypeOverrideProperties]]\n+== Optional Field Type Override Properties\n+\n+Fields can have many of the same properties as field types. Properties from the table below which are specified on an individual field will override any explicit value for that property specified on the the `fieldType` of the field, or any implicit default property value provided by the underlying `fieldType` implementation. The table below is reproduced from <<field-type-definitions-and-properties.adoc#field-type-definitions-and-properties,Field Type Definitions and Properties>>, which has more details:\n+\n+// TODO: SOLR-10655 BEGIN: refactor this into a 'field-default-properties.include.adoc' file for reuse\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,40,20,20\",options=\"header\"]\n+|===\n+|Property |Description |Values |Implicit Default\n+|indexed |If true, the value of the field can be used in queries to retrieve matching documents. |true or false |true\n+|stored |If true, the actual value of the field can be retrieved by queries. |true or false |true\n+|docValues |If true, the value of the field will be put in a column-oriented <<docvalues.adoc#docvalues,DocValues>> structure. |true or false |false\n+|sortMissingFirst sortMissingLast |Control the placement of documents when a sort field is not present. |true or false |false\n+|multiValued |If true, indicates that a single document might contain multiple values for this field type. |true or false |false\n+|omitNorms |If true, omits the norms associated with this field (this disables length normalization for the field, and saves some memory). *Defaults to true for all primitive (non-analyzed) field types, such as int, float, data, bool, and string.* Only full-text fields or fields need norms. |true or false |*\n+|omitTermFreqAndPositions |If true, omits term frequency, positions, and payloads from postings for this field. This can be a performance boost for fields that don't require that information. It also reduces the storage space required for the index. Queries that rely on position that are issued on a field with this option will silently fail to find documents. *This property defaults to true for all field types that are not text fields.* |true or false |*\n+|omitPositions |Similar to `omitTermFreqAndPositions` but preserves term frequency information. |true or false |*\n+|termVectors termPositions termOffsets termPayloads |These options instruct Solr to maintain full term vectors for each document, optionally including position, offset and payload information for each term occurrence in those vectors. These can be used to accelerate highlighting and other ancillary functionality, but impose a substantial cost in terms of index size. They are not necessary for typical uses of Solr. |true or false |false\n+|required |Instructs Solr to reject any attempts to add a document which does not have a value for this field. This property defaults to false. |true or false |false\n+|useDocValuesAsStored |If the field has `<<docvalues.adoc#docvalues,docValues>>` enabled, setting this to true would allow the field to be returned as if it were a stored field (even if it has `stored=false`) when matching \"`*`\" in an <<common-query-parameters.adoc#CommonQueryParameters-Thefl_FieldList_Parameter,fl parameter>>. |true or false |true\n+|large |Large fields are always lazy loaded and will only take up space in the document cache if the actual value is < 512KB. This option requires `stored=\"true\"` and `multiValued=\"false\"`. It's intended for fields that might have very large values so that they don't get cached in memory. |true or false |false\n+|===\n+\n+// TODO: SOLR-10655 END\n+",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/defining-fields.adoc",
                "sha": "15dba12c22b2402ed676bcd9cf2e426211c47844",
                "status": "added"
            },
            {
                "additions": 82,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/detecting-languages-during-indexing.adoc",
                "changes": 82,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/detecting-languages-during-indexing.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/detecting-languages-during-indexing.adoc",
                "patch": "@@ -0,0 +1,82 @@\n+= Detecting Languages During Indexing\n+:page-shortname: detecting-languages-during-indexing\n+:page-permalink: detecting-languages-during-indexing.html\n+\n+Solr can identify languages and map text to language-specific fields during indexing using the `langid` UpdateRequestProcessor.\n+\n+Solr supports two implementations of this feature:\n+\n+* Tika's language detection feature: http://tika.apache.org/0.10/detection.html\n+* LangDetect language detection: https://github.com/shuyo/language-detection\n+\n+You can see a comparison between the two implementations here: http://blog.mikemccandless.com/2011/10/accuracy-and-performance-of-googles.html. In general, the LangDetect implementation supports more languages with higher performance.\n+\n+For specific information on each of these language identification implementations, including a list of supported languages for each, see the relevant project websites.\n+\n+For more information about language analysis in Solr, see <<language-analysis.adoc#language-analysis,Language Analysis>>.\n+\n+[[DetectingLanguagesDuringIndexing-ConfiguringLanguageDetection]]\n+== Configuring Language Detection\n+\n+You can configure the `langid` UpdateRequestProcessor in `solrconfig.xml`. Both implementations take the same parameters, which are described in the following section. At a minimum, you must specify the fields for language identification and a field for the resulting language code.\n+\n+[[DetectingLanguagesDuringIndexing-ConfiguringTikaLanguageDetection]]\n+=== Configuring Tika Language Detection\n+\n+Here is an example of a minimal Tika `langid` configuration in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<processor class=\"org.apache.solr.update.processor.TikaLanguageIdentifierUpdateProcessorFactory\">\n+  <lst name=\"defaults\">\n+    <str name=\"langid.fl\">title,subject,text,keywords</str>\n+    <str name=\"langid.langField\">language_s</str>\n+  </lst>\n+</processor>\n+----\n+\n+[[DetectingLanguagesDuringIndexing-ConfiguringLangDetectLanguageDetection]]\n+=== Configuring LangDetect Language Detection\n+\n+Here is an example of a minimal LangDetect `langid` configuration in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<processor class=\"org.apache.solr.update.processor.LangDetectLanguageIdentifierUpdateProcessorFactory\">\n+  <lst name=\"defaults\">\n+    <str name=\"langid.fl\">title,subject,text,keywords</str>\n+    <str name=\"langid.langField\">language_s</str>\n+  </lst>\n+</processor>\n+----\n+\n+[[DetectingLanguagesDuringIndexing-langidParameters]]\n+== `langid` Parameters\n+\n+As previously mentioned, both implementations of the `langid` UpdateRequestProcessor take the same parameters.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,10,10,10,50\",options=\"header\"]\n+|===\n+|Parameter |Type |Default |Required |Description\n+|langid |Boolean |true |no |Enables and disables language detection.\n+|langid.fl |string |none |yes |A comma- or space-delimited list of fields to be processed by `langid`.\n+|langid.langField |string |none |yes |Specifies the field for the returned language code.\n+|langid.langsField |multivalued string |none |no |Specifies the field for a list of returned language codes. If you use `langid.map.individual`, each detected language will be added to this field.\n+|langid.overwrite |Boolean |false |no |Specifies whether the content of the `langField` and `langsField` fields will be overwritten if they already contain values.\n+|langid.lcmap |string |none |false |A space-separated list specifying colon delimited language code mappings to apply to the detected languages. For example, you might use this to map Chinese, Japanese, and Korean to a common `cjk` code, and map both American and British English to a single `en` code by using `langid.lcmap=ja:cjk zh:cjk ko:cjk en_GB:en en_US:en`. This affects both the values put into the `langField` and `langsField` fields, as well as the field suffixes when using `langid.map`, unless overridden by `langid.map.lcmap`\n+|langid.threshold |float |0.5 |no |Specifies a threshold value between 0 and 1 that the language identification score must reach before `langid` accepts it. With longer text fields, a high threshold such at 0.8 will give good results. For shorter text fields, you may need to lower the threshold for language identification, though you will be risking somewhat lower quality results. We recommend experimenting with your data to tune your results.\n+|langid.whitelist |string |none |no |Specifies a list of allowed language identification codes. Use this in combination with `langid.map` to ensure that you only index documents into fields that are in your schema.\n+|langid.map |Boolean |false |no |Enables field name mapping. If true, Solr will map field names for all fields listed in `langid.fl`.\n+|langid.map.fl |string |none |no |A comma-separated list of fields for `langid.map` that is different than the fields specified in `langid.fl`.\n+|langid.map.keepOrig |Boolean |false |no |If true, Solr will copy the field during the field name mapping process, leaving the original field in place.\n+|langid.map.individual |Boolean |false |no |If true, Solr will detect and map languages for each field individually.\n+|langid.map.individual.fl |string |none |no |A comma-separated list of fields for use with `langid.map.individual` that is different than the fields specified in `langid.fl`.\n+|langid.fallbackFields |string |none |no |If no language is detected that meets the `langid.threshold` score, or if the detected language is not on the `langid.whitelist`, this field specifies language codes to be used as fallback values. If no appropriate fallback languages are found, Solr will use the language code specified in `langid.fallback`.\n+|langid.fallback |string |none |no |Specifies a language code to use if no language is detected or specified in `langid.fallbackFields`.\n+|langid.map.lcmap |string |determined by `langid.lcmap` |no |A space-separated list specifying colon delimited language code mappings to use when mapping field names. For example, you might use this to make Chinese, Japanese, and Korean language fields use a common `*_cjk` suffix, and map both American and British English fields to a single `*_en` by using `langid.map.lcmap=ja:cjk zh:cjk ko:cjk en_GB:en en_US:en`.\n+|langid.map.pattern |Java regular expression |none |no |By default, fields are mapped as <field>_<language>. To change this pattern, you can specify a Java regular expression in this parameter.\n+|langid.map.replace |Java replace |none |no |By default, fields are mapped as <field>_<language>. To change this pattern, you can specify a Java replace in this parameter.\n+|langid.enforceSchema |Boolean |true |no |If false, the `langid` processor does not validate field names against your schema. This may be useful if you plan to rename or delete fields later in the UpdateChain.\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/detecting-languages-during-indexing.adoc",
                "sha": "44cd456ec742f421188f751158d348d51dd5bd44",
                "status": "added"
            },
            {
                "additions": 123,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/distributed-requests.adoc",
                "changes": 123,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/distributed-requests.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/distributed-requests.adoc",
                "patch": "@@ -0,0 +1,123 @@\n+= Distributed Requests\n+:page-shortname: distributed-requests\n+:page-permalink: distributed-requests.html\n+\n+When a Solr node receives a search request, the request is routed behind the scenes to a replica of a shard that is part of the collection being searched.\n+\n+The chosen replica acts as an aggregator: it creates internal requests to randomly chosen replicas of every shard in the collection, coordinates the responses, issues any subsequent internal requests as needed (for example, to refine facets values, or request additional stored fields), and constructs the final response for the client.\n+\n+[[DistributedRequests-LimitingWhichShardsareQueried]]\n+== Limiting Which Shards are Queried\n+\n+While one of the advantages of using SolrCloud is the ability to query very large collections distributed among various shards, in some cases <<shards-and-indexing-data-in-solrcloud.adoc#ShardsandIndexingDatainSolrCloud-DocumentRouting,you may know that you are only interested in results from a subset of your shards>>. You have the option of searching over all of your data or just parts of it.\n+\n+Querying all shards for a collection should look familiar; it's as though SolrCloud didn't even come into play:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*\n+----\n+\n+If, on the other hand, you wanted to search just one shard, you can specify that shard by its logical ID, as in:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*&shards=shard1\n+----\n+\n+If you want to search a group of shard Ids, you can specify them together:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*&shards=shard1,shard2\n+----\n+\n+In both of the above examples, the shard Id(s) will be used to pick a random replica of that shard.\n+\n+Alternatively, you can specify the explicit replicas you wish to use in place of a shard Ids:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*&shards=localhost:7574/solr/gettingstarted,localhost:8983/solr/gettingstarted\n+----\n+\n+Or you can specify a list of replicas to choose from for a single shard (for load balancing purposes) by using the pipe symbol (|):\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*&shards=localhost:7574/solr/gettingstarted|localhost:7500/solr/gettingstarted\n+----\n+\n+And of course, you can specify a list of shards (seperated by commas) each defined by a list of replicas (seperated by pipes). In this example, 2 shards are queried, the first being a random replica from shard1, the second being a random replica from the explicit pipe delimited list:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/gettingstarted/select?q=*:*&shards=shard1,localhost:7574/solr/gettingstarted|localhost:7500/solr/gettingstarted\n+----\n+\n+[[DistributedRequests-ConfiguringtheShardHandlerFactory]]\n+== Configuring the ShardHandlerFactory\n+\n+You can directly configure aspects of the concurrency and thread-pooling used within distributed search in Solr. This allows for finer grained control and you can tune it to target your own specific requirements. The default configuration favors throughput over latency.\n+\n+To configure the standard handler, provide a configuration like this in `solrconfig.xml`:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">\n+  <!-- other params go here -->\n+  <shardHandler class=\"HttpShardHandlerFactory\">\n+    <int name=\"socketTimeOut\">1000</int>\n+    <int name=\"connTimeOut\">5000</int>\n+  </shardHandler>\n+</requestHandler>\n+----\n+\n+The parameters that can be specified are as follows:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,65\",options=\"header\"]\n+|===\n+|Parameter |Default |Explanation\n+|`socketTimeout` |0 (use OS default) |The amount of time in ms that a socket is allowed to wait.\n+|`connTimeout` |0 (use OS default) |The amount of time in ms that is accepted for binding / connecting a socket\n+|`maxConnectionsPerHost` |20 |The maximum number of concurrent connections that is made to each individual shard in a distributed search.\n+|`maxConnections` |`10000` |The total maximum number of concurrent connections in distributed searches.\n+|`corePoolSize` |0 |The retained lowest limit on the number of threads used in coordinating distributed search.\n+|`maximumPoolSize` |Integer.MAX_VALUE |The maximum number of threads used for coordinating distributed search.\n+|`maxThreadIdleTime` |5 seconds |The amount of time to wait for before threads are scaled back in response to a reduction in load.\n+|`sizeOfQueue` |-1 |If specified, the thread pool will use a backing queue instead of a direct handoff buffer. High throughput systems will want to configure this to be a direct hand off (with -1). Systems that desire better latency will want to configure a reasonable size of queue to handle variations in requests.\n+|`fairnessPolicy` |false |Chooses the JVM specifics dealing with fair policy queuing, if enabled distributed searches will be handled in a First in First out fashion at a cost to throughput. If disabled throughput will be favored over latency.\n+|===\n+\n+[[DistributedRequests-ConfiguringstatsCache_DistributedIDF_]]\n+== Configuring statsCache (Distributed IDF)\n+\n+Document and term statistics are needed in order to calculate relevancy. Solr provides four implementations out of the box when it comes to document stats calculation:\n+\n+* `LocalStatsCache`: This only uses local term and document statistics to compute relevance. In cases with uniform term distribution across shards, this works reasonably well.This option is the default if no `<statsCache>` is configured.\n+* `ExactStatsCache`: This implementation uses global values (across the collection) for document frequency.\n+* `ExactSharedStatsCache`: This is exactly like the exact stats cache in its functionality but the global stats are reused for subsequent requests with the same terms.\n+* `LRUStatsCache`: This implementation uses an LRU cache to hold global stats, which are shared between requests.\n+\n+The implementation can be selected by setting `<statsCache>` in `solrconfig.xml`. For example, the following line makes Solr use the `ExactStatsCache` implementation:\n+\n+[source,xml]\n+----\n+<statsCache class=\"org.apache.solr.search.stats.ExactStatsCache\"/>\n+----\n+\n+[[DistributedRequests-AvoidingDistributedDeadlock]]\n+== Avoiding Distributed Deadlock\n+\n+Each shard serves top-level query requests and then makes sub-requests to all of the other shards. Care should be taken to ensure that the max number of threads serving HTTP requests is greater than the possible number of requests from both top-level clients and other shards. If this is not the case, the configuration may result in a distributed deadlock.\n+\n+For example, a deadlock might occur in the case of two shards, each with just a single thread to service HTTP requests. Both threads could receive a top-level request concurrently, and make sub-requests to each other. Because there are no more remaining threads to service requests, the incoming requests will be blocked until the other pending requests are finished, but they will not finish since they are waiting for the sub-requests. By ensuring that Solr is configured to handle a sufficient number of threads, you can avoid deadlock situations like this.\n+\n+[[DistributedRequests-PreferLocalShards]]\n+== Prefer Local Shards\n+\n+Solr allows you to pass an optional boolean parameter named `preferLocalShards` to indicate that a distributed query should prefer local replicas of a shard when available. In other words, if a query includes `preferLocalShards=true`, then the query controller will look for local replicas to service the query instead of selecting replicas at random from across the cluster. This is useful when a query requests many fields or large fields to be returned per document because it avoids moving large amounts of data over the network when it is available locally. In addition, this feature can be useful for minimizing the impact of a problematic replica with degraded performance, as it reduces the likelihood that the degraded replica will be hit by other healthy replicas.\n+\n+Lastly, it follows that the value of this feature diminishes as the number of shards in a collection increases because the query controller will have to direct the query to non-local replicas for most of the shards. In other words, this feature is mostly useful for optimizing queries directed towards collections with a small number of shards and many replicas. Also, this option should only be used if you are load balancing requests across all nodes that host replicas for the collection you are querying, as Solr's CloudSolrClient will do. If not load-balancing, this feature can introduce a hotspot in the cluster since queries won't be evenly distributed across the cluster.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/distributed-requests.adoc",
                "sha": "ae771791b433f1a71dff7015a379551021278004",
                "status": "added"
            },
            {
                "additions": 165,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/distributed-search-with-index-sharding.adoc",
                "changes": 165,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/distributed-search-with-index-sharding.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/distributed-search-with-index-sharding.adoc",
                "patch": "@@ -0,0 +1,165 @@\n+= Distributed Search with Index Sharding\n+:page-shortname: distributed-search-with-index-sharding\n+:page-permalink: distributed-search-with-index-sharding.html\n+\n+When using traditional index sharding, you will need to consider how to query your documents.\n+\n+It is highly recommended that you use <<solrcloud.adoc#solrcloud,SolrCloud>> when needing to scale up or scale out. The setup described below is legacy and was used prior to the existence of SolrCloud. SolrCloud provides for a truly distributed set of features with support for things like automatic routing, leader election, optimistic concurrency and other sanity checks that are expected out of a distributed system.\n+\n+Everything on this page is specific to legacy setup of distributed search. Users trying out SolrCloud should not follow any of the steps or information below.\n+\n+Update reorders (i.e., replica A may see update X then Y, and replica B may see update Y then X). *deleteByQuery* also handles reorders the same way, to ensure replicas are consistent. All replicas of a shard are consistent, even if the updates arrive in a different order on different replicas.\n+\n+[[DistributedSearchwithIndexSharding-DistributingDocumentsacrossShards]]\n+== Distributing Documents across Shards\n+\n+When not using SolrCloud, it is up to you to get all your documents indexed on each shard of your server farm. Solr supports distributed indexing (routing) in its true form only in the SolrCloud mode.\n+\n+In the legacy distributed mode, Solr does not calculate universal term/doc frequencies. For most large-scale implementations, it is not likely to matter that Solr calculates TF/IDF at the shard level. However, if your collection is heavily skewed in its distribution across servers, you may find misleading relevancy results in your searches. In general, it is probably best to randomly distribute documents to your shards.\n+\n+[[DistributedSearchwithIndexSharding-ExecutingDistributedSearcheswiththeshardsParameter]]\n+== Executing Distributed Searches with the `shards` Parameter\n+\n+If a query request includes the `shards` parameter, the Solr server distributes the request across all the shards listed as arguments to the parameter. The `shards` parameter uses this syntax:\n+\n+`host:port/base_url,host:port/base_url*`\n+\n+For example, the `shards` parameter below causes the search to be distributed across two Solr servers: *solr1* and **solr2**, both of which are running on port 8983:\n+\n+`\\http://localhost:8983/solr/core1/select?shards=solr1:8983/solr/core1,solr2:8983/solr/core1&indent=true&q=ipod+solr`\n+\n+Rather than require users to include the shards parameter explicitly, it is usually preferred to configure this parameter as a default in the RequestHandler section of `solrconfig.xml`.\n+\n+[IMPORTANT]\n+====\n+Do not add the `shards` parameter to the standard request handler; doing so may cause search queries may enter an infinite loop. Instead, define a new request handler that uses the `shards` parameter, and pass distributed search requests to that handler.\n+====\n+\n+With Legacy mode, only query requests are distributed. This includes requests to the SearchHandler (or any handler extending from `org.apache.solr.handler.component.SearchHandler`) using standard components that support distributed search.\n+\n+As in SolrCloud mode, when `shards.info=true`, distributed responses will include information about the shard (where each shard represents a logically different index or physical location)\n+\n+The following components support distributed search:\n+\n+* The *Query* component, which returns documents matching a query\n+* The *Facet* component, which processes facet.query and facet.field requests where facets are sorted by count (the default).\n+* The *Highlighting* component, which enables Solr to include \"highlighted\" matches in field values.\n+* The *Stats* component, which returns simple statistics for numeric fields within the DocSet.\n+* The *Debug* component, which helps with debugging.\n+\n+[[DistributedSearchwithIndexSharding-LimitationstoDistributedSearch]]\n+== Limitations to Distributed Search\n+\n+Distributed searching in Solr has the following limitations:\n+\n+* Each document indexed must have a unique key.\n+* If Solr discovers duplicate document IDs, Solr selects the first document and discards subsequent ones.\n+* The index for distributed searching may become momentarily out of sync if a commit happens between the first and second phase of the distributed search. This might cause a situation where a document that once matched a query and was subsequently changed may no longer match the query but will still be retrieved. This situation is expected to be quite rare, however, and is only possible for a single query request.\n+* The number of shards is limited by number of characters allowed for GET method's URI; most Web servers generally support at least 4000 characters, but many servers limit URI length to reduce their vulnerability to Denial of Service (DoS) attacks.\n+* Shard information can be returned with each document in a distributed search by including `fl=id, [shard]` in the search request. This returns the shard URL.\n+* In a distributed search, the data directory from the core descriptor overrides any data directory in `solrconfig.xml.`\n+* Update commands may be sent to any server with distributed indexing configured correctly. Document adds and deletes are forwarded to the appropriate server/shard based on a hash of the unique document id. *commit* commands and *deleteByQuery* commands are sent to every server in `shards`.\n+\n+Formerly a limitation was that TF/IDF relevancy computations only used shard-local statistics. This is still the case by default. If your data isn't randomly distributed, or if you want more exact statistics, then remember to configure the ExactStatsCache.\n+\n+[[DistributedSearchwithIndexSharding-AvoidingDistributedDeadlock]]\n+== Avoiding Distributed Deadlock\n+\n+Like in SolrCloud mode, inter-shard requests could lead to a distributed deadlock. It can be avoided by following the instructions in the section  <<distributed-requests.adoc#distributed-requests,Distributed Requests>>.\n+\n+[[DistributedSearchwithIndexSharding-TestingIndexShardingonTwoLocalServers]]\n+== Testing Index Sharding on Two Local Servers\n+\n+For simple functional testing, it's easiest to just set up two local Solr servers on different ports. (In a production environment, of course, these servers would be deployed on separate machines.)\n+\n+.  Make two Solr home directories and copy `solr.xml` into the new directories:\n++\n+[source,bash]\n+----\n+mkdir example/nodes\n+mkdir example/nodes/node1\n+# Copy solr.xml into this solr.home\n+cp server/solr/solr.xml example/nodes/node1/.\n+# Repeat the above steps for the second node\n+mkdir example/nodes/node2\n+cp server/solr/solr.xml example/nodes/node2/.\n+----\n+.  Start the two Solr instances\n++\n+[source,bash]\n+----\n+# Start first node on port 8983\n+bin/solr start -s example/nodes/node1 -p 8983\n+\n+# Start second node on port 8984\n+bin/solr start -s example/nodes/node2 -p 8984\n+----\n+.  Create a core on both the nodes with the sample_techproducts_configs.\n++\n+[source,bash]\n+----\n+bin/solr create_core -c core1 -p 8983 -d sample_techproducts_configs\n+# Create a core on the Solr node running on port 8984\n+bin/solr create_core -c core1 -p 8984 -d sample_techproducts_configs\n+----\n+.  In a third window, index an example document to each of the server:\n++\n+[source,bash]\n+----\n+bin/post -c core1 example/exampledocs/monitor.xml -port 8983\n+\n+bin/post -c core1 example/exampledocs/monitor2.xml -port 8984\n+----\n+.  Search on the node on port 8983:\n++\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/core1/select?q=*:*&wt=xml&indent=true\n+----\n++\n+This should bring back one document.\n++\n+Search on the node on port 8984:\n++\n+[source,bash]\n+----\n+curl http://localhost:8984/solr/core1/select?q=*:*&wt=xml&indent=true\n+----\n++\n+This should also bring back a single document.\n++\n+Now do a distributed search across both servers with your browser or `curl.` In the example below, an extra parameter 'fl' is passed to restrict the returned fields to id and name.\n++\n+[source,bash]\n+----\n+curl http://localhost:8983/solr/core1/select?q=*:*&indent=true&shards=localhost:8983/solr/core1,localhost:8984/solr/core1&fl=id,name\n+----\n++\n+This should contain both the documents as shown below:\n++\n+[source,xml]\n+----\n+<response>\n+  <lst name=\"responseHeader\">\n+    <int name=\"status\">0</int>\n+    <int name=\"QTime\">8</int>\n+    <lst name=\"params\">\n+      <str name=\"q\">*:*</str>\n+      <str name=\"shards\">localhost:8983/solr/core1,localhost:8984/solr/core1</str>\n+      <str name=\"indent\">true</str>\n+      <str name=\"fl\">id,name</str>\n+      <str name=\"wt\">xml</str>\n+    </lst>\n+  </lst>\n+  <result name=\"response\" numFound=\"2\" start=\"0\" maxScore=\"1.0\">\n+    <doc>\n+      <str name=\"id\">3007WFP</str>\n+      <str name=\"name\">Dell Widescreen UltraSharp 3007WFP</str>\n+    </doc>\n+    <doc>\n+      <str name=\"id\">VA902B</str>\n+      <str name=\"name\">ViewSonic VA902B - flat panel display - TFT - 19\"</str>\n+    </doc>\n+  </result>\n+</response>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/distributed-search-with-index-sharding.adoc",
                "sha": "7c7ede89d75ee8f17df8bf5b55f0267bb7629b9d",
                "status": "added"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/documents-fields-and-schema-design.adoc",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/documents-fields-and-schema-design.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/documents-fields-and-schema-design.adoc",
                "patch": "@@ -0,0 +1,28 @@\n+= Documents, Fields, and Schema Design\n+:page-shortname: documents-fields-and-schema-design\n+:page-permalink: documents-fields-and-schema-design.html\n+:page-children: overview-of-documents-fields-and-schema-design, solr-field-types, defining-fields, copying-fields, dynamic-fields, other-schema-elements, schema-api, putting-the-pieces-together, docvalues, schemaless-mode\n+\n+This section discusses how Solr organizes its data into documents and fields, as well as how to work with a schema in Solr.\n+\n+This section includes the following topics:\n+\n+<<overview-of-documents-fields-and-schema-design.adoc#overview-of-documents-fields-and-schema-design,Overview of Documents, Fields, and Schema Design>>: An introduction to the concepts covered in this section.\n+\n+<<solr-field-types.adoc#solr-field-types,Solr Field Types>>: Detailed information about field types in Solr, including the field types in the default Solr schema.\n+\n+<<defining-fields.adoc#defining-fields,Defining Fields>>: Describes how to define fields in Solr.\n+\n+<<copying-fields.adoc#copying-fields,Copying Fields>>: Describes how to populate fields with data copied from another field.\n+\n+<<dynamic-fields.adoc#dynamic-fields,Dynamic Fields>>: Information about using dynamic fields in order to catch and index fields that do not exactly conform to other field definitions in your schema.\n+\n+<<schema-api.adoc#schema-api,Schema API>>: Use curl commands to read various parts of a schema or create new fields and copyField rules.\n+\n+<<other-schema-elements.adoc#other-schema-elements,Other Schema Elements>>: Describes other important elements in the Solr schema.\n+\n+<<putting-the-pieces-together.adoc#putting-the-pieces-together,Putting the Pieces Together>>: A higher-level view of the Solr schema and how its elements work together.\n+\n+<<docvalues.adoc#docvalues,DocValues>>: Describes how to create a docValues index for faster lookups.\n+\n+<<schemaless-mode.adoc#schemaless-mode,Schemaless Mode>>: Automatically add previously unknown schema fields using value-based field type guessing.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/documents-fields-and-schema-design.adoc",
                "sha": "15b216424bfcec44bb87cee321ef7456b20b4f7c",
                "status": "added"
            },
            {
                "additions": 73,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/documents-screen.adoc",
                "changes": 73,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/documents-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/documents-screen.adoc",
                "patch": "@@ -0,0 +1,73 @@\n+= Documents Screen\n+:page-shortname: documents-screen\n+:page-permalink: documents-screen.html\n+\n+The Documents screen provides a simple form allowing you to execute various Solr indexing commands in a variety of formats directly from the browser.\n+\n+.The Documents Screen\n+image::images/documents-screen/documents_add_screen.png[image,height=400]\n+\n+The screen allows you to:\n+\n+* Copy documents in JSON, CSV or XML and submit them to the index\n+* Upload documents (in JSON, CSV or XML)\n+* Construct documents by selecting fields and field values\n+\n+\n+[TIP]\n+====\n+There are other ways to load data, see also these sections:\n+\n+* <<uploading-data-with-index-handlers.adoc#uploading-data-with-index-handlers,Uploading Data with Index Handlers>>\n+* <<uploading-data-with-solr-cell-using-apache-tika.adoc#uploading-data-with-solr-cell-using-apache-tika,Uploading Data with Solr Cell using Apache Tika>>\n+====\n+\n+The first step is to define the RequestHandler to use (aka, 'qt'). By default `/update` will be defined. To use Solr Cell, for example, change the request handler to `/update/extract`.\n+\n+Then choose the Document Type to define the type of document to load. The remaining parameters will change depending on the document type selected.\n+\n+[[DocumentsScreen-JSON]]\n+== JSON\n+\n+When using the JSON document type, the functionality is similar to using a requestHandler on the command line. Instead of putting the documents in a curl command, they can instead be input into the Document entry box. The document structure should still be in proper JSON format.\n+\n+Then you can choose when documents should be added to the index (Commit Within), & whether existing documents should be overwritten with incoming documents with the same id (if this is not *true*, then the incoming documents will be dropped).\n+\n+This option will only add or overwrite documents to the index; for other update tasks, see the <<DocumentsScreen-SolrCommand,Solr Command>> option.\n+\n+[[DocumentsScreen-CSV]]\n+== CSV\n+\n+When using the CSV document type, the functionality is similar to using a requestHandler on the command line. Instead of putting the documents in a curl command, they can instead be input into the Document entry box. The document structure should still be in proper CSV format, with columns delimited and one row per document.\n+\n+Then you can choose when documents should be added to the index (Commit Within), and whether existing documents should be overwritten with incoming documents with the same id (if this is not *true*, then the incoming documents will be dropped).\n+\n+[[DocumentsScreen-DocumentBuilder]]\n+== Document Builder\n+\n+The Document Builder provides a wizard-like interface to enter fields of a document\n+\n+[[DocumentsScreen-FileUpload]]\n+== File Upload\n+\n+The File Upload option allows choosing a prepared file and uploading it. If using only `/update` for the Request-Handler option, you will be limited to XML, CSV, and JSON.\n+\n+However, to use the ExtractingRequestHandler (aka Solr Cell), you can modify the Request-Handler to `/update/extract`. You must have this defined in your `solrconfig.xml` file, with your desired defaults. You should also update the `&literal.id` shown in the Extracting Req. Handler Params so the file chosen is given a unique id.\n+\n+Then you can choose when documents should be added to the index (Commit Within), and whether existing documents should be overwritten with incoming documents with the same id (if this is not *true*, then the incoming documents will be dropped).\n+\n+[[DocumentsScreen-SolrCommand]]\n+== Solr Command\n+\n+The Solr Command option allows you use XML or JSON to perform specific actions on documents, such as defining documents to be added or deleted, updating only certain fields of documents, or commit and optimize commands on the index.\n+\n+The documents should be structured as they would be if using `/update` on the command line.\n+\n+[[DocumentsScreen-XML]]\n+== XML\n+\n+When using the XML document type, the functionality is similar to using a requestHandler on the command line. Instead of putting the documents in a curl command, they can instead be input into the Document entry box. The document structure should still be in proper Solr XML format, with each document separated by `<doc>` tags and each field defined.\n+\n+Then you can choose when documents should be added to the index (Commit Within), and whether existing documents should be overwritten with incoming documents with the same id (if this is not **true**, then the incoming documents will be dropped).\n+\n+This option will only add or overwrite documents to the index; for other update tasks, see the <<DocumentsScreen-SolrCommand,Solr Command>> option.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/documents-screen.adoc",
                "sha": "a885e97b395425edf2a7528beb4a10fbb29210a0",
                "status": "added"
            },
            {
                "additions": 75,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/docvalues.adoc",
                "changes": 75,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/docvalues.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/docvalues.adoc",
                "patch": "@@ -0,0 +1,75 @@\n+= DocValues\n+:page-shortname: docvalues\n+:page-permalink: docvalues.html\n+\n+DocValues are a way of recording field values internally that is more efficient for some purposes, such as sorting and faceting, than traditional indexing.\n+\n+== Why DocValues?\n+\n+The standard way that Solr builds the index is with an _inverted index_. This style builds a list of terms found in all the documents in the index and next to each term is a list of documents that the term appears in (as well as how many times the term appears in that document). This makes search very fast - since users search by terms, having a ready list of term-to-document values makes the query process faster.\n+\n+For other features that we now commonly associate with search, such as sorting, faceting, and highlighting, this approach is not very efficient. The faceting engine, for example, must look up each term that appears in each document that will make up the result set and pull the document IDs in order to build the facet list. In Solr, this is maintained in memory, and can be slow to load (depending on the number of documents, terms, etc.).\n+\n+In Lucene 4.0, a new approach was introduced. DocValue fields are now column-oriented fields with a document-to-value mapping built at index time. This approach promises to relieve some of the memory requirements of the fieldCache and make lookups for faceting, sorting, and grouping much faster.\n+\n+[[DocValues-EnablingDocValues]]\n+== Enabling DocValues\n+\n+To use docValues, you only need to enable it for a field that you will use it with. As with all schema design, you need to define a field type and then define fields of that type with docValues enabled. All of these actions are done in `schema.xml`.\n+\n+Enabling a field for docValues only requires adding `docValues=\"true\"` to the field (or field type) definition, as in this example from the `schema.xml` of Solr's `sample_techproducts_configs` <<config-sets.adoc#config-sets,config set>>:\n+\n+[source,xml]\n+----\n+<field name=\"manu_exact\" type=\"string\" indexed=\"false\" stored=\"false\" docValues=\"true\" />\n+----\n+\n+[IMPORTANT]\n+If you have already indexed data into your Solr index, you will need to completely re-index your content after changing your field definitions in `schema.xml` in order to successfully use docValues.\n+\n+DocValues are only available for specific field types. The types chosen determine the underlying Lucene docValue type that will be used. The available Solr field types are:\n+\n+* `StrField` and `UUIDField`.\n+** If the field is single-valued (i.e., multi-valued is false), Lucene will use the SORTED type.\n+** If the field is multi-valued, Lucene will use the SORTED_SET type.\n+* Any `Trie*` numeric fields, date fields and `EnumField`.\n+** If the field is single-valued (i.e., multi-valued is false), Lucene will use the NUMERIC type.\n+** If the field is multi-valued, Lucene will use the SORTED_SET type.\n+* Boolean fields\n+* Int|Long|Float|Double|Date PointField\n+** If the field is single-valued (i.e., multi-valued is false), Lucene will use the NUMERIC type.\n+** If the field is multi-valued, Lucene will use the SORTED_NUMERIC type.\n+\n+These Lucene types are related to how the {lucene-javadocs}/core/org/apache/lucene/index/DocValuesType.html[values are sorted and stored].\n+\n+There is an additional configuration option available, which is to modify the `docValuesFormat` <<field-type-definitions-and-properties.adoc#FieldTypeDefinitionsandProperties-docValuesFormat,used by the field type>>. The default implementation employs a mixture of loading some things into memory and keeping some on disk. In some cases, however, you may choose to specify an alternative {lucene-javadocs}/core/org/apache/lucene/codecs/DocValuesFormat.html[DocValuesFormat implementation]. For example, you could choose to keep everything in memory by specifying `docValuesFormat=\"Memory\"` on a field type:\n+\n+[source,xml]\n+----\n+<fieldType name=\"string_in_mem_dv\" class=\"solr.StrField\" docValues=\"true\" docValuesFormat=\"Memory\" />\n+----\n+\n+Please note that the `docValuesFormat` option may change in future releases.\n+\n+[NOTE]\n+Lucene index back-compatibility is only supported for the default codec. If you choose to customize the `docValuesFormat` in your schema.xml, upgrading to a future version of Solr may require you to either switch back to the default codec and optimize your index to rewrite it into the default codec before upgrading, or re-build your entire index from scratch after upgrading.\n+\n+== Using DocValues\n+\n+=== Sorting, Faceting & Functions\n+\n+If `docValues=\"true\"` for a field, then DocValues will automatically be used any time the field is used for <<common-query-parameters.adoc#CommonQueryParameters-ThesortParameter,sorting>>, <<faceting.adoc#faceting,faceting>> or <<function-queries.adoc#function-queries,function queries>>.\n+\n+[[DocValues-RetrievingDocValuesDuringSearch]]\n+=== Retrieving DocValues During Search\n+\n+Field values retrieved during search queries are typically returned from stored values. However, non-stored docValues fields will be also returned along with other stored fields when all fields (or pattern matching globs) are specified to be returned (e.g. \"`fl=*`\") for search queries depending on the effective value of the `useDocValuesAsStored` parameter for each field. For schema versions >= 1.6, the implicit default is `useDocValuesAsStored=\"true\"`. See <<field-type-definitions-and-properties.adoc#field-type-definitions-and-properties,Field Type Definitions and Properties>> & <<defining-fields.adoc#defining-fields,Defining Fields>> for more details.\n+\n+When `useDocValuesAsStored=\"false\"`, non-stored DocValues fields can still be explicitly requested by name in the <<common-query-parameters.adoc#CommonQueryParameters-Thefl_FieldList_Parameter,fl param>>, but will not match glob patterns (`\"*\"`). Note that returning DocValues along with \"regular\" stored fields at query time has performance implications that stored fields may not because DocValues are column-oriented and may therefore incur additional cost to retrieve for each returned document. Also note that while returning non-stored fields from DocValues, the values of a multi-valued field are returned in sorted order (and not insertion order). If you require the multi-valued fields to be returned in the original insertion order, then make your multi-valued field as stored (such a change requires re-indexing).\n+\n+In cases where the query is returning _only_ docValues fields performance may improve since returning stored fields requires disk reads and decompression whereas returning docValues fields in the fl list only requires memory access.\n+\n+When retrieving fields from their docValues form (using the <<exporting-result-sets.adoc#exporting-result-sets,/export handler>>, <<streaming-expressions.adoc#streaming-expressions,streaming expressions>> or if the field is requested in the `fl` parameter), two important differences between regular stored fields and docValues fields must be understood:\n+\n+1.  Order is _not_ preserved. For simply retrieving stored fields, the insertion order is the return order. For docValues, it is the _sorted_ order.\n+2.  Multiple identical entries are collapsed into a single value. Thus if I insert values 4, 5, 2, 4, 1, my return will be 1, 2, 4, 5.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/docvalues.adoc",
                "sha": "d7ff9ad35624e22a37314dd2755c79dde1748139",
                "status": "added"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/dynamic-fields.adoc",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/dynamic-fields.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/dynamic-fields.adoc",
                "patch": "@@ -0,0 +1,20 @@\n+= Dynamic Fields\n+:page-shortname: dynamic-fields\n+:page-permalink: dynamic-fields.html\n+\n+_Dynamic fields_ allow Solr to index fields that you did not explicitly define in your schema.\n+\n+This is useful if you discover you have forgotten to define one or more fields. Dynamic fields can make your application less brittle by providing some flexibility in the documents you can add to Solr.\n+\n+A dynamic field is just like a regular field except it has a name with a wildcard in it. When you are indexing documents, a field that does not match any explicitly defined fields can be matched with a dynamic field.\n+\n+For example, suppose your schema includes a dynamic field with a name of `*_i`. If you attempt to index a document with a `cost_i` field, but no explicit `cost_i` field is defined in the schema, then the `cost_i` field will have the field type and analysis defined for `*_i`.\n+\n+Like regular fields, dynamic fields have a name, a field type, and options.\n+\n+[source,xml]\n+----\n+<dynamicField name=\"*_i\" type=\"int\" indexed=\"true\"  stored=\"true\"/>\n+----\n+\n+It is recommended that you include basic dynamic field mappings (like that shown above) in your `schema.xml`. The mappings can be very useful.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/dynamic-fields.adoc",
                "sha": "32888cca8873102ebfdae61fe907a170016529e5",
                "status": "added"
            },
            {
                "additions": 345,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/enabling-ssl.adoc",
                "changes": 345,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/enabling-ssl.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/enabling-ssl.adoc",
                "patch": "@@ -0,0 +1,345 @@\n+= Enabling SSL\n+:page-shortname: enabling-ssl\n+:page-permalink: enabling-ssl.html\n+\n+Solr can encrypt communications to and from clients, and between nodes in SolrCloud mode, with SSL.\n+\n+This section describes enabling SSL with the example Jetty server using a self-signed certificate.\n+\n+For background on SSL certificates and keys, see http://www.tldp.org/HOWTO/SSL-Certificates-HOWTO/.\n+\n+[[EnablingSSL-BasicSSLSetup]]\n+== Basic SSL Setup\n+\n+[[EnablingSSL-Generateaself-signedcertificateandakey]]\n+=== Generate a Self-Signed Certificate and a Key\n+\n+To generate a self-signed certificate and a single key that will be used to authenticate both the server and the client, we'll use the JDK https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html[`keytool`] command and create a separate keystore. This keystore will also be used as a truststore below. It's possible to use the keystore that comes with the JDK for these purposes, and to use a separate truststore, but those options aren't covered here.\n+\n+Run the commands below in the `server/etc/` directory in the binary Solr distribution. It's assumed that you have the JDK `keytool` utility on your `PATH`, and that `openssl` is also on your `PATH`. See https://www.openssl.org/related/binaries.html for OpenSSL binaries for Windows and Solaris.\n+\n+The `-ext SAN=...` `keytool` option allows you to specify all the DNS names and/or IP addresses that will be allowed during hostname verification (but see below for how to skip hostname verification between Solr nodes so that you don't have to specify all hosts here).\n+\n+In addition to `localhost` and `127.0.0.1`, this example includes a LAN IP address `192.168.1.3` for the machine the Solr nodes will be running on:\n+\n+[source,bash]\n+----\n+keytool -genkeypair -alias solr-ssl -keyalg RSA -keysize 2048 -keypass secret -storepass secret -validity 9999 -keystore solr-ssl.keystore.jks -ext SAN=DNS:localhost,IP:192.168.1.3,IP:127.0.0.1 -dname \"CN=localhost, OU=Organizational Unit, O=Organization, L=Location, ST=State, C=Country\"\n+----\n+\n+The above command will create a keystore file named `solr-ssl.keystore.jks` in the current directory.\n+\n+[[EnablingSSL-ConvertthecertificateandkeytoPEMformatforusewithcURL]]\n+=== Convert the Certificate and Key to PEM Format for Use with cURL\n+\n+cURL isn't capable of using JKS formatted keystores, so the JKS keystore needs to be converted to PEM format, which cURL understands.\n+\n+First convert the JKS keystore into PKCS12 format using `keytool`:\n+\n+[source,bash]\n+----\n+keytool -importkeystore -srckeystore solr-ssl.keystore.jks -destkeystore solr-ssl.keystore.p12 -srcstoretype jks -deststoretype pkcs12\n+----\n+\n+The keytool application will prompt you to create a destination keystore password and for the source keystore password, which was set when creating the keystore (\"secret\" in the example shown above).\n+\n+Next convert the PKCS12 format keystore, including both the certificate and the key, into PEM format using the http://www.openssl.org[`openssl`] command:\n+\n+[source,bash]\n+----\n+openssl pkcs12 -in solr-ssl.keystore.p12 -out solr-ssl.pem\n+----\n+\n+If you want to use cURL on OS X Yosemite (10.10), you'll need to create a certificate-only version of the PEM format, as follows:\n+\n+[source,bash]\n+----\n+openssl pkcs12 -nokeys -in solr-ssl.keystore.p12 -out solr-ssl.cacert.pem\n+----\n+\n+[[EnablingSSL-SetcommonSSLrelatedsystemproperties]]\n+=== Set common SSL related system properties\n+\n+The Solr Control Script is already setup to pass SSL-related Java system properties to the JVM. To activate the SSL settings, uncomment and update the set of properties beginning with SOLR_SSL_* in `bin/solr.in.sh`. (or `bin\\solr.in.cmd` on Windows).\n+\n+NOTE: If you setup Solr as a service on Linux using the steps outlined in <<taking-solr-to-production.adoc#taking-solr-to-production,Taking Solr to Production>>, then make these changes in `/var/solr/solr.in.sh` instead.\n+\n+.bin/solr.in.sh example SOLR_SSL_* configuration\n+[source,bash]\n+----\n+SOLR_SSL_KEY_STORE=etc/solr-ssl.keystore.jks\n+SOLR_SSL_KEY_STORE_PASSWORD=secret\n+SOLR_SSL_TRUST_STORE=etc/solr-ssl.keystore.jks\n+SOLR_SSL_TRUST_STORE_PASSWORD=secret\n+# Require clients to authenticate\n+SOLR_SSL_NEED_CLIENT_AUTH=false\n+# Enable clients to authenticate (but not require)\n+SOLR_SSL_WANT_CLIENT_AUTH=false\n+# Define Key Store type if necessary\n+SOLR_SSL_KEY_STORE_TYPE=JKS\n+SOLR_SSL_TRUST_STORE_TYPE=JKS\n+----\n+\n+When you start Solr, the `bin/solr` script includes the settings in `bin/solr.in.sh` and will pass these SSL-related system properties to the JVM.\n+\n+.Client Authentication Settings\n+WARNING: Enable either SOLR_SSL_NEED_CLIENT_AUTH or SOLR_SSL_WANT_CLIENT_AUTH but not both at the same time. They are mutually exclusive and Jetty will select one of them which may not be what you expect.\n+\n+Similarly, when you start Solr on Windows, the `bin\\solr.cmd` script includes the settings in `bin\\solr.in.cmd` - uncomment and update the set of properties beginning with `SOLR_SSL_*` to pass these SSL-related system properties to the JVM:\n+\n+.bin\\solr.in.cmd example SOLR_SSL_* configuration\n+[source,text]\n+----\n+set SOLR_SSL_KEY_STORE=etc/solr-ssl.keystore.jks\n+set SOLR_SSL_KEY_STORE_PASSWORD=secret\n+set SOLR_SSL_TRUST_STORE=etc/solr-ssl.keystore.jks\n+set SOLR_SSL_TRUST_STORE_PASSWORD=secret\n+REM Require clients to authenticate\n+set SOLR_SSL_NEED_CLIENT_AUTH=false\n+REM Enable clients to authenticate (but not require)\n+set SOLR_SSL_WANT_CLIENT_AUTH=false\n+----\n+\n+[[EnablingSSL-RunSingleNodeSolrusingSSL]]\n+=== Run Single Node Solr using SSL\n+\n+Start Solr using the command shown below; by default clients will not be required to authenticate:\n+\n+.*nix command\n+[source,bash]\n+----\n+bin/solr -p 8984\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+bin\\solr.cmd -p 8984\n+----\n+\n+[[EnablingSSL-SolrCloud]]\n+== SolrCloud\n+\n+This section describes how to run a two-node SolrCloud cluster with no initial collections and a single-node external ZooKeeper. The commands below assume you have already created the keystore described above.\n+\n+[[EnablingSSL-ConfigureZooKeeper]]\n+=== Configure ZooKeeper\n+\n+NOTE: ZooKeeper does not support encrypted communication with clients like Solr. There are several related JIRA tickets where SSL support is being planned/worked on: https://issues.apache.org/jira/browse/ZOOKEEPER-235[ZOOKEEPER-235]; https://issues.apache.org/jira/browse/ZOOKEEPER-236[ZOOKEEPER-236]; https://issues.apache.org/jira/browse/ZOOKEEPER-1000[ZOOKEEPER-1000]; and https://issues.apache.org/jira/browse/ZOOKEEPER-2120[ZOOKEEPER-2120].\n+\n+Before you start any SolrCloud nodes, you must configure your solr cluster properties in ZooKeeper, so that Solr nodes know to communicate via SSL.\n+\n+This section assumes you have created and started a single-node external ZooKeeper on port 2181 on localhost - see <<setting-up-an-external-zookeeper-ensemble.adoc#setting-up-an-external-zookeeper-ensemble,Setting Up an External ZooKeeper Ensemble>>.\n+\n+The `urlScheme` cluster-wide property needs to be set to `https` before any Solr node starts up. The example below uses the `zkcli` tool that comes with the binary Solr distribution to do this:\n+\n+.*nix command\n+[source,bash]\n+----\n+server/scripts/cloud-scripts/zkcli.sh -zkhost localhost:2181 -cmd clusterprop -name urlScheme -val https\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+server\\scripts\\cloud-scripts\\zkcli.bat -zkhost localhost:2181 -cmd clusterprop -name urlScheme -val https\n+----\n+\n+If you have set up your ZooKeeper cluster to use a <<taking-solr-to-production.adoc#TakingSolrtoProduction-ZooKeeperchroot,chroot\u00a0for Solr>> , make sure you use the correct `zkhost` string with `zkcli`, e.g. `-zkhost localhost:2181/solr`.\n+\n+[[EnablingSSL-RunSolrCloudwithSSL]]\n+=== Run SolrCloud with SSL\n+\n+[[EnablingSSL-CreateSolrhomedirectoriesfortwonodes]]\n+==== Create Solr home directories for two nodes\n+\n+Create two copies of the `server/solr/` directory which will serve as the Solr home directories for each of your two SolrCloud nodes:\n+\n+.*nix commands\n+[source,bash]\n+----\n+mkdir cloud\n+cp -r server/solr cloud/node1\n+cp -r server/solr cloud/node2\n+----\n+\n+.Windows commands\n+[source,text]\n+----\n+mkdir cloud\n+xcopy /E server\\solr cloud\\node1\\\n+xcopy /E server\\solr cloud\\node2\\\n+----\n+\n+[[EnablingSSL-StartthefirstSolrnode]]\n+==== Start the First Solr Node\n+\n+Next, start the first Solr node on port 8984. Be sure to stop the standalone server first if you started it when working through the previous section on this page.\n+\n+.*nix command\n+[source,bash]\n+----\n+bin/solr -cloud -s cloud/node1 -z localhost:2181 -p 8984\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+bin\\solr.cmd -cloud -s cloud\\node1 -z localhost:2181 -p 8984\n+----\n+\n+Notice the use of the `-s` option to set the location of the Solr home directory for node1.\n+\n+If you created your SSL key without all DNS names/IP addresses on which Solr nodes will run, you can tell Solr to skip hostname verification for inter-Solr-node communications by setting the `solr.ssl.checkPeerName` system property to `false`:\n+\n+.*nix command\n+[source,bash]\n+----\n+bin/solr -cloud -s cloud/node1 -z localhost:2181 -p 8984 -Dsolr.ssl.checkPeerName=false\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+bin\\solr.cmd -cloud -s cloud\\node1 -z localhost:2181 -p 8984 -Dsolr.ssl.checkPeerName=false\n+----\n+\n+[[EnablingSSL-StartthesecondSolrnode]]\n+==== Start the Second Solr Node\n+\n+Finally, start the second Solr node on port 7574 - again, to skip hostname verification, add `-Dsolr.ssl.checkPeerName=false`;\n+\n+.*nix command\n+[source,text]\n+----\n+bin/solr -cloud -s cloud/node2 -z localhost:2181 -p 7574\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+bin\\solr.cmd -cloud -s cloud\\node2 -z localhost:2181 -p 7574\n+----\n+\n+[[EnablingSSL-ExampleClientActions]]\n+== Example Client Actions\n+\n+[IMPORTANT]\n+====\n+cURL on OS X Mavericks (10.9) has degraded SSL support. For more information and workarounds to allow one-way SSL, see http://curl.haxx.se/mail/archive-2013-10/0036.html. cURL on OS X Yosemite (10.10) is improved - 2-way SSL is possible - see http://curl.haxx.se/mail/archive-2014-10/0053.html .\n+\n+The cURL commands in the following sections will not work with the system `curl` on OS X Yosemite (10.10). Instead, the certificate supplied with the `-E` param must be in PKCS12 format, and the file supplied with the `--cacert` param must contain only the CA certificate, and no key (see <<EnablingSSL-ConvertthecertificateandkeytoPEMformatforusewithcURL,above>> for instructions on creating this file):\n+\n+[source,bash]\n+curl -E solr-ssl.keystore.p12:secret --cacert solr-ssl.cacert.pem ...\n+\n+====\n+\n+NOTE: If your operating system does not include cURL, you can download binaries here: http://curl.haxx.se/download.html\n+\n+=== Create a SolrCloud Collection using `bin/solr`\n+\n+Create a 2-shard, replicationFactor=1 collection named mycollection using the default configset (data_driven_schema_configs):\n+\n+.*nix command\n+[source,bash]\n+----\n+bin/solr create -c mycollection -shards 2\n+----\n+\n+.Windows command\n+[source,text]\n+----\n+bin\\solr.cmd create -c mycollection -shards 2\n+----\n+\n+The `create` action will pass the `SOLR_SSL_*` properties set in your include file to the SolrJ code used to create the collection.\n+\n+[[EnablingSSL-RetrieveSolrCloudclusterstatususingcURL]]\n+=== Retrieve SolrCloud Cluster Status using cURL\n+\n+To get the resulting cluster status (again, if you have not enabled client authentication, remove the `-E solr-ssl.pem:secret` option):\n+\n+[source,bash]\n+----\n+curl -E solr-ssl.pem:secret --cacert solr-ssl.pem \"https://localhost:8984/solr/admin/collections?action=CLUSTERSTATUS&wt=json&indent=on\"\n+----\n+\n+You should get a response that looks like this:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":2041},\n+  \"cluster\":{\n+    \"collections\":{\n+      \"mycollection\":{\n+        \"shards\":{\n+          \"shard1\":{\n+            \"range\":\"80000000-ffffffff\",\n+            \"state\":\"active\",\n+            \"replicas\":{\"core_node1\":{\n+                \"state\":\"active\",\n+                \"base_url\":\"https://127.0.0.1:8984/solr\",\n+                \"core\":\"mycollection_shard1_replica1\",\n+                \"node_name\":\"127.0.0.1:8984_solr\",\n+                \"leader\":\"true\"}}},\n+          \"shard2\":{\n+            \"range\":\"0-7fffffff\",\n+            \"state\":\"active\",\n+            \"replicas\":{\"core_node2\":{\n+                \"state\":\"active\",\n+                \"base_url\":\"https://127.0.0.1:7574/solr\",\n+                \"core\":\"mycollection_shard2_replica1\",\n+                \"node_name\":\"127.0.0.1:7574_solr\",\n+                \"leader\":\"true\"}}}},\n+        \"maxShardsPerNode\":\"1\",\n+        \"router\":{\"name\":\"compositeId\"},\n+        \"replicationFactor\":\"1\"}},\n+    \"properties\":{\"urlScheme\":\"https\"}}}\n+----\n+\n+[[EnablingSSL-Indexdocumentsusingpost.jar]]\n+=== Index Documents using `post.jar`\n+\n+Use `post.jar` to index some example documents to the SolrCloud collection created above:\n+\n+[source,bash]\n+----\n+cd example/exampledocs\n+\n+java -Djavax.net.ssl.keyStorePassword=secret -Djavax.net.ssl.keyStore=../../server/etc/solr-ssl.keystore.jks -Djavax.net.ssl.trustStore=../../server/etc/solr-ssl.keystore.jks -Djavax.net.ssl.trustStorePassword=secret -Durl=https://localhost:8984/solr/mycollection/update -jar post.jar *.xml\n+----\n+\n+[[EnablingSSL-QueryusingcURL]]\n+=== Query Using cURL\n+\n+Use cURL to query the SolrCloud collection created above, from a directory containing the PEM formatted certificate and key created above (e.g. `example/etc/`) - if you have not enabled client authentication (system property `-Djetty.ssl.clientAuth=true)`, then you can remove the `-E solr-ssl.pem:secret` option:\n+\n+[source,bash]\n+----\n+curl -E solr-ssl.pem:secret --cacert solr-ssl.pem \"https://localhost:8984/solr/mycollection/select?q=*:*&wt=json&indent=on\"\n+----\n+\n+[[EnablingSSL-IndexadocumentusingCloudSolrClient]]\n+=== Index a document using `CloudSolrClient`\n+\n+From a java client using SolrJ, index a document. In the code below, the `javax.net.ssl.*` system properties are set programmatically, but you could instead specify them on the java command line, as in the `post.jar` example above:\n+\n+[source,java]\n+----\n+System.setProperty(\"javax.net.ssl.keyStore\", \"/path/to/solr-ssl.keystore.jks\");\n+System.setProperty(\"javax.net.ssl.keyStorePassword\", \"secret\");\n+System.setProperty(\"javax.net.ssl.trustStore\", \"/path/to/solr-ssl.keystore.jks\");\n+System.setProperty(\"javax.net.ssl.trustStorePassword\", \"secret\");\n+String zkHost = \"127.0.0.1:2181\";\n+CloudSolrClient client = new CloudSolrClient.Builder().withZkHost(zkHost).build();\n+client.setDefaultCollection(\"mycollection\");\n+SolrInputDocument doc = new SolrInputDocument();\n+doc.addField(\"id\", \"1234\");\n+doc.addField(\"name\", \"A lovely summer holiday\");\n+client.add(doc);\n+client.commit();\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/enabling-ssl.adoc",
                "sha": "122f104b55ae245e6d9feb2da2f0a760059b8a32",
                "status": "added"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/errata.adoc",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/errata.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/errata.adoc",
                "patch": "@@ -0,0 +1,17 @@\n+= Errata\n+:page-shortname: errata\n+:page-permalink: errata.html\n+\n+[[Errata-ErrataForThisDocumentation]]\n+== Errata For This Documentation\n+\n+Any mistakes found in this documentation after its release will be listed on the on-line version of this page:\n+\n+https://lucene.apache.org/solr/guide/{solr-docs-version}/errata.html\n+\n+[[Errata-ErrataForPastVersionsofThisDocumentation]]\n+== Errata For Past Versions of This Documentation\n+\n+Any known mistakes in past releases of this documentation will be noted below.\n+\n+**v2 API Blob store api path**: The 6.5 guide listed the Blob store api path as `/v2/blob`, but the correct path is `/v2/c/.system/blob`.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/errata.adoc",
                "sha": "4608992a23eaceb2134cbea9d3cf8c957107dd2c",
                "status": "added"
            },
            {
                "additions": 55,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/exporting-result-sets.adoc",
                "changes": 55,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/exporting-result-sets.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/exporting-result-sets.adoc",
                "patch": "@@ -0,0 +1,55 @@\n+= Exporting Result Sets\n+:page-shortname: exporting-result-sets\n+:page-permalink: exporting-result-sets.html\n+\n+\n+It's possible to export fully sorted result sets using a special <<query-re-ranking.adoc#query-re-ranking,rank query parser>> and <<response-writers.adoc#response-writers,response writer>> specifically designed to work together to handle scenarios that involve sorting and exporting millions of records.\n+\n+This feature uses a stream sorting technique that begins to send records within milliseconds and continues to stream results until the entire result set has been sorted and exported.\n+\n+The cases where this functionality may be useful include: session analysis, distributed merge joins, time series roll-ups, aggregations on high cardinality fields, fully distributed field collapsing, and sort based stats.\n+\n+[[ExportingResultSets-FieldRequirements]]\n+== Field Requirements\n+\n+All the fields being sorted and exported must have docValues set to true. For more information, see the section on <<docvalues.adoc#docvalues,DocValues>>.\n+\n+[[ExportingResultSets-The_exportRequestHandler]]\n+== The `/export` RequestHandler\n+\n+The `/export` request handler with the appropriate configuration is one of Solr's out-of-the-box request handlers - see <<implicit-requesthandlers.adoc#implicit-requesthandlers,Implicit RequestHandlers>> for more information.\n+\n+Note that this request handler's properties are defined as \"invariants\", which means they cannot be overridden by other properties passed at another time (such as at query time).\n+\n+[[ExportingResultSets-RequestingResultsExport]]\n+== Requesting Results Export\n+\n+You can use `/export` to make requests to export the result set of a query.\n+\n+All queries must include `sort` and `fl` parameters, or the query will return an error. Filter queries are also supported.\n+\n+The supported response writers are `json` and `javabin`. For backward compatibility reasons `wt=xsort` is also supported as input, but `wt=xsort` behaves same as `wt=json`. The default output format is `json`.\n+\n+Here is an example of an export request of some indexed log data:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/core_name/export?q=my-query&sort=severity+desc,timestamp+desc&fl=severity,timestamp,msg\n+----\n+\n+[[ExportingResultSets-SpecifyingtheSortCriteria]]\n+=== Specifying the Sort Criteria\n+\n+The `sort` property defines how documents will be sorted in the exported result set. Results can be sorted by any field that has a field type of int,long, float, double, string. The sort fields must be single valued fields.\n+\n+Up to four sort fields can be specified per request, with the 'asc' or 'desc' properties.\n+\n+[[ExportingResultSets-SpecifyingtheFieldList]]\n+=== Specifying the Field List\n+\n+The `fl` property defines the fields that will be exported with the result set. Any of the field types that can be sorted (i.e., int, long, float, double, string, date, boolean) can be used in the field list. The fields can be single or multi-valued. However, returning scores and wildcards are not supported at this time.\n+\n+[[ExportingResultSets-DistributedSupport]]\n+== Distributed Support\n+\n+See the section <<streaming-expressions.adoc#streaming-expressions,Streaming Expressions>> for distributed support.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/exporting-result-sets.adoc",
                "sha": "51639f53f9300adc58ca81891efb019a7c65e694",
                "status": "added"
            },
            {
                "additions": 738,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/faceting.adoc",
                "changes": 738,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/faceting.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/faceting.adoc",
                "patch": "@@ -0,0 +1,738 @@\n+= Faceting\n+:page-shortname: faceting\n+:page-permalink: faceting.html\n+:page-children: blockjoin-faceting\n+\n+Faceting is the arrangement of search results into categories based on indexed terms.\n+\n+Searchers are presented with the indexed terms, along with numerical counts of how many matching documents were found were each term. Faceting makes it easy for users to explore search results, narrowing in on exactly the results they are looking for.\n+\n+[[Faceting-GeneralParameters]]\n+== General Parameters\n+\n+There are two general parameters for controlling faceting.\n+\n+[[Faceting-ThefacetParameter]]\n+=== The `facet` Parameter\n+\n+If set to *true*, this parameter enables facet counts in the query response. If set to *false*, a blank or missing value, this parameter disables faceting. None of the other parameters listed below will have any effect unless this parameter is set to *true*. The default value is blank (false).\n+\n+[[Faceting-Thefacet.queryParameter]]\n+=== The `facet.query` Parameter\n+\n+This parameter allows you to specify an arbitrary query in the Lucene default syntax to generate a facet count.\n+\n+By default, Solr's faceting feature automatically determines the unique terms for a field and returns a count for each of those terms. Using `facet.query`, you can override this default behavior and select exactly which terms or expressions you would like to see counted. In a typical implementation of faceting, you will specify a number of `facet.query` parameters. This parameter can be particularly useful for numeric-range-based facets or prefix-based facets.\n+\n+You can set the `facet.query` parameter multiple times to indicate that multiple queries should be used as separate facet constraints.\n+\n+To use facet queries in a syntax other than the default syntax, prefix the facet query with the name of the query notation. For example, to use the hypothetical `myfunc` query parser, you could set the `facet.query` parameter like so:\n+\n+`facet.query={!myfunc}name~fred`\n+\n+[[Faceting-Field-ValueFacetingParameters]]\n+== Field-Value Faceting Parameters\n+\n+Several parameters can be used to trigger faceting based on the indexed terms in a field.\n+\n+When using these parameters, it is important to remember that \"term\" is a very specific concept in Lucene: it relates to the literal field/value pairs that are indexed after any analysis occurs. For text fields that include stemming, lowercasing, or word splitting, the resulting terms may not be what you expect.\n+\n+If you want Solr to perform both analysis (for searching) and faceting on the full literal strings, use the `copyField` directive in your Schema to create two versions of the field: one Text and one String. Make sure both are `indexed=\"true\"`. (For more information about the `copyField` directive, see <<documents-fields-and-schema-design.adoc#documents-fields-and-schema-design,Documents, Fields, and Schema Design>>.)\n+\n+The table below summarizes Solr's field value faceting parameters.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Parameter |Description\n+|<<Faceting-Thefacet.fieldParameter,facet.field>> |Identifies a field to be treated as a facet.\n+|<<Faceting-Thefacet.prefixParameter,facet.prefix>> |Limits the terms used for faceting to those that begin with the specified prefix.\n+|<<Faceting-Thefacet.containsParameter,facet.contains>> |Limits the terms used for faceting to those that contain the specified substring.\n+|<<Faceting-Thefacet.contains.ignoreCaseParameter,facet.contains.ignoreCase>> |If facet.contains is used, ignore case when searching for the specified substring.\n+|<<Faceting-Thefacet.sortParameter,facet.sort>> |Controls how faceted results are sorted.\n+|<<Faceting-Thefacet.limitParameter,facet.limit>> |Controls how many constraints should be returned for each facet.\n+|<<Faceting-Thefacet.offsetParameter,facet.offset>> |Specifies an offset into the facet results at which to begin displaying facets.\n+|<<Faceting-Thefacet.mincountParameter,facet.mincount>> |Specifies the minimum counts required for a facet field to be included in the response.\n+|<<Faceting-Thefacet.missingParameter,facet.missing>> |Controls whether Solr should compute a count of all matching results which have no value for the field, in addition to the term-based constraints of a facet field.\n+|<<Faceting-Thefacet.methodParameter,facet.method>> |Selects the algorithm or method Solr should use when faceting a field.\n+|<<Faceting-Thefacet.existsParameter,facet.exists>> |Caps facet counts by one. Available only for `facet.method=enum` as performance optimization.\n+|<<Faceting-Thefacet.excludeTermsParameter,facet.excludeTerms>> |Removes specific terms from facet counts. This allows you to exclude certain terms from faceting, while maintaining the terms in the index for general queries.\n+|<<Faceting-Thefacet.enum.cache.minDfParameter,facet.enum.cache.minDf>> |(Advanced) Specifies the minimum document frequency (the number of documents matching a term) for which the `filterCache` should be used when determining the constraint count for that term.\n+|<<Faceting-Over-RequestParameters,facet.overrequest.count>> |(Advanced) A number of documents, beyond the effective `facet.limit` to request from each shard in a distributed search\n+|<<Faceting-Over-RequestParameters,facet.overrequest.ratio>> |(Advanced) A multiplier of the effective `facet.limit` to request from each shard in a distributed search\n+|<<Faceting-Thefacet.threadsParameter,facet.threads>> |(Advanced) Controls parallel execution of field faceting\n+|===\n+\n+These parameters are described in the sections below.\n+\n+[[Faceting-Thefacet.fieldParameter]]\n+=== The `facet.field` Parameter\n+\n+The `facet.field` parameter identifies a field that should be treated as a facet. It iterates over each Term in the field and generate a facet count using that Term as the constraint. This parameter can be specified multiple times in a query to select multiple facet fields.\n+\n+[IMPORTANT]\n+====\n+If you do not set this parameter to at least one field in the schema, none of the other parameters described in this section will have any effect.\n+====\n+\n+[[Faceting-Thefacet.prefixParameter]]\n+=== The `facet.prefix` Parameter\n+\n+The `facet.prefix` parameter limits the terms on which to facet to those starting with the given string prefix. This does not limit the query in any way, only the facets that would be returned in response to the query.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.prefix`.\n+\n+[[Faceting-Thefacet.containsParameter]]\n+=== The `facet.contains` Parameter\n+\n+The `facet.contains` parameter limits the terms on which to facet to those containing the given substring. This does not limit the query in any way, only the facets that would be returned in response to the query.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.contains`.\n+\n+[[Faceting-Thefacet.contains.ignoreCaseParameter]]\n+=== The `facet.contains.ignoreCase` Parameter\n+\n+If `facet.contains` is used, the `facet.contains.ignoreCase` parameter causes case to be ignored when matching the given substring against candidate facet terms.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.contains.ignoreCase`.\n+\n+[[Faceting-Thefacet.sortParameter]]\n+=== The `facet.sort` Parameter\n+\n+This parameter determines the ordering of the facet field constraints.\n+\n+There are two options for this parameter.\n+\n+count:: Sort the constraints by count (highest count first).\n+index:: Return the constraints sorted in their index order (lexicographic by indexed term). For terms in the ASCII range, this will be alphabetically sorted.\n+\n+The default is `count` if `facet.limit` is greater than 0, otherwise, the default is `index`.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.sort`.\n+\n+[[Faceting-Thefacet.limitParameter]]\n+=== The `facet.limit` Parameter\n+\n+This parameter specifies the maximum number of constraint counts (essentially, the number of facets for a field that are returned) that should be returned for the facet fields. A negative value means that Solr will return unlimited number of constraint counts.\n+\n+The default value is 100.\n+\n+This parameter can be specified on a per-field basis to apply a distinct limit to each field with the syntax of `f.<fieldname>.facet.limit`.\n+\n+[[Faceting-Thefacet.offsetParameter]]\n+=== The `facet.offset` Parameter\n+\n+The `facet.offset` parameter indicates an offset into the list of constraints to allow paging.\n+\n+The default value is 0.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.offset`.\n+\n+[[Faceting-Thefacet.mincountParameter]]\n+=== The `facet.mincount` Parameter\n+\n+The `facet.mincount` parameter specifies the minimum counts required for a facet field to be included in the response. If a field's counts are below the minimum, the field's facet is not returned.\n+\n+The default value is 0.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.mincount`.\n+\n+[[Faceting-Thefacet.missingParameter]]\n+=== The `facet.missing` Parameter\n+\n+If set to true, this parameter indicates that, in addition to the Term-based constraints of a facet field, a count of all results that match the query but which have no facet value for the field should be computed and returned in the response.\n+\n+The default value is false.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.missing`.\n+\n+[[Faceting-Thefacet.methodParameter]]\n+=== The `facet.method` Parameter\n+\n+The facet.method parameter selects the type of algorithm or method Solr should use when faceting a field.\n+\n+The following methods are available.\n+\n+enum:: Enumerates all terms in a field, calculating the set intersection of documents that match the term with documents that match the query.\n++\n+This method is recommended for faceting multi-valued fields that have only a few distinct values. The average number of values per document does not matter.\n++\n+For example, faceting on a field with U.S. States such as `Alabama, Alaska, ... Wyoming` would lead to fifty cached filters which would be used over and over again. The `filterCache` should be large enough to hold all the cached filters.\n+\n+fc:: Calculates facet counts by iterating over documents that match the query and summing the terms that appear in each document.\n++\n+This is currently implemented using an `UnInvertedField` cache if the field either is multi-valued or is tokenized (according to `FieldType.isTokened()`). Each document is looked up in the cache to see what terms/values it contains, and a tally is incremented for each value.\n++\n+This method is excellent for situations where the number of indexed values for the field is high, but the number of values per document is low. For multi-valued fields, a hybrid approach is used that uses term filters from the `filterCache` for terms that match many documents. The letters `fc` stand for field cache.\n+\n+fcs:: Per-segment field faceting for single-valued string fields. Enable with `facet.method=fcs` and control the number of threads used with the `threads` local parameter. This parameter allows faceting to be faster in the presence of rapid index changes.\n+\n+The default value is `fc` (except for fields using the `BoolField` field type and when `facet.exists=true` is requested) since it tends to use less memory and is faster when a field has many unique terms in the index.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.method`.\n+\n+[[Faceting-Thefacet.enum.cache.minDfParameter]]\n+=== The `facet.enum.cache.minDf` Parameter\n+\n+This parameter indicates the minimum document frequency (the number of documents matching a term) for which the filterCache should be used when determining the constraint count for that term. This is only used with the `facet.method=enum` method of faceting.\n+\n+A value greater than zero decreases the filterCache's memory usage, but increases the time required for the query to be processed. If you are faceting on a field with a very large number of terms, and you wish to decrease memory usage, try setting this parameter to a value between 25 and 50, and run a few tests. Then, optimize the parameter setting as necessary.\n+\n+The default value is 0, causing the filterCache to be used for all terms in the field.\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.enum.cache.minDf`.\n+\n+[[Faceting-Thefacet.existsParameter]]\n+=== The `facet.exists` Parameter\n+\n+To cap facet counts by 1, specify `facet.exists=true`. It can be used with `facet.method=enum` or when it's omitted. It can be used only on non-trie fields (such as strings). It may speed up facet counting on large indices and/or high-cardinality facet values..\n+\n+This parameter can be specified on a per-field basis with the syntax of `f.<fieldname>.facet.exists` or via local parameter` facet.field={!facet.method=enum facet.exists=true}size`.\n+\n+[[Faceting-Thefacet.excludeTermsParameter]]\n+=== The `facet.excludeTerms` Parameter\n+\n+If you want to remove terms from facet counts but keep them in the index, the `facet.excludeTerms` parameter allows you to do that.\n+\n+[[Faceting-Over-RequestParameters]]\n+=== Over-Request Parameters\n+\n+In some situations, the accuracy in selecting the \"top\" constraints returned for a facet in a distributed Solr query can be improved by \"Over Requesting\" the number of desired constraints (ie: `facet.limit`) from each of the individual Shards. In these situations, each shard is by default asked for the top \"`10 + (1.5 * facet.limit)`\" constraints.\n+\n+In some situations, depending on how your docs are partitioned across your shards, and what `facet.limit` value you used, you may find it advantageous to increase or decrease the amount of over-requesting Solr does. This can be achieved by setting the `facet.overrequest.count` (defaults to 10) and `facet.overrequest.ratio` (defaults to 1.5) parameters.\n+\n+[[Faceting-Thefacet.threadsParameter]]\n+=== The `facet.threads` Parameter\n+\n+This param will cause loading the underlying fields used in faceting to be executed in parallel with the number of threads specified. Specify as `facet.threads=N` where `N` is the maximum number of threads used. Omitting this parameter or specifying the thread count as 0 will not spawn any threads, and only the main request thread will be used. Specifying a negative number of threads will create up to Integer.MAX_VALUE threads.\n+\n+[[Faceting-RangeFaceting]]\n+== Range Faceting\n+\n+You can use Range Faceting on any date field or any numeric field that supports range queries. This is particularly useful for stitching together a series of range queries (as facet by query) for things like prices.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Parameter |Description\n+|<<Faceting-Thefacet.rangeParameter,facet.range>> |Specifies the field to facet by range.\n+|<<Faceting-Thefacet.range.startParameter,facet.range.start>> |Specifies the start of the facet range.\n+|<<Faceting-Thefacet.range.endParameter,facet.range.end>> |Specifies the end of the facet range.\n+|<<Faceting-Thefacet.range.gapParameter,facet.range.gap>> |Specifies the span of the range as a value to be added to the lower bound.\n+|<<Faceting-Thefacet.range.hardendParameter,facet.range.hardend>> |A boolean parameter that specifies how Solr handles a range gap that cannot be evenly divided between the range start and end values. If true, the last range constraint will have the `facet.range.end` value an upper bound. If false, the last range will have the smallest possible upper bound greater then `facet.range.end` such that the range is the exact width of the specified range gap. The default value for this parameter is false.\n+|<<Faceting-Thefacet.range.includeParameter,facet.range.include>> |Specifies inclusion and exclusion preferences for the upper and lower bounds of the range. See the `facet.range.include` topic for more detailed information.\n+|<<Faceting-Thefacet.range.otherParameter,facet.range.other>> |Specifies counts for Solr to compute in addition to the counts for each facet range constraint.\n+|<<Faceting-Thefacet.range.methodParameter,facet.range.method>> |Specifies the algorithm or method to use for calculating facets.\n+|===\n+\n+[[Faceting-Thefacet.rangeParameter]]\n+=== The `facet.range` Parameter\n+\n+The `facet.range` parameter defines the field for which Solr should create range facets. For example:\n+\n+`facet.range=price&facet.range=age`\n+\n+`facet.range=lastModified_dt`\n+\n+[[Faceting-Thefacet.range.startParameter]]\n+=== The `facet.range.start` Parameter\n+\n+The `facet.range.start` parameter specifies the lower bound of the ranges. You can specify this parameter on a per field basis with the syntax of `f.<fieldname>.facet.range.start`. For example:\n+\n+`f.price.facet.range.start=0.0&f.age.facet.range.start=10`\n+\n+`f.lastModified_dt.facet.range.start=NOW/DAY-30DAYS`\n+\n+[[Faceting-Thefacet.range.endParameter]]\n+=== The `facet.range.end` Parameter\n+\n+The facet.range.end specifies the upper bound of the ranges. You can specify this parameter on a per field basis with the syntax of `f.<fieldname>.facet.range.end`. For example:\n+\n+`f.price.facet.range.end=1000.0&f.age.facet.range.start=99`\n+\n+`f.lastModified_dt.facet.range.end=NOW/DAY+30DAYS`\n+\n+[[Faceting-Thefacet.range.gapParameter]]\n+=== The `facet.range.gap` Parameter\n+\n+The span of each range expressed as a value to be added to the lower bound. For date fields, this should be expressed using the {solr-javadocs}/solr-core/org/apache/solr/util/DateMathParser.html[`DateMathParser` syntax] (such as, `facet.range.gap=%2B1DAY ... '+1DAY'`). You can specify this parameter on a per-field basis with the syntax of `f.<fieldname>.facet.range.gap`. For example:\n+\n+`f.price.facet.range.gap=100&f.age.facet.range.gap=10`\n+\n+`f.lastModified_dt.facet.range.gap=+1DAY`\n+\n+[[Faceting-Thefacet.range.hardendParameter]]\n+=== The `facet.range.hardend` Parameter\n+\n+The `facet.range.hardend` parameter is a Boolean parameter that specifies how Solr should handle cases where the `facet.range.gap` does not divide evenly between `facet.range.start` and `facet.range.end`.\n+\n+If *true*, the last range constraint will have the `facet.range.end` value as an upper bound. If *false*, the last range will have the smallest possible upper bound greater then `facet.range.end` such that the range is the exact width of the specified range gap. The default value for this parameter is false.\n+\n+This parameter can be specified on a per field basis with the syntax `f.<fieldname>.facet.range.hardend`.\n+\n+[[Faceting-Thefacet.range.includeParameter]]\n+=== The `facet.range.include` Parameter\n+\n+By default, the ranges used to compute range faceting between `facet.range.start` and `facet.range.end` are inclusive of their lower bounds and exclusive of the upper bounds. The \"before\" range defined with the `facet.range.other` parameter is exclusive and the \"after\" range is inclusive. This default, equivalent to \"lower\" below, will not result in double counting at the boundaries. You can use the `facet.range.include` parameter to modify this behavior using the following options:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Option |Description\n+|lower |All gap-based ranges include their lower bound.\n+|upper |All gap-based ranges include their upper bound.\n+|edge |The first and last gap ranges include their edge bounds (lower for the first one, upper for the last one) even if the corresponding upper/lower option is not specified.\n+|outer |The \"before\" and \"after\" ranges will be inclusive of their bounds, even if the first or last ranges already include those boundaries.\n+|all |Includes all options: lower, upper, edge, outer.\n+|===\n+\n+You can specify this parameter on a per field basis with the syntax of `f.<fieldname>.facet.range.include`, and you can specify it multiple times to indicate multiple choices.\n+\n+[NOTE]\n+====\n+To ensure you avoid double-counting, do not choose both `lower` and `upper`, do not choose `outer`, and do not choose `all`.\n+====\n+\n+[[Faceting-Thefacet.range.otherParameter]]\n+=== The `facet.range.other` Parameter\n+\n+The `facet.range.other` parameter specifies that in addition to the counts for each range constraint between `facet.range.start` and `facet.range.end`, counts should also be computed for these options:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Option |Description\n+|before |All records with field values lower then lower bound of the first range.\n+|after |All records with field values greater then the upper bound of the last range.\n+|between |All records with field values between the start and end bounds of all ranges.\n+|none |Do not compute any counts.\n+|all |Compute counts for before, between, and after.\n+|===\n+\n+This parameter can be specified on a per field basis with the syntax of `f.<fieldname>.facet.range.other`. In addition to the `all` option, this parameter can be specified multiple times to indicate multiple choices, but `none` will override all other options.\n+\n+[[Faceting-Thefacet.range.methodParameter]]\n+=== The `facet.range.method` Parameter\n+\n+The `facet.range.method` parameter selects the type of algorithm or method Solr should use for range faceting. Both methods produce the same results, but performance may vary.\n+\n+filter:: This method generates the ranges based on other facet.range parameters, and for each of them executes a filter that later intersects with the main query resultset to get the count. It will make use of the filterCache, so it will benefit of a cache large enough to contain all ranges.\n+\n+dv:: This method iterates the documents that match the main query, and for each of them finds the correct range for the value. This method will make use of <<docvalues.adoc#docvalues,docValues>> (if enabled for the field) or fieldCache. The `dv` method is not supported for field type DateRangeField or when using <<result-grouping.adoc#result-grouping,group.facets>>.\n+\n+Default value for this parameter is \"filter\".\n+\n+[[Faceting-Thefacet.mincountParameterinRangeFaceting]]\n+=== The `facet.mincount` Parameter in Range Faceting\n+\n+The `facet.mincount` parameter, the same one as used in field faceting is also applied to range faceting. When used, no ranges with a count below the minimum will be included in the response.\n+\n+.Date Ranges & Time Zones\n+[NOTE]\n+====\n+\n+Range faceting on date fields is a common situation where the <<working-with-dates.adoc#WorkingwithDates-TZ,`TZ`>> parameter can be useful to ensure that the \"facet counts per day\" or \"facet counts per month\" are based on a meaningful definition of when a given day/month \"starts\" relative to a particular TimeZone.\n+\n+For more information, see the examples in the <<working-with-dates.adoc#working-with-dates,Working with Dates>> section.\n+\n+====\n+\n+\n+[[Faceting-Pivot_DecisionTree_Faceting]]\n+== Pivot (Decision Tree) Faceting\n+\n+Pivoting is a summarization tool that lets you automatically sort, count, total or average data stored in a table. The results are typically displayed in a second table showing the summarized data. Pivot faceting lets you create a summary table of the results from a faceting documents by multiple fields.\n+\n+Another way to look at it is that the query produces a Decision Tree, in that Solr tells you \"for facet A, the constraints/counts are X/N, Y/M, etc. If you were to constrain A by X, then the constraint counts for B would be S/P, T/Q, etc.\". In other words, it tells you in advance what the \"next\" set of facet results would be for a field if you apply a constraint from the current facet results.\n+\n+[[Faceting-facet.pivot]]\n+=== facet.pivot\n+\n+The `facet.pivot` parameter defines the fields to use for the pivot. Multiple `facet.pivot` values will create multiple \"facet_pivot\" sections in the response. Separate each list of fields with a comma.\n+\n+[[Faceting-facet.pivot.mincount]]\n+=== facet.pivot.mincount\n+\n+The `facet.pivot.mincount` parameter defines the minimum number of documents that need to match in order for the facet to be included in results. The default is 1.\n+\n+Using the \"`bin/solr -e techproducts`\" example, A query URL like this one will return the data below, with the pivot faceting results found in the section \"facet_pivot\":\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/techproducts/select?q=*:*&facet.pivot=cat,popularity,inStock\n+   &facet.pivot=popularity,cat&facet=true&facet.field=cat&facet.limit=5\n+   &rows=0&wt=json&indent=true&facet.pivot.mincount=2\n+----\n+\n+[source,json]\n+----\n+{  \"facet_counts\":{\n+    \"facet_queries\":{},\n+    \"facet_fields\":{\n+      \"cat\":[\n+        \"electronics\",14,\n+        \"currency\",4,\n+        \"memory\",3,\n+        \"connector\",2,\n+        \"graphics card\",2]},\n+    \"facet_dates\":{},\n+    \"facet_ranges\":{},\n+    \"facet_pivot\":{\n+      \"cat,popularity,inStock\":[{\n+          \"field\":\"cat\",\n+          \"value\":\"electronics\",\n+          \"count\":14,\n+          \"pivot\":[{\n+              \"field\":\"popularity\",\n+              \"value\":6,\n+              \"count\":5,\n+              \"pivot\":[{\n+                  \"field\":\"inStock\",\n+                  \"value\":true,\n+                  \"count\":5}]}]\n+}]}}}\n+----\n+\n+[[Faceting-CombiningStatsComponentWithPivots]]\n+=== Combining Stats Component With Pivots\n+\n+In addition to some of the <<Faceting-LocalParametersforFaceting,general local parameters>> supported by other types of faceting, a `stats` local parameters can be used with `facet.pivot` to refer to <<the-stats-component.adoc#the-stats-component,`stats.field`>> instances (by tag) that you would like to have computed for each Pivot Constraint.\n+\n+In the example below, two different (overlapping) sets of statistics are computed for each of the facet.pivot result hierarchies:\n+\n+[source,text]\n+----\n+stats=true\n+stats.field={!tag=piv1,piv2 min=true max=true}price\n+stats.field={!tag=piv2 mean=true}popularity\n+facet=true\n+facet.pivot={!stats=piv1}cat,inStock\n+facet.pivot={!stats=piv2}manu,inStock\n+----\n+\n+Results:\n+\n+[source,json]\n+----\n+{\"facet_pivot\":{\n+  \"cat,inStock\":[{\n+      \"field\":\"cat\",\n+      \"value\":\"electronics\",\n+      \"count\":12,\n+      \"pivot\":[{\n+          \"field\":\"inStock\",\n+          \"value\":true,\n+          \"count\":8,\n+          \"stats\":{\n+            \"stats_fields\":{\n+              \"price\":{\n+                \"min\":74.98999786376953,\n+                \"max\":399.0}}}},\n+        {\n+          \"field\":\"inStock\",\n+          \"value\":false,\n+          \"count\":4,\n+          \"stats\":{\n+            \"stats_fields\":{\n+              \"price\":{\n+                \"min\":11.5,\n+                \"max\":649.989990234375}}}}],\n+      \"stats\":{\n+        \"stats_fields\":{\n+          \"price\":{\n+            \"min\":11.5,\n+            \"max\":649.989990234375}}}},\n+    {\n+      \"field\":\"cat\",\n+      \"value\":\"currency\",\n+      \"count\":4,\n+      \"pivot\":[{\n+          \"field\":\"inStock\",\n+          \"value\":true,\n+          \"count\":4,\n+          \"stats\":{\n+            \"stats_fields\":{\n+              \"price\":{\n+                \"...\"\n+  \"manu,inStock\":[{\n+      \"field\":\"manu\",\n+      \"value\":\"inc\",\n+      \"count\":8,\n+      \"pivot\":[{\n+          \"field\":\"inStock\",\n+          \"value\":true,\n+          \"count\":7,\n+          \"stats\":{\n+            \"stats_fields\":{\n+              \"price\":{\n+                \"min\":74.98999786376953,\n+                \"max\":2199.0},\n+              \"popularity\":{\n+                \"mean\":5.857142857142857}}}},\n+        {\n+          \"field\":\"inStock\",\n+          \"value\":false,\n+          \"count\":1,\n+          \"stats\":{\n+            \"stats_fields\":{\n+              \"price\":{\n+                \"min\":479.95001220703125,\n+                \"max\":479.95001220703125},\n+              \"popularity\":{\n+                \"mean\":7.0}}}}],\n+      \"...\"}]}}}}]}]}}\n+----\n+\n+[[Faceting-CombiningFacetQueriesAndFacetRangesWithPivotFacets]]\n+=== Combining Facet Queries And Facet Ranges With Pivot Facets\n+\n+A `query` local parameter can be used with `facet.pivot` to refer to `facet.query` instances (by tag) that should be computed for each pivot constraint. Similarly, a `range` local parameter can be used with `facet.pivot` to refer to `facet.range` instances.\n+\n+In the example below, two query facets are computed for h of the `facet.pivot` result hierarchies:\n+\n+[source,text]\n+----\n+facet=true\n+facet.query={!tag=q1}manufacturedate_dt:[2006-01-01T00:00:00Z TO NOW]\n+facet.query={!tag=q1}price:[0 TO 100]\n+facet.pivot={!query=q1}cat,inStock\n+----\n+\n+[source,json]\n+----\n+{\"facet_counts\": {\n+    \"facet_queries\": {\n+      \"{!tag=q1}manufacturedate_dt:[2006-01-01T00:00:00Z TO NOW]\": 9,\n+      \"{!tag=q1}price:[0 TO 100]\": 7\n+    },\n+    \"facet_fields\": {},\n+    \"facet_dates\": {},\n+    \"facet_ranges\": {},\n+    \"facet_intervals\": {},\n+    \"facet_heatmaps\": {},\n+    \"facet_pivot\": {\n+      \"cat,inStock\": [\n+        {\n+          \"field\": \"cat\",\n+          \"value\": \"electronics\",\n+          \"count\": 12,\n+          \"queries\": {\n+            \"{!tag=q1}manufacturedate_dt:[2006-01-01T00:00:00Z TO NOW]\": 9,\n+            \"{!tag=q1}price:[0 TO 100]\": 4\n+          },\n+          \"pivot\": [\n+            {\n+              \"field\": \"inStock\",\n+              \"value\": true,\n+              \"count\": 8,\n+              \"queries\": {\n+                \"{!tag=q1}manufacturedate_dt:[2006-01-01T00:00:00Z TO NOW]\": 6,\n+                \"{!tag=q1}price:[0 TO 100]\": 2\n+              }\n+            },\n+            \"...\"]}]}}}\n+----\n+\n+In a similar way, in the example below, two range facets are computed for each of the `facet.pivot` result hierarchies:\n+\n+[source,text]\n+----\n+facet=true\n+facet.range={!tag=r1}manufacturedate_dt\n+facet.range.start=2006-01-01T00:00:00Z\n+facet.range.end=NOW/YEAR\n+facet.range.gap=+1YEAR\n+facet.pivot={!range=r1}cat,inStock\n+----\n+\n+[source,json]\n+----\n+{\"facet_counts\":{\n+    \"facet_queries\":{},\n+    \"facet_fields\":{},\n+    \"facet_dates\":{},\n+    \"facet_ranges\":{\n+      \"manufacturedate_dt\":{\n+        \"counts\":[\n+          \"2006-01-01T00:00:00Z\",9,\n+          \"2007-01-01T00:00:00Z\",0,\n+          \"2008-01-01T00:00:00Z\",0,\n+          \"2009-01-01T00:00:00Z\",0,\n+          \"2010-01-01T00:00:00Z\",0,\n+          \"2011-01-01T00:00:00Z\",0,\n+          \"2012-01-01T00:00:00Z\",0,\n+          \"2013-01-01T00:00:00Z\",0,\n+          \"2014-01-01T00:00:00Z\",0],\n+        \"gap\":\"+1YEAR\",\n+        \"start\":\"2006-01-01T00:00:00Z\",\n+        \"end\":\"2015-01-01T00:00:00Z\"}},\n+    \"facet_intervals\":{},\n+    \"facet_heatmaps\":{},\n+    \"facet_pivot\":{\n+      \"cat,inStock\":[{\n+          \"field\":\"cat\",\n+          \"value\":\"electronics\",\n+          \"count\":12,\n+          \"ranges\":{\n+            \"manufacturedate_dt\":{\n+              \"counts\":[\n+                \"2006-01-01T00:00:00Z\",9,\n+                \"2007-01-01T00:00:00Z\",0,\n+                \"2008-01-01T00:00:00Z\",0,\n+                \"2009-01-01T00:00:00Z\",0,\n+                \"2010-01-01T00:00:00Z\",0,\n+                \"2011-01-01T00:00:00Z\",0,\n+                \"2012-01-01T00:00:00Z\",0,\n+                \"2013-01-01T00:00:00Z\",0,\n+                \"2014-01-01T00:00:00Z\",0],\n+              \"gap\":\"+1YEAR\",\n+              \"start\":\"2006-01-01T00:00:00Z\",\n+              \"end\":\"2015-01-01T00:00:00Z\"}},\n+          \"pivot\":[{\n+              \"field\":\"inStock\",\n+              \"value\":true,\n+              \"count\":8,\n+              \"ranges\":{\n+                \"manufacturedate_dt\":{\n+                  \"counts\":[\n+                    \"2006-01-01T00:00:00Z\",6,\n+                    \"2007-01-01T00:00:00Z\",0,\n+                    \"2008-01-01T00:00:00Z\",0,\n+                    \"2009-01-01T00:00:00Z\",0,\n+                    \"2010-01-01T00:00:00Z\",0,\n+                    \"2011-01-01T00:00:00Z\",0,\n+                    \"2012-01-01T00:00:00Z\",0,\n+                    \"2013-01-01T00:00:00Z\",0,\n+                    \"2014-01-01T00:00:00Z\",0],\n+                  \"gap\":\"+1YEAR\",\n+                  \"start\":\"2006-01-01T00:00:00Z\",\n+                  \"end\":\"2015-01-01T00:00:00Z\"}}},\n+                  \"...\"]}]}}}\n+----\n+\n+[[Faceting-AdditionalPivotParameters]]\n+=== Additional Pivot Parameters\n+\n+Although `facet.pivot.mincount` deviates in name from the `facet.mincount` parameter used by field faceting, many other Field faceting parameters described above can also be used with pivot faceting:\n+\n+* `facet.limit`\n+* `facet.offset`\n+* `facet.sort`\n+* `facet.overrequest.count`\n+* `facet.overrequest.ratio`\n+\n+[[Faceting-IntervalFaceting]]\n+== Interval Faceting\n+\n+Another supported form of faceting is interval faceting. This sounds similar to range faceting, but the functionality is really closer to doing facet queries with range queries. Interval faceting allows you to set variable intervals and count the number of documents that have values within those intervals in the specified field.\n+\n+Even though the same functionality can be achieved by using a facet query with range queries, the implementation of these two methods is very different and will provide different performance depending on the context.\n+\n+If you are concerned about the performance of your searches you should test with both options. Interval faceting tends to be better with multiple intervals for the same fields, while facet query tend to be better in environments where filter cache is more effective (static indexes for example).\n+\n+This method will use <<docvalues.adoc#docvalues,docValues>> if they are enabled for the field, will use fieldCache otherwise.\n+\n+[[Faceting-Thefacet.intervalparameter]]\n+=== The `facet.interval` parameter\n+\n+This parameter Indicates the field where interval faceting must be applied. It can be used multiple times in the same request to indicate multiple fields.\n+\n+`facet.interval=price&facet.interval=size`\n+\n+[[Faceting-Thefacet.interval.setparameter]]\n+=== The `facet.interval.set` parameter\n+\n+This parameter is used to set the intervals for the field, it can be specified multiple times to indicate multiple intervals. This parameter is global, which means that it will be used for all fields indicated with `facet.interval` unless there is an override for a specific field. To override this parameter on a specific field you can use: `f.<fieldname>.facet.interval.set`, for example:\n+\n+[source,text]\n+f.price.facet.interval.set=[0,10]&f.price.facet.interval.set=(10,100]\n+\n+\n+[[Faceting-IntervalSyntax]]\n+=== Interval Syntax\n+\n+Intervals must begin with either '(' or '[', be followed by the start value, then a comma (','), the end value, and finally a closing ')' or ']\u2019.\n+\n+For example:\n+\n+* (1,10) -> will include values greater than 1 and lower than 10\n+* [1,10) -> will include values greater or equal to 1 and lower than 10\n+* [1,10] -> will include values greater or equal to 1 and lower or equal to 10\n+\n+The initial and end values cannot be empty. If the interval needs to be unbounded, the special character `*` can be used for both, start and end limit.\n+\n+When using `\\*`, `(` and `[`, and `)` and `]` will be treated equal. `[*,*]` will include all documents with a value in the field.\n+\n+The interval limits may be strings but there is no need to add quotes. All the text until the comma will be treated as the start limit, and the text after that will be the end limit. For example: `[Buenos Aires,New York]`. Keep in mind that a string-like comparison will be done to match documents in string intervals (case-sensitive). The comparator can't be changed.\n+\n+Commas, brackets and square brackets can be escaped by using `\\` in front of them. Whitespaces before and after the values will be omitted.\n+\n+The start limit can't be grater than the end limit. Equal limits are allowed, this allows you to indicate the specific values that you want to count, like `[A,A]`, `[B,B]` and `[C,Z]`.\n+\n+Interval faceting supports output key replacement described below. Output keys can be replaced in both the `facet.interval parameter` and in the `facet.interval.set parameter`. For example:\n+\n+[source,text]\n+----\n+&facet.interval={!key=popularity}some_field\n+&facet.interval.set={!key=bad}[0,5]\n+&facet.interval.set={!key=good}[5,*]\n+&facet=true\n+----\n+\n+[[Faceting-LocalParametersforFaceting]]\n+== Local Parameters for Faceting\n+\n+The <<local-parameters-in-queries.adoc#local-parameters-in-queries,LocalParams syntax>> allows overriding global settings. It can also provide a method of adding metadata to other parameter values, much like XML attributes.\n+\n+[[Faceting-TaggingandExcludingFilters]]\n+=== Tagging and Excluding Filters\n+\n+You can tag specific filters and exclude those filters when faceting. This is useful when doing multi-select faceting.\n+\n+Consider the following example query with faceting:\n+\n+`q=mainquery&fq=status:public&fq=doctype:pdf&facet=true&facet.field=doctype`\n+\n+Because everything is already constrained by the filter `doctype:pdf`, the `facet.field=doctype` facet command is currently redundant and will return 0 counts for everything except `doctype:pdf`.\n+\n+To implement a multi-select facet for doctype, a GUI may want to still display the other doctype values and their associated counts, as if the http://doctypepdf[`doctype:pdf`] constraint had not yet been applied. For example:\n+\n+[source,text]\n+----\n+=== Document Type ===\n+  [ ] Word (42)\n+  [x] PDF  (96)\n+  [ ] Excel(11)\n+  [ ] HTML (63)\n+----\n+\n+To return counts for doctype values that are currently not selected, tag filters that directly constrain doctype, and exclude those filters when faceting on doctype.\n+\n+`q=mainquery&fq=status:public&fq={!tag=dt}doctype:pdf&facet=true&facet.field={!ex=dt}doctype`\n+\n+Filter exclusion is supported for all types of facets. Both the `tag` and `ex` local parameters may specify multiple values by separating them with commas.\n+\n+[[Faceting-ChangingtheOutputKey]]\n+=== Changing the Output Key\n+\n+To change the output key for a faceting command, specify a new name with the `key` local parameter. For example:\n+\n+`facet.field={!ex=dt key=mylabel}doctype`\n+\n+The parameter setting above causes the field facet results for the \"doctype\" field to be returned using the key \"mylabel\" rather than \"doctype\" in the response. This can be helpful when faceting on the same field multiple times with different exclusions.\n+\n+[[Faceting-Limitingfacetwithcertainterms]]\n+=== Limiting Facet with Certain Terms\n+\n+To limit field facet with certain terms specify them comma separated with `terms` local parameter. Commas and quotes in terms can be escaped with backslash, as in `\\,`. In this case facet is calculated on a way similar to `facet.method=enum` , but ignores `facet.enum.cache.minDf`. For example:\n+\n+`facet.field={!terms='alfa,betta,with\\,with\\',with space'}symbol`\n+\n+[[Faceting-RelatedTopics]]\n+== Related Topics\n+\n+* <<spatial-search.adoc#spatial-search,Heatmap Faceting (Spatial)>>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/faceting.adoc",
                "sha": "26bfbe2a90ef3c1c687959066f2775e4037091ce",
                "status": "added"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/feed.xml",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/feed.xml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/feed.xml",
                "patch": "@@ -0,0 +1,28 @@\n+---\n+search: exclude\n+layout: none\n+---\n+\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<rss version=\"2.0\" xmlns:atom=\"http://www.w3.org/2005/Atom\">\n+    <channel>\n+        <title>{{ site.site_title | xml_escape }}</title>\n+        <description>{{ site.description | xml_escape }}</description>\n+        <link>{{ site.url }}</link>\n+        <atom:link href=\"{{ \"/feed.xml\" | prepend: site.url }}\" rel=\"self\" type=\"application/rss+xml\"/>\n+        <pubDate>{{ site.time | date_to_rfc822 }}</pubDate>\n+        <lastBuildDate>{{ site.time | date_to_rfc822 }}</lastBuildDate>\n+        <generator>Jekyll v{{ jekyll.version }}</generator>\n+        {% for page in site.pages limit:10 %}\n+        <item>\n+            <title>{{ page.title | xml_escape }}</title>\n+            <description>{{ page.content | xml_escape }}</description>\n+            <link>{{ page.url | prepend: site.url }}</link>\n+            <guid isPermaLink=\"true\">{{ page.url | prepend: site.url }}</guid>\n+            {% for tag in page.tags %}\n+               <category>{{ tag | xml_escape }}</category>\n+            {% endfor %}\n+        </item>\n+        {% endfor %}\n+    </channel>\n+</rss>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/feed.xml",
                "sha": "d9faae8e25b975648c05fd1e760c0d51f83c5503",
                "status": "added"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-properties-by-use-case.adoc",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/field-properties-by-use-case.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/field-properties-by-use-case.adoc",
                "patch": "@@ -0,0 +1,34 @@\n+= Field Properties by Use Case\n+:page-shortname: field-properties-by-use-case\n+:page-permalink: field-properties-by-use-case.html\n+\n+Here is a summary of common use cases, and the attributes the fields or field types should have to support the case. An entry of true or false in the table indicates that the option must be set to the given value for the use case to function correctly. If no entry is provided, the setting of that attribute has no impact on the case.\n+\n+// NOTE: not currently using footnoteref here because:\n+//  - it has issues with tables in the PDF\n+//  - citing the same footnote with multiple refs causes it to generate invalid HTML (dup ids)\n+\n+[width=\"100%\",cols=\"16%,12%,12%,12%,12%,12%,12%,12%\",options=\"header\",]\n+|===\n+|Use Case |indexed |stored |multiValued |omitNorms |termVectors |termPositions |docValues\n+|search within field |true | | | | | |\n+|retrieve contents | |true^<<fpbuc_8,8>>^ | | | | |true^<<fpbuc_8,8>>^\n+|use as unique key |true | |false | | | |\n+|sort on field |true^<<fpbuc_7,7>>^ | |false |true ^<<fpbuc_1,1>>^ | | |true^<<fpbuc_7,7>>^\n+|highlighting |true^<<fpbuc_4,4>>^ |true | | |true^<<fpbuc_2,2>>^ |true ^<<fpbuc_3,3>>^ |\n+|faceting ^<<fpbuc_5,5>>^ |true^<<fpbuc_7,7>>^ | | | | | |true^<<fpbuc_7,7>>^\n+|add multiple values, maintaining order | | |true | | | |\n+|field length affects doc score | | | |false | | |\n+|MoreLikeThis ^<<fpbuc_5,5>>^ | | | | |true ^<<fpbuc_6,6>>^ | |\n+|===\n+\n+Notes:\n+\n+1. [[fpbuc_1,1]] Recommended but not necessary.\n+2. [[fpbuc_2,2]] Will be used if present, but not necessary.\n+3. [[fpbuc_3,3]] (if termVectors=true)\n+4. [[fpbuc_4,4]] A tokenizer must be defined for the field, but it doesn't need to be indexed.\n+5. [[fpbuc_5,5]] Described in <<understanding-analyzers-tokenizers-and-filters.adoc#understanding-analyzers-tokenizers-and-filters,Understanding Analyzers, Tokenizers, and Filters>>.\n+6. [[fpbuc_6,6]] Term vectors are not mandatory here. If not true, then a stored field is analyzed. So term vectors are recommended, but only required if `stored=false`.\n+7. [[fpbuc_7,7]] For most field types, either `indexed` or `docValues` must be true, but both are not required. <<docvalues.adoc#docvalues,DocValues>> can be more efficient in many cases. For `[Int/Long/Float/Double/Date]PointFields`, `docValues=true` is required.\n+8. [[fpbuc_8,8]] Stored content will be used by default, but docValues can alternatively be used. See <<docvalues.adoc#docvalues,DocValues>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-properties-by-use-case.adoc",
                "sha": "bd014b9f4d6240bdc78d13af733b166721e5c55d",
                "status": "added"
            },
            {
                "additions": 115,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-type-definitions-and-properties.adoc",
                "changes": 115,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/field-type-definitions-and-properties.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/field-type-definitions-and-properties.adoc",
                "patch": "@@ -0,0 +1,115 @@\n+= Field Type Definitions and Properties\n+:page-shortname: field-type-definitions-and-properties\n+:page-permalink: field-type-definitions-and-properties.html\n+\n+A field type defines the analysis that will occur on a field when documents are indexed or queries are sent to the index.\n+\n+A field type definition can include four types of information:\n+\n+* The name of the field type (mandatory).\n+* An implementation class name (mandatory).\n+* If the field type is `TextField`, a description of the field analysis for the field type.\n+* Field type properties - depending on the implementation class, some properties may be mandatory.\n+\n+[[FieldTypeDefinitionsandProperties-FieldTypeDefinitionsinschema.xml]]\n+== Field Type Definitions in `schema.xml`\n+\n+Field types are defined in `schema.xml`. Each field type is defined between `fieldType` elements. They can optionally be grouped within a `types` element. Here is an example of a field type definition for a type called `text_general`:\n+\n+[source,xml,subs=\"verbatim,callouts\"]\n+----\n+<fieldType name=\"text_general\" class=\"solr.TextField\" positionIncrementGap=\"100\"> --<1>\n+  <analyzer type=\"index\"> --<2>\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" />\n+    <!-- in this example, we will only use synonyms at query time\n+    <filter class=\"solr.SynonymFilterFactory\" synonyms=\"index_synonyms.txt\" ignoreCase=\"true\" expand=\"false\"/>\n+    -->\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  </analyzer>\n+  <analyzer type=\"query\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" />\n+    <filter class=\"solr.SynonymFilterFactory\" synonyms=\"synonyms.txt\" ignoreCase=\"true\" expand=\"true\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+<1> The first line in the example above contains the field type name, `text_general`, and the name of the implementing class, `solr.TextField`.\n+<2> The rest of the definition is about field analysis, described in <<understanding-analyzers-tokenizers-and-filters.adoc#understanding-analyzers-tokenizers-and-filters,Understanding Analyzers, Tokenizers, and Filters>>.\n+\n+The implementing class is responsible for making sure the field is handled correctly. In the class names in `schema.xml`, the string `solr` is shorthand for `org.apache.solr.schema` or `org.apache.solr.analysis`. Therefore, `solr.TextField` is really `org.apache.solr.schema.TextField`.\n+\n+== Field Type Properties\n+\n+The field type `class` determines most of the behavior of a field type, but optional properties can also be defined. For example, the following definition of a date field type defines two properties, `sortMissingLast` and `omitNorms`.\n+\n+[source,xml]\n+----\n+<fieldType name=\"date\" class=\"solr.TrieDateField\"\n+           sortMissingLast=\"true\" omitNorms=\"true\"/>\n+----\n+\n+The properties that can be specified for a given field type fall into three major categories:\n+\n+* Properties specific to the field type's class.\n+* <<General Properties>> Solr supports for any field type.\n+* <<Field Default Properties>> that can be specified on the field type that will be inherited by fields that use this type instead of the default behavior.\n+\n+=== General Properties\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,40,30\",options=\"header\"]\n+|===\n+|Property |Description |Values\n+|name |The name of the fieldType. This value gets used in field definitions, in the \"type\" attribute. It is strongly recommended that names consist of alphanumeric or underscore characters only and not start with a digit. This is not currently strictly enforced. |\n+|class |The class name that gets used to store and index the data for this type. Note that you may prefix included class names with \"solr.\" and Solr will automatically figure out which packages to search for the class - so `solr.TextField` will work. If you are using a third-party class, you will probably need to have a fully qualified class name. The fully qualified equivalent for `solr.TextField` is `org.apache.solr.schema.TextField`. |\n+|positionIncrementGap |For multivalued fields, specifies a distance between multiple values, which prevents spurious phrase matches |integer\n+|autoGeneratePhraseQueries |For text fields. If true, Solr automatically generates phrase queries for adjacent terms. If false, terms must be enclosed in double-quotes to be treated as phrases. |true or false\n+|enableGraphQueries |For text fields, applicable when querying with <<the-standard-query-parser.adoc#TheStandardQueryParser-StandardQueryParserParameters,`sow=false`>>. Use `true` (the default) for field types with query analyzers including graph-aware filters, e.g. <<filter-descriptions.adoc#FilterDescriptions-SynonymGraphFilter,Synonym Graph Filter>> and <<filter-descriptions.adoc#FilterDescriptions-WordDelimiterGraphFilter,Word Delimiter Graph Filter>>. Use `false` for field types with query analyzers including filters that can match docs when some tokens are missing, e.g., <<filter-descriptions.adoc#FilterDescriptions-ShingleFilter,Shingle Filter>>. |true or false\n+|[[FieldTypeDefinitionsandProperties-docValuesFormat]]docValuesFormat |Defines a custom `DocValuesFormat` to use for fields of this type. This requires that a schema-aware codec, such as the `SchemaCodecFactory` has been configured in solrconfig.xml. |n/a\n+|postingsFormat |Defines a custom `PostingsFormat` to use for fields of this type. This requires that a schema-aware codec, such as the `SchemaCodecFactory` has been configured in solrconfig.xml. |n/a\n+|===\n+\n+[NOTE]\n+====\n+Lucene index back-compatibility is only supported for the default codec. If you choose to customize the `postingsFormat` or `docValuesFormat` in your schema.xml, upgrading to a future version of Solr may require you to either switch back to the default codec and optimize your index to rewrite it into the default codec before upgrading, or re-build your entire index from scratch after upgrading.\n+====\n+\n+=== Field Default Properties\n+\n+These are properties that can be specified either on the field types, or on individual fields to override the values provided by the field types.\n+\n+The default values for each property depend on the underlying `FieldType` class, which in turn may depend on the `version` attribute of the `<schema/>`. The table below includes the default value for most `FieldType` implementations provided by Solr, assuming a `schema.xml` that declares `version=\"1.6\"`.\n+\n+// TODO: SOLR-10655 BEGIN: refactor this into a 'field-default-properties.include.adoc' file for reuse\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,40,20,20\",options=\"header\"]\n+|===\n+|Property |Description |Values |Implicit Default\n+|indexed |If true, the value of the field can be used in queries to retrieve matching documents. |true or false |true\n+|stored |If true, the actual value of the field can be retrieved by queries. |true or false |true\n+|docValues |If true, the value of the field will be put in a column-oriented <<docvalues.adoc#docvalues,DocValues>> structure. |true or false |false\n+|sortMissingFirst sortMissingLast |Control the placement of documents when a sort field is not present. |true or false |false\n+|multiValued |If true, indicates that a single document might contain multiple values for this field type. |true or false |false\n+|omitNorms |If true, omits the norms associated with this field (this disables length normalization for the field, and saves some memory). *Defaults to true for all primitive (non-analyzed) field types, such as int, float, data, bool, and string.* Only full-text fields or fields need norms. |true or false |*\n+|omitTermFreqAndPositions |If true, omits term frequency, positions, and payloads from postings for this field. This can be a performance boost for fields that don't require that information. It also reduces the storage space required for the index. Queries that rely on position that are issued on a field with this option will silently fail to find documents. *This property defaults to true for all field types that are not text fields.* |true or false |*\n+|omitPositions |Similar to `omitTermFreqAndPositions` but preserves term frequency information. |true or false |*\n+|termVectors termPositions termOffsets termPayloads |These options instruct Solr to maintain full term vectors for each document, optionally including position, offset and payload information for each term occurrence in those vectors. These can be used to accelerate highlighting and other ancillary functionality, but impose a substantial cost in terms of index size. They are not necessary for typical uses of Solr. |true or false |false\n+|required |Instructs Solr to reject any attempts to add a document which does not have a value for this field. This property defaults to false. |true or false |false\n+|useDocValuesAsStored |If the field has <<docvalues.adoc#docvalues,docValues>> enabled, setting this to true would allow the field to be returned as if it were a stored field (even if it has `stored=false`) when matching \"`*`\" in an <<common-query-parameters.adoc#CommonQueryParameters-Thefl_FieldList_Parameter,fl parameter>>. |true or false |true\n+|large |Large fields are always lazy loaded and will only take up space in the document cache if the actual value is < 512KB. This option requires `stored=\"true\"` and `multiValued=\"false\"`. It's intended for fields that might have very large values so that they don't get cached in memory. |true or false |false\n+|===\n+\n+// TODO: SOLR-10655 END\n+\n+[[FieldTypeDefinitionsandProperties-FieldTypeSimilarity]]\n+== Field Type Similarity\n+\n+A field type may optionally specify a `<similarity/>` that will be used when scoring documents that refer to fields with this type, as long as the \"global\" similarity for the collection allows it.\n+\n+By default, any field type which does not define a similarity, uses `BM25Similarity`. For more details, and examples of configuring both global & per-type Similarities, please see <<other-schema-elements.adoc#OtherSchemaElements-Similarity,Other Schema Elements>>.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-type-definitions-and-properties.adoc",
                "sha": "df066572104ff975200de591dfff43abff7436dd",
                "status": "added"
            },
            {
                "additions": 40,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-types-included-with-solr.adoc",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/field-types-included-with-solr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/field-types-included-with-solr.adoc",
                "patch": "@@ -0,0 +1,40 @@\n+= Field Types Included with Solr\n+:page-shortname: field-types-included-with-solr\n+:page-permalink: field-types-included-with-solr.html\n+\n+The following table lists the field types that are available in Solr. The `org.apache.solr.schema` package includes all the classes listed in this table.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"25,75\",options=\"header\"]\n+|===\n+|Class |Description\n+|BinaryField |Binary data.\n+|BoolField |Contains either true or false. Values of \"1\", \"t\", or \"T\" in the first character are interpreted as true. Any other values in the first character are interpreted as false.\n+|CollationField |Supports Unicode collation for sorting and range queries. ICUCollationField is a better choice if you can use ICU4J. See the section <<language-analysis.adoc#LanguageAnalysis-UnicodeCollation,Unicode Collation>>.\n+|CurrencyField |Supports currencies and exchange rates. See the section <<working-with-currencies-and-exchange-rates.adoc#working-with-currencies-and-exchange-rates,Working with Currencies and Exchange Rates>>.\n+|DateRangeField |Supports indexing date ranges, to include point in time date instances as well (single-millisecond durations). See the section <<working-with-dates.adoc#working-with-dates,Working with Dates>> for more detail on using this field type. Consider using this field type even if it's just for date instances, particularly when the queries typically fall on UTC year/month/day/hour, etc., boundaries.\n+|ExternalFileField |Pulls values from a file on disk. See the section <<working-with-external-files-and-processes.adoc#working-with-external-files-and-processes,Working with External Files and Processes>>.\n+|EnumField |Allows defining an enumerated set of values which may not be easily sorted by either alphabetic or numeric order (such as a list of severities, for example). This field type takes a configuration file, which lists the proper order of the field values. See the section <<working-with-enum-fields.adoc#working-with-enum-fields,Working with Enum Fields>> for more information.\n+|ICUCollationField |Supports Unicode collation for sorting and range queries. See the section <<language-analysis.adoc#LanguageAnalysis-UnicodeCollation,Unicode Collation>>.\n+|LatLonPointSpatialField |<<spatial-search.adoc#spatial-search,Spatial Search>>: a latitude/longitude coordinate pair; possibly multi-valued for multiple points. Usually it's specified as \"lat,lon\" order with a comma.\n+|LatLonType |(deprecated) <<spatial-search.adoc#spatial-search,Spatial Search>>: a single-valued latitude/longitude coordinate pair. Usually it's specified as \"lat,lon\" order with a comma.\n+|PointType |<<spatial-search.adoc#spatial-search,Spatial Search>>: A single-valued n-dimensional point. It's both for sorting spatial data that is _not_ lat-lon, and for some more rare use-cases. (NOTE: this is _not_ related to the \"Point\" based numeric fields)\n+|PreAnalyzedField |Provides a way to send to Solr serialized token streams, optionally with independent stored values of a field, and have this information stored and indexed without any additional text processing. Configuration and usage of PreAnalyzedField is documented on the <<working-with-external-files-and-processes.adoc#WorkingwithExternalFilesandProcesses-ThePreAnalyzedFieldType,Working with External Files and Processes>> page.\n+|RandomSortField |Does not contain a value. Queries that sort on this field type will return results in random order. Use a dynamic field to use this feature.\n+|SpatialRecursivePrefixTreeFieldType |(RPT for short) <<spatial-search.adoc#spatial-search,Spatial Search>>: Accepts latitude comma longitude strings or other shapes in WKT format.\n+|StrField |String (UTF-8 encoded string or Unicode). Strings are intended for small fields and are _not_ tokenized or analyzed in any way. They have a hard limit of slightly less than 32K.\n+|TextField |Text, usually multiple words or tokens.\n+|TrieDateField |Date field. Represents a point in time with millisecond precision. See the section <<working-with-dates.adoc#working-with-dates,Working with Dates>>. `precisionStep=\"0\"` minimizes index size; `precisionStep=\"8\"` (the default) enables more efficient range queries. For single valued fields, use `docValues=\"true\"` for efficient sorting.\n+|TrieDoubleField |Double field (64-bit IEEE floating point). `precisionStep=\"0\"` minimizes index size; `precisionStep=\"8\"` (the default) enables more efficient range queries. For single valued fields, use `docValues=\"true\"` for efficient sorting.\n+|TrieFloatField |Floating point field (32-bit IEEE floating point) . `precisionStep=\"0\"` enables efficient numeric sorting and minimizes index size; `precisionStep=\"8\"` (the default) enables efficient range queries. Use `docValues=\"true\"` for efficient sorting. For single valued fields, use `docValues=\"true\"` for efficient sorting.\n+|TrieIntField |Integer field (32-bit signed integer). `precisionStep=\"0\"` enables efficient numeric sorting and minimizes index size; `precisionStep=\"8\"` (the default) enables efficient range queries. For single valued fields, use `docValues=\"true\"` for efficient sorting.\n+|TrieLongField |Long field (64-bit signed integer). `precisionStep=\"0\"` minimizes index size; `precisionStep=\"8\"` (the default) enables more efficient range queries. For single valued fields, use `docValues=\"true\"` for efficient sorting.\n+|TrieField |If this field type is used, a \"type\" attribute must also be specified, valid values are: `integer`, `long`, `float`, `double`, `date`. Using this field is the same as using any of the Trie fields mentioned above\n+|DatePointField |Date field. Represents a point in time with millisecond precision. See the section <<working-with-dates.adoc#working-with-dates,Working with Dates>>. This class functions similarly to TrieDateField, but using a \"Dimensional Points\" based data structure instead of indexed terms, and doesn't require configuration of a precision step. For single valued fields, `docValues=\"true\"` must be used to enable sorting.\n+|DoublePointField |Double field (64-bit IEEE floating point). This class functions similarly to TrieDoubleField, but using a \"Dimensional Points\" based data structure instead of indexed terms, and doesn't require configuration of a precision step. For single valued fields, `docValues=\"true\"` must be used to enable sorting.\n+|FloatPointField |Floating point field (32-bit IEEE floating point). This class functions similarly to TrieFloatField, but using a \"Dimensional Points\" based data structure instead of indexed terms, and doesn't require configuration of a precision step. For single valued fields, `docValues=\"true\"` must be used to enable sorting.\n+|IntPointField |Integer field (32-bit signed integer). This class functions similarly to TrieIntField, but using a \"Dimensional Points\" based data structure instead of indexed terms, and doesn't require configuration of a precision step. For single valued fields, `docValues=\"true\"` must be used to enable sorting.\n+|LongPointField |Long field (64-bit signed integer). This class functions similarly to TrieLongField, but using a \"Dimensional Points\" based data structure instead of indexed terms, and doesn't require configuration of a precision step. For single valued fields, `docValues=\"true\"` must be used to enable sorting.\n+|UUIDField |Universally Unique Identifier (UUID). Pass in a value of \"NEW\" and Solr will create a new UUID. *Note*: configuring a UUIDField instance with a default value of \"NEW\" is not advisable for most users when using SolrCloud (and not possible if the UUID value is configured as the unique key field) since the result will be that each replica of each document will get a unique UUID value. Using UUIDUpdateProcessorFactory to generate UUID values when documents are added is recommended instead.\n+|===",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/field-types-included-with-solr.adoc",
                "sha": "8aaef003c584649a7a45281bdb5b597e28f11c8e",
                "status": "added"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/files-screen.adoc",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/files-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/files-screen.adoc",
                "patch": "@@ -0,0 +1,23 @@\n+= Files Screen\n+:page-shortname: files-screen\n+:page-permalink: files-screen.html\n+\n+The Files screen lets you browse & view the various configuration files (such `solrconfig.xml` and the schema file) for the collection you selected.\n+\n+.The Files Screen\n+image::images/files-screen/files-screen.png[image,height=400]\n+\n+If you are using <<solrcloud.adoc#solrcloud,SolrCloud>>, the files displayed are the configuration files for this collection stored in ZooKeeper. In a standalone Solr installations, all files in the `conf` directory are displayed.\n+\n+While `solrconfig.xml` defines the behavior of Solr as it indexes content and responds to queries, the Schema allows you to define the types of data in your content (field types), the fields your documents will be broken into, and any dynamic fields that should be generated based on patterns of field names in the incoming documents. Any other configuration files are used depending on how they are referenced in either `solrconfig.xml` or your schema.\n+\n+Configuration files cannot be edited with this screen, so a text editor of some kind must be used.\n+\n+This screen is related to the <<schema-browser-screen.adoc#schema-browser-screen,Schema Browser Screen>>, in that they both can display information from the schema, but the Schema Browser provides a way to drill into the analysis chain and displays linkages between field types, fields, and dynamic field rules.\n+\n+Many of the options defined in these configuration files are described throughout the rest of this Guide. In particular, you will want to review these sections:\n+\n+* <<indexing-and-basic-data-operations.adoc#indexing-and-basic-data-operations,Indexing and Basic Data Operations>>\n+* <<searching.adoc#searching,Searching>>\n+* <<the-well-configured-solr-instance.adoc#the-well-configured-solr-instance,The Well-Configured Solr Instance>>\n+* <<documents-fields-and-schema-design.adoc#documents-fields-and-schema-design,Documents, Fields, and Schema Design>>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/files-screen.adoc",
                "sha": "4d134e6dab26070ef016d34af8e73e3ae0c931b9",
                "status": "added"
            },
            {
                "additions": 1779,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/filter-descriptions.adoc",
                "changes": 1779,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/filter-descriptions.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/filter-descriptions.adoc",
                "patch": "@@ -0,0 +1,1779 @@\n+= Filter Descriptions\n+:page-shortname: filter-descriptions\n+:page-permalink: filter-descriptions.html\n+\n+Filters examine a stream of tokens and keep them, transform them or discard them, depending on the filter type being used.\n+\n+You configure each filter with a `<filter>` element in `schema.xml` as a child of `<analyzer>`, following the `<tokenizer>` element. Filter definitions should follow a tokenizer or another filter definition because they take a `TokenStream` as input. For example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"text\" class=\"solr.TextField\">\n+  <analyzer type=\"index\">\n+    <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+    <filter class=\"solr.LowerCaseFilterFactory\"/>...\n+  </analyzer>\n+</fieldType>\n+----\n+\n+The class attribute names a factory class that will instantiate a filter object as needed. Filter factory classes must implement the `org.apache.solr.analysis.TokenFilterFactory` interface. Like tokenizers, filters are also instances of TokenStream and thus are producers of tokens. Unlike tokenizers, filters also consume tokens from a TokenStream. This allows you to mix and match filters, in any order you prefer, downstream of a tokenizer.\n+\n+Arguments may be passed to tokenizer factories to modify their behavior by setting attributes on the `<filter>` element. For example:\n+\n+[source,xml]\n+----\n+<fieldType name=\"semicolonDelimited\" class=\"solr.TextField\">\n+  <analyzer type=\"query\">\n+    <tokenizer class=\"solr.PatternTokenizerFactory\" pattern=\"; \" />\n+    <filter class=\"solr.LengthFilterFactory\" min=\"2\" max=\"7\"/>\n+  </analyzer>\n+</fieldType>\n+----\n+\n+The following sections describe the filter factories that are included in this release of Solr.\n+\n+For user tips about Solr's filters, see http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters.\n+\n+[[FilterDescriptions-ASCIIFoldingFilter]]\n+== ASCII Folding Filter\n+\n+This filter converts alphabetic, numeric, and symbolic Unicode characters which are not in the Basic Latin Unicode block (the first 127 ASCII characters) to their ASCII equivalents, if one exists. This filter converts characters from the following Unicode blocks:\n+\n+* http://www.unicode.org/charts/PDF/U0080.pdf[C1 Controls and Latin-1 Supplement] (PDF)\n+* http://www.unicode.org/charts/PDF/U0100.pdf[Latin Extended-A] (PDF)\n+* http://www.unicode.org/charts/PDF/U0180.pdf[Latin Extended-B] (PDF)\n+* http://www.unicode.org/charts/PDF/U1E00.pdf[Latin Extended Additional] (PDF)\n+* http://www.unicode.org/charts/PDF/U2C60.pdf[Latin Extended-C] (PDF)\n+* http://www.unicode.org/charts/PDF/UA720.pdf[Latin Extended-D] (PDF)\n+* http://www.unicode.org/charts/PDF/U0250.pdf[IPA Extensions] (PDF)\n+* http://www.unicode.org/charts/PDF/U1D00.pdf[Phonetic Extensions] (PDF)\n+* http://www.unicode.org/charts/PDF/U1D80.pdf[Phonetic Extensions Supplement] (PDF)\n+* http://www.unicode.org/charts/PDF/U2000.pdf[General Punctuation] (PDF)\n+* http://www.unicode.org/charts/PDF/U2070.pdf[Superscripts and Subscripts] (PDF)\n+* http://www.unicode.org/charts/PDF/U2460.pdf[Enclosed Alphanumerics] (PDF)\n+* http://www.unicode.org/charts/PDF/U2700.pdf[Dingbats] (PDF)\n+* http://www.unicode.org/charts/PDF/U2E00.pdf[Supplemental Punctuation] (PDF)\n+* http://www.unicode.org/charts/PDF/UFB00.pdf[Alphabetic Presentation Forms] (PDF)\n+* http://www.unicode.org/charts/PDF/UFF00.pdf[Halfwidth and Fullwidth Forms] (PDF)\n+\n+*Factory class:* `solr.ASCIIFoldingFilterFactory`\n+\n+*Arguments:*\n+\n+`preserveOriginal`:: (boolean, default false) If true, the original token is preserved: \"th\u00e9\" -> \"the\", \"th\u00e9\"\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizer\"/>\n+  <filter class=\"solr.ASCIIFoldingFilterFactory\" preserveOriginal=\"false\" />\n+</analyzer>\n+----\n+\n+*In:* \"\u00e1\" (Unicode character 00E1)\n+\n+*Out:* \"a\" (ASCII character 97)\n+\n+[[FilterDescriptions-Beider-MorseFilter]]\n+== Beider-Morse Filter\n+\n+Implements the Beider-Morse Phonetic Matching (BMPM) algorithm, which allows identification of similar names, even if they are spelled differently or in different languages. More information about how this works is available in the section on <<phonetic-matching.adoc#PhoneticMatching-Beider-MorsePhoneticMatching_BMPM_,Phonetic Matching>>.\n+\n+[IMPORTANT]\n+====\n+BeiderMorseFilter changed its behavior in Solr 5.0 due to an update to version 3.04 of the BMPM algorithm. Older version of Solr implemented BMPM version 3.00 (see http://stevemorse.org/phoneticinfo.htm). Any index built using this filter with earlier versions of Solr will need to be rebuilt.\n+====\n+\n+*Factory class:* `solr.BeiderMorseFilterFactory`\n+\n+*Arguments:*\n+\n+`nameType`:: Types of names. Valid values are GENERIC, ASHKENAZI, or SEPHARDIC. If not processing Ashkenazi or Sephardic names, use GENERIC.\n+\n+`ruleType`:: Types of rules to apply. Valid values are APPROX or EXACT.\n+\n+`concat`:: Defines if multiple possible matches should be combined with a pipe (\"|\").\n+\n+`languageSet`:: The language set to use. The value \"auto\" will allow the Filter to identify the language, or a comma-separated list can be supplied.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.BeiderMorseFilterFactory\" nameType=\"GENERIC\" ruleType=\"APPROX\" concat=\"true\" languageSet=\"auto\">\n+  </filter>\n+</analyzer>\n+----\n+\n+[[FilterDescriptions-ClassicFilter]]\n+== Classic Filter\n+\n+This filter takes the output of the <<tokenizers.adoc#Tokenizers-ClassicTokenizer,Classic Tokenizer>> and strips periods from acronyms and \"'s\" from possessives.\n+\n+*Factory class:* `solr.ClassicFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.ClassicTokenizerFactory\"/>\n+  <filter class=\"solr.ClassicFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"I.B.M. cat's can't\"\n+\n+*Tokenizer to Filter:* \"I.B.M\", \"cat's\", \"can't\"\n+\n+*Out:* \"IBM\", \"cat\", \"can't\"\n+\n+[[FilterDescriptions-CommonGramsFilter]]\n+== Common Grams Filter\n+\n+This filter creates word shingles by combining common tokens such as stop words with regular tokens. This is useful for creating phrase queries containing common words, such as \"the cat.\" Solr normally ignores stop words in queried phrases, so searching for \"the cat\" would return all matches for the word \"cat.\"\n+\n+*Factory class:* `solr.CommonGramsFilterFactory`\n+\n+*Arguments:*\n+\n+`words`:: (a common word file in .txt format) Provide the name of a common word file, such as `stopwords.txt`.\n+\n+`format`:: (optional) If the stopwords list has been formatted for Snowball, you can specify `format=\"snowball\"` so Solr can read the stopwords file.\n+\n+`ignoreCase`:: (boolean) If true, the filter ignores the case of words when comparing them to the common word file. The default is false.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.CommonGramsFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n+</analyzer>\n+----\n+\n+*In:* \"the Cat\"\n+\n+*Tokenizer to Filter:* \"the\", \"Cat\"\n+\n+*Out:* \"the_cat\"\n+\n+[[FilterDescriptions-CollationKeyFilter]]\n+== Collation Key Filter\n+\n+Collation allows sorting of text in a language-sensitive way. It is usually used for sorting, but can also be used with advanced searches. We've covered this in much more detail in the section on <<language-analysis.adoc#LanguageAnalysis-UnicodeCollation,Unicode Collation>>.\n+\n+[[FilterDescriptions-Daitch-MokotoffSoundexFilter]]\n+== Daitch-Mokotoff Soundex Filter\n+\n+Implements the Daitch-Mokotoff Soundex algorithm, which allows identification of similar names, even if they are spelled differently. More information about how this works is available in the section on <<phonetic-matching.adoc#phonetic-matching,Phonetic Matching>>.\n+\n+*Factory class:* `solr.DaitchMokotoffSoundexFilterFactory`\n+\n+*Arguments:*\n+\n+`inject` :: (true/false) If true (the default), then new phonetic tokens are added to the stream. Otherwise, tokens are replaced with the phonetic equivalent. Setting this to false will enable phonetic matching, but the exact spelling of the target word may not match.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.DaitchMokotoffSoundexFilterFactory\" inject=\"true\"/>\n+</analyzer>\n+----\n+\n+[[FilterDescriptions-DoubleMetaphoneFilter]]\n+== Double Metaphone Filter\n+\n+This filter creates tokens using the http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/DoubleMetaphone.html[`DoubleMetaphone`] encoding algorithm from commons-codec. For more information, see the <<phonetic-matching.adoc#phonetic-matching,Phonetic Matching>> section.\n+\n+*Factory class:* `solr.DoubleMetaphoneFilterFactory`\n+\n+*Arguments:*\n+\n+`inject`:: (true/false) If true (the default), then new phonetic tokens are added to the stream. Otherwise, tokens are replaced with the phonetic equivalent. Setting this to false will enable phonetic matching, but the exact spelling of the target word may not match.\n+\n+`maxCodeLength`:: (integer) The maximum length of the code to be generated.\n+\n+*Example:*\n+\n+Default behavior for inject (true): keep the original token and add phonetic token(s) at the same position.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.DoubleMetaphoneFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and Kuczewski\"\n+\n+*Tokenizer to Filter:* \"four\"(1), \"score\"(2), \"and\"(3), \"Kuczewski\"(4)\n+\n+*Out:* \"four\"(1), \"FR\"(1), \"score\"(2), \"SKR\"(2), \"and\"(3), \"ANT\"(3), \"Kuczewski\"(4), \"KSSK\"(4), \"KXFS\"(4)\n+\n+The phonetic tokens have a position increment of 0, which indicates that they are at the same position as the token they were derived from (immediately preceding). Note that \"Kuczewski\" has two encodings, which are added at the same position.\n+\n+*Example:*\n+\n+Discard original token (`inject=\"false\"`).\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.DoubleMetaphoneFilterFactory\" inject=\"false\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and Kuczewski\"\n+\n+*Tokenizer to Filter:* \"four\"(1), \"score\"(2), \"and\"(3), \"Kuczewski\"(4)\n+\n+*Out:* \"FR\"(1), \"SKR\"(2), \"ANT\"(3), \"KSSK\"(4), \"KXFS\"(4)\n+\n+Note that \"Kuczewski\" has two encodings, which are added at the same position.\n+\n+[[FilterDescriptions-EdgeN-GramFilter]]\n+== Edge N-Gram Filter\n+\n+This filter generates edge n-gram tokens of sizes within the given range.\n+\n+*Factory class:* `solr.EdgeNGramFilterFactory`\n+\n+*Arguments:*\n+\n+`minGramSize`:: (integer, default 1) The minimum gram size.\n+\n+`maxGramSize`:: (integer, default 1) The maximum gram size.\n+\n+*Example:*\n+\n+Default behavior.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.EdgeNGramFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and twenty\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\", \"and\", \"twenty\"\n+\n+*Out:* \"f\", \"s\", \"a\", \"t\"\n+\n+*Example:*\n+\n+A range of 1 to 4.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.EdgeNGramFilterFactory\" minGramSize=\"1\" maxGramSize=\"4\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\"\n+\n+*Out:* \"f\", \"fo\", \"fou\", \"four\", \"s\", \"sc\", \"sco\", \"scor\"\n+\n+*Example:*\n+\n+A range of 4 to 6.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.EdgeNGramFilterFactory\" minGramSize=\"4\" maxGramSize=\"6\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and twenty\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\", \"and\", \"twenty\"\n+\n+*Out:* \"four\", \"scor\", \"score\", \"twen\", \"twent\", \"twenty\"\n+\n+[[FilterDescriptions-EnglishMinimalStemFilter]]\n+== English Minimal Stem Filter\n+\n+This filter stems plural English words to their singular form.\n+\n+*Factory class:* `solr.EnglishMinimalStemFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.EnglishMinimalStemFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"dogs cats\"\n+\n+*Tokenizer to Filter:* \"dogs\", \"cats\"\n+\n+*Out:* \"dog\", \"cat\"\n+\n+[[FilterDescriptions-EnglishPossessiveFilter]]\n+== English Possessive Filter\n+\n+This filter removes singular possessives (trailing *'s*) from words. Note that plural possessives, e.g. the *s'* in \"divers' snorkels\", are not removed by this filter.\n+\n+*Factory class:* `solr.EnglishPossessiveFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.EnglishPossessiveFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Man's dog bites dogs' man\"\n+\n+*Tokenizer to Filter:* \"Man's\", \"dog\", \"bites\", \"dogs'\", \"man\"\n+\n+*Out:* \"Man\", \"dog\", \"bites\", \"dogs'\", \"man\"\n+\n+[[FilterDescriptions-FingerprintFilter]]\n+== Fingerprint Filter\n+\n+This filter outputs a single token which is a concatenation of the sorted and de-duplicated set of input tokens. This can be useful for clustering/linking use cases.\n+\n+*Factory class:* `solr.FingerprintFilterFactory`\n+\n+*Arguments:*\n+\n+`separator`:: The character used to separate tokens combined into the single output token. Defaults to \" \" (a space character).\n+\n+`maxOutputTokenSize`:: The maximum length of the summarized output token. If exceeded, no output token is emitted. Defaults to 1024.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.FingerprintFilterFactory\" separator=\"_\" />\n+</analyzer>\n+----\n+\n+*In:* \"the quick brown fox jumped over the lazy dog\"\n+\n+*Tokenizer to Filter:* \"the\", \"quick\", \"brown\", \"fox\", \"jumped\", \"over\", \"the\", \"lazy\", \"dog\"\n+\n+*Out:* \"brown_dog_fox_jumped_lazy_over_quick_the\"\n+\n+[[FilterDescriptions-FlattenGraphFilter]]\n+== Flatten Graph Filter\n+\n+This filter must be included on index-time analyzer specifications that include at least one graph-aware filter, including Synonym Graph Filter and Word Delimiter Graph Filter.\n+\n+*Factory class:* `solr.FlattenGraphFilterFactory`\n+\n+*Arguments:* None\n+\n+See the examples below for <<Synonym Graph Filter>> and <<Word Delimiter Graph Filter>>.\n+\n+[[FilterDescriptions-HunspellStemFilter]]\n+== Hunspell Stem Filter\n+\n+The `Hunspell Stem Filter` provides support for several languages. You must provide the dictionary (`.dic`) and rules (`.aff`) files for each language you wish to use with the Hunspell Stem Filter. You can download those language files http://wiki.services.openoffice.org/wiki/Dictionaries[here].\n+\n+Be aware that your results will vary widely based on the quality of the provided dictionary and rules files. For example, some languages have only a minimal word list with no morphological information. On the other hand, for languages that have no stemmer but do have an extensive dictionary file, the Hunspell stemmer may be a good choice.\n+\n+*Factory class:* `solr.HunspellStemFilterFactory`\n+\n+*Arguments:*\n+\n+`dictionary`:: (required) The path of a dictionary file.\n+\n+`affix`:: (required) The path of a rules file.\n+\n+`ignoreCase`:: (boolean) controls whether matching is case sensitive or not. The default is false.\n+\n+`strictAffixParsing`:: (boolean) controls whether the affix parsing is strict or not. If true, an error while reading an affix rule causes a ParseException, otherwise is ignored. The default is true.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.HunspellStemFilterFactory\"\n+    dictionary=\"en_GB.dic\"\n+    affix=\"en_GB.aff\"\n+    ignoreCase=\"true\"\n+    strictAffixParsing=\"true\" />\n+</analyzer>\n+----\n+\n+*In:* \"jump jumping jumped\"\n+\n+*Tokenizer to Filter:* \"jump\", \"jumping\", \"jumped\"\n+\n+*Out:* \"jump\", \"jump\", \"jump\"\n+\n+[[FilterDescriptions-HyphenatedWordsFilter]]\n+== Hyphenated Words Filter\n+\n+This filter reconstructs hyphenated words that have been tokenized as two tokens because of a line break or other intervening whitespace in the field test. If a token ends with a hyphen, it is joined with the following token and the hyphen is discarded.\n+\n+Note that for this filter to work properly, the upstream tokenizer must not remove trailing hyphen characters. This filter is generally only useful at index time.\n+\n+*Factory class:* `solr.HyphenatedWordsFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.HyphenatedWordsFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"A hyphen- ated word\"\n+\n+*Tokenizer to Filter:* \"A\", \"hyphen-\", \"ated\", \"word\"\n+\n+*Out:* \"A\", \"hyphenated\", \"word\"\n+\n+[[FilterDescriptions-ICUFoldingFilter]]\n+== ICU Folding Filter\n+\n+This filter is a custom Unicode normalization form that applies the foldings specified in http://www.unicode.org/reports/tr30/tr30-4.html[Unicode Technical Report 30] in addition to the `NFKC_Casefold` normalization form as described in <<FilterDescriptions-ICUNormalizer2Filter,ICU Normalizer 2 Filter>>. This filter is a better substitute for the combined behavior of the <<FilterDescriptions-ASCIIFoldingFilter,ASCII Folding Filter>>, <<FilterDescriptions-LowerCaseFilter,Lower Case Filter>>, and <<FilterDescriptions-ICUNormalizer2Filter,ICU Normalizer 2 Filter>>.\n+\n+To use this filter, see `solr/contrib/analysis-extras/README.txt` for instructions on which jars you need to add to your `solr_home/lib`. For more information about adding jars, see the section <<lib-directives-in-solrconfig.adoc#lib-directives-in-solrconfig,Lib Directives in Solrconfig>>.\n+\n+*Factory class:* `solr.ICUFoldingFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ICUFoldingFilterFactory\"/>\n+</analyzer>\n+----\n+\n+For detailed information on this normalization form, see http://www.unicode.org/reports/tr30/tr30-4.html.\n+\n+[[FilterDescriptions-ICUNormalizer2Filter]]\n+== ICU Normalizer 2 Filter\n+\n+This filter factory normalizes text according to one of five Unicode Normalization Forms as described in http://unicode.org/reports/tr15/[Unicode Standard Annex #15]:\n+\n+* NFC: (name=\"nfc\" mode=\"compose\") Normalization Form C, canonical decomposition\n+* NFD: (name=\"nfc\" mode=\"decompose\") Normalization Form D, canonical decomposition, followed by canonical composition\n+* NFKC: (name=\"nfkc\" mode=\"compose\") Normalization Form KC, compatibility decomposition\n+* NFKD: (name=\"nfkc\" mode=\"decompose\") Normalization Form KD, compatibility decomposition, followed by canonical composition\n+* NFKC_Casefold: (name=\"nfkc_cf\" mode=\"compose\") Normalization Form KC, with additional Unicode case folding. Using the ICU Normalizer 2 Filter is a better-performing substitution for the <<Lower Case Filter>> and NFKC normalization.\n+\n+*Factory class:* `solr.ICUNormalizer2FilterFactory`\n+\n+*Arguments:*\n+\n+`name`:: (string) The name of the normalization form; `nfc`, `nfd`, `nfkc`, `nfkd`, `nfkc_cf`\n+\n+`mode`:: (string) The mode of Unicode character composition and decomposition; `compose` or `decompose`\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ICUNormalizer2FilterFactory\" name=\"nfkc_cf\" mode=\"compose\"/>\n+</analyzer>\n+----\n+\n+For detailed information about these Unicode Normalization Forms, see http://unicode.org/reports/tr15/.\n+\n+To use this filter, see `solr/contrib/analysis-extras/README.txt` for instructions on which jars you need to add to your `solr_home/lib`.\n+\n+[[FilterDescriptions-ICUTransformFilter]]\n+== ICU Transform Filter\n+\n+This filter applies http://userguide.icu-project.org/transforms/general[ICU Tranforms] to text. This filter supports only ICU System Transforms. Custom rule sets are not supported.\n+\n+*Factory class:* `solr.ICUTransformFilterFactory`\n+\n+*Arguments:*\n+\n+`id`:: (string) The identifier for the ICU System Transform you wish to apply with this filter. For a full list of ICU System Transforms, see http://demo.icu-project.org/icu-bin/translit?TEMPLATE_FILE=data/translit_rule_main.html.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ICUTransformFilterFactory\" id=\"Traditional-Simplified\"/>\n+</analyzer>\n+----\n+\n+For detailed information about ICU Transforms, see http://userguide.icu-project.org/transforms/general.\n+\n+To use this filter, see `solr/contrib/analysis-extras/README.txt` for instructions on which jars you need to add to your `solr_home/lib`.\n+\n+[[FilterDescriptions-KeepWordFilter]]\n+== Keep Word Filter\n+\n+This filter discards all tokens except those that are listed in the given word list. This is the inverse of the Stop Words Filter. This filter can be useful for building specialized indices for a constrained set of terms.\n+\n+*Factory class:* `solr.KeepWordFilterFactory`\n+\n+*Arguments:*\n+\n+`words`:: (required) Path of a text file containing the list of keep words, one per line. Blank lines and lines that begin with \"#\" are ignored. This may be an absolute path, or a simple filename in the Solr `conf` directory.\n+\n+`ignoreCase`:: (true/false) If *true* then comparisons are done case-insensitively. If this argument is true, then the words file is assumed to contain only lowercase words. The default is *false*.\n+\n+`enablePositionIncrements`:: if `luceneMatchVersion` is `4.3` or earlier and `enablePositionIncrements=\"false\"`, no position holes will be left by this filter when it removes tokens. *This argument is invalid if `luceneMatchVersion` is `5.0` or later.*\n+\n+*Example:*\n+\n+Where `keepwords.txt` contains:\n+\n+`happy funny silly`\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.KeepWordFilterFactory\" words=\"keepwords.txt\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Happy, sad or funny\"\n+\n+*Tokenizer to Filter:* \"Happy\", \"sad\", \"or\", \"funny\"\n+\n+*Out:* \"funny\"\n+\n+*Example:*\n+\n+Same `keepwords.txt`, case insensitive:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.KeepWordFilterFactory\" words=\"keepwords.txt\" ignoreCase=\"true\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Happy, sad or funny\"\n+\n+*Tokenizer to Filter:* \"Happy\", \"sad\", \"or\", \"funny\"\n+\n+*Out:* \"Happy\", \"funny\"\n+\n+*Example:*\n+\n+Using LowerCaseFilterFactory before filtering for keep words, no `ignoreCase` flag.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  <filter class=\"solr.KeepWordFilterFactory\" words=\"keepwords.txt\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Happy, sad or funny\"\n+\n+*Tokenizer to Filter:* \"Happy\", \"sad\", \"or\", \"funny\"\n+\n+*Filter to Filter:* \"happy\", \"sad\", \"or\", \"funny\"\n+\n+*Out:* \"happy\", \"funny\"\n+\n+[[FilterDescriptions-KStemFilter]]\n+== KStem Filter\n+\n+KStem is an alternative to the Porter Stem Filter for developers looking for a less aggressive stemmer. KStem was written by Bob Krovetz, ported to Lucene by Sergio Guzman-Lara (UMASS Amherst). This stemmer is only appropriate for English language text.\n+\n+*Factory class:* `solr.KStemFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory \"/>\n+  <filter class=\"solr.KStemFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"jump jumping jumped\"\n+\n+*Tokenizer to Filter:* \"jump\", \"jumping\", \"jumped\"\n+\n+*Out:* \"jump\", \"jump\", \"jump\"\n+\n+[[FilterDescriptions-LengthFilter]]\n+== Length Filter\n+\n+This filter passes tokens whose length falls within the min/max limit specified. All other tokens are discarded.\n+\n+*Factory class:* `solr.LengthFilterFactory`\n+\n+*Arguments:*\n+\n+`min`:: (integer, required) Minimum token length. Tokens shorter than this are discarded.\n+\n+`max`:: (integer, required, must be >= min) Maximum token length. Tokens longer than this are discarded.\n+\n+`enablePositionIncrements`:: if `luceneMatchVersion` is `4.3` or earlier and `enablePositionIncrements=\"false\"`, no position holes will be left by this filter when it removes tokens. *This argument is invalid if `luceneMatchVersion` is `5.0` or later.*\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.LengthFilterFactory\" min=\"3\" max=\"7\"/>\n+</analyzer>\n+----\n+\n+*In:* \"turn right at Albuquerque\"\n+\n+*Tokenizer to Filter:* \"turn\", \"right\", \"at\", \"Albuquerque\"\n+\n+*Out:* \"turn\", \"right\"\n+\n+[[FilterDescriptions-LimitTokenCountFilter]]\n+== Limit Token Count Filter\n+\n+This filter limits the number of accepted tokens, typically useful for index analysis.\n+\n+By default, this filter ignores any tokens in the wrapped `TokenStream` once the limit has been reached, which can result in `reset()` being called prior to `incrementToken()` returning `false`. For most `TokenStream` implementations this should be acceptable, and faster then consuming the full stream. If you are wrapping a `TokenStream` which requires that the full stream of tokens be exhausted in order to function properly, use the `consumeAllTokens=\"true\"` option.\n+\n+*Factory class:* `solr.LimitTokenCountFilterFactory`\n+\n+*Arguments:*\n+\n+`maxTokenCount`:: (integer, required) Maximum token count. After this limit has been reached, tokens are discarded.\n+\n+`consumeAllTokens`:: (boolean, defaults to false) Whether to consume (and discard) previous token filters' tokens after the maximum token count has been reached. See description above.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.LimitTokenCountFilterFactory\" maxTokenCount=\"10\"\n+          consumeAllTokens=\"false\" />\n+</analyzer>\n+----\n+\n+*In:* \"1 2 3 4 5 6 7 8 9 10 11 12\"\n+\n+*Tokenizer to Filter:* \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"\n+\n+*Out:* \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"\n+\n+[[FilterDescriptions-LimitTokenOffsetFilter]]\n+== Limit Token Offset Filter\n+\n+This filter limits tokens to those before a configured maximum start character offset. This can be useful to limit highlighting, for example.\n+\n+By default, this filter ignores any tokens in the wrapped `TokenStream` once the limit has been reached, which can result in `reset()` being called prior to `incrementToken()` returning `false`. For most `TokenStream` implementations this should be acceptable, and faster then consuming the full stream. If you are wrapping a `TokenStream` which requires that the full stream of tokens be exhausted in order to function properly, use the `consumeAllTokens=\"true\"` option.\n+\n+*Factory class:* `solr.LimitTokenOffsetFilterFactory`\n+\n+*Arguments:*\n+\n+`maxStartOffset`:: (integer, required) Maximum token start character offset. After this limit has been reached, tokens are discarded.\n+\n+`consumeAllTokens`:: (boolean, defaults to false) Whether to consume (and discard) previous token filters' tokens after the maximum start offset has been reached. See description above.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.LimitTokenOffsetFilterFactory\" maxStartOffset=\"10\"\n+          consumeAllTokens=\"false\" />\n+</analyzer>\n+----\n+\n+*In:* \"0 2 4 6 8 A C E\"\n+\n+*Tokenizer to Filter:* \"0\", \"2\", \"4\", \"6\", \"8\", \"A\", \"C\", \"E\"\n+\n+*Out:* \"0\", \"2\", \"4\", \"6\", \"8\", \"A\"\n+\n+[[FilterDescriptions-LimitTokenPositionFilter]]\n+== Limit Token Position Filter\n+\n+This filter limits tokens to those before a configured maximum token position.\n+\n+By default, this filter ignores any tokens in the wrapped `TokenStream` once the limit has been reached, which can result in `reset()` being called prior to `incrementToken()` returning `false`. For most `TokenStream` implementations this should be acceptable, and faster then consuming the full stream. If you are wrapping a `TokenStream` which requires that the full stream of tokens be exhausted in order to function properly, use the `consumeAllTokens=\"true\"` option.\n+\n+*Factory class:* `solr.LimitTokenPositionFilterFactory`\n+\n+*Arguments:*\n+\n+`maxTokenPosition`:: (integer, required) Maximum token position. After this limit has been reached, tokens are discarded.\n+\n+`consumeAllTokens`:: (boolean, defaults to false) Whether to consume (and discard) previous token filters' tokens after the maximum start offset has been reached. See description above.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.LimitTokenPositionFilterFactory\" maxTokenPosition=\"3\"\n+          consumeAllTokens=\"false\" />\n+</analyzer>\n+----\n+\n+*In:* \"1 2 3 4 5\"\n+\n+*Tokenizer to Filter:* \"1\", \"2\", \"3\", \"4\", \"5\"\n+\n+*Out:* \"1\", \"2\", \"3\"\n+\n+[[FilterDescriptions-LowerCaseFilter]]\n+== Lower Case Filter\n+\n+Converts any uppercase letters in a token to the equivalent lowercase token. All other characters are left unchanged.\n+\n+*Factory class:* `solr.LowerCaseFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.LowerCaseFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Down With CamelCase\"\n+\n+*Tokenizer to Filter:* \"Down\", \"With\", \"CamelCase\"\n+\n+*Out:* \"down\", \"with\", \"camelcase\"\n+\n+[[FilterDescriptions-ManagedStopFilter]]\n+== Managed Stop Filter\n+\n+This is specialized version of the <<FilterDescriptions-StopFilter,Stop Words Filter Factory>> that uses a set of stop words that are <<managed-resources.adoc#managed-resources,managed from a REST API.>>\n+\n+*Arguments:*\n+\n+`managed`:: The name that should be used for this set of stop words in the managed REST API.\n+\n+*Example:*\n+//TODO: make this show an actual API call.\n+With this configuration the set of words is named \"english\" and can be managed via `/solr/collection_name/schema/analysis/stopwords/english`\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ManagedStopFilterFactory\" managed=\"english\"/>\n+</analyzer>\n+----\n+\n+See <<FilterDescriptions-StopFilter,Stop Filter>> for example input/output.\n+\n+[[FilterDescriptions-ManagedSynonymFilter]]\n+== Managed Synonym Filter\n+\n+This is specialized version of the <<FilterDescriptions-SynonymFilter,Synonym Filter Factory>> that uses a mapping on synonyms that is <<managed-resources.adoc#managed-resources,managed from a REST API.>>\n+\n+*Arguments:*\n+\n+`managed`:: The name that should be used for this mapping on synonyms in the managed REST API.\n+\n+*Example:*\n+//TODO: make this show an actual API call\n+With this configuration the set of mappings is named \"english\" and can be managed via `/solr/collection_name/schema/analysis/synonyms/english`\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ManagedSynonymFilterFactory\" managed=\"english\"/>\n+</analyzer>\n+----\n+\n+See <<FilterDescriptions-SynonymFilter,Synonym Filter>> for example input/output.\n+\n+[[FilterDescriptions-N-GramFilter]]\n+== N-Gram Filter\n+\n+Generates n-gram tokens of sizes in the given range. Note that tokens are ordered by position and then by gram size.\n+\n+*Factory class:* `solr.NGramFilterFactory`\n+\n+*Arguments:*\n+\n+`minGramSize`:: (integer, default 1) The minimum gram size.\n+\n+`maxGramSize`:: (integer, default 2) The maximum gram size.\n+\n+*Example:*\n+\n+Default behavior.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.NGramFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\"\n+\n+*Out:* \"f\", \"o\", \"u\", \"r\", \"fo\", \"ou\", \"ur\", \"s\", \"c\", \"o\", \"r\", \"e\", \"sc\", \"co\", \"or\", \"re\"\n+\n+*Example:*\n+\n+A range of 1 to 4.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.NGramFilterFactory\" minGramSize=\"1\" maxGramSize=\"4\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\"\n+\n+*Out:* \"f\", \"fo\", \"fou\", \"four\", \"o\", \"ou\", \"our\", \"u\", \"ur\", \"r\", \"s\", \"sc\", \"sco\", \"scor\", \"c\", \"co\", \"cor\", \"core\", \"o\", \"or\", \"ore\", \"r\", \"re\", \"e\"\n+\n+*Example:*\n+\n+A range of 3 to 5.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.NGramFilterFactory\" minGramSize=\"3\" maxGramSize=\"5\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score\"\n+\n+*Tokenizer to Filter:* \"four\", \"score\"\n+\n+*Out:* \"fou\", \"four\", \"our\", \"sco\", \"scor\", \"score\", \"cor\", \"core\", \"ore\"\n+\n+[[FilterDescriptions-NumericPayloadTokenFilter]]\n+== Numeric Payload Token Filter\n+\n+This filter adds a numeric floating point payload value to tokens that match a given type. Refer to the Javadoc for the `org.apache.lucene.analysis.Token` class for more information about token types and payloads.\n+\n+*Factory class:* `solr.NumericPayloadTokenFilterFactory`\n+\n+*Arguments:*\n+\n+`payload`:: (required) A floating point value that will be added to all matching tokens.\n+\n+`typeMatch`:: (required) A token type name string. Tokens with a matching type name will have their payload set to the above floating point value.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.NumericPayloadTokenFilterFactory\" payload=\"0.75\" typeMatch=\"word\"/>\n+</analyzer>\n+----\n+\n+*In:* \"bing bang boom\"\n+\n+*Tokenizer to Filter:* \"bing\", \"bang\", \"boom\"\n+\n+*Out:* \"bing\"[0.75], \"bang\"[0.75], \"boom\"[0.75]\n+\n+[[FilterDescriptions-PatternReplaceFilter]]\n+== Pattern Replace Filter\n+\n+This filter applies a regular expression to each token and, for those that match, substitutes the given replacement string in place of the matched pattern. Tokens which do not match are passed though unchanged.\n+\n+*Factory class:* `solr.PatternReplaceFilterFactory`\n+\n+*Arguments:*\n+\n+`pattern`:: (required) The regular expression to test against each token, as per `java.util.regex.Pattern`.\n+\n+`replacement`:: (required) A string to substitute in place of the matched pattern. This string may contain references to capture groups in the regex pattern. See the Javadoc for `java.util.regex.Matcher`.\n+\n+`replace`:: (\"all\" or \"first\", default \"all\") Indicates whether all occurrences of the pattern in the token should be replaced, or only the first.\n+\n+*Example:*\n+\n+Simple string replace:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PatternReplaceFilterFactory\" pattern=\"cat\" replacement=\"dog\"/>\n+</analyzer>\n+----\n+\n+*In:* \"cat concatenate catycat\"\n+\n+*Tokenizer to Filter:* \"cat\", \"concatenate\", \"catycat\"\n+\n+*Out:* \"dog\", \"condogenate\", \"dogydog\"\n+\n+*Example:*\n+\n+String replacement, first occurrence only:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PatternReplaceFilterFactory\" pattern=\"cat\" replacement=\"dog\" replace=\"first\"/>\n+</analyzer>\n+----\n+\n+*In:* \"cat concatenate catycat\"\n+\n+*Tokenizer to Filter:* \"cat\", \"concatenate\", \"catycat\"\n+\n+*Out:* \"dog\", \"condogenate\", \"dogycat\"\n+\n+*Example:*\n+\n+More complex pattern with capture group reference in the replacement. Tokens that start with non-numeric characters and end with digits will have an underscore inserted before the numbers. Otherwise the token is passed through.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PatternReplaceFilterFactory\" pattern=\"(\\D+)(\\d+)$\" replacement=\"$1_$2\"/>\n+</analyzer>\n+----\n+\n+*In:* \"cat foo1234 9987 blah1234foo\"\n+\n+*Tokenizer to Filter:* \"cat\", \"foo1234\", \"9987\", \"blah1234foo\"\n+\n+*Out:* \"cat\", \"foo_1234\", \"9987\", \"blah1234foo\"\n+\n+[[FilterDescriptions-PhoneticFilter]]\n+== Phonetic Filter\n+\n+This filter creates tokens using one of the phonetic encoding algorithms in the `org.apache.commons.codec.language` package. For more information, see the section on <<phonetic-matching.adoc#phonetic-matching,Phonetic Matching>>.\n+\n+*Factory class:* `solr.PhoneticFilterFactory`\n+\n+*Arguments:*\n+\n+`encoder`:: (required) The name of the encoder to use. The encoder name must be one of the following (case insensitive): `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/DoubleMetaphone.html[DoubleMetaphone]`, `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/Metaphone.html[Metaphone]`, `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/Soundex.html[Soundex]`, `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/RefinedSoundex.html[RefinedSoundex]`, `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/Caverphone.html[Caverphone]` (v2.0), `http://commons.apache.org/codec/apidocs/org/apache/commons/codec/language/ColognePhonetic.html[ColognePhonetic]`, or `http://commons.apache.org/proper/commons-codec/apidocs/org/apache/commons/codec/language/Nysiis.html[Nysiis]`.\n+\n+`inject`:: (true/false) If true (the default), then new phonetic tokens are added to the stream. Otherwise, tokens are replaced with the phonetic equivalent. Setting this to false will enable phonetic matching, but the exact spelling of the target word may not match.\n+\n+`maxCodeLength`:: (integer) The maximum length of the code to be generated by the Metaphone or Double Metaphone encoders.\n+\n+*Example:*\n+\n+Default behavior for DoubleMetaphone encoding.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PhoneticFilterFactory\" encoder=\"DoubleMetaphone\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and twenty\"\n+\n+*Tokenizer to Filter:* \"four\"(1), \"score\"(2), \"and\"(3), \"twenty\"(4)\n+\n+*Out:* \"four\"(1), \"FR\"(1), \"score\"(2), \"SKR\"(2), \"and\"(3), \"ANT\"(3), \"twenty\"(4), \"TNT\"(4)\n+\n+The phonetic tokens have a position increment of 0, which indicates that they are at the same position as the token they were derived from (immediately preceding).\n+\n+*Example:*\n+\n+Discard original token.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PhoneticFilterFactory\" encoder=\"DoubleMetaphone\" inject=\"false\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and twenty\"\n+\n+*Tokenizer to Filter:* \"four\"(1), \"score\"(2), \"and\"(3), \"twenty\"(4)\n+\n+*Out:* \"FR\"(1), \"SKR\"(2), \"ANT\"(3), \"TWNT\"(4)\n+\n+*Example:*\n+\n+Default Soundex encoder.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.PhoneticFilterFactory\" encoder=\"Soundex\"/>\n+</analyzer>\n+----\n+\n+*In:* \"four score and twenty\"\n+\n+*Tokenizer to Filter:* \"four\"(1), \"score\"(2), \"and\"(3), \"twenty\"(4)\n+\n+*Out:* \"four\"(1), \"F600\"(1), \"score\"(2), \"S600\"(2), \"and\"(3), \"A530\"(3), \"twenty\"(4), \"T530\"(4)\n+\n+[[FilterDescriptions-PorterStemFilter]]\n+== Porter Stem Filter\n+\n+This filter applies the Porter Stemming Algorithm for English. The results are similar to using the Snowball Porter Stemmer with the `language=\"English\"` argument. But this stemmer is coded directly in Java and is not based on Snowball. It does not accept a list of protected words and is only appropriate for English language text. However, it has been benchmarked as http://markmail.org/thread/d2c443z63z37rwf6[four times faster] than the English Snowball stemmer, so can provide a performance enhancement.\n+\n+*Factory class:* `solr.PorterStemFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory \"/>\n+  <filter class=\"solr.PorterStemFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"jump jumping jumped\"\n+\n+*Tokenizer to Filter:* \"jump\", \"jumping\", \"jumped\"\n+\n+*Out:* \"jump\", \"jump\", \"jump\"\n+\n+[[FilterDescriptions-RemoveDuplicatesTokenFilter]]\n+== Remove Duplicates Token Filter\n+\n+The filter removes duplicate tokens in the stream. Tokens are considered to be duplicates ONLY if they have the same text and position values.\n+\n+Because positions must be the same, this filter might not do what a user expects it to do based on its name. It is a very specialized filter that is only useful in very specific circumstances. It has been so named for brevity, even though it is potentially misleading.\n+\n+*Factory class:* `solr.RemoveDuplicatesTokenFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+One example of where `RemoveDuplicatesTokenFilterFactory` is useful in situations where a synonym file is being used in conjunction with a stemmer. In these situations, both the stemmer and the synonym filter can cause completely identical terms with the same positions to end up in the stream, increasing index size with no benefit.\n+\n+Consider the following entry from a `synonyms.txt` file:\n+\n+[source,text]\n+----\n+ Television, Televisions, TV, TVs\n+----\n+\n+When used in the following configuration:\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"synonyms.txt\"/>\n+  <filter class=\"solr.EnglishMinimalStemFilterFactory\"/>\n+  <filter class=\"solr.RemoveDuplicatesTokenFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Watch TV\"\n+\n+*Tokenizer to Synonym Filter:* \"Watch\"(1) \"TV\"(2)\n+\n+*Synonym Filter to Stem Filter:* \"Watch\"(1) \"Television\"(2) \"Televisions\"(2) \"TV\"(2) \"TVs\"(2)\n+\n+*Stem Filter to Remove Dups Filter:* \"Watch\"(1) \"Television\"(2) \"Television\"(2) \"TV\"(2) \"TV\"(2)\n+\n+*Out:* \"Watch\"(1) \"Television\"(2) \"TV\"(2)\n+\n+== Reversed Wildcard Filter\n+\n+This filter reverses tokens to provide faster leading wildcard and prefix queries. Tokens without wildcards are not reversed.\n+\n+*Factory class:* `solr.ReversedWildcardFilterFactory`\n+\n+*Arguments:*\n+\n+`withOriginal`:: (boolean) If true, the filter produces both original and reversed tokens at the same positions. If false, produces only reversed tokens.\n+\n+`maxPosAsterisk`:: (integer, default = 2) The maximum position of the asterisk wildcard ('*') that triggers the reversal of the query term. Terms with asterisks at positions above this value are not reversed.\n+\n+`maxPosQuestion`:: (integer, default = 1) The maximum position of the question mark wildcard ('?') that triggers the reversal of query term. To reverse only pure suffix queries (queries with a single leading asterisk), set this to 0 and `maxPosAsterisk` to 1.\n+\n+`maxFractionAsterisk`:: (float, default = 0.0) An additional parameter that triggers the reversal if asterisk ('*') position is less than this fraction of the query token length.\n+\n+`minTrailing`:: (integer, default = 2) The minimum number of trailing characters in a query token after the last wildcard character. For good performance this should be set to a value larger than 1.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.ReversedWildcardFilterFactory\" withOriginal=\"true\"\n+    maxPosAsterisk=\"2\" maxPosQuestion=\"1\" minTrailing=\"2\" maxFractionAsterisk=\"0\"/>\n+</analyzer>\n+----\n+\n+*In:* \"*foo *bar\"\n+\n+*Tokenizer to Filter:* \"*foo\", \"*bar\"\n+\n+*Out:* \"oof*\", \"rab*\"\n+\n+[[FilterDescriptions-ShingleFilter]]\n+== Shingle Filter\n+\n+This filter constructs shingles, which are token n-grams, from the token stream. It combines runs of tokens into a single token.\n+\n+*Factory class:* `solr.ShingleFilterFactory`\n+\n+*Arguments:*\n+\n+`minShingleSize`:: (integer, must be >= 2, default 2) The minimum number of tokens per shingle.\n+\n+`maxShingleSize`:: (integer, must be >= `minShingleSize`, default 2) The maximum number of tokens per shingle.\n+\n+`outputUnigrams`:: (boolean, default true) If true, then each individual token is also included at its original position.\n+\n+`outputUnigramsIfNoShingles`:: (boolean, default false) If true, then individual tokens will be output if no shingles are possible.\n+\n+`tokenSeparator`:: (string, default is \" \") The string to use when joining adjacent tokens to form a shingle.\n+\n+*Example:*\n+\n+Default behavior.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ShingleFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"To be, or what?\"\n+\n+*Tokenizer to Filter:* \"To\"(1), \"be\"(2), \"or\"(3), \"what\"(4)\n+\n+*Out:* \"To\"(1), \"To be\"(1), \"be\"(2), \"be or\"(2), \"or\"(3), \"or what\"(3), \"what\"(4)\n+\n+*Example:*\n+\n+A shingle size of four, do not include original token.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.ShingleFilterFactory\" maxShingleSize=\"4\" outputUnigrams=\"false\"/>\n+</analyzer>\n+----\n+\n+*In:* \"To be, or not to be.\"\n+\n+*Tokenizer to Filter:* \"To\"(1), \"be\"(2), \"or\"(3), \"not\"(4), \"to\"(5), \"be\"(6)\n+\n+*Out:* \"To be\"(1), \"To be or\"(1), \"To be or not\"(1), \"be or\"(2), \"be or not\"(2), \"be or not to\"(2), \"or not\"(3), \"or not to\"(3), \"or not to be\"(3), \"not to\"(4), \"not to be\"(4), \"to be\"(5)\n+\n+[[FilterDescriptions-SnowballPorterStemmerFilter]]\n+== Snowball Porter Stemmer Filter\n+\n+This filter factory instantiates a language-specific stemmer generated by Snowball. Snowball is a software package that generates pattern-based word stemmers. This type of stemmer is not as accurate as a table-based stemmer, but is faster and less complex. Table-driven stemmers are labor intensive to create and maintain and so are typically commercial products.\n+\n+Solr contains Snowball stemmers for Armenian, Basque, Catalan, Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish and Turkish. For more information on Snowball, visit http://snowball.tartarus.org/.\n+\n+`StopFilterFactory`, `CommonGramsFilterFactory`, and `CommonGramsQueryFilterFactory` can optionally read stopwords in Snowball format (specify `format=\"snowball\"` in the configuration of those FilterFactories).\n+\n+*Factory class:* `solr.SnowballPorterFilterFactory`\n+\n+*Arguments:*\n+\n+`language`:: (default \"English\") The name of a language, used to select the appropriate Porter stemmer to use. Case is significant. This string is used to select a package name in the `org.tartarus.snowball.ext` class hierarchy.\n+\n+`protected`:: Path of a text file containing a list of protected words, one per line. Protected words will not be stemmed. Blank lines and lines that begin with \"#\" are ignored. This may be an absolute path, or a simple file name in the Solr `conf` directory.\n+\n+*Example:*\n+\n+Default behavior:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SnowballPorterFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"flip flipped flipping\"\n+\n+*Tokenizer to Filter:* \"flip\", \"flipped\", \"flipping\"\n+\n+*Out:* \"flip\", \"flip\", \"flip\"\n+\n+*Example:*\n+\n+French stemmer, English words:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SnowballPorterFilterFactory\" language=\"French\"/>\n+</analyzer>\n+----\n+\n+*In:* \"flip flipped flipping\"\n+\n+*Tokenizer to Filter:* \"flip\", \"flipped\", \"flipping\"\n+\n+*Out:* \"flip\", \"flipped\", \"flipping\"\n+\n+*Example:*\n+\n+Spanish stemmer, Spanish words:\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SnowballPorterFilterFactory\" language=\"Spanish\"/>\n+</analyzer>\n+----\n+\n+*In:* \"cante canta\"\n+\n+*Tokenizer to Filter:* \"cante\", \"canta\"\n+\n+*Out:* \"cant\", \"cant\"\n+\n+[[FilterDescriptions-StandardFilter]]\n+== Standard Filter\n+\n+This filter removes dots from acronyms and the substring \"'s\" from the end of tokens. This filter depends on the tokens being tagged with the appropriate term-type to recognize acronyms and words with apostrophes.\n+\n+*Factory class:* `solr.StandardFilterFactory`\n+\n+*Arguments:* None\n+\n+[WARNING]\n+====\n+This filter is no longer operational in Solr when the `luceneMatchVersion` (in `solrconfig.xml`) is higher than \"3.1\".\n+====\n+\n+[[FilterDescriptions-StopFilter]]\n+== Stop Filter\n+\n+This filter discards, or _stops_ analysis of, tokens that are on the given stop words list. A standard stop words list is included in the Solr `conf` directory, named `stopwords.txt`, which is appropriate for typical English language text.\n+\n+*Factory class:* `solr.StopFilterFactory`\n+\n+*Arguments:*\n+\n+`words`:: (optional) The path to a file that contains a list of stop words, one per line. Blank lines and lines that begin with \"#\" are ignored. This may be an absolute path, or path relative to the Solr `conf` directory.\n+\n+`format`:: (optional) If the stopwords list has been formatted for Snowball, you can specify `format=\"snowball\"` so Solr can read the stopwords file.\n+\n+`ignoreCase`:: (true/false, default false) Ignore case when testing for stop words. If true, the stop list should contain lowercase words.\n+\n+`enablePositionIncrements`:: if `luceneMatchVersion` is `4.4` or earlier and `enablePositionIncrements=\"false\"`, no position holes will be left by this filter when it removes tokens. *This argument is invalid if `luceneMatchVersion` is `5.0` or later.*\n+\n+*Example:*\n+\n+Case-sensitive matching, capitalized words not stopped. Token positions skip stopped words.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\"/>\n+</analyzer>\n+----\n+\n+*In:* \"To be or what?\"\n+\n+*Tokenizer to Filter:* \"To\"(1), \"be\"(2), \"or\"(3), \"what\"(4)\n+\n+*Out:* \"To\"(1), \"what\"(4)\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n+</analyzer>\n+----\n+\n+*In:* \"To be or what?\"\n+\n+*Tokenizer to Filter:* \"To\"(1), \"be\"(2), \"or\"(3), \"what\"(4)\n+\n+*Out:* \"what\"(4)\n+\n+[[FilterDescriptions-SuggestStopFilter]]\n+== Suggest Stop Filter\n+\n+Like <<FilterDescriptions-StopFilter,Stop Filter>>, this filter discards, or _stops_ analysis of, tokens that are on the given stop words list.\n+\n+Suggest Stop Filter differs from Stop Filter in that it will not remove the last token unless it is followed by a token separator. For example, a query \"`find the`\" would preserve the '`the`' since it was not followed by a space, punctuation etc., and mark it as a `KEYWORD` so that following filters will not change or remove it.\n+\n+By contrast, a query like \"`find the popsicle`\" would remove \"```the```\" as a stopword, since it's followed by a space. When using one of the analyzing suggesters, you would normally use the ordinary `StopFilterFactory` in your index analyzer and then SuggestStopFilter in your query analyzer.\n+\n+*Factory class:* `solr.SuggestStopFilterFactory`\n+\n+*Arguments:*\n+\n+`words`:: (optional; default: {lucene-javadocs}/analyzers-common/org/apache/lucene/analysis/core/StopAnalyzer.html[`StopAnalyzer#ENGLISH_STOP_WORDS_SET`] ) The name of a stopwords file to parse.\n+\n+`format`:: (optional; default: `wordset`) Defines how the words file will be parsed. If `words` is not specified, then `format` must not be specified. The valid values for the format option are:\n+\n+`wordset`:: This is the default format, which supports one word per line (including any intra-word whitespace) and allows whole line comments begining with the `#` character. Blank lines are ignored.\n+\n+`snowball`:: This format allows for multiple words specified on each line, and trailing comments may be specified using the vertical line (`|`). Blank lines are ignored.\n+\n+`ignoreCase`:: (optional; default: *false*) If *true*, matching is case-insensitive.\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.LowerCaseFilterFactory\"/>\n+  <filter class=\"solr.SuggestStopFilterFactory\" ignoreCase=\"true\"\n+          words=\"stopwords.txt\" format=\"wordset\"/>\n+</analyzer>\n+----\n+\n+*In:* \"The The\"\n+\n+*Tokenizer to Filter:* \"the\"(1), \"the\"(2)\n+\n+*Out:* \"the\"(2)\n+\n+[[FilterDescriptions-SynonymFilter]]\n+== Synonym Filter\n+\n+This filter does synonym mapping. Each token is looked up in the list of synonyms and if a match is found, then the synonym is emitted in place of the token. The position value of the new tokens are set such they all occur at the same position as the original token.\n+\n+.Synonym Filter has been Deprecated\n+[WARNING]\n+====\n+Synonym Filter has been deprecated in favor of Synonym Graph Filter, which is required for multi-term synonym support.\n+====\n+\n+*Factory class:* `solr.SynonymFilterFactory`\n+\n+For arguments and examples, see the Synonym Graph Filter below.\n+\n+[[FilterDescriptions-SynonymGraphFilter]]\n+== Synonym Graph Filter\n+\n+This filter maps single- or multi-token synonyms, producing a fully correct graph output. This filter is a replacement for the Synonym Filter, which produces incorrect graphs for multi-token synonyms.\n+\n+If you use this filter during indexing, you must follow it with a Flatten Graph Filter to squash tokens on top of one another like the Synonym Filter, because the indexer can't directly consume a graph. To get fully correct positional queries when your synonym replacements are multiple tokens, you should instead apply synonyms using this filter at query time.\n+\n+*Factory class:* `solr.SynonymGraphFilterFactory`\n+\n+*Arguments:*\n+\n+`synonyms`:: (required) The path of a file that contains a list of synonyms, one per line. In the (default) `solr` format - see the `format` argument below for alternatives - blank lines and lines that begin with \"`#`\" are ignored. This may be a comma-separated list of absolute paths, or paths relative to the Solr config directory.\n++\n+There are two ways to specify synonym mappings:\n++\n+* A comma-separated list of words. If the token matches any of the words, then all the words in the list are substituted, which will include the original token.\n++\n+* Two comma-separated lists of words with the symbol \"=>\" between them. If the token matches any word on the left, then the list on the right is substituted. The original token will not be included unless it is also in the list on the right.\n+\n+`ignoreCase`:: (optional; default: `false`) If `true`, synonyms will be matched case-insensitively.\n+\n+`expand`:: (optional; default: `true`) If `true`, a synonym will be expanded to all equivalent synonyms. If `false`, all equivalent synonyms will be reduced to the first in the list.\n+\n+`format`:: (optional; default: `solr`) Controls how the synonyms will be parsed. The short names `solr` (for {lucene-javadocs}/analyzers-common/org/apache/lucene/analysis/synonym/SolrSynonymParser.html[`SolrSynonymParser)`] and `wordnet` (for {lucene-javadocs}/analyzers-common/org/apache/lucene/analysis/synonym/WordnetSynonymParser.html[`WordnetSynonymParser`] ) are supported, or you may alternatively supply the name of your own {lucene-javadocs}/analyzers-common/org/apache/lucene/analysis/synonym/SynonymMap.Builder.html[`SynonymMap.Builder`] subclass.\n+\n+`tokenizerFactory`:: (optional; default: `WhitespaceTokenizerFactory`) The name of the tokenizer factory to use when parsing the synonyms file. Arguments with the name prefix `tokenizerFactory.*` will be supplied as init params to the specified tokenizer factory.\n++\n+Any arguments not consumed by the synonym filter factory, including those without the `tokenizerFactory.*` prefix, will also be supplied as init params to the tokenizer factory.\n++\n+If `tokenizerFactory` is specified, then `analyzer` may not be, and vice versa.\n+\n+`analyzer`:: (optional; default: `WhitespaceTokenizerFactory`) The name of the analyzer class to use when parsing the synonyms file. If `analyzer` is specified, then `tokenizerFactory` may not be, and vice versa.\n+\n+For the following examples, assume a synonyms file named `mysynonyms.txt`:\n+\n+[source,text]\n+----\n+couch,sofa,divan\n+teh => the\n+huge,ginormous,humungous => large\n+small => tiny,teeny,weeny\n+----\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"mysynonyms.txt\"/>\n+  <filter class=\"solr.FlattenGraphFilterFactory\"/> <!-- required on index analyzers after graph filters -->\n+</analyzer>\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n+  <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"mysynonyms.txt\"/>\n+</analyzer>\n+----\n+\n+*In:* \"teh small couch\"\n+\n+*Tokenizer to Filter:* \"teh\"(1), \"small\"(2), \"couch\"(3)\n+\n+*Out:* \"the\"(1), \"tiny\"(2), \"teeny\"(2), \"weeny\"(2), \"couch\"(3), \"sofa\"(3), \"divan\"(3)\n+\n+*Example:*\n+\n+*In:* \"teh ginormous, humungous sofa\"\n+\n+*Tokenizer to Filter:* \"teh\"(1), \"ginormous\"(2), \"humungous\"(3), \"sofa\"(4)\n+\n+*Out:* \"the\"(1), \"large\"(2), \"large\"(3), \"couch\"(4), \"sofa\"(4), \"divan\"(4)\n+\n+[[FilterDescriptions-TokenOffsetPayloadFilter]]\n+== Token Offset Payload Filter\n+\n+This filter adds the numeric character offsets of the token as a payload value for that token.\n+\n+*Factory class:* `solr.TokenOffsetPayloadTokenFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.TokenOffsetPayloadTokenFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"bing bang boom\"\n+\n+*Tokenizer to Filter:* \"bing\", \"bang\", \"boom\"\n+\n+*Out:* \"bing\"[0,4], \"bang\"[5,9], \"boom\"[10,14]\n+\n+[[FilterDescriptions-TrimFilter]]\n+== Trim Filter\n+\n+This filter trims leading and/or trailing whitespace from tokens. Most tokenizers break tokens at whitespace, so this filter is most often used for special situations.\n+\n+*Factory class:* `solr.TrimFilterFactory`\n+\n+*Arguments:*\n+\n+`updateOffsets`:: if `luceneMatchVersion` is `4.3` or earlier and `updateOffsets=\"true\"`, trimmed tokens' start and end offsets will be updated to those of the first and last characters (plus one) remaining in the token. *This argument is invalid if `luceneMatchVersion` is `5.0` or later.*\n+\n+*Example:*\n+\n+The PatternTokenizerFactory configuration used here splits the input on simple commas, it does not remove whitespace.\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.PatternTokenizerFactory\" pattern=\",\"/>\n+  <filter class=\"solr.TrimFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"one, two , three ,four \"\n+\n+*Tokenizer to Filter:* \"one\", \" two \", \" three \", \"four \"\n+\n+*Out:* \"one\", \"two\", \"three\", \"four\"\n+\n+[[FilterDescriptions-TypeAsPayloadFilter]]\n+== Type As Payload Filter\n+\n+This filter adds the token's type, as an encoded byte sequence, as its payload.\n+\n+*Factory class:* `solr.TypeAsPayloadTokenFilterFactory`\n+\n+*Arguments:* None\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.TypeAsPayloadTokenFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"Pay Bob's I.O.U.\"\n+\n+*Tokenizer to Filter:* \"Pay\", \"Bob's\", \"I.O.U.\"\n+\n+*Out:* \"Pay\"[<ALPHANUM>], \"Bob's\"[<APOSTROPHE>], \"I.O.U.\"[<ACRONYM>]\n+\n+[[FilterDescriptions-TypeTokenFilter]]\n+== Type Token Filter\n+\n+This filter blacklists or whitelists a specified list of token types, assuming the tokens have type metadata associated with them. For example, the <<tokenizers.adoc#Tokenizers-UAX29URLEmailTokenizer,UAX29 URL Email Tokenizer>> emits \"<URL>\" and \"<EMAIL>\" typed tokens, as well as other types. This filter would allow you to pull out only e-mail addresses from text as tokens, if you wish.\n+\n+*Factory class:* `solr.TypeTokenFilterFactory`\n+\n+*Arguments:*\n+\n+`types`:: Defines the location of a file of types to filter.\n+\n+`useWhitelist`:: If *true*, the file defined in `types` should be used as include list. If *false*, or undefined, the file defined in `types` is used as a blacklist.\n+\n+`enablePositionIncrements`:: if `luceneMatchVersion` is `4.3` or earlier and `enablePositionIncrements=\"false\"`, no position holes will be left by this filter when it removes tokens. *This argument is invalid if `luceneMatchVersion` is `5.0` or later.*\n+\n+*Example:*\n+\n+[source,xml]\n+----\n+<analyzer>\n+  <filter class=\"solr.TypeTokenFilterFactory\" types=\"stoptypes.txt\" useWhitelist=\"true\"/>\n+</analyzer>\n+----\n+\n+[[FilterDescriptions-WordDelimiterFilter]]\n+== Word Delimiter Filter\n+\n+This filter splits tokens at word delimiters.\n+\n+.Word Delimiter Filter has been Deprecated\n+[WARNING]\n+====\n+Word Delimiter Filter has been deprecated in favor of Word Delimiter Graph Filter, which is required to produce a correct token graph so that e.g. phrase queries can work correctly.\n+====\n+\n+*Factory class:* `solr.WordDelimiterFilterFactory`\n+\n+For a full description, including arguments and examples, see the Word Delimiter Graph Filter below.\n+\n+[[FilterDescriptions-WordDelimiterGraphFilter]]\n+== Word Delimiter Graph Filter\n+\n+This filter splits tokens at word delimiters.\n+\n+If you use this filter during indexing, you must follow it with a Flatten Graph Filter to squash tokens on top of one another like the Word Delimiter Filter, because the indexer can't directly consume a graph. To get fully correct positional queries when tokens are split, you should instead use this filter at query time.\n+\n+Note: although this filter produces correct token graphs, it cannot consume an input token graph correctly.\n+\n+The rules for determining delimiters are determined as follows:\n+\n+* A change in case within a word: \"CamelCase\" -> \"Camel\", \"Case\". This can be disabled by setting `splitOnCaseChange=\"0\"`.\n+\n+* A transition from alpha to numeric characters or vice versa: \"Gonzo5000\" -> \"Gonzo\", \"5000\" \"4500XL\" -> \"4500\", \"XL\". This can be disabled by setting `splitOnNumerics=\"0\"`.\n+\n+* Non-alphanumeric characters (discarded): \"hot-spot\" -> \"hot\", \"spot\"\n+\n+* A trailing \"'s\" is removed: \"O'Reilly's\" -> \"O\", \"Reilly\"\n+\n+* Any leading or trailing delimiters are discarded: \"--hot-spot--\" -> \"hot\", \"spot\"\n+\n+*Factory class:* `solr.WordDelimiterGraphFilterFactory`\n+\n+*Arguments:*\n+\n+`generateWordParts`:: (integer, default 1) If non-zero, splits words at delimiters. For example:\"CamelCase\", \"hot-spot\" -> \"Camel\", \"Case\", \"hot\", \"spot\"\n+\n+`generateNumberParts`:: (integer, default 1) If non-zero, splits numeric strings at delimiters:\"1947-32\" ->*\"1947\", \"32\"\n+\n+`splitOnCaseChange`:: (integer, default 1) If 0, words are not split on camel-case changes:\"BugBlaster-XL\" -> \"BugBlaster\", \"XL\". Example 1 below illustrates the default (non-zero) splitting behavior.\n+\n+`splitOnNumerics`:: (integer, default 1) If 0, don't split words on transitions from alpha to numeric:\"FemBot3000\" -> \"Fem\", \"Bot3000\"\n+\n+`catenateWords`:: (integer, default 0) If non-zero, maximal runs of word parts will be joined: \"hot-spot-sensor's\" -> \"hotspotsensor\"\n+\n+`catenateNumbers`:: (integer, default 0) If non-zero, maximal runs of number parts will be joined: 1947-32\" -> \"194732\"\n+\n+`catenateAll`:: (0/1, default 0) If non-zero, runs of word and number parts will be joined: \"Zap-Master-9000\" -> \"ZapMaster9000\"\n+\n+`preserveOriginal`:: (integer, default 0) If non-zero, the original token is preserved: \"Zap-Master-9000\" -> \"Zap-Master-9000\", \"Zap\", \"Master\", \"9000\"\n+\n+`protected`:: (optional) The pathname of a file that contains a list of protected words that should be passed through without splitting.\n+\n+`stemEnglishPossessive`:: (integer, default 1) If 1, strips the possessive `'s` from each subword.\n+\n+`types`:: (optional) The pathname of a file that contains *character => type* mappings, which enable customization of this filter's splitting behavior. Recognized character types: `LOWER`, `UPPER`, `ALPHA`, `DIGIT`, `ALPHANUM`, and `SUBWORD_DELIM`.\n++\n+The default for any character without a customized mapping is computed from Unicode character properties. Blank lines and comment lines starting with '#' are ignored. An example file:\n++\n+[source,text]\n+----\n+# Don't split numbers at '$', '.' or ','\n+$ => DIGIT\n+. => DIGIT\n+\\u002C => DIGIT\n+\n+# Don't split on ZWJ: http://en.wikipedia.org/wiki/Zero-width_joiner\n+\\u200D => ALPHANUM\n+----\n+\n+*Example:*\n+\n+Default behavior. The whitespace tokenizer is used here to preserve non-alphanumeric characters.\n+\n+[source,xml]\n+----\n+<analyzer type=\"index\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\"/>\n+  <filter class=\"solr.FlattenGraphFilterFactory\"/> <!-- required on index analyzers after graph filters -->\n+</analyzer>\n+\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\"/>\n+</analyzer>\n+----\n+\n+*In:* \"hot-spot RoboBlaster/9000 100XL\"\n+\n+*Tokenizer to Filter:* \"hot-spot\", \"RoboBlaster/9000\", \"100XL\"\n+\n+*Out:* \"hot\", \"spot\", \"Robo\", \"Blaster\", \"9000\", \"100\", \"XL\"\n+\n+*Example:*\n+\n+Do not split on case changes, and do not generate number parts. Note that by not generating number parts, tokens containing only numeric parts are ultimately discarded.\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\" generateNumberParts=\"0\" splitOnCaseChange=\"0\"/>\n+</analyzer>\n+----\n+\n+*In:* \"hot-spot RoboBlaster/9000 100-42\"\n+\n+*Tokenizer to Filter:* \"hot-spot\", \"RoboBlaster/9000\", \"100-42\"\n+\n+*Out:* \"hot\", \"spot\", \"RoboBlaster\", \"9000\"\n+\n+*Example:*\n+\n+Concatenate word parts and number parts, but not word and number parts that occur in the same token.\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\" catenateWords=\"1\" catenateNumbers=\"1\"/>\n+</analyzer>\n+----\n+\n+*In:* \"hot-spot 100+42 XL40\"\n+\n+*Tokenizer to Filter:* \"hot-spot\"(1), \"100+42\"(2), \"XL40\"(3)\n+\n+*Out:* \"hot\"(1), \"spot\"(2), \"hotspot\"(2), \"100\"(3), \"42\"(4), \"10042\"(4), \"XL\"(5), \"40\"(6)\n+\n+*Example:*\n+\n+Concatenate all. Word and/or number parts are joined together.\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\" catenateAll=\"1\"/>\n+</analyzer>\n+----\n+\n+*In:* \"XL-4000/ES\"\n+\n+*Tokenizer to Filter:* \"XL-4000/ES\"(1)\n+\n+*Out:* \"XL\"(1), \"4000\"(2), \"ES\"(3), \"XL4000ES\"(3)\n+\n+*Example:*\n+\n+Using a protected words list that contains \"AstroBlaster\" and \"XL-5000\" (among others).\n+\n+[source,xml]\n+----\n+<analyzer type=\"query\">\n+  <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n+  <filter class=\"solr.WordDelimiterGraphFilterFactory\" protected=\"protwords.txt\"/>\n+</analyzer>\n+----\n+\n+*In:* \"FooBar AstroBlaster XL-5000 ==ES-34-\"\n+\n+*Tokenizer to Filter:* \"FooBar\", \"AstroBlaster\", \"XL-5000\", \"==ES-34-\"\n+\n+*Out:* \"FooBar\", \"FooBar\", \"AstroBlaster\", \"XL-5000\", \"ES\", \"34\"",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/filter-descriptions.adoc",
                "sha": "f4c8e259a0007d654d8e6eb1da86ae1ea40cdf89",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Bold.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Bold.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Bold.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Bold.ttf",
                "sha": "809c1f5828f86235347019a50e78b4b486a6a045",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Regular.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Regular.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Regular.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/Inconsolata-Regular.ttf",
                "sha": "fc981ce7ad6c42d2384f0ef74b73174b9302ee65",
                "status": "added"
            },
            {
                "additions": 92,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/OFL.txt",
                "changes": 92,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Inconsolata/OFL.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Inconsolata/OFL.txt",
                "patch": "@@ -0,0 +1,92 @@\n+Copyright 2006 The Inconsolata Project Authors\r\n+This Font Software is licensed under the SIL Open Font License, Version 1.1.\r\n+This license is copied below, and is also available with a FAQ at:\r\n+http://scripts.sil.org/OFL\r\n+\r\n+\r\n+-----------------------------------------------------------\r\n+SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007\r\n+-----------------------------------------------------------\r\n+\r\n+PREAMBLE\r\n+The goals of the Open Font License (OFL) are to stimulate worldwide\r\n+development of collaborative font projects, to support the font creation\r\n+efforts of academic and linguistic communities, and to provide a free and\r\n+open framework in which fonts may be shared and improved in partnership\r\n+with others.\r\n+\r\n+The OFL allows the licensed fonts to be used, studied, modified and\r\n+redistributed freely as long as they are not sold by themselves. The\r\n+fonts, including any derivative works, can be bundled, embedded, \r\n+redistributed and/or sold with any software provided that any reserved\r\n+names are not used by derivative works. The fonts and derivatives,\r\n+however, cannot be released under any other type of license. The\r\n+requirement for fonts to remain under this license does not apply\r\n+to any document created using the fonts or their derivatives.\r\n+\r\n+DEFINITIONS\r\n+\"Font Software\" refers to the set of files released by the Copyright\r\n+Holder(s) under this license and clearly marked as such. This may\r\n+include source files, build scripts and documentation.\r\n+\r\n+\"Reserved Font Name\" refers to any names specified as such after the\r\n+copyright statement(s).\r\n+\r\n+\"Original Version\" refers to the collection of Font Software components as\r\n+distributed by the Copyright Holder(s).\r\n+\r\n+\"Modified Version\" refers to any derivative made by adding to, deleting,\r\n+or substituting -- in part or in whole -- any of the components of the\r\n+Original Version, by changing formats or by porting the Font Software to a\r\n+new environment.\r\n+\r\n+\"Author\" refers to any designer, engineer, programmer, technical\r\n+writer or other person who contributed to the Font Software.\r\n+\r\n+PERMISSION & CONDITIONS\r\n+Permission is hereby granted, free of charge, to any person obtaining\r\n+a copy of the Font Software, to use, study, copy, merge, embed, modify,\r\n+redistribute, and sell modified and unmodified copies of the Font\r\n+Software, subject to the following conditions:\r\n+\r\n+1) Neither the Font Software nor any of its individual components,\r\n+in Original or Modified Versions, may be sold by itself.\r\n+\r\n+2) Original or Modified Versions of the Font Software may be bundled,\r\n+redistributed and/or sold with any software, provided that each copy\r\n+contains the above copyright notice and this license. These can be\r\n+included either as stand-alone text files, human-readable headers or\r\n+in the appropriate machine-readable metadata fields within text or\r\n+binary files as long as those fields can be easily viewed by the user.\r\n+\r\n+3) No Modified Version of the Font Software may use the Reserved Font\r\n+Name(s) unless explicit written permission is granted by the corresponding\r\n+Copyright Holder. This restriction only applies to the primary font name as\r\n+presented to the users.\r\n+\r\n+4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font\r\n+Software shall not be used to promote, endorse or advertise any\r\n+Modified Version, except to acknowledge the contribution(s) of the\r\n+Copyright Holder(s) and the Author(s) or with their explicit written\r\n+permission.\r\n+\r\n+5) The Font Software, modified or unmodified, in part or in whole,\r\n+must be distributed entirely under this license, and must not be\r\n+distributed under any other license. The requirement for fonts to\r\n+remain under this license does not apply to any document created\r\n+using the Font Software.\r\n+\r\n+TERMINATION\r\n+This license becomes null and void if any of the above conditions are\r\n+not met.\r\n+\r\n+DISCLAIMER\r\n+THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n+EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF\r\n+MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT\r\n+OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE\r\n+COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\r\n+INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL\r\n+DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\n+FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM\r\n+OTHER DEALINGS IN THE FONT SOFTWARE.\r",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Inconsolata/OFL.txt",
                "sha": "6078b5ee828dcb5eae49dddd2e3628d73fd3bb02",
                "status": "added"
            },
            {
                "additions": 202,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/LICENSE.txt",
                "changes": 202,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Noto_Sans/LICENSE.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Noto_Sans/LICENSE.txt",
                "patch": "@@ -0,0 +1,202 @@\n+\r\n+                                 Apache License\r\n+                           Version 2.0, January 2004\r\n+                        http://www.apache.org/licenses/\r\n+\r\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\r\n+\r\n+   1. Definitions.\r\n+\r\n+      \"License\" shall mean the terms and conditions for use, reproduction,\r\n+      and distribution as defined by Sections 1 through 9 of this document.\r\n+\r\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\r\n+      the copyright owner that is granting the License.\r\n+\r\n+      \"Legal Entity\" shall mean the union of the acting entity and all\r\n+      other entities that control, are controlled by, or are under common\r\n+      control with that entity. For the purposes of this definition,\r\n+      \"control\" means (i) the power, direct or indirect, to cause the\r\n+      direction or management of such entity, whether by contract or\r\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\r\n+      outstanding shares, or (iii) beneficial ownership of such entity.\r\n+\r\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\r\n+      exercising permissions granted by this License.\r\n+\r\n+      \"Source\" form shall mean the preferred form for making modifications,\r\n+      including but not limited to software source code, documentation\r\n+      source, and configuration files.\r\n+\r\n+      \"Object\" form shall mean any form resulting from mechanical\r\n+      transformation or translation of a Source form, including but\r\n+      not limited to compiled object code, generated documentation,\r\n+      and conversions to other media types.\r\n+\r\n+      \"Work\" shall mean the work of authorship, whether in Source or\r\n+      Object form, made available under the License, as indicated by a\r\n+      copyright notice that is included in or attached to the work\r\n+      (an example is provided in the Appendix below).\r\n+\r\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\r\n+      form, that is based on (or derived from) the Work and for which the\r\n+      editorial revisions, annotations, elaborations, or other modifications\r\n+      represent, as a whole, an original work of authorship. For the purposes\r\n+      of this License, Derivative Works shall not include works that remain\r\n+      separable from, or merely link (or bind by name) to the interfaces of,\r\n+      the Work and Derivative Works thereof.\r\n+\r\n+      \"Contribution\" shall mean any work of authorship, including\r\n+      the original version of the Work and any modifications or additions\r\n+      to that Work or Derivative Works thereof, that is intentionally\r\n+      submitted to Licensor for inclusion in the Work by the copyright owner\r\n+      or by an individual or Legal Entity authorized to submit on behalf of\r\n+      the copyright owner. For the purposes of this definition, \"submitted\"\r\n+      means any form of electronic, verbal, or written communication sent\r\n+      to the Licensor or its representatives, including but not limited to\r\n+      communication on electronic mailing lists, source code control systems,\r\n+      and issue tracking systems that are managed by, or on behalf of, the\r\n+      Licensor for the purpose of discussing and improving the Work, but\r\n+      excluding communication that is conspicuously marked or otherwise\r\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\r\n+\r\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\r\n+      on behalf of whom a Contribution has been received by Licensor and\r\n+      subsequently incorporated within the Work.\r\n+\r\n+   2. Grant of Copyright License. Subject to the terms and conditions of\r\n+      this License, each Contributor hereby grants to You a perpetual,\r\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\r\n+      copyright license to reproduce, prepare Derivative Works of,\r\n+      publicly display, publicly perform, sublicense, and distribute the\r\n+      Work and such Derivative Works in Source or Object form.\r\n+\r\n+   3. Grant of Patent License. Subject to the terms and conditions of\r\n+      this License, each Contributor hereby grants to You a perpetual,\r\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\r\n+      (except as stated in this section) patent license to make, have made,\r\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\r\n+      where such license applies only to those patent claims licensable\r\n+      by such Contributor that are necessarily infringed by their\r\n+      Contribution(s) alone or by combination of their Contribution(s)\r\n+      with the Work to which such Contribution(s) was submitted. If You\r\n+      institute patent litigation against any entity (including a\r\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\r\n+      or a Contribution incorporated within the Work constitutes direct\r\n+      or contributory patent infringement, then any patent licenses\r\n+      granted to You under this License for that Work shall terminate\r\n+      as of the date such litigation is filed.\r\n+\r\n+   4. Redistribution. You may reproduce and distribute copies of the\r\n+      Work or Derivative Works thereof in any medium, with or without\r\n+      modifications, and in Source or Object form, provided that You\r\n+      meet the following conditions:\r\n+\r\n+      (a) You must give any other recipients of the Work or\r\n+          Derivative Works a copy of this License; and\r\n+\r\n+      (b) You must cause any modified files to carry prominent notices\r\n+          stating that You changed the files; and\r\n+\r\n+      (c) You must retain, in the Source form of any Derivative Works\r\n+          that You distribute, all copyright, patent, trademark, and\r\n+          attribution notices from the Source form of the Work,\r\n+          excluding those notices that do not pertain to any part of\r\n+          the Derivative Works; and\r\n+\r\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\r\n+          distribution, then any Derivative Works that You distribute must\r\n+          include a readable copy of the attribution notices contained\r\n+          within such NOTICE file, excluding those notices that do not\r\n+          pertain to any part of the Derivative Works, in at least one\r\n+          of the following places: within a NOTICE text file distributed\r\n+          as part of the Derivative Works; within the Source form or\r\n+          documentation, if provided along with the Derivative Works; or,\r\n+          within a display generated by the Derivative Works, if and\r\n+          wherever such third-party notices normally appear. The contents\r\n+          of the NOTICE file are for informational purposes only and\r\n+          do not modify the License. You may add Your own attribution\r\n+          notices within Derivative Works that You distribute, alongside\r\n+          or as an addendum to the NOTICE text from the Work, provided\r\n+          that such additional attribution notices cannot be construed\r\n+          as modifying the License.\r\n+\r\n+      You may add Your own copyright statement to Your modifications and\r\n+      may provide additional or different license terms and conditions\r\n+      for use, reproduction, or distribution of Your modifications, or\r\n+      for any such Derivative Works as a whole, provided Your use,\r\n+      reproduction, and distribution of the Work otherwise complies with\r\n+      the conditions stated in this License.\r\n+\r\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\r\n+      any Contribution intentionally submitted for inclusion in the Work\r\n+      by You to the Licensor shall be under the terms and conditions of\r\n+      this License, without any additional terms or conditions.\r\n+      Notwithstanding the above, nothing herein shall supersede or modify\r\n+      the terms of any separate license agreement you may have executed\r\n+      with Licensor regarding such Contributions.\r\n+\r\n+   6. Trademarks. This License does not grant permission to use the trade\r\n+      names, trademarks, service marks, or product names of the Licensor,\r\n+      except as required for reasonable and customary use in describing the\r\n+      origin of the Work and reproducing the content of the NOTICE file.\r\n+\r\n+   7. Disclaimer of Warranty. Unless required by applicable law or\r\n+      agreed to in writing, Licensor provides the Work (and each\r\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\r\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\r\n+      implied, including, without limitation, any warranties or conditions\r\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\r\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\r\n+      appropriateness of using or redistributing the Work and assume any\r\n+      risks associated with Your exercise of permissions under this License.\r\n+\r\n+   8. Limitation of Liability. In no event and under no legal theory,\r\n+      whether in tort (including negligence), contract, or otherwise,\r\n+      unless required by applicable law (such as deliberate and grossly\r\n+      negligent acts) or agreed to in writing, shall any Contributor be\r\n+      liable to You for damages, including any direct, indirect, special,\r\n+      incidental, or consequential damages of any character arising as a\r\n+      result of this License or out of the use or inability to use the\r\n+      Work (including but not limited to damages for loss of goodwill,\r\n+      work stoppage, computer failure or malfunction, or any and all\r\n+      other commercial damages or losses), even if such Contributor\r\n+      has been advised of the possibility of such damages.\r\n+\r\n+   9. Accepting Warranty or Additional Liability. While redistributing\r\n+      the Work or Derivative Works thereof, You may choose to offer,\r\n+      and charge a fee for, acceptance of support, warranty, indemnity,\r\n+      or other liability obligations and/or rights consistent with this\r\n+      License. However, in accepting such obligations, You may act only\r\n+      on Your own behalf and on Your sole responsibility, not on behalf\r\n+      of any other Contributor, and only if You agree to indemnify,\r\n+      defend, and hold each Contributor harmless for any liability\r\n+      incurred by, or claims asserted against, such Contributor by reason\r\n+      of your accepting any such warranty or additional liability.\r\n+\r\n+   END OF TERMS AND CONDITIONS\r\n+\r\n+   APPENDIX: How to apply the Apache License to your work.\r\n+\r\n+      To apply the Apache License to your work, attach the following\r\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\r\n+      replaced with your own identifying information. (Don't include\r\n+      the brackets!)  The text should be enclosed in the appropriate\r\n+      comment syntax for the file format. We also recommend that a\r\n+      file or class name and description of purpose be included on the\r\n+      same \"printed page\" as the copyright notice for easier\r\n+      identification within third-party archives.\r\n+\r\n+   Copyright [yyyy] [name of copyright owner]\r\n+\r\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\r\n+   you may not use this file except in compliance with the License.\r\n+   You may obtain a copy of the License at\r\n+\r\n+       http://www.apache.org/licenses/LICENSE-2.0\r\n+\r\n+   Unless required by applicable law or agreed to in writing, software\r\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\r\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n+   See the License for the specific language governing permissions and\r\n+   limitations under the License.\r",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/LICENSE.txt",
                "sha": "75b52484ea471f882c29e02693b4f02dba175b5e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Bold.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Bold.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Bold.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Bold.ttf",
                "sha": "6e00cdce1dac34e409a0111296c90e98c6f40701",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-BoldItalic.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-BoldItalic.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-BoldItalic.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-BoldItalic.ttf",
                "sha": "51b7b29568f9874543de4037950883627c7bd51c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Italic.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Italic.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Italic.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Italic.ttf",
                "sha": "dc93fea6cf3f0473c083ef20eb6a1ef2e6b8e857",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Regular.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Regular.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Regular.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/Noto_Sans/NotoSans-Regular.ttf",
                "sha": "9dd10199bc8e8fcfcc5c3a1a394557ed00c567c5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/FontAwesome.otf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/fontawesome/FontAwesome.otf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/fontawesome/FontAwesome.otf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/FontAwesome.otf",
                "sha": "81c9ad949b47f64afeca5642ee2494b6e3147f44",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.eot",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.eot?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.eot",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.eot",
                "sha": "84677bc0c5f37f1fac9d87548c4554b5c91717cf",
                "status": "added"
            },
            {
                "additions": 520,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.svg",
                "changes": 520,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.svg?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.svg",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.svg",
                "sha": "d907b25ae60ec7e3d32e4027aa6e6b7595de97af",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.ttf",
                "sha": "96a3639cdde5e8ab459c6380e3b9524ee81641dc",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.woff",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.woff?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.woff",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/fontawesome/fontawesome-webfont.woff",
                "sha": "628b6a52a87e62c6f22426e17c01f6a303aa194e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.eot",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.eot?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.eot",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.eot",
                "sha": "b93a4953fff68df523aa7656497ee339d6026d64",
                "status": "added"
            },
            {
                "additions": 288,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.svg",
                "changes": 288,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.svg?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.svg",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.svg",
                "sha": "94fb5490a2ed10b2c69a4a567a4fd2e4f706d841",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.ttf",
                "sha": "1413fc609ab6f21774de0cb7e01360095584f65b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff",
                "sha": "9e612858f802245ddcbf59788a0db942224bab35",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff2",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff2?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff2",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/glyphicons/glyphicons-halflings-regular.woff2",
                "sha": "64539b54c3751a6d9adb44c8e3a45ba5a73b77f0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold-ascii.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold-ascii.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold-ascii.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold-ascii.ttf",
                "sha": "726bcc46931d3ec5922103ee0a46dbc21f171c58",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold_italic-ascii.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold_italic-ascii.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold_italic-ascii.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-bold_italic-ascii.ttf",
                "sha": "c91d944a179b558870fbf0134ee90fd62bcc72f6",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-italic-ascii.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-italic-ascii.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-italic-ascii.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-italic-ascii.ttf",
                "sha": "77c16844c92ac34d3d8ca59cc2a38aa3a0101939",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-regular-ascii-conums.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-regular-ascii-conums.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-regular-ascii-conums.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1mn/mplus1mn-regular-ascii-conums.ttf",
                "sha": "5645bbeb3ee8ba0ebd29248e99e8b53b24ef7379",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1p-regular-fallback.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/fonts/mplus1p-regular-fallback.ttf?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/fonts/mplus1p-regular-fallback.ttf",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/fonts/mplus1p-regular-fallback.ttf",
                "sha": "5251e5c4b6d41fce7e2e8933348b49fad5832759",
                "status": "added"
            },
            {
                "additions": 151,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/format-of-solr-xml.adoc",
                "changes": 151,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/format-of-solr-xml.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/format-of-solr-xml.adoc",
                "patch": "@@ -0,0 +1,151 @@\n+= Format of solr.xml\n+:page-shortname: format-of-solr-xml\n+:page-permalink: format-of-solr-xml.html\n+\n+The `solr.xml` file defines some global configuration options that apply to all or many cores.\n+\n+This section will describe the default `solr.xml` file included with Solr and how to modify it for your needs. For details on how to configure `core.properties`, see the section <<defining-core-properties.adoc#defining-core-properties,Defining core.properties>>.\n+\n+[[Formatofsolr.xml-Definingsolr.xml]]\n+== Defining solr.xml\n+\n+You can find `solr.xml` in your Solr Home directory or in Zookeeper. The default `solr.xml` file looks like this:\n+\n+[source,xml]\n+----\n+<solr>\n+\n+  <solrcloud>\n+    <str name=\"host\">${host:}</str>\n+    <int name=\"hostPort\">${jetty.port:8983}</int>\n+    <str name=\"hostContext\">${hostContext:solr}</str>\n+    <int name=\"zkClientTimeout\">${zkClientTimeout:15000}</int>\n+    <bool name=\"genericCoreNodeNames\">${genericCoreNodeNames:true}</bool>\n+  </solrcloud>\n+\n+  <shardHandlerFactory name=\"shardHandlerFactory\"\n+    class=\"HttpShardHandlerFactory\">\n+    <int name=\"socketTimeout\">${socketTimeout:0}</int>\n+    <int name=\"connTimeout\">${connTimeout:0}</int>\n+  </shardHandlerFactory>\n+\n+</solr>\n+----\n+\n+As you can see, the discovery Solr configuration is \"SolrCloud friendly\". However, the presence of the `<solrcloud>` element does _not_ mean that the Solr instance is running in SolrCloud mode. Unless the `-DzkHost` or `-DzkRun` are specified at startup time, this section is ignored.\n+\n+[[Formatofsolr.xml-Solr.xmlParameters]]\n+=== Solr.xml Parameters\n+\n+==== The `<solr>` Element\n+\n+There are no attributes that you can specify in the `<solr>` tag, which is the root element of `solr.xml`. The tables below list the child nodes of each XML element in `solr.xml`.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Node |Description\n+|`adminHandler` |If used, this attribute should be set to the FQN (Fully qualified name) of a class that inherits from CoreAdminHandler. For example, `<str name=\"adminHandler\">com.myorg.MyAdminHandler</str>` would configure the custom admin handler (MyAdminHandler) to handle admin requests. If this attribute isn't set, Solr uses the default admin handler, `org.apache.solr.handler.admin.CoreAdminHandler`. For more information on this parameter, see the Solr Wiki at http://wiki.apache.org/solr/CoreAdmin#cores.\n+|`collectionsHandler` |As above, for custom CollectionsHandler implementations.\n+| `infoHandler` |As above, for custom InfoHandler implementations.\n+|`coreLoadThreads` |Specifies the number of threads that will be assigned to load cores in parallel.\n+|`coreRootDirectory` |The root of the core discovery tree, defaults to SOLR_HOME.\n+|`managementPath` |Currently non-operational.\n+|`sharedLib` |Specifies the path to a common library directory that will be shared across all cores. Any JAR files in this directory will be added to the search path for Solr plugins. This path is relative to the top-level container's Solr Home. Custom handlers may be placed in this directory\n+|`shareSchema` |This attribute, when set to true, ensures that the multiple cores pointing to the same Schema resource file will be referring to the same IndexSchema Object. Sharing the IndexSchema Object makes loading the core faster. If you use this feature, make sure that no core-specific property is used in your Schema file.\n+|`transientCacheSize` |Defines how many cores with transient=true that can be loaded before swapping the least recently used core for a new core.\n+|`configSetBaseDir` |The directory under which configsets for solr cores can be found. Defaults to SOLR_HOME/configsets\n+|===\n+\n+==== The `<solrcloud>` element\n+\n+This element defines several parameters that relate so SolrCloud. This section is ignored unless the solr instance is started with either `-DzkRun` or `-DzkHost`\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Node |Description\n+|`distribUpdateConnTimeout` |Used to set the underlying \"connTimeout\" for intra-cluster updates.\n+|`distribUpdateSoTimeout` |Used to set the underlying \"socketTimeout\" for intra-cluster updates.\n+|`host` |The hostname Solr uses to access cores.\n+|`hostContext` |The url context path.\n+|`hostPort` |The port Solr uses to access cores. In the default `solr.xml` file, this is set to `${jetty.port:8983`}, which will use the Solr port defined in Jetty, and otherwise fall back to 8983.\n+|`leaderVoteWait` |When SolrCloud is starting up, how long each Solr node will wait for all known replicas for that shard to be found before assuming that any nodes that haven't reported are down.\n+|`leaderConflictResolveWait` |When trying to elect a leader for a shard, this property sets the maximum time a replica will wait to see conflicting state information to be resolved; temporary conflicts in state information can occur when doing rolling restarts, especially when the node hosting the Overseer is restarted. Typically, the default value of 180000 (ms) is sufficient for conflicts to be resolved; you may need to increase this value if you have hundreds or thousands of small collections in SolrCloud.\n+|`zkClientTimeout` |A timeout for connection to a ZooKeeper server. It is used with SolrCloud.\n+|`zkHost` |In SolrCloud mode, the URL of the ZooKeeper host that Solr should use for cluster state information.\n+|`genericCoreNodeNames` |If `TRUE`, node names are not based on the address of the node, but on a generic name that identifies the core. When a different machine takes over serving that core things will be much easier to understand.\n+|`zkCredentialsProvider` & ` zkACLProvider` |Optional parameters that can be specified if you are using <<zookeeper-access-control.adoc#zookeeper-access-control,ZooKeeper Access Control>>.\n+|===\n+\n+==== The `<logging>` element\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Node |Description\n+|`class` |The class to use for logging. The corresponding JAR file must be available to solr, perhaps through a `<lib>` directive in solrconfig.xml.\n+|`enabled` |true/false - whether to enable logging or not.\n+|===\n+\n+===== The `<logging><watcher>` element\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Node |Description\n+|`size` |The number of log events that are buffered.\n+|`threshold` |The logging level above which your particular logging implementation will record. For example when using log4j one might specify DEBUG, WARN, INFO, etc.\n+|===\n+\n+==== The `<shardHandlerFactory>` element\n+\n+Custom shard handlers can be defined in `solr.xml` if you wish to create a custom shard handler.\n+\n+[source,xml]\n+----\n+<shardHandlerFactory name=\"ShardHandlerFactory\" class=\"qualified.class.name\">\n+----\n+\n+Since this is a custom shard handler, sub-elements are specific to the implementation. The default and only shard handler provided by Solr is the HttpShardHandlerFactory in which case, the following sub-elements can be specified:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Node |Description\n+|`socketTimeout` |The read timeout for intra-cluster query and administrative requests. The default is the same as the distribUpdateSoTimeout specified in the solrcloud section.\n+|`connTimeout` |The connection timeout for intra-cluster query and administrative requests. Defaults to the distribUpdateConnTimeout specified in the solrcloud section\n+|`urlScheme` |URL scheme to be used in distributed search\n+|`maxConnectionsPerHost` |Maximum connections allowed per host. Defaults to 20\n+|`maxConnections` |Maximum total connections allowed. Defaults to 10000\n+|`corePoolSize` |The initial core size of the threadpool servicing requests. Default is 0.\n+|`maximumPoolSize` |The maximum size of the threadpool servicing requests. Default is unlimited.\n+|`maxThreadIdleTime` |The amount of time in seconds that idle threads persist for in the queue, before being killed. Default is 5 seconds.\n+|`sizeOfQueue` |If the threadpool uses a backing queue, what is its maximum size to use direct handoff. Default is to use a SynchronousQueue.\n+|`fairnessPolicy` |A boolean to configure if the threadpool favours fairness over throughput. Default is false to favor throughput.\n+|===\n+\n+[[Formatofsolr.xml-SubstitutingJVMSystemPropertiesinsolr.xml]]\n+== Substituting JVM System Properties in solr.xml\n+\n+Solr supports variable substitution of JVM system property values in `solr.xml`, which allows runtime specification of various configuration options. The syntax is `${propertyname[:option default value]`}. This allows defining a default that can be overridden when Solr is launched. If a default value is not specified, then the property must be specified at runtime or the `solr.xml` file will generate an error when parsed.\n+\n+Any JVM system properties usually specified using the -D flag when starting the JVM, can be used as variables in the `solr.xml` file.\n+\n+For example, in the `solr.xml` file shown below, the `socketTimeout` and `connTimeout` values are each set to \"0\". However, if you start Solr using '`bin/solr -DsocketTimeout=1000`', the `socketTimeout` option of the `HttpShardHandlerFactory` to be overridden using a value of 1000ms, while the `connTimeout` option will continue to use the default property value of \"0\".\n+\n+[source,xml]\n+----\n+<solr>\n+  <shardHandlerFactory name=\"shardHandlerFactory\"\n+                       class=\"HttpShardHandlerFactory\">\n+    <int name=\"socketTimeout\">${socketTimeout:0}</int>\n+    <int name=\"connTimeout\">${connTimeout:0}</int>\n+  </shardHandlerFactory>\n+</solr>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/format-of-solr-xml.adoc",
                "sha": "6483ce1f6e553f68a1c40d88096fd9b6ef48cf36",
                "status": "added"
            },
            {
                "additions": 252,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/function-queries.adoc",
                "changes": 252,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/function-queries.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/function-queries.adoc",
                "patch": "@@ -0,0 +1,252 @@\n+= Function Queries\n+:page-shortname: function-queries\n+:page-permalink: function-queries.html\n+\n+Function queries enable you to generate a relevancy score using the actual value of one or more numeric fields.\n+\n+Function queries are supported by the <<the-dismax-query-parser.adoc#the-dismax-query-parser,DisMax>>, <<the-extended-dismax-query-parser.adoc#the-extended-dismax-query-parser,Extended DisMax>>, and <<the-standard-query-parser.adoc#the-standard-query-parser,standard>> query parsers.\n+\n+Function queries use _functions_. The functions can be a constant (numeric or string literal), a field, another function or a parameter substitution argument. You can use these functions to modify the ranking of results for users. These could be used to change the ranking of results based on a user's location, or some other calculation.\n+\n+[[FunctionQueries-UsingFunctionQuery]]\n+== Using Function Query\n+\n+Functions must be expressed as function calls (for example, `sum(a,b)` instead of simply `a+b`).\n+\n+There are several ways of using function queries in a Solr query:\n+\n+* Via an explicit QParser that expects function arguments, such <<other-parsers.adoc#OtherParsers-FunctionQueryParser,`func`>> or <<other-parsers.adoc#OtherParsers-FunctionRangeQueryParser,`frange`>> . For example:\n++\n+[source,text]\n+----\n+q={!func}div(popularity,price)&fq={!frange l=1000}customer_ratings\n+----\n+* In a Sort expression. For example:\n++\n+[source,text]\n+----\n+sort=div(popularity,price) desc, score desc\n+----\n+* Add the results of functions as pseudo-fields to documents in query results. For instance, for:\n++\n+[source,text]\n+----\n+&fl=sum(x, y),id,a,b,c,score\n+----\n++\n+the output would be:\n++\n+[source,xml]\n+----\n+...\n+<str name=\"id\">foo</str>\n+<float name=\"sum(x,y)\">40</float>\n+<float name=\"score\">0.343</float>\n+...\n+----\n+* Use in a parameter that is explicitly for specifying functions, such as the EDisMax query parser's <<the-extended-dismax-query-parser.adoc#the-extended-dismax-query-parser,`boost`>> param, or DisMax query parser's <<the-dismax-query-parser.adoc#TheDisMaxQueryParser-Thebf_BoostFunctions_Parameter,`bf` (boost function) parameter>>. (Note that the `bf` parameter actually takes a list of function queries separated by white space and each with an optional boost. Make sure you eliminate any internal white space in single function queries when using `bf`). For example:\n++\n+[source,text]\n+----\n+q=dismax&bf=\"ord(popularity)^0.5 recip(rord(price),1,1000,1000)^0.3\"\n+----\n+* Introduce a function query inline in the lucene QParser with the `\\_val_` keyword. For example:\n++\n+[source,text]\n+----\n+q=_val_:mynumericfield _val_:\"recip(rord(myfield),1,2,3)\"\n+----\n+\n+Only functions with fast random access are recommended.\n+\n+[[FunctionQueries-AvailableFunctions]]\n+== Available Functions\n+\n+The table below summarizes the functions available for function queries.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,40,40\",options=\"header\"]\n+|===\n+|Function |Description |Syntax Examples\n+|abs |Returns the absolute value of the specified value or function. |`abs(x)` `abs(-5)`\n+|\"constant\" |Specifies a floating point constant. |`1.5`\n+|def |`def` is short for default. Returns the value of field \"field\", or if the field does not exist, returns the default value specified. and yields the first value where `exists()==true`.) |`def(rating,5):` This `def()` function returns the rating, or if no rating specified in the doc, returns 5 `def(myfield, 1.0):` equivalent to `if(exists(myfield),myfield,1.0)`\n+|div |Divides one value or function by another. div(x,y) divides x by y. |`div(1,y)` `div(sum(x,100),max(y,1))`\n+|dist |Return the distance between two vectors (points) in an n-dimensional space. Takes in the power, plus two or more ValueSource instances and calculates the distances between the two vectors. Each ValueSource must be a number. There must be an even number of ValueSource instances passed in and the method assumes that the first half represent the first vector and the second half represent the second vector. |`dist(2, x, y, 0, 0):` calculates the Euclidean distance between (0,0) and (x,y) for each document `dist(1, x, y, 0, 0)`: calculates the Manhattan (taxicab) distance between (0,0) and (x,y) for each document `dist(2, x,y,z,0,0,0):` Euclidean distance between (0,0,0) and (x,y,z) for each document. `dist(1,x,y,z,e,f,g)`: Manhattan distance between (x,y,z) and (e,f,g) where each letter is a field name\n+|docfreq(field,val) |Returns the number of documents that contain the term in the field. This is a constant (the same value for all documents in the index). You can quote the term if it's more complex, or do parameter substitution for the term value. |`docfreq(text,'solr')` `...&defType=func` `&q=docfreq(text,$myterm)&myterm=solr`\n+|field[[FunctionQueries-field]] a|\n+Returns the numeric docValues or indexed value of the field with the specified name. In its simplest (single argument) form, this function can only be used on single valued fields, and can be called using the name of the field as a string, or for most conventional field names simply use the field name by itself with out using the `field(...)` syntax.\n+\n+When using docValues, an optional 2nd argument can be specified to select the \"`min\"` or \"```max```\" value of multivalued fields.\n+\n+0 is returned for documents without a value in the field.\n+\n+ a|\n+These 3 examples are all equivalent:\n+\n+* `myFloatFieldName`\n+* `field(myFloatFieldName)`\n+* `field(\"myFloatFieldName\")`\n+\n+The last form is convinient when your field name is atypical:\n+\n+* `field(\"my complex float fieldName\")`\n+\n+For multivalued docValues fields:\n+\n+* `field(myMultiValuedFloatField,min)`\n+* `field(myMultiValuedFloatField,max)`\n+\n+|hsin |The Haversine distance calculates the distance between two points on a sphere when traveling along the sphere. The values must be in radians. `hsin` also take a Boolean argument to specify whether the function should convert its output to radians. |`hsin(2, true, x, y, 0, 0)`\n+|idf |Inverse document frequency; a measure of whether the term is common or rare across all documents. Obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient. See also `tf`. |`idf(fieldName,'solr')`: measures the inverse of the frequency of the occurrence of the term `'solr'` in` fieldName`.\n+|if a|\n+Enables conditional function queries. In `if(test,value1,value2)`:\n+\n+* `test` is or refers to a logical value or expression that returns a logical value (TRUE or FALSE).\n+* `value1` is the value that is returned by the function if `test` yields TRUE.\n+* `value2` is the value that is returned by the function if `test` yields FALSE.\n+\n+An expression can be any function which outputs boolean values, or even functions returning numeric values, in which case value 0 will be interpreted as false, or strings, in which case empty string is interpreted as false.\n+\n+ |`if(termfreq` `(cat,'electronics'),` `popularity,42)` : This function checks each document for the to see if it contains the term \"```electronics```\" in the `cat` field. If it does, then the value of the `popularity` field is returned, otherwise the value of `42` is returned.\n+|linear |Implements `m*x+c` where `m` and `c` are constants and `x` is an arbitrary function. This is equivalent to `sum(product(m,x),c)`, but slightly more efficient as it is implemented as a single function. |`linear(x,m,c)` `linear(x,2,4)` returns `2*x+4`\n+|log |Returns the log base 10 of the specified function. a|\n+`log(x)`\n+\n+`log(sum(x,100))`\n+\n+|map |Maps any values of an input function x that fall within min and max inclusive to the specified target. The arguments min and max must be constants. The arguments `target` and `default` can be constants or functions. If the value of x does not fall between min and max, then either the value of x is returned, or a default value is returned if specified as a 5th argument. a|\n+`map(x,min,max,target)` `map(x,0,0,1)` - changes any values of 0 to 1. This can be useful in handling default 0 values.\n+\n+`map(x,min,max,target,default)` `map(x,0,100,1,-1)` - changes any values between `0` and `100` to `1`, and all other values to` -1`.\n+\n+`map(x,0,100,` `sum(x,599),` `docfreq(text,solr))` - changes any values between `0` and `100` to x+599, and all other values to frequency of the term 'solr' in the field text.\n+\n+|max a|\n+Returns the maximum numeric value of multiple nested functions or constants, which are specified as arguments: `max(x,y,...)`. The max function can also be useful for \"bottoming out\" another function or field at some specified constant.\n+\n+(Use the `field(myfield,max)` syntax for <<FunctionQueries-field,selecting the maximum value of a single multivalued field>>)\n+\n+ |`max(myfield,myotherfield,0)`\n+|maxdoc |Returns the number of documents in the index, including those that are marked as deleted but have not yet been purged. This is a constant (the same value for all documents in the index). |`maxdoc()`\n+|min a|\n+Returns the minimum numeric value of multiple nested functions of constants, which are specified as arguments: `min(x,y,...)`. The min function can also be useful for providing an \"upper bound\" on a function using a constant.\n+\n+(Use the `field(myfield,min)` <<FunctionQueries-field,syntax for selecting the minimum value of a single multivalued field>>)\n+\n+ |`min(myfield,myotherfield,0)`\n+|ms a|\n+Returns milliseconds of difference between its arguments. Dates are relative to the Unix or POSIX time epoch, midnight, January 1, 1970 UTC. Arguments may be the name of an indexed `TrieDateField`, or date math based on a <<working-with-dates.adoc#working-with-dates,constant date or `NOW`>>.\n+\n+* `ms()`: Equivalent to `ms(NOW)`, number of milliseconds since the epoch.\n+* `ms(a):` Returns the number of milliseconds since the epoch that the argument represents.\n+* `ms(a,b)` : Returns the number of milliseconds that b occurs before a (that is, a - b)\n+\n+ |`ms(NOW/DAY)` `ms(2000-01-01T00:00:00Z)` `ms(mydatefield)` `ms(NOW,mydatefield)` `ms(mydatefield,` `2000-01-01T00:00:00Z)` `ms(datefield1,` `datefield2)`\n+|norm(_field_) |Returns the \"norm\" stored in the index for the specified field. This is the product of the index time boost and the length normalization factor, according to the {lucene-javadocs}/core/org/apache/lucene/search/similarities/Similarity.html[Similarity] for the field. |`norm(fieldName)`\n+|numdocs |Returns the number of documents in the index, not including those that are marked as deleted but have not yet been purged. This is a constant (the same value for all documents in the index). |`numdocs()`\n+|ord a|\n+Returns the ordinal of the indexed field value within the indexed list of terms for that field in Lucene index order (lexicographically ordered by unicode value), starting at 1. In other words, for a given field, all values are ordered lexicographically; this function then returns the offset of a particular value in that ordering. The field must have a maximum of one value per document (not multi-valued). 0 is returned for documents without a value in the field.\n+\n+[IMPORTANT]\n+====\n+`ord()` depends on the position in an index and can change when other documents are inserted or deleted.\n+====\n+\n+See also `rord` below.\n+\n+ |`ord(myIndexedField)` Example: If there were only three values (\"apple\",\"banana\",\"pear\") for a particular field X, then: `ord(X) `would be 1 for documents containing \"apple\", 2 for documnts containing \"banana\", etc...\n+|payload a|\n+Returns the float value computed from the decoded payloads of the term specified. The return value is computed using the `min`, `max`, or `average` of the decoded payloads. A special `first` function can be used instead of the others, to short-circuit term enumeration and return only the decoded payload of the first term. The field specified must have float or integer payload encoding capability (via `DelimitedPayloadTokenFilter` or `NumericPayloadTokenFilter`). If no payload is found for the term, the default value is returned.\n+\n+* `payload(field_name,term)`: default value is 0.0, `average` function is used.\n+* `payload(field_name,term,default_value)`: default value can be a constant, field name, or another float returning function. `average` function used.\n+* `payload(field_name,term,default_value,function)`: function values can be `min`, `max`, `average`, or `first`. |`payload(payloaded_field_dpf,term,0.0,first)`\n+\n+|pow |Raises the specified base to the specified power. `pow(x,y)` raises x to the power of y. |`pow(x,y)` `pow(x,log(y))` `pow(x,0.5):` the same as `sqrt`\n+|product |Returns the product of multiple values or functions, which are specified in a comma-separated list. `mul(...)` may also be used as an alias for this function. |`product(x,y,...)` `product(x,2)` `product(x,y)mul(x,y)`\n+|query |Returns the score for the given subquery, or the default value for documents not matching the query. Any type of subquery is supported through either parameter de-referencing `$otherparam` or direct specification of the query string in the <<local-parameters-in-queries.adoc#local-parameters-in-queries,Local Parameters>> through the `v` key. |`query(subquery, default)` `q=product` `(popularity,` ` query({!dismax v='solr rocks'})`: returns the product of the popularity and the score of the DisMax query. `q=product` `(popularity,` ` query($qq))&qq={!dismax}solr rocks`: equivalent to the previous query, using parameter de-referencing. `q=product` `(popularity,` ` query($qq,0.1))` `&qq={!dismax}` `solr rocks`: specifies a default score of 0.1 for documents that don't match the DisMax query.\n+|recip a|\n+Performs a reciprocal function with `recip(x,m,a,b)` implementing `a/(m*x+b)` where `m,a,b` are constants, and `x` is any arbitrarily complex function.\n+\n+When a and b are equal, and x>=0, this function has a maximum value of 1 that drops as x increases. Increasing the value of a and b together results in a movement of the entire function to a flatter part of the curve. These properties can make this an ideal function for boosting more recent documents when x is `rord(datefield)`.\n+\n+ |`recip(myfield,m,a,b)` `recip(rord` `(creationDate),` `1,1000,1000)`\n+|rord |Returns the reverse ordering of that returned by `ord`. |`rord(myDateField)`\n+|scale a|\n+Scales values of the function x such that they fall between the specified `minTarget` and `maxTarget` inclusive. The current implementation traverses all of the function values to obtain the min and max, so it can pick the correct scale.\n+\n+The current implementation cannot distinguish when documents have been deleted or documents that have no value. It uses 0.0 values for these cases. This means that if values are normally all greater than 0.0, one can still end up with 0.0 as the min value to map from. In these cases, an appropriate map() function could be used as a workaround to change 0.0 to a value in the real range, as shown here: scale(map(x,0,0,5),1,2)\n+\n+ |`scale(x,` `minTarget,` `maxTarget)` `scale(x,1,2)`: scales the values of x such that all values will be between 1 and 2 inclusive.\n+|sqedist |The Square Euclidean distance calculates the 2-norm (Euclidean distance) but does not take the square root, thus saving a fairly expensive operation. It is often the case that applications that care about Euclidean distance do not need the actual distance, but instead can use the square of the distance. There must be an even number of ValueSource instances passed in and the method assumes that the first half represent the first vector and the second half represent the second vector. |`sqedist(x_td, y_td, 0, 0)`\n+|sqrt |Returns the square root of the specified value or function. |`sqrt(x)sqrt(100)sqrt(sum(x,100))`\n+|strdist |Calculate the distance between two strings. Uses the Lucene spell checker `StringDistance` interface and supports all of the implementations available in that package, plus allows applications to plug in their own via Solr's resource loading capabilities. `strdist` takes (string1, string2, distance measure). Possible values for distance measure are: jw: Jaro-Winkler edit: Levenstein or Edit distance ngram: The NGramDistance, if specified, can optionally pass in the ngram size too. Default is 2. FQN: Fully Qualified class Name for an implementation of the StringDistance interface. Must have a no-arg constructor. |`strdist(\"SOLR\",id,edit)`\n+|sub |Returns x-y from sub(x,y). |`sub(myfield,myfield2)` `sub(100,` `sqrt(myfield))`\n+|sum |Returns the sum of multiple values or functions, which are specified in a comma-separated list. `add(...)` may be used as an alias for this function |`sum(x,y,...) sum(x,1)` `sum(x,y)` `sum(sqrt(x),log(y),z,0.5)add(x,y)`\n+|sumtotaltermfreq |Returns the sum of `totaltermfreq` values for all terms in the field in the entire index (i.e., the number of indexed tokens for that field). (Aliases `sumtotaltermfreq` to `sttf`.) |If doc1:(fieldX:A B C) and doc2:(fieldX:A A A A): `docFreq(fieldX:A)` = 2 (A appears in 2 docs) `freq(doc1, fieldX:A)` = 4 (A appears 4 times in doc 2) `totalTermFreq(fieldX:A)` = 5 (A appears 5 times across all docs) `sumTotalTermFreq(fieldX)` = 7 in `fieldX`, there are 5 As, 1 B, 1 C\n+|termfreq |Returns the number of times the term appears in the field for that document. |`termfreq(text,'memory')`\n+|tf |Term frequency; returns the term frequency factor for the given term, using the {lucene-javadocs}/core/org/apache/lucene/search/similarities/Similarity.html[Similarity] for the field. The `tf-idf` value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the document, which helps to control for the fact that some words are generally more common than others. See also `idf`. |`tf(text,'solr')`\n+|top a|\n+Causes the function query argument to derive its values from the top-level IndexReader containing all parts of an index. For example, the ordinal of a value in a single segment will be different from the ordinal of that same value in the complete index.\n+\n+The `ord()` and `rord()` functions implicitly use `top()`, and hence `ord(foo)` is equivalent to `top(ord(foo))`.\n+\n+ |\n+|totaltermfreq |Returns the number of times the term appears in the field in the entire index. (Aliases `totaltermfreq` to `ttf`.) |`ttf(text,'memory')`\n+|===\n+\n+The following functions are boolean \u2013 they return true or false. They are mostly useful as the first argument of the `if` function, and some of these can be combined. If used somewhere else, it will yield a '1' or '0'.\n+\n+[width=\"100%\",options=\"header\",]\n+|===\n+|Function |Description |Syntax Examples\n+|and |Returns a value of true if and only if all of its operands evaluate to true. |`and(not` `(exists` `(popularity)),` `exists` `(price)):` returns `true` for any document which has a value in the `price` field, but does not have a value in the `popularity` field\n+|or |A logical disjunction. |`or(value1,value2):` TRUE if either `value1` or `value2` is true.\n+|xor |Logical exclusive disjunction, or one or the other but not both. |`xor(field1,field2)` returns TRUE if either `field1` or `field2` is true; FALSE if both are true.\n+|not |The logically negated value of the wrapped function. |`not(exists(author))`: TRUE only when `exists(author)` is false.\n+|exists |Returns TRUE if any member of the field exists. |`exists(author)` returns TRUE for any document has a value in the \"author\" field. `exists(query(price:5.00))` returns TRUE if \"price\" matches \"5.00\".\n+|gt, gte, lt, lte, eq |5 comparison functions: Greater Than, Greater Than or Equal, Less Than, Less Than or Equal, Equal |`if(lt(ms(mydatefield),315569259747),0.8,1)` translates to this pseudocode: `if mydatefield < 315569259747 then 0.8 else 1`\n+|===\n+\n+[[FunctionQueries-ExampleFunctionQueries]]\n+== Example Function Queries\n+\n+To give you a better understanding of how function queries can be used in Solr, suppose an index stores the dimensions in meters x,y,z of some hypothetical boxes with arbitrary names stored in field `boxname`. Suppose we want to search for box matching name `findbox` but ranked according to volumes of boxes. The query parameters would be:\n+\n+`q=boxname:findbox _val_:\"product(x,y,z)\"`\n+\n+This query will rank the results based on volumes. In order to get the computed volume, you will need to request the `score`, which will contain the resultant volume:\n+\n+`&fl=*, score`\n+\n+Suppose that you also have a field storing the weight of the box as `weight`. To sort by the density of the box and return the value of the density in score, you would submit the following query:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/collection_name/select?q=boxname:findbox _val_:\"div(weight,product(x,y,z))\"&fl=boxname x y z weight score\n+----\n+\n+[[FunctionQueries-SortByFunction]]\n+== Sort By Function\n+\n+You can sort your query results by the output of a function. For example, to sort results by distance, you could enter:\n+\n+[source,text]\n+----\n+http://localhost:8983/solr/collection_name/select?q=*:*&sort=dist(2, point1, point2) desc\n+----\n+\n+Sort by function also supports pseudo-fields: fields can be generated dynamically and return results as though it was normal field in the index. For example,\n+\n+`&fl=id,sum(x, y),score`\n+\n+would return:\n+\n+[source,xml]\n+----\n+<str name=\"id\">foo</str>\n+<float name=\"sum(x,y)\">40</float>\n+<float name=\"score\">0.343</float>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/function-queries.adoc",
                "sha": "99a704a457f58c95be15af71840df76c125c514a",
                "status": "added"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/further-assistance.adoc",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/further-assistance.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/further-assistance.adoc",
                "patch": "@@ -0,0 +1,7 @@\n+= Further Assistance\n+:page-shortname: further-assistance\n+:page-permalink: further-assistance.html\n+\n+There is a very active user community around Solr and Lucene. The solr-user mailing list, and #solr IRC channel are both great resources for asking questions.\n+\n+To view the mailing list archives, subscribe to the list, or join the IRC channel, please see https://lucene.apache.org/solr/community.html.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/further-assistance.adoc",
                "sha": "8cbeedc8fa576f6194ea2d5b6c4b7b41e259ba15",
                "status": "added"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-assistance.adoc",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/getting-assistance.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/getting-assistance.adoc",
                "patch": "@@ -0,0 +1,25 @@\n+= Getting Assistance\n+:page-shortname: getting-assistance\n+:page-permalink: getting-assistance.html\n+\n+At the bottom of each screen of the Admin UI is a set of links that can be used to get more assistance with configuring and using Solr.\n+\n+.Assistance icons\n+image::images/getting-assistance/Assistance.png[image]\n+\n+\n+These icons include the following links.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"25,75\",options=\"header\"]\n+|===\n+|Link |Description\n+|Documentation |Navigates to the Apache Solr documentation hosted on https://lucene.apache.org/solr/.\n+|Issue Tracker |Navigates to the JIRA issue tracking server for the Apache Solr project. This server resides at https://issues.apache.org/jira/browse/SOLR.\n+|IRC Channel |Navigates to Solr's http://en.wikipedia.org/wiki/Internet_Relay_Chat[IRC] live-chat room: http://webchat.freenode.net/?channels=#solr.\n+|Community forum |Navigates to the Apache Wiki page which has further information about ways to engage in the Solr User community mailing lists: https://wiki.apache.org/solr/UsingMailingLists.\n+|Solr Query Syntax |Navigates to the section <<query-syntax-and-parsing.adoc#query-syntax-and-parsing,Query Syntax and Parsing>> in this Reference Guide.\n+|===\n+\n+These links cannot be modified without editing the `index.html` in the `server/solr/solr-webapp` directory that contains the Admin UI files.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-assistance.adoc",
                "sha": "85f9cecbb59b8532a54acb7a9d58e14fc789a017",
                "status": "added"
            },
            {
                "additions": 159,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-started-with-solrcloud.adoc",
                "changes": 159,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/getting-started-with-solrcloud.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/getting-started-with-solrcloud.adoc",
                "patch": "@@ -0,0 +1,159 @@\n+= Getting Started with SolrCloud\n+:page-shortname: getting-started-with-solrcloud\n+:page-permalink: getting-started-with-solrcloud.html\n+\n+SolrCloud is designed to provide a highly available, fault tolerant environment for distributing your indexed content and query requests across multiple servers.\n+\n+It's a system in which data is organized into multiple pieces, or shards, that can be hosted on multiple machines, with replicas providing redundancy for both scalability and fault tolerance, and a ZooKeeper server that helps manage the overall structure so that both indexing and search requests can be routed properly.\n+\n+This section explains SolrCloud and its inner workings in detail, but before you dive in, it's best to have an idea of what it is you're trying to accomplish.\n+\n+This page provides a simple tutorial to start Solr in SolrCloud mode, so you can begin to get a sense for how shards interact with each other during indexing and when serving queries. To that end, we'll use simple examples of configuring SolrCloud on a single machine, which is obviously not a real production environment, which would include several servers or virtual machines. In a real production environment, you'll also use the real machine names instead of \"localhost\" which we've used here.\n+\n+In this section you will learn how to start a SolrCloud cluster using startup scripts and a specific configset.\n+\n+[TIP]\n+====\n+This tutorial assumes that you're already familiar with the basics of using Solr. If you need a refresher, please see the <<getting-started.adoc#getting-started,Getting Started section>> to get a grounding in Solr concepts. If you load documents as part of that exercise, you should start over with a fresh Solr installation for these SolrCloud tutorials.\n+====\n+\n+[[GettingStartedwithSolrCloud-SolrCloudExample]]\n+== SolrCloud Example\n+\n+[[GettingStartedwithSolrCloud-InteractiveStartup]]\n+=== Interactive Startup\n+\n+The `bin/solr` script makes it easy to get started with SolrCloud as it walks you through the process of launching Solr nodes in cloud mode and adding a collection. To get started, simply do:\n+\n+[source,bash]\n+----\n+bin/solr -e cloud\n+----\n+\n+This starts an interactive session to walk you through the steps of setting up a simple SolrCloud cluster with embedded ZooKeeper.\n+\n+The script starts by asking you how many Solr nodes you want to run in your local cluster, with the default being 2.\n+\n+[source,plain]\n+----\n+Welcome to the SolrCloud example!\n+\n+This interactive session will help you launch a SolrCloud cluster on your local workstation.\n+To begin, how many Solr nodes would you like to run in your local cluster? (specify 1-4 nodes) [2]\n+----\n+\n+The script supports starting up to 4 nodes, but we recommend using the default of 2 when starting out. These nodes will each exist on a single machine, but will use different ports to mimic operation on different servers.\n+\n+Next, the script will prompt you for the port to bind each of the Solr nodes to, such as:\n+\n+[source,plain]\n+----\n+ Please enter the port for node1 [8983]\n+----\n+\n+Choose any available port for each node; the default for the first node is 8983 and 7574 for the second node. The script will start each node in order and show you the command it uses to start the server, such as:\n+\n+[source,bash]\n+----\n+solr start -cloud -s example/cloud/node1/solr -p 8983\n+----\n+\n+The first node will also start an embedded ZooKeeper server bound to port 9983. The Solr home for the first node is in `example/cloud/node1/solr` as indicated by the `-s` option.\n+\n+After starting up all nodes in the cluster, the script prompts you for the name of the collection to create:\n+\n+[source,plain]\n+----\n+ Please provide a name for your new collection: [gettingstarted]\n+----\n+\n+The suggested default is \"gettingstarted\" but you might want to choose a name more appropriate for your specific search application.\n+\n+Next, the script prompts you for the number of shards to distribute the collection across. <<shards-and-indexing-data-in-solrcloud.adoc#shards-and-indexing-data-in-solrcloud,Sharding>> is covered in more detail later on, so if you're unsure, we suggest using the default of 2 so that you can see how a collection is distributed across multiple nodes in a SolrCloud cluster.\n+\n+Next, the script will prompt you for the number of replicas to create for each shard.  <<shards-and-indexing-data-in-solrcloud.adoc#shards-and-indexing-data-in-solrcloud,Replication>> is covered in more detail later in the guide, so if you're unsure, then use the default of 2 so that you can see how replication is handled in SolrCloud.\n+\n+Lastly, the script will prompt you for the name of a configuration directory for your collection. You can choose *basic_configs*, *data_driven_schema_configs*, or *sample_techproducts_configs*. The configuration directories are pulled from `server/solr/configsets/` so you can review them beforehand if you wish. The *data_driven_schema_configs* configuration (the default) is useful when you're still designing a schema for your documents and need some flexiblity as you experiment with Solr.\n+\n+At this point, you should have a new collection created in your local SolrCloud cluster. To verify this, you can run the status command:\n+\n+[source,bash]\n+----\n+bin/solr status\n+----\n+\n+If you encounter any errors during this process, check the Solr log files in `example/cloud/node1/logs` and `example/cloud/node2/logs`.\n+\n+You can see how your collection is deployed across the cluster by visiting the cloud panel in the Solr Admin UI: http://localhost:8983/solr/#/~cloud. Solr also provides a way to perform basic diagnostics for a collection using the healthcheck command:\n+\n+[source,bash]\n+----\n+bin/solr healthcheck -c gettingstarted\n+----\n+\n+The healthcheck command gathers basic information about each replica in a collection, such as number of docs, current status (active, down, etc), and address (where the replica lives in the cluster).\n+\n+Documents can now be added to SolrCloud using the <<post-tool.adoc#post-tool,Post Tool>>.\n+\n+To stop Solr in SolrCloud mode, you would use the `bin/solr` script and issue the `stop` command, as in:\n+\n+[source,bash]\n+----\n+bin/solr stop -all\n+----\n+\n+[[GettingStartedwithSolrCloud-Startingwith-noprompt]]\n+=== Starting with -noprompt\n+\n+You can also get SolrCloud started with all the defaults instead of the interactive session using the following command:\n+\n+[source,bash]\n+----\n+bin/solr -e cloud -noprompt\n+----\n+\n+[[GettingStartedwithSolrCloud-RestartingNodes]]\n+=== Restarting Nodes\n+\n+You can restart your SolrCloud nodes using the `bin/solr` script. For instance, to restart node1 running on port 8983 (with an embedded ZooKeeper server), you would do:\n+\n+[source,bash]\n+----\n+bin/solr restart -c -p 8983 -s example/cloud/node1/solr\n+----\n+\n+To restart node2 running on port 7574, you can do:\n+\n+[source,bash]\n+----\n+bin/solr restart -c -p 7574 -z localhost:9983 -s example/cloud/node2/solr\n+----\n+\n+Notice that you need to specify the ZooKeeper address (`-z localhost:9983`) when starting node2 so that it can join the cluster with node1.\n+\n+[[GettingStartedwithSolrCloud-Addinganodetoacluster]]\n+=== Adding a node to a cluster\n+\n+Adding a node to an existing cluster is a bit advanced and involves a little more understanding of Solr. Once you startup a SolrCloud cluster using the startup scripts, you can add a new node to it by:\n+\n+[source,bash]\n+----\n+mkdir <solr.home for new solr node>\n+cp <existing solr.xml path> <new solr.home>\n+bin/solr start -cloud -s solr.home/solr -p <port num> -z <zk hosts string>\n+----\n+\n+Notice that the above requires you to create a Solr home directory. You either need to copy `solr.xml` to the `solr_home` directory, or keep in centrally in ZooKeeper `/solr.xml`.\n+\n+Example (with directory structure) that adds a node to an example started with \"bin/solr -e cloud\":\n+\n+[source,bash]\n+----\n+mkdir -p example/cloud/node3/solr\n+cp server/solr/solr.xml example/cloud/node3/solr\n+bin/solr start -cloud -s example/cloud/node3/solr -p 8987 -z localhost:9983\n+----\n+\n+The previous command will start another Solr node on port 8987 with Solr home set to `example/cloud/node3/solr`. The new node will write its log files to `example/cloud/node3/logs`.\n+\n+Once you're comfortable with how the SolrCloud example works, we recommend using the process described in <<taking-solr-to-production.adoc#taking-solr-to-production,Taking Solr to Production>> for setting up SolrCloud nodes in production.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-started-with-solrcloud.adoc",
                "sha": "3f7eb65c3fc86d12a6bcd4325970c975581113c9",
                "status": "added"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-started.adoc",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/getting-started.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/getting-started.adoc",
                "patch": "@@ -0,0 +1,27 @@\n+= Getting Started\n+:page-shortname: getting-started\n+:page-permalink: getting-started.html\n+:page-children: installing-solr, running-solr, a-quick-overview, a-step-closer, solr-control-script-reference\n+\n+Solr makes it easy for programmers to develop sophisticated, high-performance search applications with advanced features such as faceting (arranging search results in columns with numerical counts of key terms).\n+\n+Solr builds on another open source search technology: Lucene, a Java library that provides indexing and search technology, as well as spellchecking, hit highlighting and advanced analysis/tokenization capabilities. Both Solr and Lucene are managed by the Apache Software Foundation (http://www.apache.org/[www.apache.org)].\n+\n+The Lucene search library currently ranks among the top 15 open source projects and is one of the top 5 Apache projects, with installations at over 4,000 companies. Lucene/Solr downloads have grown nearly ten times over the past three years, with a current run-rate of over 6,000 downloads a day. The Solr search server, which provides application builders a ready-to-use search platform on top of the Lucene search library, is the fastest growing Lucene sub-project. Apache Lucene/Solr offers an attractive alternative to the proprietary licensed search and discovery software vendors.\n+\n+This section helps you get Solr up and running quickly, and introduces you to the basic Solr architecture and features. It covers the following topics:\n+\n+<<installing-solr.adoc#installing-solr,Installing Solr>>: A walkthrough of the Solr installation process.\n+\n+<<running-solr.adoc#running-solr,Running Solr>>: An introduction to running Solr. Includes information on starting up the servers, adding documents, and running queries.\n+\n+<<a-quick-overview.adoc#a-quick-overview,A Quick Overview>>: A high-level overview of how Solr works.\n+\n+<<a-step-closer.adoc#a-step-closer,A Step Closer>>: An introduction to Solr's home directory and configuration options.\n+\n+<<solr-control-script-reference.adoc#solr-control-script-reference,Solr Control Script Reference>>: a complete reference of all of the commands and options available with the bin/solr script.\n+\n+[TIP]\n+====\n+Solr includes a Quick Start tutorial which will be helpful if you are just starting out with Solr. You can find it online at http://lucene.apache.org/solr/quickstart.html, or in your Solr installation at `$SOLR_INSTALL_DIR/docs/quickstart.html`.\n+====",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/getting-started.adoc",
                "sha": "3fd7c76ffd6858b7aa5301dfd052a112836f75bc",
                "status": "added"
            },
            {
                "additions": 532,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/graph-traversal.adoc",
                "changes": 532,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/graph-traversal.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/graph-traversal.adoc",
                "patch": "@@ -0,0 +1,532 @@\n+= Graph Traversal\n+:page-shortname: graph-traversal\n+:page-permalink: graph-traversal.html\n+\n+Graph traversal with streaming expressions uses the `gatherNodes` function to perform a breadth-first graph traversal.\n+\n+The `gatherNodes` function can be combined with the `scoreNodes` function to provide recommendations. `gatherNodes` can also be combined with the wider streaming expression library to perform complex operations on gathered node sets.\n+\n+`gatherNodes` traversals are distributed within a SolrCloud collection and can span collections.\n+\n+`gatherNodes` is designed for use cases that involve zooming into a neighborhood in the graph and performing precise traversals to gather node sets and aggregations. In these types of use cases `gatherNodes` will often provide sub-second performance. Some sample use cases are provided later in the document.\n+\n+[IMPORTANT]\n+====\n+This document assumes a basic understanding of graph terminology and streaming expressions. You can begin exploring graph traversal concepts with this https://en.wikipedia.org/wiki/Graph_traversal[Wikipedia article]. More details about streaming expressions are available in this Guide, in the section <<streaming-expressions.adoc#streaming-expressions,Streaming Expressions>>.\n+====\n+\n+[[GraphTraversal-BasicSyntax]]\n+== Basic Syntax\n+\n+We'll start with the most basic syntax and slowly build up more complexity. The most basic syntax for `gatherNodes` is:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            walk=\"johndoe@apache.org->from\",\n+            gather=\"to\")\n+----\n+\n+Let's break down this simple expression.\n+\n+The first parameter, `emails`, is the collection being traversed. The second parameter, `walk`, maps a hard-coded node ID (\"\\johndoe@apache.org\") to a field in the index (`from`). This will return all the *edges* in the index that have `johndoe@apache.org` in the `from` field.\n+\n+The `gather` parameter tells the function to gather the values in the `to `field. The values that are gathered are the node IDs emitted by the function.\n+\n+In the example above the nodes emitted will be all of the people that \"johndoe@apache.org\" has emailed.\n+\n+The walk parameter also accepts a list of root node IDs:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            walk=\"johndoe@apache.org, janesmith@apache.org->from\",\n+            gather=\"to\")\n+----\n+\n+The `gatherNodes` function above finds all the edges with \"johndoe@apache.org\" or \"janesmith@apache.org\" in the `from` field and gathers the `to` field.\n+\n+Like all <<streaming-expressions.adoc#streaming-expressions,Streaming Expressions>>, you can execute a `gatherNodes` expression by sending it to the `/stream` handler. For example:\n+\n+[source,bash]\n+----\n+curl --data-urlencode 'expr=gatherNodes(emails,\n+                                        walk=\"johndoe@apache.org, janesmith@apache.org->from\",\n+                                        gather=\"to\")' http://localhost:8983/solr/emails/stream\n+----\n+\n+The output of this expression would look like this:\n+\n+[source,json]\n+----\n+{\n+  \"result-set\": {\n+    \"docs\": [\n+      {\n+        \"node\": \"slist@campbell.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"node\": \"catherine.pernot@enron.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"node\": \"airam.arteaga@enron.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"EOF\": true,\n+        \"RESPONSE_TIME\": 44\n+      }\n+    ]\n+  }\n+}\n+----\n+\n+All of the tuples returned have the `node` field. The `node` field contains the node IDs gathered by the function. The `collection`, `field`, and `level` of the traversal are also included in the output.\n+\n+Notice that the level is \"1\" for each tuple in the example. The root nodes are level 0 (in the example above, the root nodes are \"johndoe@apache.org, janesmith@apache.org\") By default the `gatherNodes` function emits only the _*leaf nodes*_ of the traversal, which is the outer-most node set. To emit the root nodes you can specify the `scatter` parameter:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            walk=\"johndoe@apache.org->from\",\n+            gather=\"to\",\n+            scatter=\"branches, leaves\")\n+----\n+\n+The `scatter` parameter controls whether to emit the _branches_ with the _leaves_. The root nodes are considered \"branches\" because they are not the outer-most level of the traversal.\n+\n+When scattering both branches and leaves the output would like this:\n+\n+[source,json]\n+----\n+{\n+  \"result-set\": {\n+    \"docs\": [\n+      {\n+        \"node\": \"johndoe@apache.org\",\n+        \"collection\": \"emails\",\n+        \"field\": \"node\",\n+        \"level\": 0\n+      },\n+      {\n+        \"node\": \"slist@campbell.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"node\": \"catherine.pernot@enron.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"node\": \"airam.arteaga@enron.com\",\n+        \"collection\": \"emails\",\n+        \"field\": \"to\",\n+        \"level\": 1\n+      },\n+      {\n+        \"EOF\": true,\n+        \"RESPONSE_TIME\": 44\n+      }\n+    ]\n+  }\n+}\n+----\n+\n+Now the level 0 root node is included in the output.\n+\n+[[GraphTraversal-Aggregations]]\n+== Aggregations\n+\n+`gatherNodes` also supports aggregations. For example:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            walk=\"johndoe@apache.org, janesmith@apache.org->from\",\n+            gather=\"to\",\n+            count(*))\n+----\n+\n+The expression above finds the edges with \"\\johndoe@apache.org\" or \"\\janesmith@apache.org\" in the `from` field and gathers the values from the `to` field. It also aggregates the count for each node ID gathered.\n+\n+A gathered node could have a count of 2 if both \"\\johndoe@apache.org\" and \"\\janesmith@apache.org\" have emailed the same person. Node sets contain a unique set of nodes, so the same person won't appear twice in the node set, but the count will reflect that it appeared twice during the traversal.\n+\n+Edges are uniqued as part of the traversal so the count will *not* reflect the number of times \"\\johndoe@apache.org\" emailed the same person. For example, personA might have emailed personB 100 times. These edges would get uniqued and only be counted once. But if person personC also emailed personB this would increment the count for personB.\n+\n+The aggregation functions supported are `count(*)`, `sum(field)`, `min(field)`, `max(field)`, and `avg(field)`. The fields being aggregated should be present in the edges collected during the traversal. Later examples (below) will show aggregations can be a powerful tool for providing recommendations and limiting the scope of traversals.\n+\n+[[GraphTraversal-NestinggatherNodesfunctions]]\n+== Nesting gatherNodes functions\n+\n+The `gatherNodes` function can be nested to traverse deeper into the graph. For example:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            gatherNodes(emails,\n+                        walk=\"johndoe@apache.org->from\",\n+                        gather=\"to\"),\n+            walk=\"node->from\",\n+            gather=\"to\")\n+----\n+\n+In the example above the outer `gatherNodes` function operates on the node set collected from the inner `gatherNodes` function.\n+\n+Notice that the inner `gatherNodes` function behaves exactly as the examples already discussed. But the `walk` parameter of the outer `gatherNodes` function behaves differently.\n+\n+In the outer `gatherNodes` function the `walk` parameter works with tuples coming from an internal streaming expression. In this scenario the `walk` parameter maps the `node` field to the `from` field. Remember that the node IDs collected from the inner `gatherNodes` expression are placed in the `node` field.\n+\n+Put more simply, the inner expression gathers all the people that \"\\johndoe@apache.org\" has emailed. We can call this group the \"friends of \\johndoe@apache.org\". The outer expression gathers all the people that the \"friends of \\johndoe@apache.org\" have emailed. This is a basic friends-of-friends traversal.\n+\n+This construct of nesting `gatherNodes` functions is the basic technique for doing a controlled traversal through the graph.\n+\n+[[GraphTraversal-CycleDetection]]\n+== Cycle Detection\n+\n+The `gatherNodes` function performs cycle detection across the entire traversal. This ensures that nodes that have already been visited are not traversed again. Cycle detection is important for both limiting the size of traversals and gathering accurate aggregations. Without cycle detection the size of the traversal could grow exponentially with each hop in the traversal. With cycle detection only new nodes encountered are traversed.\n+\n+Cycle detection *does not* cross collection boundaries. This is because internally the collection name is part of the node ID. For example the node ID \"\\johndoe@apache.org\", is really `emails/johndoe@apache.org`. When traversing to another collection \"\\johndoe@apache.org\" will be traversed.\n+\n+[[GraphTraversal-FilteringtheTraversal]]\n+== Filtering the Traversal\n+\n+Each level in the traversal can be filtered with a filter query. For example:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            walk=\"johndoe@apache.org->from\",\n+            fq=\"body:(solr rocks)\",\n+            gather=\"to\")\n+----\n+\n+In the example above only emails that match the filter query will be included in the traversal. Any Solr query can be included here. So you can do fun things like <<spatial-search.adoc#spatial-search,geospatial queries>>, apply any of the available <<query-syntax-and-parsing.adoc#query-syntax-and-parsing,query parsers>>, or even write custom query parsers to limit the traversal.\n+\n+[[GraphTraversal-RootStreams]]\n+== Root Streams\n+\n+Any streaming expression can be used to provide the root nodes for a traversal. For example:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            search(emails, q=\"body:(solr rocks)\", fl=\"to\", sort=\"score desc\", rows=\"20\")\n+            walk=\"to->from\",\n+            gather=\"to\")\n+----\n+\n+The example above provides the root nodes through a search expression. You can also provide arbitrarily complex, nested streaming expressions with joins, etc., to specify the root nodes.\n+\n+Notice that the `walk` parameter maps a field from the tuples generated by the inner stream. In this case it maps the `to` field from the inner stream to the `from` field.\n+\n+[[GraphTraversal-SkippingHighFrequencyNodes]]\n+== Skipping High Frequency Nodes\n+\n+It's often desirable to skip traversing high frequency nodes in the graph. This is similar in nature to a search term stop list. The best way to describe this is through an example use case.\n+\n+Let's say that you want to recommend content for a user based on a collaborative filter. Below is one approach for a simple collaborative filter:\n+\n+. Find all content userA has read.\n+. Find users whose reading list is closest to userA. These are users with similar tastes as userA.\n+. Recommend content based on what the users in step 2 have read, that userA has not yet read.\n+\n+Look closely at step 2. In large graphs, step 2 can lead to a very large traversal. This is because userA may have viewed content that has been viewed by millions of other people. We may want to skip these high frequency nodes for two reasons:\n+\n+. A large traversal that visit millions of unique nodes is slow and takes a lot of memory because cycle detection is tracked in memory.\n+. High frequency nodes are also not useful in determining users with similar tastes. The content that fewer people have viewed provides a more precise recommendation.\n+\n+The `gatherNodes` function has the `maxDocFreq` param to allow for filtering out high frequency nodes. The sample code below shows steps 1 and 2 of the recommendation:\n+\n+[source,plain]\n+----\n+ gatherNodes(logs,\n+             search(logs, q=\"userID:user1\", fl=\"articleID\", sort=\"articleID asc\", fq=\"action:view\", qt=\"/export\"),\n+             walk=\"articleID->articleID\",\n+             gather=\"userID\",\n+             fq=\"action:view\",\n+             maxDocFreq=\"10000\",\n+             count(*)))\n+----\n+\n+In the example above, the inner search expression searches the `logs` collection and returning all the articles viewed by \"user1\". The outer `gatherNodes` expression takes all the articles emitted from the inner search expression and finds all the records in the logs collection for those articles. It then gathers and aggregates the users that have read the articles. The `maxDocFreq` parameter limits the articles returned to those that appear in no more then 10,000 log records (per shard). This guards against returning articles that have been viewed by millions of users.\n+\n+[[GraphTraversal-TrackingtheTraversal]]\n+== Tracking the Traversal\n+\n+By default the `gatherNodes` function only tracks enough information to do cycle detection. This provides enough information to output the nodes and aggregations in the graph.\n+\n+For some use cases, such as graph visualization, we also need to output the edges. Setting `trackTraversal=\"true\"` tells `gatherNodes` to track the connections between nodes, so the edges can be constructed. When `trackTraversal` is enabled a new `ancestors` property will appear with each node. The `ancestors` property contains a list of node IDs that pointed to the node.\n+\n+Below is a sample `gatherNodes` expression with `trackTraversal` set to true:\n+\n+[source,plain]\n+----\n+gatherNodes(emails,\n+            gatherNodes(emails,\n+                        walk=\"johndoe@apache.org->from\",\n+                        gather=\"to\",\n+                        trackTraversal=\"true\"),\n+            walk=\"node->from\",\n+            trackTraversal=\"true\",\n+            gather=\"to\")\n+----\n+\n+[[GraphTraversal-Cross-CollectionTraversals]]\n+== Cross-Collection Traversals\n+\n+Nested `gatherNodes` functions can operate on different SolrCloud collections. This allow traversals to \"walk\" from one collection to another to gather nodes. Cycle detection does not cross collection boundaries, so nodes collected in one collection will be traversed in a different collection. This was done deliberately to support cross-collection traversals. Note that the output from a cross-collection traversal will likely contain duplicate nodes with different collection attributes.\n+\n+Below is a sample `gatherNodes` expression that traverses from the \"emails\" collection to the \"logs\" collection:\n+\n+[source,plain]\n+----\n+gatherNodes(logs,\n+            gatherNodes(emails,\n+                        search(emails, q=\"body:(solr rocks)\", fl=\"from\", sort=\"score desc\", rows=\"20\")\n+                        walk=\"from->from\",\n+                        gather=\"to\",\n+                        scatter=\"leaves, branches\"),\n+            walk=\"node->user\",\n+            fq=\"action:edit\",\n+            gather=\"contentID\")\n+----\n+\n+The example above finds all people who sent emails with a body that contains \"solr rocks\". It then finds all the people these people have emailed. Then it traverses to the logs collection and gathers all the content IDs that these people have edited.\n+\n+[[GraphTraversal-CombininggatherNodesWithOtherStreamingExpressions]]\n+== Combining gatherNodes With Other Streaming Expressions\n+\n+The `gatherNodes` function can act as both a stream source and a stream decorator. The connection with the wider stream expression library provides tremendous power and flexibility when performing graph traversals. Here is an example of using the streaming expression library to intersect two friend networks:\n+\n+[source,plain]\n+----\n+            intersect(on=\"node\",\n+                      sort(by=\"node asc\",\n+                           gatherNodes(emails,\n+                                       gatherNodes(emails,\n+                                                   walk=\"johndoe@apache.org->from\",\n+                                                   gather=\"to\"),\n+                                       walk=\"node->from\",\n+                                       gather=\"to\",\n+                                       scatter=\"branches,leaves\")),\n+                       sort(by=\"node asc\",\n+                            gatherNodes(emails,\n+                                        gatherNodes(emails,\n+                                                    walk=\"janedoe@apache.org->from\",\n+                                                    gather=\"to\"),\n+                                        walk=\"node->from\",\n+                                        gather=\"to\",\n+                                        scatter=\"branches,leaves\")))\n+----\n+\n+The example above gathers two separate friend networks, one rooted with \"\\johndoe@apache.org\" and another rooted with \"\\janedoe@apache.org\". The friend networks are then sorted by the `node` field, and intersected. The resulting node set will be the intersection of the two friend networks.\n+\n+[[GraphTraversal-SampleUseCases]]\n+== Sample Use Cases\n+\n+[[GraphTraversal-CalculateMarketBasketCo-occurrence]]\n+=== Calculate Market Basket Co-occurrence\n+\n+It is often useful to know which products are most frequently purchased with a particular product. This example uses a simple market basket table (indexed in Solr) to store past shopping baskets. The schema for the table is very simple with each row containing a `basketID` and a `productID`. This can be seen as a graph with each row in the table representing an edge. And it can be traversed very quickly to calculate basket co-occurrence, even when the graph contains billions of edges.\n+\n+Here is the sample syntax:\n+\n+[source,plain]\n+----\n+top(n=\"5\",\n+    sort=\"count(*) desc\",\n+    gatherNodes(baskets,\n+                random(baskets, q=\"productID:ABC\", fl=\"basketID\", rows=\"500\"),\n+                walk=\"basketID->basketID\",\n+                fq=\"-productID:ABC\",\n+                gather=\"productID\",\n+                count(*)))\n+----\n+\n+Let's break down exactly what this traversal is doing.\n+\n+. The first expression evaluated is the inner `random` expression, which returns 500 random basketIDs, from the `baskets` collection, that have the `productID` \"ABC\". The `random` expression is very useful for recommendations because it limits the traversal to a fixed set of baskets, and because it adds the element of surprise into the recommendation. Using the `random` function you can provide fast sample sets from very large graphs.\n+. The outer `gatherNodes` expression finds all the records in the `baskets` collection for the basketIDs generated in step 1. It also filters out `productID` \"ABC\" so it doesn't show up in the results. It then gathers and counts the productID's across these baskets.\n+. The outer `top` expression ranks the productIDs emitted in step 2 by the count and selects the top 5.\n+\n+In a nutshell this expression finds the products that most frequently co-occur with product \"ABC\" in past shopping baskets.\n+\n+[[GraphTraversal-UsingthescoreNodesFunctiontoMakeaRecommendation]]\n+=== Using the scoreNodes Function to Make a Recommendation\n+\n+This use case builds on the market basket example <<GraphTraversal-CalculateMarketBasketCo-occurrence,above>> that calculates which products co-occur most frequently with productID:ABC. The ranked co-occurrence counts provide candidates for a recommendation. The `scoreNodes` function can be used to score the candidates to find the best recommendation.\n+\n+Before diving into the syntax of the `scoreNodes` function it's useful to understand why the raw co-occurrence counts may not produce the best recommendation. The reason is that raw co-occurrence counts favor items that occur frequently across all baskets. A better recommendation would find the product that has the most significant relationship with productID ABC. The `scoreNodes` function uses a term frequency-inverse document frequency (TF-IDF) algorithm to find the most significant relationship.\n+\n+[[GraphTraversal-HowItWorks]]\n+==== *How It Works*\n+\n+The `scoreNodes` function assigns a score to each node emitted by the gatherNodes expression. By default the `scoreNodes` function uses the `count(*)` aggregation, which is the co-occurrence count, as the TF value. The IDF value for each node is fetched from the collection where the node was gathered. Each node is then scored using the TF*IDF formula, which provides a boost to nodes with a lower frequency across all market baskets.\n+\n+Combining the co-occurrence count with the IDF provides a score that shows how important the relationship is between productID ABC and the recommendation candidates.\n+\n+The `scoreNodes` function adds the score to each node in the `nodeScore` field.\n+\n+[[GraphTraversal-ExampleSyntax]]\n+==== *Example Syntax*\n+\n+[source,plain]\n+----\n+top(n=\"1\",\n+    sort=\"nodeScore desc\",\n+    scoreNodes(top(n=\"50\",\n+                   sort=\"count(*) desc\",\n+                   gatherNodes(baskets,\n+                               random(baskets, q=\"productID:ABC\", fl=\"basketID\", rows=\"500\"),\n+                               walk=\"basketID->basketID\",\n+                               fq=\"-productID:ABC\",\n+                               gather=\"productID\",\n+                               count(*)))))\n+----\n+\n+This example builds on the earlier example \"Calculate market basket co-occurrence\".\n+\n+. Notice that the inner-most `top` function is taking the top 50 products that co-occur most frequently with productID ABC. This provides 50 candidate recommendations.\n+. The `scoreNodes` function then assigns a score to the candidates based on the TF*IDF of each node.\n+. The outer `top` expression selects the highest scoring node. This is the recommendation.\n+\n+[[GraphTraversal-RecommendContentBasedonCollaborativeFilter]]\n+=== Recommend Content Based on Collaborative Filter\n+\n+In this example we'll recommend content for a user based on a collaborative filter. This recommendation is made using log records that contain the `userID` and `articleID` and the action performed. In this scenario each log record can be viewed as an edge in a graph. The userID and articleID are the nodes and the action is an edge property used to filter the traversal.\n+\n+Here is the sample syntax:\n+\n+[source,plain]\n+----\n+top(n=\"5\",\n+    sort=\"count(*) desc\",\n+    gatherNodes(logs,\n+                top(n=\"30\",\n+                    sort=\"count(*) desc\",\n+                    gatherNodes(logs,\n+                                search(logs, q=\"userID:user1\", fl=\"articleID\", sort=\"articleID asc\", fq=\"action:read\", qt=\"/export\"),\n+                                walk=\"articleID->articleID\",\n+                                gather=\"userID\",\n+                                fq=\"action:read\",\n+                                maxDocFreq=\"10000\",\n+                                count(*))),\n+                walk=\"node->userID\",\n+                gather=\"articleID\",\n+                fq=\"action:read\",\n+                count(*)))\n+----\n+\n+Let's break down the expression above step-by-step.\n+\n+. The first expression evaluated is the inner `search` expression. This expression searches the `logs` collection for all records matching \"user1\". This is the user we are making the recommendation for.\n++\n+There is a filter applied to pull back only records where the \"action:read\". It returns the `articleID` for each record found. In other words, this expression returns all the articles \"user1\" has read.\n+. The inner `gatherNodes` expression operates over the articleIDs returned from step 1. It takes each `articleID` found and searches them against the `articleID` field.\n++\n+Note that it skips high frequency nodes using the `maxDocFreq` param to filter out articles that appear over 10,000 times in the logs. It gathers userIDs and aggregates the counts for each user. This step finds the users that have read the same articles that \"user1\" has read and counts how many of the same articles they have read.\n+. The inner `top` expression ranks the users emitted from step 2. It will emit the top 30 users who have the most overlap with user1's reading list.\n+. The outer `gatherNodes` expression gathers the reading list for the users emitted from step 3. It counts the articleIDs that are gathered.\n++\n+Any article selected in step 1 (user1 reading list), will not appear in this step due to cycle detection. So this step returns the articles read by the users with the most similar readings habits to \"user1\" that \"user1\" has not read yet. It also counts the number of times each article has been read across this user group.\n+. The outer `top` expression takes the top articles emitted from step 4. This is the recommendation.\n+\n+[[GraphTraversal-ProteinPathwayTraversal]]\n+=== Protein Pathway Traversal\n+\n+In recent years, scientists have become increasingly able to rationally design drugs that target the mutated proteins, called oncogenes, responsible for some cancers. Proteins typically act through long chains of chemical interactions between multiple proteins, called pathways, and, while the oncogene in the pathway may not have a corresponding drug, another protein in the pathway may. Graph traversal on a protein collection that records protein interactions and drugs may yield possible candidates. (Thanks to Lewis Geer of the NCBI, for providing this example).\n+\n+The example below illustrates a protein pathway traversal:\n+\n+[source,plain]\n+----\n+gatherNodes(proteins,\n+            gatherNodes(proteins,\n+                        walk=\"NRAS->name\",\n+                        gather=\"interacts\"),\n+            walk=\"node->name\",\n+            gather=\"drug\")\n+----\n+\n+Let's break down exactly what this traversal is doing.\n+\n+. The inner `gatherNodes` expression traverses in the `proteins` collection. It finds all the edges in the graph where the name of the protein is \"NRAS\". Then it gathers the proteins in the `interacts` field. This gathers all the proteins that \"NRAS\" interactions with.\n+. The outer `gatherNodes` expression also works with the `proteins` collection. It gathers all the drugs that correspond to proteins emitted from step 1.\n+. Using this stepwise approach you can gather the drugs along the pathway of interactions any number of steps away from the root protein.\n+\n+[[GraphTraversal-ExportingGraphMLtoSupportGraphVisualization]]\n+== Exporting GraphML to Support Graph Visualization\n+\n+In the examples above, the `gatherNodes` expression was sent to Solr's `/stream` handler like any other streaming expression. This approach outputs the nodes in the same JSON tuple format as other streaming expressions so that it can be treated like any other streaming expression. You can use the `/stream` handler when you need to operate directly on the tuples, such as in the recommendation use cases above.\n+\n+There are other graph traversal use cases that involve graph visualization. Solr supports these use cases with the introduction of the `/graph` request handler, which takes a `gatherNodes` expression and outputs the results in GraphML.\n+\n+http://graphml.graphdrawing.org/[GraphML] is an XML format supported by graph visualization tools such as https://gephi.org/[Gephi], which is a sophisticated open source tool for statistically analyzing and visualizing graphs. Using a `gatherNodes` expression, parts of a larger graph can be exported in GraphML and then imported into tools like Gephi.\n+\n+There are a few things to keep mind when exporting a graph in GraphML:\n+\n+. The `/graph` handler can export both the nodes and edges in the graph. By default, it only exports the nodes. To export the edges you must set `trackTraversal=\"true\"` in the `gatherNodes` expression.\n+. The `/graph` handler currently accepts an arbitrarily complex streaming expression which includes a `gatherNodes` expression. If the streaming expression doesn't include a `gatherNodes` expression, the `/graph` handler will not properly output GraphML.\n+. The `/graph` handler currently accepts a single arbitrarily complex, nested `gatherNodes` expression per request. This means you cannot send in a streaming expression that joins or intersects the node sets from multiple `gatherNodes` expressions. The `/graph` handler does support any level of nesting within a single `gatherNodes` expression. The `/stream` handler does support joining and intersecting node sets, but the `/graph` handler currently does not.\n+\n+[[GraphTraversal-SampleRequest]]\n+=== Sample Request\n+\n+[source,bash]\n+----\n+curl --data-urlencode 'expr=gatherNodes(enron_emails,\n+                                        gatherNodes(enron_emails,\n+                                                    walk=\"kayne.coulter@enron.com->from\",\n+                                                    trackTraversal=\"true\",\n+                                                    gather=\"to\"),\n+                                        walk=\"node->from\",\n+                                        scatter=\"leaves,branches\",\n+                                        trackTraversal=\"true\",\n+                                        gather=\"to\")' http://localhost:8983/solr/enron_emails/graph\n+----\n+\n+[[GraphTraversal-SampleGraphMLOutput]]\n+=== Sample GraphML Output\n+\n+[source,xml]\n+----\n+<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\"\n+xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">\n+<graph id=\"G\" edgedefault=\"directed\">\n+     <node id=\"kayne.coulter@enron.com\">\n+           <data key=\"field\">node</data>\n+           <data key=\"level\">0</data>\n+           <data key=\"count(*)\">0.0</data>\n+     </node>\n+     <node id=\"don.baughman@enron.com\">\n+           <data key=\"field\">to</data>\n+           <data key=\"level\">1</data>\n+           <data key=\"count(*)\">1.0</data>\n+     </node>\n+     <edge id=\"1\"  source=\"kayne.coulter@enron.com\"  target=\"don.baughman@enron.com\"/>\n+     <node id=\"john.kinser@enron.com\">\n+           <data key=\"field\">to</data>\n+           <data key=\"level\">1</data>\n+           <data key=\"count(*)\">1.0</data>\n+    </node>\n+    <edge id=\"2\"  source=\"kayne.coulter@enron.com\"  target=\"john.kinser@enron.com\"/>\n+    <node id=\"jay.wills@enron.com\">\n+          <data key=\"field\">to</data>\n+          <data key=\"level\">1</data>\n+          <data key=\"count(*)\">1.0</data>\n+    </node>\n+    <edge id=\"3\"  source=\"kayne.coulter@enron.com\"  target=\"jay.wills@enron.com\"/>\n+</graph></graphml>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/graph-traversal.adoc",
                "sha": "66e55d2dfbdf7ef0adce26b1d5a7aefc2b925b3d",
                "status": "added"
            },
            {
                "additions": 116,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/hadoop-authentication-plugin.adoc",
                "changes": 116,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/hadoop-authentication-plugin.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/hadoop-authentication-plugin.adoc",
                "patch": "@@ -0,0 +1,116 @@\n+= Hadoop Authentication Plugin\n+:page-shortname: hadoop-authentication-plugin\n+:page-permalink: hadoop-authentication-plugin.html\n+\n+The Hadoop authentication plugin enables Solr to use the https://hadoop.apache.org/docs/stable/hadoop-auth/index.html[Hadoop authentication library] for securing Solr nodes.\n+\n+This authentication plugin is a thin wrapper that delegates all functionality to the Hadoop authentication library. All configuration parameters for the library are passed through the plugin.\n+\n+This plugin can be particularly useful in leveraging an extended set of features or newly available features in the Hadoop authentication library.\n+\n+Please note that the version of Hadoop library used by Solr is upgraded periodically. While Solr will ensure the stability and backwards compatibility of the structure of the plugin configuration (viz., the parameter names of this plugin), the values of these parameters may change based on the version of Hadoop library. Please review the Hadoop documentation for the version used by your Solr installation for more details.\n+\n+For some of the authentication schemes (e.g., Kerberos), Solr provides a native implementation of authentication plugin. If you require a more stable setup, in terms of configuration, ability to perform rolling upgrades, backward compatibility, etc., you should consider using such plugin. Please review the section <<authentication-and-authorization-plugins.adoc#authentication-and-authorization-plugins,Authentication and Authorization Plugins>> for an overview of authentication plugin options in Solr.\n+\n+There are two plugin classes:\n+\n+* `HadoopAuthPlugin`: This can be used with standalone Solr as well as Solrcloud with <<authentication-and-authorization-plugins.adoc#AuthenticationandAuthorizationPlugins-PKI,PKI authentication>> for internode communication.\n+* `ConfigurableInternodeAuthHadoopPlugin`: This is an extension of HadoopAuthPlugin that allows you to configure the authentication scheme for internode communication.\n+\n+[TIP]\n+====\n+For most SolrCloud or standalone Solr setups, the `HadoopAuthPlugin` should suffice.\n+====\n+\n+[[HadoopAuthenticationPlugin-PluginConfiguration]]\n+== Plugin Configuration\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,65\",options=\"header\"]\n+|===\n+|Parameter Name |Required |Description\n+|class |Yes |Should be either `solr.HadoopAuthPlugin` or `solr.ConfigurableInternodeAuthHadoopPlugin`.\n+|type |Yes |The type of authentication scheme to be configured. See https://hadoop.apache.org/docs/stable/hadoop-auth/Configuration.html[configuration] options.\n+|sysPropPrefix |Yes |The prefix to be used to define the Java system property for configuring the authentication mechanism. The name of the Java system property is defined by appending the configuration parameter name to this prefix value. For example, if the prefix is 'solr' then the Java system property 'solr.kerberos.principal' defines the value of configuration parameter 'kerberos.principal'.\n+|authConfigs |Yes |Configuration parameters required by the authentication scheme defined by the type property. For more details, see https://hadoop.apache.org/docs/stable/hadoop-auth/Configuration.html[Hadoop configuration] options.\n+|defaultConfigs |No |Default values for the configuration parameters specified by the `authConfigs` property. The default values are specified as a collection of key-value pairs (i.e., `property-name:default_value`).\n+|enableDelegationToken |No |Enable (or disable) the delegation tokens functionality.\n+|initKerberosZk |No |For enabling initialization of kerberos before connecting to Zookeeper (if applicable).\n+|proxyUserConfigs |No |Configures proxy users for the underlying Hadoop authentication mechanism. This configuration is expressed as a collection of key-value pairs (i.e., `property-name:value`).\n+|clientBuilderFactory |No |The `HttpClientBuilderFactory` implementation used for the Solr internal communication. Only applicable for `ConfigurableInternodeAuthHadoopPlugin`.\n+|===\n+\n+[[HadoopAuthenticationPlugin-ExampleConfigurations]]\n+== Example Configurations\n+\n+[[HadoopAuthenticationPlugin-KerberosAuthenticationusingHadoopAuthenticationPlugin]]\n+=== Kerberos Authentication using Hadoop Authentication Plugin\n+\n+This example lets you configure Solr to use Kerberos Authentication, similar to how you would use the <<kerberos-authentication-plugin.adoc#kerberos-authentication-plugin,Kerberos Authentication Plugin>>.\n+\n+After consulting the Hadoop authentication library's documentation, you can supply per host configuration parameters using the `solr.*` prefix. As an example, the Hadoop authentication library expects a parameter `kerberos.principal`, which can be supplied as a system property named `solr.kerberos.principal` when starting a Solr node. Refer to the section <<kerberos-authentication-plugin.adoc#kerberos-authentication-plugin,Kerberos Authentication Plugin>> for other typical configuration parameters.\n+\n+Please note that this example uses `ConfigurableInternodeAuthHadoopPlugin`, and hence you must provide the `clientBuilderFactory` implementation. As a result, all internode communication will use the Kerberos mechanism, instead of PKI authentication.\n+\n+To setup this plugin, use the following in your `security.json` file.\n+\n+[source,json]\n+----\n+{\n+    \"authentication\": {\n+        \"class\": \"solr.ConfigurableInternodeAuthHadoopPlugin\",\n+        \"sysPropPrefix\": \"solr.\",\n+        \"type\": \"kerberos\",\n+        \"clientBuilderFactory\": \"org.apache.solr.client.solrj.impl.Krb5HttpClientBuilder\",\n+        \"initKerberosZk\": \"true\",\n+        \"authConfigs\": [\n+            \"kerberos.principal\",\n+            \"kerberos.keytab\",\n+            \"kerberos.name.rules\"\n+        ],\n+        \"defaultConfigs\": {\n+        }\n+    }\n+}\n+----\n+\n+[[HadoopAuthenticationPlugin-SimpleAuthenticationwithDelegationTokens]]\n+=== Simple Authentication with Delegation Tokens\n+\n+Similar to the previous example, this is an example of setting up a Solr cluster that uses delegation tokens. Refer to the parameters in the Hadoop authentication library's https://hadoop.apache.org/docs/stable/hadoop-auth/Configuration.html[documentation] or refer to the section <<kerberos-authentication-plugin.adoc#kerberos-authentication-plugin,Kerberos Authentication Plugin>> for further details. Please note that this example does not use Kerberos and the requests made to Solr must contain valid delegation tokens.\n+\n+To setup this plugin, use the following in your `security.json` file.\n+\n+[source,json]\n+----\n+{\n+    \"authentication\": {\n+        \"class\": \"solr.HadoopAuthPlugin\",\n+        \"sysPropPrefix\": \"solr.\",\n+        \"type\": \"simple\",\n+        \"enableDelegationToken\":\"true\",\n+        \"authConfigs\": [\n+            \"delegation-token.token-kind\",\n+            \"delegation-token.update-interval.sec\",\n+            \"delegation-token.max-lifetime.sec\",\n+            \"delegation-token.renewal-interval.sec\",\n+            \"delegation-token.removal-scan-interval.sec\",\n+            \"cookie.domain\",\n+            \"signer.secret.provider\",\n+            \"zk-dt-secret-manager.enable\",\n+            \"zk-dt-secret-manager.znodeWorkingPath\",\n+            \"signer.secret.provider.zookeeper.path\"\n+        ],\n+        \"defaultConfigs\": {\n+            \"delegation-token.token-kind\": \"solr-dt\",\n+            \"signer.secret.provider\": \"zookeeper\",\n+            \"zk-dt-secret-manager.enable\": \"true\",\n+            \"token.validity\": \"36000\",\n+            \"zk-dt-secret-manager.znodeWorkingPath\": \"solr/security/zkdtsm\",\n+            \"signer.secret.provider.zookeeper.path\": \"/token\",\n+            \"cookie.domain\": \"127.0.0.1\"\n+        }\n+    }\n+}\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/hadoop-authentication-plugin.adoc",
                "sha": "cbbb3a15a920f7646f2e9668c765f4dcfbdd20ee",
                "status": "added"
            },
            {
                "additions": 293,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/highlighting.adoc",
                "changes": 293,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/highlighting.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/highlighting.adoc",
                "patch": "@@ -0,0 +1,293 @@\n+= Highlighting\n+:page-shortname: highlighting\n+:page-permalink: highlighting.html\n+\n+Highlighting in Solr allows fragments of documents that match the user's query to be included with the query response.\n+\n+The fragments are included in a special section of the query response (the `highlighting` section), and the client uses the formatting clues also included to determine how to present the snippets to users. Fragments are a portion of a document field that contains matches from the query and are sometimes also referred to as \"snippets\" or \"passages\".\n+\n+Highlighting is extremely configurable, perhaps more than any other part of Solr. There are many parameters each for fragment sizing, formatting, ordering, backup/alternate behavior, and more options that are hard to categorize. Nonetheless, highlighting is very simple to use.\n+\n+[[Highlighting-Usage]]\n+== Usage\n+\n+You only need to set the `hl` and often `hl.fl` parameters to get results. The following table documents these and some other supported parameters. Note that many highlighting parameters support per-field overrides, such as: `f._title_txt_.hl.snippets`\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,65\",options=\"header\"]\n+|===\n+|Parameter |Default |Description\n+|hl |false |Use this parameter to enable or disable highlighting.\n+|hl.method |original |The highlighting implementation to use. Acceptable values are: `unified`, `original`, `fastVector`, and `postings`. See the <<Highlighting-ChoosingaHighlighter,Choosing a Highlighter>> section below for more details on the differences between the available highlighters.\n+|hl.fl |_(df=)_ |Specifies a list of fields to highlight. Accepts a comma- or space-delimited list of fields for which Solr should generate highlighted snippets. A wildcard of `\\*` (asterisk) can be used to match field globs, such as `text_*` or even `\\*` to highlight on all fields where highlighting is possible. When using `\\*`, consider adding `hl.requireFieldMatch=true`.\n+|hl.q |_(q=)_ |A query to use for highlighting. This parameter allows you to highlight different terms than those being used to retrieve documents.\n+|hl.qparser |_(defType=)_ |The query parser to use for the `hl.q` query.\n+|hl.requireFieldMatch |false a|\n+By default, *false*, all query terms will be highlighted for each field to be highlighted (`hl.fl`) no matter what fields the parsed query refer to. If set to *true*, only query terms aligning with the field being highlighted will in turn be highlighted.\n+\n+Note: if the query references fields different from the field being highlighted and they have different text analysis, the query may not highlight query terms it should have and vice versa. The analysis used is that of the field being highlighted (`hl.fl`), not the query fields.\n+\n+|hl.usePhraseHighlighter |true |If set to *true*, Solr will highlight phrase queries (and other advanced position-sensitive queries) accurately \u2013 as phrases. If *false*, the parts of the phrase will be highlighted everywhere instead of only when it forms the given phrase.\n+|hl.highlightMultiTerm |true |If set to *true*, Solr will highlight wildcard queries (and other `MultiTermQuery` subclasses). If *false*, they won't be highlighted at all.\n+|hl.snippets |1 |Specifies maximum number of highlighted snippets to generate per field. It is possible for any number of snippets from zero to this value to be generated.\n+|hl.fragsize |100 |Specifies the approximate size, in characters, of fragments to consider for highlighting. *0* indicates that no fragmenting should be considered and the whole field value should be used.\n+|hl.tag.pre |<em> |(`hl.simple.pre` for the Original Highlighter) Specifies the \u201ctag\u201d to use before a highlighted term. This can be any string, but is most often an HTML or XML tag.\n+|hl.tag.post |</em> |(`hl.simple.post` for the Original Highlighter) Specifies the \u201ctag\u201d to use after a highlighted term. This can be any string, but is most often an HTML or XML tag.\n+|hl.encoder |_(blank)_ |If blank, the default, then the stored text will be returned without any escaping/encoding performed by the highlighter. If set to *html* then special HMTL/XML characters will be encoded (e.g. `&` becomes `\\&amp;`). The pre/post snippet characters are never encoded.\n+|hl.maxAnalyzedChars |51200 |The character limit to look for highlights, after which no highlighting will be done. This is mostly only a performance concern for an _analysis_ based offset source since it's the slowest. See <<Schema Options and Performance Considerations>>.\n+|===\n+\n+There are more parameters supported as well depending on the highlighter (via `hl.method`) chosen.\n+\n+[[Highlighting-HighlightingintheQueryResponse]]\n+=== Highlighting in the Query Response\n+\n+In the response to a query, Solr includes highlighting data in a section separate from the documents. It is up to a client to determine how to process this response and display the highlights to users.\n+\n+Using the example documents included with Solr, we can see how this might work:\n+\n+In response to a query such as:\n+\n+[source,text]\n+http://localhost:8983/solr/gettingstarted/select?hl=on&q=apple&wt=json&hl.fl=manu&fl=id,name,manu,cat\n+\n+we get a response such as this (truncated slightly for space):\n+\n+[source,json]\n+----\n+{\n+    \"responseHeader\": {\n+        \"...\"\n+        }\n+    },\n+    \"response\": {\n+        \"numFound\": 1,\n+        \"start\": 0,\n+        \"docs\": [{\n+            \"id\": \"MA147LL/A\",\n+            \"name\": \"Apple 60 GB iPod with Video Playback Black\",\n+            \"manu\": \"Apple Computer Inc.\",\n+            \"cat\": [\n+                \"electronics\",\n+                \"music\"\n+            ]\n+        }]\n+    },\n+    \"highlighting\": {\n+        \"MA147LL/A\": {\n+            \"manu\": [\n+                \"<em>Apple</em> Computer Inc.\"\n+            ]\n+        }\n+    }\n+}\n+----\n+\n+Note the two sections `docs` and `highlighting`. The `docs` section contains the fields of the document requested with the `fl` parameter of the query (only \"id\", \"name\", \"manu\", and \"cat\").\n+\n+The `highlighting` section includes the ID of each document, and the field that contains the highlighted portion. In this example, we used the `hl.fl` parameter to say we wanted query terms highlighted in the \"manu\" field. When there is a match to the query term in that field, it will be included for each document ID in the list.\n+\n+[[Highlighting-ChoosingaHighlighter]]\n+== Choosing a Highlighter\n+\n+Solr provides a `HighlightComponent` (a `SearchComponent`) and it's in the default list of components for search handlers. It offers a somewhat unified API over multiple actual highlighting implementations (or simply \"highlighters\") that do the business of highlighting.\n+\n+There are many parameters supported by more than one highlighter, and sometimes the implementation details and semantics will be a bit different, so don't expect identical results when switching highlighters. You should use the `hl.method` parameter to choose a highlighter but it's also possible to explicitly configure an implementation by class name in `solrconfig.xml`.\n+\n+There are four highlighters available that can be chosen at runtime with the `hl.method` parameter, in order of general recommendation:\n+\n+<<The Unified Highlighter,Unified Highlighter>>:: (`hl.method=unified`)\n++\n+The Unified Highlighter is the newest highlighter (as of Solr 6.4), which stands out as the most flexible and performant of the options. We recommend that you try this highlighter even though it isn't the default (yet).\n++\n+This highlighter supports the most common highlighting parameters and can handle just about any query accurately, even SpanQueries (e.g. as seen from the `surround` parser). A strong benefit to this highlighter is that you can opt to configure Solr to put more information in the underlying index to speed up highlighting of large documents; multiple configurations are supported, even on a per-field basis. There is little or no such flexibility for the other highlighters. More on this below.\n+\n+<<The Original Highlighter,Original Highlighter>>:: (`hl.method=original`, the default)\n++\n+The Original Highlighter, sometimes called the \"Standard Highlighter\" or \"Default Highlighter\", is Lucene's original highlighter \u2013 a venerable option with a high degree of customization options. Its ability to highlight just about any query accurately is a strength shared with the Unified Highlighter (they share some code for this in fact).\n++\n+The Original Highlighter will normally analyze stored text on the fly in order to highlight. It will use full term vectors if available, however in this mode it isn't as fast as the Unified Highlighter or FastVector Highlighter.\n++\n+This highlighter is a good choice for a wide variety of search use-cases. Where it falls short is performance; it's often twice as slow as the Unified Highlighter. And despite being the most customizable, it doesn't have a BreakIterator based fragmenter (all the others do), which could pose a challenge for some languages.\n+\n+<<The FastVector Highlighter,FastVector Highlighter>>:: (`hl.method=fastVector`)\n++\n+The FastVector Highlighter _requires_ full term vector options (`termVectors`, `termPositions`, and `termOffsets`) on the field, and is optimized with that in mind. It is nearly as configurable as the Original Highlighter with some variability.\n++\n+This highlighter notably supports multi-colored highlighting such that different query words can be denoted in the fragment with different marking, usually expressed as an HTML tag with a unique color.\n++\n+This highlighter's query-representation is less advanced than the Original or Unified Highlighters: for example it will not work well with the `surround` parser, and there are multiple reported bugs pertaining to queries with stop-words.\n++\n+Note that both the FastVector and Original Highlighters can be used in conjunction in a search request to highlight some fields with one and some the other. In contrast, the other highlighters can only be chosen exclusively.\n+\n+<<Highlighting-ThePostingsHighlighter,Postings Highlighter>>:: (`hl.method=postings`)\n++\n+The Postings Highlighter is the ancestor of the Unified Highlighter, supporting a subset of its options and none of its index configuration flexibility - it _requires_ `storeOffsetsWithPositions` on all fields to highlight. This option is here for backwards compatibility; if you find you need it, please share your experience with the Solr community.\n+\n+The Unified Highlighter and Postings Highlighter from which it derives, are exclusively configured via search parameters. In contrast, some settings for the Original and FastVector Highlighters are set in `solrconfig.xml`. There's a robust example of the latter in the \"```techproducts```\" configset.\n+\n+In addition to further information below, more information can be found in the {solr-javadocs}/solr-core/org/apache/solr/highlight/package-summary.html[Solr javadocs].\n+\n+[[Highlighting-SchemaOptionsandPerformanceConsiderations]]\n+=== Schema Options and Performance Considerations\n+\n+Fundamental to the internals of highlighting are detecting the _offsets_ of the individual words that match the query. Some of the highlighters can run the stored text through the analysis chain defined in the schema, some can look them up from _postings_, and some can look them up from _term vectors._ These choices have different trade-offs:\n+\n+* *Analysis*: Supported by the Unified and Original Highlighters. If you don't go out of your way to configure the other options below, the highlighter will analyze the stored text on the fly (during highlighting) to calculate offsets.\n++\n+The benefit of this approach is that your index won't grow larger with any extra data that isn't strictly necessary for highlighting.\n++\n+The down side is that highlighting speed is roughly linear with the amount of text to process, with a large factor being the complexity of your analysis chain.\n++\n+For \"short\" text, this is a good choice. Or maybe it's not short but you're prioritizing a smaller index and indexing speed over highlighting performance.\n+* *Postings*: Supported by the Unified and Postings Highlighters. Set `storeOffsetsWithPositions` to `true`. This adds a moderate amount of extra data to the index but it speeds up highlighting tremendously, especially compared to analysis with longer text fields.\n++\n+However, wildcard queries will fall back to analysis unless \"light\" term vectors are added.\n+\n+** *with Term Vectors (light)*: Supported only by the Unified Highlighter. To enable this mode set `termVectors` to `true` but no other term vector related options on the field being highlighted.\n++\n+This adds even more data to the index than just `storeOffsetsWithPositions` but not as much as enabling all the extra term vector options. Term Vectors are only accessed by the highlighter when a wildcard query is used and will prevent a fall back to analysis of the stored text.\n++\n+This is definitely the fastest option for highlighting wildcard queries on large text fields.\n+* *Term Vectors (full)*: Supported by the Unified, FastVector, and Original Highlighters. Set `termVectors`, `termPositions`, and `termOffsets` to `true`, and potentially `termPayloads` for advanced use cases.\n++\n+This adds substantial weight to the index \u2013 similar in size to the compressed stored text. If you are using the Unified Highlighter then this is not a recommended configuration since it's slower and heavier than postings with light term vectors. However, this could make sense if full term vectors are already needed for another use-case.\n+\n+[[Highlighting-TheUnifiedHighlighter]]\n+== The Unified Highlighter\n+\n+The Unified Highlighter supports these following additional parameters to the ones listed earlier:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,65\",options=\"header\"]\n+|===\n+|Parameter |Default |Description\n+|hl.offsetSource |_(blank)_ |By default, the Unified Highlighter will usually pick the right offset source (see above). However it may be ambiguous such as during a migration from one offset source to another that hasn't completed. The offset source can be explicitly configured to one of: *ANALYSIS,* *POSTINGS*, *POSTINGS_WITH_TERM_VECTORS*, *TERM_VECTORS*\n+|hl.tag.ellipsis |_(blank)_ |By default, each snippet is returned as a separate value (as is done with the other highlighters). Set this parameter to instead return one string with this text as the delimiter. _Note: this is likely to be removed in the future._\n+|hl.defaultSummary |false |If *true*, use the leading portion of the text as a snippet if a proper highlighted snippet can't otherwise be generated.\n+|hl.score.k1 |1.2 |Specifies BM25 term frequency normalization parameter 'k1'. For example, it can be set to \"0\" to rank passages solely based on the number of query terms that match.\n+|hl.score.b |0.75 |Specifies BM25 length normalization parameter 'b'. For example, it can be set to \"0\" to ignore the length of passages entirely when ranking.\n+|hl.score.pivot |87 |Specifies BM25 average passage length in characters.\n+|hl.bs.language |_(blank)_ |Specifies the breakiterator language for dividing the document into passages.\n+|hl.bs.country |_(blank)_ |Specifies the breakiterator country for dividing the document into passages.\n+|hl.bs.variant |_(blank)_ |Specifies the breakiterator variant for dividing the document into passages.\n+|hl.bs.type |SENTENCE |Specifies the breakiterator type for dividing the document into passages. Can be *SEPARATOR*, *SENTENCE*, *WORD*, *CHARACTER*, *LINE*, or *WHOLE*. SEPARATOR is special value that splits text on a user-provided character in `hl.bs.separator`.\n+|hl.bs.separator |_(blank)_ |Indicates which character to break the text on. Requires `hl.bs.type=SEPARATOR`. This is useful when the text has already been manipulated in advance to have a special delineation character at desired highlight passage boundaries. This character will still appear in the text as the last character of a passage.\n+|===\n+\n+[[Highlighting-ThePostingsHighlighter]]\n+=== The Postings Highlighter\n+\n+The Postings Highlighter is the ancestor of the Unified Highlighter, supporting a subset of it's options and sometimes with different default settings for some common parameters.\n+\n+Viewed from the perspective of the Unified Highlighter, these settings are effectively non-settings and fixed as-such:\n+\n+* `hl.offsetSource=POSTINGS`\n+* `hl.requireFieldMatch=true`\n+* `hl.usePhraseHighlighter=false`\n+* `hl.fragsize=-1` (none).\n+\n+It has these different default settings:\n+\n+* `hl.defaultSummary=true`\n+* `hl.tag.ellipsis=\"... \"`.\n+\n+In addition, it has a setting `hl.multiValuedSeparatorChar=\" \"` (space).\n+\n+This highlighter never returns separate snippets as separate values; they are always joined by `hl.tag.ellipsis`.\n+\n+[[Highlighting-TheOriginalHighlighter]]\n+== The Original Highlighter\n+\n+The Original Highlighter supports these following additional parameters to the ones listed earlier:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"25,15,60\",options=\"header\"]\n+|===\n+|Parameter |Default |Description\n+|hl.mergeContiguous |false |Instructs Solr to collapse contiguous fragments into a single fragment. A value of *true* indicates contiguous fragments will be collapsed into single fragment. The default value, *false*, is also the backward-compatible setting.\n+|hl.maxMultiValuedToExamine |`Integer.MAX_VALUE` |Specifies the maximum number of entries in a multi-valued field to examine before stopping. This can potentially return zero results if the limit is reached before any matches are found. If used with the `maxMultiValuedToMatch`, whichever limit is reached first will determine when to stop looking.\n+|hl.maxMultiValuedToMatch |`Integer.MAX_VALUE` |Specifies the maximum number of matches in a multi-valued field that are found before stopping. If `hl.maxMultiValuedToExamine` is also defined, whichever limit is reached first will determine when to stop looking.\n+|hl.alternateField |_(blank)_ |Specifies a field to be used as a backup default summary if Solr cannot generate a snippet (i.e., because no terms match).\n+|hl.maxAlternateFieldLength |_(unlimited)_ |Specifies the maximum number of characters of the field to return. Any value less than or equal to 0 means the field's length is unlimited. This parameter is only used in conjunction with the `hl.alternateField` parameter.\n+|hl.highlightAlternate |true |If set to *true*, and `hl.alternateFieldName` is active, Solr will show the entire alternate field, with highlighting of occurrences. If `hl.maxAlternateFieldLength=N` is used, Solr returns max `N` characters surrounding the best matching fragment. If set to *false*, or if there is no match in the alternate field either, the alternate field will be shown without highlighting.\n+|hl.formatter |simple |Selects a formatter for the highlighted output. Currently the only legal value is *simple*, which surrounds a highlighted term with a customizable pre- and post-text snippet.\n+|hl.simple.prehl.simple.post |<em> and </em> |Specifies the text that should appear before (`hl.simple.pre`) and after (`hl.simple.post`) a highlighted term, when using the simple formatter.\n+|hl.fragmenter |gap |Specifies a text snippet generator for highlighted text. The standard fragmenter is *gap*, which creates fixed-sized fragments with gaps for multi-valued fields. Another option is *regex*, which tries to create fragments that resemble a specified regular expression.\n+|hl.regex.slop |0.6 |When using the regex fragmenter (`hl.fragmenter=regex`), this parameter defines the factor by which the fragmenter can stray from the ideal fragment size (given by `hl.fragsize`) to accommodate a regular expression. For instance, a slop of 0.2 with `hl.fragsize=100` should yield fragments between 80 and 120 characters in length. It is usually good to provide a slightly smaller `hl.fragsize` value when using the regex fragmenter.\n+|hl.regex.pattern |_(blank)_ |Specifies the regular expression for fragmenting. This could be used to extract sentences.\n+|hl.regex.maxAnalyzedChars |10000 |Instructs Solr to analyze only this many characters from a field when using the regex fragmenter (after which, the fragmenter produces fixed-sized fragments). Applying a complicated regex to a huge field is computationally expensive.\n+|hl.preserveMulti |false |If *true*, multi-valued fields will return all values in the order they were saved in the index. If *false*, only values that match the highlight request will be returned.\n+|hl.payloads |_(automatic)_ |When `hl.usePhraseHighlighter` is true and the indexed field has payloads but not term vectors (generally quite rare), the index's payloads will be read into the highlighter's memory index along with the postings. If this may happen and you know you don't need them for highlighting (i.e. your queries don't filter by payload) then you can save a little memory by setting this to false.\n+|===\n+\n+The Original Highlighter has a plugin architecture that enables new functionality to be registered in `solrconfig.xml`. The \"```techproducts```\" configset shows most of these settings explicitly. You can use it as a guide to provide your own components to include a `SolrFormatter`, `SolrEncoder`, and `SolrFragmenter.`\n+\n+[[Highlighting-TheFastVectorHighlighter]]\n+== The FastVector Highlighter\n+\n+The FastVector Highlighter (FVH) can be used in conjunction with the Original Highlighter if not all fields should be highlighted with the FVH. In such a mode, set `hl.method=original` and `f.yourTermVecField.hl.method=fastVector` for all fields that should use the FVH. One annoyance to keep in mind is that the Original Highlighter uses `hl.simple.pre` whereas the FVH (and other highlighters) use `hl.tag.pre`.\n+\n+In addition to the initial listed parameters, the following parameters documented for the Original Highlighter above are also supported by the FVH:\n+\n+* `hl.alternateField`\n+* `hl.maxAlternateFieldLength`\n+* `hl.highlightAlternate`\n+\n+And here are additional parameters supported by the FVH:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"20,15,65\",options=\"header\"]\n+|===\n+|Parameter |Default |Description\n+|hl.fragListBuilder |weighted |The snippet fragmenting algorithm. The *weighted* fragListBuilder uses IDF-weights to order fragments. Other options are *single*, which returns the entire field contents as one snippet, or *simple*. You can select a fragListBuilder with this parameter, or modify an existing implementation in `solrconfig.xml` to be the default by adding \"default=true\".\n+|hl.fragmentsBuilder |default |The fragments builder is responsible for formatting the fragments, which uses <em> and </em> markup (if `hl.tag.pre` and `hl.tag.post` are not defined). Another pre-configured choice is *colored*, which is an example of how to use the fragments builder to insert HTML into the snippets for colored highlights if you choose. You can also implement your own if you'd like. You can select a fragments builder with this parameter, or modify an existing implementation in `solrconfig.xml` to be the default by adding \"default=true\".\n+|hl.boundaryScanner | |See <<Using Boundary Scanners with the FastVector Highlighter>> below.\n+|hl.bs.* | |See <<Using Boundary Scanners with the FastVector Highlighter>> below.\n+|hl.phraseLimit |5000 |The maximum number of phrases to analyze when searching for the highest-scoring phrase.\n+|hl.multiValuedSeparatorChar |\" \" _(space)_ |Text to use to separate one value from the next for a multi-valued field.\n+|===\n+\n+[[Highlighting-UsingBoundaryScannerswiththeFastVectorHighlighter]]\n+=== Using Boundary Scanners with the FastVector Highlighter\n+\n+The FastVector Highlighter will occasionally truncate highlighted words. To prevent this, implement a boundary scanner in `solrconfig.xml`, then use the `hl.boundaryScanner` parameter to specify the boundary scanner for highlighting.\n+\n+Solr supports two boundary scanners: `breakIterator` and `simple`.\n+\n+[[Highlighting-ThebreakIteratorBoundaryScanner]]\n+==== The `breakIterator` Boundary Scanner\n+\n+The `breakIterator` boundary scanner offers excellent performance right out of the box by taking locale and boundary type into account. In most cases you will want to use the `breakIterator` boundary scanner. To implement the `breakIterator` boundary scanner, add this code to the `highlighting` section of your `solrconfig.xml` file, adjusting the type, language, and country values as appropriate to your application:\n+\n+[source,xml]\n+----\n+<boundaryScanner name=\"breakIterator\" class=\"solr.highlight.BreakIteratorBoundaryScanner\">\n+   <lst name=\"defaults\">\n+     <str name=\"hl.bs.type\">WORD</str>\n+     <str name=\"hl.bs.language\">en</str>\n+     <str name=\"hl.bs.country\">US</str>\n+   </lst>\n+</boundaryScanner>\n+----\n+\n+Possible values for the `hl.bs.type` parameter are WORD, LINE, SENTENCE, and CHARACTER.\n+\n+[[Highlighting-ThesimpleBoundaryScanner]]\n+==== The `simple` Boundary Scanner\n+\n+The `simple` boundary scanner scans term boundaries for a specified maximum character value (`hl.bs.maxScan`) and for common delimiters such as punctuation marks (`hl.bs.chars`). The `simple` boundary scanner may be useful for some custom To implement the `simple` boundary scanner, add this code to the `highlighting` section of your `solrconfig.xml` file, adjusting the values as appropriate to your application:\n+\n+[source,xml]\n+----\n+<boundaryScanner name=\"simple\" class=\"solr.highlight.SimpleBoundaryScanner\" default=\"true\">\n+   <lst name=\"defaults\">\n+     <str name=\"hl.bs.maxScan\">10</str >\n+     <str name=\"hl.bs.chars\">.,!?\\t\\n</str >\n+   </lst >\n+</boundaryScanner>\n+----",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/highlighting.adoc",
                "sha": "b0e0cb28bfcc78d87ef97c4f3c6c479947b3b4e6",
                "status": "added"
            },
            {
                "additions": 37,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/how-solrcloud-works.adoc",
                "changes": 37,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/how-solrcloud-works.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/how-solrcloud-works.adoc",
                "patch": "@@ -0,0 +1,37 @@\n+= How SolrCloud Works\n+:page-shortname: how-solrcloud-works\n+:page-permalink: how-solrcloud-works.html\n+:page-children: shards-and-indexing-data-in-solrcloud, distributed-requests, read-and-write-side-fault-tolerance\n+\n+The following sections cover provide general information about how various SolrCloud features work. To understand these features, it's important to first understand a few key concepts that relate to SolrCloud.\n+\n+* <<shards-and-indexing-data-in-solrcloud.adoc#shards-and-indexing-data-in-solrcloud,Shards and Indexing Data in SolrCloud>>\n+* <<distributed-requests.adoc#distributed-requests,Distributed Requests>>\n+* <<read-and-write-side-fault-tolerance.adoc#read-and-write-side-fault-tolerance,Read and Write Side Fault Tolerance>>\n+\n+If you are already familiar with SolrCloud concepts and basic functionality, you can skip to the section covering <<solrcloud-configuration-and-parameters.adoc#solrcloud-configuration-and-parameters,SolrCloud Configuration and Parameters>>.\n+\n+[[HowSolrCloudWorks-KeySolrCloudConcepts]]\n+== Key SolrCloud Concepts\n+\n+A SolrCloud cluster consists of some \"logical\" concepts layered on top of some \"physical\" concepts.\n+\n+[[HowSolrCloudWorks-Logical]]\n+=== Logical\n+\n+* A Cluster can host multiple Collections of Solr Documents.\n+* A collection can be partitioned into multiple Shards, which contain a subset of the Documents in the Collection.\n+* The number of Shards that a Collection has determines:\n+** The theoretical limit to the number of Documents that Collection can reasonably contain.\n+** The amount of parallelization that is possible for an individual search request.\n+\n+[[HowSolrCloudWorks-Physical]]\n+=== Physical\n+\n+* A Cluster is made up of one or more Solr Nodes, which are running instances of the Solr server process.\n+* Each Node can host multiple Cores.\n+* Each Core in a Cluster is a physical Replica for a logical Shard.\n+* Every Replica uses the same configuration specified for the Collection that it is a part of.\n+* The number of Replicas that each Shard has determines:\n+** The level of redundancy built into the Collection and how fault tolerant the Cluster can be in the event that some Nodes become unavailable.\n+** The theoretical limit in the number concurrent search requests that can be processed under heavy load.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/how-solrcloud-works.adoc",
                "sha": "ac028702c4f73bfff33abee3beac1116348b7ae3",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.png",
                "sha": "7c181b39909431c143816d339ed6a1b198292e39",
                "status": "added"
            },
            {
                "additions": 488,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.svg",
                "changes": 488,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.svg?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.svg",
                "patch": "@@ -0,0 +1,488 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n+<!-- Created with Inkscape (http://www.inkscape.org/) -->\n+\n+<svg\n+   xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n+   xmlns:cc=\"http://creativecommons.org/ns#\"\n+   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n+   xmlns:svg=\"http://www.w3.org/2000/svg\"\n+   xmlns=\"http://www.w3.org/2000/svg\"\n+   xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\"\n+   xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\"\n+   width=\"951.83209\"\n+   height=\"722.24835\"\n+   id=\"svg2\"\n+   version=\"1.1\"\n+   inkscape:version=\"0.48.3.1 r9886\"\n+   sodipodi:docname=\"arch.svg\"\n+   inkscape:export-filename=\"/home/hossman/tmp/arch.png\"\n+   inkscape:export-xdpi=\"90\"\n+   inkscape:export-ydpi=\"90\">\n+  <defs\n+     id=\"defs4\">\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"TriangleInL\"\n+       style=\"overflow:visible\">\n+      <path\n+         id=\"path4575\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\"\n+         inkscape:connector-curvature=\"0\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleOutL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"TriangleOutL\"\n+       style=\"overflow:visible\">\n+      <path\n+         id=\"path4584\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(0.8,0.8)\"\n+         inkscape:connector-curvature=\"0\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow2Lend\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"Arrow2Lend\"\n+       style=\"overflow:visible\">\n+      <path\n+         id=\"path4463\"\n+         style=\"fill-rule:evenodd;stroke-width:0.625;stroke-linejoin:round\"\n+         d=\"M 8.7185878,4.0337352 -2.2072895,0.01601326 8.7185884,-4.0017078 c -1.7454984,2.3720609 -1.7354408,5.6174519 -6e-7,8.035443 z\"\n+         transform=\"matrix(-1.1,0,0,-1.1,-1.1,0)\"\n+         inkscape:connector-curvature=\"0\" />\n+    </marker>\n+    <clipPath\n+       id=\"clipPath3037\"\n+       clipPathUnits=\"userSpaceOnUse\">\n+      <path\n+         id=\"path3039\"\n+         d=\"m 0,102.654 203.005,0 L 203.005,0 0,0 0,102.654 z\"\n+         inkscape:connector-curvature=\"0\" />\n+    </clipPath>\n+    <clipPath\n+       id=\"clipPath3151\"\n+       clipPathUnits=\"userSpaceOnUse\">\n+      <path\n+         id=\"path3153\"\n+         d=\"m 0,102.654 203.005,0 L 203.005,0 0,0 0,102.654 z\"\n+         inkscape:connector-curvature=\"0\" />\n+    </clipPath>\n+    <clipPath\n+       id=\"clipPath3151-9\"\n+       clipPathUnits=\"userSpaceOnUse\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path3153-7\"\n+         d=\"m 0,102.654 203.005,0 L 203.005,0 0,0 0,102.654 z\" />\n+    </clipPath>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"TriangleInL-6\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4575-5\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"marker5640\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path5642\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"TriangleInL-2\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4575-9\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"marker5640-2\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path5642-6\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"TriangleInL-0\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4575-1\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"TriangleInL\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"marker5640-8\"\n+       style=\"overflow:visible\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path5642-2\"\n+         d=\"m 5.77,0 -8.65,5 0,-10 8.65,5 z\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt\"\n+         transform=\"scale(-0.8,-0.8)\" />\n+    </marker>\n+  </defs>\n+  <sodipodi:namedview\n+     id=\"base\"\n+     pagecolor=\"#ffffff\"\n+     bordercolor=\"#666666\"\n+     borderopacity=\"1.0\"\n+     inkscape:pageopacity=\"0.0\"\n+     inkscape:pageshadow=\"2\"\n+     inkscape:zoom=\"0.50362889\"\n+     inkscape:cx=\"500.2462\"\n+     inkscape:cy=\"305.15545\"\n+     inkscape:document-units=\"px\"\n+     inkscape:current-layer=\"layer1\"\n+     showgrid=\"false\"\n+     inkscape:object-nodes=\"true\"\n+     inkscape:window-width=\"1025\"\n+     inkscape:window-height=\"709\"\n+     inkscape:window-x=\"125\"\n+     inkscape:window-y=\"99\"\n+     inkscape:window-maximized=\"0\"\n+     fit-margin-top=\"50\"\n+     fit-margin-right=\"50\"\n+     fit-margin-bottom=\"50\"\n+     fit-margin-left=\"50\" />\n+  <metadata\n+     id=\"metadata7\">\n+    <rdf:RDF>\n+      <cc:Work\n+         rdf:about=\"\">\n+        <dc:format>image/svg+xml</dc:format>\n+        <dc:type\n+           rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\" />\n+        <dc:title></dc:title>\n+      </cc:Work>\n+    </rdf:RDF>\n+  </metadata>\n+  <g\n+     inkscape:label=\"Layer 1\"\n+     inkscape:groupmode=\"layer\"\n+     id=\"layer1\"\n+     transform=\"translate(185.02727,-109.08811)\">\n+    <g\n+       id=\"g3236\"\n+       transform=\"translate(-255.1482,174.73183)\">\n+      <g\n+         id=\"g3145\"\n+         inkscape:label=\"Solr_Logo_on_white\"\n+         transform=\"matrix(1.25,0,0,-1.25,160.03949,571.47669)\">\n+        <g\n+           id=\"g3147\">\n+          <g\n+             id=\"g3149\"\n+             clip-path=\"url(#clipPath3151)\">\n+            <g\n+               id=\"g3155\"\n+               transform=\"translate(40.7606,31.7631)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"m 0,0 c -2.345,1.248 -4.995,2.127 -7.875,2.613 -2.829,0.476 -5.707,0.717 -8.554,0.717 -2.327,0 -4.681,0.201 -6.998,0.597 -2.256,0.384 -4.299,1.092 -6.076,2.104 -1.729,0.984 -3.159,2.361 -4.252,4.095 -1.078,1.706 -1.624,3.968 -1.624,6.697 0.052,2.41 0.612,4.472 1.666,6.129 1.068,1.684 2.464,3.052 4.147,4.067 1.726,1.041 3.718,1.806 5.921,2.274 3.751,0.796 7.713,0.945 11.749,0.382 1.575,-0.222 3.133,-0.615 4.63,-1.168 1.47,-0.545 2.852,-1.292 4.106,-2.217 1.236,-0.915 2.328,-2.063 3.246,-3.411 L 0.6,22.124 4.388,23.718 3.584,24.853 c -1.031,1.456 -2.173,2.767 -3.395,3.899 -1.247,1.151 -2.712,2.13 -4.356,2.906 -1.623,0.765 -3.48,1.354 -5.522,1.751 -2.021,0.392 -4.377,0.59 -7.003,0.59 -2.519,0 -5.12,-0.288 -7.73,-0.858 -2.649,-0.58 -5.106,-1.538 -7.301,-2.849 -2.242,-1.34 -4.09,-3.125 -5.493,-5.306 -1.425,-2.219 -2.149,-4.957 -2.149,-8.139 0,-3.34 0.671,-6.183 1.993,-8.449 1.314,-2.252 3.076,-4.077 5.237,-5.423 2.116,-1.32 4.585,-2.269 7.338,-2.82 2.69,-0.538 5.505,-0.811 8.368,-0.811 2.276,0 4.686,-0.172 7.164,-0.515 2.411,-0.333 4.655,-1.005 6.669,-1.997 1.962,-0.969 3.597,-2.316 4.857,-4.005 1.219,-1.635 1.838,-3.843 1.838,-6.562 0,-2.442 -0.596,-4.524 -1.769,-6.193 -1.212,-1.724 -2.786,-3.147 -4.679,-4.229 -1.934,-1.105 -4.123,-1.919 -6.51,-2.418 -2.425,-0.508 -4.825,-0.765 -7.132,-0.765 -3.873,0 -7.7,0.74 -11.374,2.2 -3.658,1.451 -6.902,3.632 -9.64,6.482 l -0.735,0.765 -3.021,-2.618 0.848,-0.848 c 2.703,-2.705 6.06,-5.06 9.975,-7.002 3.963,-1.967 8.656,-2.964 13.947,-2.964 2.516,0 5.186,0.288 7.938,0.855 2.79,0.577 5.408,1.562 7.78,2.931 2.41,1.39 4.415,3.209 5.962,5.406 1.589,2.257 2.395,5.081 2.395,8.398 0,3.361 -0.755,6.207 -2.245,8.459 C 4.368,-3.056 2.404,-1.28 0,0\"\n+                 style=\"fill:#241f2b;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3157\" />\n+            </g>\n+            <g\n+               id=\"g3159\"\n+               transform=\"translate(76.3898,3.9853)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"m 0,0 c -2.732,0 -5.23,0.564 -7.426,1.676 -2.225,1.125 -4.189,2.657 -5.839,4.556 -1.659,1.907 -2.977,4.137 -3.917,6.629 -0.947,2.503 -1.484,5.127 -1.593,7.754 0,2.429 0.45,4.911 1.336,7.378 0.885,2.459 2.174,4.702 3.833,6.666 1.654,1.957 3.667,3.578 5.984,4.82 2.278,1.22 4.842,1.839 7.622,1.839 2.614,0 5.083,-0.579 7.338,-1.719 2.286,-1.157 4.297,-2.707 5.978,-4.607 1.685,-1.908 3.031,-4.139 4.002,-6.632 0.967,-2.49 1.457,-5.096 1.457,-7.745 0,-2.426 -0.45,-4.909 -1.335,-7.377 C 16.553,10.774 15.264,8.532 13.606,6.57 11.955,4.617 9.945,3.012 7.631,1.8 5.352,0.605 2.785,0 0,0 m 16.577,37.377 c -1.982,2.316 -4.391,4.232 -7.162,5.694 -2.809,1.482 -5.977,2.232 -9.415,2.232 -3.132,0 -6.124,-0.671 -8.893,-1.993 -2.749,-1.314 -5.18,-3.126 -7.225,-5.384 -2.037,-2.249 -3.67,-4.898 -4.854,-7.873 -1.186,-2.979 -1.788,-6.155 -1.788,-9.438 0,-3.103 0.555,-6.14 1.65,-9.027 1.093,-2.885 2.649,-5.503 4.625,-7.784 1.985,-2.291 4.399,-4.164 7.175,-5.566 2.797,-1.414 5.923,-2.162 9.29,-2.223 l 0.021,0 0.021,0 c 3.186,0.061 6.203,0.778 8.967,2.128 2.744,1.34 5.172,3.166 7.217,5.424 2.037,2.25 3.656,4.87 4.81,7.787 1.157,2.924 1.744,6.04 1.744,9.261 0,2.917 -0.539,5.89 -1.6,8.835 -1.063,2.945 -2.605,5.612 -4.583,7.927\"\n+                 style=\"fill:#241f2b;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3161\" />\n+            </g>\n+            <g\n+               id=\"g3163\"\n+               transform=\"translate(119.7832,5.0906)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"m 0,0 c -0.67,-0.167 -1.26,-0.294 -1.752,-0.376 -0.518,-0.086 -1.08,-0.173 -1.685,-0.259 -0.557,-0.079 -1.108,-0.12 -1.638,-0.12 -1.337,0 -2.321,0.443 -3.01,1.355 -0.761,1.004 -1.131,2.001 -1.131,3.049 l 0,58.337 -3.985,0 0,-58.337 c 0,-2.189 0.691,-4.126 2.055,-5.754 1.413,-1.691 3.426,-2.547 5.983,-2.547 0.802,0 1.598,0.047 2.367,0.139 0.742,0.089 1.409,0.178 2.006,0.267 0.61,0.092 1.316,0.23 2.1,0.41 L 2.661,-3.524 0.887,0.222 0,0 z\"\n+                 style=\"fill:#241f2b;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3165\" />\n+            </g>\n+            <g\n+               id=\"g3167\"\n+               transform=\"translate(136.9779,45.2734)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"m 0,0 c -2.073,-1.457 -3.904,-3.307 -5.471,-5.522 l 0,8.836 -3.985,0 0,-47.711 3.985,0 0,29.704 c 0.552,1.946 1.312,3.771 2.261,5.426 0.957,1.667 2.148,3.135 3.538,4.362 1.39,1.226 3.008,2.221 4.811,2.958 1.798,0.736 3.827,1.166 6.031,1.277 l 1.06,0.053 0,3.931 -1.116,0 C 6.867,3.314 3.128,2.199 0,0\"\n+                 style=\"fill:#241f2b;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3169\" />\n+            </g>\n+            <g\n+               id=\"g3171\"\n+               transform=\"translate(193.9115,92.0414)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 -33,-35.677 8.473,-16.543 C 7.246,-10.213 4.242,-4.521 0,0\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3173\" />\n+            </g>\n+            <g\n+               id=\"g3175\"\n+               transform=\"translate(169.4268,102.6536)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 C -4.572,0 -8.928,-0.917 -12.9,-2.572 L -17.328,-39.886 4.799,-0.347 C 3.231,-0.122 1.63,0 0,0\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3177\" />\n+            </g>\n+            <g\n+               id=\"g3179\"\n+               transform=\"translate(202.7133,73.4428)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"m 0,0 -39.298,-21.992 36.87,4.375 c 1.748,4.065 2.72,8.543 2.72,13.249 C 0.292,-2.886 0.186,-1.431 0,0\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3181\" />\n+            </g>\n+            <g\n+               id=\"g3183\"\n+               transform=\"translate(188.2247,41.2478)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 C 4.391,2.972 8.037,6.958 10.612,11.619 L -23.947,4.756 0,0 z\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3185\" />\n+            </g>\n+            <g\n+               id=\"g3187\"\n+               transform=\"translate(176.2492,101.9586)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 -19.237,-41.695 16.448,-8.689 C 11.973,-4.384 6.313,-1.303 0,0\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3189\" />\n+            </g>\n+            <g\n+               id=\"g3191\"\n+               transform=\"translate(172.2334,35.622)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 C 3.718,0.308 7.264,1.217 10.54,2.638 L -8.818,4.935 0,0 z\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3193\" />\n+            </g>\n+            <g\n+               id=\"g3195\"\n+               transform=\"translate(138.8186,82.8789)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 C -1.51,-3.343 -2.489,-6.974 -2.829,-10.792 L 2.386,-20.112 0,0 z\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3197\" />\n+            </g>\n+            <g\n+               id=\"g3199\"\n+               transform=\"translate(153.617,98.7011)\">\n+              <path\n+                 inkscape:connector-curvature=\"0\"\n+                 d=\"M 0,0 C -4.738,-2.534 -8.794,-6.17 -11.832,-10.567 L -6.965,-35.071 0,0 z\"\n+                 style=\"fill:#da3522;fill-opacity:1;fill-rule:nonzero;stroke:none\"\n+                 id=\"path3201\" />\n+            </g>\n+          </g>\n+        </g>\n+      </g>\n+      <rect\n+         y=\"409.03134\"\n+         x=\"121.12093\"\n+         height=\"196.57332\"\n+         width=\"331.59335\"\n+         id=\"rect3234\"\n+         style=\"opacity:0.79680008;fill:none;stroke:#000000;stroke-width:2;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none\" />\n+    </g>\n+    <g\n+       id=\"g4393\"\n+       transform=\"translate(-254.1554,71.23301)\">\n+      <rect\n+         y=\"90.344292\"\n+         x=\"120.12814\"\n+         height=\"196.57332\"\n+         width=\"331.59335\"\n+         id=\"rect3234-0\"\n+         style=\"fill:#0008de;fill-opacity:0.25531915;stroke:#000000;stroke-width:2;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3402\"\n+         y=\"149.31458\"\n+         x=\"284.4502\"\n+         style=\"font-size:40px;font-style:normal;font-weight:normal;text-align:center;line-height:125%;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;font-family:Sans\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"149.31458\"\n+           x=\"284.4502\"\n+           id=\"tspan3404\"\n+           sodipodi:role=\"line\">Content</tspan><tspan\n+           id=\"tspan3406\"\n+           y=\"199.31458\"\n+           x=\"284.4502\"\n+           sodipodi:role=\"line\">Management</tspan><tspan\n+           id=\"tspan3408\"\n+           y=\"249.31458\"\n+           x=\"284.4502\"\n+           sodipodi:role=\"line\">System</tspan></text>\n+    </g>\n+    <g\n+       id=\"g4400\"\n+       transform=\"translate(301.80953,-76.445144)\">\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3435\"\n+         y=\"744.53015\"\n+         x=\"249.76111\"\n+         style=\"font-size:40px;font-style:normal;font-weight:normal;text-align:center;line-height:125%;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;font-family:Sans\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"744.53015\"\n+           x=\"249.76111\"\n+           id=\"tspan3437\"\n+           sodipodi:role=\"line\">End User</tspan><tspan\n+           id=\"tspan3439\"\n+           y=\"794.53015\"\n+           x=\"249.76111\"\n+           sodipodi:role=\"line\">Application</tspan></text>\n+      <rect\n+         y=\"660.20831\"\n+         x=\"82.401939\"\n+         height=\"196.57332\"\n+         width=\"331.59335\"\n+         id=\"rect3234-0-6-4\"\n+         style=\"fill:#0008de;fill-opacity:0.25531915;stroke:#000000;stroke-width:2;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none\" />\n+    </g>\n+    <g\n+       id=\"g4425\"\n+       transform=\"translate(757.254,-37.477991)\">\n+      <path\n+         inkscape:transform-center-y=\"194.58772\"\n+         inkscape:transform-center-x=\"45.668548\"\n+         d=\"m -101.26504,410.02414 c 0,10.4178 -47.56035,18.8631 -106.22901,18.8631 -58.66866,0 -106.22901,-8.4453 -106.22901,-18.8631 0,-10.4178 47.56035,-18.8631 106.22901,-18.8631 58.66866,0 106.22901,8.4453 106.22901,18.8631 z\"\n+         sodipodi:ry=\"18.863096\"\n+         sodipodi:rx=\"106.22901\"\n+         sodipodi:cy=\"410.02414\"\n+         sodipodi:cx=\"-207.49405\"\n+         id=\"path3502-5\"\n+         style=\"opacity:0.79680008;fill:none;stroke:#000000;stroke-width:2;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none\"\n+         sodipodi:type=\"arc\"\n+         transform=\"translate(0.24819563,-193.59494)\" />\n+      <path\n+         sodipodi:open=\"true\"\n+         sodipodi:end=\"3.1415927\"\n+         sodipodi:start=\"0\"\n+         inkscape:transform-center-y=\"194.58772\"\n+         inkscape:transform-center-x=\"45.668548\"\n+         d=\"m -101.26504,410.02414 c 0,10.4178 -47.56035,18.8631 -106.22901,18.8631 -58.66866,0 -106.22901,-8.4453 -106.22901,-18.8631 0,0 0,0 0,0\"\n+         sodipodi:ry=\"18.863096\"\n+         sodipodi:rx=\"106.22901\"\n+         sodipodi:cy=\"410.02414\"\n+         sodipodi:cx=\"-207.49405\"\n+         id=\"path3502-5-4\"\n+         style=\"opacity:0.79680008;fill:none;stroke:#000000;stroke-width:2;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none\"\n+         sodipodi:type=\"arc\"\n+         transform=\"translate(0.24819563,-31.769434)\" />\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4371\"\n+         d=\"m -313.47486,216.4292 c 0,161.82551 0,161.82551 0,161.82551\"\n+         style=\"fill:none;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\" />\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4373\"\n+         d=\"m -101.01684,216.4292 c 0,161.82551 0,161.82551 0,161.82551\"\n+         style=\"fill:none;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\" />\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4377\"\n+         d=\"m -243.16769,394.36964 c -34.17364,-2.31715 -64.43561,-9.27295 -66.76621,-15.34641 -0.34116,-0.88903 -0.62029,-36.66066 -0.62029,-79.4925 l 0,-77.87606 2.23379,1.4223 c 6.48455,4.12882 24.60949,8.18861 49.93322,11.1845 21.31886,2.5221 84.81991,2.52073 106.18372,-0.002 24.57791,-2.9026 40.06909,-6.37707 48.98167,-10.98594 l 3.14004,-1.62378 0,77.82597 c 0,76.61463 -0.0313,77.86572 -2.00819,80.37898 -5.00987,6.36901 -31.35126,12.054 -67.48743,14.5651 -16.40633,1.14008 -56.44098,1.11294 -73.59032,-0.0498 l 0,-3e-5 z\"\n+         style=\"fill:#00da00;fill-opacity:0.25531915;stroke:none\" />\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4379\"\n+         d=\"m -243.16769,232.54414 c -33.27902,-2.25649 -64.58959,-9.3163 -66.6709,-15.03275 -1.48692,-4.08393 12.30392,-9.90261 31.05383,-13.10232 37.23448,-6.35415 101.85345,-6.78769 140.48042,-0.94251 19.32495,2.92433 35.44716,8.07086 36.86603,11.76837 2.72049,7.08948 -26.13239,14.44003 -68.13906,17.35907 -16.40633,1.14008 -56.44098,1.11295 -73.59032,-0.0499 z\"\n+         style=\"fill:#00da00;fill-opacity:0.25531915;stroke:none\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text4381\"\n+         y=\"286.60049\"\n+         x=\"-205.57187\"\n+         style=\"font-size:40px;font-style:normal;font-weight:normal;text-align:center;line-height:125%;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;font-family:Sans\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"286.60049\"\n+           x=\"-205.57187\"\n+           id=\"tspan4383\"\n+           sodipodi:role=\"line\">Data</tspan><tspan\n+           id=\"tspan4385\"\n+           y=\"336.60049\"\n+           x=\"-205.57187\"\n+           sodipodi:role=\"line\">Source</tspan></text>\n+    </g>\n+    <path\n+       style=\"fill:none;stroke:#000000;stroke-width:2;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none;marker-start:url(#TriangleInL);marker-end:url(#TriangleInL)\"\n+       d=\"m 31.769415,398.4829 c 0,146.93359 0,144.948 0,144.948\"\n+       id=\"path4436\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;stroke:#000000;stroke-width:2;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none;marker-start:none;marker-end:url(#TriangleInL)\"\n+       d=\"m 550.00815,398.48291 c 0,146.93359 0,144.948 0,144.948\"\n+       id=\"path4436-9\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;stroke:#000000;stroke-width:2;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none;marker-start:url(#TriangleInL);marker-end:url(#TriangleInL)\"\n+       d=\"m 396.12501,259.86396 c -146.93359,0 -144.948,0 -144.948,0\"\n+       id=\"path4436-0\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;stroke:#000000;stroke-width:2;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-opacity:1;stroke-dasharray:none;marker-start:none;marker-end:url(#TriangleInL)\"\n+       d=\"m 208.19,682.04983 c 146.93359,0 144.948,0 144.948,0\"\n+       id=\"path4436-6\"\n+       inkscape:connector-curvature=\"0\" />\n+  </g>\n+</svg>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/a-quick-overview/sample-client-app-arch.svg",
                "sha": "90adca0f13a221bba3d8ffe89ae4a6ccf9b5a078",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/analysis-screen/analysis_normal.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/analysis-screen/analysis_normal.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/analysis-screen/analysis_normal.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/analysis-screen/analysis_normal.png",
                "sha": "f180ca988dc9573fe421480eb7f511f6b2536548",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/analysis-screen/analysis_verbose.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/analysis-screen/analysis_verbose.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/analysis-screen/analysis_verbose.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/analysis-screen/analysis_verbose.png",
                "sha": "13f8fc744d42a2ceaa111e7257effb3fd103442a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-graph.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/cloud-screens/cloud-graph.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/cloud-screens/cloud-graph.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-graph.png",
                "sha": "a1f81b2ade04b58c8a8d8d9b9cfca66fc44cd057",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-radial.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/cloud-screens/cloud-radial.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/cloud-screens/cloud-radial.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-radial.png",
                "sha": "76f9e1e13c51ada7a4e34d8b8bc85f46e66f7744",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-tree.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/cloud-screens/cloud-tree.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/cloud-screens/cloud-tree.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cloud-screens/cloud-tree.png",
                "sha": "127812adad3e6a52f8f832995d7f6fe8ee44e861",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collection-specific-tools/collection_dashboard.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/collection-specific-tools/collection_dashboard.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/collection-specific-tools/collection_dashboard.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collection-specific-tools/collection_dashboard.png",
                "sha": "66a31e2c288617d6e3479677602f6b1d464d9f78",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collections-core-admin/DeleteShard.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/collections-core-admin/DeleteShard.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/collections-core-admin/DeleteShard.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collections-core-admin/DeleteShard.png",
                "sha": "b7723e7755ada80a9ed4b35b3a7ea7f857cf15b8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collections-core-admin/collection-admin.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/collections-core-admin/collection-admin.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/collections-core-admin/collection-admin.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/collections-core-admin/collection-admin.png",
                "sha": "86c367f3613bbe07bcb4bf78ac7073cc42018a73",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/combining-distribution-and-replication/worddav4101c16174820e932b44baa22abcfcd1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/combining-distribution-and-replication/worddav4101c16174820e932b44baa22abcfcd1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/combining-distribution-and-replication/worddav4101c16174820e932b44baa22abcfcd1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/combining-distribution-and-replication/worddav4101c16174820e932b44baa22abcfcd1.png",
                "sha": "f0e4d89f835906a85b24a334539427d7fcdfb432",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/core-specific-tools/core_dashboard.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/core-specific-tools/core_dashboard.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/core-specific-tools/core_dashboard.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/core-specific-tools/core_dashboard.png",
                "sha": "b4e941aaca84a1e4971e34b333dad097e49f2fd0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cross-data-center-replication-cdcr-/CDCR_arch.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/cross-data-center-replication-cdcr-/CDCR_arch.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/cross-data-center-replication-cdcr-/CDCR_arch.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/cross-data-center-replication-cdcr-/CDCR_arch.png",
                "sha": "4dc6ee55286b15931264185613bcf122810a7d73",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/dataimport-screen/dataimport.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/dataimport-screen/dataimport.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/dataimport-screen/dataimport.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/dataimport-screen/dataimport.png",
                "sha": "7444c27eac2efb6c228ffda66ff657b3ad3f6d2e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/documents-screen/documents_add_screen.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/documents-screen/documents_add_screen.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/documents-screen/documents_add_screen.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/documents-screen/documents_add_screen.png",
                "sha": "571d40ac1ddd63fd7596650df5656518779a6a03",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/files-screen/files-screen.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/files-screen/files-screen.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/files-screen/files-screen.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/files-screen/files-screen.png",
                "sha": "0ec0a2f9a325503d0aa9a132907157c6dd6a66e1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/getting-assistance/Assistance.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/getting-assistance/Assistance.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/getting-assistance/Assistance.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/getting-assistance/Assistance.png",
                "sha": "abb405adcec67a18610286add2578351421fba1f",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/bullet_blue.gif",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/icons/bullet_blue.gif?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/icons/bullet_blue.gif",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/bullet_blue.gif",
                "sha": "25bfa0cf2b75f92b9902fe5a01571c67018e8b2b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/contenttypes/home_page_16.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/icons/contenttypes/home_page_16.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/icons/contenttypes/home_page_16.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/contenttypes/home_page_16.png",
                "sha": "32888f65b15245d480146e25b57900fd9699dc93",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/emoticons/warning.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/icons/emoticons/warning.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/icons/emoticons/warning.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/icons/emoticons/warning.png",
                "sha": "7a8ab4909c8f6abe055026f37d54b61787a9ec2b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/index-replication/worddav2b7e14725d898b4104cdd9c502fc77cd.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/index-replication/worddav2b7e14725d898b4104cdd9c502fc77cd.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/index-replication/worddav2b7e14725d898b4104cdd9c502fc77cd.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/index-replication/worddav2b7e14725d898b4104cdd9c502fc77cd.png",
                "sha": "e635aad8d206c6fd8326edebb0b46b17637bd7ed",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/java-properties/javaproperties.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/java-properties/javaproperties.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/java-properties/javaproperties.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/java-properties/javaproperties.png",
                "sha": "8dd0ab3580e43e095df153e1779ad2ef4116f661",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/logging/level_menu.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/logging/level_menu.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/logging/level_menu.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/logging/level_menu.png",
                "sha": "008a417f650876d7f11596141932602a9d0e168c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/logging/logging.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/logging/logging.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/logging/logging.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/logging/logging.png",
                "sha": "18fdf396013fc0c745858ce3db49d4972b48ac8a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.png",
                "sha": "816fa0660ae654104901ff17b0302c1cdddb8ebe",
                "status": "added"
            },
            {
                "additions": 606,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.svg",
                "changes": 606,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.svg?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.svg",
                "patch": "@@ -0,0 +1,606 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n+<!-- Created with Inkscape (http://www.inkscape.org/) -->\n+\n+<svg\n+   xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n+   xmlns:cc=\"http://creativecommons.org/ns#\"\n+   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n+   xmlns:svg=\"http://www.w3.org/2000/svg\"\n+   xmlns=\"http://www.w3.org/2000/svg\"\n+   xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\"\n+   xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\"\n+   width=\"800\"\n+   height=\"800\"\n+   viewBox=\"0 0 800.00001 800.00001\"\n+   id=\"svg2\"\n+   version=\"1.1\"\n+   inkscape:version=\"0.91 r13725\"\n+   sodipodi:docname=\"graph_qparser_example.svg\"\n+   inkscape:export-filename=\"/home/hossman/tmp/graph_qparser_example.png\"\n+   inkscape:export-xdpi=\"68.417511\"\n+   inkscape:export-ydpi=\"68.417511\">\n+  <defs\n+     id=\"defs4\">\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0.0\"\n+       refX=\"0.0\"\n+       id=\"marker7255\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\">\n+      <path\n+         id=\"path7257\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         transform=\"scale(0.8) translate(12.5,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:isstock=\"true\"\n+       style=\"overflow:visible\"\n+       id=\"marker7179\"\n+       refX=\"0.0\"\n+       refY=\"0.0\"\n+       orient=\"auto\"\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       inkscape:collect=\"always\">\n+      <path\n+         transform=\"scale(0.8) translate(12.5,0)\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         id=\"path7181\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0.0\"\n+       refX=\"0.0\"\n+       id=\"marker7109\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\"\n+       inkscape:collect=\"always\">\n+      <path\n+         id=\"path7111\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         transform=\"scale(0.8) translate(12.5,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:isstock=\"true\"\n+       style=\"overflow:visible\"\n+       id=\"marker7045\"\n+       refX=\"0.0\"\n+       refY=\"0.0\"\n+       orient=\"auto\"\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       inkscape:collect=\"always\">\n+      <path\n+         transform=\"scale(0.8) translate(12.5,0)\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         id=\"path7047\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0.0\"\n+       refX=\"0.0\"\n+       id=\"marker6979\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\"\n+       inkscape:collect=\"always\">\n+      <path\n+         id=\"path6981\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         transform=\"scale(0.8) translate(12.5,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:isstock=\"true\"\n+       style=\"overflow:visible\"\n+       id=\"marker6921\"\n+       refX=\"0.0\"\n+       refY=\"0.0\"\n+       orient=\"auto\"\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       inkscape:collect=\"always\">\n+      <path\n+         transform=\"scale(0.8) translate(12.5,0)\"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         id=\"path6923\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lend\"\n+       orient=\"auto\"\n+       refY=\"0.0\"\n+       refX=\"0.0\"\n+       id=\"Arrow1Lend\"\n+       style=\"overflow:visible;\"\n+       inkscape:isstock=\"true\">\n+      <path\n+         id=\"path4389\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         transform=\"scale(0.8) rotate(180) translate(12.5,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0.0\"\n+       refX=\"0.0\"\n+       id=\"Arrow1Lstart\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\"\n+       inkscape:collect=\"always\">\n+      <path\n+         id=\"path4386\"\n+         d=\"M 0.0,0.0 L 5.0,-5.0 L -12.5,0.0 L 5.0,5.0 L 0.0,0.0 z \"\n+         style=\"fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1;fill:#000000;fill-opacity:1\"\n+         transform=\"scale(0.8) translate(12.5,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"Arrow1Lstart-1\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4386-5\"\n+         d=\"M 0,0 5,-5 -12.5,0 5,5 0,0 Z\"\n+         style=\"fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1\"\n+         transform=\"matrix(0.8,0,0,0.8,10,0)\" />\n+    </marker>\n+    <marker\n+       inkscape:stockid=\"Arrow1Lstart\"\n+       orient=\"auto\"\n+       refY=\"0\"\n+       refX=\"0\"\n+       id=\"Arrow1Lstart-0\"\n+       style=\"overflow:visible\"\n+       inkscape:isstock=\"true\">\n+      <path\n+         inkscape:connector-curvature=\"0\"\n+         id=\"path4386-7\"\n+         d=\"M 0,0 5,-5 -12.5,0 5,5 0,0 Z\"\n+         style=\"fill:#000000;fill-opacity:1;fill-rule:evenodd;stroke:#000000;stroke-width:1pt;stroke-opacity:1\"\n+         transform=\"matrix(0.8,0,0,0.8,10,0)\" />\n+    </marker>\n+  </defs>\n+  <sodipodi:namedview\n+     id=\"base\"\n+     pagecolor=\"#ffffff\"\n+     bordercolor=\"#666666\"\n+     borderopacity=\"1.0\"\n+     inkscape:pageopacity=\"0.0\"\n+     inkscape:pageshadow=\"2\"\n+     inkscape:zoom=\"0.8275\"\n+     inkscape:cx=\"398.79154\"\n+     inkscape:cy=\"400\"\n+     inkscape:document-units=\"px\"\n+     inkscape:current-layer=\"layer1\"\n+     showgrid=\"false\"\n+     units=\"px\"\n+     inkscape:window-width=\"1600\"\n+     inkscape:window-height=\"849\"\n+     inkscape:window-x=\"0\"\n+     inkscape:window-y=\"27\"\n+     inkscape:window-maximized=\"1\" />\n+  <metadata\n+     id=\"metadata7\">\n+    <rdf:RDF>\n+      <cc:Work\n+         rdf:about=\"\">\n+        <dc:format>image/svg+xml</dc:format>\n+        <dc:type\n+           rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\" />\n+        <dc:title />\n+      </cc:Work>\n+    </rdf:RDF>\n+  </metadata>\n+  <g\n+     inkscape:label=\"Layer 1\"\n+     inkscape:groupmode=\"layer\"\n+     id=\"layer1\"\n+     transform=\"translate(0,-252.36216)\">\n+    <g\n+       id=\"g3527\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"347.29736\"\n+         cx=\"400\"\n+         id=\"path3344\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346\"\n+         y=\"344.16544\"\n+         x=\"400\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"344.16544\"\n+           x=\"400\"\n+           id=\"tspan3348\"\n+           sodipodi:role=\"line\">A</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350\"\n+         y=\"374.32938\"\n+         x=\"400.78735\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"374.32938\"\n+           x=\"400.78735\"\n+           id=\"tspan3352\"\n+           sodipodi:role=\"line\">foo=7</tspan></text>\n+    </g>\n+    <g\n+       id=\"g3534\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"523.18182\"\n+         cx=\"224.26228\"\n+         id=\"path3344-1\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-7\"\n+         y=\"520.04993\"\n+         x=\"224.26228\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"520.04993\"\n+           x=\"224.26228\"\n+           id=\"tspan3348-2\"\n+           sodipodi:role=\"line\">B</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-2\"\n+         y=\"550.21387\"\n+         x=\"225.04964\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"550.21387\"\n+           x=\"225.04964\"\n+           id=\"tspan3352-6\"\n+           sodipodi:role=\"line\">foo=12</tspan></text>\n+    </g>\n+    <g\n+       id=\"g3541\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"523.18182\"\n+         cx=\"582.2951\"\n+         id=\"path3344-6\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-9\"\n+         y=\"520.04993\"\n+         x=\"582.2951\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"520.04993\"\n+           x=\"582.2951\"\n+           id=\"tspan3348-8\"\n+           sodipodi:role=\"line\">C</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-1\"\n+         y=\"550.21387\"\n+         x=\"583.08246\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"550.21387\"\n+           x=\"583.08246\"\n+           id=\"tspan3352-1\"\n+           sodipodi:role=\"line\">foo=10</tspan></text>\n+    </g>\n+    <g\n+       id=\"g3555\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"744.16541\"\n+         cx=\"400\"\n+         id=\"path3344-12\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-5\"\n+         y=\"741.03351\"\n+         x=\"400\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"741.03351\"\n+           x=\"400\"\n+           id=\"tspan3348-3\"\n+           sodipodi:role=\"line\">D</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-9\"\n+         y=\"771.19745\"\n+         x=\"400.78735\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"771.19745\"\n+           x=\"400.78735\"\n+           id=\"tspan3352-5\"\n+           sodipodi:role=\"line\">foo=20</tspan></text>\n+    </g>\n+    <circle\n+       style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\"\n+       id=\"path3344-17\"\n+       cx=\"429.83609\"\n+       cy=\"947.8454\"\n+       r=\"60.327869\" />\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"429.83609\"\n+       y=\"944.71344\"\n+       id=\"text3346-93\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan3348-20\"\n+         x=\"429.83609\"\n+         y=\"944.71344\">F</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"430.62344\"\n+       y=\"974.87738\"\n+       id=\"text3350-5\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan3352-3\"\n+         x=\"430.62344\"\n+         y=\"974.87738\">foo=11</tspan></text>\n+    <g\n+       id=\"g3548\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"744.16541\"\n+         cx=\"74.754105\"\n+         id=\"path3344-3\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-2\"\n+         y=\"741.03351\"\n+         x=\"74.754105\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"741.03351\"\n+           x=\"74.754105\"\n+           id=\"tspan3348-0\"\n+           sodipodi:role=\"line\">E</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-6\"\n+         y=\"771.19745\"\n+         x=\"75.541458\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"771.19745\"\n+           x=\"75.541458\"\n+           id=\"tspan3352-9\"\n+           sodipodi:role=\"line\">foo=17</tspan></text>\n+    </g>\n+    <g\n+       id=\"g3562\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"744.16541\"\n+         cx=\"665.57373\"\n+         id=\"path3344-8\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-73\"\n+         y=\"741.03351\"\n+         x=\"665.57373\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"741.03351\"\n+           x=\"665.57373\"\n+           id=\"tspan3348-5\"\n+           sodipodi:role=\"line\">G</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-8\"\n+         y=\"771.19745\"\n+         x=\"666.36108\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"771.19745\"\n+           x=\"666.36108\"\n+           id=\"tspan3352-36\"\n+           sodipodi:role=\"line\">foo=7</tspan></text>\n+    </g>\n+    <g\n+       id=\"g3569\"\n+       transform=\"translate(29.836082,9.5815814)\">\n+      <circle\n+         r=\"60.327869\"\n+         cy=\"938.26379\"\n+         cx=\"665.57373\"\n+         id=\"path3344-9\"\n+         style=\"fill:none;fill-opacity:1;stroke:#000000;stroke-width:4.05000019;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\" />\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3346-3\"\n+         y=\"935.13184\"\n+         x=\"665.57373\"\n+         style=\"font-style:normal;font-weight:normal;font-size:40px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"935.13184\"\n+           x=\"665.57373\"\n+           id=\"tspan3348-6\"\n+           sodipodi:role=\"line\">H</tspan></text>\n+      <text\n+         sodipodi:linespacing=\"125%\"\n+         id=\"text3350-3\"\n+         y=\"965.29578\"\n+         x=\"666.36108\"\n+         style=\"font-style:normal;font-weight:normal;font-size:25px;line-height:125%;font-family:sans-serif;text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+         xml:space=\"preserve\"><tspan\n+           y=\"965.29578\"\n+           x=\"666.36108\"\n+           id=\"tspan3352-4\"\n+           sodipodi:role=\"line\">foo=10</tspan></text>\n+    </g>\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#Arrow1Lstart-1)\"\n+       d=\"m 450.85425,419.1709 c 16.96777,96.24487 99.75252,95.37482 99.75252,95.37482 l 0,0\"\n+       id=\"path3580-8\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#Arrow1Lstart-0)\"\n+       d=\"m 582.94113,473.26835 c -3.99086,-97.6476 -86.1532,-107.8172 -86.1532,-107.8172 l 0,0\"\n+       id=\"path3580-1\"\n+       inkscape:connector-curvature=\"0\" />\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"546.55737\"\n+       y=\"423.25522\"\n+       id=\"text6461\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan6463\"\n+         x=\"546.55737\"\n+         y=\"423.25522\">9</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"484.91806\"\n+       y=\"474.40274\"\n+       id=\"text6465\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan6467\"\n+         x=\"484.91806\"\n+         y=\"474.40274\">2</tspan></text>\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#Arrow1Lstart)\"\n+       d=\"m 428.5246,428.50112 c -2.62295,253.11475 -2.62295,253.11475 -2.62295,253.11475 l 0,0\"\n+       id=\"path6847\"\n+       inkscape:connector-curvature=\"0\" />\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"437.70493\"\n+       y=\"563.58313\"\n+       id=\"text6897\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan6899\"\n+         x=\"437.70493\"\n+         y=\"563.58313\">4</tspan></text>\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker6921)\"\n+       d=\"m 301.31149,480.96013 c 78.68852,-78.68852 78.68852,-78.68852 78.68852,-78.68852\"\n+       id=\"path6901\"\n+       inkscape:connector-curvature=\"0\" />\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"326.22952\"\n+       y=\"429.81259\"\n+       id=\"text6967\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan6969\"\n+         x=\"326.22952\"\n+         y=\"429.81259\">1</tspan></text>\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker6979)\"\n+       d=\"m 141.31149,689.48472 c 73.44262,-98.36065 73.44262,-97.04918 73.44262,-97.04918\"\n+       id=\"path6971\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker7045)\"\n+       d=\"M 382.62297,693.41915 C 297.37706,585.87817 297.37706,585.87817 297.37706,585.87817\"\n+       id=\"path7031\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker7179)\"\n+       d=\"m 429.83608,874.40276 c 0,-52.45902 0,-52.45902 0,-52.45902\"\n+       id=\"path7033\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker7255)\"\n+       d=\"m 693.44264,877.02571 c 1.31147,-57.70492 1.31147,-57.70492 1.31147,-57.70492\"\n+       id=\"path7035\"\n+       inkscape:connector-curvature=\"0\" />\n+    <path\n+       style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;marker-start:url(#marker7109)\"\n+       d=\"M 475.73772,696.0421 C 563.60657,583.25522 563.60657,583.25522 563.60657,583.25522\"\n+       id=\"path7037\"\n+       inkscape:connector-curvature=\"0\" />\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"158.36066\"\n+       y=\"639.64868\"\n+       id=\"text7331\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan7333\"\n+         x=\"158.36066\"\n+         y=\"639.64868\">6</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"433.77051\"\n+       y=\"849.48474\"\n+       id=\"text7335\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan7337\"\n+         x=\"433.77051\"\n+         y=\"849.48474\">7</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"698.68854\"\n+       y=\"849.48474\"\n+       id=\"text7339\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan7341\"\n+         x=\"698.68854\"\n+         y=\"849.48474\">8</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"537.37708\"\n+       y=\"637.02576\"\n+       id=\"text7343\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan7345\"\n+         x=\"537.37708\"\n+         y=\"637.02576\">5</tspan></text>\n+    <text\n+       xml:space=\"preserve\"\n+       style=\"font-style:normal;font-weight:normal;font-size:22.5px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"\n+       x=\"315.73773\"\n+       y=\"644.89459\"\n+       id=\"text7347\"\n+       sodipodi:linespacing=\"125%\"><tspan\n+         sodipodi:role=\"line\"\n+         id=\"tspan7349\"\n+         x=\"315.73773\"\n+         y=\"644.89459\">3</tspan></text>\n+  </g>\n+</svg>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/other-parsers/graph_qparser_example.svg",
                "sha": "f9efcc20a272bf7b0b6ddc111437fe7f6a129db1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav16392965e726e04513a21641fabad474.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav16392965e726e04513a21641fabad474.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav16392965e726e04513a21641fabad474.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav16392965e726e04513a21641fabad474.png",
                "sha": "fe8f022b854735f5128c5b6b222ab31362a2b74b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav88969a784fb8a63d8c46e9c043f5f953.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav88969a784fb8a63d8c46e9c043f5f953.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav88969a784fb8a63d8c46e9c043f5f953.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-searching-in-solr/worddav88969a784fb8a63d8c46e9c043f5f953.png",
                "sha": "9b980e115fb6ed85f2c4a52ff9ab81a9765614b0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-the-solr-admin-ui/dashboard.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/overview-of-the-solr-admin-ui/dashboard.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/overview-of-the-solr-admin-ui/dashboard.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/overview-of-the-solr-admin-ui/dashboard.png",
                "sha": "2ff363cd0b5159fb9b676755758109c26946a169",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/parallel-sql-interface/cluster.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/parallel-sql-interface/cluster.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/parallel-sql-interface/cluster.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/parallel-sql-interface/cluster.png",
                "sha": "10f134ffba4e47b57edd4d22cbe30cc0556f19c2",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/ping/ping.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/ping/ping.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/ping/ping.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/ping/ping.png",
                "sha": "055b344546de149d719409e5a00fbaaee42a40a5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/plugins-stats-screen/plugin-searcher.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/plugins-stats-screen/plugin-searcher.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/plugins-stats-screen/plugin-searcher.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/plugins-stats-screen/plugin-searcher.png",
                "sha": "a977f3647405473f47b8919cf191f206f6f1998b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/query-screen/query-top.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/query-screen/query-top.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/query-screen/query-top.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/query-screen/query-top.png",
                "sha": "0de032d3455662880bf87780f737d227cabf927a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/replication-screen/replication.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/replication-screen/replication.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/replication-screen/replication.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/replication-screen/replication.png",
                "sha": "ea9d938fffb2b1417a097ebec3e33d391f9de1f6",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/result-clustering/carrot2-workbench.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/result-clustering/carrot2-workbench.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/result-clustering/carrot2-workbench.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/result-clustering/carrot2-workbench.png",
                "sha": "c7567b2fdf4cff37443ef8568b6e094c4797b4ea",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/result-clustering/carrot2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/result-clustering/carrot2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/result-clustering/carrot2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/result-clustering/carrot2.png",
                "sha": "2af8a469d409d089f85eaad2c08738be432c719c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-solr/SolrAdminDashboard.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-solr/SolrAdminDashboard.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-solr/SolrAdminDashboard.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-solr/SolrAdminDashboard.png",
                "sha": "f0333993db24ba20b014f8e87684ce61b7203a22",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-solr/solr34_responseHeader.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-solr/solr34_responseHeader.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-solr/solr34_responseHeader.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-solr/solr34_responseHeader.png",
                "sha": "27d5d6be7a7a9a74a9746de4a2803265f30c1e88",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_0.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_0.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_0.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_0.png",
                "sha": "47d0b10361ce3164fba6e1a40cd83f056f138731",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_1.png",
                "sha": "b0fbf4daf1a21a44d872ae48cfc4acf52ac61947",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_2.png",
                "sha": "4c9d7248185d33c77a5d8da5b8c92ecd4e2294c6",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_3.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_3.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_3.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_3.png",
                "sha": "83d9d57f71fb547f4e735e09aa043f62b1f95a85",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_4.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_4.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_4.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/running-your-analyzer/analysis_compare_4.png",
                "sha": "f9aae926dfb3647d0592c19312fba0dab78ad535",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/schema-browser-screen/schema_browser_terms.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/schema-browser-screen/schema_browser_terms.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/schema-browser-screen/schema_browser_terms.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/schema-browser-screen/schema_browser_terms.png",
                "sha": "0f42e49576727e2a7cbd8e64917b391875cbf1eb",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/segments-info/segments_info.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/segments-info/segments_info.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/segments-info/segments_info.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/segments-info/segments_info.png",
                "sha": "0dbadf81df04d7d5af256426e64a7e21a1c1bdb4",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_1.png",
                "sha": "c450cbbc256bc3e0f53f11796cc4ee7363745bc4",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_2.png",
                "sha": "439531b46a765582dc8d47b6cbd7950d2aceb58d",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_3.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_3.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_3.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_3.png",
                "sha": "40b3ca08c4ebdb91f948a29f4c3822c0b72bdeb5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_4.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_4.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_4.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_4.png",
                "sha": "a6fe59a0be396dfe5b09291e337d4a847c04a621",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_5.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_5.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_5.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_5.png",
                "sha": "a6e0942352931ed3a89823e0f9d2b1ca01826f06",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_6.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_6.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_6.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-apache-zeppelin/zeppelin_solrjdbc_6.png",
                "sha": "1b8793ae696c29f32c29c78fd61f280fc6b05fd3",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_1.png",
                "sha": "eb1d655ef8ad6f833077587827519038dea6ef9e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_11.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_11.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_11.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_11.png",
                "sha": "8d051a29402e729609f51e4d31213aa5b81ad9b8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_12.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_12.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_12.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_12.png",
                "sha": "69abcf7f9ff62ee90e0cd2e1a246a383d8ead9b2",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_13.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_13.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_13.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_13.png",
                "sha": "e7ca8fec3b717429a3c2bc6b43f133e9dd6f0341",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_14.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_14.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_14.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_14.png",
                "sha": "6bc3f4f7e9badfafb76a93a761de437d4d354136",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_15.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_15.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_15.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_15.png",
                "sha": "d6696d9515a33ee6a8414336451a9bf5ed2981c1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_16.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_16.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_16.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_16.png",
                "sha": "a07772e2099e794678fc33669c390dd58441274d",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_17.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_17.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_17.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_17.png",
                "sha": "b748a9a8b742b7e387287d7a1c17d552f77e9138",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_19.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_19.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_19.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_19.png",
                "sha": "8d01bc06ecd1eac27ab74d230fdc9c1476f5ec2e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_2.png",
                "sha": "eabb3f856c04efea5f7171a0a717271dc86a42eb",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_20.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_20.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_20.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_20.png",
                "sha": "8680d2f0f8a420d815748e632073e19950d0a974",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_3.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_3.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_3.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_3.png",
                "sha": "ab24004ae68f61b46e106091a54f6cedc255c367",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_4.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_4.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_4.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_4.png",
                "sha": "1321f05b6adefa8a4ede6732313c064aa94454a9",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_5.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_5.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_5.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_5.png",
                "sha": "76a579876612b01fbc9614cf3ba7e80dc37dee8c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_6.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_6.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_6.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_6.png",
                "sha": "111de69512145ccfc8d0dbd7c16dfbaf725c3327",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_7.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_7.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_7.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_7.png",
                "sha": "bcedc5918fc2bcd1c3b7558531aef97c006336cb",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_9.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_9.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_9.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-dbvisualizer/dbvisualizer_solrjdbc_9.png",
                "sha": "f5de9c41fb6356ca7e77e6a24518132ead23cc67",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_1.png",
                "sha": "50f07a33082385891e241b919b818c4ef4f60eaf",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_10.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_10.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_10.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_10.png",
                "sha": "9e8c21a18cb524da443bb8ba2b57570059d78b2b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_11.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_11.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_11.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_11.png",
                "sha": "92bcda2a54768349574ea88f161e2795bc975c04",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_12.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_12.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_12.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_12.png",
                "sha": "f2766b2b346cc8bf7048e56d8e30fdf6fc32e091",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_13.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_13.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_13.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_13.png",
                "sha": "bda4388009a1891369727c9c0ca0659e8bad0946",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_14.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_14.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_14.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_14.png",
                "sha": "5c5950bd33c44ee04b6b1e1128bbfcadf76e38f1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_15.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_15.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_15.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_15.png",
                "sha": "dc7afbc3b7f141957e57ab8ed4366dab0589f05b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_2.png",
                "sha": "9c662672bef73c0d7bc5fd05909a0051324586fa",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_3.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_3.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_3.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_3.png",
                "sha": "0581017e6b1d3fa69a91ea388c840536d95459a3",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_4.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_4.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_4.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_4.png",
                "sha": "1b20a9ad1b02b4ce19febd899070f35eece7498b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_5.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_5.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_5.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_5.png",
                "sha": "96084c05099956473b91338de0edf4fc7edc118a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_7.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_7.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_7.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_7.png",
                "sha": "5aab15cf8f1f8899212c77317c6c6db4c5892e79",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_9.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_9.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_9.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/solr-jdbc-squirrel-sql/squirrelsql_solrjdbc_9.png",
                "sha": "0faf53d86edfc4a54d777aceffe7af894e6fc628",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/spatial-search/bbox.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/spatial-search/bbox.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/spatial-search/bbox.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/spatial-search/bbox.png",
                "sha": "604b8c20ec2e7bf6a2cb255d41047b39356569ee",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/spatial-search/circle.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/spatial-search/circle.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/spatial-search/circle.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/spatial-search/circle.png",
                "sha": "8f1683f58ac886a1fcaff8ca8fae8df5838b7e75",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/stream-screen/StreamScreen.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/stream-screen/StreamScreen.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/stream-screen/StreamScreen.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/stream-screen/StreamScreen.png",
                "sha": "62fea6de3eae171e254fe51f033fac3f03121ea9",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/thread-dump/thread_dump_1.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/thread-dump/thread_dump_1.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/thread-dump/thread_dump_1.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/thread-dump/thread_dump_1.png",
                "sha": "ccfed8f5fa2db00e36a175f61a50b2c027dde93b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/thread-dump/thread_dump_2.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/thread-dump/thread_dump_2.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/thread-dump/thread_dump_2.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/thread-dump/thread_dump_2.png",
                "sha": "bacb3dfaefd9f52ff45667d3fec5e128a69ec0d8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/velocity-search-ui/techproducts_browse.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/images/velocity-search-ui/techproducts_browse.png?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/images/velocity-search-ui/techproducts_browse.png",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/images/velocity-search-ui/techproducts_browse.png",
                "sha": "09f105d444a08af177eb12cec9c91c0d2e1631da",
                "status": "added"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/implicit-requesthandlers.adoc",
                "changes": 61,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/implicit-requesthandlers.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/implicit-requesthandlers.adoc",
                "patch": "@@ -0,0 +1,61 @@\n+= Implicit RequestHandlers\n+:page-shortname: implicit-requesthandlers\n+:page-permalink: implicit-requesthandlers.html\n+\n+Solr ships with many out-of-the-box RequestHandlers, which are called implicit because they are not configured in `solrconfig.xml`.\n+\n+[[ImplicitRequestHandlers-ListofImplicitlyAvailableEndpoints]]\n+== List of Implicitly Available Endpoints\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"15,20,15,50\",options=\"header\"]\n+|===\n+|Endpoint |Request Handler class |Paramset |Description\n+|`/admin/file` |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/ShowFileRequestHandler.html[ShowFileRequestHandler] |`_ADMIN_FILE` |Returns content of files in `${solr.home}` `/conf/`.\n+|`/admin/logging` |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/ShowFileRequestHandler.html[LoggingHandler] |`_ADMIN_LOGGING` |Retrieve/modify registered loggers.\n+|http://wiki.apache.org/solr/LukeRequestHandler[`/admin/luke`] |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/LukeRequestHandler.html[LukeRequestHandler] |`_ADMIN_LUKE` |Expose the internal lucene index.\n+|<<mbean-request-handler.adoc#mbean-request-handler,`/admin/mbeans`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/SolrInfoMBeanHandler.html[SolrInfoMBeanHandler] |`_ADMIN_MBEANS` |Provide info about all registered {solr-javadocs}/solr-core/org/apache/solr/core/SolrInfoMBean.html[SolrInfoMBeans].\n+|<<ping.adoc#ping,`/admin/ping`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/PingRequestHandler.html[PingRequestHandler] |`_ADMIN_PING` |Health check.\n+|`/admin/plugins` |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/PluginInfoHandler.html[PluginInfoHandler] |N/A |Return info about all registered plugins.\n+|`/admin/properties` |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/PropertiesRequestHandler.html[PropertiesRequestHandler] |`_ADMIN_PROPERTIES` |Return JRE system properties.\n+|`/admin/segments` |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/SegmentsInfoRequestHandler.html[SegmentsInfoRequestHandler] |`_ADMIN_SEGMENTS` |Return info on last commit generation Lucene index segments.\n+|https://wiki.apache.org/solr/SystemInformationRequestHandlers#SystemInfoHandler[`/admin/system`] |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/SystemInfoHandler.html[SystemInfoHandler] |`_ADMIN_SYSTEM` |Return server statistics and settings\n+|https://wiki.apache.org/solr/SystemInformationRequestHandlers#ThreadDumpHandler[`/admin/threads`] |{solr-javadocs}/solr-core/org/apache/solr/handler/admin/ThreadDumpHandler.html[ThreadDumpHandler] |`_ADMIN_THREADS` |Return info on all JVM threads.\n+|https://wiki.apache.org/solr/AnalysisRequestHandler[`/analysis/document`] |{solr-javadocs}/solr-core/org/apache/solr/handler/DocumentAnalysisRequestHandler.html[DocumentAnalysisRequestHandler] |`_ANALYSIS_DOCUMENT` |Return a breakdown of the analysis process of the given document.\n+|`/analysis/field` |{solr-javadocs}/solr-core/org/apache/solr/handler/FieldAnalysisRequestHandler.html[FieldAnalysisRequestHandler] |`_ANALYSIS_FIELD` |Return index- and query-time analysis over the given field(s)/field type(s).\n+|<<config-api.adoc#config-api,`/config`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/SolrConfigHandler.html[SolrConfigHandler] |`_CONFIG` |Retrieve/modify Solr configuration.\n+|`/debug/dump` |{solr-javadocs}/solr-core/org/apache/solr/handler/DumpRequestHandler.html[DumpRequestHandler] |`_DEBUG_DUMP` |Echo the request contents back to the client.\n+|<<exporting-result-sets.adoc#exporting-result-sets,`/export`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/component/SearchHandler.html[SearchHandler] |`_EXPORT` |Export full sorted result sets.\n+|<<realtime-get.adoc#realtime-get,`/get`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/RealTimeGetHandler.html[RealTimeGetHandler] |`_GET` |Real-time get: low-latency retrieval of the latest version of a document.\n+|<<graph-traversal.adoc#GraphTraversal-ExportingGraphMLtoSupportGraphVisualization,`/graph`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/GraphHandler.html[GraphHandler] |`_ADMIN_GRAPH` |Return http://graphml.graphdrawing.org/[GraphML] formatted output from a <<graph-traversal.adoc#graph-traversal,`gather` `Nodes` streaming expression>>.\n+|<<index-replication.adoc#index-replication,`/replication`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/ReplicationHandler.html[ReplicationHandler] |`_REPLICATION` |Replicate indexes for SolrCloud recovery and Master/Slave index distribution.\n+|<<schema-api.adoc#schema-api,`/schema`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/SchemaHandler.html[SchemaHandler] |`_SCHEMA` |Retrieve/modify Solr schema.\n+|<<parallel-sql-interface.adoc#sql-request-handler,`/sql`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/SQLHandler.html[SQLHandler] |`_SQL` |Front end of the Parallel SQL interface.\n+|<<streaming-expressions.adoc#StreamingExpressions-StreamingRequestsandResponses,`/stream`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/StreamHandler.html[StreamHandler] |`_STREAM` |Distributed stream processing.\n+|<<the-terms-component.adoc#TheTermsComponent-UsingtheTermsComponentinaRequestHandler,`/terms`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/component/SearchHandler.html[SearchHandler] |`_TERMS` |Return a field's indexed terms and the number of documents containing each term.\n+|<<uploading-data-with-index-handlers.adoc#uploading-data-with-index-handlers,`/update`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/UpdateRequestHandler.html[UpdateRequestHandler] |`_UPDATE` |Add, delete and update indexed documents formatted as SolrXML, CSV, SolrJSON or javabin.\n+|<<uploading-data-with-index-handlers.adoc#UploadingDatawithIndexHandlers-CSVUpdateConveniencePaths,`/update/csv`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/UpdateRequestHandler.html[UpdateRequestHandler] |`_UPDATE_CSV` |Add and update CSV-formatted documents.\n+|<<uploading-data-with-index-handlers.adoc#UploadingDatawithIndexHandlers-CSVUpdateConveniencePaths,`/update/json`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/UpdateRequestHandler.html[UpdateRequestHandler] |`_UPDATE_JSON` |Add, delete and update SolrJSON-formatted documents.\n+|<<transforming-and-indexing-custom-json.adoc#transforming-and-indexing-custom-json,`/update/json/docs`>> |{solr-javadocs}/solr-core/org/apache/solr/handler/UpdateRequestHandler.html[UpdateRequestHandler] |`_UPDATE_JSON_DOCS ` |Add and update custom JSON-formatted documents.\n+|===\n+\n+[[ImplicitRequestHandlers-HowtoViewtheConfiguration]]\n+== How to View the Configuration\n+\n+You can see configuration for all request handlers, including the implicit request handlers, via the <<config-api.adoc#config-api,Config API>>. E.g. for the `gettingstarted` collection:\n+\n+`curl http://localhost:8983/solr/gettingstarted/config/requestHandler`\n+\n+To restrict the results to the configuration for a particular request handler, use the `componentName` request param. E.g. to see just the configuration for the `/export` request handler:\n+\n+`curl \"http://localhost:8983/solr/gettingstarted/config/requestHandler?componentName=/export\"`\n+\n+To include the expanded paramset in the response, as well as the effective parameters from merging the paramset params with the built-in params, use the `expandParams` request param. E.g. for the `/export` request handler:\n+\n+`curl \"http://localhost:8983/solr/gettingstarted/config/requestHandler?componentName=/export&expandParams=true\"`\n+\n+[[ImplicitRequestHandlers-HowtoEdittheConfiguration]]\n+== How to Edit the Configuration\n+\n+Because implicit request handlers are not present in `solrconfig.xml`, configuration of their associated `default`, `invariant` and `appends` parameters may be edited via<<request-parameters-api.adoc#request-parameters-api,\u00a0Request Parameters API>> using the paramset listed in the above table. However, other parameters, including SearchHandler components, may not be modified. The invariants and appends specified in the implicit configuration cannot be overridden.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/implicit-requesthandlers.adoc",
                "sha": "46e339a960dd07f74b3234d83dc6eccfcab853d5",
                "status": "added"
            },
            {
                "additions": 293,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/index-replication.adoc",
                "changes": 293,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/index-replication.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/index-replication.adoc",
                "patch": "@@ -0,0 +1,293 @@\n+= Index Replication\n+:page-shortname: index-replication\n+:page-permalink: index-replication.html\n+\n+Index Replication distributes complete copies of a master index to one or more slave servers. The master server continues to manage updates to the index. All querying is handled by the slaves. This division of labor enables Solr to scale to provide adequate responsiveness to queries against large search volumes.\n+\n+The figure below shows a Solr configuration using index replication. The master server's index is replicated on the slaves.\n+\n+.A Solr index can be replicated across multiple slave servers, which then process requests.\n+image::images/index-replication/worddav2b7e14725d898b4104cdd9c502fc77cd.png[image,width=159,height=235]\n+\n+\n+[[IndexReplication-IndexReplicationinSolr]]\n+== Index Replication in Solr\n+\n+Solr includes a Java implementation of index replication that works over HTTP:\n+\n+* The configuration affecting replication is controlled by a single file, `solrconfig.xml`\n+* Supports the replication of configuration files as well as index files\n+* Works across platforms with same configuration\n+* No reliance on OS-dependent file system features (eg: hard links)\n+* Tightly integrated with Solr; an admin page offers fine-grained control of each aspect of replication\n+* The Java-based replication feature is implemented as a request handler. Configuring replication is therefore similar to any normal request handler.\n+\n+.Replication In SolrCloud\n+[NOTE]\n+====\n+Although there is no explicit concept of \"master/slave\" nodes in a <<solrcloud.adoc#solrcloud,SolrCloud>> cluster, the `ReplicationHandler` discussed on this page is still used by SolrCloud as needed to support \"shard recovery\" \u2013 but this is done in a peer to peer manner.\n+\n+When using SolrCloud, the `ReplicationHandler` must be available via the `/replication` path. Solr does this implicitly unless overridden explicitly in your `solrconfig.xml`, but if you wish to override the default behavior, make certain that you do not explicitly set any of the \"master\" or \"slave\" configuration options mentioned below, or they will interfere with normal SolrCloud operation.\n+====\n+\n+[[IndexReplication-ReplicationTerminology]]\n+== Replication Terminology\n+\n+The table below defines the key terms associated with Solr replication.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Term |Definition\n+|Index |A Lucene index is a directory of files. These files make up the searchable and returnable data of a Solr Core.\n+|Distribution |The copying of an index from the master server to all slaves. The distribution process takes advantage of Lucene's index file structure.\n+|Inserts and Deletes |As inserts and deletes occur in the index, the directory remains unchanged. Documents are always inserted into newly created files. Documents that are deleted are not removed from the files. They are flagged in the file, deletable, and are not removed from the files until the index is optimized.\n+|Master and Slave |A Solr replication master is a single node which receives all updates initially and keeps everything organized. Solr replication slave nodes receive no updates directly, instead all changes (such as inserts, updates, deletes, etc.) are made against the single master node. Changes made on the master are distributed to all the slave nodes which service all query requests from the clients.\n+|Update |An update is a single change request against a single Solr instance. It may be a request to delete a document, add a new document, change a document, delete all documents matching a query, etc. Updates are handled synchronously within an individual Solr instance.\n+|Optimization |A process that compacts the index and merges segments in order to improve query performance. Optimization should only be run on the master nodes. An optimized index may give query performance gains compared to an index that has become fragmented over a period of time with many updates. Distributing an optimized index requires a much longer time than the distribution of new segments to an un-optimized index.\n+|Segments |A self contained subset of an index consisting of some documents and data structures related to the inverted index of terms in those documents.\n+|mergeFactor |A parameter that controls the number of segments in an index. For example, when mergeFactor is set to 3, Solr will fill one segment with documents until the limit maxBufferedDocs is met, then it will start a new segment. When the number of segments specified by mergeFactor is reached (in this example, 3) then Solr will merge all the segments into a single index file, then begin writing new documents to a new segment.\n+|Snapshot |A directory containing hard links to the data files of an index. Snapshots are distributed from the master nodes when the slaves pull them, \"smart copying\" any segments the slave node does not have in snapshot directory that contains the hard links to the most recent index data files.\n+|===\n+\n+[[IndexReplication-ConfiguringtheReplicationHandler]]\n+== Configuring the ReplicationHandler\n+\n+In addition to `ReplicationHandler` configuration options specific to the master/slave roles, there are a few special configuration options that are generally supported (even when using SolrCloud).\n+\n+* `maxNumberOfBackups` an integer value dictating the maximum number of backups this node will keep on disk as it receives `backup` commands.\n+* Similar to most other request handlers in Solr you may configure a set of <<requesthandlers-and-searchcomponents-in-solrconfig.adoc#RequestHandlersandSearchComponentsinSolrConfig-SearchHandlers,defaults, invariants, and/or appends>> parameters corresponding with any request parameters supported by the `ReplicationHandler` when <<IndexReplication-HTTPAPICommandsfortheReplicationHandler,processing commands>>.\n+\n+[[IndexReplication-ConfiguringtheReplicationRequestHandleronaMasterServer]]\n+=== Configuring the Replication RequestHandler on a Master Server\n+\n+Before running a replication, you should set the following parameters on initialization of the handler:\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Name |Description\n+|replicateAfter |String specifying action after which replication should occur. Valid values are commit, optimize, or startup. There can be multiple values for this parameter. If you use \"startup\", you need to have a \"commit\" and/or \"optimize\" entry also if you want to trigger replication on future commits or optimizes.\n+|backupAfter |String specifying action after which a backup should occur. Valid values are commit, optimize, or startup. There can be multiple values for this parameter. It is not required for replication, it just makes a backup.\n+|maxNumberOfBackups |Integer specifying how many backups to keep. This can be used to delete all but the most recent N backups.\n+|confFiles |The configuration files to replicate, separated by a comma.\n+|commitReserveDuration |If your commits are very frequent and your network is slow, you can tweak this parameter to increase the amount of time taken to download 5Mb from the master to a slave. The default is 10 seconds.\n+|===\n+\n+The example below shows a possible 'master' configuration for the `ReplicationHandler`, including a fixed number of backups and an invariant setting for the `maxWriteMBPerSec` request parameter to prevent slaves from saturating its network interface\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/replication\" class=\"solr.ReplicationHandler\">\n+  <lst name=\"master\">\n+    <str name=\"replicateAfter\">optimize</str>\n+    <str name=\"backupAfter\">optimize</str>\n+    <str name=\"confFiles\">schema.xml,stopwords.txt,elevate.xml</str>\n+    <str name=\"commitReserveDuration\">00:00:10</str>\n+  </lst>\n+  <int name=\"maxNumberOfBackups\">2</int>\n+  <lst name=\"invariants\">\n+    <str name=\"maxWriteMBPerSec\">16</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+[[IndexReplication-Replicatingsolrconfig.xml]]\n+==== Replicating `solrconfig.xml`\n+\n+In the configuration file on the master server, include a line like the following:\n+\n+[source,xml]\n+----\n+<str name=\"confFiles\">solrconfig_slave.xml:solrconfig.xml,x.xml,y.xml</str>\n+----\n+\n+This ensures that the local configuration `solrconfig_slave.xml` will be saved as `solrconfig.xml` on the slave. All other files will be saved with their original names.\n+\n+On the master server, the file name of the slave configuration file can be anything, as long as the name is correctly identified in the `confFiles` string; then it will be saved as whatever file name appears after the colon ':'.\n+\n+[[IndexReplication-ConfiguringtheReplicationRequestHandleronaSlaveServer]]\n+=== Configuring the Replication RequestHandler on a Slave Server\n+\n+The code below shows how to configure a ReplicationHandler on a slave.\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/replication\" class=\"solr.ReplicationHandler\">\n+  <lst name=\"slave\">\n+\n+    <!-- fully qualified url for the replication handler of master. It is\n+         possible to pass on this as a request param for the fetchindex command -->\n+    <str name=\"masterUrl\">http://remote_host:port/solr/core_name/replication</str>\n+\n+    <!-- Interval in which the slave should poll master.  Format is HH:mm:ss .\n+         If this is absent slave does not poll automatically.\n+\n+         But a fetchindex can be triggered from the admin or the http API -->\n+\n+    <str name=\"pollInterval\">00:00:20</str>\n+\n+    <!-- THE FOLLOWING PARAMETERS ARE USUALLY NOT REQUIRED-->\n+\n+    <!-- To use compression while transferring the index files. The possible\n+         values are internal|external.  If the value is 'external' make sure\n+         that your master Solr has the settings to honor the accept-encoding header.\n+         See here for details: http://wiki.apache.org/solr/SolrHttpCompression\n+         If it is 'internal' everything will be taken care of automatically.\n+         USE THIS ONLY IF YOUR BANDWIDTH IS LOW.\n+         THIS CAN ACTUALLY SLOWDOWN REPLICATION IN A LAN -->\n+    <str name=\"compression\">internal</str>\n+\n+    <!-- The following values are used when the slave connects to the master to\n+         download the index files.  Default values implicitly set as 5000ms and\n+         10000ms respectively. The user DOES NOT need to specify these unless the\n+         bandwidth is extremely low or if there is an extremely high latency -->\n+\n+    <str name=\"httpConnTimeout\">5000</str>\n+    <str name=\"httpReadTimeout\">10000</str>\n+\n+    <!-- If HTTP Basic authentication is enabled on the master, then the slave\n+         can be configured with the following -->\n+\n+    <str name=\"httpBasicAuthUser\">username</str>\n+    <str name=\"httpBasicAuthPassword\">password</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+[[IndexReplication-SettingUpaRepeaterwiththeReplicationHandler]]\n+== Setting Up a Repeater with the ReplicationHandler\n+\n+A master may be able to serve only so many slaves without affecting performance. Some organizations have deployed slave servers across multiple data centers. If each slave downloads the index from a remote data center, the resulting download may consume too much network bandwidth. To avoid performance degradation in cases like this, you can configure one or more slaves as repeaters. A repeater is simply a node that acts as both a master and a slave.\n+\n+* To configure a server as a repeater, the definition of the Replication `requestHandler` in the `solrconfig.xml` file must include file lists of use for both masters and slaves.\n+* Be sure to set the `replicateAfter` parameter to commit, even if `replicateAfter` is set to optimize on the main master. This is because on a repeater (or any slave), a commit is called only after the index is downloaded. The optimize command is never called on slaves.\n+* Optionally, one can configure the repeater to fetch compressed files from the master through the compression parameter to reduce the index download time.\n+\n+Here is an example of a ReplicationHandler configuration for a repeater:\n+\n+[source,xml]\n+----\n+<requestHandler name=\"/replication\" class=\"solr.ReplicationHandler\">\n+  <lst name=\"master\">\n+    <str name=\"replicateAfter\">commit</str>\n+    <str name=\"confFiles\">schema.xml,stopwords.txt,synonyms.txt</str>\n+  </lst>\n+  <lst name=\"slave\">\n+    <str name=\"masterUrl\">http://master.solr.company.com:8983/solr/core_name/replication</str>\n+    <str name=\"pollInterval\">00:00:60</str>\n+  </lst>\n+</requestHandler>\n+----\n+\n+[[IndexReplication-CommitandOptimizeOperations]]\n+== Commit and Optimize Operations\n+\n+When a commit or optimize operation is performed on the master, the RequestHandler reads the list of file names which are associated with each commit point. This relies on the `replicateAfter` parameter in the configuration to decide which types of events should trigger replication.\n+\n+// TODO: Change column width to %autowidth.spread when https://github.com/asciidoctor/asciidoctor-pdf/issues/599 is fixed\n+\n+[cols=\"30,70\",options=\"header\"]\n+|===\n+|Setting on the Master |Description\n+|commit |Triggers replication whenever a commit is performed on the master index.\n+|optimize |Triggers replication whenever the master index is optimized.\n+|startup |Triggers replication whenever the master index starts up.\n+|===\n+\n+The replicateAfter parameter can accept multiple arguments. For example:\n+\n+[source,xml]\n+----\n+<str name=\"replicateAfter\">startup</str>\n+<str name=\"replicateAfter\">commit</str>\n+<str name=\"replicateAfter\">optimize</str>\n+----\n+\n+[[IndexReplication-SlaveReplication]]\n+== Slave Replication\n+\n+The master is totally unaware of the slaves.\n+\n+The slave continuously keeps polling the master (depending on the `pollInterval` parameter) to check the current index version of the master. If the slave finds out that the master has a newer version of the index it initiates a replication process. The steps are as follows:\n+\n+* The slave issues a `filelist` command to get the list of the files. This command returns the names of the files as well as some metadata (for example, size, a lastmodified timestamp, an alias if any).\n+* The slave checks with its own index if it has any of those files in the local index. It then runs the filecontent command to download the missing files. This uses a custom format (akin to the HTTP chunked encoding) to download the full content or a part of each file. If the connection breaks in between, the download resumes from the point it failed. At any point, the slave tries 5 times before giving up a replication altogether.\n+* The files are downloaded into a temp directory, so that if either the slave or the master crashes during the download process, no files will be corrupted. Instead, the current replication will simply abort.\n+* After the download completes, all the new files are moved to the live index directory and the file's timestamp is same as its counterpart on the master.\n+* A commit command is issued on the slave by the Slave's ReplicationHandler and the new index is loaded.\n+\n+[[IndexReplication-ReplicatingConfigurationFiles]]\n+=== Replicating Configuration Files\n+\n+To replicate configuration files, list them using using the `confFiles` parameter. Only files found in the `conf` directory of the master's Solr instance will be replicated.\n+\n+Solr replicates configuration files only when the index itself is replicated. That means even if a configuration file is changed on the master, that file will be replicated only after there is a new commit/optimize on master's index.\n+\n+Unlike the index files, where the timestamp is good enough to figure out if they are identical, configuration files are compared against their checksum. The `schema.xml` files (on master and slave) are judged to be identical if their checksums are identical.\n+\n+As a precaution when replicating configuration files, Solr copies configuration files to a temporary directory before moving them into their ultimate location in the conf directory. The old configuration files are then renamed and kept in the same `conf/` directory. The ReplicationHandler does not automatically clean up these old files.\n+\n+If a replication involved downloading of at least one configuration file, the ReplicationHandler issues a core-reload command instead of a commit command.\n+\n+[[IndexReplication-ResolvingCorruptionIssuesonSlaveServers]]\n+=== Resolving Corruption Issues on Slave Servers\n+\n+If documents are added to the slave, then the slave is no longer in sync with its master. However, the slave will not undertake any action to put itself in sync, until the master has new index data.\n+\n+When a commit operation takes place on the master, the index version of the master becomes different from that of the slave. The slave then fetches the list of files and finds that some of the files present on the master are also present in the local index but with different sizes and timestamps. This means that the master and slave have incompatible indexes.\n+\n+To correct this problem, the slave then copies all the index files from master to a new index directory and asks the core to load the fresh index from the new directory.\n+\n+[[IndexReplication-HTTPAPICommandsfortheReplicationHandler]]\n+== HTTP API Commands for the ReplicationHandler\n+\n+You can use the HTTP commands below to control the ReplicationHandler's operations.\n+\n+[width=\"100%\",options=\"header\",]\n+|===\n+|Command |Description\n+|http://_master_host:port_/solr/_core_name_/replication?command=enablereplication |Enables replication on the master for all its slaves.\n+|http://_master_host:port_/solr/_core_name_/replication?command=disablereplication |Disables replication on the master for all its slaves.\n+|http://_host:port_/solr/_core_name_/replication?command=indexversion |Returns the version of the latest replicatable index on the specified master or slave.\n+|http://_slave_host:port_/solr/_core_name_/replication?command=fetchindex |Forces the specified slave to fetch a copy of the index from its master. If you like, you can pass an extra attribute such as masterUrl or compression (or any other parameter which is specified in the `<lst name=\"slave\">` tag) to do a one time replication from a master. This obviates the need for hard-coding the master in the slave.\n+|http://_slave_host:port_/solr/_core_name_/replication?command=abortfetch |Aborts copying an index from a master to the specified slave.\n+|http://_slave_host:port_/solr/_core_name_/replication?command=enablepoll |Enables the specified slave to poll for changes on the master.\n+|http://_slave_host:port_/solr/_core_name_/replication?command=disablepoll |Disables the specified slave from polling for changes on the master.\n+|http://_slave_host:port_/solr/_core_name_/replication?command=details |Retrieves configuration details and current status.\n+|http://_host:port_/solr/_core_name_/replication?command=filelist&generation=<_generation-number_> |Retrieves a list of Lucene files present in the specified host's index. You can discover the generation number of the index by running the `indexversion` command.\n+|http://_master_host:port_/solr/_core_name_/replication?command=backup a|\n+Creates a backup on master if there are committed index data in the server; otherwise, does nothing. This command is useful for making periodic backups.\n+\n+supported request parameters:\n+\n+* `numberToKeep:` request parameter can be used with the backup command unless the `maxNumberOfBackups` initialization parameter has been specified on the handler \u2013 in which case `maxNumberOfBackups` is always used and attempts to use the `numberToKeep` request parameter will cause an error.\n+* `name` : (optional) Backup name . The snapshot will be created in a directory called snapshot.<name> within the data directory of the core . By default the name is generated using date in `yyyyMMddHHmmssSSS` format. If `location` parameter is passed , that would be used instead of the data directory\n+* `location`: Backup location\n+\n+|http://_master_host:port_ /solr/_core_name_/replication?command=deletebackup a|\n+Delete any backup created using the `backup` command .\n+\n+Request parameters:\n+\n+* name: The name of the snapshot . A snapshot with the name snapshot.<name> must exist .If not, an error is thrown\n+* location: Location where the snapshot is created\n+\n+|===\n+\n+[[IndexReplication-DistributionandOptimization]]\n+== Distribution and Optimization\n+\n+Optimizing an index is not something most users should generally worry about - but in particular users should be aware of the impacts of optimizing an index when using the `ReplicationHandler`.\n+\n+The time required to optimize a master index can vary dramatically. A small index may be optimized in minutes. A very large index may take hours. The variables include the size of the index and the speed of the hardware.\n+\n+Distributing a newly optimized index may take only a few minutes or up to an hour or more, again depending on the size of the index and the performance capabilities of network connections and disks. During optimization the machine is under load and does not process queries very well. Given a schedule of updates being driven a few times an hour to the slaves, we cannot run an optimize with every committed snapshot.\n+\n+Copying an optimized index means that the *entire* index will need to be transferred during the next snappull. This is a large expense, but not nearly as huge as running the optimize everywhere. Consider this example: on a three-slave one-master configuration, distributing a newly-optimized index takes approximately 80 seconds _total_. Rolling the change across a tier would require approximately ten minutes per machine (or machine group). If this optimize were rolled across the query tier, and if each slave node being optimized were disabled and not receiving queries, a rollout would take at least twenty minutes and potentially as long as an hour and a half. Additionally, the files would need to be synchronized so that the _following_ the optimize, snappull would not think that the independently optimized files were different in any way. This would also leave the door open to independent corruption of indexes instead of each being a perfect copy of the master.\n+\n+Optimizing on the master allows for a straight-forward optimization operation. No query slaves need to be taken out of service. The optimized index can be distributed in the background as queries are being normally serviced. The optimization can occur at any time convenient to the application providing index updates.\n+\n+While optimizing may have some benefits in some situations, a rapidly changing index will not retain those benefits for long, and since optimization is an intensive process, it may be better to consider other options, such as lowering the merge factor (discussed in the section on <<indexconfig-in-solrconfig.adoc#merge-factors,Index Configuration>>).",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/index-replication.adoc",
                "sha": "b606b00e136ed29f22730534c822c901e7515f77",
                "status": "added"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/index.adoc",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/index.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/index.adoc",
                "patch": "@@ -0,0 +1,30 @@\n+= Apache Solr Reference Guide\n+:page-shortname: index\n+:page-permalink: index.html\n+:page-children: about-this-guide, getting-started, upgrading-solr, using-the-solr-administration-user-interface, documents-fields-and-schema-design, understanding-analyzers-tokenizers-and-filters, indexing-and-basic-data-operations, searching, the-well-configured-solr-instance, managing-solr, solrcloud, legacy-scaling-and-distribution, client-apis, major-changes-from-solr-5-to-solr-6, upgrading-a-solr-cluster, further-assistance, solr-glossary, errata\n+\n+This reference guide describes Apache Solr, the open source solution for search. You can download Apache Solr from the Solr website at http://lucene.apache.org/solr/.\n+\n+This Guide contains the following sections:\n+\n+*<<getting-started.adoc#getting-started,Getting Started>>*: This section guides you through the installation and setup of Solr.\n+\n+*<<using-the-solr-administration-user-interface.adoc#using-the-solr-administration-user-interface,Using the Solr Administration User Interface>>*: This section introduces the Solr Web-based user interface. From your browser you can view configuration files, submit queries, view logfile settings and Java environment settings, and monitor and control distributed configurations.\n+\n+*<<documents-fields-and-schema-design.adoc#documents-fields-and-schema-design,Documents, Fields, and Schema Design>>*: This section describes how Solr organizes its data for indexing. It explains how a Solr schema defines the fields and field types which Solr uses to organize data within the document files it indexes.\n+\n+*<<understanding-analyzers-tokenizers-and-filters.adoc#understanding-analyzers-tokenizers-and-filters,Understanding Analyzers, Tokenizers, and Filters>>*: This section explains how Solr prepares text for indexing and searching. Analyzers parse text and produce a stream of tokens, lexical units used for indexing and searching. Tokenizers break field data down into tokens. Filters perform other transformational or selective work on token streams.\n+\n+*<<indexing-and-basic-data-operations.adoc#indexing-and-basic-data-operations,Indexing and Basic Data Operations>>*: This section describes the indexing process and basic index operations, such as commit, optimize, and rollback.\n+\n+*<<searching.adoc#searching,Searching>>*: This section presents an overview of the search process in Solr. It describes the main components used in searches, including request handlers, query parsers, and response writers. It lists the query parameters that can be passed to Solr, and it describes features such as boosting and faceting, which can be used to fine-tune search results.\n+\n+*<<the-well-configured-solr-instance.adoc#the-well-configured-solr-instance,The Well-Configured Solr Instance>>*: This section discusses performance tuning for Solr. It begins with an overview of the `solrconfig.xml` file, then tells you how to configure cores with `solr.xml`, how to configure the Lucene index writer, and more.\n+\n+*<<managing-solr.adoc#managing-solr,Managing Solr>>*: This section discusses important topics for running and monitoring Solr. Other topics include how to back up a Solr instance, and how to run Solr with Java Management Extensions (JMX).\n+\n+*<<solrcloud.adoc#solrcloud,SolrCloud>>*: This section describes the newest and most exciting of Solr's new features, SolrCloud, which provides comprehensive distributed capabilities.\n+\n+*<<legacy-scaling-and-distribution.adoc#legacy-scaling-and-distribution,Legacy Scaling and Distribution>>*: This section tells you how to grow a Solr distribution by dividing a large index into sections called shards, which are then distributed across multiple servers, or by replicating a single index across multiple services.\n+\n+*<<client-apis.adoc#client-apis,Client APIs>>*: This section tells you how to access Solr through various client APIs, including JavaScript, JSON, and Ruby.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/index.adoc",
                "sha": "d1f0a840e51bdbf6393c9e41a2b7c4ef40170e18",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexconfig-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/indexconfig-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/indexconfig-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexconfig-in-solrconfig.adoc",
                "sha": "97fe220e18cb7603b9c1618bb09a48d6e99ba240",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexing-and-basic-data-operations.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/indexing-and-basic-data-operations.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/indexing-and-basic-data-operations.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexing-and-basic-data-operations.adoc",
                "sha": "ebd35e1e7d29941d8d2d4c1a845c81d1eb0f5eed",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexupgrader-tool.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/indexupgrader-tool.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/indexupgrader-tool.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/indexupgrader-tool.adoc",
                "sha": "1c3db45c11825ec6dea110aabb5f3d5bad5d9a39",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/initparams-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/initparams-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/initparams-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/initparams-in-solrconfig.adoc",
                "sha": "54238015333ab4648f48d870c486f098762471eb",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/installing-solr.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/installing-solr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/installing-solr.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/installing-solr.adoc",
                "sha": "ab3fe5bc34f558fcf8b469f0b7d9f91fe321b4ce",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-client-apis.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/introduction-to-client-apis.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/introduction-to-client-apis.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-client-apis.adoc",
                "sha": "c32f3e27880cea2927a081fcbea66282a96568d1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-scaling-and-distribution.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/introduction-to-scaling-and-distribution.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/introduction-to-scaling-and-distribution.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-scaling-and-distribution.adoc",
                "sha": "9eb43133322321e11b847c65790cc951ad58913d",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-solr-indexing.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/introduction-to-solr-indexing.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/introduction-to-solr-indexing.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/introduction-to-solr-indexing.adoc",
                "sha": "80f4cfd29efca8e3acc1d9b1b2c977686514ad95",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/java-properties.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/java-properties.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/java-properties.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/java-properties.adoc",
                "sha": "7b6553c1f60d9a7cacee14bcdb9a327d90c786e5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/customscripts.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/js/customscripts.js?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/js/customscripts.js",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/customscripts.js",
                "sha": "19156c5a83e952d31b9c112cc85cc2d70687f13a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/jekyll-search.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/js/jekyll-search.js?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/js/jekyll-search.js",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/jekyll-search.js",
                "sha": "04d6a0d3a481521d1ef1a49a7ff0e26ca98d6444",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/jquery.navgoco.min.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/js/jquery.navgoco.min.js?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/js/jquery.navgoco.min.js",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/jquery.navgoco.min.js",
                "sha": "4ba44753323370cf0cd4f1dc79eb61a99d0379f6",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/toc.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/js/toc.js?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/js/toc.js",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/js/toc.js",
                "sha": "9adff0daf9343930d28f5686e0c3078d954526bc",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/jvm-settings.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/jvm-settings.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/jvm-settings.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/jvm-settings.adoc",
                "sha": "dbb06405c70972f0324dcd708b2e5e2899d4145c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/kerberos-authentication-plugin.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/kerberos-authentication-plugin.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/kerberos-authentication-plugin.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/kerberos-authentication-plugin.adoc",
                "sha": "7bf30603f9e3b86519ee7470f0932ad805ff0880",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/language-analysis.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/language-analysis.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/language-analysis.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/language-analysis.adoc",
                "sha": "ea12424232c72232e83452b26d086ef16892c413",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/learning-to-rank.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/learning-to-rank.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/learning-to-rank.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/learning-to-rank.adoc",
                "sha": "e6dbe0a9dc08686f4d9f100a2aad99ce6b135a25",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/legacy-scaling-and-distribution.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/legacy-scaling-and-distribution.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/legacy-scaling-and-distribution.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/legacy-scaling-and-distribution.adoc",
                "sha": "3499387601a9b16e33a790e488934075e67e1b8c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/lib-directives-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/lib-directives-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/lib-directives-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/lib-directives-in-solrconfig.adoc",
                "sha": "036e00a800058698ab3792570dd576ca1406c475",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/licenses/LICENSE",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/licenses/LICENSE?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/licenses/LICENSE",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/licenses/LICENSE",
                "sha": "e04b3d02e32f76000dd95f56ca68316d1e5f148f",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/licenses/LICENSE-BSD-NAVGOCO.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/licenses/LICENSE-BSD-NAVGOCO.txt?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/licenses/LICENSE-BSD-NAVGOCO.txt",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/licenses/LICENSE-BSD-NAVGOCO.txt",
                "sha": "7fdefc390326f80bf5059b61b165b24d3e500f44",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/local-parameters-in-queries.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/local-parameters-in-queries.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/local-parameters-in-queries.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/local-parameters-in-queries.adoc",
                "sha": "1d24b61932a298c25e48ae5f0ce7a17790c8145a",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/logging.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/logging.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/logging.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/logging.adoc",
                "sha": "a048b24fc79e110d9688cfc6a78c70e155fa3ac4",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/major-changes-from-solr-5-to-solr-6.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/major-changes-from-solr-5-to-solr-6.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/major-changes-from-solr-5-to-solr-6.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/major-changes-from-solr-5-to-solr-6.adoc",
                "sha": "671e5b4ea4093284c6181e00df1a76c7b086c495",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/making-and-restoring-backups.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/making-and-restoring-backups.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/making-and-restoring-backups.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/making-and-restoring-backups.adoc",
                "sha": "a1fdabad2d469d97e51bca292634d00fc2b57cae",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/managed-resources.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/managed-resources.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/managed-resources.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/managed-resources.adoc",
                "sha": "7e91ee37d7fd633d5a2cd06b95a1ff825199ec96",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/managing-solr.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/managing-solr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/managing-solr.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/managing-solr.adoc",
                "sha": "ad13113151bc3de0e25527a44097741478e13a48",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/mbean-request-handler.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/mbean-request-handler.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/mbean-request-handler.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/mbean-request-handler.adoc",
                "sha": "0582b82128c0845c81810a2225da07e8558ecf09",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/merging-indexes.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/merging-indexes.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/merging-indexes.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/merging-indexes.adoc",
                "sha": "bf554aa5496735ba0f69f9035801fde6a5efa602",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/metrics-reporting.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/metrics-reporting.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/metrics-reporting.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/metrics-reporting.adoc",
                "sha": "24a4ee191c3412d6d4d90014202eb0de214fb079",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/morelikethis.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/morelikethis.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/morelikethis.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/morelikethis.adoc",
                "sha": "a99cc0336328de32c487e650d94e67cf3973d796",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/near-real-time-searching.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/near-real-time-searching.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/near-real-time-searching.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/near-real-time-searching.adoc",
                "sha": "f4396f39c40583d7bca90c3321192617c724a99e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/other-parsers.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/other-parsers.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/other-parsers.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/other-parsers.adoc",
                "sha": "290c5b81e7a7686f865d2a91b2362e5e669b6f20",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/other-schema-elements.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/other-schema-elements.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/other-schema-elements.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/other-schema-elements.adoc",
                "sha": "42254ebeb07fe2c88b48effed64430beb5486c37",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-documents-fields-and-schema-design.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/overview-of-documents-fields-and-schema-design.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/overview-of-documents-fields-and-schema-design.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-documents-fields-and-schema-design.adoc",
                "sha": "6af1941abd9822818120e2d540c41242867b3c4c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-searching-in-solr.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/overview-of-searching-in-solr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/overview-of-searching-in-solr.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-searching-in-solr.adoc",
                "sha": "c432f200a8e820bc4695ef4f0c9ca521f3e95bb8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-the-solr-admin-ui.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/overview-of-the-solr-admin-ui.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/overview-of-the-solr-admin-ui.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/overview-of-the-solr-admin-ui.adoc",
                "sha": "1f96ccc98cc984763ea949d6fd1b632c684654f8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pagination-of-results.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/pagination-of-results.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/pagination-of-results.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pagination-of-results.adoc",
                "sha": "98d750f8c0b925a2a20dfe0211c356da7122941b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/parallel-sql-interface.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/parallel-sql-interface.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/parallel-sql-interface.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/parallel-sql-interface.adoc",
                "sha": "d4bb2c070077b2dc203cacc0c83f6960da791b1b",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/parameter-reference.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/parameter-reference.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/parameter-reference.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/parameter-reference.adoc",
                "sha": "4942f57470c1b66dadf21a86b8ad93c35e79bca0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pdf/SolrRefGuide-all.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/pdf/SolrRefGuide-all.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/pdf/SolrRefGuide-all.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pdf/SolrRefGuide-all.adoc",
                "sha": "667fc3b9ac3e7582466327e642f289bc92146074",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pdf/themes/refguide-theme.yml",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/pdf/themes/refguide-theme.yml?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/pdf/themes/refguide-theme.yml",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/pdf/themes/refguide-theme.yml",
                "sha": "5e272ced49b52f84489d1cb1294908d598d64011",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/performance-statistics-reference.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/performance-statistics-reference.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/performance-statistics-reference.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/performance-statistics-reference.adoc",
                "sha": "c0dfa1b2831f985b4d630a3a0862fc97a0689ed5",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/phonetic-matching.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/phonetic-matching.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/phonetic-matching.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/phonetic-matching.adoc",
                "sha": "1f2f3c0c51687000e9d4af1935623ba2626775a9",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/ping.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/ping.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/ping.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/ping.adoc",
                "sha": "d0a6039681c0f5ab2dade87279b2e8d707f29196",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/plugins-stats-screen.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/plugins-stats-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/plugins-stats-screen.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/plugins-stats-screen.adoc",
                "sha": "e32ca052511849173ece4fccdadd3dcb132327d0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/post-tool.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/post-tool.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/post-tool.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/post-tool.adoc",
                "sha": "f6d084b24d511ae8d6812332ea9258fdc4e639b0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/putting-the-pieces-together.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/putting-the-pieces-together.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/putting-the-pieces-together.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/putting-the-pieces-together.adoc",
                "sha": "eac49b205932eb5424461d0a7c8f2e06126bfcae",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-re-ranking.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/query-re-ranking.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/query-re-ranking.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-re-ranking.adoc",
                "sha": "9f020594cb8cb38ca3b994fd1bd8d58267b01c66",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-screen.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/query-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/query-screen.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-screen.adoc",
                "sha": "548079641c516ec91f839e4be0f40821a765cf63",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-settings-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/query-settings-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/query-settings-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-settings-in-solrconfig.adoc",
                "sha": "52f852d3b44e29d4c0cf43ec2769fde72a01b4e2",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-syntax-and-parsing.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/query-syntax-and-parsing.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/query-syntax-and-parsing.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/query-syntax-and-parsing.adoc",
                "sha": "31f5131eb183440bdbe2850c8325bfb275b773b2",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/read-and-write-side-fault-tolerance.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/read-and-write-side-fault-tolerance.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/read-and-write-side-fault-tolerance.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/read-and-write-side-fault-tolerance.adoc",
                "sha": "91d94bb0b305b20a9394903c8b46f31be9d875d0",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/realtime-get.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/realtime-get.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/realtime-get.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/realtime-get.adoc",
                "sha": "e9ddc5cf9c2c4baa6dd3a8659c3302fbd053000e",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/relevance.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/relevance.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/relevance.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/relevance.adoc",
                "sha": "afa37e57822911d08acad8daa64d7366dbf7e4b2",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/replication-screen.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/replication-screen.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/replication-screen.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/replication-screen.adoc",
                "sha": "d8c8e3fbeb3a5516e677963de521cfecd240a79f",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/request-parameters-api.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/request-parameters-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/request-parameters-api.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/request-parameters-api.adoc",
                "sha": "8037421d88fd3da985f6c189deeae954933819fe",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/requestdispatcher-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/requestdispatcher-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/requestdispatcher-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/requestdispatcher-in-solrconfig.adoc",
                "sha": "44ef0b134f4b95b4e8c46a6efb3568df4e52494c",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/requesthandlers-and-searchcomponents-in-solrconfig.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/requesthandlers-and-searchcomponents-in-solrconfig.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/requesthandlers-and-searchcomponents-in-solrconfig.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/requesthandlers-and-searchcomponents-in-solrconfig.adoc",
                "sha": "380e2c56f66950d6dc03a387dc3f6ca7b7680e74",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/response-writers.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/response-writers.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/response-writers.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/response-writers.adoc",
                "sha": "3fe3bf4cc87c2a9bea206393d802e3036909d752",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/result-clustering.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/result-clustering.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/result-clustering.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/result-clustering.adoc",
                "sha": "03214451206a2df31622584ce89c51a165e767d8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/result-grouping.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/result-grouping.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/result-grouping.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/result-grouping.adoc",
                "sha": "d2dfafb268f2f7f2b9d30f50fde1b7296f04abe7",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/rule-based-authorization-plugin.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/rule-based-authorization-plugin.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/rule-based-authorization-plugin.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/rule-based-authorization-plugin.adoc",
                "sha": "cc85567edae614a15698efec78997a003c6acea1",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/rule-based-replica-placement.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/rule-based-replica-placement.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/rule-based-replica-placement.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/rule-based-replica-placement.adoc",
                "sha": "c069cf3eb83cf64934cf728a57e7684f97f36894",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-solr-on-hdfs.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/running-solr-on-hdfs.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/running-solr-on-hdfs.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-solr-on-hdfs.adoc",
                "sha": "4e514461c7246d4ccca68aacd3e73060b9672149",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-solr.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/running-solr.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/running-solr.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-solr.adoc",
                "sha": "6cb904d0b7120b4cacf476c32a22f7fa10a7a74d",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-your-analyzer.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/running-your-analyzer.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/running-your-analyzer.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/running-your-analyzer.adoc",
                "sha": "c143d7f31758c38c08f5b4fca47bd4afc6ef2bd8",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/lucene-solr/blob/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/schema-api.adoc",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solr-ref-guide/src/schema-api.adoc?ref=95968c69fd3acdbd276a6785732458e7595bebae",
                "deletions": 0,
                "filename": "solr/solr-ref-guide/src/schema-api.adoc",
                "raw_url": "https://github.com/apache/lucene-solr/raw/95968c69fd3acdbd276a6785732458e7595bebae/solr/solr-ref-guide/src/schema-api.adoc",
                "sha": "f1ea86b061bdb0eedda53f75f92478757c98649c",
                "status": "added"
            }
        ],
        "message": "squash merge jira/solr-10290 into master\n\nSquashed commit of the following:\n\ncommit babe763e9d0f9561622171a45ab78607955c5dab\nMerge: 5a4d757 69783f6\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 13:26:09 2017 -0700\n\n    Merge branch 'master' into jira/solr-10290\n\n    Conflicts:\n    \tlucene/ivy-versions.properties\n    \tsolr/CHANGES.txt\n    \tsolr/core/src/java/org/apache/solr/handler/admin/CollectionHandlerApi.java\n    \tsolr/licenses/android-json-LICENSE-ASL.txt\n    \tsolr/licenses/asciidoctor-ant-LICENSE-ASL.txt\n    \tsolr/solr-ref-guide/src/fonts/Noto_Sans/LICENSE.txt\n\ncommit 5a4d7579c7d7b84263fd96e2f0dbe0c9db2f0ca0\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 12:08:30 2017 -0700\n\n    ref guide tools: replace org.json with (not quite) drop in clean room replacement from android, and add all missting licenes and checksums\n\ncommit 4570315c38a11cf18a336bb68f5ba2e9195e53e8\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 10:36:35 2017 -0700\n\n    license headers for tools\n\ncommit bd3d1cfad6579fbcdca76d9a98ce6362174dcce7\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 10:32:08 2017 -0700\n\n    fix solr 'resolve' target to also resolve ref guide\n\ncommit f132c9634ddc6423a2760f3df602b4add6052de8\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 10:22:44 2017 -0700\n\n    Fix some ivy related precommit issues\n\ncommit 2210941839329422fa1e1de09f799678fc219cbc\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 10:09:38 2017 -0700\n\n    remove old nocommit debugging code (was tired that night)\n\ncommit 4c80ac15abbae01b5adde2119dba450ae62f6698\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 10:08:28 2017 -0700\n\n    tabs to spaces\n\ncommit da77243dd315c63242ac4f986c85f348ea302baa\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 10 09:47:02 2017 -0700\n\n    fix broken anchors\n\ncommit 7856fdf7a1ffb8ce038f3a40e8057f9f62dc89ec\nAuthor: Cassandra Targett <cassandra.targett@lucidworks.com>\nDate:   Wed May 10 09:43:19 2017 -0500\n\n    SOLR-10290: make page TOC appear on page load\n\ncommit 39fdd15700de7c3a23f332b11fd64b1393b37895\nAuthor: Cassandra Targett <cassandra.targett@lucidworks.com>\nDate:   Wed May 10 09:42:45 2017 -0500\n\n    SOLR-10290: remove unused usermaps and tab formats\n\ncommit fb86e76d1a8caa6051a1a066496897abbe3e6830\nAuthor: Cassandra Targett <cassandra.targett@lucidworks.com>\nDate:   Wed May 10 08:38:57 2017 -0500\n\n    Add back json and jsoup dependencies\n\ncommit 3d036dec3cd1e18e9048d1832f84207e625dd752\nAuthor: Cassandra Targett <cassandra.targett@lucidworks.com>\nDate:   Wed May 10 08:01:57 2017 -0500\n\n    Update comment for asciidoctor-ant\n\ncommit ffdc0b4511b62642a01f9df16e1806199f17b818\nAuthor: Alan Woodward <romseygeek@apache.org>\nDate:   Wed May 10 08:29:55 2017 +0100\n\n    LUCENE-7741: Add explain() to DoubleValuesSource\n\ncommit 370adaa6f1d033e94e051b50a9633a5e8737ea69\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue May 9 15:18:22 2017 +0100\n\n    SOLR-10535: remove six unused test files\n    (Jason Gerlowski via Christine Poerschke)\n\ncommit 017da204ed18dfbe4bd28b77d484a1a4b071b2d9\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Tue May 9 12:53:18 2017 +0200\n\n    SOLR-10262: Add support for configurable metrics implementations.\n\ncommit dea9c334fc597953dcdff31ce6df73d584e744ec\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Tue May 9 13:03:18 2017 +0200\n\n    SOLR-10644: solr.in.sh installed by install script should be writable by solr user\n\ncommit 788b696cdc6f89479e200189b29646d293f83094\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Tue May 9 12:42:41 2017 +0530\n\n    SOLR-8440: Support for enabling basic authentication using bin/solr|bin/solr.cmd\n\n      Usage:\n        bin/solr auth -enable -prompt\n        bin/solr auth -enable -credentials solr:SolrRocks\n        bin/solr auth -disable\n\ncommit fba5c76fc2e830c44a1078ee492d3932e31b80dc\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Tue May 9 13:56:49 2017 +0700\n\n    SOLR-10619: Optimize using cache for DistributedQueue in case of single-consumer\n\ncommit 1a8bdc53dd733d18391251029d99209f1e7269fe\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 8 22:21:10 2017 -0400\n\n    SOLR-10638: Update CHANGES.txt\n\ncommit 33c2ffd91ed8bde2c1160e3642bcc7ffb227f442\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 8 22:04:51 2017 -0400\n\n    SOLR-10638: Add normalize Stream Evaluator\n\ncommit b4646846e573bfeb53218dcb1944c82f3ea0abb0\nAuthor: Scott Blum <dragonsinth@apache.org>\nDate:   Mon May 8 20:32:38 2017 -0400\n\n    SOLR-10524: Build fix for NPE\n\n    Introduced by ZkStateWriter batching optimizations.\n\ncommit 5a253a428607ae1153852c9343e7871317d8789c\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Mon May 8 17:30:22 2017 -0700\n\n    SOLR-10639: Removed entry from CHANGES.txt\n\ncommit 46e6133540bfb018da9f463bc970b041dc9f1b25\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Mon May 8 17:11:35 2017 -0700\n\n    SOLR-10639: Fix NPE in LRU/LFU/FastLRU caches toString method\n\ncommit 4b116a96f3efd40b62b9e400e52df4d25972883f\nAuthor: jdyer1 <jdyer@apache.org>\nDate:   Mon May 8 13:28:55 2017 -0500\n\n    SOLR-10522: Revert \"SOLR-9972: SpellCheckComponent collations and suggestions returned as a JSON object rather than a list\"\n\ncommit fd626bf0f17e1812bbded71e74446c1a7977fb02\nAuthor: jdyer1 <jdyer@apache.org>\nDate:   Mon May 8 13:26:42 2017 -0500\n\n    SOLR-10522: Revert \"SOLR-9972: SpellCheckComponent collations and suggestions returned as a JSON object rather than a list\"\n\n    This reverts commit 4cd3d15da8ef77ef50e2bda91ed6d3c6e87b5426.\n\ncommit 42e4ea69c6d59bd7b36495149743af486129b42f\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 8 10:19:41 2017 -0400\n\n    SOLR-10625: Update CHANGES.txt\n\ncommit 8675ced8e36eb2fc15edc0aa4dae34caec26d933\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 8 09:53:12 2017 -0400\n\n    SOLR-10625: Add convolution Stream Evaluator\n\ncommit f830eff0c03e61b2608f8b9d12593b04ace8262f\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon May 8 16:11:01 2017 +0530\n\n    Fixed nsToMs calculation in OverseerTest\n\ncommit 65d5ead9b0a443444529c5b0047b585353233e17\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon May 8 15:50:10 2017 +0530\n\n    SOLR-10630: HttpSolrCall.getAuthCtx().new AuthorizationContext() {...}.getParams() sometimes throws java.lang.NullPointerException\n\ncommit 1df6d3b5e07edbe737473c72a1301b2859481671\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Mon May 8 16:21:19 2017 +0700\n\n    SOLR-10524: Explore in-memory partitioning for processing Overseer queue messages\n\ncommit f627c9fbaf225684401fe2166c454f91999266b7\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Mon May 8 10:48:20 2017 +0200\n\n    SOLR-8149: Admin UI - Plugins / Stats - active item is now highlighted\n\ncommit 09a7cba99c178636dc57c5ffc59c08c81b6504e0\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sun May 7 21:02:41 2017 -0400\n\n    SOLR-10626: Update CHANGES.txt\n\ncommit 0051bacaa35e05515c33b92c58828da3ea382d13\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sun May 7 20:42:39 2017 -0400\n\n    SOLR-10626: Add covariance Stream Evaluator\n\ncommit 07b707f4a2d153266a771dc9c5d3571db9f7628d\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sun May 7 16:26:53 2017 -0400\n\n    SOLR-10622: Update CHANGES.txt\n\ncommit c2a68d152534a8bef37f65cddc696e7983691821\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sun May 7 15:23:56 2017 -0400\n\n    SOLR-10622: Add regress and predict Stream Evaluators\n\ncommit a95438e851570c37ca5652e9ce41e57eb5aaa0fd\nAuthor: Uwe Schindler <uschindler@apache.org>\nDate:   Sun May 7 13:24:21 2017 +0200\n\n    LUCENE-5365, LUCENE-7818: Fix incorrect condition in queryparser's QueryNodeOperation#logicalAnd()\n\ncommit 6de19d0f48fb1413a46379284928da8b35f0dd85\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sat May 6 10:44:57 2017 +0300\n\n    SOLR-10614: remove static backdoor fields from SimplePostTool.\n    Enabling testTechproductsExample\n\ncommit 204b54b0ad15678a656c4544b52846ea69932153\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sat May 6 12:53:29 2017 -0400\n\n    SOLR-10601: Update CHANGES.txt\n\ncommit 264ec0e791c847717e41983fad2efa2f4a7851c3\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sat May 6 12:45:53 2017 -0400\n\n    SOLR-10536: Update CHANGES.txt\n\ncommit 1f6e30fef088c1629ad35ad149c0a655f105a414\nAuthor: yonik <yonik@apache.org>\nDate:   Sat May 6 05:49:19 2017 -0400\n\n    SOLR-10547: consolidate MinAgg+MaxAgg, add min/max support for single valued string fields\n\ncommit 93962273a9fa79c9714edeb45df9cdb0f7e744e6\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sat May 6 00:36:00 2017 +0300\n\n    SOLR-10615: latching SDF.doFilter() on init(); respond 404 instead of 500 in case of init failures or corecontainer shutdown.\n\ncommit d22431b2bf782cbf11d1605e8f45b17f4b08643a\nAuthor: Noble Paul <noble@apache.org>\nDate:   Sat May 6 07:54:22 2017 +0930\n\n    SOLR-9530: addressing test failures with seed 9F9128B8E3E8FAA7\n\ncommit 3da09c91c6729d5e9a349e831608e5d59c0de8e9\nAuthor: Noble Paul <noble@apache.org>\nDate:   Sat May 6 06:00:54 2017 +0930\n\n    SOLR-9530: fixing test error\n\ncommit dd93e0f0ac07e3609e75e8fdef08cafb270dec38\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 14:45:11 2017 -0400\n\n    SOLR-10582: Update CHANGES.txt\n\ncommit 45a7998d0d79a7e230b0c9fe4f8345b94529603c\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 14:36:32 2017 -0400\n\n    SOLR-10559: Update CHANGES.txt\n\ncommit 717da83895dc23ef7c7c291404eb54463318241c\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 14:27:46 2017 -0400\n\n    SOLR-10566: Update CHANGES.txt\n\ncommit 181d2821b1d2eed28172e748fc39415c679ada9d\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Thu May 4 18:20:52 2017 +0100\n\n    SOLR-10572: Removed three \"no longer supported in solrconfig.xml\" asserts.\n\ncommit 338bdf27fb021a5b34b538d0ed65db9a9d774fb2\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:57:03 2017 -0400\n\n    SOLR-10516: Update CHANGES.txt\n\ncommit 15f2014bfd2899f404579fb4c9d4738755399fe5\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:48:47 2017 -0400\n\n    SOLR-10504: Update CHANGES.txt\n\ncommit 2cf6c76b58dca10d6f77035f2c74a429991fc493\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:40:02 2017 -0400\n\n    SOLR-10274: Update CHANGES.txt\n\ncommit 4d6a8d92447d97c74171edf9f21df304bc4e6b3c\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:32:33 2017 -0400\n\n    SOLR-10426: Add shuffle Streaming Expression\n\ncommit 9bf20444feb13c81047726c5f18cdb0145fd5beb\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:24:59 2017 -0400\n\n    SOLR-10351: Update CHANGES.txt\n\ncommit ec687156c6ebe1c58654ff0f29061bf02adad79d\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri May 5 13:14:15 2017 -0400\n\n    SOLR-10303: Update CHANGES.txt\n\ncommit 71f39e747b996bb734cbe4984ce651de59768d8d\nAuthor: yonik <yonik@apache.org>\nDate:   Thu May 4 23:50:50 2017 -0400\n\n    tests: test reset for other bucket aggregations\n\ncommit 1ad2f3932b81ddacce428dc4f9edd17e57a19218\nAuthor: Noble Paul <noble@apache.org>\nDate:   Fri May 5 10:47:57 2017 +0930\n\n    SOLR-9530: An Update Processor to convert normal update operation to an atomic operations such as add, set,inc, remove ,set, removeregex\n\ncommit d99c9e64270f3e8510a4e6fd86d25482b5d4b3c3\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Fri May 5 02:17:44 2017 +0300\n\n    SOLR-9867: @Ignore TestSolrCLIRunExample.testTechproductsExample()\n\ncommit b2495028201a7cae9c4d0c1edf903ddeda5a2e2b\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Fri May 5 00:53:50 2017 +0200\n\n    SOLR-7041: Cut over tests from <defaultSearchField> in schema to df on requests\n\ncommit f945c8608fe3d338d610fd573c0b1b6ad82d7610\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Thu May 4 15:16:05 2017 -0400\n\n    LUCENE-7811: add concurrent SortedSet facets implementation\n\ncommit 60b27234bcf369b2c3e92137353b021119927a3c\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Thu May 4 08:10:30 2017 -0700\n\n    SOLR-10607: Improve RTimerTree documentation\n\ncommit 14e3451ebae14a50a419de37cbb42111ef43e798\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Thu May 4 17:18:24 2017 +0300\n\n    SOLR-9867: fixing JvmMetricsTest broken earlier, bring back testTechproductsExample()\n    and single SDF.cores assignment.\n\ncommit 76fc383911c83f5166ee5f2ae2dcace63efd2c10\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Thu May 4 16:19:14 2017 +0300\n\n    SOLR-9867: rollback SDF.createCoreContainer(). disable testTechproductsExample\n\ncommit e6f7dd4ed90b089b963caa90437c7a431e4b170d\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Thu May 4 15:45:14 2017 +0300\n\n    SOLR-9867: make sure cores are assigned in the end of SolrDispatchFilter.createCoreContainer() only\n\ncommit 487a804dcdf8b78f7f5a75eab8c94a0057c99c75\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sat Apr 29 00:25:28 2017 +0300\n\n    SOLR-9867: fixing TestSolrCLIRunExample.testTechproductsExample\n\n    - SolrDispatchFilter.doFilter rejects invocation until init() is completed.\n    - introducing isLoaded=false, isLoading=true core status\n    - blocking shutdown until core loading stops\n    - looping run example tool while core is loading 1 min max.\n\ncommit faa140d2ae46a04097b78fef8ab9cfaab77792ad\nAuthor: Noble Paul <noble@apache.org>\nDate:   Thu May 4 15:13:01 2017 +0930\n\n    added extra check if it is a liveNode\n\ncommit d0fdfb1e6036b49a4c1de68e3f806a59f4d74154\nAuthor: yonik <yonik@apache.org>\nDate:   Wed May 3 23:04:33 2017 -0400\n\n    SOLR-10596: fix unique/hll docvalue iterator reuse\n\ncommit 018801ad393e4c09ea9cfcd73873a9622f4ec702\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed May 3 15:50:34 2017 -0400\n\n    LUCENE-7814: DateRangePrefixTree bug in years >= 292M\n\ncommit 3231c205722e0a7a49aa24c38100153d30dfdca4\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Wed May 3 10:30:02 2017 -0700\n\n    SOLR-10583: JSON Faceting now supports a query time 'join' domain change option\n\ncommit 6a6063c6fbf4785043da0900321fbbce6f569787\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed May 3 10:25:30 2017 -0400\n\n    SOLR-10601: StreamExpressionParser should handle white space around = in named parameters\n\ncommit 2b4835f24ff12f1b1b4bdcd9b5cab36fbcf75f3f\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed May 3 10:07:12 2017 -0400\n\n    * SOLR-10549: (typo fix in CHANGES.txt)\n\ncommit f0b15e198146cc97df23420741564e10ce5924c5\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed May 3 09:30:34 2017 -0400\n\n    * SOLR-10549: The new 'large' attribute had been forgotten in /schema/fields?showDefaults=true (David Smiley)\n\ncommit b3dc62dc4c1b2d849d9f29f73ccdb173f31d9ee0\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sun Apr 30 23:37:51 2017 +0300\n\n    SOLR-10588: Prevent redundant double core reload on config update.\n\ncommit fd874be6497d97b18311b823f1407174736dcd22\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue May 2 15:44:15 2017 -0400\n\n    SOLR-10536: stats Streaming Expression should work in non-SolrCloud mode\n\ncommit f94865ed36f2b1062615c28bca47ca0be8d65ef0\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Tue May 2 19:41:06 2017 -0400\n\n    SOLR-1485: improve TokenStream API usage\n\ncommit 858a9bb70b8e0a27af11accb65528883e9752978\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Tue May 2 13:58:47 2017 -0700\n\n    SOLR-10519: SolrCLI.atPath cannot handle children that begin with a slash.\n\ncommit e9431219e402b9726ee7b7cc14a2e828554bdf9b\nAuthor: Mark Miller <markrmiller@apache.org>\nDate:   Tue May 2 15:31:57 2017 -0300\n\n    SOLR-10316: Unloading a core can remove a ZK SolrCore registration entry for the wrong SolrCore.\n\ncommit 0418ea5b7a04e103d06abfeffd79bee4cf49ad24\nAuthor: Mark Miller <markrmiller@apache.org>\nDate:   Tue May 2 13:38:44 2017 -0300\n\n    SOLR-10430: Add ls command to ZkCLI for listing only sub-directories.\n\ncommit 064172798acd2cc54bb9856a42118aade321786c\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Tue May 2 10:13:24 2017 -0400\n\n    SOLR-1485: remove unused import\n\ncommit c25560d6f36fd403aecf7614c90a0cd418f489bd\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Tue May 2 07:50:12 2017 -0400\n\n    SOLR-1485: fix tests, removing unnecessary tie to Similarity in PayloadDecoder\n\ncommit dd5da77c1ca89496daaafece9cb139932b957863\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Mon May 1 21:35:29 2017 -0400\n\n    SOLR-1485: Add payload support\n\ncommit 09fff4da5916f30a624d784bce55c0266716a0e3\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 1 12:32:37 2017 -0400\n\n    SOLR-10559: Fix TupStream to respect field order\n\ncommit 235f303f9c33ef089dd2d08842012844afa995c2\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon May 1 12:06:00 2017 -0400\n\n    SOLR-10566: Fix error handling\n\ncommit 1d20b518bf4a68405e909db66d49df7cfd9a40a5\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Mon May 1 10:26:41 2017 -0400\n\n    SOLR-9386: Move default clientPort specification to before calling QuorumPeerConfig.parseProperties(), which requires that clientPort be specified.\n\ncommit f890fbf106603310ca6c13c26d73906384ba2015\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sun Apr 30 22:14:01 2017 -0400\n\n    SOLR-10559: Remove debuggin\n\ncommit fdcde26d9d3a67a63a386466e68ec4ede6eb0eb7\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Fri Apr 28 22:12:17 2017 +0200\n\n    SOLR-7041: Remove a lot of defaultOperator and defaultSearchField from test configs (still more work to do)\n\ncommit 97d80a1abfdf2014b1f6cebfab5d84181d01701d\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sat Apr 29 13:35:24 2017 +0300\n\n    LUCENE-7798: Add .equals and .hashCode to ToParentBlockJoinSortField\n\ncommit 177880ea0d6309c50ff7ab241549510ae12569d0\nAuthor: Dennis Gove <dpgove@gmail.com>\nDate:   Fri Apr 28 21:45:56 2017 -0400\n\n    SOLR-10559: Updates TupStream and enhances evaluators to work over values in the SteamContext\n\ncommit 730dc2f01ce3d0ca45ee29c433923c6ae5dc456f\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri Apr 28 15:01:43 2017 -0400\n\n    SOLR-10582: Add Correlation Evaluator\n\ncommit baa6cdaded4fd528bdd3801d64f28649416d1519\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Fri Apr 28 15:36:50 2017 -0400\n\n    SOLR-9596: Add Solr support for SimpleTextCodec, via <codecFactory class=solr.SimpleTextCodecFactory/> in solrconfig.xml (per-field specification in the schema is not possible).\n\ncommit eeeb947db5399abebcf361f20278fe17e5a61335\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Fri Apr 28 11:24:53 2017 -0400\n\n    SOLR-9386: Upgrade Zookeeper to 3.4.10\n\ncommit 21bab68f2fdb341723801fef7317cb8e43cbaba8\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Fri Apr 28 10:14:38 2017 -0400\n\n    LUCENE-7794: buildAndPushRelease.py should run validate and documentation-lint\n\ncommit 0c9cf102e2d330f405e18072cebc11b6fba99404\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Fri Apr 28 09:58:02 2017 -0400\n\n    LUCENE-7793: smokeTestRelease.py should run documentation-lint\n\ncommit 2b687866a96878f38ab46de22cceb9bd92d7a0dc\nAuthor: Dawid Weiss <dweiss@apache.org>\nDate:   Fri Apr 28 10:58:55 2017 +0200\n\n    LUCENE-7796: Make IOUtils.reThrow idiom declare Error return type so\n    callers may use it in a way that compiler knows subsequent code is\n    unreachable. reThrow is now deprecated in favor of IOUtils.rethrowAlways.\n\ncommit 0b699d6a3338031d7812f1c0d07db86352ff1193\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sat Apr 22 14:39:33 2017 +0300\n\n    SOLR-10521: adding sort=childfield(field,$q) asc for {!parent} query.\n\ncommit 97c6ed53d19cda6a6c46209d858387949a34b088\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 27 17:03:01 2017 -0400\n\n    SOLR-10559: Fix precommit\n\ncommit d8e991cecdd0d829ae97ee92f628ffa2aebda87d\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 27 16:40:24 2017 -0400\n\n    SOLR-10559: Fixed compilation error\n\ncommit ff9fd224db521a1009be7ff5ac734c267b110088\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 27 16:30:46 2017 -0400\n\n    SOLR-10559: Cleaner syntax\n\ncommit 59c76a2e69701125a200f84a673129b24397d30b\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Thu Apr 27 15:34:47 2017 -0400\n\n    Remove unused imports\n\ncommit 44dff45ad5ac0f10d0838e70173dad73457e48eb\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Thu Apr 27 15:16:43 2017 -0400\n\n    Add CHANGES entry for LUCENE-7481\n\ncommit 2ff15d575046f6b5cc0291e33a0270e2940d67d1\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Thu Apr 27 15:08:51 2017 -0400\n\n    LUCENE-7481: Fix PayloadScoreQuery rewrite\n\ncommit 8f37fb29e94211869c3046ae048dc462dd187f9d\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Thu Apr 27 08:55:05 2017 -0400\n\n    LUCENE-7481: Fix SpanPayloadCheckQuery rewrite\n\ncommit 53c1c5fa205702425c7cfc45f480bc1ee1d2c92f\nAuthor: Jim Ferenczi <jimczi@apache.org>\nDate:   Thu Apr 27 13:53:52 2017 +0200\n\n    Add 6.5.1 back compat test indexes\n\ncommit 733829de9d293af95ff1ef230f81a8ed537cb29a\nAuthor: Jim Ferenczi <jimczi@apache.org>\nDate:   Thu Apr 27 13:06:39 2017 +0200\n\n    update doap files with Lucene / Solr 6.5.1 release\n\ncommit afc0a997d930c8a414850fa73a8616eb9dcc3d24\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Thu Apr 27 06:59:24 2017 -0400\n\n    fix wrong version in logging message\n\ncommit 6082e9e1bd9eadc814132e39b096ea835830db9b\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Thu Apr 27 13:01:07 2017 +0300\n\n    SOLR-10500: fix many parents with nested children per /update/json/docs request\n\ncommit 10c1379bc3cd2f0fb75b61e72e8d3bc3a6283ab0\nAuthor: Noble Paul <noble@apache.org>\nDate:   Thu Apr 27 12:38:34 2017 +0930\n\n    SOLR-10507: Core Admin status command to emit collection details of each core\n\ncommit a8d2792b21f182aaaf9bc0da3aea571507b0f8ae\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 26 22:34:20 2017 -0400\n\n    SEARCH-313: Handled unescaped plus sign in gap\n\ncommit df3e927ade3f6befdfde511abc4ef2c067df7268\nAuthor: Erik Hatcher <ehatcher@apache.org>\nDate:   Wed Apr 26 20:05:32 2017 -0400\n\n    LUCENE-7808: Fix PayloadScoreQuery and SpanPayloadCheckQuery .equals and .hashCode methods.\n\ncommit 2e3ee9a40de51f4eb91bb80c870d95fb114d8e07\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed Apr 26 14:04:35 2017 -0400\n\n    SOLR-10526: fix facet.heatmap facet exclusion when distributed/sharded\n\ncommit deb017464c5d63688848c722edd54df239eeedcd\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Wed Apr 26 19:50:31 2017 +0200\n\n    SOLR-10569: \"updateHandler\" stats is null when queried via MBeans handler.\n\ncommit 3ead4b38d9f6ec28d2c44fd9e255432cca646ab8\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 26 17:01:29 2017 +0100\n\n    SOLR-10046: move from 6.6.0 to 7.0.0 CHANGES.txt (backport yet to be completed)\n\ncommit 28e3134910655c0a41bd241652f1f514c4fe9c20\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Wed Apr 26 17:47:34 2017 +0200\n\n    SOLR-10565: Make root names more unique.\n\ncommit 92901c859bf2029c49e5eb10dad89280860a928c\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 26 11:17:22 2017 -0400\n\n    SOLR-10566: Fix precommit\n\ncommit 8a3cbb5c75df08858b04f3191d8b3cfbc748f28d\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 26 10:57:52 2017 -0400\n\n    SOLR-10566: Add timeseries Streaming Expression\n\ncommit def07596935e3192d82edc6ce70b76ef8997c021\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Wed Apr 26 09:36:14 2017 -0400\n\n    LUCENE-7792: add try/finally to make sure semaphore is released on exceptions\n\ncommit 004f086c1a7eff00362ebea350a27e648c798c96\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed Apr 26 08:38:52 2017 -0400\n\n    SOLR-10537: Added SolrParams.toLocalParamsString() and moved QP.encodeLocalParamVal to ClientUtils\n\ncommit 6febaa31715fe57b2794aae0325b29a64aa6223e\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Wed Apr 26 06:38:28 2017 -0400\n\n    LUCENE-7792: add optional concurrency to OfflineSorter\n\ncommit 0c4f83af1d5bcedafc6f2bf44ee5225ef9e7cd48\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Wed Apr 26 12:31:39 2017 +0200\n\n    SOLR-10489: Fix an occasional NPE.\n\ncommit 0adfdba01e1790844375db4f319ca01a4060788c\nAuthor: yonik <yonik@apache.org>\nDate:   Tue Apr 25 22:56:44 2017 -0400\n\n    SOLR-10480: fix offset param handling in JSON Facet API\n\ncommit 4e20b288a8d70043e1ae4e209c0e5e43574ff928\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Tue Apr 25 20:34:00 2017 -0400\n\n    LUCENE-7801: SortedSetDocValuesReaderState now implements Accountable\n\ncommit 78ae8b98764e08c901031ab8674954678aa187cc\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Tue Apr 25 17:07:42 2017 -0400\n\n    SOLR-10310: Fix CopyFieldTest failure\n\ncommit 8c58414bf73a0949859d7f6eaea57519f9569e17\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Tue Apr 25 12:02:25 2017 -0400\n\n    SOLR-10310: By default, stop splitting on whitespace prior to analysis in edismax and standard/\"lucene\" query parsers\n\ncommit aff53529218c86f1e71dc1988fa277f72ab6eba8\nAuthor: yonik <yonik@apache.org>\nDate:   Tue Apr 25 11:00:30 2017 -0400\n\n    SOLR-7452: JSON Facet API - refining for numBuckets\n\ncommit d19848665bb09fe0adc757ec0eb57b031db3d5fe\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Tue Apr 25 12:27:18 2017 +0300\n\n    SOLR-10520: fix child.facet.field counts\n\ncommit 61c121cffdf4e1cd3005a6cea69a22761b4356d4\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon Apr 24 17:27:37 2017 -0400\n\n    SOLR-10559: Add let and get Streaming Expressions\n\ncommit 2c20d1d5dfb69af3faee10c5cfc52ecddde5f527\nAuthor: yonik <yonik@apache.org>\nDate:   Mon Apr 24 18:17:17 2017 -0400\n\n    SOLR-10548: SOLR-10552: numBuckets should use hll and ignore mincount>1 filtering\n\ncommit 5d57d866e31b8e3575b254dcbef0792b524e5c97\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Mon Apr 24 22:34:46 2017 +0200\n\n    SOLR-10557: Make \"compact\" format default for /admin/metrics.\n\ncommit 26e717b22d74ea635a4cd510d8b0ccfd1a69e399\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Mon Apr 24 12:17:46 2017 -0700\n\n    SOLR-10493: Investigate SolrCloudExampleTest failures.\n\n    (cherry picked from commit 0247acd)\n\ncommit 24bea6c588320decad5bcfc4c0e51843eae12b12\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Apr 25 00:26:21 2017 +0530\n\n    SOLR-10047: Move test into its own test class and force use of NoMergePolicy to fix test failures\n\n    This closes #195\n\ncommit a11a49bbd644ffe157b75b295dbc981dbc8b0316\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Mon Apr 24 16:12:02 2017 +0200\n\n    SOLR-10489 Tentative fix for a test failure (Mikhail Khludnev via ab)\n\ncommit b7e56dbbf41e914b78fb93afcbd32fe8dfc7bf1c\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Sat Apr 22 18:45:27 2017 -0400\n\n    don't allow ExtrasFS for this test case\n\ncommit 044e0fb915124d05faeb736835af235015e4893f\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Sun Apr 23 00:28:20 2017 +0300\n\n    SOLR-9217: delay JoinUtil call to createWeight for score join\n\ncommit 96f8100ad10d51e233a268a9afa07c376e1db047\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sat Apr 22 17:26:19 2017 -0400\n\n    SOLR-10551: Improve tests\n\ncommit 75a250d12d94caf2ff3077ea34bf6f0706642b33\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Sat Apr 22 16:38:38 2017 -0400\n\n    SOLR-10551: Add list and cell Streaming Expressions\n\ncommit 744e5deaa4dbb7a97ab0aecf67c3f73e05032aba\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Sat Apr 22 08:49:34 2017 -0400\n\n    LUCENE-7797: the static FSDirectory.listAll was always returning an empty array\n\ncommit 4f5ea24213321f63ccdaaa6d2699c6db9152e03a\nAuthor: Jim Ferenczi <jimczi@apache.org>\nDate:   Fri Apr 21 12:01:09 2017 +0200\n\n    LUCENE-7791: add tests for index sorting with sparse text fields and norms\n\ncommit 3f59e233ee3f38fd4b543324fbe64a985833332a\nAuthor: Jim Ferenczi <jimczi@apache.org>\nDate:   Fri Apr 21 04:41:24 2017 +0200\n\n    LUCENE-7791: add tests with index sorting and sparse docvalues fields\n\ncommit f933c812e4cadf92b1bd356780c1d8763e2fd1ed\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Thu Apr 20 17:46:28 2017 -0400\n\n    SOLR-10499: facet.heatmap DocSet to Bits optimizations\n\ncommit 7270943e56bfff7d4be4bd5e2649b4078594a698\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Thu Apr 20 15:09:14 2017 +0200\n\n    SOLR-10514 Upgrade Metrics library to 3.2.2.\n\ncommit a2b316e60fd3d10e8122ab9ac31b5127ec291a5e\nAuthor: Shai Erera <shaie@apache.org>\nDate:   Thu Apr 20 15:32:27 2017 +0300\n\n    Shorten docFreq and totalTermFreq to df and ttf in TermsComponent\n\ncommit 20674464e04a261eda815e4a1a01e0111f882d60\nAuthor: Shai Erera <shaie@apache.org>\nDate:   Tue Apr 18 06:33:18 2017 +0300\n\n    SOLR-10505: Add multi-field support to TermsComponent for terms stats\n\ncommit 4d7efe1f0c735788f75cb5b2d968ba8c77d6f76d\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Wed Apr 19 20:10:11 2017 -0400\n\n    SOLR-10527: move CHANGES entry to 6.5.1 section\n\ncommit b07f6f4c4b0df53638eb1e672505fd57ba315335\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Wed Apr 19 19:02:32 2017 -0400\n\n    SOLR-10527: edismax with sow=false fails to create dismax-per-term queries when any field is boosted\n\ncommit 7a9728df01cd7b5e7c42578290f427e7c44a64f9\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 19 12:05:00 2017 +0100\n\n    (part 1 of several) SOLR-10415: use parameterized debug logging in SearchHandler and RealTimeGetComponent (Michael Braun via Christine Poerschke)\n\ncommit fd5f957bb0bc3c27cefe9ca26423ae6a440b0a74\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 19 11:50:24 2017 +0100\n\n    SOLR-10394: a few more essentially non-public sortWithinGroup to withinGroupSort renames\n\ncommit 86fe1543b32db0c1316b49ef0b19cd36be03324f\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 19 11:45:59 2017 +0100\n\n    SOLR-5127: Multiple highlight fields and wildcards are now supported e.g. hl.fl=title,text_*\n    (Sven-S. Porst, Daniel Debray, Simon Endele, Christine Poerschke)\n\ncommit 972dc3164581950f1b33e74fa9841f86413c2cd3\nAuthor: Dawid Weiss <dweiss@apache.org>\nDate:   Wed Apr 19 12:21:18 2017 +0200\n\n    LUCENE-7785: Move dictionary for Ukrainian analyzer to external dependency. (Andriy Rysin via Dawid Weiss)\n\ncommit 432aa350b8e7d7e436aea3556c7c27e99f09b4cb\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue Apr 18 20:56:21 2017 -0400\n\n    SOLR-10516: Add eval() Streaming Expression\n\ncommit 036ce79066dbe1ff7b435bdf006ad069d6b73f8f\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Tue Apr 18 17:02:07 2017 -0400\n\n    SOLR-10439: 'large' was forgotten in /schema/fields?showDefaults=true\n\ncommit c0f50ad282be823c192c9650b8d5a0442eedb6f0\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Tue Apr 18 11:58:35 2017 -0700\n\n    SOLR-10472: Fixed uninversion (aka: FieldCache) bugs with the numeric PointField classes, and CurrencyField\n\ncommit 79ab781507d8d7728bbb89faae495d5174424676\nAuthor: Scott Blum <dragonsinth@gmail.com>\nDate:   Mon Apr 17 18:27:12 2017 -0400\n\n    SOLR-10420: fix watcher leak in DistributedQueue\n\ncommit 2e9bea5c062da5e2efedd5158dcf84fab9978c50\nAuthor: Scott Blum <dragonsinth@gmail.com>\nDate:   Tue Apr 18 14:36:01 2017 -0400\n\n    changes\n\ncommit f1ef3d1dbd95591460c7e00fcc31193ae70a1083\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Tue Apr 18 14:14:38 2017 -0400\n\n    LUCENE-7769: UnifiedHighlighter wasn't seeing inside BoostQuery or SpanBoostQuery\n\ncommit 8a7401550a5f624286704736f9fdf957bdcce88e\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Tue Apr 18 12:32:12 2017 -0400\n\n    LUCENE-7787: HeatmapFacetCounter Bits.MatchNoBits optimization\n\ncommit 43d02330c96128320cfa905ffc85f81d2bd8cb2c\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue Apr 18 11:21:15 2017 -0400\n\n    SOLR-10504: Add echo Streaming Expression\n\ncommit d44f6698ed426f20833fb3f558afd6248c9c0456\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 18 15:53:13 2017 +0100\n\n    Remove unused imports.\n\ncommit 44db665e9989550fe41261246d075889985fec91\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Tue Apr 18 12:46:39 2017 +0200\n\n    SOLR-10418: Metrics API should return JVM system properties.\n\ncommit be6d90f5965b8408130dc14cace470a19f1a036b\nAuthor: yonik <yonik@apache.org>\nDate:   Mon Apr 17 22:30:29 2017 -0400\n\n    SOLR-10082: JSON Facet API, add stddev and variance functions\n\ncommit 3e9d4c64ed0145aeeb3c3f5ec32c056e71541f26\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Tue Apr 18 03:29:45 2017 +0530\n\n    SOLR-10447, SOLR-8589: Adding Yago Riveiro to changelog\n\ncommit edafee5838ac9ae469429a189aae2955ac955977\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Tue Apr 18 03:12:41 2017 +0530\n\n    SOLR-10447, SOLR-4968, SOLR-8589: Adding contributors to CHANGES.txt\n\ncommit 4c25637aa8dc7c48399c583fe9f3aa17d0674971\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Tue Apr 18 03:09:46 2017 +0530\n\n    SOLR-10446: Making HttpClusterStateProvider work with server that doesn't have LISTALIASES\n\ncommit 491d3231ac6221e6d7520013dcf28debea1be6f6\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon Apr 17 11:08:53 2017 -0400\n\n    SOLR-10486: Fix precommit\n\ncommit a7a3cb69292d62824f54c2fc3dcff5a8c0b8c153\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon Apr 17 10:10:05 2017 -0400\n\n    SOLR-10486: Add Length Conversion Evaluators\n\ncommit b903026ed4d72a423f39f3b28a3a55d2846b22c7\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 13 11:57:45 2017 -0400\n\n    SOLR-10485: Remove incorrect code comment\n\ncommit 249baee1850b0a2608ec029f8865fba54ecaff44\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon Apr 17 13:59:26 2017 +0530\n\n    SOLR-10047: Mismatched Docvalues segments cause exception in Sorting/Faceting. Solr now uninverts per segment to avoid such exceptions\n\n    Squashed commit of the following:\n\n    commit c38f4cabc2828ee83b53b931dd829e29a3e1701c\n    Author: Keith Laban <kelaban17@gmail.com>\n    Date:   Tue Apr 11 17:17:05 2017 -0400\n\n        reverted tests to using old wrap interface\n\n    commit 806f33e092491cc6a2ee292d2934c76171e40dc7\n    Author: Keith Laban <kelaban17@gmail.com>\n    Date:   Tue Apr 11 17:13:34 2017 -0400\n\n        updated UninvertingReader.wrap / tests\n\n    commit b10bcab338b362b909491fea1cf13de66f5f17c0\n    Author: Keith Laban <klaban1@bloomberg.net>\n    Date:   Wed Apr 5 14:57:28 2017 -0400\n\n        SOLR-10047 - Updated javadoc/renamed class/added getReaderCacheHelper\n\n    commit 90ecf5a4ae4feaf3efc42a1ed8643ad21e1c73ce\n    Author: Keith Laban <klaban1@bloomberg.net>\n    Date:   Wed Jan 18 16:39:51 2017 -0500\n\n        SOLR-10047 - SolrIndexSearcher, UninvertingReader, uninvert docvalues per segment\n\ncommit 3dbc429295ae4f565c2a998c4f3122e2ffa6502e\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Mon Apr 17 10:11:18 2017 +0530\n\n    SOLR-10447, SOLR-10447: LISTALIASES Collections API command; CloudSolrClient can be initialized using Solr URL\n\n       SOLR-10447: Collections API now supports a LISTALIASES command to return a list of all collection aliases.\n\n       SOLR-10446: CloudSolrClient can now be initialized using the base URL of a Solr instance instead of\n        ZooKeeper hosts. This is possible through the use of newly introduced HttpClusterStateProvider.\n        To fetch a list of collection aliases, this depends on LISTALIASES command, and hence this way of\n        initializing CloudSolrClient would not work with older versions of Solr that doesn't support LISTALIASES.\n\ncommit 6f691363fe914157a9c39e4de23e4d0eb49e4c34\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Fri Apr 14 08:15:32 2017 -0400\n\n    LUCENE-7782: OfflineSorter now passes the number of items it will write to getWriter\n\ncommit 3a84e9a55a4547009ca8e115759d5886dcc2f207\nAuthor: markrmiller <markrmiller@apache.org>\nDate:   Fri Apr 14 01:33:19 2017 -0400\n\n    SOLR-9936: Allow configuration for recoveryExecutor thread pool size.\n\ncommit 07c09b6f84defe5be00d135005ac56652ef72d75\nAuthor: markrmiller <markrmiller@apache.org>\nDate:   Fri Apr 14 01:17:03 2017 -0400\n\n    SOLR-10151: Use monotonically incrementing counter for doc ids in TestRecovery.\n\ncommit 9ca384377c41e16721e1c84bb32fe20865cd0eec\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Thu Apr 13 17:31:22 2017 +0530\n\n    SOLR-6736: Fix authorization permissions\n\ncommit 664a4236e4133359b6857d45149f019b9354bc03\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Thu Apr 13 09:43:01 2017 +0200\n\n    LUCENE-7783: Fix NPE when getting points on a non-existing field.\n\ncommit 3b41debf70f7f71df52b36a6de89f00545f454e6\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Thu Apr 13 08:21:39 2017 +0200\n\n    LUCENE-7780: Remove TermValComparator.isNull.\n\ncommit a216928eafc25e8af24c6a1384d5d6dfa22d9ff9\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Thu Apr 13 08:20:56 2017 +0200\n\n    LUCENE-7781: Call ensureOpen when registering closed listeners.\n\ncommit 58de889d2bc9de254c881121fa2bc6054261e600\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Wed Apr 12 17:02:40 2017 -0700\n\n    SOLR-10007: Clean up references to CoreContainer and CoreDescriptors\n\ncommit 27936c20edd5c828fe9c8ff69ab1a80cf011f8e0\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 12 17:26:30 2017 -0400\n\n    SOLR-10485: Fix precommit\n\ncommit df9d1958d413499e657147459549a3ca8c821d71\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 12 17:09:36 2017 -0400\n\n    SOLR-10485: Add CalculateStream to allow Solr to behave like a scientific calculator\n\ncommit 7da48bd9dfc0281e1fe2c7bc6feb316fb91d1aca\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Wed Apr 12 17:17:30 2017 -0400\n\n    LUCENE-7779: don't call BytesSequencesReader.next again after it already returned null\n\ncommit 88e85dc0a5e5bf5ec4bff76747040bc5ca4bb111\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 12 14:46:31 2017 -0400\n\n    SOLR-10303: Fix precommit\n\ncommit 7799fcf8c48bf103730d6741041b3a4edf6d04ab\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 12 13:18:19 2017 -0400\n\n    SOLR-10303: Add the tuple context to avoid creating multiple LocalDateTime instances for the same Tuple\n\ncommit 8c67cbc345a01f198baaabec016fc33052d209cd\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Wed Apr 12 18:00:35 2017 +0200\n\n    SOLR-10303:  Removing the unused class DatePartEvaluator from the test\n\ncommit 0f2259de6770163351f4e3f0ef4d2f85d34565bd\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Thu Apr 6 17:19:31 2017 +0200\n\n    SOLR-10303:  Error message formatting for TemporalEvaluator\n\ncommit 3fc1c254efe6e87ce74a2afe49a7a581fb7f961a\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Thu Apr 6 17:19:02 2017 +0200\n\n    SOLR-10303:  Removing the unused class, replaced by TemporalEvaluator\n\ncommit d138df5745ed2b1f05f132a480d2c63a4e9a0209\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Thu Apr 6 11:58:26 2017 +0200\n\n    SOLR-10303:  Refactored to multiple TemporalEvaluator classes based on feedback\n\ncommit 3c65492947d844070efbe00d7029bd1a9886010f\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Mon Mar 20 17:08:15 2017 +0100\n\n    SOLR-10303:  Switched to pascal casing\n\ncommit a325c359b0188ea8dd3ceb87bccad6a50e56c507\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Mon Mar 20 17:02:41 2017 +0100\n\n    SOLR-10303:  Supporting more datatypes via a TemporalAccessor\n\ncommit 9f3f27d4eb403431878fb80fe08165341a6fed21\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Sat Mar 18 10:42:19 2017 +0100\n\n    SOLR-10303:  Supporting epoch for LocalDateTime\n\ncommit 7d97c1692d32d31b94116ec4458fe571e873149f\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Fri Mar 17 18:11:00 2017 +0100\n\n    SOLR-10303:  Switching from the fieldName param to subEvaluators\n\ncommit 748bff204b7037ad85b6d2c061a5aba4920304a1\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Fri Mar 17 15:30:12 2017 +0100\n\n    SOLR-10303: Renamed to DatePartEvaluator and adding support for Instant, Date, LocalDateTime\n\ncommit e11a40426a36152ccf02f32d0d7ccc6c178b6053\nAuthor: Gethin James <gethin.james@alfresco.com>\nDate:   Fri Mar 17 14:07:50 2017 +0100\n\n    SOLR-10303: Initial support for common date/time Stream Evaluators\n\ncommit 0f3a35220a1097e0f314b0a800ebbadae28e3cc8\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 11 11:16:23 2017 +0100\n\n    LUCENE-7746: precommit to ignore less and (potentially) error more\n\ncommit e1e9a71f976aaaa5e43d2615cc6479e5a5259321\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 11 11:14:34 2017 +0100\n\n    SOLR-10473: Correct LBHttpSolrClient's confusing SolrServerException message when timeAllowed is exceeded.\n\ncommit 4ed424dc8e6ffdc1deb9f5b479dc74adfe5eb7f5\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Wed Apr 12 10:40:58 2017 +0200\n\n    SOLR-9959 Increase the timeout to allow searcher to register metrics.\n\ncommit 6df755782089c82e94e2c763aa1d6f5d39a17269\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Wed Apr 12 09:55:03 2017 +0200\n\n    LUCENE-7776 - adjusted failing tests in solr due to switching to bm25 in knn\n\ncommit 4485f66d4a91e3387cb88b4229eace1055dfa889\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Tue Apr 11 15:37:42 2017 -0400\n\n    LUCENE-7760: improve setMaxTokenLength javadocs for StandardAnalyzer/Tokenizer and UAX29URLEmailAnalyzer/Tokenizer\n\ncommit 6e1418c9f2f6d60b3f6462ecc7da0ed2d1d3228b\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue Apr 11 15:36:03 2017 -0400\n\n    SOLR-10274: fix precommit\n\ncommit 579b5f9199899225f40a82b95b4a213a2cfab7af\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue Apr 11 15:17:03 2017 -0400\n\n    SOLR-10274: The search Streaming Expression should work in non-SolrCloud mode\n\ncommit dea126033ef363a9736b1fbb568838a9741432f8\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 11 20:01:05 2017 +0100\n\n    Removed two unused imports.\n\ncommit ed9f434f37ee64ef0e2bfa5a479feac2f970cb45\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 11 19:36:44 2017 +0100\n\n    LUCENE-7776: change javadocs default mention from Classic to BM25\n\n    (Also kinda added missing javadoc for new method to fix 'ant precommit'.)\n\ncommit 72b4579b71e0a7958c8602eba0122f898d88a64b\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Tue Apr 11 19:22:23 2017 +0200\n\n    SOLR-9959: SolrInfoMBean-s category and hierarchy cleanup.\n\ncommit c21e8664e3ccffee96addb46bd2426d3db80835c\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Tue Apr 11 11:47:31 2017 -0400\n\n    LUCENE-7777: fix AIOOBE from ByteBlockPool.readBytes when byte block exceeds 32 KB\n\ncommit 6b3dcad5244406be51b03d33d1c1e988a3805120\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Tue Apr 11 17:12:13 2017 +0200\n\n    LUCENE-7776 - visualize diff btwn BytesRef values in ClassificationTestBase\n\ncommit 87d3b8cc5afd40512016407320b1d9356bfb543b\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 11 11:25:39 2017 +0100\n\n    LUCENE-7776: remove unused import\n\ncommit 6586d7ce9022e913271e3cc4d83031c555bb7d85\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Tue Apr 11 10:44:36 2017 +0200\n\n    LUCENE-7776 - use bm25 for knn classifier\n\ncommit 58f7f68d7142dc3a6f9d3bcd0b036f084b6879ad\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Tue Apr 11 10:02:51 2017 +0200\n\n    LUCENE-7767: SortedDocValues.ordValue() now throws an IOException.\n\ncommit 9f300bb85da19635dc627db1c51f3dead10120e1\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Mon Apr 10 19:07:25 2017 -0400\n\n    LUCENE-7775: fix exception handling to throw first exception hit\n\ncommit b0cb9cff99d3d0386193e7c84b50fd61c07c8dc0\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Mon Apr 10 15:26:28 2017 -0400\n\n    SOLR-10474: TestPointFields.testPointFieldReturn() depends on order of unsorted hits\n\ncommit 6535a3cd40eb5e35cbf112d4e131584bb163fbee\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Mon Apr 10 09:48:07 2017 -0700\n\n    SOLR-10437: Delete index after each test in TestUseDocValuesAsStored\n\ncommit 82f13b8c5e8bd7e3d476c0a6bbe8f5d7ebad057c\nAuthor: jdyer1 <jdyer@apache.org>\nDate:   Mon Apr 10 08:39:41 2017 -0500\n\n    SOLR-8807: disable the CollapseQParser Plugin when testing spellcheck collations for hit-counts\n\ncommit e0a2890a6f35e26d045dfc9e37f028efcb6dfbd7\nAuthor: Alan Woodward <romseygeek@apache.org>\nDate:   Tue Mar 28 19:52:53 2017 +0100\n\n    LUCENE-7701: Refactor grouping collectors\n\ncommit adf2819c16af26cb15b59afbdecf666fc8b78f66\nAuthor: Noble Paul <noble@apache.org>\nDate:   Mon Apr 10 06:43:27 2017 +0930\n\n    SOLR-10429: UpdateRequest#getRoutes()should copy the response parser\n\ncommit 76a594a5677429b4e0d51a4e25d796d5a77a6120\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Fri Apr 7 14:11:25 2017 -0700\n\n    SOLR-10443: Improvements to TestPointFields\n\n    * Fixes testInternals, index needs to be cleaned after each field\n    * Validate that SolrQueryParser generates a PointInSetQuery when possible\n\ncommit 94817b40a65bfbfb95dbed1a35ede606c1d30978\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Fri Apr 7 11:36:22 2017 -0700\n\n    SOLR-10437: Improve test coverage of useDocValuesAsStored=false\n\ncommit 5b84bad617c21a2af1242ce3e098c28b58715397\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Fri Apr 7 12:36:19 2017 -0400\n\n    Add version 6.5.1\n\ncommit b60de7380b49906096c6bdc40fbfccc78a3df1fe\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Fri Apr 7 11:11:23 2017 +0100\n\n    SOLR-10264: Fixes multi-term synonym parsing in ManagedSynonymFilterFactory.\n    (J\u00f6rg Rathlev, Steve Rowe, Christine Poerschke)\n\ncommit 315843008bf287c882361aec9847844c8fa9d273\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Fri Apr 7 11:04:41 2017 +0100\n\n    SOLR-10440: LBHttpSolrClient.doRequest is now always wrapped in a Mapped Diagnostic Context (MDC).\n\ncommit 27bea7dc2738281fa1a3beb801f83920f48ce009\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Fri Apr 7 10:37:30 2017 +0100\n\n    SOLR-10441: remove no longer used HttpShardHandlerFactory.USE_RETRIES\n\ncommit c2d73021182bbe5789e1ca5e3d08a16e1282e7f5\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Fri Apr 7 10:58:49 2017 +0200\n\n    LUCENE-5548 - improved testing for SNBC\n\ncommit 6af46f1195d899f542aa603684433b4360329423\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Thu Apr 6 19:13:50 2017 +0200\n\n    LUCENE-6853 - re-enabled test classification measures for bpc\n\ncommit 99c57f533eaf896ac7750f0833939fbd220fbd5b\nAuthor: Tommaso Teofili <tommaso@apache.org>\nDate:   Thu Apr 6 19:05:52 2017 +0200\n\n    LUCENE-6853 - renamed threshold to bias, initialize to avg tf\n\ncommit 9a3c8c43af63de6a3e37f07df6aa2834b80a81e7\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 6 22:06:07 2017 -0400\n\n    SOLR-10341, SOLR-10444: Update CHANGES.txt\n\ncommit ed052b20c923f6b3883068b7cf570881686cdcc2\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 6 21:33:47 2017 -0400\n\n    SOLR-10444: Fix precommit\n\ncommit 47f2548a221482f071ad7facfb5d982d5d20dafe\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Apr 6 21:17:02 2017 -0400\n\n    SOLR-10444: SQL interface does not use client cache\n\ncommit 878fdedba086a660c5483ba08a3cb05f02abafac\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Thu Apr 6 12:07:41 2017 -0700\n\n    SOLR-10425: Fix indexed=\"false\" on numeric PointFields\n\ncommit 5a1d69782f30bf8b8fb4342ef2bfcf862777b8f6\nAuthor: jdyer1 <jdyer@apache.org>\nDate:   Thu Apr 6 12:48:19 2017 -0500\n\n    SOLR-10323: fix to SpellingQueryConverter to properly strip out colons in field-specific queries\n\ncommit 338a5e6920a639ad0901079b9f7c4763174a1177\nAuthor: yonik <yonik@apache.org>\nDate:   Thu Apr 6 09:29:29 2017 -0400\n\n    SOLR-7452: add support for refining missing allBuckets\n\ncommit ec5731a60905cbdcc648fbe30502e0d595b6bf00\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Thu Apr 6 16:02:20 2017 +0700\n\n    SOLR-10239: Update CHANGES.txt\n\ncommit f89f9f4ea44d95c44dd2d4ad6d329053b5afd0c2\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Thu Apr 6 15:57:43 2017 +0700\n\n    SOLR-10239: change empty lambda to null\n\ncommit 4942a94d7198af70091cb510695468f3802d6198\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Thu Apr 6 15:48:38 2017 +0700\n\n    SOLR-10239: MOVEREPLICA API\n\ncommit 03c3282de1049589360e8e33110ae0ce697c9854\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Wed Apr 5 17:57:11 2017 -0400\n\n    SOLR-10426: Add shuffle Streaming Expression\n\ncommit fd3b624e9f3f7c458ffbdec86ebe572ce1f7a7f7\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Wed Apr 5 16:23:26 2017 -0400\n\n    SOLR-10423: Disable graph query production via schema configuration <fieldtype ... enableGraphQueries=\"false\">.  This fixes broken queries for ShingleFilter-containing query-time analyzers when request param sow=false.\n\ncommit d0b5031ffdbd9f2ee2b45db5354d7b931fdce42c\nAuthor: Nicholas Knize <nknize@gmail.com>\nDate:   Wed Apr 5 11:10:15 2017 -0500\n\n    LUCENE-7738: Fix min/max verification bug in InetAddressRange to correctly compare IPv4 and IPv6. Update tests.\n\ncommit 14231a9625f483cbd4ff8bc62aa52d22f6c64d63\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Wed Apr 5 08:56:50 2017 -0400\n\n    SOLR-10404: fetch() streaming expression: escape values in generated query.\n\ncommit 62bf5c334c3cb9fddbb5fe2732bc53ba443b54fc\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 5 11:52:34 2017 +0100\n\n    Remove unused (private static final) loggers in LTRQParserPlugin and LTRFeatureLoggerTransformerFactory.\n\ncommit 039e256b59b18e600cbef5443daf86056b6d0e1f\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Wed Apr 5 11:50:13 2017 +0100\n\n    SOLR-10421: Fix params persistence for solr/contrib/ltr (MinMax|Standard)Normalizer classes.\n    (Jianxiong Dong, Christine Poerschke)\n\ncommit ae603ddf5bc6e09e633e75059912f16f583aa726\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Wed Apr 5 16:01:44 2017 +0530\n\n    SOLR-10277: On 'downnode', lots of wasteful mutations are done to ZK\n\ncommit 9f7ef3f878ee70c53531a26866da5447b4c61b97\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Tue Apr 4 13:11:02 2017 -0700\n\n    SOLR-10347: Remove index level boost support from 'documents' section of the admin UI\n\ncommit 8cd9deff5b0619807254749d7300048c741c0807\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Tue Apr 4 12:52:09 2017 +0100\n\n    SOLR-10394: Rename getSortWithinGroup to getWithinGroupSort in search.grouping.Command class.\n    (Judith Silverman, Christine Poerschke)\n\ncommit 4288bc73e456925c0e4ab04fe99a061b98a10482\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Tue Apr 4 14:20:31 2017 +0530\n\n    SOLR-10416: The JSON output of /admin/metrics is fixed to write the container as a map (SimpleOrderedMap) instead of an array (NamedList)\n\ncommit e8d9987d536b431e29d321b3cfb7222911d3574b\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Tue Apr 4 11:01:19 2017 +0300\n\n    SOLR-9745: check exit code only if process has finished\n\ncommit c10dd97496eac37aa07cac28759f14c62c9f3438\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Thu Mar 30 09:12:45 2017 +0200\n\n    LUCENE-7756: Only record the major Lucene version that created the index, and record the minimum Lucene version that contributed to segments.\n\ncommit 0c8d63373ac94a9deec5e1ec1991ab135dcc5707\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Tue Apr 4 08:42:31 2017 +0300\n\n    SOLR-9745: bring back timeout value to fix tests\n\ncommit 4d6eb98561729b778b4feac9f8362d42f196beb1\nAuthor: Mark Miller <markrmiller@apache.org>\nDate:   Mon Apr 3 22:00:08 2017 -0300\n\n    SOLR-10338: Revert configure SecureRandom non blocking for tests. (reverted from commit 0445f8200e0630e1bb8b7117f200529ed1259747)\n\ncommit 5430570655c8377d45479dffd50cfa0cad3af47a\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Mon Apr 3 20:39:37 2017 -0400\n\n    SOLR-10351: Add try-with-resources clause around TokenStream\n\ncommit 4111f12e8bfcd6fa2076cb781bb85abdab144534\nAuthor: Mikhail Khludnev <mkhl@apache.org>\nDate:   Mon Apr 3 23:45:54 2017 +0300\n\n    SOLR-9745: fix solr.cmd to print errors from invoked script\n\ncommit 5ffb14bf57992ede5370bc6ca168dfc75d062c41\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Mon Apr 3 13:27:12 2017 -0700\n\n    SOLR-8906: Make transient core cache pluggable\n\ncommit e1c6dd4b2fba4b709a39ec5d2a27650ce5f1b954\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Mon Apr 3 13:49:05 2017 +0200\n\n    LUCENE-7749: Made LRUQueryCache delegate the scoreSupplier method.\n\ncommit cf9ce6ad127844d08f80386e69324d7b02beeb07\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Mon Apr 3 13:01:16 2017 +0100\n\n    SOLR-10383: Fix debug related NullPointerException in solr/contrib/ltr OriginalScoreFeature class.\n    (Vitezslav Zak, Christine Poerschke)\n\ncommit a902df5f45ce05b315243bf352f9c63fa27e341e\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Mon Apr 3 12:10:09 2017 +0100\n\n    SOLR-10383: reduce code duplication in TestOriginalScoreFeature\n\ncommit 780a5304487925d4c8e0a3270dd86c38dcb97a3b\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Sun Apr 2 16:25:09 2017 -0400\n\n    switch to advanceExact\n\ncommit 4c85f560b074a350e3559505a9fc075866f13abc\nAuthor: Dennis Gove <dpgove@gmail.com>\nDate:   Fri Mar 31 20:52:42 2017 -0400\n\n    SOLR-10393: Adds UUID Streaming Evaluator\n\ncommit ae138852fed59bae2a4106c218b76fca01538198\nAuthor: Dennis Gove <dpgove@gmail.com>\nDate:   Thu Mar 23 20:08:11 2017 -0400\n\n    SOLR-10356: Adds basic math streaming evaluators\n\ncommit e027bc4b566acd34a04f75cdf4700a26713738ac\nAuthor: Alexandre Rafalovitch <arafalov@apache.org>\nDate:   Sat Apr 1 19:06:50 2017 -0400\n\n    SOLR-9601: DIH Tika example is now minimal\n    Only keep definitions and files required to show Tika-extraction in DIH\n\ncommit a78aef990d5f4ae9a7d6704d677bd000ce16f8a9\nAuthor: Alexandre Rafalovitch <arafalov@apache.org>\nDate:   Sat Apr 1 13:42:23 2017 -0400\n\n    SOLR-7383: Replace DIH 'rss' example with 'atom'\n    rss example was broken for multiple reasons.\n    atom example showcases the same - and more - features\n    and uses the smallest config file needed to make it work.\n\ncommit 3e5e6522f0c63abc860da812d59f2f1116746f5b\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Fri Mar 31 18:16:13 2017 -0700\n\n    SOLR-10399: cleanup unused imports\n\ncommit 95bddaf0bb431c2aef7e41b59a4777ecc044f3e2\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Fri Mar 31 17:01:42 2017 -0700\n\n    SOLR-10399: Generalize some internal facet logic to simplify points/non-points field handling\n\ncommit d6cdcceac7a857e983713d9839c4cddfb2e9916c\nAuthor: Christine Poerschke <cpoerschke@apache.org>\nDate:   Fri Mar 31 18:10:27 2017 +0100\n\n    LUCENE-7763: Remove outdated comment in IndexWriterConfig.setIndexSort javadocs.\n    (\u9a6c\u53ef\u9633 via Christine Poerschke)\n\ncommit b865e31397e2a519a34606b493003a5952fafc08\nAuthor: yonik <yonik@apache.org>\nDate:   Fri Mar 31 12:55:15 2017 -0400\n\n    SOLR-7452: add more tests for refinement of missing buckets\n\ncommit 8d91c30a67b8aca488b3640ec5d996075362828d\nAuthor: yonik <yonik@apache.org>\nDate:   Thu Mar 30 12:55:27 2017 -0400\n\n    SOLR-7452: refinement of missing buckets and partial facets through missing buckets\n\ncommit 90c02315cb935b29051596061fb4ce7d7383d575\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Fri Mar 31 16:22:45 2017 +0200\n\n    LUCENE-7753: Make fields static when possible.\n\ncommit b9dd7bf4456cba88a21ac98f8587a03aa677bac5\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Fri Mar 31 16:11:19 2017 +0200\n\n    LUCENE-7761: Fixed comment in ReqExclScorer.\n\ncommit ae421e820ab45328d7229d756b16677d957385c3\nAuthor: markrmiller <markrmiller@apache.org>\nDate:   Fri Mar 31 10:53:20 2017 -0400\n\n    SOLR-10338: Configure SecureRandom non blocking for tests.\n\ncommit 99ebb56439b29ab0a11c66d3afd9904995e8fe91\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Mar 30 17:52:16 2017 +0100\n\n    SOLR-10351: Fix pre-commit\n\ncommit a45f36ef3d3ebdf97149fe405a9980145b79c133\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Thu Mar 30 17:34:28 2017 +0100\n\n    SOLR-10351: Add analyze Stream Evaluator to support streaming NLP\n\ncommit 5a401ab5262224052d0abf671a64bac99a5e4d7c\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Thu Mar 30 15:11:52 2017 +0200\n\n    LUCENE-7755: Join queries should not reference IndexReaders.\n\ncommit 139f885554dc88863559dd43e7dc153ec256714c\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Wed Mar 29 21:13:40 2017 -0700\n\n    SOLR-10387: zkTransfer normalizes destination path incorrectly if source is a windows directory\n\ncommit 317ef93a17890c076846a69e1e630d983362aba0\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Wed Mar 29 19:22:02 2017 +0530\n\n    SOLR-10352: Fixing available entropy warning limit to 300\n\ncommit 4269c23bd87234ac078bd5ff2f893e2086c15115\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Wed Mar 29 14:42:20 2017 +0200\n\n    SOLR-10362 Be more specific when catching this exception.\n\ncommit b6b2aac3f63823819d81a9b9d8f9f77fd65c7ced\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Wed Mar 29 08:48:26 2017 -0400\n\n    remove dead code\n\ncommit 00f2db48f7ebdf5d49181f8b72079897a3999e4a\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Wed Mar 29 10:51:34 2017 +0200\n\n    SOLR-10147: Admin UI -> Cloud -> Graph: Impossible to see shard state\n\ncommit 3a9ae68230e98c46782e9fb190c4fb37f2517771\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Wed Mar 29 13:52:51 2017 +0700\n\n    SOLR-9993: Add support for ExpandComponent with PointFields\n\ncommit 25b5d090455cc856d6bda5bd4129f6eefcb725dd\nAuthor: Shai Erera <shaie@apache.org>\nDate:   Thu Mar 23 08:28:05 2017 +0200\n\n    SOLR-10349: Add totalTermFreq support to TermsComponent\n\n    TermsComponent only returns docFreq information per requested term.\n    This commit adds a terms.ttf parameter, which if set to true, will\n    return both docFreq and totalTermFreq statistics for each requested\n    term.\n\ncommit 90efd090bfa5e8bbf45bb8ccba0997f916b1d2f7\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Wed Mar 29 08:09:40 2017 +0700\n\n    SOLR-10079: TestInPlaceUpdates(Distrib|Standalone) failures\n\ncommit 83fb5d7758e6c2653386d483ff2cc9495864ad81\nAuthor: yonik <yonik@apache.org>\nDate:   Tue Mar 28 19:52:51 2017 -0400\n\n    SOLR-7452: change terminology from _m missing-bucket to _p partial-bucket for refinement\n\ncommit 3c2e9c913435bdb685f2bfdcc6e0059e0d5e1c0f\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Tue Mar 28 18:39:28 2017 -0400\n\n    SOLR-10357: Enable edismax and standard query parsers to handle the option combination sow=false / autoGeneratePhraseQueries=true by setting QueryBuilder.autoGenerateMultiTermSynonymsQuery\n\ncommit 2762e31bfe243144f7dbba305c60b66d8c43793e\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Wed Mar 29 00:44:27 2017 +0530\n\n    SOLR-6736: Adding support for uploading zipped configsets using ConfigSets API\n\ncommit 94d69590e67259b14efcfebb54f748a381c37a82\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Wed Mar 29 00:26:31 2017 +0530\n\n    SOLR-10365: Handle a SolrCoreInitializationException while publishing core state during SolrCore creation\n\ncommit a3d51aebe3724fbcc2162b5fc8862b336595fe57\nAuthor: Joel Bernstein <jbernste@apache.org>\nDate:   Tue Mar 28 09:25:25 2017 +0100\n\n    SOLR-10341: SQL AVG function mis-interprets field type\n\ncommit 9a927620c0d59801dc633d8aace14aaf2aa86dc3\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Tue Mar 28 11:47:02 2017 -0400\n\n    SOLR-10343: Update Solr default/example and test configs to use SynonymGraphFilterFactory\n\ncommit c2d8c05387c8085af2ae14e688daa979b5632ff0\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Tue Mar 28 15:25:16 2017 +0200\n\n    LUCENE-7743: Avoid calling new String(String).\n\ncommit 4e317da9ee19b17619dfbbf9f69026d61782c8c2\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Tue Mar 28 15:21:35 2017 +0200\n\n    LUCENE-7751: Avoid boxing primitives only to call compareTo.\n\ncommit 41f533559db6d442a633c5fcfda14fd11cf027af\nAuthor: Adrien Grand <jpountz@gmail.com>\nDate:   Tue Mar 28 15:15:45 2017 +0200\n\n    LUCENE-7754: Inner classes should be static whenever possible.\n\ncommit b216a28f720c0cd6342e050a1a7b895248c65a6d\nAuthor: Jan H\u00f8ydahl <janhoy@apache.org>\nDate:   Tue Mar 28 14:24:09 2017 +0200\n\n    SOLR-10369: bin\\solr.cmd delete and healthcheck now works again (fixed continuation chars ^)\n\ncommit a3eb7488a69f1824a02f9d3e7820f1e9d7f0531c\nAuthor: Steve Rowe <sarowe@gmail.com>\nDate:   Mon Mar 27 23:53:55 2017 -0400\n\n    SOLR-10344: Update Solr default/example and test configs to use WordDelimiterGraphFilterFactory\n\ncommit b6fcaadbb9ac53557fca901b11af3801cab2ddad\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Mon Mar 27 22:17:34 2017 +0200\n\n    SOLR-10362: \"Memory Pool not found\" error when reporting JVM metrics.\n\ncommit 398c9200876cdd0973fb9da0d35fd6765264d50d\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Mon Mar 27 12:15:05 2017 -0700\n\n    SLR-10108: bin/solr script recursive copy broken\n\ncommit 39584af1f0a3a1ace793b8ace45cb07cdff3edf4\nAuthor: Ishan Chattopadhyaya <ishan@apache.org>\nDate:   Mon Mar 27 23:56:23 2017 +0530\n\n    SOLR-10352: bin/solr script now prints warning when available system entropy is lower than 300\n\ncommit ce6a309140a76af1a85a88362e53a57f047edc3b\nAuthor: Erick Erickson <erick@apache.org>\nDate:   Mon Mar 27 09:31:15 2017 -0700\n\n    SOLR-10371: There is some spelling mistakes in the Java source code Thanks hu xiaodong\"\n\ncommit e030eacba8f63d66fcfbcd5e94f89463de2a77f0\nAuthor: markrmiller <markrmiller@apache.org>\nDate:   Mon Mar 27 10:44:27 2017 -0400\n\n    SOLR-10076: Move changes entry to 6.6 release.\n\ncommit 9e8a9df5076e98ca7af2272495a287fc5a916700\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Mon Mar 27 20:06:01 2017 +0530\n\n    SOLR-9835: Fixed precommit failure.\n\ncommit 19df35c95f3042c676f311f26c299b3e1921cf0d\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Mon Mar 27 16:44:22 2017 +0700\n\n    SOLR-9835: TestInjection.waitForInSyncWithLeader() should rely on commit point of searcher\n\ncommit 781c9e7855d4a830c8c9d0c0a5c813e856e8f18d\nAuthor: Jim Ferenczi <jim.ferenczi@elastic.co>\nDate:   Sat Mar 25 18:44:39 2017 +0100\n\n    Update project doap files with 6.5.0 release\n\ncommit 0545d0886176a511a8dcb72872051f3b3488242e\nAuthor: Jim Ferenczi <jim.ferenczi@elastic.co>\nDate:   Sat Mar 25 18:37:25 2017 +0100\n\n    Add 6.5.0 back compat test indexes\n\ncommit 51c16b81eca762a2348c9526694fdf07bab7c332\nAuthor: Mike McCandless <mikemccand@apache.org>\nDate:   Sat Mar 25 06:21:29 2017 -0400\n\n    fix typo in comment\n\ncommit 9c0fc47bb88cf3823dc47ebb9d729b3c5ed3d21e\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Fri Mar 24 23:01:32 2017 -0400\n\n    SOLR-10304: Refactor new SolrDocumentFetcher out of SolrIndexSearcher\n\ncommit a67d143cde7ddc26343e6b68f37acf3d6c7b2e3d\nAuthor: David Smiley <dsmiley@apache.org>\nDate:   Fri Mar 24 22:46:24 2017 -0400\n\n    SOLR-10249: Refactor IndexFetcher to return detailed result\n\ncommit 75f4376e07b540291a22fe9956b50c9cb9160cb2\nAuthor: yonik <yonik@apache.org>\nDate:   Fri Mar 24 20:43:44 2017 -0400\n\n    SOLR-7452: add support for _m buckets, missing and has sub-facets in need of refinement\n\ncommit c7d33661013543fe32a231d5b18e36e929a95125\nAuthor: Steve Rowe <sarowe@apache.org>\nDate:   Fri Mar 24 12:31:16 2017 -0400\n\n    SOLR-9221: Remove Solr contribs: map-reduce, morphlines-core and morphlines-cell\n\ncommit d72d707f0406b51153423b19a3387a669467fc51\nAuthor: Chris Hostetter <hossman@apache.org>\nDate:   Thu Mar 23 18:28:10 2017 -0700\n\n    Fix test to stop asserting specific order when secondary sort is unspecified, add new checks that do assert an explicit order when secondary sort IS specified.\n\ncommit 665d0a954cf981fdbcb5aead4f7bb1b31ec0b75c\nAuthor: Shalin Shekhar Mangar <shalin@apache.org>\nDate:   Thu Mar 23 19:33:45 2017 +0530\n\n    SOLR-10281: ADMIN_PATHS is duplicated in two places and inconsistent\n\ncommit aefcdd1ab1a1fecbba7c8a31226b48363bb76313\nAuthor: Noble Paul <noble@apache.org>\nDate:   Thu Mar 23 18:12:20 2017 +1030\n\n    SOLR-6615: use constants for 'sort', 'distrib'\n\ncommit 0e4562d6a29ad072b45ee9aae0d83b5febd5600f\nAuthor: koji <koji@apache.org>\nDate:   Thu Mar 23 14:57:45 2017 +0900\n\n    SOLR-9184: Add a static convenience method ModifiableSolrParams#of(SolrParams) which returns the same instance if it already is modifiable, otherwise creates a new ModifiableSolrParams instance.\n\ncommit d762464e305b6b0fd70f921dcade41c5c25d1d2f\nAuthor: Noble Paul <noble@apache.org>\nDate:   Thu Mar 23 11:45:50 2017 +1030\n\n    SOLR-6615: use constants for 'id', '_route_', '_version_'\n\ncommit 3ad6ffe8bffc3eee2ec9320d4f11300451fc3519\nAuthor: yonik <yonik@apache.org>\nDate:   Wed Mar 22 19:53:50 2017 -0400\n\n    SOLR-7452: facet refinement - don't generate domain if skipping bucket\n\ncommit c913835cb701a4a4743840afe6b3ec28bf5e171b\nAuthor: Tomas Fernandez Lobbe <tflobbe@apache.org>\nDate:   Wed Mar 22 10:52:14 2017 -0700\n\n    SOLR-9986: Add javadoc to DatePointField class\n\ncommit 6747c82fbf846eaf3471ca58183502e2f818418b\nAuthor: Cao Manh Dat <datcm@apache.org>\nDate:   Wed Mar 22 15:00:33 2017 +0700\n\n    Add support for CollapseQParser with PointFields\n\ncommit 532829cd79e203ad064ff6841eedba9e5dbd9799\nAuthor: yonik <yonik@apache.org>\nDate:   Tue Mar 21 08:42:33 2017 -0400\n\n    SOLR-7452: json facet API, refine/skip through buckets already visited\n\ncommit 24caf3e39405137cec787e3f4f6f607aad82d28c\nAuthor: Dennis Gove <dpgove@gmail.com>\nDate:   Tue Mar 21 08:40:40 2017 -0400\n\n    SOLR-10333: Fixes use of HashedMap in StreamEvaluator tests\n\ncommit 1d0e38d3d0b6f558220473578236daead6faff34\nAuthor: Dennis Gove <dpgove@gmail.com>\nDate:   Mon Mar 20 16:36:05 2017 -0400\n\n    SOLR-10292:\u2026",
        "parent": "https://github.com/apache/lucene-solr/commit/69783f6403b01c4358578344801c5133ce0b812d",
        "repo": "lucene-solr",
        "unit_tests": [
            "DeleteShardTest.java"
        ]
    },
    "lucene-solr_96e8392": {
        "bug_id": "lucene-solr_96e8392",
        "commit": "https://github.com/apache/lucene-solr/commit/96e8392921792b9ec281c28f28f49b50f998ceed",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -212,6 +212,8 @@ Bug Fixes\n   This would fix the NPE when using the search stream with partitionKeys. (Varun Thacker)\n \n \n+* SOLR-11770: NPE in tvrh if no field is specified and document doesn't contain any fields with term vectors\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/CHANGES.txt",
                "sha": "e21b931040edabb5efcc6320225afed9b429e793",
                "status": "modified"
            },
            {
                "additions": 45,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "changes": 89,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 44,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "patch": "@@ -17,7 +17,6 @@\n package org.apache.solr.handler.component;\n \n import java.io.IOException;\n-import java.nio.charset.StandardCharsets;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n@@ -28,27 +27,31 @@\n import java.util.Map;\n import java.util.Set;\n \n-import org.apache.lucene.index.FieldInfo;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.StoredField;\n import org.apache.lucene.index.Fields;\n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.index.PostingsEnum;\n-import org.apache.lucene.index.StoredFieldVisitor;\n import org.apache.lucene.index.Term;\n import org.apache.lucene.index.Terms;\n import org.apache.lucene.index.TermsEnum;\n import org.apache.lucene.util.BytesRef;\n+import org.apache.solr.common.SolrDocument;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.CommonParams;\n import org.apache.solr.common.params.SolrParams;\n import org.apache.solr.common.params.TermVectorParams;\n import org.apache.solr.common.util.Base64;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.core.SolrCore;\n+import org.apache.solr.response.DocsStreamer;\n+import org.apache.solr.response.RetrieveFieldsOptimizer;\n import org.apache.solr.schema.IndexSchema;\n import org.apache.solr.schema.SchemaField;\n import org.apache.solr.search.DocList;\n import org.apache.solr.search.DocListAndSet;\n import org.apache.solr.search.ReturnFields;\n+import org.apache.solr.search.SolrDocumentFetcher;\n import org.apache.solr.search.SolrIndexSearcher;\n import org.apache.solr.search.SolrReturnFields;\n import org.apache.solr.util.SolrPluginUtils;\n@@ -262,54 +265,49 @@ public void process(ResponseBuilder rb) throws IOException {\n \n     //Only load the id field to get the uniqueKey of that\n     //field\n-\n-    final String finalUniqFieldName = uniqFieldName;\n-\n-    final List<String> uniqValues = new ArrayList<>();\n-    \n-    // TODO: is this required to be single-valued? if so, we should STOP\n-    // once we find it...\n-    final StoredFieldVisitor getUniqValue = new StoredFieldVisitor() {\n-      @Override \n-      public void stringField(FieldInfo fieldInfo, byte[] bytes) {\n-        uniqValues.add(new String(bytes, StandardCharsets.UTF_8));\n-      }\n-\n-      @Override \n-      public void intField(FieldInfo fieldInfo, int value) {\n-        uniqValues.add(Integer.toString(value));\n-      }\n-\n-      @Override \n-      public void longField(FieldInfo fieldInfo, long value) {\n-        uniqValues.add(Long.toString(value));\n-      }\n-\n-      @Override\n-      public Status needsField(FieldInfo fieldInfo) {\n-        return (fieldInfo.name.equals(finalUniqFieldName)) ? Status.YES : Status.NO;\n-      }\n-    };\n+    SolrDocumentFetcher docFetcher = searcher.getDocFetcher();\n+    SolrReturnFields srf = new SolrReturnFields(uniqFieldName, rb.req);\n+    RetrieveFieldsOptimizer retrieveFieldsOptimizer = RetrieveFieldsOptimizer.create(docFetcher, srf);\n \n     while (iter.hasNext()) {\n       Integer docId = iter.next();\n       NamedList<Object> docNL = new NamedList<>();\n \n       if (keyField != null) {\n-        reader.document(docId, getUniqValue);\n-        String uniqVal = null;\n-        if (uniqValues.size() != 0) {\n-          uniqVal = uniqValues.get(0);\n-          uniqValues.clear();\n-          docNL.add(\"uniqueKey\", uniqVal);\n-          termVectors.add(uniqVal, docNL);\n+        SolrDocument sdoc = null;\n+        try {\n+          if (retrieveFieldsOptimizer.returnStoredFields()) {\n+            Document doc = docFetcher.doc(docId, retrieveFieldsOptimizer.getStoredFields());\n+            // make sure to use the schema from the searcher and not the request (cross-core)\n+            sdoc = DocsStreamer.convertLuceneDocToSolrDoc(doc, searcher.getSchema(), srf);\n+          } else {\n+            // no need to get stored fields of the document, see SOLR-5968\n+            sdoc = new SolrDocument();\n+          }\n+\n+          // decorate the document with non-stored docValues fields\n+          if (retrieveFieldsOptimizer.returnDVFields()) {\n+            docFetcher.decorateDocValueFields(sdoc, docId, retrieveFieldsOptimizer.getDvFields());\n+          }\n+        } catch (IOException e) {\n+          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error reading document with docId \" + docId, e);\n         }\n+        Object val = sdoc.getFieldValue(uniqFieldName);\n+        String uniqVal = \"\";\n+        if (val instanceof StoredField) {\n+          uniqVal = ((StoredField) val).stringValue();\n+        } else {\n+          uniqVal = val.toString();\n+        }\n+\n+        docNL.add(\"uniqueKey\", uniqVal);\n+        termVectors.add(uniqVal, docNL);\n       } else {\n         // support for schemas w/o a unique key,\n         termVectors.add(\"doc-\" + docId, docNL);\n       }\n \n-      if ( null != fields ) {\n+      if (null != fields) {\n         for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n           final String field = entry.getKey();\n           final Terms vector = reader.getTermVector(docId, field);\n@@ -321,11 +319,14 @@ public Status needsField(FieldInfo fieldInfo) {\n       } else {\n         // extract all fields\n         final Fields vectors = reader.getTermVectors(docId);\n-        for (String field : vectors) {\n-          Terms terms = vectors.terms(field);\n-          if (terms != null) {\n-            TermsEnum termsEnum = terms.iterator();\n-            mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n+        // There can be no documents with vectors\n+        if (vectors != null) {\n+          for (String field : vectors) {\n+            Terms terms = vectors.terms(field);\n+            if (terms != null) {\n+              TermsEnum termsEnum = terms.iterator();\n+              mapOneVector(docNL, allFields, reader, docId, termsEnum, field);\n+            }\n           }\n         }\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "sha": "784dc814206c316d1a0e2bc3153afcfdecf76070",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "patch": "@@ -53,19 +53,19 @@ void optimize(Set<String> dvsCanSubstituteStored) {\n     storedFields.clear();\n   }\n \n-  boolean returnStoredFields() {\n+  public boolean returnStoredFields() {\n     return !(storedFields != null && storedFields.isEmpty());\n   }\n \n-  boolean returnDVFields() {\n+  public boolean returnDVFields() {\n     return !dvFields.isEmpty();\n   }\n \n-  Set<String> getStoredFields() {\n+  public Set<String> getStoredFields() {\n     return storedFields;\n   }\n \n-  Set<String> getDvFields() {\n+  public Set<String> getDvFields() {\n     return dvFields;\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/response/RetrieveFieldsOptimizer.java",
                "sha": "fcd47a732a4bdeb3c28136306bd5dd07313e0e4e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/response/transform/BaseEditorialTransformer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/response/transform/BaseEditorialTransformer.java?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/response/transform/BaseEditorialTransformer.java",
                "patch": "@@ -73,6 +73,8 @@ protected BytesRef getKey(SolrDocument doc) {\n         ft.readableToIndexed(f.stringValue(), bytesRefBuilder);\n       }\n       return bytesRefBuilder.get();\n+    } else if (obj instanceof String) { // Allows the idField to be stored=false, docValues=true\n+      return new BytesRef(((String)obj));\n     }\n     throw new AssertionError(\"Expected an IndexableField but got: \" + obj.getClass());\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/java/org/apache/solr/response/transform/BaseEditorialTransformer.java",
                "sha": "d23813161d3646b6db9db42e60311d7155b3a4af",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/schema.xml?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 1,
                "filename": "solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "patch": "@@ -502,7 +502,7 @@\n   </fieldType>\n   <fieldType name=\"severityType\" class=\"${solr.tests.EnumFieldType}\" enumsConfig=\"enumsConfig.xml\" enumName=\"severity\"/>\n \n-  <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\" required=\"false\"/>\n+  <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"${solr.tests.id.stored:true}\" multiValued=\"false\" required=\"false\" docValues=\"${solr.tests.id.docValues:false}\"/>\n   <field name=\"_root_\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\" required=\"false\"/>\n \n   <field name=\"signatureField\" type=\"string\" indexed=\"true\" stored=\"false\"/>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "sha": "b1a261b6c73b268c7c6e1e7188ecbf25334d642a",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test/org/apache/solr/handler/component/QueryElevationComponentTest.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/QueryElevationComponentTest.java?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/QueryElevationComponentTest.java",
                "patch": "@@ -23,6 +23,7 @@\n import java.lang.invoke.MethodHandles;\n import java.nio.charset.StandardCharsets;\n \n+import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;\n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.util.BytesRef;\n import org.apache.solr.SolrTestCaseJ4;\n@@ -36,14 +37,43 @@\n import org.apache.solr.search.SolrIndexSearcher;\n import org.apache.solr.util.FileUtils;\n import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TestRule;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n public class QueryElevationComponentTest extends SolrTestCaseJ4 {\n \n+  @Rule\n+  public TestRule solrTestRules = RuleChain.outerRule(new SystemPropertiesRestoreRule());\n+\n+\n   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n \n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    switch (random().nextInt(3)) {\n+      case 0:\n+        System.setProperty(\"solr.tests.id.stored\", \"true\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"true\");\n+        break;\n+      case 1:\n+        System.setProperty(\"solr.tests.id.stored\", \"true\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"false\");\n+        break;\n+      case 2:\n+        System.setProperty(\"solr.tests.id.stored\", \"false\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"true\");\n+        break;\n+      default:\n+        fail(\"Bad random number generatged not between 0-2 iunclusive\");\n+        break;\n+    }\n+  }\n+\n   @Before\n   @Override\n   public void setUp() throws Exception {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test/org/apache/solr/handler/component/QueryElevationComponentTest.java",
                "sha": "0db6b0f7be56ae46beefe15860da7384f3409a7d",
                "status": "modified"
            },
            {
                "additions": 196,
                "blob_url": "https://github.com/apache/lucene-solr/blob/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java",
                "changes": 340,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java?ref=96e8392921792b9ec281c28f28f49b50f998ceed",
                "deletions": 144,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java",
                "patch": "@@ -20,201 +20,237 @@\n import java.util.Arrays;\n import java.util.List;\n \n+import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;\n import org.apache.solr.SolrTestCaseJ4;\n import org.apache.solr.common.params.TermVectorParams;\n import org.junit.BeforeClass;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TestRule;\n+\n /**\n  *\n  *\n  **/\n public class TermVectorComponentTest extends SolrTestCaseJ4 {\n+\n+  @Rule\n+  public TestRule solrTestRules = RuleChain.outerRule(new SystemPropertiesRestoreRule());\n+\n+  // ensure that we operate correctly with all valid combinations of the uniqueKey being\n+  // stored and/or in docValues.\n   @BeforeClass\n   public static void beforeClass() throws Exception {\n-    initCore(\"solrconfig.xml\",\"schema.xml\");\n+    switch (random().nextInt(3)) {\n+      case 0:\n+        System.setProperty(\"solr.tests.id.stored\", \"true\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"true\");\n+        break;\n+      case 1:\n+        System.setProperty(\"solr.tests.id.stored\", \"true\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"false\");\n+        break;\n+      case 2:\n+        System.setProperty(\"solr.tests.id.stored\", \"false\");\n+        System.setProperty(\"solr.tests.id.docValues\", \"true\");\n+        break;\n+      default:\n+        fail(\"Bad random number generatged not between 0-2 iunclusive\");\n+        break;\n+    }\n+    initCore(\"solrconfig.xml\", \"schema.xml\");\n+  }\n+\n+  static String tv = \"/tvrh\";\n \n+  @Test\n+  public void testCanned() throws Exception {\n+\n+    clearIndex();\n     assertU(adoc(\"id\", \"0\",\n-            \"test_posoffpaytv\", \"This is a title and another title\",\n-            \"test_posofftv\", \"This is a title and another title\",\n-            \"test_basictv\", \"This is a title and another title\",\n-            \"test_notv\", \"This is a title and another title\",\n-            \"test_postv\", \"This is a title and another title\",\n-            \"test_offtv\", \"This is a title and another title\"\n+        \"test_posoffpaytv\", \"This is a title and another title\",\n+        \"test_posofftv\", \"This is a title and another title\",\n+        \"test_basictv\", \"This is a title and another title\",\n+        \"test_notv\", \"This is a title and another title\",\n+        \"test_postv\", \"This is a title and another title\",\n+        \"test_offtv\", \"This is a title and another title\"\n     ));\n     assertU(adoc(\"id\", \"1\",\n-            \"test_posoffpaytv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n-            \"test_posofftv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n-            \"test_basictv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n-            \"test_notv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n-            \"test_postv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n-            \"test_offtv\", \"The quick reb fox jumped over the lazy brown dogs.\"\n+        \"test_posoffpaytv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n+        \"test_posofftv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n+        \"test_basictv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n+        \"test_notv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n+        \"test_postv\", \"The quick reb fox jumped over the lazy brown dogs.\",\n+        \"test_offtv\", \"The quick reb fox jumped over the lazy brown dogs.\"\n     ));\n     assertU(adoc(\"id\", \"2\",\n-            \"test_posoffpaytv\", \"This is a document\",\n-            \"test_posofftv\", \"This is a document\",\n-            \"test_basictv\", \"This is a document\",\n-            \"test_notv\", \"This is a document\",\n-            \"test_postv\", \"This is a document\",\n-            \"test_offtv\", \"This is a document\"\n+        \"test_posoffpaytv\", \"This is a document\",\n+        \"test_posofftv\", \"This is a document\",\n+        \"test_basictv\", \"This is a document\",\n+        \"test_notv\", \"This is a document\",\n+        \"test_postv\", \"This is a document\",\n+        \"test_offtv\", \"This is a document\"\n     ));\n     assertU(adoc(\"id\", \"3\",\n-            \"test_posoffpaytv\", \"another document\",\n-            \"test_posofftv\", \"another document\",\n-            \"test_basictv\", \"another document\",\n-            \"test_notv\", \"another document\",\n-            \"test_postv\", \"another document\",\n-            \"test_offtv\", \"another document\"\n+        \"test_posoffpaytv\", \"another document\",\n+        \"test_posofftv\", \"another document\",\n+        \"test_basictv\", \"another document\",\n+        \"test_notv\", \"another document\",\n+        \"test_postv\", \"another document\",\n+        \"test_offtv\", \"another document\"\n     ));\n     //bunch of docs that are variants on blue\n     assertU(adoc(\"id\", \"4\",\n-            \"test_posoffpaytv\", \"blue\",\n-            \"test_posofftv\", \"blue\",\n-            \"test_basictv\", \"blue\",\n-            \"test_notv\", \"blue\",\n-            \"test_postv\", \"blue\",\n-            \"test_offtv\", \"blue\"\n+        \"test_posoffpaytv\", \"blue\",\n+        \"test_posofftv\", \"blue\",\n+        \"test_basictv\", \"blue\",\n+        \"test_notv\", \"blue\",\n+        \"test_postv\", \"blue\",\n+        \"test_offtv\", \"blue\"\n     ));\n     assertU(adoc(\"id\", \"5\",\n-            \"test_posoffpaytv\", \"blud\",\n-            \"test_posofftv\", \"blud\",\n-            \"test_basictv\", \"blud\",\n-            \"test_notv\", \"blud\",\n-            \"test_postv\", \"blud\",\n-            \"test_offtv\", \"blud\"\n+        \"test_posoffpaytv\", \"blud\",\n+        \"test_posofftv\", \"blud\",\n+        \"test_basictv\", \"blud\",\n+        \"test_notv\", \"blud\",\n+        \"test_postv\", \"blud\",\n+        \"test_offtv\", \"blud\"\n     ));\n     assertU(adoc(\"id\", \"6\",\n-            \"test_posoffpaytv\", \"boue\",\n-            \"test_posofftv\", \"boue\",\n-            \"test_basictv\", \"boue\",\n-            \"test_notv\", \"boue\",\n-            \"test_postv\", \"boue\",\n-            \"test_offtv\", \"boue\"\n+        \"test_posoffpaytv\", \"boue\",\n+        \"test_posofftv\", \"boue\",\n+        \"test_basictv\", \"boue\",\n+        \"test_notv\", \"boue\",\n+        \"test_postv\", \"boue\",\n+        \"test_offtv\", \"boue\"\n     ));\n     assertU(adoc(\"id\", \"7\",\n-            \"test_posoffpaytv\", \"glue\",\n-            \"test_posofftv\", \"glue\",\n-            \"test_basictv\", \"glue\",\n-            \"test_notv\", \"glue\",\n-            \"test_postv\", \"glue\",\n-            \"test_offtv\", \"glue\"\n+        \"test_posoffpaytv\", \"glue\",\n+        \"test_posofftv\", \"glue\",\n+        \"test_basictv\", \"glue\",\n+        \"test_notv\", \"glue\",\n+        \"test_postv\", \"glue\",\n+        \"test_offtv\", \"glue\"\n     ));\n     assertU(adoc(\"id\", \"8\",\n-            \"test_posoffpaytv\", \"blee\",\n-            \"test_posofftv\", \"blee\",\n-            \"test_basictv\", \"blee\",\n-            \"test_notv\", \"blee\",\n-            \"test_postv\", \"blee\",\n-            \"test_offtv\", \"blee\"\n+        \"test_posoffpaytv\", \"blee\",\n+        \"test_posofftv\", \"blee\",\n+        \"test_basictv\", \"blee\",\n+        \"test_notv\", \"blee\",\n+        \"test_postv\", \"blee\",\n+        \"test_offtv\", \"blee\"\n     ));\n     assertU(adoc(\"id\", \"9\",\n-            \"test_posoffpaytv\", \"blah\",\n-            \"test_posofftv\", \"blah\",\n-            \"test_basictv\", \"blah\",\n-            \"test_notv\", \"blah\",\n-            \"test_postv\", \"blah\",\n-            \"test_offtv\", \"blah\"\n+        \"test_posoffpaytv\", \"blah\",\n+        \"test_posofftv\", \"blah\",\n+        \"test_basictv\", \"blah\",\n+        \"test_notv\", \"blah\",\n+        \"test_postv\", \"blah\",\n+        \"test_offtv\", \"blah\"\n     ));\n \n     assertNull(h.validateUpdate(commit()));\n+    doBasics();\n+    doOptions();\n+    doPerField();\n+    doPayloads();\n   }\n \n-  static String tv = \"/tvrh\";\n \n-  @Test\n-  public void testBasics() throws Exception {\n-    assertJQ(req(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\", TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+  private void doBasics() throws Exception {\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\", TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_offtv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_posofftv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_posoffpaytv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_postv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n     // tv.fl diff from fl\n-    assertJQ(req(\"json.nl\",\"map\", \n-                 \"qt\",tv, \n-                 \"q\", \"id:0\", \n-                 \"fl\", \"*,score\",\n-                 \"tv.fl\", \"test_basictv,test_offtv\",\n-                 TermVectorComponent.COMPONENT_NAME, \"true\", \n-                 TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+    assertJQ(req(\"json.nl\", \"map\",\n+        \"qt\", tv,\n+        \"q\", \"id:0\",\n+        \"fl\", \"*,score\",\n+        \"tv.fl\", \"test_basictv,test_offtv\",\n+        TermVectorComponent.COMPONENT_NAME, \"true\",\n+        TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_offtv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n     // multi-valued tv.fl \n-    assertJQ(req(\"json.nl\",\"map\", \n-                 \"qt\",tv, \n-                 \"q\", \"id:0\", \n-                 \"fl\", \"*,score\",\n-                 \"tv.fl\", \"test_basictv\",\n-                 \"tv.fl\",\"test_offtv\",\n-                 TermVectorComponent.COMPONENT_NAME, \"true\", \n-                 TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+    assertJQ(req(\"json.nl\", \"map\",\n+        \"qt\", tv,\n+        \"q\", \"id:0\",\n+        \"fl\", \"*,score\",\n+        \"tv.fl\", \"test_basictv\",\n+        \"tv.fl\", \"test_offtv\",\n+        TermVectorComponent.COMPONENT_NAME, \"true\",\n+        TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_offtv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n     // re-use fl glob\n-    assertJQ(req(\"json.nl\",\"map\", \n-                 \"qt\",tv, \n-                 \"q\", \"id:0\", \n-                 \"fl\", \"*,score\",\n-                 TermVectorComponent.COMPONENT_NAME, \"true\", \n-                 TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+    assertJQ(req(\"json.nl\", \"map\",\n+        \"qt\", tv,\n+        \"q\", \"id:0\",\n+        \"fl\", \"*,score\",\n+        TermVectorComponent.COMPONENT_NAME, \"true\",\n+        TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_offtv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_posofftv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_posoffpaytv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_postv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n     // re-use fl, ignore things we can't handle\n-    assertJQ(req(\"json.nl\",\"map\", \n-                 \"qt\",tv, \n-                 \"q\", \"id:0\", \n-                 \"fl\", \"score,test_basictv,[docid],test_postv,val:sum(3,4)\",\n-                 TermVectorComponent.COMPONENT_NAME, \"true\", \n-                 TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+    assertJQ(req(\"json.nl\", \"map\",\n+        \"qt\", tv,\n+        \"q\", \"id:0\",\n+        \"fl\", \"score,test_basictv,[docid],test_postv,val:sum(3,4)\",\n+        TermVectorComponent.COMPONENT_NAME, \"true\",\n+        TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_postv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n     // re-use (multi-valued) fl, ignore things we can't handle\n-    assertJQ(req(\"json.nl\",\"map\", \n-                 \"qt\",tv, \n-                 \"q\", \"id:0\", \n-                 \"fl\", \"score,test_basictv\",\n-                 \"fl\", \"[docid],test_postv,val:sum(3,4)\",\n-                 TermVectorComponent.COMPONENT_NAME, \"true\", \n-                 TermVectorParams.TF, \"true\")\n-       ,\"/termVectors=={'0':{'uniqueKey':'0',\" +\n+    assertJQ(req(\"json.nl\", \"map\",\n+        \"qt\", tv,\n+        \"q\", \"id:0\",\n+        \"fl\", \"score,test_basictv\",\n+        \"fl\", \"[docid],test_postv,val:sum(3,4)\",\n+        TermVectorComponent.COMPONENT_NAME, \"true\",\n+        TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0',\" +\n             \" 'test_basictv':{'anoth':{'tf':1},'titl':{'tf':2}},\" +\n             \" 'test_postv':{'anoth':{'tf':1},'titl':{'tf':2}}}}\"\n     );\n \n   }\n \n-  @Test\n-  public void testOptions() throws Exception {\n-    assertJQ(req(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n-       , TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\")\n-       ,\"/termVectors/0/test_posofftv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n+  private void doOptions() throws Exception {\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n+        , TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\")\n+        , \"/termVectors/0/test_posofftv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n     );\n-    \n-    assertJQ(req(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n+\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n         , TermVectorParams.ALL, \"true\")\n-        ,\"/termVectors/0/test_posofftv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n-     );\n-    \n+        , \"/termVectors/0/test_posofftv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n+    );\n+\n     // test each combination at random\n     final List<String> list = new ArrayList<>();\n-    list.addAll(Arrays.asList(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"));\n-    String[][] options = new String[][] { { TermVectorParams.TF, \"'tf':1\" },\n-        { TermVectorParams.OFFSETS, \"'offsets':{'start':20, 'end':27}\" },\n-        { TermVectorParams.POSITIONS, \"'positions':{'position':5}\" },\n-        { TermVectorParams.DF, \"'df':2\" },\n-        { TermVectorParams.TF_IDF, \"'tf-idf':0.5\" } };\n+    list.addAll(Arrays.asList(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"));\n+    String[][] options = new String[][]{{TermVectorParams.TF, \"'tf':1\"},\n+        {TermVectorParams.OFFSETS, \"'offsets':{'start':20, 'end':27}\"},\n+        {TermVectorParams.POSITIONS, \"'positions':{'position':5}\"},\n+        {TermVectorParams.DF, \"'df':2\"},\n+        {TermVectorParams.TF_IDF, \"'tf-idf':0.5\"}};\n     StringBuilder expected = new StringBuilder(\"/termVectors/0/test_posofftv/anoth=={\");\n     boolean first = true;\n     for (int i = 0; i < options.length; i++) {\n@@ -225,46 +261,62 @@ public void testOptions() throws Exception {\n         }\n         first = false;\n         expected.append(options[i][1]);\n-        \n+\n       }\n       list.add(options[i][0]);\n       list.add(use ? \"true\" : \"false\");\n     }\n-    \n+\n     expected.append(\"}\");\n     assertJQ(req(list.toArray(new String[0])), expected.toString());\n   }\n \n-  @Test\n-  public void testPerField() throws Exception {\n-    assertJQ(req(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n-        ,TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\"\n-        ,TermVectorParams.FIELDS, \"test_basictv,test_notv,test_postv,test_offtv,test_posofftv,test_posoffpaytv\"\n-        ,\"f.test_posoffpaytv.\" + TermVectorParams.PAYLOADS, \"false\"\n-        ,\"f.test_posofftv.\" + TermVectorParams.POSITIONS, \"false\"\n-        ,\"f.test_offtv.\" + TermVectorParams.OFFSETS, \"false\"\n-        ,\"f.test_basictv.\" + TermVectorParams.DF, \"false\"\n-        ,\"f.test_basictv.\" + TermVectorParams.TF, \"false\"\n-        ,\"f.test_basictv.\" + TermVectorParams.TF_IDF, \"false\"\n+  private void doPerField() throws Exception {\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n+        , TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\"\n+        , TermVectorParams.FIELDS, \"test_basictv,test_notv,test_postv,test_offtv,test_posofftv,test_posoffpaytv\"\n+        , \"f.test_posoffpaytv.\" + TermVectorParams.PAYLOADS, \"false\"\n+        , \"f.test_posofftv.\" + TermVectorParams.POSITIONS, \"false\"\n+        , \"f.test_offtv.\" + TermVectorParams.OFFSETS, \"false\"\n+        , \"f.test_basictv.\" + TermVectorParams.DF, \"false\"\n+        , \"f.test_basictv.\" + TermVectorParams.TF, \"false\"\n+        , \"f.test_basictv.\" + TermVectorParams.TF_IDF, \"false\"\n         )\n-    ,\"/termVectors/0/test_basictv=={'anoth':{},'titl':{}}\"\n-    ,\"/termVectors/0/test_postv/anoth=={'tf':1, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n-    ,\"/termVectors/0/test_offtv/anoth=={'tf':1, 'df':2, 'tf-idf':0.5}\"\n-    ,\"/termVectors/warnings=={ 'noTermVectors':['test_notv'], 'noPositions':['test_basictv', 'test_offtv'], 'noOffsets':['test_basictv', 'test_postv']}\"\n+        , \"/termVectors/0/test_basictv=={'anoth':{},'titl':{}}\"\n+        , \"/termVectors/0/test_postv/anoth=={'tf':1, 'positions':{'position':5}, 'df':2, 'tf-idf':0.5}\"\n+        , \"/termVectors/0/test_offtv/anoth=={'tf':1, 'df':2, 'tf-idf':0.5}\"\n+        , \"/termVectors/warnings=={ 'noTermVectors':['test_notv'], 'noPositions':['test_basictv', 'test_offtv'], 'noOffsets':['test_basictv', 'test_postv']}\"\n     );\n   }\n \n-  @Test\n-  public void testPayloads() throws Exception {\n+  private void doPayloads() throws Exception {\n     // This field uses TokenOffsetPayloadTokenFilter, which\n     // stuffs start (20) and end offset (27) into the\n     // payload:\n-    assertJQ(req(\"json.nl\",\"map\", \"qt\",tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n-                 , TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\",\n-                 TermVectorParams.PAYLOADS, \"true\")\n-       ,\"/termVectors/0/test_posoffpaytv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'payloads':{'payload': 'AAAAFAAAABs='}, 'df':2, 'tf-idf':0.5}\"\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\"\n+        , TermVectorParams.TF, \"true\", TermVectorParams.DF, \"true\", TermVectorParams.OFFSETS, \"true\", TermVectorParams.POSITIONS, \"true\", TermVectorParams.TF_IDF, \"true\",\n+        TermVectorParams.PAYLOADS, \"true\")\n+        , \"/termVectors/0/test_posoffpaytv/anoth=={'tf':1, 'offsets':{'start':20, 'end':27}, 'positions':{'position':5}, 'payloads':{'payload': 'AAAAFAAAABs='}, 'df':2, 'tf-idf':0.5}\"\n+    );\n+  }\n+\n+  @Test\n+  public void testNoVectors() throws Exception {\n+    clearIndex();\n+    assertU(adoc(\"id\", \"0\"));\n+    assertU(adoc(\"id\", \"1\"));\n+    assertU(adoc(\"id\", \"2\"));\n+    assertU(adoc(\"id\", \"3\"));\n+    assertNull(h.validateUpdate(commit()));\n+\n+    // Kind of an odd test, but we just want to know if we don't generate an NPE when there is nothing to give back in the term vectors.\n+    assertJQ(req(\"json.nl\", \"map\", \"qt\", tv, \"q\", \"id:0\", TermVectorComponent.COMPONENT_NAME, \"true\", TermVectorParams.TF, \"true\")\n+        , \"/termVectors=={'0':{'uniqueKey':'0'}}}\"\n     );\n+\n+\n   }\n+\n }\n \n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/96e8392921792b9ec281c28f28f49b50f998ceed/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentTest.java",
                "sha": "c083a0a616e44d3ffba3c1cd4753927d72efa6ff",
                "status": "modified"
            }
        ],
        "message": "SOLR-11770: NPE in tvrh if no field is specified and document doesn't contain any fields with term vectors",
        "parent": "https://github.com/apache/lucene-solr/commit/896fd0ebd55aaafa51222aa9200e16f2dbb093e4",
        "repo": "lucene-solr",
        "unit_tests": [
            "TermVectorComponentTest.java",
            "TestRetrieveFieldsOptimizer.java"
        ]
    },
    "lucene-solr_972e342": {
        "bug_id": "lucene-solr_972e342",
        "commit": "https://github.com/apache/lucene-solr/commit/972e342fee7a02e71300a9739b9971e63708589b",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/972e342fee7a02e71300a9739b9971e63708589b/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=972e342fee7a02e71300a9739b9971e63708589b",
                "deletions": 1,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -256,7 +256,7 @@ Optimizations\n * SOLR-10548: JSON Facet API now uses hyper-log-log++ for determining the number of buckets\n   when merging requests from a multi-shard distributed request. (yonik)\n \n-* SOLR-10524: Explore in-memory partitioning for processing Overseer queue messages (Cao Manh Dat, Noble Paul, shalin, Scott Blum)\n+* SOLR-10524: Better ZkStateWriter batching (Cao Manh Dat, Noble Paul, shalin, Scott Blum)\n \n Bug Fixes\n ----------------------",
                "raw_url": "https://github.com/apache/lucene-solr/raw/972e342fee7a02e71300a9739b9971e63708589b/solr/CHANGES.txt",
                "sha": "cdbbcc8d217c930996cabfebbf0f51ea394c9952",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/972e342fee7a02e71300a9739b9971e63708589b/solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java?ref=972e342fee7a02e71300a9739b9971e63708589b",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java",
                "patch": "@@ -166,6 +166,9 @@ public ClusterState enqueueUpdate(ClusterState prevState, ZkWriteCommand cmd, Zk\n    * @return true if a flush is required, false otherwise\n    */\n   protected boolean maybeFlushBefore(ZkWriteCommand cmd) {\n+    if (cmd.collection == null || lastStateFormat <= 0) {\n+      return false;\n+    }\n     return cmd.collection.getStateFormat() != lastStateFormat;\n   }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/972e342fee7a02e71300a9739b9971e63708589b/solr/core/src/java/org/apache/solr/cloud/overseer/ZkStateWriter.java",
                "sha": "da0f57c4eb2223603eac4d262e4f6b2546d5c5d7",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/972e342fee7a02e71300a9739b9971e63708589b/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java?ref=972e342fee7a02e71300a9739b9971e63708589b",
                "deletions": 5,
                "filename": "solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java",
                "patch": "@@ -77,7 +77,7 @@ public void testZkStateWriterBatching() throws Exception {\n \n         ZkWriteCommand c2 = new ZkWriteCommand(\"c2\",\n             new DocCollection(\"c2\", new HashMap<>(), new HashMap<>(), DocRouter.DEFAULT, 0, ZkStateReader.COLLECTIONS_ZKNODE + \"/c2\"));\n-        assertTrue(\"Different (new) collection create cannot be batched together with another create\", writer.maybeFlushBefore(c2));\n+        assertFalse(\"Different (new) collection create can be batched together with another create\", writer.maybeFlushBefore(c2));\n \n         // simulate three state changes on same collection, all should be batched together before\n         assertFalse(writer.maybeFlushBefore(c1));\n@@ -88,13 +88,13 @@ public void testZkStateWriterBatching() throws Exception {\n         assertFalse(writer.maybeFlushAfter(c1));\n         assertFalse(writer.maybeFlushAfter(c1));\n \n-        // simulate three state changes on two different collections with stateFormat=2, none should be batched\n+        // simulate three state changes on two different collections with stateFormat=2, all should be batched\n         assertFalse(writer.maybeFlushBefore(c1));\n         // flushAfter has to be called as it updates the internal batching related info\n         assertFalse(writer.maybeFlushAfter(c1));\n-        assertTrue(writer.maybeFlushBefore(c2));\n+        assertFalse(writer.maybeFlushBefore(c2));\n         assertFalse(writer.maybeFlushAfter(c2));\n-        assertTrue(writer.maybeFlushBefore(c1));\n+        assertFalse(writer.maybeFlushBefore(c1));\n         assertFalse(writer.maybeFlushAfter(c1));\n \n         // create a collection in stateFormat = 1 i.e. inside the main cluster state\n@@ -168,7 +168,7 @@ public void testSingleLegacyCollection() throws Exception {\n     }\n   }\n \n-  public void testSingleExternalCollection() throws Exception{\n+  public void testSingleExternalCollection() throws Exception {\n     String zkDir = createTempDir(\"testSingleExternalCollection\").toFile().getAbsolutePath();\n \n     ZkTestServer server = new ZkTestServer(zkDir);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/972e342fee7a02e71300a9739b9971e63708589b/solr/core/src/test/org/apache/solr/cloud/overseer/ZkStateWriterTest.java",
                "sha": "f96b5e2adbaef4d2786cc1c51c8bb77b19070d74",
                "status": "modified"
            }
        ],
        "message": "SOLR-10524: Build fix for NPE\n\nIntroduced by ZkStateWriter batching optimizations.",
        "parent": "https://github.com/apache/lucene-solr/commit/6f978c5878157f4deca1a8f05ace07c69b6eadd7",
        "repo": "lucene-solr",
        "unit_tests": [
            "ZkStateWriterTest.java"
        ]
    },
    "lucene-solr_9a24dc5": {
        "bug_id": "lucene-solr_9a24dc5",
        "commit": "https://github.com/apache/lucene-solr/commit/9a24dc5d2ca890a50dc9751cb3abfd93c9939fee",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9a24dc5d2ca890a50dc9751cb3abfd93c9939fee/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=9a24dc5d2ca890a50dc9751cb3abfd93c9939fee",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -163,6 +163,8 @@ Bug Fixes\n \n * SOLR-9334: CloudSolrClient.collectionStateCache is unbounded (noble)\n \n+* SOLR-9339: NPE in CloudSolrClient when the response is null (noble)\n+\n \n Optimizations\n ----------------------",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9a24dc5d2ca890a50dc9751cb3abfd93c9939fee/solr/CHANGES.txt",
                "sha": "4da2d0eef9467fed23fdba299b5416cc51b0db2e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9a24dc5d2ca890a50dc9751cb3abfd93c9939fee/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java?ref=9a24dc5d2ca890a50dc9751cb3abfd93c9939fee",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "patch": "@@ -1060,7 +1060,7 @@ public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<\n     try {\n       resp = sendRequest(request, collection);\n       //to avoid an O(n) operation we always add STATE_VERSION to the last and try to read it from there\n-      Object o = resp.get(STATE_VERSION, resp.size()-1);\n+      Object o = resp == null || resp.size() == 0 ? null : resp.get(STATE_VERSION, resp.size() - 1);\n       if(o != null && o instanceof Map) {\n         //remove this because no one else needs this and tests would fail if they are comparing responses\n         resp.remove(resp.size()-1);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9a24dc5d2ca890a50dc9751cb3abfd93c9939fee/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "sha": "1f1c675c8273a8e8ce5ba0c301dedf070a504841",
                "status": "modified"
            }
        ],
        "message": "SOLR-9339: NPE in CloudSolrClient when the response is null",
        "parent": "https://github.com/apache/lucene-solr/commit/4ed68bc80e7990f4acd1b73dce3b5b8cd16d9fe5",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudSolrClientTest.java"
        ]
    },
    "lucene-solr_9b6b4ec": {
        "bug_id": "lucene-solr_9b6b4ec",
        "commit": "https://github.com/apache/lucene-solr/commit/9b6b4ec7032f5533a46d21348ea61e0479238946",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9b6b4ec7032f5533a46d21348ea61e0479238946/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java?ref=9b6b4ec7032f5533a46d21348ea61e0479238946",
                "deletions": 1,
                "filename": "lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java",
                "patch": "@@ -30,6 +30,7 @@\n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.index.MultiFields;\n import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n import org.apache.lucene.search.*;\n import org.apache.lucene.search.similarities.TFIDFSimilarity;\n import org.apache.lucene.search.similarities.DefaultSimilarity;\n@@ -196,6 +197,10 @@ private void addTerms(IndexReader reader, FieldVals f) throws IOException {\n     int corpusNumDocs = reader.numDocs();\n     HashSet<String> processedTerms = new HashSet<String>();\n     ts.reset();\n+    final Terms terms = MultiFields.getTerms(reader, f.fieldName);\n+    if (terms == null) {\n+      return;\n+    }\n     while (ts.incrementToken()) {\n       String term = termAtt.toString();\n       if (!processedTerms.contains(term)) {\n@@ -206,7 +211,7 @@ private void addTerms(IndexReader reader, FieldVals f) throws IOException {\n         AttributeSource atts = new AttributeSource();\n         MaxNonCompetitiveBoostAttribute maxBoostAtt =\n             atts.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n-        SlowFuzzyTermsEnum fe = new SlowFuzzyTermsEnum(MultiFields.getTerms(reader, startTerm.field()), atts, startTerm, f.minSimilarity, f.prefixLength);\n+        SlowFuzzyTermsEnum fe = new SlowFuzzyTermsEnum(terms, atts, startTerm, f.minSimilarity, f.prefixLength);\n         //store the df so all variants use same idf\n         int df = reader.docFreq(startTerm);\n         int numVariants = 0;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9b6b4ec7032f5533a46d21348ea61e0479238946/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/FuzzyLikeThisQuery.java",
                "sha": "a8a08d9bf7a0c959abf10b2703c877e1dd2992f2",
                "status": "modified"
            },
            {
                "additions": 19,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9b6b4ec7032f5533a46d21348ea61e0479238946/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java?ref=9b6b4ec7032f5533a46d21348ea61e0479238946",
                "deletions": 0,
                "filename": "lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java",
                "patch": "@@ -108,6 +108,25 @@ public void testMultiWord() throws Throwable {\n     StoredDocument doc = searcher.doc(sd[0].doc);\n     assertEquals(\"Should match most similar when using 2 words\", \"2\", doc.get(\"id\"));\n   }\n+  \n+  // LUCENE-4809\n+  public void testNonExistingField() throws Throwable {\n+    FuzzyLikeThisQuery flt = new FuzzyLikeThisQuery(10, analyzer);\n+    flt.addTerms(\"jonathin smoth\", \"name\", 0.3f, 1);\n+    flt.addTerms(\"jonathin smoth\", \"this field does not exist\", 0.3f, 1);\n+    // don't fail here just because the field doesn't exits\n+    Query q = flt.rewrite(searcher.getIndexReader());\n+    HashSet<Term> queryTerms = new HashSet<Term>();\n+    q.extractTerms(queryTerms);\n+    assertTrue(\"Should have variant jonathan\", queryTerms.contains(new Term(\"name\", \"jonathan\")));\n+    assertTrue(\"Should have variant smith\", queryTerms.contains(new Term(\"name\", \"smith\")));\n+    TopDocs topDocs = searcher.search(flt, 1);\n+    ScoreDoc[] sd = topDocs.scoreDocs;\n+    assertTrue(\"score docs must match 1 doc\", (sd != null) && (sd.length > 0));\n+    StoredDocument doc = searcher.doc(sd[0].doc);\n+    assertEquals(\"Should match most similar when using 2 words\", \"2\", doc.get(\"id\"));\n+  }\n+\n \n   //Test bug found when first query word does not match anything\n   public void testNoMatchFirstWordBug() throws Throwable {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9b6b4ec7032f5533a46d21348ea61e0479238946/lucene/sandbox/src/test/org/apache/lucene/sandbox/queries/FuzzyLikeThisQueryTest.java",
                "sha": "2b7070a41b04b47fa91e5ea5d82e1413a530cb94",
                "status": "modified"
            }
        ],
        "message": "LUCENE-4809: FuzzyLikeThisQuery fails if field does not exist or is not indexed with NPE during rewrite\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1451577 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/abd85ff5a0d41d13405147d28a5d9828067b545d",
        "repo": "lucene-solr",
        "unit_tests": [
            "FuzzyLikeThisQueryTest.java"
        ]
    },
    "lucene-solr_9c1d10c": {
        "bug_id": "lucene-solr_9c1d10c",
        "commit": "https://github.com/apache/lucene-solr/commit/9c1d10c4e982b79b1672d2513ccd0570f40fb162",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9c1d10c4e982b79b1672d2513ccd0570f40fb162/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java?ref=9c1d10c4e982b79b1672d2513ccd0570f40fb162",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "patch": "@@ -403,12 +403,20 @@ public void preClose(SolrCore core) {}\n         @Override\n         public void postClose(SolrCore core) {\n           File dataDir = new File(core.getIndexDir());\n-          for (File file : dataDir.listFiles()) {\n-            if (!file.delete()) {\n-              log.error(file.getAbsolutePath() + \" could not be deleted on core unload\");\n+          File[] files = dataDir.listFiles();\n+          if (files != null) {\n+            for (File file : files) {\n+              if (!file.delete()) {\n+                log.error(file.getAbsolutePath()\n+                    + \" could not be deleted on core unload\");\n+              }\n             }\n+            if (!dataDir.delete()) log.error(dataDir.getAbsolutePath()\n+                + \" could not be deleted on core unload\");\n+          } else {\n+            log.error(dataDir.getAbsolutePath()\n+                + \" could not be deleted on core unload\");\n           }\n-          if (!dataDir.delete()) log.error(dataDir.getAbsolutePath() + \" could not be deleted on core unload\");\n         }\n       });\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9c1d10c4e982b79b1672d2513ccd0570f40fb162/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "sha": "4d325b727447651e7d33f4002c9528e6e5ba846e",
                "status": "modified"
            }
        ],
        "message": "defense against NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1156201 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/8c83a10317b37315ce698ce1bde4c2eb147ef27d",
        "repo": "lucene-solr",
        "unit_tests": [
            "CoreAdminHandlerTest.java"
        ]
    },
    "lucene-solr_9d49a76": {
        "bug_id": "lucene-solr_9d49a76",
        "commit": "https://github.com/apache/lucene-solr/commit/9d49a76d01a3bb639c2ed3cf977a5063b0971c94",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=9d49a76d01a3bb639c2ed3cf977a5063b0971c94",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -162,6 +162,9 @@ Bug Fixes\n * LUCENE-6427: Added assertion about the presence of ghost bits in\n   (Fixed|Long)BitSet. (Luc Vanlerberghe via Adrien Grand)\n \n+* LUCENE-6468: Fixed NPE with empty Kuromoji user dictionary.\n+  (Jun Ohtani via Christian Moen)\n+\n API Changes\n \n * LUCENE-6377: SearcherFactory#newSearcher now accepts the previous reader",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/CHANGES.txt",
                "sha": "0f373ba423547459fbd7492bbcd4effe960f337c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java?ref=9d49a76d01a3bb639c2ed3cf977a5063b0971c94",
                "deletions": 1,
                "filename": "lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java",
                "patch": "@@ -91,7 +91,7 @@ public void inform(ResourceLoader loader) throws IOException {\n           .onMalformedInput(CodingErrorAction.REPORT)\n           .onUnmappableCharacter(CodingErrorAction.REPORT);\n       Reader reader = new InputStreamReader(stream, decoder);\n-      userDictionary = new UserDictionary(reader);\n+      userDictionary = UserDictionary.open(reader);\n     } else {\n       userDictionary = null;\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java",
                "sha": "13a2de5fcbd0ce1f14e7d5e0b411e5e2084c6a35",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java?ref=9d49a76d01a3bb639c2ed3cf977a5063b0971c94",
                "deletions": 6,
                "filename": "lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java",
                "patch": "@@ -56,26 +56,36 @@\n   public static final int LEFT_ID = 5;\n   \n   public static final int RIGHT_ID = 5;\n-  \n-  public UserDictionary(Reader reader) throws IOException {\n+\n+  public static UserDictionary open(Reader reader) throws IOException {\n+\n     BufferedReader br = new BufferedReader(reader);\n     String line = null;\n-    int wordId = CUSTOM_DICTIONARY_WORD_ID_OFFSET;\n     List<String[]> featureEntries = new ArrayList<>();\n- \n+\n     // text, segmentation, readings, POS\n     while ((line = br.readLine()) != null) {\n       // Remove comments\n       line = line.replaceAll(\"#.*$\", \"\");\n-      \n+\n       // Skip empty lines or comment lines\n       if (line.trim().length() == 0) {\n         continue;\n       }\n       String[] values = CSVUtil.parse(line);\n       featureEntries.add(values);\n     }\n-    \n+\n+    if (featureEntries.isEmpty()) {\n+      return null;\n+    } else {\n+      return new UserDictionary(featureEntries);\n+    }\n+  }\n+\n+  private UserDictionary(List<String[]> featureEntries) throws IOException {\n+\n+    int wordId = CUSTOM_DICTIONARY_WORD_ID_OFFSET;\n     // TODO: should we allow multiple segmentations per input 'phrase'?\n     // the old treemap didn't support this either, and i'm not sure if it's needed/useful?\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java",
                "sha": "3e72745120bb0cccd5b114bdec2461c9484e26a1",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java?ref=9d49a76d01a3bb639c2ed3cf977a5063b0971c94",
                "deletions": 2,
                "filename": "lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java",
                "patch": "@@ -22,6 +22,7 @@\n import java.io.InputStreamReader;\n import java.io.LineNumberReader;\n import java.io.Reader;\n+import java.io.StringReader;\n import java.nio.charset.StandardCharsets;\n import java.util.Random;\n \n@@ -39,7 +40,8 @@\n import org.apache.lucene.util.TestUtil;\n import org.apache.lucene.util.UnicodeUtil;\n \n-public class TestJapaneseTokenizer extends BaseTokenStreamTestCase {\n+public class\n+    TestJapaneseTokenizer extends BaseTokenStreamTestCase {\n \n   public static UserDictionary readDict() {\n     InputStream is = TestJapaneseTokenizer.class.getResourceAsStream(\"userdict.txt\");\n@@ -49,7 +51,7 @@ public static UserDictionary readDict() {\n     try {\n       try {\n         Reader reader = new InputStreamReader(is, StandardCharsets.UTF_8);\n-        return new UserDictionary(reader);\n+        return UserDictionary.open(reader);\n       } finally {\n         is.close();\n       }\n@@ -686,4 +688,24 @@ public void testCompoundOverPunctuation() throws Exception {\n                               new int[] { 1, 1, 1, 1, 1},\n                               new int[] { 1, 1, 1, 1, 1});\n   }\n+\n+  public void testEmptyUserDict() throws Exception {\n+    Reader emptyReader = new StringReader(\"\\n# This is an empty user dictionary\\n\\n\");\n+    UserDictionary emptyDict = UserDictionary.open(emptyReader);\n+\n+    Analyzer analyzer = new Analyzer() {\n+      @Override\n+      protected TokenStreamComponents createComponents(String fieldName) {\n+        Tokenizer tokenizer = new JapaneseTokenizer(newAttributeFactory(), emptyDict, false, Mode.SEARCH);\n+        return new TokenStreamComponents(tokenizer, tokenizer);\n+      }\n+    };\n+\n+    assertAnalyzesTo(analyzer, \"\u3053\u308c\u306f\u672c\u3067\u306f\u306a\u3044\",\n+        new String[]{\"\u3053\u308c\", \"\u306f\", \"\u672c\", \"\u3067\", \"\u306f\", \"\u306a\u3044\"},\n+        new int[]{0, 2, 3, 4, 5, 6},\n+        new int[]{2, 3, 4, 5, 6, 8}\n+    );\n+    analyzer.close();\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9d49a76d01a3bb639c2ed3cf977a5063b0971c94/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java",
                "sha": "ba172a00222d3bb394a410bbdab4ed330b0fea4b",
                "status": "modified"
            }
        ],
        "message": "Fix for empty Kuromoji user dictionary NPE (LUCENE-6468)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1678685 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/216fd8d46a6749b83f928b1e174cc7ea7b57d91b",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestJapaneseTokenizerFactory.java",
            "UserDictionaryTest.java"
        ]
    },
    "lucene-solr_9e61daf": {
        "bug_id": "lucene-solr_9e61daf",
        "commit": "https://github.com/apache/lucene-solr/commit/9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -239,6 +239,9 @@ Bug Fixes\n * SOLR-7810: map-reduce contrib script to set classpath for convenience refers to example\n   rather than server. (Mark Miller)\n \n+* SOLR-7765: Hardened the behavior of TokenizerChain when null arguments are used in constructor.\n+  This prevents NPEs in some code paths.  (Konstantin Gribov, hossman)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/CHANGES.txt",
                "sha": "f70f008ca9c644b8664658a4141ef2e8b73b4dec",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java",
                "patch": "@@ -29,22 +29,47 @@\n  * create a TokenStream.\n  */\n public final class TokenizerChain extends SolrAnalyzer {\n+  private static final CharFilterFactory[] EMPTY_CHAR_FITLERS = new CharFilterFactory[0];\n+  private static final TokenFilterFactory[] EMPTY_TOKEN_FITLERS = new TokenFilterFactory[0];\n+  \n   final private CharFilterFactory[] charFilters;\n   final private TokenizerFactory tokenizer;\n   final private TokenFilterFactory[] filters;\n \n+  /** \n+   * Creates a new TokenizerChain w/o any CharFilterFactories.\n+   *\n+   * @param tokenizer Factory for the Tokenizer to use, must not be null.\n+   * @param filters Factories for the TokenFilters to use - if null, will be treated as if empty.\n+   */\n   public TokenizerChain(TokenizerFactory tokenizer, TokenFilterFactory[] filters) {\n     this(null,tokenizer,filters);\n   }\n \n+  /** \n+   * Creates a new TokenizerChain.\n+   *\n+   * @param charFilters Factories for the CharFilters to use, if any - if null, will be treated as if empty.\n+   * @param tokenizer Factory for the Tokenizer to use, must not be null.\n+   * @param filters Factories for the TokenFilters to use if any- if null, will be treated as if empty.\n+   */\n   public TokenizerChain(CharFilterFactory[] charFilters, TokenizerFactory tokenizer, TokenFilterFactory[] filters) {\n+    charFilters = null == charFilters ? EMPTY_CHAR_FITLERS : charFilters;\n+    filters = null == filters ? EMPTY_TOKEN_FITLERS : filters;\n+    if (null == tokenizer) {\n+      throw new NullPointerException(\"TokenizerFactory must not be null\");\n+    }\n+    \n     this.charFilters = charFilters;\n     this.tokenizer = tokenizer;\n     this.filters = filters;\n   }\n \n+  /** @return array of CharFilterFactories, may be empty but never null */\n   public CharFilterFactory[] getCharFilterFactories() { return charFilters; }\n+  /** @return the TokenizerFactory in use, will never be null */\n   public TokenizerFactory getTokenizerFactory() { return tokenizer; }\n+  /** @return array of TokenFilterFactories, may be empty but never null */\n   public TokenFilterFactory[] getTokenFilterFactories() { return filters; }\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java",
                "sha": "ca51d69fbda9015fab3cd51f9e7e5d9148673277",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java",
                "patch": "@@ -104,7 +104,7 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n \n     NamedList<Object> namedList = new NamedList<>();\n \n-    if( cfiltfacs != null ){\n+    if (0 < cfiltfacs.length) {\n       String source = value;\n       for(CharFilterFactory cfiltfac : cfiltfacs ){\n         Reader reader = new StringReader(source);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java",
                "sha": "0f5b0ea7f7c83f3e4115c6a9d53456edad0029ad",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 18,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "patch": "@@ -497,15 +497,15 @@ private static StoredDocument getFirstLiveDoc(Terms terms, LeafReader reader) th\n       TokenizerChain tchain = (TokenizerChain)analyzer;\n \n       CharFilterFactory[] cfiltfacs = tchain.getCharFilterFactories();\n-      SimpleOrderedMap<Map<String, Object>> cfilters = new SimpleOrderedMap<>();\n-      for (CharFilterFactory cfiltfac : cfiltfacs) {\n-        Map<String, Object> tok = new HashMap<>();\n-        String className = cfiltfac.getClass().getName();\n-        tok.put(\"className\", className);\n-        tok.put(\"args\", cfiltfac.getOriginalArgs());\n-        cfilters.add(className.substring(className.lastIndexOf('.')+1), tok);\n-      }\n-      if (cfilters.size() > 0) {\n+      if (0 < cfiltfacs.length) {\n+        SimpleOrderedMap<Map<String, Object>> cfilters = new SimpleOrderedMap<>();\n+        for (CharFilterFactory cfiltfac : cfiltfacs) {\n+          Map<String, Object> tok = new HashMap<>();\n+          String className = cfiltfac.getClass().getName();\n+          tok.put(\"className\", className);\n+          tok.put(\"args\", cfiltfac.getOriginalArgs());\n+          cfilters.add(className.substring(className.lastIndexOf('.')+1), tok);\n+        }\n         aninfo.add(\"charFilters\", cfilters);\n       }\n \n@@ -516,15 +516,15 @@ private static StoredDocument getFirstLiveDoc(Terms terms, LeafReader reader) th\n       aninfo.add(\"tokenizer\", tokenizer);\n \n       TokenFilterFactory[] filtfacs = tchain.getTokenFilterFactories();\n-      SimpleOrderedMap<Map<String, Object>> filters = new SimpleOrderedMap<>();\n-      for (TokenFilterFactory filtfac : filtfacs) {\n-        Map<String, Object> tok = new HashMap<>();\n-        String className = filtfac.getClass().getName();\n-        tok.put(\"className\", className);\n-        tok.put(\"args\", filtfac.getOriginalArgs());\n-        filters.add(className.substring(className.lastIndexOf('.')+1), tok);\n-      }\n-      if (filters.size() > 0) {\n+      if (0 < filtfacs.length) {\n+        SimpleOrderedMap<Map<String, Object>> filters = new SimpleOrderedMap<>();\n+        for (TokenFilterFactory filtfac : filtfacs) {\n+          Map<String, Object> tok = new HashMap<>();\n+          String className = filtfac.getClass().getName();\n+          tok.put(\"className\", className);\n+          tok.put(\"args\", filtfac.getOriginalArgs());\n+          filters.add(className.substring(className.lastIndexOf('.')+1), tok);\n+        }\n         aninfo.add(\"filters\", filters);\n       }\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "sha": "fe7b400b6defe907aa2494b18c27671a30936154",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/FieldType.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/schema/FieldType.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/schema/FieldType.java",
                "patch": "@@ -883,7 +883,7 @@ public void checkSchemaField(final SchemaField field) {\n       Map<String,String> factoryArgs;\n       TokenizerChain tokenizerChain = (TokenizerChain)analyzer;\n       CharFilterFactory[] charFilterFactories = tokenizerChain.getCharFilterFactories();\n-      if (null != charFilterFactories && charFilterFactories.length > 0) {\n+      if (0 < charFilterFactories.length) {\n         List<SimpleOrderedMap<Object>> charFilterProps = new ArrayList<>();\n         for (CharFilterFactory charFilterFactory : charFilterFactories) {\n           SimpleOrderedMap<Object> props = new SimpleOrderedMap<>();\n@@ -927,7 +927,7 @@ public void checkSchemaField(final SchemaField field) {\n       analyzerProps.add(TOKENIZER, tokenizerProps);\n \n       TokenFilterFactory[] filterFactories = tokenizerChain.getTokenFilterFactories();\n-      if (null != filterFactories && filterFactories.length > 0) {\n+      if (0 < filterFactories.length) {\n         List<SimpleOrderedMap<Object>> filterProps = new ArrayList<>();\n         for (TokenFilterFactory filterFactory : filterFactories) {\n           SimpleOrderedMap<Object> props = new SimpleOrderedMap<>();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/FieldType.java",
                "sha": "41b89889e3b7535916296c1df5dbde9b0c61da79",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader.java",
                "patch": "@@ -175,10 +175,8 @@ private Analyzer constructMultiTermAnalyzer(Analyzer queryAnalyzer) {\n     MultiTermChainBuilder builder = new MultiTermChainBuilder();\n \n     CharFilterFactory[] charFactories = tc.getCharFilterFactories();\n-    if (charFactories != null) {\n-      for (CharFilterFactory fact : charFactories) {\n-        builder.add(fact);\n-      }\n+    for (CharFilterFactory fact : charFactories) {\n+      builder.add(fact);\n     }\n \n     builder.add(tc.getTokenizerFactory());",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader.java",
                "sha": "da560ea0bfa9774eacffd8c532bd7f5d66bde935",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 18,
                "filename": "solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "patch": "@@ -1285,20 +1285,18 @@ public FieldType newFieldType(String typeName, String className, Map<String, ?>\n    */\n   protected void informResourceLoaderAwareObjectsInChain(TokenizerChain chain) {\n     CharFilterFactory[] charFilters = chain.getCharFilterFactories();\n-    if (charFilters != null) {\n-      for (CharFilterFactory next : charFilters) {\n-        if (next instanceof ResourceLoaderAware) {\n-          try {\n-            ((ResourceLoaderAware) next).inform(loader);\n-          } catch (IOException e) {\n-            throw new SolrException(ErrorCode.SERVER_ERROR, e);\n-          }\n+    for (CharFilterFactory next : charFilters) {\n+      if (next instanceof ResourceLoaderAware) {\n+        try {\n+          ((ResourceLoaderAware) next).inform(loader);\n+        } catch (IOException e) {\n+          throw new SolrException(ErrorCode.SERVER_ERROR, e);\n+        }\n         }\n-      }\n     }\n \n     TokenizerFactory tokenizerFactory = chain.getTokenizerFactory();\n-    if (tokenizerFactory != null && tokenizerFactory instanceof ResourceLoaderAware) {\n+    if (tokenizerFactory instanceof ResourceLoaderAware) {\n       try {\n         ((ResourceLoaderAware) tokenizerFactory).inform(loader);\n       } catch (IOException e) {\n@@ -1307,14 +1305,12 @@ protected void informResourceLoaderAwareObjectsInChain(TokenizerChain chain) {\n     }\n \n     TokenFilterFactory[] filters = chain.getTokenFilterFactories();\n-    if (filters != null) {\n-      for (TokenFilterFactory next : filters) {\n-        if (next instanceof ResourceLoaderAware) {\n-          try {\n-            ((ResourceLoaderAware) next).inform(loader);\n-          } catch (IOException e) {\n-            throw new SolrException(ErrorCode.SERVER_ERROR, e);\n-          }\n+    for (TokenFilterFactory next : filters) {\n+      if (next instanceof ResourceLoaderAware) {\n+        try {\n+          ((ResourceLoaderAware) next).inform(loader);\n+        } catch (IOException e) {\n+          throw new SolrException(ErrorCode.SERVER_ERROR, e);\n         }\n       }\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java",
                "sha": "8a0ea630da2906fa2fa03880e74a2f62dbbbb26c",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test-files/solr/collection1/conf/schema-null-charfilters-analyzer.xml",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/schema-null-charfilters-analyzer.xml?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/schema-null-charfilters-analyzer.xml",
                "patch": "@@ -0,0 +1,27 @@\n+<?xml version=\"1.0\" ?>\n+<!--\n+  Licensed to the Apache Software Foundation (ASF) under one or more\n+  contributor license agreements.  See the NOTICE file distributed with\n+  this work for additional information regarding copyright ownership.\n+  The ASF licenses this file to You under the Apache License, Version 2.0\n+  (the \"License\"); you may not use this file except in compliance with\n+  the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+  Unless required by applicable law or agreed to in writing, software\n+  distributed under the License is distributed on an \"AS IS\" BASIS,\n+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  See the License for the specific language governing permissions and\n+  limitations under the License.\n+  -->\n+\n+<schema name=\"test\" version=\"1.4\">\n+  <fieldType name=\"string\" class=\"solr.StrField\"/>\n+\n+  <!-- field type with custom TokenizerChain analyzer (created with 2-arg constructor, see SOLR-7765) -->\n+  <fieldType name=\"custom_tc_string\" class=\"solr.CustomAnalyzerStrField\"/>\n+\n+\n+  <dynamicField name=\"*\" type=\"string\" indexed=\"true\" stored=\"true\" />\n+</schema>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test-files/solr/collection1/conf/schema-null-charfilters-analyzer.xml",
                "sha": "1ad96ca958a98987cc636cb07e6070efda478c2a",
                "status": "added"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "patch": "@@ -20,6 +20,7 @@\n import org.apache.solr.common.luke.FieldFlag;\n import org.apache.solr.request.SolrQueryRequest;\n import org.apache.solr.schema.IndexSchema;\n+import org.apache.solr.schema.CustomAnalyzerStrField; // jdoc\n import org.apache.solr.util.AbstractSolrTestCase;\n import org.apache.solr.util.TestHarness;\n import org.junit.Before;\n@@ -198,6 +199,27 @@ public void testNumTerms() throws Exception {\n     }\n   }\n \n+  /** @see CustomAnalyzerStrField */\n+  public void testNullFactories() throws Exception {\n+    deleteCore();\n+    initCore(\"solrconfig.xml\", \"schema-null-charfilters-analyzer.xml\");\n+\n+    try {\n+      assertQ(req(\"qt\", \"/admin/luke\", \"show\", \"schema\")\n+              , \"//lst[@name='custom_tc_string']/lst[@name='indexAnalyzer']\"\n+              , \"//lst[@name='custom_tc_string']/lst[@name='queryAnalyzer']\"\n+              , \"0=count(//lst[@name='custom_tc_string']/lst[@name='indexAnalyzer']/lst[@name='filters'])\"\n+              , \"0=count(//lst[@name='custom_tc_string']/lst[@name='queryAnalyzer']/lst[@name='filters'])\"\n+              , \"0=count(//lst[@name='custom_tc_string']/lst[@name='indexAnalyzer']/lst[@name='charFilters'])\"\n+              , \"0=count(//lst[@name='custom_tc_string']/lst[@name='queryAnalyzer']/lst[@name='charFilters'])\"\n+              );\n+    } finally {\n+      // Put back the configuration expected by the rest of the tests in this suite\n+      deleteCore();\n+      initCore(\"solrconfig.xml\", \"schema12.xml\");\n+    }\n+  }\n+\n   public void testCopyFieldLists() throws Exception {\n     SolrQueryRequest req = req(\"qt\", \"/admin/luke\", \"show\", \"schema\");\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "sha": "b16e45fbd8d19f34a97294942ba0328080e9182b",
                "status": "modified"
            },
            {
                "additions": 74,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/schema/CustomAnalyzerStrField.java",
                "changes": 74,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/schema/CustomAnalyzerStrField.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/schema/CustomAnalyzerStrField.java",
                "patch": "@@ -0,0 +1,74 @@\n+package org.apache.solr.schema;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import java.util.HashMap;\n+import java.util.Random;\n+\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.analysis.core.KeywordTokenizerFactory;\n+import org.apache.lucene.analysis.util.TokenFilterFactory;\n+import org.apache.lucene.analysis.util.CharFilterFactory;\n+import org.apache.lucene.util.LuceneTestCase;\n+\n+import org.apache.solr.analysis.TokenizerChain;\n+import org.apache.solr.handler.admin.LukeRequestHandlerTest; // jdoc\n+\n+/**\n+ * A Test only custom FieldType that specifies null for various params when constructing \n+ * TokenizerChain instances to ensure that they are still well behaved.\n+ *\n+ * @see LukeRequestHandlerTest#testNullFactories\n+ */\n+public class CustomAnalyzerStrField extends StrField {\n+  private final Analyzer indexAnalyzer;\n+  private final Analyzer queryAnalyzer;\n+\n+  public CustomAnalyzerStrField() {\n+    Random r = LuceneTestCase.random();\n+\n+    // two arg constructor\n+    Analyzer a2 = new TokenizerChain\n+      (new KeywordTokenizerFactory(new HashMap<>()),\n+       r.nextBoolean() ? null : new TokenFilterFactory[0]);\n+    \n+    // three arg constructor\n+    Analyzer a3 = new TokenizerChain\n+      (r.nextBoolean() ? null : new CharFilterFactory[0],\n+       new KeywordTokenizerFactory(new HashMap<>()),\n+       r.nextBoolean() ? null : new TokenFilterFactory[0]);\n+\n+    if (r.nextBoolean()) {\n+      indexAnalyzer = a2;\n+      queryAnalyzer = a3;\n+    } else {\n+      queryAnalyzer = a2;\n+      indexAnalyzer = a3;\n+    }\n+  }\n+\n+  @Override\n+  public Analyzer getIndexAnalyzer() {\n+    return indexAnalyzer;\n+  }\n+\n+  @Override\n+  public Analyzer getQueryAnalyzer() {\n+    return queryAnalyzer;\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/schema/CustomAnalyzerStrField.java",
                "sha": "c24114a05c7cabad110eda4dafbbe4e1525b4c4b",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/schema/MultiTermTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/schema/MultiTermTest.java?ref=9e61daf0fa4b95bf167dab57b905138a5bbb4cca",
                "deletions": 1,
                "filename": "solr/core/src/test/org/apache/solr/schema/MultiTermTest.java",
                "patch": "@@ -88,7 +88,7 @@ public void testDefaultCopiedToMulti() {\n       assertTrue((factory instanceof ASCIIFoldingFilterFactory) || (factory instanceof LowerCaseFilterFactory));\n     }\n \n-    assertTrue(tc.getCharFilterFactories() == null);\n+    assertTrue(tc.getCharFilterFactories().length == 0);\n \n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9e61daf0fa4b95bf167dab57b905138a5bbb4cca/solr/core/src/test/org/apache/solr/schema/MultiTermTest.java",
                "sha": "ba8515a3da326bf183585cdf4cd32aede577b553",
                "status": "modified"
            }
        ],
        "message": "SOLR-7765: Hardened the behavior of TokenizerChain when null arguments are used in constructor. This prevents NPEs in some code paths.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1692170 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/585f8a7b2618f95a33c2d546bc2e61875264001c",
        "repo": "lucene-solr",
        "unit_tests": [
            "TokenizerChainTest.java",
            "LukeRequestHandlerTest.java",
            "TestFieldType.java"
        ]
    },
    "lucene-solr_9f644b1": {
        "bug_id": "lucene-solr_9f644b1",
        "commit": "https://github.com/apache/lucene-solr/commit/9f644b1c6911a68b7ed29d5992bc0bec66dec0ed",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9f644b1c6911a68b7ed29d5992bc0bec66dec0ed/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=9f644b1c6911a68b7ed29d5992bc0bec66dec0ed",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -217,6 +217,8 @@ Bug Fixes\n \n * SOLR-13408: Cannot start/stop DaemonStream repeatedly, other API improvements (Erick Erickson)\n \n+* SOLR-13281: Fixed NPE in DocExpirationUpdateProcessorFactory (Munendra S N, Tom\u00e1s Fern\u00e1ndez L\u00f6bbe)\n+\n Improvements\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9f644b1c6911a68b7ed29d5992bc0bec66dec0ed/solr/CHANGES.txt",
                "sha": "d08112c9d0e58b0ebeee7a93b53d45b080c15d1a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/9f644b1c6911a68b7ed29d5992bc0bec66dec0ed/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java?ref=9f644b1c6911a68b7ed29d5992bc0bec66dec0ed",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "patch": "@@ -38,6 +38,7 @@\n import org.apache.solr.common.cloud.Slice;\n import org.apache.solr.common.util.ExecutorUtil;\n import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.common.util.SimpleOrderedMap;\n import org.apache.solr.core.CloseHook;\n import org.apache.solr.core.SolrCore;\n import org.apache.solr.request.LocalSolrQueryRequest;\n@@ -384,6 +385,7 @@ public void run() {\n         (factory.core, Collections.<String,String[]>emptyMap());\n       try {\n         final SolrQueryResponse rsp = new SolrQueryResponse();\n+        rsp.addResponseHeader(new SimpleOrderedMap<>(1));\n         SolrRequestInfo.setRequestInfo(new SolrRequestInfo(req, rsp));\n         try {\n           ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/9f644b1c6911a68b7ed29d5992bc0bec66dec0ed/solr/core/src/java/org/apache/solr/update/processor/DocExpirationUpdateProcessorFactory.java",
                "sha": "38f6c47be5853f2249be94552c4063b2d04d430c",
                "status": "modified"
            }
        ],
        "message": "SOLR-13281: Fix NPE in DocExpirationUpdateProcessor",
        "parent": "https://github.com/apache/lucene-solr/commit/2a3bd8e8648e85963a668d46a239cc48db777f5b",
        "repo": "lucene-solr",
        "unit_tests": [
            "DocExpirationUpdateProcessorFactoryTest.java"
        ]
    },
    "lucene-solr_a0396da": {
        "bug_id": "lucene-solr_a0396da",
        "commit": "https://github.com/apache/lucene-solr/commit/a0396da64b5874886a801f22b7cb81e11ed9642a",
        "file": [
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a0396da64b5874886a801f22b7cb81e11ed9642a/solr/core/src/java/org/apache/solr/search/CaffeineCache.java",
                "changes": 42,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/CaffeineCache.java?ref=a0396da64b5874886a801f22b7cb81e11ed9642a",
                "deletions": 20,
                "filename": "solr/core/src/java/org/apache/solr/search/CaffeineCache.java",
                "patch": "@@ -76,7 +76,7 @@\n   private CacheStats priorStats;\n   private long priorInserts;\n \n-  private String description;\n+  private String description = \"Caffeine Cache\";\n   private LongAdder inserts;\n   private Cache<K,V> cache;\n   private long warmupTime;\n@@ -340,25 +340,27 @@ public String toString() {\n   public void initializeMetrics(SolrMetricManager manager, String registryName, String tag, String scope) {\n     registry = manager.registry(registryName);\n     cacheMap = new MetricsMap((detailed, map) -> {\n-      CacheStats stats = cache.stats();\n-      long insertCount = inserts.sum();\n-\n-      map.put(LOOKUPS_PARAM, stats.requestCount());\n-      map.put(HITS_PARAM, stats.hitCount());\n-      map.put(HIT_RATIO_PARAM, stats.hitRate());\n-      map.put(INSERTS_PARAM, insertCount);\n-      map.put(EVICTIONS_PARAM, stats.evictionCount());\n-      map.put(SIZE_PARAM, cache.asMap().size());\n-      map.put(\"warmupTime\", warmupTime);\n-      map.put(RAM_BYTES_USED_PARAM, ramBytesUsed());\n-      map.put(MAX_RAM_MB_PARAM, getMaxRamMB());\n-\n-      CacheStats cumulativeStats = priorStats.plus(stats);\n-      map.put(\"cumulative_lookups\", cumulativeStats.requestCount());\n-      map.put(\"cumulative_hits\", cumulativeStats.hitCount());\n-      map.put(\"cumulative_hitratio\", cumulativeStats.hitRate());\n-      map.put(\"cumulative_inserts\", priorInserts + insertCount);\n-      map.put(\"cumulative_evictions\", cumulativeStats.evictionCount());\n+      if (cache != null) {\n+        CacheStats stats = cache.stats();\n+        long insertCount = inserts.sum();\n+\n+        map.put(LOOKUPS_PARAM, stats.requestCount());\n+        map.put(HITS_PARAM, stats.hitCount());\n+        map.put(HIT_RATIO_PARAM, stats.hitRate());\n+        map.put(INSERTS_PARAM, insertCount);\n+        map.put(EVICTIONS_PARAM, stats.evictionCount());\n+        map.put(SIZE_PARAM, cache.asMap().size());\n+        map.put(\"warmupTime\", warmupTime);\n+        map.put(RAM_BYTES_USED_PARAM, ramBytesUsed());\n+        map.put(MAX_RAM_MB_PARAM, getMaxRamMB());\n+\n+        CacheStats cumulativeStats = priorStats.plus(stats);\n+        map.put(\"cumulative_lookups\", cumulativeStats.requestCount());\n+        map.put(\"cumulative_hits\", cumulativeStats.hitCount());\n+        map.put(\"cumulative_hitratio\", cumulativeStats.hitRate());\n+        map.put(\"cumulative_inserts\", priorInserts + insertCount);\n+        map.put(\"cumulative_evictions\", cumulativeStats.evictionCount());\n+      }\n     });\n     manager.registerGauge(this, registryName, cacheMap, tag, true, scope, getCategory().toString());\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a0396da64b5874886a801f22b7cb81e11ed9642a/solr/core/src/java/org/apache/solr/search/CaffeineCache.java",
                "sha": "71eb86f34ddacac44755c45ffc8af4f5a9a0a401",
                "status": "modified"
            }
        ],
        "message": "SOLR-8241: Fix an NPE.",
        "parent": "https://github.com/apache/lucene-solr/commit/8007ac0cb0c88838ba6e58e56e2bc23374c15dc4",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestCaffeineCache.java"
        ]
    },
    "lucene-solr_a162755": {
        "bug_id": "lucene-solr_a162755",
        "commit": "https://github.com/apache/lucene-solr/commit/a162755e24561250210560521aee58dd896c859e",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a162755e24561250210560521aee58dd896c859e/src/solrj/org/apache/solr/client/solrj/response/QueryResponse.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/solrj/org/apache/solr/client/solrj/response/QueryResponse.java?ref=a162755e24561250210560521aee58dd896c859e",
                "deletions": 2,
                "filename": "src/solrj/org/apache/solr/client/solrj/response/QueryResponse.java",
                "patch": "@@ -131,8 +131,11 @@ private void extractStatsInfo(NamedList<Object> info) {\n       NamedList<NamedList<Object>> ff = (NamedList<NamedList<Object>>) info.get( \"stats_fields\" );\n       if( ff != null ) {\n         for( Map.Entry<String,NamedList<Object>> entry : ff ) {\n-          _fieldStatsInfo.put( entry.getKey(), \n-              new FieldStatsInfo( entry.getValue(), entry.getKey() ) );\n+          NamedList<Object> v = entry.getValue();\n+          if( v != null ) {\n+            _fieldStatsInfo.put( entry.getKey(), \n+                new FieldStatsInfo( v, entry.getKey() ) );\n+          }\n         }\n       }\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a162755e24561250210560521aee58dd896c859e/src/solrj/org/apache/solr/client/solrj/response/QueryResponse.java",
                "sha": "61571693f1794cca760a86f81a2ef10e63c4f9e0",
                "status": "modified"
            }
        ],
        "message": "fix potential NPE with FieldStatsInfo\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@763791 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/c9ed885d3b6a4246fac3ed40021da9d209bb79ea",
        "repo": "lucene-solr",
        "unit_tests": [
            "QueryResponseTest.java"
        ]
    },
    "lucene-solr_a2d3151": {
        "bug_id": "lucene-solr_a2d3151",
        "commit": "https://github.com/apache/lucene-solr/commit/a2d31510a1c2963849ceec255715aa42ce27b3c0",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=a2d31510a1c2963849ceec255715aa42ce27b3c0",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -474,6 +474,9 @@ New features\n   to wrap any other Analyzer and provide the same functionality as\n   MaxFieldLength provided on IndexWriter.  This patch also fixes a bug\n   in the offset calculation in CharTokenizer. (Uwe Schindler, Shai Erera)\n+\n+* LUCENE-2526: Don't throw NPE from MultiPhraseQuery.toString when\n+  it's empty.  (Ross Woolf via Mike McCandless)\n   \n Optimizations\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/CHANGES.txt",
                "sha": "4279fffb43acfa1eae5cbb7738938c053b715daf",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java?ref=a2d31510a1c2963849ceec255715aa42ce27b3c0",
                "deletions": 1,
                "filename": "lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "patch": "@@ -336,7 +336,7 @@ public Weight createWeight(Searcher searcher) throws IOException {\n   @Override\n   public final String toString(String f) {\n     StringBuilder buffer = new StringBuilder();\n-    if (!field.equals(f)) {\n+    if (field == null || !field.equals(f)) {\n       buffer.append(field);\n       buffer.append(\":\");\n     }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/src/java/org/apache/lucene/search/MultiPhraseQuery.java",
                "sha": "330089c805299b4312fb0bc1f0a680f03456bd9a",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java?ref=a2d31510a1c2963849ceec255715aa42ce27b3c0",
                "deletions": 0,
                "filename": "lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java",
                "patch": "@@ -263,4 +263,9 @@ private void add(String s, String type, IndexWriter writer) throws IOException {\n     writer.addDocument(doc);\n   }\n \n+  // LUCENE-2526\n+  public void testEmptyToString() {\n+    new MultiPhraseQuery().toString();\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a2d31510a1c2963849ceec255715aa42ce27b3c0/lucene/src/test/org/apache/lucene/search/TestMultiPhraseQuery.java",
                "sha": "c10d4fee86b921b049d18720b188070273b397d2",
                "status": "modified"
            }
        ],
        "message": "LUCENE-2526: don't throw NPE from MultiPhraseQuery.toString if it has no terms\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@960367 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/14e13edd85bbbaafb8a33a5e29e8a2b5829ce268",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestMultiPhraseQuery.java"
        ]
    },
    "lucene-solr_a417a2c": {
        "bug_id": "lucene-solr_a417a2c",
        "commit": "https://github.com/apache/lucene-solr/commit/a417a2cd6a612e7ed1a99b14230c3f08e455f9c1",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a417a2cd6a612e7ed1a99b14230c3f08e455f9c1/solr/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=a417a2cd6a612e7ed1a99b14230c3f08e455f9c1",
                "deletions": 1,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -161,7 +161,9 @@ Bug Fixes\n   (Amrit Sarkar, Varun Thacker)\n \n * SOLR-11840: Fix bin/solr help-text inconsistencies (Jason Gerlowski)\n- \n+\n+* SOLR-10169: PeerSync will hit an NPE on no response errors when looking for fingerprint. (Erick Erickson)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a417a2cd6a612e7ed1a99b14230c3f08e455f9c1/solr/CHANGES.txt",
                "sha": "e01036684fa39dc6e5eca419f8bf55950c37bc7f",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a417a2cd6a612e7ed1a99b14230c3f08e455f9c1/solr/core/src/java/org/apache/solr/update/PeerSync.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/PeerSync.java?ref=a417a2cd6a612e7ed1a99b14230c3f08e455f9c1",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/update/PeerSync.java",
                "patch": "@@ -388,9 +388,13 @@ private boolean alreadyInSync() {\n       ShardResponse srsp = shardHandler.takeCompletedOrError();\n       if (srsp == null) break;\n \n-      Object replicaFingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n+      Object replicaFingerprint = null;\n+      if (srsp.getSolrResponse() != null && srsp.getSolrResponse().getResponse() != null) {\n+        replicaFingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n+      }\n+\n       if (replicaFingerprint == null) {\n-        log.warn(\"Replica did not return a fingerprint - possibly an older Solr version\");\n+        log.warn(\"Replica did not return a fingerprint - possibly an older Solr version or exception\");\n         continue;\n       }\n       \n@@ -402,7 +406,7 @@ private boolean alreadyInSync() {\n           return true;\n         }\n       } catch(IOException e) {\n-        log.warn(\"Could not cofirm if we are already in sync. Continue with PeerSync\");\n+        log.warn(\"Could not confirm if we are already in sync. Continue with PeerSync\");\n       }\n     }\n     ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a417a2cd6a612e7ed1a99b14230c3f08e455f9c1/solr/core/src/java/org/apache/solr/update/PeerSync.java",
                "sha": "3511a6cb4738558a559c27b6ad42a92c3fe6d9d1",
                "status": "modified"
            }
        ],
        "message": "SOLR-10169: PeerSync will hit an NPE on no response errors when looking for fingerprint.",
        "parent": "https://github.com/apache/lucene-solr/commit/7edfd9c41018f16e7b6af1b58e9983e427eff9de",
        "repo": "lucene-solr",
        "unit_tests": [
            "PeerSyncTest.java"
        ]
    },
    "lucene-solr_a8804b7": {
        "bug_id": "lucene-solr_a8804b7",
        "commit": "https://github.com/apache/lucene-solr/commit/a8804b7867b8c899b037eabb82c37d21c499cdf7",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=a8804b7867b8c899b037eabb82c37d21c499cdf7",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -180,6 +180,9 @@ Bug fixes\n   rethrown with more useful information about the problem, omitting the\n   incorrect OutOfMemoryError.  (Robert Muir, Uwe Schindler)\n \n+* LUCENE-5682: NPE in QueryRescorer when Scorer is null\n+  (Joel Bernstein, Mike McCandless)\n+\n Test Framework\n \n * LUCENE-5622: Fail tests if they print over the given limit of bytes to ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/CHANGES.txt",
                "sha": "0d310a6f1ace6fa9d65e8c8275242e782db9fe1e",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java?ref=a8804b7867b8c899b037eabb82c37d21c499cdf7",
                "deletions": 9,
                "filename": "lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java",
                "patch": "@@ -85,18 +85,23 @@ public int compare(ScoreDoc a, ScoreDoc b) {\n         scorer = weight.scorer(readerContext, null);\n       }\n \n-      int targetDoc = docID - docBase;\n-      int actualDoc = scorer.docID();\n-      if (actualDoc < targetDoc) {\n-        actualDoc = scorer.advance(targetDoc);\n-      }\n+      if(scorer != null) {\n+        int targetDoc = docID - docBase;\n+        int actualDoc = scorer.docID();\n+        if (actualDoc < targetDoc) {\n+          actualDoc = scorer.advance(targetDoc);\n+        }\n \n-      if (actualDoc == targetDoc) {\n-        // Query did match this doc:\n-        hit.score = combine(hit.score, true, scorer.score());\n+        if (actualDoc == targetDoc) {\n+          // Query did match this doc:\n+          hit.score = combine(hit.score, true, scorer.score());\n+        } else {\n+          // Query did not match this doc:\n+          assert actualDoc > targetDoc;\n+          hit.score = combine(hit.score, false, 0.0f);\n+        }\n       } else {\n         // Query did not match this doc:\n-        assert actualDoc > targetDoc;\n         hit.score = combine(hit.score, false, 0.0f);\n       }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/core/src/java/org/apache/lucene/search/QueryRescorer.java",
                "sha": "755c3cd4d8a8ef4636305d2ac7bce81df184c497",
                "status": "modified"
            },
            {
                "additions": 40,
                "blob_url": "https://github.com/apache/lucene-solr/blob/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java?ref=a8804b7867b8c899b037eabb82c37d21c499cdf7",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java",
                "patch": "@@ -107,6 +107,46 @@ public void testBasic() throws Exception {\n     dir.close();\n   }\n \n+  // Test LUCENE-5682\n+  public void testNullScorerTermQuery() throws Exception {\n+    Directory dir = newDirectory();\n+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n+\n+    Document doc = new Document();\n+    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n+    doc.add(newTextField(\"field\", \"wizard the the the the the oz\", Field.Store.NO));\n+    w.addDocument(doc);\n+    doc = new Document();\n+    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n+    // 1 extra token, but wizard and oz are close;\n+    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\", Field.Store.NO));\n+    w.addDocument(doc);\n+    IndexReader r = w.getReader();\n+    w.shutdown();\n+\n+    // Do ordinary BooleanQuery:\n+    BooleanQuery bq = new BooleanQuery();\n+    bq.add(new TermQuery(new Term(\"field\", \"wizard\")), Occur.SHOULD);\n+    bq.add(new TermQuery(new Term(\"field\", \"oz\")), Occur.SHOULD);\n+    IndexSearcher searcher = getSearcher(r);\n+    searcher.setSimilarity(new DefaultSimilarity());\n+\n+    TopDocs hits = searcher.search(bq, 10);\n+    assertEquals(2, hits.totalHits);\n+    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n+    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n+\n+    // Now, resort using TermQuery on term that does not exist.\n+    TermQuery tq = new TermQuery(new Term(\"field\", \"gold\"));\n+    TopDocs hits2 = QueryRescorer.rescore(searcher, hits, tq, 2.0, 10);\n+\n+    // Just testing that null scorer is handled.\n+    assertEquals(2, hits2.totalHits);\n+\n+    r.close();\n+    dir.close();\n+  }\n+\n   public void testCustomCombine() throws Exception {\n     Directory dir = newDirectory();\n     RandomIndexWriter w = new RandomIndexWriter(random(), dir);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/a8804b7867b8c899b037eabb82c37d21c499cdf7/lucene/core/src/test/org/apache/lucene/search/TestQueryRescorer.java",
                "sha": "28f78b031dd9186674a79d3bef84acd6c0a2fe2e",
                "status": "modified"
            }
        ],
        "message": "LUCENE-5682: NPE in QueryRescorer when Scorer is null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1595973 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/f039b0f0fbc44ba184f752ce64ee061fba3d35ae",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestQueryRescorer.java"
        ]
    },
    "lucene-solr_ab768b8": {
        "bug_id": "lucene-solr_ab768b8",
        "commit": "https://github.com/apache/lucene-solr/commit/ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -256,6 +256,9 @@ Bug Fixes\n \n * SOLR-5667: Performance problem when not using hdfs block cache. (Mark Miller)\n \n+* SOLR-5526: Fixed NPE that could arrise when explicitly configuring some built \n+  in QParserPlugins (Nikolay Khitrin, Vitaliy Zhovtyuk, hossman)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/CHANGES.txt",
                "sha": "093e878adea5dd25a0f0b36c9c789f9964821c37",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/BoostQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/BoostQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/BoostQParserPlugin.java",
                "patch": "@@ -37,7 +37,7 @@\n  * {@link org.apache.lucene.queries.function.valuesource.ReciprocalFloatFunction}\n  */\n public class BoostQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"boost\";\n+  public static final String NAME = \"boost\";\n   public static String BOOSTFUNC = \"b\";\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/BoostQParserPlugin.java",
                "sha": "d73b02544a5f40ca0d015736db398e6aff56c51b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/DisMaxQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/DisMaxQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/DisMaxQParserPlugin.java",
                "patch": "@@ -110,7 +110,7 @@\n  *\n  */\n public class DisMaxQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"dismax\";\n+  public static final String NAME = \"dismax\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/DisMaxQParserPlugin.java",
                "sha": "d2efbcc3895e39f522bd282da91f7250d2217cd5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FieldQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/FieldQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/FieldQParserPlugin.java",
                "patch": "@@ -32,7 +32,7 @@\n  * This is generally equivalent to the Lucene query parser expression <code>myfield:\"Foo Bar\"</code>\n  */\n public class FieldQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"field\";\n+  public static final String NAME = \"field\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FieldQParserPlugin.java",
                "sha": "4a5199399adcdfd8943e7cc8abd246c3071ca6ba",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FunctionQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/FunctionQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/FunctionQParserPlugin.java",
                "patch": "@@ -26,7 +26,7 @@\n  * <br>Example: <code>{!func}log(foo)</code>\n  */\n public class FunctionQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"func\";\n+  public static final String NAME = \"func\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FunctionQParserPlugin.java",
                "sha": "00eba696d56a6e9932e18e0667ca0cb47d00bc98",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FunctionRangeQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/FunctionRangeQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/FunctionRangeQParserPlugin.java",
                "patch": "@@ -36,7 +36,7 @@\n  * <br>Filter query example: <code>fq={!frange l=0 u=2.2}sum(user_ranking,editor_ranking)</code> \n  */\n public class FunctionRangeQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"frange\";\n+  public static final String NAME = \"frange\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/FunctionRangeQParserPlugin.java",
                "sha": "0c3f8c8610f186a73c09e1ea0c8642fb59125bdb",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "patch": "@@ -45,7 +45,7 @@\n \n \n public class JoinQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"join\";\n+  public static final String NAME = \"join\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java",
                "sha": "d4970ca33d8a4655f5d76deab83c1b34017ae7a9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/LuceneQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/LuceneQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/LuceneQParserPlugin.java",
                "patch": "@@ -34,7 +34,7 @@\n  * <br>Example: <code>{!lucene q.op=AND df=text sort='price asc'}myfield:foo +bar -baz</code>\n  */\n public class LuceneQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"lucene\";\n+  public static final String NAME = \"lucene\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/LuceneQParserPlugin.java",
                "sha": "3e608e7a93a6fce98c2f3e49fdd7c7ee4e8be8f6",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/MaxScoreQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/MaxScoreQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/MaxScoreQParserPlugin.java",
                "patch": "@@ -26,7 +26,7 @@\n  * <br>Example: <code>q=foo {!maxscore v=$myq}&myq=A OR B OR C</code>\n  */\n public class MaxScoreQParserPlugin extends LuceneQParserPlugin {\n-  public static String NAME = \"maxscore\";\n+  public static final String NAME = \"maxscore\";\n \n   @Override\n   public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/MaxScoreQParserPlugin.java",
                "sha": "0ff5bb6e79b4f1d587d07d6e13bb9dbf99f6eb8e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/NestedQParserPlugin.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/NestedQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/search/NestedQParserPlugin.java",
                "patch": "@@ -32,7 +32,7 @@\n  *     created from the lucene syntax string that matches documents with inStock=true.\n  */\n public class NestedQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"query\";\n+  public static final String NAME = \"query\";\n \n   @Override\n   public void init(NamedList args) {\n@@ -69,4 +69,4 @@ public void addDebugInfo(NamedList<Object> debugInfo) {\n     };\n   }\n \n-}\n\\ No newline at end of file\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/NestedQParserPlugin.java",
                "sha": "23910d8457add903e3af612cea20c33328d2740b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/OldLuceneQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/OldLuceneQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/OldLuceneQParserPlugin.java",
                "patch": "@@ -26,7 +26,7 @@\n  * <br>Example: <code>{!lucenePlusSort}myfield:foo +bar -baz;price asc</code>\n  */\n public class OldLuceneQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"lucenePlusSort\";\n+  public static final String NAME = \"lucenePlusSort\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/OldLuceneQParserPlugin.java",
                "sha": "006e36cab0b0ec4f8b7a84895a3dd3485c8e90b9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/PrefixQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/PrefixQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/PrefixQParserPlugin.java",
                "patch": "@@ -32,7 +32,7 @@\n  * to the Lucene query parser expression <code>myfield:foo*</code>\n  */\n public class PrefixQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"prefix\";\n+  public static final String NAME = \"prefix\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/PrefixQParserPlugin.java",
                "sha": "e66d4dc4a7ad035e8a53a2a2af304b82cda0ab4f",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/QParserPlugin.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/QParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/search/QParserPlugin.java",
                "patch": "@@ -28,9 +28,15 @@\n \n public abstract class QParserPlugin implements NamedListInitializedPlugin, SolrInfoMBean {\n   /** internal use - name of the default parser */\n-  public static String DEFAULT_QTYPE = LuceneQParserPlugin.NAME;\n+  public static final String DEFAULT_QTYPE = LuceneQParserPlugin.NAME;\n \n-  /** internal use - name to class mappings of builtin parsers */\n+  /**\n+   * Internal use - name to class mappings of builtin parsers.\n+   * Each query parser plugin extending {@link QParserPlugin} has own instance of standardPlugins.\n+   * This leads to cyclic dependencies of static fields and to case when NAME field is not yet initialized.\n+   * This result to NPE during initialization.\n+   * For every plugin, listed here, NAME field has to be final and static.\n+   */\n   public static final Object[] standardPlugins = {\n     LuceneQParserPlugin.NAME, LuceneQParserPlugin.class,\n     OldLuceneQParserPlugin.NAME, OldLuceneQParserPlugin.class,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/QParserPlugin.java",
                "sha": "3cb6f4dbfcd366e588b7d22342bce7ebdad940ed",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/RawQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/RawQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/RawQParserPlugin.java",
                "patch": "@@ -34,7 +34,7 @@\n  * <br>Example: <code>{!raw f=myfield}Foo Bar</code> creates <code>TermQuery(Term(\"myfield\",\"Foo Bar\"))</code>\n  */\n public class RawQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"raw\";\n+  public static final String NAME = \"raw\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/RawQParserPlugin.java",
                "sha": "77fe52393f9f679bd5af0c11071770801544261a",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SimpleQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SimpleQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/SimpleQParserPlugin.java",
                "patch": "@@ -69,7 +69,7 @@\n  */\n public class SimpleQParserPlugin extends QParserPlugin {\n   /** The name that can be used to specify this plugin should be used to parse the query. */\n-  public static String NAME = \"simple\";\n+  public static final String NAME = \"simple\";\n \n   /** Map of string operators to their int counterparts in SimpleQueryParser. */\n   private static final Map<String, Integer> OPERATORS = new HashMap<String, Integer>();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SimpleQParserPlugin.java",
                "sha": "54e5ee4c0b4f5e7297cc99e9d117a46a1eb6825a",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SpatialBoxQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SpatialBoxQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/SpatialBoxQParserPlugin.java",
                "patch": "@@ -22,7 +22,7 @@\n import org.apache.solr.request.SolrQueryRequest;\n \n public class SpatialBoxQParserPlugin extends SpatialFilterQParserPlugin {\n-  public static String NAME = \"bbox\";\n+  public static final String NAME = \"bbox\";\n \n   @Override\n   public QParser createParser(String qstr, SolrParams localParams,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SpatialBoxQParserPlugin.java",
                "sha": "00afb1a1c5345ddfb31709091eafbee82d29d3d4",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java",
                "patch": "@@ -49,7 +49,7 @@\n  * to the field, making it useful as a component of the main query or a boosting query.\n  */\n public class SpatialFilterQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"geofilt\";\n+  public static final String NAME = \"geofilt\";\n \n   @Override\n   public QParser createParser(String qstr, SolrParams localParams,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SpatialFilterQParserPlugin.java",
                "sha": "a83a073815edee564f051458eb1b08158e0d4db5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SurroundQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SurroundQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/SurroundQParserPlugin.java",
                "patch": "@@ -42,7 +42,7 @@\n  */\n \n public class SurroundQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"surround\";\n+  public static final String NAME = \"surround\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SurroundQParserPlugin.java",
                "sha": "ab091f6b18fe494ad05cf2792514e6daf1c0b3f7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SwitchQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/SwitchQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/SwitchQParserPlugin.java",
                "patch": "@@ -135,7 +135,7 @@\n  * &lt;/requestHandler&gt;</pre>\n  */\n public class SwitchQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"switch\";\n+  public static final String NAME = \"switch\";\n \n   /** \n    * Used as both a local params key to find the \"default\" if no",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/SwitchQParserPlugin.java",
                "sha": "8f3944849cf81f5560598bd2bad09336ce2d58df",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/TermQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/TermQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/TermQParserPlugin.java",
                "patch": "@@ -41,7 +41,7 @@\n  * <br>Example: <code>{!term f=weight}1.5</code>\n  */\n public class TermQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"term\";\n+  public static final String NAME = \"term\";\n \n   @Override\n   public void init(NamedList args) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/TermQParserPlugin.java",
                "sha": "5b81943e947a7ec9488599876af506a754ffc520",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/join/BlockJoinChildQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/join/BlockJoinChildQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/join/BlockJoinChildQParserPlugin.java",
                "patch": "@@ -26,7 +26,7 @@\n  *\n  **/\n public class BlockJoinChildQParserPlugin extends BlockJoinParentQParserPlugin {\n-  public static String NAME = \"child\";\n+  public static final String NAME = \"child\";\n \n   @Override\n   protected QParser createBJQParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/join/BlockJoinChildQParserPlugin.java",
                "sha": "3edcaabe02b680834c03b234b3a7f335be0d379f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParserPlugin.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParserPlugin.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParserPlugin.java",
                "patch": "@@ -28,7 +28,7 @@\n  *\n  **/\n public class BlockJoinParentQParserPlugin extends QParserPlugin {\n-  public static String NAME = \"parent\";\n+  public static final String NAME = \"parent\";\n \n   @Override\n   public QParser createParser(String qstr, SolrParams localParams, SolrParams params, SolrQueryRequest req) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParserPlugin.java",
                "sha": "14813bcff36b0264dcbcd92b52bee8871022d372",
                "status": "modified"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test-files/solr/collection1/conf/solrconfig-query-parser-init.xml",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/solrconfig-query-parser-init.xml?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/solrconfig-query-parser-init.xml",
                "patch": "@@ -0,0 +1,31 @@\n+<?xml version=\"1.0\" ?>\n+\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+\n+<!--\n+   Test Config for QParser init\n+  -->\n+<config>\n+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>\n+  <xi:include href=\"solrconfig.snippet.randomindexconfig.xml\" xmlns:xi=\"http://www.w3.org/2001/XInclude\"/>\n+  <requestHandler name=\"standard\" class=\"solr.StandardRequestHandler\"></requestHandler>\n+  <directoryFactory name=\"DirectoryFactory\" class=\"${solr.directoryFactory:solr.RAMDirectoryFactory}\"/>\n+  <!-- query parser without final NAME field lead to NPE during query parser initialization-->\n+  <queryParser name=\"fail\" class=\"solr.search.LuceneQParserPlugin\"/>\n+\n+</config>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test-files/solr/collection1/conf/solrconfig-query-parser-init.xml",
                "sha": "e98de695c3b466b0d2d272a57a2eac215af3a663",
                "status": "added"
            },
            {
                "additions": 63,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test/org/apache/solr/search/TestInitQParser.java",
                "changes": 63,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/TestInitQParser.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/search/TestInitQParser.java",
                "patch": "@@ -0,0 +1,63 @@\n+package org.apache.solr.search;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Checking QParser plugin initialization, failing with NPE during Solr startup.\n+ * Ensures that query is working by registered in solrconfig.xml \"fail\" query parser.\n+ */\n+public class TestInitQParser extends SolrTestCaseJ4 {\n+  private static void createIndex() {\n+    String v;\n+    v = \"how now brown cow\";\n+    assertU(adoc(\"id\", \"1\", \"text\", v, \"text_np\", v));\n+    v = \"now cow\";\n+    assertU(adoc(\"id\", \"2\", \"text\", v, \"text_np\", v));\n+    assertU(adoc(\"id\", \"3\", \"foo_s\", \"a ' \\\" \\\\ {! ) } ( { z\"));  // A value filled with special chars\n+\n+    assertU(adoc(\"id\", \"10\", \"qqq_s\", \"X\"));\n+    assertU(adoc(\"id\", \"11\", \"www_s\", \"X\"));\n+    assertU(adoc(\"id\", \"12\", \"eee_s\", \"X\"));\n+    assertU(adoc(\"id\", \"13\", \"eee_s\", \"'balance'\"));\n+\n+    assertU(commit());\n+\n+  }\n+\n+  @Override\n+  @Before\n+  public void setUp() throws Exception {\n+    super.setUp();\n+    System.setProperty(\"enable.update.log\", \"false\"); // schema12 doesn't support _version_\n+    initCore(\"solrconfig-query-parser-init.xml\", \"schema12.xml\");\n+    createIndex();\n+  }\n+\n+  @Test\n+  public void testQueryParserInit() throws Exception {\n+    // should query using registered fail (defType=fail) QParser and match only one doc\n+    assertQ(req(\"q\", \"id:1\", \"indent\", \"true\", \"defType\", \"fail\")\n+        , \"//*[@numFound='1']\"\n+    );\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test/org/apache/solr/search/TestInitQParser.java",
                "sha": "651a2c53e527eab98f6d70ef955d858ba152f478",
                "status": "added"
            },
            {
                "additions": 108,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test/org/apache/solr/search/TestStandardQParsers.java",
                "changes": 108,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/search/TestStandardQParsers.java?ref=ab768b83b0e6a8064f7f3dfd422c1c09313d068a",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/search/TestStandardQParsers.java",
                "patch": "@@ -0,0 +1,108 @@\n+package org.apache.solr.search;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.lucene.util.LuceneTestCase;\n+import org.junit.Test;\n+\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Check standard query parsers for class loading problems during initialization (NAME field is final and static).\n+ * Because every query plugin extend {@link org.apache.solr.search.QParserPlugin} and contains own instance of {@link org.apache.solr.search.QParserPlugin#standardPlugins},\n+ * There are a cyclic dependencies of static fields between plugins and order of initialization can be wrong if NAME field is not final.\n+ * This leads to NPEs during Solr startup.\n+ * @see <a href=\"https://issues.apache.org/jira/browse/SOLR-5526\">SOLR-5526</a>\n+ * @see org.apache.solr.search.QParserPlugin#standardPlugins\n+ *\n+ */\n+public class TestStandardQParsers extends LuceneTestCase {\n+  /**\n+   * Field name of constant mandatory for query parser plugin.\n+   */\n+  public static final String FIELD_NAME = \"NAME\";\n+\n+  /**\n+   * Test standard query parsers registered in {@link org.apache.solr.search.QParserPlugin#standardPlugins}\n+   * have NAME field which is final, static, and matches the registered name.\n+   */\n+  @Test\n+  public void testRegisteredName() throws Exception {\n+    Map<String, Class<QParserPlugin>> standardPlugins = getStandardQParsers();\n+\n+    List<String> notStatic = new ArrayList<String>(standardPlugins.size());\n+    List<String> notFinal = new ArrayList<String>(standardPlugins.size());\n+    List<String> mismatch = new ArrayList<String>(standardPlugins.size());\n+ \n+    for (Map.Entry<String,Class<QParserPlugin>> pair : standardPlugins.entrySet()) {\n+      String regName = pair.getKey();\n+      Class<QParserPlugin> clazz = pair.getValue();\n+\n+      Field nameField = clazz.getField(FIELD_NAME);\n+      int modifiers = nameField.getModifiers();\n+      if (!Modifier.isFinal(modifiers)) {\n+        notFinal.add(clazz.getName());\n+      }\n+      if (!Modifier.isStatic(modifiers)) {\n+        notStatic.add(clazz.getName());\n+      } else if (! regName.equals(nameField.get(null))) {\n+        mismatch.add(regName +\" != \"+ nameField.get(null) +\"(\"+ clazz.getName() +\")\");\n+      }\n+    }\n+\n+    assertTrue(\"All standard QParsers must have final NAME, broken: \" + notFinal, \n+               notFinal.isEmpty());\n+    assertTrue(\"All standard QParsers must have static NAME, broken: \" + notStatic, \n+               notStatic.isEmpty());\n+    assertTrue(\"All standard QParsers must be registered using NAME, broken: \" + mismatch, \n+               mismatch.isEmpty());\n+\n+    assertTrue(\"DEFAULT_QTYPE is not in the standard set of registered names: \" + \n+               QParserPlugin.DEFAULT_QTYPE,\n+               standardPlugins.keySet().contains(QParserPlugin.DEFAULT_QTYPE));\n+\n+  }\n+\n+  /**\n+   * Get standard query parsers registered by default.\n+   *\n+   * @see org.apache.solr.search.QParserPlugin#standardPlugins\n+   * @return Map of classes extending QParserPlugin keyed by the registered name\n+   */\n+  private Map<String,Class<QParserPlugin>> getStandardQParsers() {\n+    Object[] standardPluginsValue = QParserPlugin.standardPlugins;\n+\n+    Map<String, Class<QParserPlugin>> standardPlugins \n+      = new HashMap<String, Class<QParserPlugin>>(standardPluginsValue.length / 2);\n+\n+    for (int i = 0; i < standardPluginsValue.length; i += 2) {\n+      @SuppressWarnings(\"unchecked\")\n+      String registeredName = (String) standardPluginsValue[i];\n+      @SuppressWarnings(\"unchecked\")\n+      Class<QParserPlugin> clazz = (Class<QParserPlugin>) standardPluginsValue[i + 1];\n+      standardPlugins.put(registeredName, clazz);\n+    }\n+    return standardPlugins;\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ab768b83b0e6a8064f7f3dfd422c1c09313d068a/solr/core/src/test/org/apache/solr/search/TestStandardQParsers.java",
                "sha": "3a74e6731ad8c5f88ff901b56b06e59f22afeeb7",
                "status": "added"
            }
        ],
        "message": "SOLR-5526: Fixed NPE that could arrise when explicitly configuring some built in QParserPlugins\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1564588 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/178ec39037078373dc35a95c5734cf5f4780876d",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSimpleQParserPlugin.java"
        ]
    },
    "lucene-solr_b007152": {
        "bug_id": "lucene-solr_b007152",
        "commit": "https://github.com/apache/lucene-solr/commit/b007152303cba90a5819075d711fc8e9a0c4b4e7",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/common/org/apache/solr/common/params/CoreAdminParams.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/common/org/apache/solr/common/params/CoreAdminParams.java?ref=b007152303cba90a5819075d711fc8e9a0c4b4e7",
                "deletions": 1,
                "filename": "src/common/org/apache/solr/common/params/CoreAdminParams.java",
                "patch": "@@ -55,7 +55,7 @@\n   \n   /** If you merge indexes, what are the index directories.\n    * The directories are separated by \",\". */\n-  public final static String INDEX_DIRS = \"indexDirs\";\n+  public final static String INDEX_DIR = \"indexDir\";\n \n   public enum CoreAdminAction {\n     STATUS,  ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/common/org/apache/solr/common/params/CoreAdminParams.java",
                "sha": "4c69eaa720521b4782b95705639231a985784b90",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java?ref=b007152303cba90a5819075d711fc8e9a0c4b4e7",
                "deletions": 3,
                "filename": "src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "patch": "@@ -31,6 +31,7 @@\n import org.apache.solr.handler.RequestHandlerBase;\n import org.apache.solr.request.SolrQueryRequest;\n import org.apache.solr.request.SolrQueryResponse;\n+import org.apache.solr.request.LocalSolrQueryRequest;\n import org.apache.solr.search.SolrIndexSearcher;\n import org.apache.solr.util.RefCounted;\n import org.apache.solr.update.MergeIndexesCommand;\n@@ -177,8 +178,7 @@ protected boolean handleMergeAction(SolrQueryRequest req, SolrQueryResponse rsp)\n       try {\n         doPersist = coreContainer.isPersistent();\n \n-        String p = required.get(CoreAdminParams.INDEX_DIRS);\n-        String[] dirNames = p.split(\",\");\n+        String[] dirNames = required.getParams(CoreAdminParams.INDEX_DIR);\n \n         DirectoryFactory dirFactory = core.getDirectoryFactory();\n         Directory[] dirs = new Directory[dirNames.length];\n@@ -188,8 +188,9 @@ protected boolean handleMergeAction(SolrQueryRequest req, SolrQueryResponse rsp)\n \n         UpdateRequestProcessorChain processorChain =\n                 core.getUpdateProcessingChain(params.get(UpdateParams.UPDATE_PROCESSOR));\n+        SolrQueryRequest wrappedReq = new LocalSolrQueryRequest(core, req.getParams());\n         UpdateRequestProcessor processor =\n-                processorChain.createProcessor(req, rsp);\n+                processorChain.createProcessor(wrappedReq, rsp);\n         processor.processMergeIndexes(new MergeIndexesCommand(dirs));\n       } finally {\n         core.close();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "sha": "7c7e00d889f86a7451a0cb98ceda57b05fad32dd",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/solrj/org/apache/solr/client/solrj/request/CoreAdminRequest.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/solrj/org/apache/solr/client/solrj/request/CoreAdminRequest.java?ref=b007152303cba90a5819075d711fc8e9a0c4b4e7",
                "deletions": 15,
                "filename": "src/solrj/org/apache/solr/client/solrj/request/CoreAdminRequest.java",
                "patch": "@@ -19,6 +19,8 @@\n \n import java.io.IOException;\n import java.util.Collection;\n+import java.util.List;\n+import java.util.Arrays;\n \n import org.apache.solr.client.solrj.SolrRequest;\n import org.apache.solr.client.solrj.SolrServer;\n@@ -110,17 +112,17 @@ public SolrParams getParams() {\n   }\n   \n   public static class MergeIndexes extends CoreAdminRequest {\n-    protected String indexDirs;\n+    protected List<String> indexDirs;\n \n     public MergeIndexes() {\n       action = CoreAdminAction.MERGEINDEXES;\n     }\n \n-    public void setIndexDirs(String indexDirs) {\n+    public void setIndexDirs(List<String> indexDirs) {\n       this.indexDirs = indexDirs;\n     }\n \n-    public String getIndexDirs() {\n+    public List<String> getIndexDirs() {\n       return indexDirs;\n     }\n \n@@ -132,7 +134,11 @@ public SolrParams getParams() {\n       ModifiableSolrParams params = new ModifiableSolrParams();\n       params.set(CoreAdminParams.ACTION, action.toString());\n       params.set(CoreAdminParams.CORE, core);\n-      params.set(CoreAdminParams.INDEX_DIRS, indexDirs);\n+      if (indexDirs != null)  {\n+        for (String indexDir : indexDirs) {\n+          params.set(CoreAdminParams.INDEX_DIR, indexDir);\n+        }\n+      }\n       return params;\n     }\n   }\n@@ -281,17 +287,7 @@ public static CoreAdminResponse mergeIndexes(String name,\n       IOException {\n     CoreAdminRequest.MergeIndexes req = new CoreAdminRequest.MergeIndexes();\n     req.setCoreName(name);\n-    String p = null;\n-    if (indexDirs.length == 1) {\n-      p = indexDirs[0];\n-    } else if (indexDirs.length > 1) {\n-      StringBuilder s = new StringBuilder(indexDirs[0]);\n-      for (int i = 1; i < indexDirs.length; i++) {\n-        s.append(\",\").append(indexDirs[i]);\n-      }\n-      p = s.toString();\n-    }\n-    req.setIndexDirs(p);\n+    req.setIndexDirs(Arrays.asList(indexDirs));\n     return req.process(server);\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b007152303cba90a5819075d711fc8e9a0c4b4e7/src/solrj/org/apache/solr/client/solrj/request/CoreAdminRequest.java",
                "sha": "11d7e8b25c61b3da4aa235d1b1c47f4aee6de6ed",
                "status": "modified"
            }
        ],
        "message": "SOLR-1051 -- Fix NPE and change comma separated indexDirs parameter to multiple indexDir parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@781688 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/fa807c01d76eef4e1452b15cd0ebf981119d9121",
        "repo": "lucene-solr",
        "unit_tests": [
            "CoreAdminHandlerTest.java"
        ]
    },
    "lucene-solr_b00f109": {
        "bug_id": "lucene-solr_b00f109",
        "commit": "https://github.com/apache/lucene-solr/commit/b00f10916bfdcd1bdf138ba46a8204091e0bb428",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=b00f10916bfdcd1bdf138ba46a8204091e0bb428",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -265,6 +265,8 @@ Other Changes\n \n * SOLR-8385: Narrow StreamFactory.withFunctionName clazz parameter to prevent misconfiguration (Jason Gerlowski, Kevin Risden)\n \n+* SOLR-8969: SQLHandler causes NPE in non-cloud mode (Markus Jelsma, Kevin Risden)\n+\n ==================  6.2.1 ==================\n \n Bug Fixes",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/CHANGES.txt",
                "sha": "27939d6381a010810fef3316fde3ac18251fc324",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/SQLHandler.java?ref=b00f10916bfdcd1bdf138ba46a8204091e0bb428",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "patch": "@@ -88,6 +88,7 @@\n   }\n \n   private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+  static final String sqlNonCloudErrorMsg = \"/sql handler only works in Solr Cloud mode\";\n \n   public void inform(SolrCore core) {\n \n@@ -111,7 +112,7 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n     String sql = params.get(\"stmt\");\n     int numWorkers = params.getInt(\"numWorkers\", 1);\n     String workerCollection = params.get(\"workerCollection\", defaultWorkerCollection);\n-    String workerZkhost = params.get(\"workerZkhost\",defaultZkhost);\n+    String workerZkhost = params.get(\"workerZkhost\", defaultZkhost);\n     String mode = params.get(\"aggregationMode\", \"map_reduce\");\n     StreamContext context = new StreamContext();\n \n@@ -120,6 +121,10 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw\n \n     try {\n \n+      if(workerZkhost == null) {\n+        throw new IllegalStateException(sqlNonCloudErrorMsg);\n+      }\n+\n       if(sql == null) {\n         throw new Exception(\"stmt parameter cannot be null\");\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/core/src/java/org/apache/solr/handler/SQLHandler.java",
                "sha": "5fcf93828e37f957a74e6aa3d46d5ead5e26f699",
                "status": "modified"
            },
            {
                "additions": 92,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/core/src/test/org/apache/solr/handler/TestSQLHandlerNonCloud.java",
                "changes": 92,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/TestSQLHandlerNonCloud.java?ref=b00f10916bfdcd1bdf138ba46a8204091e0bb428",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/TestSQLHandlerNonCloud.java",
                "patch": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.handler;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.solr.SolrJettyTestBase;\n+import org.apache.solr.client.solrj.io.Tuple;\n+import org.apache.solr.client.solrj.io.stream.SolrStream;\n+import org.apache.solr.client.solrj.io.stream.TupleStream;\n+import org.apache.solr.common.params.CommonParams;\n+import org.apache.solr.common.params.ModifiableSolrParams;\n+import org.apache.solr.common.params.SolrParams;\n+import org.apache.solr.common.util.IOUtils;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public class TestSQLHandlerNonCloud extends SolrJettyTestBase {\n+\n+  private static File createSolrHome() throws Exception {\n+    File workDir = createTempDir().toFile();\n+    setupJettyTestHome(workDir, DEFAULT_TEST_COLLECTION_NAME);\n+    return workDir;\n+  }\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    File solrHome = createSolrHome();\n+    solrHome.deleteOnExit();\n+    createJetty(solrHome.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void testSQLHandler() throws Exception {\n+    String sql = \"select id, field_i, str_s from \" + DEFAULT_TEST_COLLECTION_NAME + \" limit 10\";\n+    SolrParams sParams = mapParams(CommonParams.QT, \"/sql\", \"stmt\", sql);\n+    String url = jetty.getBaseUrl() + \"/\" + DEFAULT_TEST_COLLECTION_NAME;\n+\n+    SolrStream solrStream = new SolrStream(url, sParams);\n+    try {\n+      getTuples(solrStream);\n+      fail(SQLHandler.sqlNonCloudErrorMsg);\n+    } catch (IOException e) {\n+      assertTrue(e.getMessage().contains(SQLHandler.sqlNonCloudErrorMsg));\n+    }\n+  }\n+\n+  private List<Tuple> getTuples(TupleStream tupleStream) throws IOException {\n+    List<Tuple> tuples = new ArrayList<>();\n+    try {\n+      tupleStream.open();\n+      for (; ; ) {\n+        Tuple t = tupleStream.read();\n+        if (t.EOF) {\n+          break;\n+        } else {\n+          tuples.add(t);\n+        }\n+      }\n+    } finally {\n+      IOUtils.closeQuietly(tupleStream);\n+    }\n+    return tuples;\n+  }\n+\n+  public static SolrParams mapParams(String... vals) {\n+    ModifiableSolrParams params = new ModifiableSolrParams();\n+    assertEquals(\"Parameters passed in here must be in pairs!\", 0, (vals.length % 2));\n+    for (int idx = 0; idx < vals.length; idx += 2) {\n+      params.add(vals[idx], vals[idx + 1]);\n+    }\n+\n+    return params;\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b00f10916bfdcd1bdf138ba46a8204091e0bb428/solr/core/src/test/org/apache/solr/handler/TestSQLHandlerNonCloud.java",
                "sha": "8623290844d2ecca6835c5376cc7c2ff13c4e99d",
                "status": "added"
            }
        ],
        "message": "SOLR-8969: Resolve NPE for SQLHandler when in non-cloud mode",
        "parent": "https://github.com/apache/lucene-solr/commit/d25aba2336fe8e7e2a831ccceb6635eb8881cf0f",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSQLHandler.java"
        ]
    },
    "lucene-solr_b3241a2": {
        "bug_id": "lucene-solr_b3241a2",
        "commit": "https://github.com/apache/lucene-solr/commit/b3241a23b34ebfa633766e6a6a31e831ba653fd2",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b3241a23b34ebfa633766e6a6a31e831ba653fd2/solr/solrj/src/java/org/apache/solr/client/solrj/util/ClientUtils.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/util/ClientUtils.java?ref=b3241a23b34ebfa633766e6a6a31e831ba653fd2",
                "deletions": 10,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/util/ClientUtils.java",
                "patch": "@@ -23,13 +23,7 @@\n import java.net.URLEncoder;\n import java.text.DateFormat;\n import java.text.ParseException;\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.Date;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.TimeZone;\n+import java.util.*;\n import java.util.Map.Entry;\n import java.nio.ByteBuffer;\n \n@@ -231,9 +225,13 @@ public static String toQueryString( SolrParams params, boolean xml ) {\n   }\n   \n   public static void appendMap(String collection, Map<String,Slice> map1, Map<String,Slice> map2) {\n-    Set<Entry<String,Slice>> entrySet = map2.entrySet();\n-    for (Entry<String,Slice> entry : entrySet) {\n-      map1.put(collection + \"_\" + entry.getKey(), entry.getValue());\n+    if (map1==null)\n+      map1 = new HashMap<String,Slice>();\n+    if (map2!=null) {\n+      Set<Entry<String,Slice>> entrySet = map2.entrySet();\n+      for (Entry<String,Slice> entry : entrySet) {\n+        map1.put(collection + \"_\" + entry.getKey(), entry.getValue());\n+      }\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b3241a23b34ebfa633766e6a6a31e831ba653fd2/solr/solrj/src/java/org/apache/solr/client/solrj/util/ClientUtils.java",
                "sha": "6353e8332a2e43fed43253c70c253cc413186522",
                "status": "modified"
            }
        ],
        "message": "[SOLR-3396] - avoid NPEs on appendMap method\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1329640 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/b91898b5df905754324d7e274c41775b70c439ee",
        "repo": "lucene-solr",
        "unit_tests": [
            "ClientUtilsTest.java"
        ]
    },
    "lucene-solr_b5db48c": {
        "bug_id": "lucene-solr_b5db48c",
        "commit": "https://github.com/apache/lucene-solr/commit/b5db48c783e9d0dc19c087101f03d8834b201106",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=b5db48c783e9d0dc19c087101f03d8834b201106",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -484,6 +484,10 @@ Bug Fixes\n   high frequency terms in extremely large indices (Robert Muir, Mike\n   McCandless)\n \n+* LUCENE-6093: Don't throw NullPointerException from\n+  BlendedInfixSuggester for lookups that do not end in a prefix\n+  token.  (jane chang via Mike McCandless)\n+\n Documentation\n \n * LUCENE-5392: Add/improve analysis package documentation to reflect",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/CHANGES.txt",
                "sha": "e2d711cf4a73af60f651000cfa69c41edbc9ee7b",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java?ref=b5db48c783e9d0dc19c087101f03d8834b201106",
                "deletions": 1,
                "filename": "lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java",
                "patch": "@@ -576,7 +576,11 @@ protected Query getLastTokenQuery(String token) throws IOException {\n \n   /**\n    * Create the results based on the search hits.\n-   * Can be overridden by subclass to add particular behavior (e.g. weight transformation)\n+   * Can be overridden by subclass to add particular behavior (e.g. weight transformation).\n+   * Note that there is no prefix toke (the {@code prefixToken} argument will\n+   * be null) whenever the final token in the incoming request was in fact finished\n+   * (had trailing characters, such as white-space).\n+   *\n    * @throws IOException If there are problems reading fields from the underlying Lucene index.\n    */\n   protected List<LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num,",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java",
                "sha": "b38d54d7a4fea98d8bd14b929e7f66ac7b501794",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java?ref=b5db48c783e9d0dc19c087101f03d8834b201106",
                "deletions": 2,
                "filename": "lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java",
                "patch": "@@ -261,8 +261,8 @@ private double createCoefficient(IndexSearcher searcher, int doc, Set<String> ma\n \n       String docTerm = term.utf8ToString();\n \n-      if (matchedTokens.contains(docTerm) || docTerm.startsWith(prefixToken)) {\n-\n+      if (matchedTokens.contains(docTerm) || (prefixToken != null && docTerm.startsWith(prefixToken))) {\n+ \n         DocsAndPositionsEnum docPosEnum = it.docsAndPositions(null, null, DocsAndPositionsEnum.FLAG_OFFSETS);\n         docPosEnum.nextDoc();\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester.java",
                "sha": "e49a88691eb1c917aff0e2a36bf338886d4c4c08",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java?ref=b5db48c783e9d0dc19c087101f03d8834b201106",
                "deletions": 0,
                "filename": "lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java",
                "patch": "@@ -165,6 +165,33 @@ public void testRequiresMore() throws IOException {\n     suggester.close();\n   }\n \n+  /**\n+   * Handle trailing spaces that result in no prefix token LUCENE-6093\n+   */\n+  public void testNullPrefixToken() throws IOException {\n+\n+    BytesRef payload = new BytesRef(\"lake\");\n+\n+    Input keys[] = new Input[]{\n+        new Input(\"top of the lake\", 8, payload)\n+    };\n+\n+    Path tempDir = createTempDir(\"BlendedInfixSuggesterTest\");\n+\n+    Analyzer a = new StandardAnalyzer(CharArraySet.EMPTY_SET);\n+    BlendedInfixSuggester suggester = new BlendedInfixSuggester(newFSDirectory(tempDir), a, a,\n+                                                                AnalyzingInfixSuggester.DEFAULT_MIN_PREFIX_CHARS,\n+                                                                BlendedInfixSuggester.BlenderType.POSITION_LINEAR,\n+                                                                BlendedInfixSuggester.DEFAULT_NUM_FACTOR, false);\n+    suggester.build(new InputArrayIterator(keys));\n+\n+    getInResults(suggester, \"of \", payload, 1);\n+    getInResults(suggester, \"the \", payload, 1);\n+    getInResults(suggester, \"lake \", payload, 1);\n+\n+    suggester.close();\n+  }\n+\n   public void /*testT*/rying() throws IOException {\n \n     BytesRef lake = new BytesRef(\"lake\");",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b5db48c783e9d0dc19c087101f03d8834b201106/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggesterTest.java",
                "sha": "cb22d36a8ac5bd98769ad9e0bfe6ec1aef6f42d8",
                "status": "modified"
            }
        ],
        "message": "LUCENE-6093: don't throw NPE when BlendedInfixSuggester.lookup doesn't have a prefix token\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1656173 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/a705371bfce8227f8aa24c152f133330437afae4",
        "repo": "lucene-solr",
        "unit_tests": [
            "AnalyzingInfixSuggesterTest.java",
            "BlendedInfixSuggesterTest.java"
        ]
    },
    "lucene-solr_b7f99fe": {
        "bug_id": "lucene-solr_b7f99fe",
        "commit": "https://github.com/apache/lucene-solr/commit/b7f99fe55a6fb6e7b38828676750b3512d6899a1",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b7f99fe55a6fb6e7b38828676750b3512d6899a1/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=b7f99fe55a6fb6e7b38828676750b3512d6899a1",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -247,6 +247,8 @@ Bug Fixes\n * SOLR-13053: NodeAddedTrigger and NodeLostTrigger do not reserve added/removed time populated by restoreState\n   (Cao Manh Dat)\n \n+* SOLR-13137: NPE when /admin/zookeeper/status endpoint hit in standalone mode (janhoy)\n+\n Improvements\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b7f99fe55a6fb6e7b38828676750b3512d6899a1/solr/CHANGES.txt",
                "sha": "8aa752776294974ef25cc9779fc4bbf9dd038405",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/b7f99fe55a6fb6e7b38828676750b3512d6899a1/solr/core/src/java/org/apache/solr/handler/admin/ZookeeperStatusHandler.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/ZookeeperStatusHandler.java?ref=b7f99fe55a6fb6e7b38828676750b3512d6899a1",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/ZookeeperStatusHandler.java",
                "patch": "@@ -32,7 +32,6 @@\n import java.util.stream.Collectors;\n \n import org.apache.solr.common.SolrException;\n-import org.apache.solr.common.params.SolrParams;\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.core.CoreContainer;\n import org.apache.solr.handler.RequestHandlerBase;\n@@ -73,10 +72,12 @@ public Category getCategory() {\n \n   @Override\n   public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception {\n-    final SolrParams params = req.getParams();\n-    Map<String, String> map = new HashMap<>(1);\n     NamedList values = rsp.getValues();\n-    values.add(\"zkStatus\", getZkStatus(cores.getZkController().getZkServerAddress()));\n+    if (cores.isZooKeeperAware()) {\n+      values.add(\"zkStatus\", getZkStatus(cores.getZkController().getZkServerAddress()));\n+    } else {\n+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The Zookeeper status API is only available in Cloud mode\");\n+    }\n   }\n \n   /*",
                "raw_url": "https://github.com/apache/lucene-solr/raw/b7f99fe55a6fb6e7b38828676750b3512d6899a1/solr/core/src/java/org/apache/solr/handler/admin/ZookeeperStatusHandler.java",
                "sha": "1f3a50401aab71accb6af49f572a0d56249c9ae7",
                "status": "modified"
            }
        ],
        "message": "SOLR-13137: NPE when /admin/zookeeper/status endpoint hit in standalone mode",
        "parent": "https://github.com/apache/lucene-solr/commit/d4e016afdf41baf0104f79e82d953a4650df42aa",
        "repo": "lucene-solr",
        "unit_tests": [
            "ZookeeperStatusHandlerTest.java"
        ]
    },
    "lucene-solr_bc6a8d9": {
        "bug_id": "lucene-solr_bc6a8d9",
        "commit": "https://github.com/apache/lucene-solr/commit/bc6a8d9fff38c1fa303626d8169ea0229be8ce18",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/bc6a8d9fff38c1fa303626d8169ea0229be8ce18/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=bc6a8d9fff38c1fa303626d8169ea0229be8ce18",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -139,6 +139,9 @@ Bug Fixes\n \n * SOLR-7920: Resolve XSS issue in Admin UI Schema Browser (David Chiu via Upayavira)\n \n+* SOLR-7935: Fix very rare race condition that can cause an update to fail\n+  via NullPointerException during a core reload. (yonik)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/bc6a8d9fff38c1fa303626d8169ea0229be8ce18/solr/CHANGES.txt",
                "sha": "581365ede3bb1b32b47c3c6acfa4294c92fae9b3",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/bc6a8d9fff38c1fa303626d8169ea0229be8ce18/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/core/SolrCore.java?ref=bc6a8d9fff38c1fa303626d8169ea0229be8ce18",
                "deletions": 3,
                "filename": "solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "patch": "@@ -1584,8 +1584,8 @@ public UpdateHandler getUpdateHandler() {\n \n         // SolrCore.verbose(\"start reopen from\",previousSearcher,\"writer=\",writer);\n \n-        RefCounted<IndexWriter> writer = getUpdateHandler().getSolrCoreState()\n-            .getIndexWriter(null);\n+        RefCounted<IndexWriter> writer = getSolrCoreState().getIndexWriter(null);\n+\n         try {\n           if (writer != null) {\n             // if in NRT mode, open from the writer\n@@ -1639,7 +1639,7 @@ public UpdateHandler getUpdateHandler() {\n           tmp = new SolrIndexSearcher(this, newIndexDir, getLatestSchema(),\n               (realtime ? \"realtime\":\"main\"), newReader, true, !realtime, true, directoryFactory);\n         } else  {\n-          RefCounted<IndexWriter> writer = getUpdateHandler().getSolrCoreState().getIndexWriter(this);\n+          RefCounted<IndexWriter> writer = getSolrCoreState().getIndexWriter(this);\n           DirectoryReader newReader = null;\n           try {\n             newReader = indexReaderFactory.newReader(writer.get(), this);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/bc6a8d9fff38c1fa303626d8169ea0229be8ce18/solr/core/src/java/org/apache/solr/core/SolrCore.java",
                "sha": "80707cb21ad5246e2dbc71c5502c09bf827064f3",
                "status": "modified"
            }
        ],
        "message": "SOLR-7935:fix race that can cause a NPE in openNewSearcher called from an update concurrent with a core reload\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1696417 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/3109c453bb01ee33b965538a6cfb2428212efa62",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrCoreTest.java"
        ]
    },
    "lucene-solr_c186cbf": {
        "bug_id": "lucene-solr_c186cbf",
        "commit": "https://github.com/apache/lucene-solr/commit/c186cbfcbc4bf838d0756892c9710b1a67883590",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/CHANGES.txt",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=c186cbfcbc4bf838d0756892c9710b1a67883590",
                "deletions": 6,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -319,6 +319,10 @@ Bug Fixes\n * SOLR-6626: NPE in FieldMutatingUpdateProcessor when indexing a doc with\n   null field value (Noble Paul)\n \n+* SOLR-6604: SOLR-6812: Fix NPE with distrib.singlePass=true and expand\n+  component. Increased test coverage of expand component with docValues.\n+  (Christine Poerschke, Per Steffensen, shalin)\n+\n Optimizations\n ----------------------\n \n@@ -484,12 +488,6 @@ Other Changes\n   the example directory instead of server/solr. (Alexandre Rafalovitch, Anshum Gupta, hossman,\n   Timothy Potter)\n \n-* SOLR-6843: JMX RMI connector should be disabled by default but can be activated by\n-  setting ENABLE_REMOTE_JMX_OPTS to true in solr.in.(sh|cmd). (Timothy Potter)\n-  \n-* SOLR-6844: Rename ConfigSolr.getZkHostPort(), which actually returns the Solr port,\n-  to .getSolrHostPort().  (Martijn Koster, Steve Rowe)\n-\n ==================  4.10.3 ==================\n \n Bug Fixes",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/CHANGES.txt",
                "sha": "6bcf9be3f7f30a5b164c7216b3977f82b5a073be",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java?ref=c186cbfcbc4bf838d0756892c9710b1a67883590",
                "deletions": 9,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "patch": "@@ -86,6 +86,7 @@\n  */\n public class ExpandComponent extends SearchComponent implements PluginInfoInitialized, SolrCoreAware {\n   public static final String COMPONENT_NAME = \"expand\";\n+  private static final int finishingStage = ResponseBuilder.STAGE_GET_FIELDS;\n   private PluginInfo info = PluginInfo.EMPTY_INFO;\n \n   @Override\n@@ -116,13 +117,6 @@ public void process(ResponseBuilder rb) throws IOException {\n     SolrQueryRequest req = rb.req;\n     SolrParams params = req.getParams();\n \n-    boolean isShard = params.getBool(ShardParams.IS_SHARD, false);\n-    String ids = params.get(ShardParams.IDS);\n-\n-    if (ids == null && isShard) {\n-      return;\n-    }\n-\n     String field = params.get(ExpandParams.EXPAND_FIELD);\n     if (field == null) {\n       List<Query> filters = rb.getFilters();\n@@ -246,9 +240,23 @@ public void process(ResponseBuilder rb) throws IOException {\n     rb.rsp.add(\"expanded\", outMap);\n   }\n \n+  @Override\n+  public int distributedProcess(ResponseBuilder rb) throws IOException {\n+    if (rb.doExpand && rb.stage < finishingStage) {\n+      return finishingStage;\n+    }\n+    return ResponseBuilder.STAGE_DONE;\n+  }\n+    \n   @Override\n   public void modifyRequest(ResponseBuilder rb, SearchComponent who, ShardRequest sreq) {\n-\n+    SolrParams params = rb.req.getParams();\n+    if (!params.getBool(COMPONENT_NAME, false)) return;\n+    if (!rb.onePassDistributedQuery && (sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) == 0) {\n+      sreq.params.set(COMPONENT_NAME, \"false\");\n+    } else {\n+      sreq.params.set(COMPONENT_NAME, \"true\");\n+    }\n   }\n \n   @SuppressWarnings(\"unchecked\")\n@@ -286,7 +294,7 @@ public void finishStage(ResponseBuilder rb) {\n       return;\n     }\n \n-    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n+    if (rb.stage != finishingStage) {\n       return;\n     }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java",
                "sha": "6b39a014c9b215d7f8e55bc272fb86070e841c08",
                "status": "modified"
            },
            {
                "additions": 62,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/test/org/apache/solr/handler/component/DistributedExpandComponentTest.java",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedExpandComponentTest.java?ref=c186cbfcbc4bf838d0756892c9710b1a67883590",
                "deletions": 21,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedExpandComponentTest.java",
                "patch": "@@ -50,20 +50,22 @@ public static void setUpBeforeClass() throws Exception {\n \n   @Override\n   public void doTest() throws Exception {\n+    final String group = (random().nextBoolean() ? \"group_s\" : \"group_s_dv\");\n+    \n     del(\"*:*\");\n \n-    index_specific(0,\"id\",\"1\", \"term_s\", \"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"5\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n-    index_specific(0,\"id\",\"2\", \"term_s\", \"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"50\", \"test_tl\", \"100\", \"test_tf\", \"200\");\n-    index_specific(1,\"id\",\"5\", \"term_s\", \"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"4\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n-    index_specific(1,\"id\",\"6\", \"term_s\", \"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"10\", \"test_tl\", \"100\", \"test_tf\", \"200\");\n-    index_specific(0,\"id\",\"7\", \"term_s\", \"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"1\",  \"test_tl\", \"100000\", \"test_tf\", \"2000\");\n-    index_specific(1,\"id\",\"8\", \"term_s\", \"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"2\",  \"test_tl\", \"100000\", \"test_tf\", \"200\");\n-    index_specific(2,\"id\",\"9\", \"term_s\", \"YYYY\", \"group_s\", \"group3\", \"test_ti\", \"1000\", \"test_tl\", \"1005\", \"test_tf\", \"3000\");\n-    index_specific(2, \"id\", \"10\", \"term_s\", \"YYYY\", \"group_s\", \"group3\", \"test_ti\", \"1500\", \"test_tl\", \"1001\", \"test_tf\", \"3200\");\n-    index_specific(2,\"id\", \"11\",  \"term_s\", \"YYYY\", \"group_s\", \"group3\", \"test_ti\", \"1300\", \"test_tl\", \"1002\", \"test_tf\", \"3300\");\n-    index_specific(1,\"id\",\"12\", \"term_s\", \"YYYY\", \"group_s\", \"group4\", \"test_ti\", \"15\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n-    index_specific(1,\"id\",\"13\", \"term_s\", \"YYYY\", \"group_s\", \"group4\", \"test_ti\", \"16\",  \"test_tl\", \"9\", \"test_tf\", \"2000\");\n-    index_specific(1,\"id\",\"14\", \"term_s\", \"YYYY\", \"group_s\", \"group4\", \"test_ti\", \"1\",  \"test_tl\", \"20\", \"test_tf\", \"2000\");\n+    index_specific(0,\"id\",\"1\", \"term_s\", \"YYYY\", group, \"group1\", \"test_ti\", \"5\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n+    index_specific(0,\"id\",\"2\", \"term_s\", \"YYYY\", group, \"group1\", \"test_ti\", \"50\", \"test_tl\", \"100\", \"test_tf\", \"200\");\n+    index_specific(1,\"id\",\"5\", \"term_s\", \"YYYY\", group, \"group2\", \"test_ti\", \"4\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n+    index_specific(1,\"id\",\"6\", \"term_s\", \"YYYY\", group, \"group2\", \"test_ti\", \"10\", \"test_tl\", \"100\", \"test_tf\", \"200\");\n+    index_specific(0,\"id\",\"7\", \"term_s\", \"YYYY\", group, \"group1\", \"test_ti\", \"1\",  \"test_tl\", \"100000\", \"test_tf\", \"2000\");\n+    index_specific(1,\"id\",\"8\", \"term_s\", \"YYYY\", group, \"group2\", \"test_ti\", \"2\",  \"test_tl\", \"100000\", \"test_tf\", \"200\");\n+    index_specific(2,\"id\",\"9\", \"term_s\", \"YYYY\", group, \"group3\", \"test_ti\", \"1000\", \"test_tl\", \"1005\", \"test_tf\", \"3000\");\n+    index_specific(2, \"id\", \"10\", \"term_s\", \"YYYY\", group, \"group3\", \"test_ti\", \"1500\", \"test_tl\", \"1001\", \"test_tf\", \"3200\");\n+    index_specific(2,\"id\", \"11\",  \"term_s\", \"YYYY\", group, \"group3\", \"test_ti\", \"1300\", \"test_tl\", \"1002\", \"test_tf\", \"3300\");\n+    index_specific(1,\"id\",\"12\", \"term_s\", \"YYYY\", group, \"group4\", \"test_ti\", \"15\",  \"test_tl\", \"10\", \"test_tf\", \"2000\");\n+    index_specific(1,\"id\",\"13\", \"term_s\", \"YYYY\", group, \"group4\", \"test_ti\", \"16\",  \"test_tl\", \"9\", \"test_tf\", \"2000\");\n+    index_specific(1,\"id\",\"14\", \"term_s\", \"YYYY\", group, \"group4\", \"test_ti\", \"1\",  \"test_tl\", \"20\", \"test_tf\", \"2000\");\n \n \n     commit();\n@@ -80,21 +82,21 @@ public void doTest() throws Exception {\n     handle.put(\"maxScore\", SKIPVAL);\n     handle.put(\"_version_\", SKIP);\n \n-    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"fl\",\"*,score\");\n-    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"fl\",\"*,score\");\n-    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n+    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"fl\",\"*,score\");\n+    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"fl\",\"*,score\");\n+    query(\"q\", \"*:*\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n     //Test no expand results\n-    query(\"q\", \"test_ti:5\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n+    query(\"q\", \"test_ti:5\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n     //Test zero results\n-    query(\"q\", \"test_ti:5434343\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n+    query(\"q\", \"test_ti:5434343\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"expand.sort\", \"test_tl desc\", \"expand.rows\", \"1\", \"fl\",\"*,score\");\n     //Test page 2\n-    query(\"q\", \"*:*\", \"start\",\"1\", \"rows\", \"1\", \"fq\", \"{!collapse field=group_s}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"fl\",\"*,score\");\n+    query(\"q\", \"*:*\", \"start\",\"1\", \"rows\", \"1\", \"fq\", \"{!collapse field=\"+group+\"}\", \"defType\", \"edismax\", \"bf\", \"field(test_ti)\", \"expand\", \"true\", \"fl\",\"*,score\");\n \n \n     //First basic test case.\n     ModifiableSolrParams params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -113,7 +115,7 @@ public void doTest() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -132,7 +134,7 @@ public void doTest() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -147,6 +149,45 @@ public void doTest() throws Exception {\n     assertExpandGroupCountAndOrder(\"group3\", 1, results, \"9.0\");\n     assertExpandGroupCountAndOrder(\"group4\", 1, results, \"14.0\");\n \n+\n+    //Test key-only fl\n+\n+    params = new ModifiableSolrParams();\n+    params.add(\"q\", \"*:*\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n+    params.add(\"defType\", \"edismax\");\n+    params.add(\"bf\", \"field(test_ti)\");\n+    params.add(\"expand\", \"true\");\n+    params.add(\"fl\", \"id\");\n+\n+    setDistributedParams(params);\n+    rsp = queryServer(params);\n+    results = rsp.getExpandedResults();\n+    assertExpandGroups(results, \"group1\",\"group2\", \"group3\", \"group4\");\n+    assertExpandGroupCountAndOrder(\"group1\", 2, results, \"1.0\", \"7.0\");\n+    assertExpandGroupCountAndOrder(\"group2\", 2, results, \"5.0\", \"8.0\");\n+    assertExpandGroupCountAndOrder(\"group3\", 2, results, \"11.0\", \"9.0\");\n+    assertExpandGroupCountAndOrder(\"group4\", 2, results, \"12.0\", \"14.0\");\n+\n+    //Test distrib.singlePass true\n+\n+    params = new ModifiableSolrParams();\n+    params.add(\"q\", \"*:*\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n+    params.add(\"defType\", \"edismax\");\n+    params.add(\"bf\", \"field(test_ti)\");\n+    params.add(\"expand\", \"true\");\n+    params.add(\"distrib.singlePass\", \"true\");\n+\n+    setDistributedParams(params);\n+    rsp = queryServer(params);\n+    results = rsp.getExpandedResults();\n+    assertExpandGroups(results, \"group1\",\"group2\", \"group3\", \"group4\");\n+    assertExpandGroupCountAndOrder(\"group1\", 2, results, \"1.0\", \"7.0\");\n+    assertExpandGroupCountAndOrder(\"group2\", 2, results, \"5.0\", \"8.0\");\n+    assertExpandGroupCountAndOrder(\"group3\", 2, results, \"11.0\", \"9.0\");\n+    assertExpandGroupCountAndOrder(\"group4\", 2, results, \"12.0\", \"14.0\");\n+\n   }\n \n   private void assertExpandGroups(Map<String, SolrDocumentList> expandedResults, String... groups) throws Exception {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/test/org/apache/solr/handler/component/DistributedExpandComponentTest.java",
                "sha": "9cd6f52c016c53256d77d4dccec31062538fed1d",
                "status": "modified"
            },
            {
                "additions": 37,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "changes": 53,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java?ref=c186cbfcbc4bf838d0756892c9710b1a67883590",
                "deletions": 16,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "patch": "@@ -45,10 +45,12 @@ public void setUp() throws Exception {\n \n   @Test\n   public void testExpand() throws Exception {\n-    String[] doc = {\"id\",\"1\", \"term_s\", \"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"5\", \"test_tl\", \"10\", \"test_tf\", \"2000\", \"type_s\", \"parent\"};\n+    final String group = (random().nextBoolean() ? \"group_s\" : \"group_s_dv\");\n+    \n+    String[] doc = {\"id\",\"1\", \"term_s\", \"YYYY\", group, \"group1\", \"test_ti\", \"5\", \"test_tl\", \"10\", \"test_tf\", \"2000\", \"type_s\", \"parent\"};\n     assertU(adoc(doc));\n     assertU(commit());\n-    String[] doc1 = {\"id\",\"2\", \"term_s\",\"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"50\", \"test_tl\", \"100\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n+    String[] doc1 = {\"id\",\"2\", \"term_s\",\"YYYY\", group, \"group1\", \"test_ti\", \"50\", \"test_tl\", \"100\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n     assertU(adoc(doc1));\n \n     String[] doc2 = {\"id\",\"3\", \"term_s\", \"YYYY\", \"test_ti\", \"5000\", \"test_tl\", \"100\", \"test_tf\", \"200\"};\n@@ -58,25 +60,25 @@ public void testExpand() throws Exception {\n     assertU(adoc(doc3));\n \n \n-    String[] doc4 = {\"id\",\"5\", \"term_s\", \"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"4\", \"test_tl\", \"10\", \"test_tf\", \"2000\", \"type_s\", \"parent\"};\n+    String[] doc4 = {\"id\",\"5\", \"term_s\", \"YYYY\", group, \"group2\", \"test_ti\", \"4\", \"test_tl\", \"10\", \"test_tf\", \"2000\", \"type_s\", \"parent\"};\n     assertU(adoc(doc4));\n     assertU(commit());\n-    String[] doc5 = {\"id\",\"6\", \"term_s\",\"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"10\", \"test_tl\", \"100\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n+    String[] doc5 = {\"id\",\"6\", \"term_s\",\"YYYY\", group, \"group2\", \"test_ti\", \"10\", \"test_tl\", \"100\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n     assertU(adoc(doc5));\n     assertU(commit());\n \n-    String[] doc6 = {\"id\",\"7\", \"term_s\", \"YYYY\", \"group_s\", \"group1\", \"test_ti\", \"1\", \"test_tl\", \"100000\", \"test_tf\", \"2000\", \"type_s\", \"child\"};\n+    String[] doc6 = {\"id\",\"7\", \"term_s\", \"YYYY\", group, \"group1\", \"test_ti\", \"1\", \"test_tl\", \"100000\", \"test_tf\", \"2000\", \"type_s\", \"child\"};\n     assertU(adoc(doc6));\n     assertU(commit());\n-    String[] doc7 = {\"id\",\"8\", \"term_s\",\"YYYY\", \"group_s\", \"group2\", \"test_ti\", \"2\", \"test_tl\", \"100000\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n+    String[] doc7 = {\"id\",\"8\", \"term_s\",\"YYYY\", group, \"group2\", \"test_ti\", \"2\", \"test_tl\", \"100000\", \"test_tf\", \"200\", \"type_s\", \"child\"};\n     assertU(adoc(doc7));\n \n     assertU(commit());\n \n     //First basic test case.\n     ModifiableSolrParams params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -94,7 +96,7 @@ public void testExpand() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -110,7 +112,7 @@ public void testExpand() throws Exception {\n     //Test expand.sort\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -129,7 +131,7 @@ public void testExpand() throws Exception {\n     //Main result set should include the doc with null value in the collapse field.\n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s nullPolicy=collapse}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\" nullPolicy=collapse}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -154,7 +156,7 @@ public void testExpand() throws Exception {\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n     params.add(\"expand.q\", \"type_s:child\");\n-    params.add(\"expand.field\", \"group_s\");\n+    params.add(\"expand.field\", group);\n     params.add(\"expand.sort\", \"test_tl desc\");\n     assertQ(req(params), \"*[count(/response/result/doc)=2]\",\n         \"*[count(/response/lst[@name='expanded']/result)=2]\",\n@@ -176,7 +178,7 @@ public void testExpand() throws Exception {\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n     params.add(\"expand.fq\", \"type_s:child\");\n-    params.add(\"expand.field\", \"group_s\");\n+    params.add(\"expand.field\", group);\n     params.add(\"expand.sort\", \"test_tl desc\");\n     assertQ(req(params), \"*[count(/response/result/doc)=2]\",\n         \"*[count(/response/lst[@name='expanded']/result)=2]\",\n@@ -198,7 +200,7 @@ public void testExpand() throws Exception {\n     params.add(\"expand\", \"true\");\n     params.add(\"expand.q\", \"type_s:child\");\n     params.add(\"expand.fq\", \"*:*\");\n-    params.add(\"expand.field\", \"group_s\");\n+    params.add(\"expand.field\", group);\n     params.add(\"expand.sort\", \"test_tl desc\");\n     assertQ(req(params), \"*[count(/response/result/doc)=2]\",\n         \"*[count(/response/lst[@name='expanded']/result)=2]\",\n@@ -214,7 +216,7 @@ public void testExpand() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"*:*\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -235,7 +237,7 @@ public void testExpand() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"test_ti:5\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -249,7 +251,7 @@ public void testExpand() throws Exception {\n \n     params = new ModifiableSolrParams();\n     params.add(\"q\", \"test_ti:5532535\");\n-    params.add(\"fq\", \"{!collapse field=group_s}\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n     params.add(\"defType\", \"edismax\");\n     params.add(\"bf\", \"field(test_ti)\");\n     params.add(\"expand\", \"true\");\n@@ -258,6 +260,25 @@ public void testExpand() throws Exception {\n     assertQ(req(params), \"*[count(/response/result/doc)=0]\",\n         \"*[count(/response/lst[@name='expanded']/result)=0]\"\n     );\n+\n+    //Test key-only fl\n+\n+    params = new ModifiableSolrParams();\n+    params.add(\"q\", \"*:*\");\n+    params.add(\"fq\", \"{!collapse field=\"+group+\"}\");\n+    params.add(\"defType\", \"edismax\");\n+    params.add(\"bf\", \"field(test_ti)\");\n+    params.add(\"expand\", \"true\");\n+    params.add(\"fl\", \"id\");\n+    assertQ(req(params), \"*[count(/response/result/doc)=2]\",\n+        \"*[count(/response/lst[@name='expanded']/result)=2]\",\n+        \"/response/result/doc[1]/float[@name='id'][.='2.0']\",\n+        \"/response/result/doc[2]/float[@name='id'][.='6.0']\",\n+        \"/response/lst[@name='expanded']/result[@name='group1']/doc[1]/float[@name='id'][.='1.0']\",\n+        \"/response/lst[@name='expanded']/result[@name='group1']/doc[2]/float[@name='id'][.='7.0']\",\n+        \"/response/lst[@name='expanded']/result[@name='group2']/doc[1]/float[@name='id'][.='5.0']\",\n+        \"/response/lst[@name='expanded']/result[@name='group2']/doc[2]/float[@name='id'][.='8.0']\"\n+    );\n   }\n \n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c186cbfcbc4bf838d0756892c9710b1a67883590/solr/core/src/test/org/apache/solr/handler/component/TestExpandComponent.java",
                "sha": "2da638dccaa1fae4508e29d20b8ef4b9eeda5dc3",
                "status": "modified"
            }
        ],
        "message": "SOLR-6604: SOLR-6812: Fix NPE with distrib.singlePass=true and expand component. Increased test coverage of expand component with docValues.\n\nThis closes #98.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1645098 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/980c23f49800e7345afbac911b58cf7185e7ded7",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestExpandComponent.java"
        ]
    },
    "lucene-solr_c2c2e8a": {
        "bug_id": "lucene-solr_c2c2e8a",
        "commit": "https://github.com/apache/lucene-solr/commit/c2c2e8a85e92024d627381858cd1dbcff4cbab72",
        "file": [
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c2c2e8a85e92024d627381858cd1dbcff4cbab72/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java?ref=c2c2e8a85e92024d627381858cd1dbcff4cbab72",
                "deletions": 14,
                "filename": "lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "patch": "@@ -113,24 +113,26 @@ public SimpleNaiveBayesDocumentClassifier(IndexReader indexReader, Query query,\n     Map<String, List<String[]>> fieldName2tokensArray = new LinkedHashMap<>();\n     Map<String, Float> fieldName2boost = new LinkedHashMap<>();\n     Terms classes = MultiFields.getTerms(indexReader, classFieldName);\n-    TermsEnum classesEnum = classes.iterator();\n-    BytesRef c;\n+    if (classes != null) {\n+      TermsEnum classesEnum = classes.iterator();\n+      BytesRef c;\n \n-    analyzeSeedDocument(inputDocument, fieldName2tokensArray, fieldName2boost);\n+      analyzeSeedDocument(inputDocument, fieldName2tokensArray, fieldName2boost);\n \n-    int docsWithClassSize = countDocsWithClass();\n-    while ((c = classesEnum.next()) != null) {\n-      double classScore = 0;\n-      Term term = new Term(this.classFieldName, c);\n-      for (String fieldName : textFieldNames) {\n-        List<String[]> tokensArrays = fieldName2tokensArray.get(fieldName);\n-        double fieldScore = 0;\n-        for (String[] fieldTokensArray : tokensArrays) {\n-          fieldScore += calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(fieldTokensArray, fieldName, term, docsWithClassSize) * fieldName2boost.get(fieldName);\n+      int docsWithClassSize = countDocsWithClass();\n+      while ((c = classesEnum.next()) != null) {\n+        double classScore = 0;\n+        Term term = new Term(this.classFieldName, c);\n+        for (String fieldName : textFieldNames) {\n+          List<String[]> tokensArrays = fieldName2tokensArray.get(fieldName);\n+          double fieldScore = 0;\n+          for (String[] fieldTokensArray : tokensArrays) {\n+            fieldScore += calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(fieldTokensArray, fieldName, term, docsWithClassSize) * fieldName2boost.get(fieldName);\n+          }\n+          classScore += fieldScore;\n         }\n-        classScore += fieldScore;\n+        assignedClasses.add(new ClassificationResult<>(term.bytes(), classScore));\n       }\n-      assignedClasses.add(new ClassificationResult<>(term.bytes(), classScore));\n     }\n     return normClassificationResults(assignedClasses);\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c2c2e8a85e92024d627381858cd1dbcff4cbab72/lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier.java",
                "sha": "6bc8573c094dcd6cbca004500f5e5b8eeb624533",
                "status": "modified"
            }
        ],
        "message": "LUCENE-7950 - fixed potential NPE when no docs have the class field",
        "parent": "https://github.com/apache/lucene-solr/commit/cd471cc98dcee4f587739b2288e4e120f8c54808",
        "repo": "lucene-solr",
        "unit_tests": [
            "SimpleNaiveBayesDocumentClassifierTest.java"
        ]
    },
    "lucene-solr_c3f2a19": {
        "bug_id": "lucene-solr_c3f2a19",
        "commit": "https://github.com/apache/lucene-solr/commit/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -302,6 +302,9 @@ Bug Fixes\n   webcontainers / proxies. (Jakob Furrer, hossman, Shawn Heisey, Uwe Schindler,\n   Mark Miller)\n \n+* SOLR-5580: NPE when creating a core with both explicit shard and coreNodeName.\n+  (YouPeng Yang, Mark Miller)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/CHANGES.txt",
                "sha": "a90c913018b2397a7f88ae86d5e0f6a009736471",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/core/src/java/org/apache/solr/cloud/Overseer.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/Overseer.java?ref=c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925",
                "deletions": 11,
                "filename": "solr/core/src/java/org/apache/solr/cloud/Overseer.java",
                "patch": "@@ -442,18 +442,10 @@ private ClusterState updateState(ClusterState state, final ZkNodeProps message)\n             // if coreNodeName is null, auto assign one\n             coreNodeName = Assign.assignNode(collection, state);\n           }\n-          message.getProperties().put(ZkStateReader.CORE_NODE_NAME_PROP, coreNodeName);\n-        } else {\n-          //probably, this core was removed explicitly\n-          if (sliceName !=null && collectionExists &&  !\"true\".equals(state.getCollection(collection).getStr(\"autoCreated\"))) {\n-            Slice slice = state.getSlice(collection, sliceName);\n-            if (slice.getReplica(coreNodeName) == null) {\n-              log.info(\"core_deleted . Just return\");\n-              return state;\n-            }\n-          }\n-\n+          message.getProperties().put(ZkStateReader.CORE_NODE_NAME_PROP,\n+              coreNodeName);\n         }\n+\n         // use the provided non null shardId\n         if (sliceName == null) {\n           //get shardId from ClusterState",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/core/src/java/org/apache/solr/cloud/Overseer.java",
                "sha": "f8b2f7a690200abbe0f9e0156a6d62a527d3bfae",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java?ref=c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925",
                "deletions": 1,
                "filename": "solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java",
                "patch": "@@ -34,6 +34,7 @@\n import java.util.concurrent.SynchronousQueue;\n import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n import org.apache.commons.lang.StringUtils;\n import org.apache.lucene.util.LuceneTestCase.Slow;\n@@ -100,6 +101,8 @@\n   private String oneInstanceCollection = \"oneInstanceCollection\";\n   private String oneInstanceCollection2 = \"oneInstanceCollection2\";\n   \n+  private AtomicInteger nodeCounter = new AtomicInteger();\n+  \n   ThreadPoolExecutor executor = new ThreadPoolExecutor(0,\n       Integer.MAX_VALUE, 5, TimeUnit.SECONDS, new SynchronousQueue<Runnable>(),\n       new DefaultSolrThreadFactory(\"testExecutor\"));\n@@ -928,11 +931,16 @@ public Object call() {\n         try {\n           server = new HttpSolrServer(baseUrl);\n           server.setConnectionTimeout(15000);\n-          server.setSoTimeout(60000);\n           Create createCmd = new Create();\n           createCmd.setRoles(\"none\");\n           createCmd.setCoreName(collection + num);\n           createCmd.setCollection(collection);\n+          \n+          if (random().nextBoolean()) {\n+            // sometimes we use an explicit core node name\n+            createCmd.setCoreNodeName(\"anode\" + nodeCounter.incrementAndGet());\n+          }\n+          \n           if (shardId == null) {\n             createCmd.setNumShards(2);\n           }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c3f2a19022b514f6e2b34451ad5ea4ae8a2a8925/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java",
                "sha": "0da31f46461c6089fc9695cf6a7b73333bc24752",
                "status": "modified"
            }
        ],
        "message": "SOLR-5580: NPE when creating a core with both explicit shard and coreNodeName.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1553967 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/26e92f36ad24455c2208a8507007b7bf6590835b",
        "repo": "lucene-solr",
        "unit_tests": [
            "OverseerTest.java"
        ]
    },
    "lucene-solr_c694d44": {
        "bug_id": "lucene-solr_c694d44",
        "commit": "https://github.com/apache/lucene-solr/commit/c694d44442c28b3e873b0a064e72899f6dc2b5c2",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c694d44442c28b3e873b0a064e72899f6dc2b5c2/src/java/org/apache/lucene/queryParser/QueryParser.jj",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/queryParser/QueryParser.jj?ref=c694d44442c28b3e873b0a064e72899f6dc2b5c2",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/queryParser/QueryParser.jj",
                "patch": "@@ -535,7 +535,10 @@ Query Term(String field) : {\n       }\n       catch (Exception ignored) { }\n \n-      q.setBoost(f);\n+      // could happen with boosted stopword\n+      if(q != null) {\n+        q.setBoost(f);\n+      }\n     }\n     return q;\n   }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c694d44442c28b3e873b0a064e72899f6dc2b5c2/src/java/org/apache/lucene/queryParser/QueryParser.jj",
                "sha": "9d5ccbd22e22ca3db319eeff3d440cae5dce5816",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/c694d44442c28b3e873b0a064e72899f6dc2b5c2/src/test/org/apache/lucene/queryParser/TestQueryParser.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/queryParser/TestQueryParser.java?ref=c694d44442c28b3e873b0a064e72899f6dc2b5c2",
                "deletions": 0,
                "filename": "src/test/org/apache/lucene/queryParser/TestQueryParser.java",
                "patch": "@@ -306,4 +306,21 @@ public void testSimpleDAO()\n \tassertQueryEqualsDOA(\"term +term +term\", null, \"+term +term +term\");\n \tassertQueryEqualsDOA(\"-term term term\", null, \"-term +term +term\");\n     }\n+\n+    public void testBoost()\n+        throws Exception\n+    {\n+        StandardAnalyzer oneStopAnalyzer = new StandardAnalyzer(new String[]{\"on\"});\n+        QueryParser qp = new QueryParser(\"field\", oneStopAnalyzer);\n+        Query q = qp.parse(\"on^1.0\");\n+        assertNotNull(q);\n+        q = qp.parse(\"\\\"hello\\\"^2.0\");\n+        assertNotNull(q);\n+        assertEquals(q.getBoost(), (float)2.0, (float)0.5);\n+        q = qp.parse(\"hello^2.0\");\n+        assertNotNull(q);\n+        assertEquals(q.getBoost(), (float)2.0, (float)0.5);\n+        q = qp.parse(\"\\\"on\\\"^1.0\");\n+        assertNotNull(q);\n+    }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/c694d44442c28b3e873b0a064e72899f6dc2b5c2/src/test/org/apache/lucene/queryParser/TestQueryParser.java",
                "sha": "db8c75e22999d4b8fa46ee2f0202d3a42d450857",
                "status": "modified"
            }
        ],
        "message": "- NPE fix.\nPR: bug #16043\nSubmitted by: Peter Mularien\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@149935 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/d1fec6e83059c7f1c183c476896d7a265bd419c1",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestQueryParser.java"
        ]
    },
    "lucene-solr_cab7d10": {
        "bug_id": "lucene-solr_cab7d10",
        "commit": "https://github.com/apache/lucene-solr/commit/cab7d103d69be3bba1e0b857b8de810e71f3174c",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=cab7d103d69be3bba1e0b857b8de810e71f3174c",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -60,6 +60,9 @@ Bug fixes\n   closed listeners. This was fixed by LUCENE-6501.\n   (Adrien Grand, Uwe Schindler)\n \n+* LUCENE-6520: Geo3D GeoPath.done() would throw an NPE if adjacent path\n+  segments were co-linear. (Karl Wright via David Smiley)\n+\n Changes in Runtime Behavior\n \n * LUCENE-6501: The subreader structure in ParallelCompositeReader",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/CHANGES.txt",
                "sha": "34e78ac16da79282b78eaf212dad02c92a10b8f7",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/spatial/src/java/org/apache/lucene/spatial/spatial4j/geo3d/GeoPath.java",
                "changes": 42,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/spatial/src/java/org/apache/lucene/spatial/spatial4j/geo3d/GeoPath.java?ref=cab7d103d69be3bba1e0b857b8de810e71f3174c",
                "deletions": 19,
                "filename": "lucene/spatial/src/java/org/apache/lucene/spatial/spatial4j/geo3d/GeoPath.java",
                "patch": "@@ -113,15 +113,21 @@ public void done() {\n       \n       // General intersection case\n       final PathSegment prevSegment = segments.get(i-1);\n-      if (prevSegment.upperConnectingPlane.isNumericallyIdentical(currentSegment.upperConnectingPlane) &&\n-          prevSegment.lowerConnectingPlane.isNumericallyIdentical(currentSegment.lowerConnectingPlane)) {\n+      // We construct four separate planes, and evaluate which one includes all interior points with least overlap\n+      final SidedPlane candidate1 = SidedPlane.constructNormalizedThreePointSidedPlane(currentSegment.start, prevSegment.URHC, currentSegment.ULHC, currentSegment.LLHC);\n+      final SidedPlane candidate2 = SidedPlane.constructNormalizedThreePointSidedPlane(currentSegment.start, currentSegment.ULHC, currentSegment.LLHC, prevSegment.LRHC);\n+      final SidedPlane candidate3 = SidedPlane.constructNormalizedThreePointSidedPlane(currentSegment.start, currentSegment.LLHC, prevSegment.LRHC, prevSegment.URHC);\n+      final SidedPlane candidate4 = SidedPlane.constructNormalizedThreePointSidedPlane(currentSegment.start, prevSegment.LRHC, prevSegment.URHC, currentSegment.ULHC);\n+\n+      if (candidate1 == null && candidate2 == null && candidate3 == null && candidate4 == null) {\n         // The planes are identical.  We don't need a circle at all.  Special constructor...\n         endPoints.add(new SegmentEndpoint(currentSegment.start));\n       } else {\n         endPoints.add(new SegmentEndpoint(currentSegment.start,\n           prevSegment.endCutoffPlane, currentSegment.startCutoffPlane,\n           prevSegment.URHC, prevSegment.LRHC,\n-          currentSegment.ULHC, currentSegment.LLHC));\n+          currentSegment.ULHC, currentSegment.LLHC,\n+          candidate1, candidate2, candidate3, candidate4));\n       }\n     }\n     // Do final endpoint\n@@ -458,8 +464,9 @@ public SegmentEndpoint(final GeoPoint point,\n      */\n     public SegmentEndpoint(final GeoPoint point,\n       final SidedPlane prevCutoffPlane, final SidedPlane nextCutoffPlane,\n-      final GeoPoint prevUpperGeoPoint, final GeoPoint prevLowerGeoPoint,\n-      final GeoPoint nextUpperGeoPoint, final GeoPoint nextLowerGeoPoint) {\n+      final GeoPoint notCand2Point, final GeoPoint notCand1Point,\n+      final GeoPoint notCand3Point, final GeoPoint notCand4Point,\n+      final SidedPlane candidate1, final SidedPlane candidate2, final SidedPlane candidate3, final SidedPlane candidate4) {\n       // Note: What we really need is a single plane that goes through all four points.\n       // Since that's not possible in the ellipsoid case (because three points determine a plane, not four), we\n       // need an approximation that at least creates a boundary that has no interruptions.\n@@ -472,38 +479,35 @@ public SegmentEndpoint(final GeoPoint point,\n       this.point = point;\n       \n       // We construct four separate planes, and evaluate which one includes all interior points with least overlap\n-      final SidedPlane candidate1 = SidedPlane.constructNormalizedThreePointSidedPlane(point, prevUpperGeoPoint, nextUpperGeoPoint, nextLowerGeoPoint);\n-      final SidedPlane candidate2 = SidedPlane.constructNormalizedThreePointSidedPlane(point, nextUpperGeoPoint, nextLowerGeoPoint, prevLowerGeoPoint);\n-      final SidedPlane candidate3 = SidedPlane.constructNormalizedThreePointSidedPlane(point, nextLowerGeoPoint, prevLowerGeoPoint, prevUpperGeoPoint);\n-      final SidedPlane candidate4 = SidedPlane.constructNormalizedThreePointSidedPlane(point, prevLowerGeoPoint, prevUpperGeoPoint, nextUpperGeoPoint);\n-\n-      final boolean cand1IsOtherWithin = candidate1.isWithin(prevLowerGeoPoint);\n-      final boolean cand2IsOtherWithin = candidate2.isWithin(prevUpperGeoPoint);\n-      final boolean cand3IsOtherWithin = candidate3.isWithin(nextUpperGeoPoint);\n-      final boolean cand4IsOtherWithin = candidate4.isWithin(nextLowerGeoPoint);\n+      // (Constructed beforehand because we need them for degeneracy check)\n+\n+      final boolean cand1IsOtherWithin = candidate1!=null?candidate1.isWithin(notCand1Point):false;\n+      final boolean cand2IsOtherWithin = candidate2!=null?candidate2.isWithin(notCand2Point):false;\n+      final boolean cand3IsOtherWithin = candidate3!=null?candidate3.isWithin(notCand3Point):false;\n+      final boolean cand4IsOtherWithin = candidate4!=null?candidate4.isWithin(notCand4Point):false;\n       \n       if (cand1IsOtherWithin && cand2IsOtherWithin && cand3IsOtherWithin && cand4IsOtherWithin) {\n         // The only way we should see both within is if all four points are coplanar.  In that case, we default to the simplest treatment.\n         this.circlePlane = candidate1;  // doesn't matter which\n-        this.notablePoints = new GeoPoint[]{prevUpperGeoPoint, nextUpperGeoPoint, prevLowerGeoPoint, nextLowerGeoPoint};\n+        this.notablePoints = new GeoPoint[]{notCand2Point, notCand3Point, notCand1Point, notCand4Point};\n         this.cutoffPlanes = new Membership[]{new SidedPlane(prevCutoffPlane), new SidedPlane(nextCutoffPlane)};\n       } else if (cand1IsOtherWithin) {\n         // Use candidate1, and DON'T include prevCutoffPlane in the cutoff planes list\n         this.circlePlane = candidate1;\n-        this.notablePoints = new GeoPoint[]{prevUpperGeoPoint, nextUpperGeoPoint, nextLowerGeoPoint};\n+        this.notablePoints = new GeoPoint[]{notCand2Point, notCand3Point, notCand4Point};\n         this.cutoffPlanes = new Membership[]{new SidedPlane(nextCutoffPlane)};\n       } else if (cand2IsOtherWithin) {\n         // Use candidate2\n         this.circlePlane = candidate2;\n-        this.notablePoints = new GeoPoint[]{nextUpperGeoPoint, nextLowerGeoPoint, prevLowerGeoPoint};\n+        this.notablePoints = new GeoPoint[]{notCand3Point, notCand4Point, notCand1Point};\n         this.cutoffPlanes = new Membership[]{new SidedPlane(nextCutoffPlane)};\n       } else if (cand3IsOtherWithin) {\n         this.circlePlane = candidate3;\n-        this.notablePoints = new GeoPoint[]{nextLowerGeoPoint, prevLowerGeoPoint, prevUpperGeoPoint};\n+        this.notablePoints = new GeoPoint[]{notCand4Point, notCand1Point, notCand2Point};\n         this.cutoffPlanes = new Membership[]{new SidedPlane(prevCutoffPlane)};\n       } else if (cand4IsOtherWithin) {\n         this.circlePlane = candidate4;\n-        this.notablePoints = new GeoPoint[]{prevLowerGeoPoint, prevUpperGeoPoint, nextUpperGeoPoint};\n+        this.notablePoints = new GeoPoint[]{notCand1Point, notCand2Point, notCand3Point};\n         this.cutoffPlanes = new Membership[]{new SidedPlane(prevCutoffPlane)};\n       } else {\n         // dunno what happened",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/spatial/src/java/org/apache/lucene/spatial/spatial4j/geo3d/GeoPath.java",
                "sha": "2dfacaca1d14027d5bf85ca64741f2a828bc9199",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/spatial/src/test/org/apache/lucene/spatial/spatial4j/geo3d/GeoPathTest.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/spatial/src/test/org/apache/lucene/spatial/spatial4j/geo3d/GeoPathTest.java?ref=cab7d103d69be3bba1e0b857b8de810e71f3174c",
                "deletions": 0,
                "filename": "lucene/spatial/src/test/org/apache/lucene/spatial/spatial4j/geo3d/GeoPathTest.java",
                "patch": "@@ -19,6 +19,7 @@\n \n import org.junit.Test;\n \n+import static java.lang.Math.toRadians;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n@@ -182,4 +183,14 @@ public void testPathBounds() {\n \n   }\n \n+  @Test\n+  public void testCoLinear() {\n+    // p1: (12,-90), p2: (11, -55), (129, -90)\n+    GeoPath p = new GeoPath(PlanetModel.SPHERE, 0.1);\n+    p.addPoint(toRadians(-90), toRadians(12));//south pole\n+    p.addPoint(toRadians(-55), toRadians(11));\n+    p.addPoint(toRadians(-90), toRadians(129));//south pole again\n+    p.done();//at least test this doesn't bomb like it used too -- LUCENE-6520\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cab7d103d69be3bba1e0b857b8de810e71f3174c/lucene/spatial/src/test/org/apache/lucene/spatial/spatial4j/geo3d/GeoPathTest.java",
                "sha": "998cbe8ccb0668d19668b501410171dd0cf2efdb",
                "status": "modified"
            }
        ],
        "message": "LUCENE-6520: Geo3D GeoPath.done() would throw an NPE if adjacent path segments were co-linear\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1683532 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/d01c4d6afbe555c13ccba9c14f7204f18b848653",
        "repo": "lucene-solr",
        "unit_tests": [
            "GeoPathTest.java"
        ]
    },
    "lucene-solr_cabc125": {
        "bug_id": "lucene-solr_cabc125",
        "commit": "https://github.com/apache/lucene-solr/commit/cabc125eefce10a8b021f1698371eabc6289ed60",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -115,6 +115,8 @@ Bug Fixes\n \n * SOLR-13827: Fail on unknown operation in Request Parameters API (Munendra S N, noble)\n \n+* SOLR-13403: Fix NPE in TermsComponent for DatePointField (yonik, Munendra S N)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/CHANGES.txt",
                "sha": "b21ef2cad6b53dab5b467e7c028d2a95b54f35bf",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/java/org/apache/solr/handler/component/TermsComponent.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/TermsComponent.java?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 4,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/TermsComponent.java",
                "patch": "@@ -50,6 +50,7 @@\n import org.apache.solr.common.util.NamedList;\n import org.apache.solr.common.util.SimpleOrderedMap;\n import org.apache.solr.common.util.StrUtils;\n+import org.apache.solr.common.util.Utils;\n import org.apache.solr.handler.component.HttpShardHandlerFactory.WhitelistHostChecker;\n import org.apache.solr.request.SimpleFacets.CountPair;\n import org.apache.solr.schema.FieldType;\n@@ -201,7 +202,7 @@ public void process(ResponseBuilder rb) throws IOException {\n         SchemaField sf = rb.req.getSchema().getFieldOrNull(field);\n         if (sf != null && sf.getType().isPointField()) {\n           // FIXME: terms.ttf=true is not supported for pointFields\n-          if (lowerStr!=null || upperStr!=null || prefix!=null || regexp!=null) {\n+          if (lowerStr != null || upperStr != null || prefix != null || regexp != null) {\n             throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                 String.format(Locale.ROOT, \"The terms component does not support Points-based fields with sorting or with parameters %s,%s,%s,%s \", TermsParams.TERMS_LOWER, TermsParams.TERMS_UPPER, TermsParams.TERMS_PREFIX_STR, TermsParams.TERMS_REGEXP_STR));\n           }\n@@ -221,7 +222,7 @@ public void process(ResponseBuilder rb) throws IOException {\n             }\n \n             for (CountPair<MutableValue, Integer> item : queue) {\n-              fieldTerms.add(item.key.toString(), item.val);\n+              fieldTerms.add(Utils.OBJECT_TO_STRING.apply(item.key.toObject()), item.val);\n             }\n             continue;\n           } else {\n@@ -237,7 +238,7 @@ public void process(ResponseBuilder rb) throws IOException {\n                 if (count < 0) break;\n                 if (count < freqmin || count > freqmax) continue;\n                 if (++num > limit) break;\n-                ew.put(mv.toString(), (int)count); // match the numeric type of terms\n+                ew.put(Utils.OBJECT_TO_STRING.apply(mv.toObject()), (int)count); // match the numeric type of terms\n               }\n             });\n              ***/\n@@ -250,7 +251,7 @@ public void process(ResponseBuilder rb) throws IOException {\n               if (count < 0) break;\n               if (count < freqmin || count > freqmax) continue;\n               if (++num > limit) break;\n-              fieldTerms.add(mv.toString(), (int)count); // match the numeric type of terms\n+              fieldTerms.add(Utils.OBJECT_TO_STRING.apply(mv.toObject()), (int)count); // match the numeric type of terms\n             }\n             continue;\n           }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/java/org/apache/solr/handler/component/TermsComponent.java",
                "sha": "022a844a0cf35badcab6eb21b3ee741e67812399",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/java/org/apache/solr/search/PointMerger.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/search/PointMerger.java?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/search/PointMerger.java",
                "patch": "@@ -80,6 +80,7 @@ public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int tot\n             seg = new DoubleSeg(pv, capacity);\n             break;\n           case DATE:\n+            seg = new DateSeg(pv, capacity);\n             break;\n         }\n         int count = seg.setNextValue();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/java/org/apache/solr/search/PointMerger.java",
                "sha": "a2d9ade015111b7c957f8a429cefc9bd1fcf1b3b",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test-files/solr/collection1/conf/schema.xml?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 0,
                "filename": "solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "patch": "@@ -841,6 +841,11 @@\n    <dynamicField name=\"*_ds_ni_p\"   type=\"pdouble\"    indexed=\"false\"  stored=\"true\" docValues=\"true\" multiValued=\"true\"/>\n    <dynamicField name=\"*_sortable\"  type=\"sortable_text\" indexed=\"true\" multiValued=\"false\" stored=\"true\" />\n \n+  <dynamicField name=\"*_date_p\"      type=\"pdate\"    indexed=\"true\"  stored=\"true\" docValues=\"true\" multiValued=\"false\"/>\n+  <dynamicField name=\"*_dates_p\"     type=\"pdate\"    indexed=\"true\"  stored=\"true\" docValues=\"true\" multiValued=\"true\"/>\n+  <dynamicField name=\"*_date_ni_p\"   type=\"pdate\"    indexed=\"false\"  stored=\"true\" docValues=\"true\" multiValued=\"false\"/>\n+  <dynamicField name=\"*_dates_ni_p\"  type=\"pdate\"    indexed=\"false\"  stored=\"true\" docValues=\"true\" multiValued=\"true\"/>\n+\n   <copyField source=\"single_i_dvn\" dest=\"copy_single_i_dvn\"/>\n   <copyField source=\"single_d_dvn\" dest=\"copy_single_d_dvn\"/>\n   <copyField source=\"single_s_dvn\" dest=\"copy_single_s_dvn\"/>",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test-files/solr/collection1/conf/schema.xml",
                "sha": "d5cf09035f44bbd0929b68d11cd585b1b598c8e1",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test/org/apache/solr/handler/component/DistributedTermsComponentTest.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedTermsComponentTest.java?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 6,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedTermsComponentTest.java",
                "patch": "@@ -51,13 +51,13 @@ public void test() throws Exception {\n     Random random = random();\n     del(\"*:*\");\n     index(id, random.nextInt(), \"b_t\", \"snake a,b spider shark snail slug seal\", \"foo_i\", \"1\");\n-    index(id, random.nextInt(), \"b_t\", \"snake spider shark snail slug\", \"foo_i\", \"2\");\n+    index(id, random.nextInt(), \"b_t\", \"snake spider shark snail slug\", \"foo_i\", \"2\", \"foo_date_p\", \"2015-01-03T14:30:00Z\");\n     index(id, random.nextInt(), \"b_t\", \"snake spider shark snail\", \"foo_i\", \"3\");\n-    index(id, random.nextInt(), \"b_t\", \"snake spider shark\", \"foo_i\", \"2\");\n-    index(id, random.nextInt(), \"b_t\", \"snake spider\", \"c_t\", \"snake spider\");\n-    index(id, random.nextInt(), \"b_t\", \"snake\", \"c_t\", \"snake\");\n-    index(id, random.nextInt(), \"b_t\", \"ant zebra\", \"c_t\", \"ant zebra\");\n-    index(id, random.nextInt(), \"b_t\", \"zebra\", \"c_t\", \"zebra\");\n+    index(id, random.nextInt(), \"b_t\", \"snake spider shark\", \"foo_i\", \"2\", \"foo_date_p\", \"2014-03-15T12:00:00Z\");\n+    index(id, random.nextInt(), \"b_t\", \"snake spider\", \"c_t\", \"snake spider\", \"foo_date_p\", \"2014-03-15T12:00:00Z\");\n+    index(id, random.nextInt(), \"b_t\", \"snake\", \"c_t\", \"snake\", \"foo_date_p\", \"2014-03-15T12:00:00Z\");\n+    index(id, random.nextInt(), \"b_t\", \"ant zebra\", \"c_t\", \"ant zebra\", \"foo_date_p\", \"2015-01-03T14:30:00Z\");\n+    index(id, random.nextInt(), \"b_t\", \"zebra\", \"c_t\", \"zebra\", \"foo_date_p\", \"2015-01-03T14:30:00Z\");\n     commit();\n \n     handle.clear();\n@@ -77,6 +77,11 @@ public void test() throws Exception {\n     query(\"qt\", \"/terms\", \"shards.qt\", \"/terms\", \"terms\", \"true\", \"terms.fl\", \"foo_i\", \"terms.stats\", \"true\",\"terms.list\", \"2,3,1\");\n     query(\"qt\", \"/terms\", \"shards.qt\", \"/terms\", \"terms\", \"true\", \"terms.fl\", \"b_t\", \"terms.list\", \"snake,zebra\", \"terms.ttf\", \"true\");\n     query(\"qt\", \"/terms\", \"shards.qt\", \"/terms\", \"terms\", \"true\", \"terms.fl\", \"b_t\", \"terms.fl\", \"c_t\", \"terms.list\", \"snake,ant,zebra\", \"terms.ttf\", \"true\");\n+\n+    // for date point field\n+    query(\"qt\", \"/terms\", \"shards.qt\", \"/terms\", \"terms\", \"true\", \"terms.fl\", \"foo_date_p\");\n+    // terms.ttf=true doesn't work for point fields\n+    //query(\"qt\", \"/terms\", \"shards.qt\", \"/terms\", \"terms\", \"true\", \"terms.fl\", \"foo_date_p\", \"terms.ttf\", \"true\");\n   }\n   \n   protected QueryResponse query(Object... q) throws Exception {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test/org/apache/solr/handler/component/DistributedTermsComponentTest.java",
                "sha": "8e7dc9b16f795e461ced1543b7daeb2d6d3b9b65",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test/org/apache/solr/handler/component/TermsComponentTest.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/TermsComponentTest.java?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/TermsComponentTest.java",
                "patch": "@@ -612,4 +612,28 @@ public void testTermsSortIndexDistribution() {\n   private static String createShardQueryParamsString(ModifiableSolrParams params) {\n     return TermsComponent.createShardQuery(params).params.toString();\n   }\n+\n+  @Test\n+  public void testDatePointField() throws Exception {\n+    String[] dates = new String[]{\"2015-01-03T14:30:00Z\", \"2014-03-15T12:00:00Z\"};\n+    for (int i = 0; i < 100; i++) {\n+      assertU(adoc(\"id\", Integer.toString(100000+i), \"foo_pdt\", dates[i % 2]) );\n+      if (random().nextInt(10) == 0) assertU(commit());  // make multiple segments\n+    }\n+    assertU(commit());\n+    assertU(adoc(\"id\", Integer.toString(100102), \"foo_pdt\", dates[1]));\n+    assertU(commit());\n+\n+    try {\n+      assertQ(req(\"indent\",\"true\", \"qt\",\"/terms\", \"terms\",\"true\",\n+          \"terms.fl\",\"foo_pdt\", \"terms.sort\",\"count\"),\n+          \"count(//lst[@name='foo_pdt']/*)=2\",\n+          \"//lst[@name='foo_pdt']/int[1][@name='\" + dates[1] + \"'][.='51']\",\n+          \"//lst[@name='foo_pdt']/int[2][@name='\" + dates[0] + \"'][.='50']\"\n+      );\n+    } finally {\n+      assertU(delQ(\"foo_pdt:[* TO *]\"));\n+      assertU(commit());\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/core/src/test/org/apache/solr/handler/component/TermsComponentTest.java",
                "sha": "3a39d38e9b060c7fb0e7b8191b2c2b93c00e3138",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/lucene-solr/blob/cabc125eefce10a8b021f1698371eabc6289ed60/solr/solrj/src/java/org/apache/solr/common/util/Utils.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/util/Utils.java?ref=cabc125eefce10a8b021f1698371eabc6289ed60",
                "deletions": 9,
                "filename": "solr/solrj/src/java/org/apache/solr/common/util/Utils.java",
                "patch": "@@ -23,7 +23,6 @@\n import java.io.OutputStreamWriter;\n import java.io.Reader;\n import java.io.StringReader;\n-import java.io.UnsupportedEncodingException;\n import java.io.Writer;\n import java.lang.invoke.MethodHandles;\n import java.net.URL;\n@@ -36,12 +35,14 @@\n import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n+import java.util.Date;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.LinkedHashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.NoSuchElementException;\n+import java.util.Objects;\n import java.util.Set;\n import java.util.TreeMap;\n import java.util.TreeSet;\n@@ -324,6 +325,13 @@ public Object newObject() {\n     }\n   };\n \n+  /**\n+   * Util function to convert {@link Object} to {@link String}\n+   * Specially handles {@link Date} to string conversion\n+   */\n+  public static final Function<Object, String> OBJECT_TO_STRING =\n+      obj -> ((obj instanceof Date) ? Objects.toString(((Date) obj).toInstant()) : Objects.toString(obj));\n+\n   public static Object fromJSON(InputStream is, Function<JSONParser, ObjectBuilder> objBuilderProvider) {\n     try {\n       return objBuilderProvider.apply(getJSONParser((new InputStreamReader(is, StandardCharsets.UTF_8)))).getVal();\n@@ -646,7 +654,6 @@ public static String parseMetricsReplicaName(String collectionName, String coreN\n    * @param input the json with new values\n    * @return whether there was any change made to sink or not.\n    */\n-\n   public static boolean mergeJson(Map<String, Object> sink, Map<String, Object> input) {\n     boolean isModified = false;\n     for (Map.Entry<String, Object> e : input.entrySet()) {\n@@ -686,12 +693,8 @@ public static String getBaseUrlForNodeName(final String nodeName, String urlSche\n       throw new IllegalArgumentException(\"nodeName does not contain expected '_' separator: \" + nodeName);\n     }\n     final String hostAndPort = nodeName.substring(0, _offset);\n-    try {\n-      final String path = URLDecoder.decode(nodeName.substring(1 + _offset), \"UTF-8\");\n-      return urlScheme + \"://\" + hostAndPort + (path.isEmpty() ? \"\" : (\"/\" + path));\n-    } catch (UnsupportedEncodingException e) {\n-      throw new IllegalStateException(\"JVM Does not seem to support UTF-8\", e);\n-    }\n+    final String path = URLDecoder.decode(nodeName.substring(1 + _offset), UTF_8);\n+    return urlScheme + \"://\" + hostAndPort + (path.isEmpty() ? \"\" : (\"/\" + path));\n   }\n \n   public static long time(TimeSource timeSource, TimeUnit unit) {\n@@ -728,7 +731,7 @@ public static String getMDCNode() {\n   }\n \n   public static final InputStreamConsumer<?> JAVABINCONSUMER = is -> new JavaBinCodec().unmarshal(is);\n-  public static final InputStreamConsumer<?> JSONCONSUMER = is -> Utils.fromJSON(is);\n+  public static final InputStreamConsumer<?> JSONCONSUMER = Utils::fromJSON;\n \n   public static InputStreamConsumer<ByteBuffer> newBytesConsumer(int maxSize) {\n     return is -> {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/cabc125eefce10a8b021f1698371eabc6289ed60/solr/solrj/src/java/org/apache/solr/common/util/Utils.java",
                "sha": "7d9f7834598ee81acd8bbdb69ee229c8615aac9a",
                "status": "modified"
            }
        ],
        "message": "SOLR-13403: fix NPE in terms for DatePointField\n\n* This fixes NPE and adds support for DatePointField in terms\n  component",
        "parent": "https://github.com/apache/lucene-solr/commit/227a624f8afe846a8e1157d1114a312c7f84df66",
        "repo": "lucene-solr",
        "unit_tests": [
            "TermsComponentTest.java",
            "TestUtils.java"
        ]
    },
    "lucene-solr_ce9b805": {
        "bug_id": "lucene-solr_ce9b805",
        "commit": "https://github.com/apache/lucene-solr/commit/ce9b80539d8b3c1558c08adba8206a4d0c168b25",
        "file": [
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ce9b80539d8b3c1558c08adba8206a4d0c168b25/src/java/org/apache/lucene/index/SegmentInfos.java",
                "changes": 70,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/SegmentInfos.java?ref=ce9b80539d8b3c1558c08adba8206a4d0c168b25",
                "deletions": 31,
                "filename": "src/java/org/apache/lucene/index/SegmentInfos.java",
                "patch": "@@ -528,41 +528,43 @@ public Object run() throws CorruptIndexException, IOException {\n           // a stale cache (NFS) we have a better chance of\n           // getting the right generation.\n           long genB = -1;\n-          for(int i=0;i<defaultGenFileRetryCount;i++) {\n-            IndexInput genInput = null;\n-            try {\n-              genInput = directory.openInput(IndexFileNames.SEGMENTS_GEN);\n-            } catch (FileNotFoundException e) {\n-              message(\"segments.gen open: FileNotFoundException \" + e);\n-              break;\n-            } catch (IOException e) {\n-              message(\"segments.gen open: IOException \" + e);\n-            }\n-\n-            if (genInput != null) {\n+          if (directory != null) {\n+            for(int i=0;i<defaultGenFileRetryCount;i++) {\n+              IndexInput genInput = null;\n               try {\n-                int version = genInput.readInt();\n-                if (version == FORMAT_LOCKLESS) {\n-                  long gen0 = genInput.readLong();\n-                  long gen1 = genInput.readLong();\n-                  message(\"fallback check: \" + gen0 + \"; \" + gen1);\n-                  if (gen0 == gen1) {\n-                    // The file is consistent.\n-                    genB = gen0;\n-                    break;\n+                genInput = directory.openInput(IndexFileNames.SEGMENTS_GEN);\n+              } catch (FileNotFoundException e) {\n+                message(\"segments.gen open: FileNotFoundException \" + e);\n+                break;\n+              } catch (IOException e) {\n+                message(\"segments.gen open: IOException \" + e);\n+              }\n+\n+              if (genInput != null) {\n+                try {\n+                  int version = genInput.readInt();\n+                  if (version == FORMAT_LOCKLESS) {\n+                    long gen0 = genInput.readLong();\n+                    long gen1 = genInput.readLong();\n+                    message(\"fallback check: \" + gen0 + \"; \" + gen1);\n+                    if (gen0 == gen1) {\n+                      // The file is consistent.\n+                      genB = gen0;\n+                      break;\n+                    }\n                   }\n+                } catch (IOException err2) {\n+                  // will retry\n+                } finally {\n+                  genInput.close();\n                 }\n-              } catch (IOException err2) {\n+              }\n+              try {\n+                Thread.sleep(defaultGenFileRetryPauseMsec);\n+              } catch (InterruptedException e) {\n                 // will retry\n-              } finally {\n-                genInput.close();\n               }\n             }\n-            try {\n-              Thread.sleep(defaultGenFileRetryPauseMsec);\n-            } catch (InterruptedException e) {\n-              // will retry\n-            }\n           }\n \n           message(IndexFileNames.SEGMENTS_GEN + \" check: genB=\" + genB);\n@@ -655,8 +657,14 @@ public Object run() throws CorruptIndexException, IOException {\n             String prevSegmentFileName = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,\n                                                                                \"\",\n                                                                                gen-1);\n-            \n-            if (directory.fileExists(prevSegmentFileName)) {\n+\n+            final boolean prevExists;\n+            if (directory != null)\n+              prevExists = directory.fileExists(prevSegmentFileName);\n+            else\n+              prevExists = new File(fileDirectory, prevSegmentFileName).exists();\n+\n+            if (prevExists) {\n               message(\"fallback to prior segment file '\" + prevSegmentFileName + \"'\");\n               try {\n                 Object v = doBody(prevSegmentFileName);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ce9b80539d8b3c1558c08adba8206a4d0c168b25/src/java/org/apache/lucene/index/SegmentInfos.java",
                "sha": "c5fade9dc29a989cb3193c101aa46e66db163936",
                "status": "modified"
            },
            {
                "additions": 45,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ce9b80539d8b3c1558c08adba8206a4d0c168b25/src/test/org/apache/lucene/index/TestIndexReader.java",
                "changes": 65,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/index/TestIndexReader.java?ref=ce9b80539d8b3c1558c08adba8206a4d0c168b25",
                "deletions": 20,
                "filename": "src/test/org/apache/lucene/index/TestIndexReader.java",
                "patch": "@@ -595,26 +595,51 @@ public void testFilesOpenClose() throws IOException\n \n     public void testLastModified() throws IOException {\n       assertFalse(IndexReader.indexExists(\"there_is_no_such_index\"));\n-      Directory dir = new MockRAMDirectory();\n-      assertFalse(IndexReader.indexExists(dir));\n-      IndexWriter writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n-      addDocumentWithFields(writer);\n-      assertTrue(IndexReader.isLocked(dir));\t\t// writer open, so dir is locked\n-      writer.close();\n-      assertTrue(IndexReader.indexExists(dir));\n-      IndexReader reader = IndexReader.open(dir);\n-      assertFalse(IndexReader.isLocked(dir));\t\t// reader only, no lock\n-      long version = IndexReader.lastModified(dir);\n-      reader.close();\n-      // modify index and check version has been\n-      // incremented:\n-      writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n-      addDocumentWithFields(writer);\n-      writer.close();\n-      reader = IndexReader.open(dir);\n-      assertTrue(\"old lastModified is \" + version + \"; new lastModified is \" + IndexReader.lastModified(dir), version <= IndexReader.lastModified(dir));\n-      reader.close();\n-      dir.close();\n+      final File fileDir = new File(System.getProperty(\"tempDir\"), \"testIndex\");\n+      for(int i=0;i<2;i++) {\n+        try {\n+          final Directory dir;\n+          if (0 == i)\n+            dir = new MockRAMDirectory();\n+          else\n+            dir = getDirectory();\n+          assertFalse(IndexReader.indexExists(dir));\n+          IndexWriter writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n+          addDocumentWithFields(writer);\n+          assertTrue(IndexReader.isLocked(dir));\t\t// writer open, so dir is locked\n+          writer.close();\n+          assertTrue(IndexReader.indexExists(dir));\n+          IndexReader reader = IndexReader.open(dir);\n+          assertFalse(IndexReader.isLocked(dir));\t\t// reader only, no lock\n+          long version = IndexReader.lastModified(dir);\n+          if (i == 1) {\n+            long version2 = IndexReader.lastModified(fileDir);\n+            assertEquals(version, version2);\n+          }\n+          reader.close();\n+          // modify index and check version has been\n+          // incremented:\n+          while(true) {\n+            try {\n+              Thread.sleep(1000);\n+              break;\n+            } catch (InterruptedException ie) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+\n+          writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n+          addDocumentWithFields(writer);\n+          writer.close();\n+          reader = IndexReader.open(dir);\n+          assertTrue(\"old lastModified is \" + version + \"; new lastModified is \" + IndexReader.lastModified(dir), version <= IndexReader.lastModified(dir));\n+          reader.close();\n+          dir.close();\n+        } finally {\n+          if (i == 1)\n+            _TestUtil.rmDir(fileDir);\n+        }\n+      }\n     }\n \n     public void testVersion() throws IOException {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ce9b80539d8b3c1558c08adba8206a4d0c168b25/src/test/org/apache/lucene/index/TestIndexReader.java",
                "sha": "7d7e2eca1c589590ae2d09be0fe3d76190fe3395",
                "status": "modified"
            }
        ],
        "message": "LUCENE-1082: fix NPE in IndexReader.lastModified(*) methods\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@602055 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/11895271a3b455dad1fbc8d92b5e8880bd67dc43",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSegmentInfos.java"
        ]
    },
    "lucene-solr_ced0243": {
        "bug_id": "lucene-solr_ced0243",
        "commit": "https://github.com/apache/lucene-solr/commit/ced0243a3eea9360993035842e556c1daf9f4bd0",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainCategoryRoutedAliasCmd.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainCategoryRoutedAliasCmd.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainCategoryRoutedAliasCmd.java",
                "patch": "@@ -92,9 +92,9 @@ public void call(ClusterState state, ZkNodeProps message, NamedList results) thr\n     final ZkStateReader.AliasesManager aliasesManager = ocmh.zkStateReader.aliasesManager;\n     final Aliases aliases = aliasesManager.getAliases();\n     final Map<String, String> aliasMetadata = aliases.getCollectionAliasProperties(aliasName);\n-    if (aliasMetadata == null) {\n+    if (aliasMetadata.isEmpty()) {\n       throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Alias \" + aliasName + \" does not exist.\"); // if it did exist, we'd have a non-null map\n+          \"Alias \" + aliasName + \" does not exist or is not a routed alias.\"); // if it did exist, we'd have a non-null map\n     }\n     final CategoryRoutedAlias categoryRoutedAlias = (CategoryRoutedAlias) RoutedAlias.fromProps(aliasName, aliasMetadata);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainCategoryRoutedAliasCmd.java",
                "sha": "28787355acd266d1b5cdf226e5347a4e8555d506",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainTimeRoutedAliasCmd.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainTimeRoutedAliasCmd.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainTimeRoutedAliasCmd.java",
                "patch": "@@ -103,9 +103,9 @@ public void call(ClusterState clusterState, ZkNodeProps message, NamedList resul\n     final ZkStateReader.AliasesManager aliasesManager = ocmh.zkStateReader.aliasesManager;\n     final Aliases aliases = aliasesManager.getAliases();\n     final Map<String, String> aliasMetadata = aliases.getCollectionAliasProperties(aliasName);\n-    if (aliasMetadata == null) {\n+    if (aliasMetadata.isEmpty()) {\n       throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Alias \" + aliasName + \" does not exist.\"); // if it did exist, we'd have a non-null map\n+          \"Alias \" + aliasName + \" does not exist or is not a routed alias.\"); // if it did exist, we'd have a non-null map\n     }\n     final TimeRoutedAlias timeRoutedAlias = new TimeRoutedAlias(aliasName, aliasMetadata);\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/cloud/api/collections/MaintainTimeRoutedAliasCmd.java",
                "sha": "c1a015e26416063bc0a9bca36e171921002e0ece",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "patch": "@@ -698,7 +698,7 @@ private static void addStatusToResponse(NamedList<Object> results, RequestStatus\n         Map<String,Map<String,String>> meta = new LinkedHashMap<>();\n         for (String alias : aliases.getCollectionAliasListMap().keySet()) {\n           Map<String, String> collectionAliasProperties = aliases.getCollectionAliasProperties(alias);\n-          if (collectionAliasProperties != null) {\n+          if (!collectionAliasProperties.isEmpty()) {\n             meta.put(alias, collectionAliasProperties);\n           }\n         }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java",
                "sha": "07ec42a84f0031521a47364ae1d617706753077d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "patch": "@@ -105,7 +105,7 @@ public static UpdateRequestProcessor wrap(SolrQueryRequest req, UpdateRequestPro\n   private static Map<String, String> getAliasProps(SolrQueryRequest req, String aliasName) {\n     ZkController zkController = req.getCore().getCoreContainer().getZkController();\n     final Map<String, String> aliasProperties = zkController.getZkStateReader().getAliases().getCollectionAliasProperties(aliasName);\n-    if (aliasProperties == null) {\n+    if (aliasProperties.isEmpty()) {\n       throw RoutedAlias.newAliasMustExistException(aliasName); // if it did exist, we'd have a non-null map\n     }\n     return aliasProperties;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/core/src/java/org/apache/solr/update/processor/RoutedAliasUpdateProcessor.java",
                "sha": "13dd731b53f9535f25430a5182ef4dd8e39e98b0",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 1,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java",
                "patch": "@@ -246,7 +246,7 @@ public String resolveSimpleAlias(String aliasName) throws IllegalArgumentExcepti\n   @Override\n   public Map<String, String> getAliasProperties(String alias) {\n     getAliases(false);\n-    return Collections.unmodifiableMap(aliasProperties.get(alias));\n+    return Collections.unmodifiableMap(aliasProperties.getOrDefault(alias, Collections.emptyMap()));\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/solrj/src/java/org/apache/solr/client/solrj/impl/BaseHttpClusterStateProvider.java",
                "sha": "87f4a2fe7f4b5d156de865adcd93996baf338f7a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/solrj/src/java/org/apache/solr/common/cloud/Aliases.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/common/cloud/Aliases.java?ref=ced0243a3eea9360993035842e556c1daf9f4bd0",
                "deletions": 3,
                "filename": "solr/solrj/src/java/org/apache/solr/common/cloud/Aliases.java",
                "patch": "@@ -160,11 +160,10 @@ public int getZNodeVersion() {\n   }\n \n   /**\n-   * Returns an unmodifiable Map of properties for a given alias. If an alias by the given name\n-   * exists, this method will never return null.\n+   * Returns an unmodifiable Map of properties for a given alias. This method will never return null.\n    *\n    * @param alias the name of an alias also found as a key in {@link #getCollectionAliasListMap()}\n-   * @return The properties for the alias (possibly empty) or null if the alias does not exist.\n+   * @return The properties for the alias (possibly empty).\n    */\n   public Map<String,String> getCollectionAliasProperties(String alias) {\n     // Note: map is already unmodifiable; it can be shared safely",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ced0243a3eea9360993035842e556c1daf9f4bd0/solr/solrj/src/java/org/apache/solr/common/cloud/Aliases.java",
                "sha": "6f97c2525231ade68c761d6c5b5a368dbc7e31ea",
                "status": "modified"
            }
        ],
        "message": "SOLR-13407: Fix NPE and be consistent about returning empty instead of null properties.",
        "parent": "https://github.com/apache/lucene-solr/commit/f77c56dbc636ec2305826c1734ae0885f222dd03",
        "repo": "lucene-solr",
        "unit_tests": [
            "RoutedAliasUpdateProcessorTest.java"
        ]
    },
    "lucene-solr_d0ed896": {
        "bug_id": "lucene-solr_d0ed896",
        "commit": "https://github.com/apache/lucene-solr/commit/d0ed896f4b8a03f56bbc575b51919ab677795318",
        "file": [
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d0ed896f4b8a03f56bbc575b51919ab677795318/src/java/org/apache/solr/common/util/NamedListCodec.java",
                "changes": 49,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/common/util/NamedListCodec.java?ref=d0ed896f4b8a03f56bbc575b51919ab677795318",
                "deletions": 24,
                "filename": "src/java/org/apache/solr/common/util/NamedListCodec.java",
                "patch": "@@ -87,7 +87,7 @@ public NamedList unmarshal(InputStream is) throws IOException {\n   }\n \n \n-  private SimpleOrderedMap readOrderedMap(FastInputStream dis) throws IOException {\n+  public SimpleOrderedMap readOrderedMap(FastInputStream dis) throws IOException {\n     int sz = readSize(dis);\n     SimpleOrderedMap nl = new SimpleOrderedMap();\n     for (int i = 0; i < sz; i++) {\n@@ -98,7 +98,7 @@ private SimpleOrderedMap readOrderedMap(FastInputStream dis) throws IOException\n     return nl;\n   }\n \n-  private NamedList readNamedList(FastInputStream dis) throws IOException {\n+  public NamedList readNamedList(FastInputStream dis) throws IOException {\n     int sz = readSize(dis);\n     NamedList nl = new NamedList();\n     for (int i = 0; i < sz; i++) {\n@@ -109,7 +109,7 @@ private NamedList readNamedList(FastInputStream dis) throws IOException {\n     return nl;\n   }\n \n-  private void writeNamedList(NamedList nl) throws IOException {\n+  public void writeNamedList(NamedList nl) throws IOException {\n     writeTag(nl instanceof SimpleOrderedMap ? ORDERED_MAP : NAMED_LST, nl.size());\n     for (int i = 0; i < nl.size(); i++) {\n       String name = nl.getName(i);\n@@ -135,7 +135,7 @@ public void writeVal(Object val) throws IOException {\n   }\n \n   byte tagByte;\n-  private Object readVal(FastInputStream dis) throws IOException {\n+  public Object readVal(FastInputStream dis) throws IOException {\n     tagByte = dis.readByte();\n \n     // if ((tagByte & 0xe0) == 0) {\n@@ -171,7 +171,7 @@ private Object readVal(FastInputStream dis) throws IOException {\n     throw new RuntimeException(\"Unknown type \" + tagByte);\n   }\n \n-  private boolean writeKnownType(Object val) throws IOException {\n+  public boolean writeKnownType(Object val) throws IOException {\n     if (writePrimitive(val)) return true;\n     if (val instanceof NamedList) {\n       writeNamedList((NamedList) val);\n@@ -222,12 +222,12 @@ public void writeTag(byte tag, int size) throws IOException {\n     }\n   }\n \n-  private void writeByteArray(byte[] arr, int offset, int len) throws IOException {\n+  public void writeByteArray(byte[] arr, int offset, int len) throws IOException {\n     writeTag(BYTEARR, len);\n     daos.write(arr, offset, len);\n   }\n \n-  private byte[] readByteArray(FastInputStream dis) throws IOException {\n+  public byte[] readByteArray(FastInputStream dis) throws IOException {\n     byte[] arr = new byte[readVInt(dis)];\n     dis.readFully(arr);\n     return arr;\n@@ -244,7 +244,7 @@ public void writeSolrDocument(SolrDocument doc) throws IOException {\n     }\n   }\n \n-   private SolrDocument readSolrDocument(FastInputStream dis) throws IOException {\n+   public SolrDocument readSolrDocument(FastInputStream dis) throws IOException {\n     NamedList nl = (NamedList) readVal(dis);\n     SolrDocument doc = new SolrDocument();\n     for (int i = 0; i < nl.size(); i++) {\n@@ -255,7 +255,7 @@ private SolrDocument readSolrDocument(FastInputStream dis) throws IOException {\n     return doc;\n   }\n \n-  private SolrDocumentList readSolrDocumentList(FastInputStream dis) throws IOException {\n+  public SolrDocumentList readSolrDocumentList(FastInputStream dis) throws IOException {\n     SolrDocumentList solrDocs = new SolrDocumentList();\n     List list = (List) readVal(dis);\n     solrDocs.setNumFound((Long) list.get(0));\n@@ -267,7 +267,7 @@ private SolrDocumentList readSolrDocumentList(FastInputStream dis) throws IOExce\n     return solrDocs;\n   }\n \n-   private void writeSolrDocumentList(SolrDocumentList docs)\n+   public void writeSolrDocumentList(SolrDocumentList docs)\n          throws IOException {\n      writeTag(SOLRDOCLST);\n      List l = new ArrayList(3);\n@@ -278,7 +278,7 @@ private void writeSolrDocumentList(SolrDocumentList docs)\n      writeArray(docs);\n    }\n \n-  private Map readMap(FastInputStream dis)\n+  public Map readMap(FastInputStream dis)\n           throws IOException {\n     int sz = readVInt(dis);\n     Map m = new LinkedHashMap();\n@@ -291,7 +291,7 @@ private Map readMap(FastInputStream dis)\n     return m;\n   }\n \n-  private void writeIterator(Iterator iter) throws IOException {\n+  public void writeIterator(Iterator iter) throws IOException {\n     ArrayList l = new ArrayList();\n     while (iter.hasNext()) l.add(iter.next());\n     writeArray(l);\n@@ -312,7 +312,7 @@ public void writeArray(Object[] arr) throws IOException {\n     }\n   }\n \n-  private List readArray(FastInputStream dis) throws IOException {\n+  public List readArray(FastInputStream dis) throws IOException {\n     int sz = readSize(dis);\n     ArrayList l = new ArrayList(sz);\n     for (int i = 0; i < sz; i++) {\n@@ -324,9 +324,10 @@ private List readArray(FastInputStream dis) throws IOException {\n   /** write the string as tag+length, with length being the number of UTF-16 characters,\n    * followed by the string encoded in modified-UTF8 \n    */\n-  private void writeStr(String s) throws IOException {\n+  public void writeStr(String s) throws IOException {\n     if (s==null) {\n       writeTag(NULL);\n+      return;\n     }\n     // Can't use string serialization or toUTF()... it's limited to 64K\n     // plus it's bigger than it needs to be for small strings anyway\n@@ -346,7 +347,7 @@ private String readStr(FastInputStream dis) throws IOException {\n     return new String(charArr, 0, sz);\n   }\n \n-  private void writeInt(int val) throws IOException {\n+  public void writeInt(int val) throws IOException {\n     if (val>0) {\n       int b = SINT | (val & 0x0f);\n \n@@ -364,15 +365,15 @@ private void writeInt(int val) throws IOException {\n     }\n   }\n \n-  private int readSmallInt(FastInputStream dis) throws IOException {\n+  public int readSmallInt(FastInputStream dis) throws IOException {\n     int v = tagByte & 0x0F;\n     if ((tagByte & 0x10) != 0)\n       v = (readVInt(dis)<<4) | v;\n     return v;\n   }\n \n \n-  private void writeLong(long val) throws IOException {\n+  public void writeLong(long val) throws IOException {\n     if ((val & 0xff00000000000000L) == 0) {\n       int b = SLONG | ((int)val & 0x0f);\n       if (val >= 0x0f) {\n@@ -388,14 +389,14 @@ private void writeLong(long val) throws IOException {\n     }\n   }\n \n-  private long readSmallLong(FastInputStream dis) throws IOException {\n+  public long readSmallLong(FastInputStream dis) throws IOException {\n     long v = tagByte & 0x0F;\n     if ((tagByte & 0x10) != 0)\n       v = (readVLong(dis)<<4) | v;\n     return v;\n   }\n \n-  private boolean writePrimitive(Object val) throws IOException {\n+  public boolean writePrimitive(Object val) throws IOException {\n     if (val == null) {\n       daos.writeByte(NULL);\n       return true;\n@@ -439,7 +440,7 @@ private boolean writePrimitive(Object val) throws IOException {\n     return false;\n   }\n \n-  private void writeMap( Map val)\n+  public void writeMap( Map val)\n           throws IOException {\n     writeTag(MAP, val.size());\n     for (Map.Entry entry : (Set<Map.Entry>) val.entrySet()) {\n@@ -449,7 +450,7 @@ private void writeMap( Map val)\n   }\n \n \n-  private int readSize(FastInputStream in) throws IOException {\n+  public int readSize(FastInputStream in) throws IOException {\n     int sz = tagByte & 0x1f;\n     if (sz == 0x1f) sz += readVInt(in);\n     return sz;\n@@ -465,7 +466,7 @@ private int readSize(FastInputStream in) throws IOException {\n    * @param out\n    * @throws IOException\n    */\n-  private static void writeVInt(int i, FastOutputStream out) throws IOException {\n+  public static void writeVInt(int i, FastOutputStream out) throws IOException {\n     while ((i & ~0x7F) != 0) {\n       out.writeByte((byte) ((i & 0x7f) | 0x80));\n       i >>>= 7;\n@@ -491,15 +492,15 @@ public static int readVInt(FastInputStream in) throws IOException {\n   }\n \n \n-  private static void writeVLong(long i, FastOutputStream out) throws IOException {\n+  public static void writeVLong(long i, FastOutputStream out) throws IOException {\n     while ((i & ~0x7F) != 0) {\n       out.writeByte((byte)((i & 0x7f) | 0x80));\n       i >>>= 7;\n     }\n     out.writeByte((byte) i);\n   }\n \n-  private static long readVLong(FastInputStream in) throws IOException {\n+  public static long readVLong(FastInputStream in) throws IOException {\n     byte b = in.readByte();\n     long i = b & 0x7F;\n     for (int shift = 7; (b & 0x80) != 0; shift += 7) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d0ed896f4b8a03f56bbc575b51919ab677795318/src/java/org/apache/solr/common/util/NamedListCodec.java",
                "sha": "fa3608b4621697720356ebc50ec8f4a4251f43d5",
                "status": "modified"
            }
        ],
        "message": "SOLR-562: Namedlistcodec throws NPE for null names\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@653511 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/f3ed5f8424b47d087a3c8c4a5d48058d3e17ed35",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestNamedListCodec.java"
        ]
    },
    "lucene-solr_d2a2cc1": {
        "bug_id": "lucene-solr_d2a2cc1",
        "commit": "https://github.com/apache/lucene-solr/commit/d2a2cc12dc7cf85eeacf939f76e9d0457a254047",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=d2a2cc12dc7cf85eeacf939f76e9d0457a254047",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -307,6 +307,9 @@ Bug Fixes\n   switching shard states. Multiple bugs related to sub shard recovery and\n   replication are also fixed. (shalin)\n \n+* SOLR-5034: A facet.query that parses or analyzes down to a null Query would\n+  throw a NPE. Fixed. (David Smiley)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/CHANGES.txt",
                "sha": "a6d887b4ce2965c16249369325126894d388271b",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/request/SimpleFacets.java?ref=d2a2cc12dc7cf85eeacf939f76e9d0457a254047",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "patch": "@@ -295,7 +295,9 @@ protected void parseParams(String type, String param) throws SyntaxError, IOExce\n         // TODO: slight optimization would prevent double-parsing of any localParams\n         Query qobj = QParser.getParser(q, null, req).getQuery();\n \n-        if (params.getBool(GroupParams.GROUP_FACET, false)) {\n+        if (qobj == null) {\n+          res.add(key, 0);\n+        } else if (params.getBool(GroupParams.GROUP_FACET, false)) {\n           res.add(key, getGroupedFacetQueryCount(qobj));\n         } else {\n           res.add(key, searcher.numDocs(qobj, docs));",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/core/src/java/org/apache/solr/request/SimpleFacets.java",
                "sha": "7822c1e7f80da6290b2215564a9d1e775a741720",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/core/src/test/org/apache/solr/request/SimpleFacetsTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/request/SimpleFacetsTest.java?ref=d2a2cc12dc7cf85eeacf939f76e9d0457a254047",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/request/SimpleFacetsTest.java",
                "patch": "@@ -621,6 +621,13 @@ public void testSimpleFacetCounts() {\n                 )\n             ,\"*[count(//lst[@name='zerolen_s']/int)=1]\"\n      );\n+\n+    assertQ(\"a facet.query that analyzes to no query shoud not NPE\",\n+        req(\"q\", \"*:*\",\n+            \"facet\", \"true\",\n+            \"facet.query\", \"{!field key=k f=lengthfilt}a\"),//2 char minimum\n+        \"//lst[@name='facet_queries']/int[@name='k'][.='0']\"\n+    );\n   }\n \n   public static void indexDateFacets() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d2a2cc12dc7cf85eeacf939f76e9d0457a254047/solr/core/src/test/org/apache/solr/request/SimpleFacetsTest.java",
                "sha": "b516200943586f46f186a1c84b1ad15319611c56",
                "status": "modified"
            }
        ],
        "message": "SOLR-5034: A facet.query that parses or analyzes down to a null Query would throw a NPE.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1502730 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/792bae8b26c7357196e0824e67b27a28b75c288f",
        "repo": "lucene-solr",
        "unit_tests": [
            "SimpleFacetsTest.java"
        ]
    },
    "lucene-solr_d34f549": {
        "bug_id": "lucene-solr_d34f549",
        "commit": "https://github.com/apache/lucene-solr/commit/d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -121,6 +121,8 @@ Bug Fixes\n \n * SOLR-9979: Macro expansion should not be done in shard requests (Tom\u00e1s Fern\u00e1ndez L\u00f6bbe)\n \n+* SOLR-9114: NPE using TermVectorComponent, MoreLikeThisComponent in combination with ExactStatsCache (Cao Manh Dat, Varun Thacker)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/CHANGES.txt",
                "sha": "a68f4454191ec72855a337099d6746d2f7cf261b",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java?ref=d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "patch": "@@ -221,7 +221,17 @@ public void finishStage(ResponseBuilder rb) {\n     }\n     super.finishStage(rb);\n   }\n-  \n+\n+  @Override\n+  public void modifyRequest(ResponseBuilder rb, SearchComponent who, ShardRequest sreq) {\n+    SolrParams params = rb.req.getParams();\n+    if (!params.getBool(COMPONENT_NAME, false)) return;\n+    if ((sreq.purpose & ShardRequest.PURPOSE_GET_MLT_RESULTS) == 0\n+        && (sreq.purpose & ShardRequest.PURPOSE_GET_TOP_IDS) == 0) {\n+      sreq.params.set(COMPONENT_NAME, \"false\");\n+    }\n+  }\n+\n   /**\n    * Returns NamedList based on the order of\n    * resultIds.shardDoc.positionInResponse",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/java/org/apache/solr/handler/component/MoreLikeThisComponent.java",
                "sha": "55edc631114c7c7ab31dde9ec2662eb83e51902a",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java?ref=d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
                "deletions": 0,
                "filename": "solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "patch": "@@ -464,6 +464,15 @@ public void finishStage(ResponseBuilder rb) {\n     }\n   }\n \n+  @Override\n+  public void modifyRequest(ResponseBuilder rb, SearchComponent who, ShardRequest sreq) {\n+    SolrParams params = rb.req.getParams();\n+    if (!params.getBool(COMPONENT_NAME, false)) return;\n+    if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) == 0) {\n+      sreq.params.set(COMPONENT_NAME, \"false\");\n+    }\n+  }\n+\n   //////////////////////// NamedListInitializedPlugin methods //////////////////////\n \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent.java",
                "sha": "e81ed85f8788023af9c9e798e35357687b886a44",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/test/org/apache/solr/handler/component/DistributedMLTComponentTest.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/DistributedMLTComponentTest.java?ref=d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/DistributedMLTComponentTest.java",
                "patch": "@@ -20,11 +20,17 @@\n import java.util.Map;\n \n import org.apache.lucene.util.LuceneTestCase.Slow;\n+import org.apache.lucene.util.TestUtil;\n import org.apache.solr.BaseDistributedSearchTestCase;\n import org.apache.solr.client.solrj.response.QueryResponse;\n import org.apache.solr.common.SolrDocumentList;\n import org.apache.solr.common.params.MoreLikeThisParams;\n import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.search.stats.ExactStatsCache;\n+import org.apache.solr.search.stats.LRUStatsCache;\n+import org.apache.solr.search.stats.LocalStatsCache;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n import org.junit.Test;\n \n /**\n@@ -49,6 +55,23 @@ public void distribSetUp() throws Exception {\n     requestHandlerName = \"mltrh\";\n     super.distribSetUp();\n   }\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    int statsType = TestUtil.nextInt(random(), 1, 3);\n+    if (statsType == 1) {\n+      System.setProperty(\"solr.statsCache\", ExactStatsCache.class.getName());\n+    } else if (statsType == 2) {\n+      System.setProperty(\"solr.statsCache\", LRUStatsCache.class.getName());\n+    } else {\n+      System.setProperty(\"solr.statsCache\", LocalStatsCache.class.getName());\n+    }\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    System.clearProperty(\"solr.statsCache\");\n+  }\n   \n   @Test\n   @ShardsFixed(num = 3)",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/test/org/apache/solr/handler/component/DistributedMLTComponentTest.java",
                "sha": "10116b971c60c85f33fa20b0e962b1706a642909",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentDistributedTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentDistributedTest.java?ref=d34f549df6cee0db7cbff1ec2639262c2f7e21e2",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentDistributedTest.java",
                "patch": "@@ -18,9 +18,14 @@\n \n import org.apache.lucene.util.Constants;\n \n+import org.apache.lucene.util.TestUtil;\n import org.apache.solr.BaseDistributedSearchTestCase;\n import org.apache.solr.common.params.ShardParams;\n import org.apache.solr.common.params.TermVectorParams;\n+import org.apache.solr.search.stats.ExactStatsCache;\n+import org.apache.solr.search.stats.LRUStatsCache;\n+import org.apache.solr.search.stats.LocalStatsCache;\n+import org.junit.AfterClass;\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n@@ -29,6 +34,19 @@\n   public static void betterNotBeJ9() {\n     assumeFalse(\"FIXME: SOLR-5792: This test fails under IBM J9\", \n                 Constants.JAVA_VENDOR.startsWith(\"IBM\"));\n+    int statsType = TestUtil.nextInt(random(), 1, 3);\n+    if (statsType == 1) {\n+      System.setProperty(\"solr.statsCache\", ExactStatsCache.class.getName());\n+    } else if (statsType == 2) {\n+      System.setProperty(\"solr.statsCache\", LRUStatsCache.class.getName());\n+    } else {\n+      System.setProperty(\"solr.statsCache\", LocalStatsCache.class.getName());\n+    }\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    System.clearProperty(\"solr.statsCache\");\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d34f549df6cee0db7cbff1ec2639262c2f7e21e2/solr/core/src/test/org/apache/solr/handler/component/TermVectorComponentDistributedTest.java",
                "sha": "0527d9e50749667de2684b0243d3460aa072e318",
                "status": "modified"
            }
        ],
        "message": "SOLR-9114: NPE using TermVectorComponent, MoreLikeThisComponent in combination with ExactStatsCache",
        "parent": "https://github.com/apache/lucene-solr/commit/6693c261e5782bc49dea92002745a91215c4166e",
        "repo": "lucene-solr",
        "unit_tests": [
            "MoreLikeThisComponentTest.java",
            "TermVectorComponentTest.java"
        ]
    },
    "lucene-solr_d67884a": {
        "bug_id": "lucene-solr_d67884a",
        "commit": "https://github.com/apache/lucene-solr/commit/d67884a07c2946f10e505a80529af652c9162a08",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d67884a07c2946f10e505a80529af652c9162a08/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=d67884a07c2946f10e505a80529af652c9162a08",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -132,6 +132,9 @@ Bug Fixes\n * SOLR-6037: Fixed incorrect max/sum/stddev for Date fields in StatsComponent\n   (Brett Lucey, hossman)\n \n+* SOLR-6023: FieldAnalysisRequestHandler throws NPE if no parameters are supplied.\n+  (shalin)\n+\n Other Changes\n ---------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d67884a07c2946f10e505a80529af652c9162a08/solr/CHANGES.txt",
                "sha": "64a0b917ad1f8a56575c2dce6dd5167cd8c5dd55",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d67884a07c2946f10e505a80529af652c9162a08/solr/core/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java?ref=d67884a07c2946f10e505a80529af652c9162a08",
                "deletions": 1,
                "filename": "solr/core/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "patch": "@@ -139,7 +139,7 @@ FieldAnalysisRequest resolveAnalysisRequest(SolrQueryRequest req) {\n     }\n     analysisRequest.setQuery(solrParams.get(AnalysisParams.QUERY, solrParams.get(CommonParams.Q)));\n \n-    String value = solrParams.get(AnalysisParams.FIELD_VALUE);\n+    String value = solrParams.required().get(AnalysisParams.FIELD_VALUE);\n \n     Iterable<ContentStream> streams = req.getContentStreams();\n     if (streams != null) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d67884a07c2946f10e505a80529af652c9162a08/solr/core/src/java/org/apache/solr/handler/FieldAnalysisRequestHandler.java",
                "sha": "e1044da2e835821033b3a271ed16e8790ff626cc",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d67884a07c2946f10e505a80529af652c9162a08/solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java?ref=d67884a07c2946f10e505a80529af652c9162a08",
                "deletions": 1,
                "filename": "solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "patch": "@@ -19,6 +19,7 @@\n \n import org.apache.lucene.analysis.MockTokenizer;\n import org.apache.lucene.analysis.core.WhitespaceTokenizer;\n+import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.AnalysisParams;\n import org.apache.solr.common.params.CommonParams;\n import org.apache.solr.common.params.ModifiableSolrParams;\n@@ -379,5 +380,20 @@ public void testPositionHistoryWithWDF() throws Exception {\n     assertToken(tokenList.get(4), new TokenInfo(\"a\", null, \"word\", 12, 13, 4, new int[]{3,4,4}, null, false));\n     assertToken(tokenList.get(5), new TokenInfo(\"test\", null, \"word\", 14, 18, 5, new int[]{4,5,5}, null, false));\n   }\n-  \n+\n+  public void testRequiredParamHandling() throws Exception {\n+    ModifiableSolrParams params = new ModifiableSolrParams();\n+    params.add(CommonParams.Q, \"fox brown\");\n+\n+    SolrQueryRequest req = new LocalSolrQueryRequest(h.getCore(), params);\n+    try {\n+      FieldAnalysisRequest request = handler.resolveAnalysisRequest(req);\n+      fail(\"A request with no parameters should not have succeeded\");\n+    } catch (NullPointerException npe) {\n+      fail(\"A request with no paramters should not result in NPE\");\n+    } catch (SolrException e) {\n+      assertEquals(\"A request with no parameters should have returned a BAD_REQUEST error\", e.code(),\n+          SolrException.ErrorCode.BAD_REQUEST.code);\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d67884a07c2946f10e505a80529af652c9162a08/solr/core/src/test/org/apache/solr/handler/FieldAnalysisRequestHandlerTest.java",
                "sha": "43cec6afe7766743e450f2a9a783e7e43c8ddb9f",
                "status": "modified"
            }
        ],
        "message": "SOLR-6023: FieldAnalysisRequestHandler throws NPE if no parameters are supplied\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1592195 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/7db6edeb75b4a973285033b67a8a05cd5c48a1b6",
        "repo": "lucene-solr",
        "unit_tests": [
            "FieldAnalysisRequestHandlerTest.java"
        ]
    },
    "lucene-solr_d897920": {
        "bug_id": "lucene-solr_d897920",
        "commit": "https://github.com/apache/lucene-solr/commit/d8979209bc31076480f5ffa23318fb3aa7229ccd",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d8979209bc31076480f5ffa23318fb3aa7229ccd/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/CHANGES.txt?ref=d8979209bc31076480f5ffa23318fb3aa7229ccd",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -193,6 +193,10 @@ API Changes\n 17. LUCENE-780: Add a static Directory.copy() method to copy files\n     from one Directory to another.  (Jiri Kuhn via Mike McCandless)\n \n+18. LUCENE-773: Added Directory.clearLock(String name) to forcefully\n+    remove an old lock.  The default implementation is to ask the\n+    lockFactory (if non null) to clear the lock.  (Mike McCandless)\n+\n Bug fixes\n \n  1. Fixed the web application demo (built with \"ant war-demo\") which",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d8979209bc31076480f5ffa23318fb3aa7229ccd/CHANGES.txt",
                "sha": "d8c46052be773b4fe1ef597ce95a2c922fd77b47",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/java/org/apache/lucene/index/IndexWriter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/IndexWriter.java?ref=d8979209bc31076480f5ffa23318fb3aa7229ccd",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/index/IndexWriter.java",
                "patch": "@@ -333,7 +333,7 @@ private void init(Directory d, Analyzer a, final boolean create, boolean closeDi\n \n     if (create) {\n       // Clear the write lock in case it's leftover:\n-      directory.getLockFactory().clearLock(IndexWriter.WRITE_LOCK_NAME);\n+      directory.clearLock(IndexWriter.WRITE_LOCK_NAME);\n     }\n \n     Lock writeLock = directory.makeLock(IndexWriter.WRITE_LOCK_NAME);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/java/org/apache/lucene/index/IndexWriter.java",
                "sha": "473ba4270cd4d41be7154edb490d851e776ebd07",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/java/org/apache/lucene/store/Directory.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/store/Directory.java?ref=d8979209bc31076480f5ffa23318fb3aa7229ccd",
                "deletions": 1,
                "filename": "src/java/org/apache/lucene/store/Directory.java",
                "patch": "@@ -88,6 +88,17 @@ public abstract IndexInput openInput(String name)\n   public Lock makeLock(String name) {\n       return lockFactory.makeLock(name);\n   }\n+  /**\n+   * Attempt to clear (forcefully unlock and remove) the\n+   * specified lock.  Only call this at a time when you are\n+   * certain this lock is no longer in use.\n+   * @param lockName name of the lock to be cleared.\n+   */\n+  public void clearLock(String name) throws IOException {\n+    if (lockFactory != null) {\n+      lockFactory.clearLock(name);\n+    }\n+  }\n \n   /** Closes the store. */\n   public abstract void close()\n@@ -106,8 +117,12 @@ public void setLockFactory(LockFactory lockFactory) {\n       this.lockFactory = lockFactory;\n       lockFactory.setLockPrefix(this.getLockID());\n   }\n+\n   /**\n-   * Get the LockFactory that this Directory instance is using for its locking implementation.\n+   * Get the LockFactory that this Directory instance is\n+   * using for its locking implementation.  Note that this\n+   * may be null for Directory implementations that provide\n+   * their own locking implementation.\n    */\n   public LockFactory getLockFactory() {\n       return this.lockFactory;",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/java/org/apache/lucene/store/Directory.java",
                "sha": "158a7a47706dd1a0cbac8bb5f7ccc110ec9e8e58",
                "status": "modified"
            },
            {
                "additions": 40,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/test/org/apache/lucene/index/TestIndexWriter.java?ref=d8979209bc31076480f5ffa23318fb3aa7229ccd",
                "deletions": 0,
                "filename": "src/test/org/apache/lucene/index/TestIndexWriter.java",
                "patch": "@@ -21,6 +21,9 @@\n import org.apache.lucene.store.IndexOutput;\n \n import org.apache.lucene.store.MockRAMDirectory;\n+import org.apache.lucene.store.LockFactory;\n+import org.apache.lucene.store.Lock;\n+import org.apache.lucene.store.SingleInstanceLockFactory;\n \n /**\n  * @author goller\n@@ -690,6 +693,43 @@ public void testSimulatedCorruptIndex2() throws IOException {\n         }\n     }\n \n+    // Make sure that a Directory implementation that does\n+    // not use LockFactory at all (ie overrides makeLock and\n+    // implements its own private locking) works OK.  This\n+    // was raised on java-dev as loss of backwards\n+    // compatibility.\n+    public void testNullLockFactory() throws IOException {\n+\n+      final class MyRAMDirectory extends RAMDirectory {\n+        private LockFactory myLockFactory;\n+        MyRAMDirectory() {\n+          lockFactory = null;\n+          myLockFactory = new SingleInstanceLockFactory();\n+        }\n+        public Lock makeLock(String name) {\n+          return myLockFactory.makeLock(name);\n+        }\n+      }\n+      \n+      Directory dir = new MyRAMDirectory();\n+      IndexWriter writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n+      for (int i = 0; i < 100; i++) {\n+        addDoc(writer);\n+      }\n+      writer.close();\n+      IndexReader reader = IndexReader.open(dir);\n+      Term searchTerm = new Term(\"content\", \"aaa\");        \n+      IndexSearcher searcher = new IndexSearcher(dir);\n+      Hits hits = searcher.search(new TermQuery(searchTerm));\n+      assertEquals(\"did not get right number of hits\", 100, hits.length());\n+      writer.close();\n+\n+      writer  = new IndexWriter(dir, new WhitespaceAnalyzer(), true);\n+      writer.close();\n+\n+      dir.close();\n+    }\n+\n     private void rmDir(File dir) {\n         File[] files = dir.listFiles();\n         if (files != null) {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d8979209bc31076480f5ffa23318fb3aa7229ccd/src/test/org/apache/lucene/index/TestIndexWriter.java",
                "sha": "f6744364eb3dc3d4639bdd2da24e1f9f40ed580e",
                "status": "modified"
            }
        ],
        "message": "LUCENE-773: fixed NPE caused by IndexWriter assuming LockFactory was non-null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@499089 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/3b13126bf560e3ae1fc430b7d53c54e1c5519507",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestIndexWriter.java",
            "TestDirectory.java"
        ]
    },
    "lucene-solr_d90d10e": {
        "bug_id": "lucene-solr_d90d10e",
        "commit": "https://github.com/apache/lucene-solr/commit/d90d10e48e6dfeec37643e4bbdee6c154c473df1",
        "file": [
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/lucene-solr/blob/d90d10e48e6dfeec37643e4bbdee6c154c473df1/solr/src/java/org/apache/solr/search/QueryParsing.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/src/java/org/apache/solr/search/QueryParsing.java?ref=d90d10e48e6dfeec37643e4bbdee6c154c473df1",
                "deletions": 3,
                "filename": "solr/src/java/org/apache/solr/search/QueryParsing.java",
                "patch": "@@ -32,6 +32,8 @@\n import org.apache.lucene.search.TermQuery;\n import org.apache.lucene.search.TermRangeQuery;\n import org.apache.lucene.search.WildcardQuery;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.CharsRef;\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.params.MapSolrParams;\n import org.apache.solr.common.params.SolrParams;\n@@ -382,6 +384,22 @@ static void writeFieldVal(String val, FieldType ft, Appendable out, int flags) t\n     }\n   }\n \n+  static void writeFieldVal(BytesRef val, FieldType ft, Appendable out, int flags) throws IOException {\n+    if (ft != null) {\n+      try {\n+        CharsRef readable = new CharsRef();\n+        ft.indexedToReadable(val, readable);\n+        out.append(readable);\n+      } catch (Exception e) {\n+        out.append(\"EXCEPTION(val=\");\n+        out.append(val.utf8ToString());\n+        out.append(\")\");\n+      }\n+    } else {\n+      out.append(val.utf8ToString());\n+    }\n+  }\n+\n   /**\n    * @see #toString(Query,IndexSchema)\n    */\n@@ -392,14 +410,14 @@ public static void toString(Query query, IndexSchema schema, Appendable out, int\n       TermQuery q = (TermQuery) query;\n       Term t = q.getTerm();\n       FieldType ft = writeFieldName(t.field(), schema, out, flags);\n-      writeFieldVal(t.text(), ft, out, flags);\n+      writeFieldVal(t.bytes(), ft, out, flags);\n     } else if (query instanceof TermRangeQuery) {\n       TermRangeQuery q = (TermRangeQuery) query;\n       String fname = q.getField();\n       FieldType ft = writeFieldName(fname, schema, out, flags);\n       out.append(q.includesLower() ? '[' : '{');\n-      String lt = q.getLowerTerm().utf8ToString();\n-      String ut = q.getUpperTerm().utf8ToString();\n+      BytesRef lt = q.getLowerTerm();\n+      BytesRef ut = q.getUpperTerm();\n       if (lt == null) {\n         out.append('*');\n       } else {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/d90d10e48e6dfeec37643e4bbdee6c154c473df1/solr/src/java/org/apache/solr/search/QueryParsing.java",
                "sha": "22a68f8266a438b257a7bdd1f1885f4782931cf2",
                "status": "modified"
            }
        ],
        "message": "LUCENE-2514: fix NPE in solr's toString when range endpoints are null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1131029 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/6f607a5fda4abddd60a8160c327b18254a7506ce",
        "repo": "lucene-solr",
        "unit_tests": [
            "QueryParsingTest.java"
        ]
    },
    "lucene-solr_da5cfe8": {
        "bug_id": "lucene-solr_da5cfe8",
        "commit": "https://github.com/apache/lucene-solr/commit/da5cfe80340faacaffd65a55550bde40f0c57391",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/da5cfe80340faacaffd65a55550bde40f0c57391/src/java/org/apache/lucene/index/SegmentReader.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/lucene/index/SegmentReader.java?ref=da5cfe80340faacaffd65a55550bde40f0c57391",
                "deletions": 2,
                "filename": "src/java/org/apache/lucene/index/SegmentReader.java",
                "patch": "@@ -242,8 +242,12 @@ synchronized void decRef() throws IOException {\n           storeCFSReader.close();\n         }\n \n-        // Force FieldCache to evict our entries at this point\n-        if (freqStream != null) {\n+        // Force FieldCache to evict our entries at this\n+        // point.  If the exception occurred while\n+        // initialzing the core readers, then\n+        // origInstance will be null, and we don't want\n+        // to call FieldcAche.purge (it leads to NPE):\n+        if (origInstance != null) {\n           FieldCache.DEFAULT.purge(origInstance);\n         }\n       }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/da5cfe80340faacaffd65a55550bde40f0c57391/src/java/org/apache/lucene/index/SegmentReader.java",
                "sha": "6caaf9100fd4a5b05a4fa6a6dc5bde03f09b38ac",
                "status": "modified"
            }
        ],
        "message": "don't throw NPE if an exception is hit while init'ing the core readers in SegmentReader\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@903742 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/e9a979f1eb80733756b0467950e1c2cc70b84800",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSegmentReader.java"
        ]
    },
    "lucene-solr_db01548": {
        "bug_id": "lucene-solr_db01548",
        "commit": "https://github.com/apache/lucene-solr/commit/db01548109792eab06ee0875dda67b2b6a8ea92f",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/db01548109792eab06ee0875dda67b2b6a8ea92f/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java?ref=db01548109792eab06ee0875dda67b2b6a8ea92f",
                "deletions": 3,
                "filename": "lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java",
                "patch": "@@ -34,7 +34,6 @@\n import org.apache.lucene.index.TermsEnum;\n import org.apache.lucene.search.similarities.Similarity;\n import org.apache.lucene.search.spans.SpanNearQuery;\n-import org.apache.lucene.util.Bits;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.automaton.Automaton;\n import org.apache.lucene.util.automaton.Operations;\n@@ -386,20 +385,25 @@ public Scorer scorer(LeafReaderContext context) throws IOException {\n       // Initialize the enums; null for a given slot means that term didn't appear in this reader\n       EnumAndScorer[] enums = new EnumAndScorer[idToTerm.size()];\n \n+      boolean any = false;\n       for(Map.Entry<Integer,TermContext> ent : termStates.entrySet()) {\n         TermContext termContext = ent.getValue();\n         assert termContext.topReaderContext == ReaderUtil.getTopLevelContext(context) : \"The top-reader used to create Weight (\" + termContext.topReaderContext + \") is not the same as the current reader's top-reader (\" + ReaderUtil.getTopLevelContext(context);\n         BytesRef term = idToTerm.get(ent.getKey());\n         TermState state = termContext.get(context.ord);\n         if (state != null) {\n-\n           TermsEnum termsEnum = context.reader().terms(field).iterator();\n           termsEnum.seekExact(term, state);\n           enums[ent.getKey()] = new EnumAndScorer(ent.getKey(), termsEnum.postings(null, PostingsEnum.POSITIONS));\n+          any = true;\n         }\n       }\n \n-      return new TermAutomatonScorer(this, enums, anyTermID, idToTerm, similarity.simScorer(stats, context));\n+      if (any) {\n+        return new TermAutomatonScorer(this, enums, anyTermID, idToTerm, similarity.simScorer(stats, context));\n+      } else {\n+        return null;\n+      }\n     }\n     \n     @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/db01548109792eab06ee0875dda67b2b6a8ea92f/lucene/sandbox/src/java/org/apache/lucene/search/TermAutomatonQuery.java",
                "sha": "2a172d9af36c3e1d6e252d3a6dd5e5e23426709c",
                "status": "modified"
            },
            {
                "additions": 47,
                "blob_url": "https://github.com/apache/lucene-solr/blob/db01548109792eab06ee0875dda67b2b6a8ea92f/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java",
                "changes": 47,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java?ref=db01548109792eab06ee0875dda67b2b6a8ea92f",
                "deletions": 0,
                "filename": "lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java",
                "patch": "@@ -738,4 +738,51 @@ public void testWithCycles2() throws Exception {\n     r.close();\n     dir.close();\n   }\n+\n+  public void testTermDoesNotExist() throws Exception {\n+    Directory dir = newDirectory();\n+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n+    Document doc = new Document();\n+    doc.add(newTextField(\"field\", \"x y z\", Field.Store.NO));\n+    w.addDocument(doc);\n+\n+    IndexReader r = w.getReader();\n+    IndexSearcher s = newSearcher(r);\n+\n+    TokenStream ts = new CannedTokenStream(new Token[] {\n+        token(\"a\", 1, 1),\n+      });\n+\n+    TermAutomatonQuery q = new TokenStreamToTermAutomatonQuery().toQuery(\"field\", ts);\n+    // System.out.println(\"DOT: \" + q.toDot());\n+    assertEquals(0, s.search(q, 1).totalHits);\n+\n+    w.close();\n+    r.close();\n+    dir.close();\n+  }\n+\n+  public void testOneTermDoesNotExist() throws Exception {\n+    Directory dir = newDirectory();\n+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n+    Document doc = new Document();\n+    doc.add(newTextField(\"field\", \"x y z\", Field.Store.NO));\n+    w.addDocument(doc);\n+\n+    IndexReader r = w.getReader();\n+    IndexSearcher s = newSearcher(r);\n+\n+    TokenStream ts = new CannedTokenStream(new Token[] {\n+        token(\"a\", 1, 1),\n+        token(\"x\", 1, 1),\n+      });\n+\n+    TermAutomatonQuery q = new TokenStreamToTermAutomatonQuery().toQuery(\"field\", ts);\n+    // System.out.println(\"DOT: \" + q.toDot());\n+    assertEquals(0, s.search(q, 1).totalHits);\n+\n+    w.close();\n+    r.close();\n+    dir.close();\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/db01548109792eab06ee0875dda67b2b6a8ea92f/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java",
                "sha": "cf4561e01c693beb46fa226de914844073cd9514",
                "status": "modified"
            }
        ],
        "message": "LUCENE-6657: don't throw NPE when a given segment never saw all terms used in the TAQ\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1689133 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/7b2973f40896f5c8bb27c21ea8a591be1f74db81",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestTermAutomatonQuery.java"
        ]
    },
    "lucene-solr_dfc05fa": {
        "bug_id": "lucene-solr_dfc05fa",
        "commit": "https://github.com/apache/lucene-solr/commit/dfc05faa352c7037c4924aafb2f5746872e36448",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/dfc05faa352c7037c4924aafb2f5746872e36448/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java?ref=dfc05faa352c7037c4924aafb2f5746872e36448",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java",
                "patch": "@@ -29,6 +29,7 @@\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicReference;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.util.TestUtil;\n import org.apache.solr.client.solrj.SolrClient;\n import org.apache.solr.client.solrj.SolrRequest;\n@@ -64,6 +65,7 @@\n  *\n  */\n @LogLevel(\"org.apache.solr.cloud.autoscaling=DEBUG\")\n+@LuceneTestCase.AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12181\")\n public class IndexSizeTriggerTest extends SolrCloudTestCase {\n   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/dfc05faa352c7037c4924aafb2f5746872e36448/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java",
                "sha": "3bf702157011eb79098e6e8c7d935fffba72e662",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/dfc05faa352c7037c4924aafb2f5746872e36448/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java?ref=dfc05faa352c7037c4924aafb2f5746872e36448",
                "deletions": 2,
                "filename": "solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "patch": "@@ -1049,9 +1049,14 @@ public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, Interru\n         for (String id : deletes) {\n           Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n           // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n-          String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n+          Replica leader = s.getLeader();\n+          if (leader == null) {\n+            LOG.debug(\"-- no leader in \" + s);\n+            continue;\n+          }\n+          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n           if (numDocsStr == null) {\n-            LOG.debug(\"-- no docs in \" + s.getLeader());\n+            LOG.debug(\"-- no docs in \" + leader);\n             continue;\n           }\n           long numDocs = Long.parseLong(numDocsStr);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/dfc05faa352c7037c4924aafb2f5746872e36448/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java",
                "sha": "12aa9c1a9830d5d0b41755c0087fcf73f2bb467d",
                "status": "modified"
            }
        ],
        "message": "SOLR-12181: Fix NPE. Disable the test until it's fixed.",
        "parent": "https://github.com/apache/lucene-solr/commit/e851b89cbeb1f55edc0f2c1276e2ae812eca2643",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestSimClusterStateProvider.java"
        ]
    },
    "lucene-solr_e2583ca": {
        "bug_id": "lucene-solr_e2583ca",
        "commit": "https://github.com/apache/lucene-solr/commit/e2583ca6ddd6c90b3c0881314e5616c3779d5891",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e2583ca6ddd6c90b3c0881314e5616c3779d5891/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/CHANGES.txt?ref=e2583ca6ddd6c90b3c0881314e5616c3779d5891",
                "deletions": 1,
                "filename": "CHANGES.txt",
                "patch": "@@ -355,7 +355,8 @@ Bug Fixes\n     when no RequestHandler is mapped to \"/update\") now logs error correctly.\n     (hossman)\n \n-\n+26. SOLR-509: Moved firstSearcher event notification to the end of the SolrCore constructor (Koji Sekiguchi via gsingers)\n+    \n Other Changes\n  1. SOLR-135: Moved common classes to org.apache.solr.common and altered the\n     build scripts to make two jars: apache-solr-1.3.jar and ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e2583ca6ddd6c90b3c0881314e5616c3779d5891/CHANGES.txt",
                "sha": "0be158268d7af1bbf71d9a329df643eacd597356",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e2583ca6ddd6c90b3c0881314e5616c3779d5891/src/java/org/apache/solr/core/SolrCore.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/src/java/org/apache/solr/core/SolrCore.java?ref=e2583ca6ddd6c90b3c0881314e5616c3779d5891",
                "deletions": 17,
                "filename": "src/java/org/apache/solr/core/SolrCore.java",
                "patch": "@@ -396,6 +396,29 @@ public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema sche\n       // Finally tell anyone who wants to know\n       loader.inform( loader );\n       loader.inform( this );\n+      \n+      // execute firstSearcher event\n+      //TODO: It may not always be the case that this is the only time the first searcher event needs to fire.\n+      doFirstSearcherEvent(getSearcher().get());\n+    }\n+  }\n+  \n+  private void doFirstSearcherEvent(final SolrIndexSearcher firstSearcher){\n+    if (firstSearcherListeners.size() > 0) {\n+      searcherExecutor.submit(\n+              new Callable() {\n+                public Object call() throws Exception {\n+                  try {\n+                    for (SolrEventListener listener : firstSearcherListeners) {\n+                      listener.newSearcher(firstSearcher,null);\n+                    }\n+                  } catch (Throwable e) {\n+                    SolrException.logOnce(log,null,e);\n+                  }\n+                  return null;\n+                }\n+              }\n+      );\n     }\n   }\n \n@@ -780,23 +803,6 @@ public Object call() throws Exception {\n         );\n       }\n \n-      if (currSearcher==null && firstSearcherListeners.size() > 0) {\n-        future = searcherExecutor.submit(\n-                new Callable() {\n-                  public Object call() throws Exception {\n-                    try {\n-                      for (SolrEventListener listener : firstSearcherListeners) {\n-                        listener.newSearcher(newSearcher,null);\n-                      }\n-                    } catch (Throwable e) {\n-                      SolrException.logOnce(log,null,e);\n-                    }\n-                    return null;\n-                  }\n-                }\n-        );\n-      }\n-\n       if (currSearcher!=null && newSearcherListeners.size() > 0) {\n         future = searcherExecutor.submit(\n                 new Callable() {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e2583ca6ddd6c90b3c0881314e5616c3779d5891/src/java/org/apache/solr/core/SolrCore.java",
                "sha": "e242642551270aca0d7885df9165972543a26ec2",
                "status": "modified"
            }
        ],
        "message": "SOLR-509: Fix NPE when starting up SolrCore due to FirstSearcher event not being initialized\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@649046 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/783bd8c9e94ddc9ff1f55d837edc8d70ed280753",
        "repo": "lucene-solr",
        "unit_tests": [
            "SolrCoreTest.java"
        ]
    },
    "lucene-solr_e670e32": {
        "bug_id": "lucene-solr_e670e32",
        "commit": "https://github.com/apache/lucene-solr/commit/e670e324717e6f0098cc4f1211ba276f6cd2989e",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 1,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java",
                "patch": "@@ -120,7 +120,7 @@ public ClassicTokenizer(Version matchVersion, AttributeFactory factory, Reader i\n   }\n \n   private void init(Version matchVersion) {\n-    this.scanner = new ClassicTokenizerImpl(input);\n+    this.scanner = new ClassicTokenizerImpl(null); // best effort NPE if you dont call reset\n   }\n \n   // this tokenizer generates three attributes:",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java",
                "sha": "c837ab3e8d84fffa719cc639f24e542827304778",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 1,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java",
                "patch": "@@ -134,7 +134,7 @@ public StandardTokenizer(Version matchVersion, AttributeFactory factory, Reader\n   }\n \n   private final void init(Version matchVersion) {\n-    this.scanner = new StandardTokenizerImpl(input);\n+    this.scanner = new StandardTokenizerImpl(null); // best effort NPE if you dont call reset\n   }\n \n   // this tokenizer generates three attributes:",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java",
                "sha": "ed83d9e87391ffd51aedac71b5b7ec9e53b5c126",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 5,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java",
                "patch": "@@ -98,27 +98,27 @@ public int getMaxTokenLength() {\n    */\n   public UAX29URLEmailTokenizer(Version matchVersion, Reader input) {\n     super(input);\n-    this.scanner = getScannerFor(matchVersion, input);\n+    this.scanner = getScannerFor(matchVersion);\n   }\n \n   /**\n    * Creates a new UAX29URLEmailTokenizer with a given {@link AttributeSource}. \n    */\n   public UAX29URLEmailTokenizer(Version matchVersion, AttributeSource source, Reader input) {\n     super(source, input);\n-    this.scanner = getScannerFor(matchVersion, input);\n+    this.scanner = getScannerFor(matchVersion);\n   }\n \n   /**\n    * Creates a new UAX29URLEmailTokenizer with a given {@link AttributeFactory} \n    */\n   public UAX29URLEmailTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {\n     super(factory, input);\n-    this.scanner = getScannerFor(matchVersion, input);\n+    this.scanner = getScannerFor(matchVersion);\n   }\n \n-  private static StandardTokenizerInterface getScannerFor(Version matchVersion, Reader input) {\n-    return new UAX29URLEmailTokenizerImpl(input);\n+  private static StandardTokenizerInterface getScannerFor(Version matchVersion) {\n+    return new UAX29URLEmailTokenizerImpl(null); // best effort NPE if you dont call reset\n   }\n \n   // this tokenizer generates three attributes:",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizer.java",
                "sha": "6d3251befcd0ccf7cc5dce14f120f2372908bc29",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 3,
                "filename": "lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java",
                "patch": "@@ -143,7 +143,7 @@ public WikipediaTokenizer(Reader input) {\n    */\n   public WikipediaTokenizer(Reader input, int tokenOutput, Set<String> untokenizedTypes) {\n     super(input);\n-    this.scanner = new WikipediaTokenizerImpl(input);\n+    this.scanner = new WikipediaTokenizerImpl(null); // best effort NPE if you dont call reset\n     init(tokenOutput, untokenizedTypes);\n   }\n \n@@ -156,7 +156,7 @@ public WikipediaTokenizer(Reader input, int tokenOutput, Set<String> untokenized\n    */\n   public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set<String> untokenizedTypes) {\n     super(factory, input);\n-    this.scanner = new WikipediaTokenizerImpl(input);\n+    this.scanner = new WikipediaTokenizerImpl(null); // best effort NPE if you dont call reset\n     init(tokenOutput, untokenizedTypes);\n   }\n \n@@ -169,7 +169,7 @@ public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutpu\n    */\n   public WikipediaTokenizer(AttributeSource source, Reader input, int tokenOutput, Set<String> untokenizedTypes) {\n     super(source, input);\n-    this.scanner = new WikipediaTokenizerImpl(input);\n+    this.scanner = new WikipediaTokenizerImpl(null); // best effort NPE if you dont call reset\n     init(tokenOutput, untokenizedTypes);\n   }\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizer.java",
                "sha": "0d8029af649f0b928f0c232792c79d13c0f30b35",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 0,
                "filename": "lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "patch": "@@ -52,9 +52,12 @@ public void testElision() throws Exception {\n   private List<String> filter(TokenFilter filter) throws IOException {\n     List<String> tas = new ArrayList<String>();\n     CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);\n+    filter.reset();\n     while (filter.incrementToken()) {\n       tas.add(termAtt.toString());\n     }\n+    filter.end();\n+    filter.close();\n     return tas;\n   }\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestElision.java",
                "sha": "0d5cead735f7577c26aa445e39f7d8e06a11bfd0",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikAnalyzer.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikAnalyzer.java?ref=e670e324717e6f0098cc4f1211ba276f6cd2989e",
                "deletions": 0,
                "filename": "lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikAnalyzer.java",
                "patch": "@@ -62,12 +62,16 @@ public final void testLeftoverStems() throws IOException {\n     ts_1.reset();\n     ts_1.incrementToken();\n     assertEquals(\"first stream\", \"li\u015bcie\", termAtt_1.toString());\n+    ts_1.end();\n+    ts_1.close();\n \n     TokenStream ts_2 = a.tokenStream(\"dummy\", new StringReader(\"danych\"));\n     CharTermAttribute termAtt_2 = ts_2.getAttribute(CharTermAttribute.class);\n     ts_2.reset();\n     ts_2.incrementToken();\n     assertEquals(\"second stream\", \"dany\", termAtt_2.toString());\n+    ts_2.end();\n+    ts_2.close();\n   }\n \n   /** Test stemming of mixed-case tokens. */\n@@ -110,6 +114,7 @@ private void assertPOSToken(TokenStream ts, String term, String... tags) throws\n   public final void testPOSAttribute() throws IOException {\n     TokenStream ts = getTestAnalyzer().tokenStream(\"dummy\", new StringReader(\"li\u015bcie\"));\n \n+    ts.reset();\n     assertPOSToken(ts, \"li\u015bcie\",  \n         \"subst:sg:acc:n2\",\n         \"subst:sg:nom:n2\",\n@@ -127,6 +132,8 @@ public final void testPOSAttribute() throws IOException {\n     assertPOSToken(ts, \"lista\", \n         \"subst:sg:dat:f\",\n         \"subst:sg:loc:f\");\n+    ts.end();\n+    ts.close();\n   }\n \n   /** blast some random strings through the analyzer */",
                "raw_url": "https://github.com/apache/lucene-solr/raw/e670e324717e6f0098cc4f1211ba276f6cd2989e/lucene/analysis/morfologik/src/test/org/apache/lucene/analysis/morfologik/TestMorfologikAnalyzer.java",
                "sha": "c26d403127b3245823e6be6684faa25a8a9ac8db",
                "status": "modified"
            }
        ],
        "message": "throw a best-effort NPE from the jflex-based tokenizers if you don't consume the TS correctly\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1401449 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/9caa4a68bdfcce10dd53db0186ff03023341499f",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestUAX29URLEmailTokenizer.java",
            "WikipediaTokenizerTest.java"
        ]
    },
    "lucene-solr_eb104d2": {
        "bug_id": "lucene-solr_eb104d2",
        "commit": "https://github.com/apache/lucene-solr/commit/eb104d2190d3440f7c8b23072c86d4585fa53092",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=eb104d2190d3440f7c8b23072c86d4585fa53092",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -100,6 +100,9 @@ Bug Fixes\n   when generating collations involving multiple word-break corrections.\n   (James Dyer)\n \n+* SOLR-5107: Fixed NPE when using numTerms=0 in LukeRequestHandler\n+  (Ahmet Arslan, hossman)\n+\n Optimizations\n ----------------------\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/CHANGES.txt",
                "sha": "ffe123ce61499d313bee23b12da28717aaaf70aa",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java?ref=eb104d2190d3440f7c8b23072c86d4585fa53092",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "patch": "@@ -576,7 +576,7 @@ private static void getDetailedFieldInfo(SolrQueryRequest req, String field, Sim\n       throws IOException {\n \n     SolrParams params = req.getParams();\n-    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n+    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n \n     TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n \n@@ -600,7 +600,7 @@ private static void getDetailedFieldInfo(SolrQueryRequest req, String field, Sim\n       int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n       int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n       buckets[slot] = buckets[slot] + 1;\n-      if (freq > tiq.minFreq) {\n+      if (numTerms > 0 && freq > tiq.minFreq) {\n         UnicodeUtil.UTF8toUTF16(text, spare);\n         String t = spare.toString();\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java",
                "sha": "6bc4e8c54ff175d691ca46ed81c633ed3da5eb03",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/lucene-solr/blob/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java?ref=eb104d2190d3440f7c8b23072c86d4585fa53092",
                "deletions": 0,
                "filename": "solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "patch": "@@ -184,6 +184,29 @@ public void testFlParam() {\n     }\n   }\n \n+  public void testNumTerms() throws Exception {\n+    final String f = \"name\";\n+    for (String n : new String[] {\"2\", \"3\", \"100\", \"99999\"}) {\n+      assertQ(req(\"qt\", \"/admin/luke\", \"fl\", f, \"numTerms\", n),\n+              field(f) + \"lst[@name='topTerms']/int[@name='Apache']\",\n+              field(f) + \"lst[@name='topTerms']/int[@name='Solr']\",\n+              \"count(\"+field(f)+\"lst[@name='topTerms']/int)=2\");\n+    }\n+    \n+    assertQ(req(\"qt\", \"/admin/luke\", \"fl\", f, \"numTerms\", \"1\"),\n+            // no garuntee which one we find\n+            \"count(\"+field(f)+\"lst[@name='topTerms']/int)=1\");\n+\n+    assertQ(req(\"qt\", \"/admin/luke\", \"fl\", f, \"numTerms\", \"0\"),\n+            \"count(\"+field(f)+\"lst[@name='topTerms']/int)=0\");\n+\n+    // field with no terms shouldn't error\n+    for (String n : new String[] {\"0\", \"1\", \"2\", \"100\", \"99999\"}) {\n+      assertQ(req(\"qt\", \"/admin/luke\", \"fl\", \"bogus_s\", \"numTerms\", n),\n+              \"count(\"+field(f)+\"lst[@name='topTerms']/int)=0\");\n+    }\n+  }\n+\n   public void testCopyFieldLists() throws Exception {\n     SolrQueryRequest req = req(\"qt\", \"/admin/luke\", \"show\", \"schema\");\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/eb104d2190d3440f7c8b23072c86d4585fa53092/solr/core/src/test/org/apache/solr/handler/admin/LukeRequestHandlerTest.java",
                "sha": "12f6e11f9e748c7b5c882f61367a022540f6a20c",
                "status": "modified"
            }
        ],
        "message": "SOLR-5107: Fixed NPE when using numTerms=0 in LukeRequestHandler\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1511064 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/8256f805235f281d1fcc78c0e61788462442b919",
        "repo": "lucene-solr",
        "unit_tests": [
            "LukeRequestHandlerTest.java"
        ]
    },
    "lucene-solr_ee55158": {
        "bug_id": "lucene-solr_ee55158",
        "commit": "https://github.com/apache/lucene-solr/commit/ee55158d07cb1ad3e7db049711900218f496ee01",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/CHANGES.txt",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -147,6 +147,10 @@ Bug Fixes\n   allow 1+maxMergeCount merges threads to be created, instead of just\n   maxMergeCount (Radim Kolar, Mike McCandless)\n \n+* LUCENE-4567: Fixed NullPointerException in analzying, fuzzy, and\n+  WFST suggesters when no suggestions were added (selckin via Mike\n+  McCandless)\n+\n Optimizations\n \n * LUCENE-2221: oal.util.BitUtil was modified to use Long.bitCount and",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/CHANGES.txt",
                "sha": "76267f8b5aee276e9e4e00027e815a22663a9798",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 0,
                "filename": "lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java",
                "patch": "@@ -23,6 +23,7 @@\n import java.io.OutputStream;\n import java.io.StringReader;\n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.Comparator;\n import java.util.HashSet;\n import java.util.List;\n@@ -530,6 +531,10 @@ public void build(TermFreqIterator iterator) throws IOException {\n   public boolean store(OutputStream output) throws IOException {\n     DataOutput dataOut = new OutputStreamDataOutput(output);\n     try {\n+      if (fst == null) {\n+        return false;\n+      }\n+\n       fst.save(dataOut);\n       dataOut.writeVInt(maxAnalyzedPathsForOneInput);\n     } finally {\n@@ -557,6 +562,9 @@ public boolean load(InputStream input) throws IOException {\n     if (onlyMorePopular) {\n       throw new IllegalArgumentException(\"this suggester only works with onlyMorePopular=false\");\n     }\n+    if (fst == null) {\n+      return Collections.emptyList();\n+    }\n \n     //System.out.println(\"lookup key=\" + key + \" num=\" + num);\n     final BytesRef utf8Key = new BytesRef(key);",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester.java",
                "sha": "5b96f0d61fc0f2497112ed873f38dfdce1d5b8b7",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 0,
                "filename": "lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java",
                "patch": "@@ -147,6 +147,10 @@ public boolean load(InputStream input) throws IOException {\n       throw new IllegalArgumentException(\"this suggester only works with onlyMorePopular=false\");\n     }\n \n+    if (fst == null) {\n+      return Collections.emptyList();\n+    }\n+\n     BytesRef scratch = new BytesRef(key);\n     int prefixLength = scratch.length;\n     Arc<Long> arc = new Arc<Long>();\n@@ -219,6 +223,9 @@ private Long lookupPrefix(BytesRef scratch, Arc<Long> arc) throws /*Bogus*/IOExc\n    * or null if it does not exist.\n    */\n   public Object get(CharSequence key) {\n+    if (fst == null) {\n+      return null;\n+    }\n     Arc<Long> arc = new Arc<Long>();\n     Long result = null;\n     try {",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java",
                "sha": "6b2ba97c5b11826a2f6624c470ac20cb5fa83d57",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 0,
                "filename": "lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java",
                "patch": "@@ -134,6 +134,15 @@ public void testStandard() throws Exception {\n     assertEquals(50, results.get(0).value, 0.01F);\n   }\n \n+  public void testEmpty() throws Exception {\n+    Analyzer standard = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n+    AnalyzingSuggester suggester = new AnalyzingSuggester(standard);\n+    suggester.build(new TermFreqArrayIterator(new TermFreq[0]));\n+\n+    List<LookupResult> result = suggester.lookup(\"a\", false, 20);\n+    assertTrue(result.isEmpty());\n+  }\n+\n   public void testNoSeps() throws Exception {\n     TermFreq[] keys = new TermFreq[] {\n       new TermFreq(\"ab cd\", 0),",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest.java",
                "sha": "0057d9aa1a420a5b522e11a50d5919e625317fcc",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 2,
                "filename": "lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java",
                "patch": "@@ -263,8 +263,14 @@ protected void setReader(final Reader reader) throws IOException {\n     assertEquals(\"wi fi network is fast\", results.get(1).key);\n     assertEquals(10, results.get(1).value);\n   }\n-  \n-  \n+\n+  public void testEmpty() throws Exception {\n+    FuzzySuggester suggester = new FuzzySuggester(new MockAnalyzer(random(), MockTokenizer.KEYWORD, false));\n+    suggester.build(new TermFreqArrayIterator(new TermFreq[0]));\n+\n+    List<LookupResult> result = suggester.lookup(\"a\", false, 20);\n+    assertTrue(result.isEmpty());\n+  }\n \n   public void testInputPathRequired() throws Exception {\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest.java",
                "sha": "b473e4dfc45ca209641f4290e2091b7a1b34c155",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/lucene-solr/blob/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java?ref=ee55158d07cb1ad3e7db049711900218f496ee01",
                "deletions": 0,
                "filename": "lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java",
                "patch": "@@ -209,4 +209,12 @@ public void test0ByteKeys() throws Exception {\n           new TermFreq(key2, 50),\n         }));\n   }\n+\n+  public void testEmpty() throws Exception {\n+    WFSTCompletionLookup suggester = new WFSTCompletionLookup(false);\n+\n+    suggester.build(new TermFreqArrayIterator(new TermFreq[0]));\n+    List<LookupResult> result = suggester.lookup(\"a\", false, 20);\n+    assertTrue(result.isEmpty());\n+  }\n }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/ee55158d07cb1ad3e7db049711900218f496ee01/lucene/suggest/src/test/org/apache/lucene/search/suggest/fst/WFSTCompletionTest.java",
                "sha": "65e281a8e66f674af82a24d1474689466e094d83",
                "status": "modified"
            }
        ],
        "message": "LUCENE-4567: avoid NPE if no suggestions were built\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1411796 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/84cdc246f499d4b4e0df6b5c816db71148cc852f",
        "repo": "lucene-solr",
        "unit_tests": [
            "AnalyzingSuggesterTest.java"
        ]
    },
    "lucene-solr_f13080d": {
        "bug_id": "lucene-solr_f13080d",
        "commit": "https://github.com/apache/lucene-solr/commit/f13080dd64e9b176704986629de902f38171d7e3",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f13080dd64e9b176704986629de902f38171d7e3/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=f13080dd64e9b176704986629de902f38171d7e3",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -74,6 +74,9 @@ Bug Fixes\n * LUCENE-4705: Pass on FilterStrategy in FilteredQuery if the filtered query is \n   rewritten. (Simon Willnauer)\n \n+* LUCENE-4712: MemoryIndex#normValues() throws NPE if field doesn't exist. \n+  (Simon Willnauer, Ricky Pritchett)\n+\n * LUCENE-4550: Shapes wider than 180 degrees would use too much accuracy for the\n   PrefixTree based SpatialStrategy. For a pathological case of nearly 360\n   degrees and barely any height, it would generate so many indexed terms",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f13080dd64e9b176704986629de902f38171d7e3/lucene/CHANGES.txt",
                "sha": "28611653987cef3333c73e216193c375bb8113a7",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f13080dd64e9b176704986629de902f38171d7e3/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java?ref=f13080dd64e9b176704986629de902f38171d7e3",
                "deletions": 1,
                "filename": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "patch": "@@ -1138,7 +1138,8 @@ public DocValues docValues(String field) {\n     \n     @Override\n     public DocValues normValues(String field) {\n-      if (fieldInfos.get(field).omitsNorms())\n+      FieldInfo fieldInfo = fieldInfos.get(field);\n+      if (fieldInfo == null || fieldInfo.omitsNorms())\n         return null;\n       DocValues norms = cachedNormValues;\n       Similarity sim = getSimilarity();",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f13080dd64e9b176704986629de902f38171d7e3/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
                "sha": "64a9e3661858d9aad7beb3cc0889409d0d85a3ce",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f13080dd64e9b176704986629de902f38171d7e3/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java?ref=f13080dd64e9b176704986629de902f38171d7e3",
                "deletions": 0,
                "filename": "lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "patch": "@@ -381,6 +381,17 @@ public void testSameFieldAddedMultipleTimes() throws IOException {\n     assertTrue(\"posGap\" + mockAnalyzer.getPositionIncrementGap(\"field\") , mindex.search(query) > 0.0001);\n   }\n   \n+  public void testNonExistingsField() throws IOException {\n+    MemoryIndex mindex = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n+    MockAnalyzer mockAnalyzer = new MockAnalyzer(random());\n+    mindex.addField(\"field\", \"the quick brown fox\", mockAnalyzer);\n+    AtomicReader reader = (AtomicReader) mindex.createSearcher().getIndexReader();\n+    assertNull(reader.docValues(\"not-in-index\"));\n+    assertNull(reader.normValues(\"not-in-index\"));\n+    assertNull(reader.termDocsEnum(new Term(\"not-in-index\", \"foo\")));\n+    assertNull(reader.termPositionsEnum(new Term(\"not-in-index\", \"foo\")));\n+    assertNull(reader.terms(\"not-in-index\"));\n+  }\n   \n   public void testDuellMemIndex() throws IOException {\n     LineFileDocs lineFileDocs = new LineFileDocs(random());",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f13080dd64e9b176704986629de902f38171d7e3/lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java",
                "sha": "cd68341724de48df07efdbd94b4cec3bd9e6f0db",
                "status": "modified"
            }
        ],
        "message": "LUCENE-4712: MemoryIndex throws NPE in #normValues(String) if field does not exist\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1437604 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/891fcf99da75ef983289a51902b99ff51d07ff08",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestMemoryIndex.java"
        ]
    },
    "lucene-solr_f1a6b68": {
        "bug_id": "lucene-solr_f1a6b68",
        "commit": "https://github.com/apache/lucene-solr/commit/f1a6b68d75e58f464b2ed4ee3702a6c1b14511a0",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f1a6b68d75e58f464b2ed4ee3702a6c1b14511a0/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java?ref=f1a6b68d75e58f464b2ed4ee3702a6c1b14511a0",
                "deletions": 4,
                "filename": "solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "patch": "@@ -922,10 +922,12 @@ public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<\n         // so that the next attempt would fetch the fresh state\n         // just re-read state for all of them, if it has not been retried\n         // in retryExpiryTime time\n-        for (DocCollection ext : requestedCollections) {\n-          ExpiringCachedDocCollection cacheEntry = collectionStateCache.get(ext.getName());\n-          if (cacheEntry == null) continue;\n-          cacheEntry.maybeStale = true;\n+        if (requestedCollections != null) {\n+          for (DocCollection ext : requestedCollections) {\n+            ExpiringCachedDocCollection cacheEntry = collectionStateCache.get(ext.getName());\n+            if (cacheEntry == null) continue;\n+            cacheEntry.maybeStale = true;\n+          }\n         }\n         if (retryCount < MAX_STALE_RETRIES) {//if it is a communication error , we must try again\n           //may be, we have a stale version of the collection state",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f1a6b68d75e58f464b2ed4ee3702a6c1b14511a0/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java",
                "sha": "d746fe6b8a54ee6e123861cd0a1f2e5af3e0b97d",
                "status": "modified"
            }
        ],
        "message": "SOLR-11484: fixing NPE",
        "parent": "https://github.com/apache/lucene-solr/commit/64f60e5cec447ff534a51bd1a9da24c67188508d",
        "repo": "lucene-solr",
        "unit_tests": [
            "CloudSolrClientTest.java"
        ]
    },
    "lucene-solr_f51253a": {
        "bug_id": "lucene-solr_f51253a",
        "commit": "https://github.com/apache/lucene-solr/commit/f51253a331fb938fd92eab4dab60df380d6837b8",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f51253a331fb938fd92eab4dab60df380d6837b8/solr/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/CHANGES.txt?ref=f51253a331fb938fd92eab4dab60df380d6837b8",
                "deletions": 0,
                "filename": "solr/CHANGES.txt",
                "patch": "@@ -231,6 +231,8 @@ Bug Fixes\n   Default settings in solrconfig.xml /config/indexConfig/metrics have been changed to turn off\n   IndexWriter and Directory level metrics collection. (ab, ishan)\n \n+* SOLR-10138: Transaction log replay can hit an NPE due to new Metrics code. (ab)\n+\n ==================  6.4.1 ==================\n \n Consult the LUCENE_CHANGES.txt file for additional, low level, changes in this release.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f51253a331fb938fd92eab4dab60df380d6837b8/solr/CHANGES.txt",
                "sha": "9fcc20c29e4a3dd23d3d6c110e0520365eba815a",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f51253a331fb938fd92eab4dab60df380d6837b8/solr/core/src/java/org/apache/solr/update/HdfsUpdateLog.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/update/HdfsUpdateLog.java?ref=f51253a331fb938fd92eab4dab60df380d6837b8",
                "deletions": 2,
                "filename": "solr/core/src/java/org/apache/solr/update/HdfsUpdateLog.java",
                "patch": "@@ -37,6 +37,7 @@\n import org.apache.solr.common.util.IOUtils;\n import org.apache.solr.core.PluginInfo;\n import org.apache.solr.core.SolrCore;\n+import org.apache.solr.core.SolrInfoMBean;\n import org.apache.solr.util.HdfsUtil;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -121,7 +122,7 @@ public void init(UpdateHandler uhandler, SolrCore core) {\n     String ulogDir = core.getCoreDescriptor().getUlogDir();\n \n     this.uhandler = uhandler;\n-    \n+\n     synchronized (fsLock) {\n       // just like dataDir, we do not allow\n       // moving the tlog dir on reload\n@@ -259,7 +260,9 @@ public void init(UpdateHandler uhandler, SolrCore core) {\n       }\n \n     }\n-    \n+\n+    // initialize metrics\n+    core.getCoreMetricManager().registerMetricProducer(SolrInfoMBean.Category.TLOG.toString(), this);\n   }\n   \n   @Override",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f51253a331fb938fd92eab4dab60df380d6837b8/solr/core/src/java/org/apache/solr/update/HdfsUpdateLog.java",
                "sha": "71e20d9f2608ab409f8301cbb95dc576799e47cb",
                "status": "modified"
            }
        ],
        "message": "SOLR-10138: Transaction log replay can hit an NPE due to new Metrics code.",
        "parent": "https://github.com/apache/lucene-solr/commit/9275c2f87ff4fb6909bc748c59ba673cbc599c2c",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestHdfsUpdateLog.java"
        ]
    },
    "lucene-solr_f96b02a": {
        "bug_id": "lucene-solr_f96b02a",
        "commit": "https://github.com/apache/lucene-solr/commit/f96b02af060feaa044b85224bfbfeeb548e8b1da",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f96b02af060feaa044b85224bfbfeeb548e8b1da/lucene/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=f96b02af060feaa044b85224bfbfeeb548e8b1da",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -219,6 +219,9 @@ Bug Fixes\n   In addition, it wasn't possible to index a shape representing the entire\n   globe.\n \n+* LUCENE--4595: EnwikiContentSource had a thread safety problem (NPE) in \n+  'forever' mode (Doron Cohen)\n+\n Optimizations\n \n * LUCENE-2221: oal.util.BitUtil was modified to use Long.bitCount and",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f96b02af060feaa044b85224bfbfeeb548e8b1da/lucene/CHANGES.txt",
                "sha": "d6a7d92d3e7d18bf2585f04cab62fdf25c4228fd",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/lucene-solr/blob/f96b02af060feaa044b85224bfbfeeb548e8b1da/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiContentSource.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiContentSource.java?ref=f96b02af060feaa044b85224bfbfeeb548e8b1da",
                "deletions": 15,
                "filename": "lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiContentSource.java",
                "patch": "@@ -178,23 +178,25 @@ public void run() {\n         reader.setErrorHandler(this);\n         while(!stopped){\n           final InputStream localFileIS = is;\n-          try {\n-            // To work around a bug in XERCES (XERCESJ-1257), we assume the XML is always UTF8, so we simply provide reader.\n-            CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n-                .onMalformedInput(CodingErrorAction.REPORT)\n-                .onUnmappableCharacter(CodingErrorAction.REPORT);\n-            reader.parse(new InputSource(new BufferedReader(new InputStreamReader(localFileIS, decoder))));\n-          } catch (IOException ioe) {\n-            synchronized(EnwikiContentSource.this) {\n-              if (localFileIS != is) {\n-                // fileIS was closed on us, so, just fall through\n-              } else\n-                // Exception is real\n-                throw ioe;\n+          if (localFileIS != null) { // null means fileIS was closed on us \n+            try {\n+              // To work around a bug in XERCES (XERCESJ-1257), we assume the XML is always UTF8, so we simply provide reader.\n+              CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n+                  .onMalformedInput(CodingErrorAction.REPORT)\n+                  .onUnmappableCharacter(CodingErrorAction.REPORT);\n+              reader.parse(new InputSource(new BufferedReader(new InputStreamReader(localFileIS, decoder))));\n+            } catch (IOException ioe) {\n+              synchronized(EnwikiContentSource.this) {\n+                if (localFileIS != is) {\n+                  // fileIS was closed on us, so, just fall through\n+                } else\n+                  // Exception is real\n+                  throw ioe;\n+              }\n             }\n           }\n           synchronized(this) {\n-            if (!forever) {\n+            if (stopped || !forever) {\n               nmde = new NoMoreDataException();\n               notify();\n               return;\n@@ -291,11 +293,11 @@ private final static int getElementType(String elem) {\n   @Override\n   public void close() throws IOException {\n     synchronized (EnwikiContentSource.this) {\n+      parser.stop();\n       if (is != null) {\n         is.close();\n         is = null;\n       }\n-      parser.stop();\n     }\n   }\n   ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/f96b02af060feaa044b85224bfbfeeb548e8b1da/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiContentSource.java",
                "sha": "09745cbe88e3ba3b698d693400c6800aa693481e",
                "status": "modified"
            }
        ],
        "message": "LUCENE--4595: EnwikiContentSource thread safety NPE in 'forever' mode\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1418281 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/49593470e3337d433996b73afd992c61df40db6a",
        "repo": "lucene-solr",
        "unit_tests": [
            "EnwikiContentSourceTest.java"
        ]
    },
    "lucene-solr_fc6f3a4": {
        "bug_id": "lucene-solr_fc6f3a4",
        "commit": "https://github.com/apache/lucene-solr/commit/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/lucene-solr/blob/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/CHANGES.txt?ref=fc6f3a45f8bdd1518ed49b68fbdc62988b34644b",
                "deletions": 0,
                "filename": "lucene/CHANGES.txt",
                "patch": "@@ -144,6 +144,8 @@ Bug Fixes\n \n * LUCENE-8120: Fix LatLonBoundingBox's toString() method (Martijn van Groningen, Adrien Grand)\n \n+* LUCENE-8130: Fix NullPointerException from TermStates.toString() (Mike McCandless)\n+\n Other\n \n * LUCENE-8111: IndexOrDocValuesQuery Javadoc references outdated method name.",
                "raw_url": "https://github.com/apache/lucene-solr/raw/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/CHANGES.txt",
                "sha": "6b90215e9356b6197e4b2d6ebaf226a6273c0517",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/lucene-solr/blob/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/core/src/java/org/apache/lucene/index/TermStates.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/java/org/apache/lucene/index/TermStates.java?ref=fc6f3a45f8bdd1518ed49b68fbdc62988b34644b",
                "deletions": 1,
                "filename": "lucene/core/src/java/org/apache/lucene/index/TermStates.java",
                "patch": "@@ -224,7 +224,7 @@ public String toString() {\n     sb.append(\"TermStates\\n\");\n     for(TermState termState : states) {\n       sb.append(\"  state=\");\n-      sb.append(termState.toString());\n+      sb.append(termState);\n       sb.append('\\n');\n     }\n ",
                "raw_url": "https://github.com/apache/lucene-solr/raw/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/core/src/java/org/apache/lucene/index/TermStates.java",
                "sha": "4bb83fe4e8f8c2aef311d0fe34f55675e2c4af33",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/lucene-solr/blob/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/core/src/test/org/apache/lucene/index/TestTermStates.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/lucene/core/src/test/org/apache/lucene/index/TestTermStates.java?ref=fc6f3a45f8bdd1518ed49b68fbdc62988b34644b",
                "deletions": 0,
                "filename": "lucene/core/src/test/org/apache/lucene/index/TestTermStates.java",
                "patch": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.IOUtils;\n+import org.apache.lucene.util.LuceneTestCase;\n+\n+public class TestTermStates extends LuceneTestCase {\n+\n+  public void testToStringOnNullTermState() throws Exception {\n+    Directory dir = newDirectory();\n+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n+    w.addDocument(new Document());\n+    IndexReader r = w.getReader();\n+    TermStates states = TermStates.build(r.getContext(), new Term(\"foo\", \"bar\"), random().nextBoolean());\n+    assertEquals(\"TermStates\\n  state=null\\n\", states.toString());\n+    IOUtils.close(r, w, dir);\n+  }\n+}",
                "raw_url": "https://github.com/apache/lucene-solr/raw/fc6f3a45f8bdd1518ed49b68fbdc62988b34644b/lucene/core/src/test/org/apache/lucene/index/TestTermStates.java",
                "sha": "a89fe7bb04acee9c110a975e8140c5a247e37d6b",
                "status": "added"
            }
        ],
        "message": "LUCENE-8130: fix NPE from TermStates.toString",
        "parent": "https://github.com/apache/lucene-solr/commit/5425353402641307d71af727ff18c63e4579c5c1",
        "repo": "lucene-solr",
        "unit_tests": [
            "TestTermStates.java"
        ]
    },
    "lucene-solr_fd993e0": {
        "bug_id": "lucene-solr_fd993e0",
        "commit": "https://github.com/apache/lucene-solr/commit/fd993e0c116b98ff31ca06af642e46f13d72ca60",
        "file": [
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/lucene-solr/blob/fd993e0c116b98ff31ca06af642e46f13d72ca60/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/lucene-solr/contents/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java?ref=fd993e0c116b98ff31ca06af642e46f13d72ca60",
                "deletions": 14,
                "filename": "solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "patch": "@@ -36,6 +36,7 @@\n import org.apache.solr.common.SolrException;\n import org.apache.solr.common.SolrException.ErrorCode;\n import org.apache.solr.common.cloud.CloudState;\n+import org.apache.solr.common.cloud.Slice;\n import org.apache.solr.common.cloud.ZkCoreNodeProps;\n import org.apache.solr.common.cloud.ZkNodeProps;\n import org.apache.solr.common.cloud.ZkStateReader;\n@@ -645,20 +646,21 @@ protected void handleWaitForStateAction(SolrQueryRequest req,\n             .getZkController()\n             .getCloudState();\n         String collection = cloudDescriptor.getCollectionName();\n-        ZkNodeProps nodeProps = \n-            cloudState.getSlice(collection,\n-                cloudDescriptor.getShardId()).getShards().get(coreNodeName);\n-        \n-        if (nodeProps != null) {\n-          state = nodeProps.get(ZkStateReader.STATE_PROP);\n-          live = cloudState.liveNodesContain(nodeName);\n-          if (nodeProps != null && state.equals(waitForState)) {\n-            if (checkLive == null) {\n-              break;\n-            } else if (checkLive && live) {\n-              break;\n-            } else if (!checkLive && !live) {\n-              break;\n+        Slice slice = cloudState.getSlice(collection,\n+            cloudDescriptor.getShardId());\n+        if (slice != null) {\n+          ZkNodeProps nodeProps = slice.getShards().get(coreNodeName);\n+          if (nodeProps != null) {\n+            state = nodeProps.get(ZkStateReader.STATE_PROP);\n+            live = cloudState.liveNodesContain(nodeName);\n+            if (nodeProps != null && state.equals(waitForState)) {\n+              if (checkLive == null) {\n+                break;\n+              } else if (checkLive && live) {\n+                break;\n+              } else if (!checkLive && !live) {\n+                break;\n+              }\n             }\n           }\n         }",
                "raw_url": "https://github.com/apache/lucene-solr/raw/fd993e0c116b98ff31ca06af642e46f13d72ca60/solr/core/src/java/org/apache/solr/handler/admin/CoreAdminHandler.java",
                "sha": "132cfc6cad05d749c9c6a7045ffc580fcd195eb0",
                "status": "modified"
            }
        ],
        "message": "be careful about retrying rather than NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1292312 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/lucene-solr/commit/baee5394c1f8fbc313828d2b0f4848df6aab1e00",
        "repo": "lucene-solr",
        "unit_tests": [
            "CoreAdminHandlerTest.java"
        ]
    }
}