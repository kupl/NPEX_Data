[
    {
        "repo": "hive",
        "commit": "https://github.com/apache/hive/commit/fb79870592d775cd836d5611e21ab1c7030aadba",
        "bug_id": "hive_fb79870",
        "message": "HIVE-13745: UDF current_date\u3001current_timestamp\u3001unix_timestamp NPE (Biao Wu, reviewed by Yongzhi Chen)",
        "parent": "https://github.com/apache/hive/commit/68b66a64f0d9b0d587a7ce1e085a0e8e45253adb",
        "patched_files": [
            "SessionState.java",
            "HiveConf.java"
        ],
        "file": [
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb79870592d775cd836d5611e21ab1c7030aadba/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java?ref=fb79870592d775cd836d5611e21ab1c7030aadba",
                "filename": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java",
                "deletions": 0,
                "sha": "44b9eb2824c1d0c475fc56d8737e023513f49d78",
                "blob_url": "https://github.com/apache/hive/blob/fb79870592d775cd836d5611e21ab1c7030aadba/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java",
                "patch": "@@ -1843,6 +1843,7 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n     TESTMODE_BUCKET_CODEC_VERSION(\"hive.test.bucketcodec.version\", 1,\n       \"For testing only.  Will make ACID subsystem write RecordIdentifier.bucketId in specified\\n\" +\n         \"format\", false),\n+    HIVE_QUERY_TIMESTAMP(\"hive.query.timestamp\", System.currentTimeMillis(), \"query execute time.\"),\n \n     HIVEMERGEMAPFILES(\"hive.merge.mapfiles\", true,\n         \"Merge small files at the end of a map-only job\"),",
                "changes": 1
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java?ref=fb79870592d775cd836d5611e21ab1c7030aadba",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
                "deletions": 0,
                "sha": "9f65a771f95a7c0bd3fdb4e56e47c0fc70235850",
                "blob_url": "https://github.com/apache/hive/blob/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
                "patch": "@@ -1924,6 +1924,7 @@ public String getNextValuesTempTableSuffix() {\n    */\n   public void setupQueryCurrentTimestamp() {\n     queryCurrentTimestamp = new Timestamp(System.currentTimeMillis());\n+    sessionConf.setLongVar(ConfVars.HIVE_QUERY_TIMESTAMP, queryCurrentTimestamp.getTime());\n \n     // Provide a facility to set current timestamp during tests\n     if (sessionConf.getBoolVar(ConfVars.HIVE_IN_TEST)) {",
                "changes": 1
            },
            {
                "status": "modified",
                "additions": 25,
                "raw_url": "https://github.com/apache/hive/raw/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java?ref=fb79870592d775cd836d5611e21ab1c7030aadba",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java",
                "deletions": 1,
                "sha": "91fd08f13e5cdc28cc80acffea0599e14a45a96e",
                "blob_url": "https://github.com/apache/hive/blob/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentDate.java",
                "patch": "@@ -18,8 +18,12 @@\n package org.apache.hadoop.hive.ql.udf.generic;\n \n import java.sql.Date;\n+import java.sql.Timestamp;\n \n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;\n import org.apache.hadoop.hive.ql.metadata.HiveException;\n@@ -39,6 +43,13 @@\n public class GenericUDFCurrentDate extends GenericUDF {\n \n   protected DateWritable currentDate;\n+  private Configuration conf;\n+\n+  @Override\n+  public void configure(MapredContext context) {\n+    super.configure(context);\n+    conf = context.getJobConf();\n+  }\n \n   @Override\n   public ObjectInspector initialize(ObjectInspector[] arguments)\n@@ -50,8 +61,21 @@ public ObjectInspector initialize(ObjectInspector[] arguments)\n     }\n \n     if (currentDate == null) {\n+      SessionState ss = SessionState.get();\n+      Timestamp queryTimestamp;\n+      if (ss == null) {\n+        if (conf == null) {\n+          queryTimestamp = new Timestamp(System.currentTimeMillis());\n+        } else {\n+          queryTimestamp = new Timestamp(\n+                  HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));\n+        }\n+      } else {\n+        queryTimestamp = ss.getQueryCurrentTimestamp();\n+      }\n+\n       Date dateVal =\n-          Date.valueOf(SessionState.get().getQueryCurrentTimestamp().toString().substring(0, 10));\n+              Date.valueOf(queryTimestamp.toString().substring(0, 10));\n       currentDate = new DateWritable(dateVal);\n     }\n ",
                "changes": 26
            },
            {
                "status": "modified",
                "additions": 25,
                "raw_url": "https://github.com/apache/hive/raw/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java?ref=fb79870592d775cd836d5611e21ab1c7030aadba",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java",
                "deletions": 1,
                "sha": "ca43840e372a26accda20386ef4c8679310783fe",
                "blob_url": "https://github.com/apache/hive/blob/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFCurrentTimestamp.java",
                "patch": "@@ -17,7 +17,12 @@\n  */\n package org.apache.hadoop.hive.ql.udf.generic;\n \n+import java.sql.Timestamp;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;\n import org.apache.hadoop.hive.ql.metadata.HiveException;\n@@ -37,6 +42,13 @@\n public class GenericUDFCurrentTimestamp extends GenericUDF {\n \n   protected TimestampWritable currentTimestamp;\n+  private Configuration conf;\n+\n+  @Override\n+  public void configure(MapredContext context) {\n+    super.configure(context);\n+    conf = context.getJobConf();\n+  }\n \n   @Override\n   public ObjectInspector initialize(ObjectInspector[] arguments)\n@@ -48,7 +60,19 @@ public ObjectInspector initialize(ObjectInspector[] arguments)\n     }\n \n     if (currentTimestamp == null) {\n-      currentTimestamp = new TimestampWritable(SessionState.get().getQueryCurrentTimestamp());\n+      SessionState ss = SessionState.get();\n+      Timestamp queryTimestamp;\n+      if (ss == null) {\n+        if (conf == null) {\n+          queryTimestamp = new Timestamp(System.currentTimeMillis());\n+        } else {\n+          queryTimestamp = new Timestamp(\n+                  HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));\n+        }\n+      } else {\n+        queryTimestamp = ss.getQueryCurrentTimestamp();\n+      }\n+      currentTimestamp = new TimestampWritable(queryTimestamp);\n     }\n \n     return PrimitiveObjectInspectorFactory.writableTimestampObjectInspector;",
                "changes": 26
            },
            {
                "status": "modified",
                "additions": 26,
                "raw_url": "https://github.com/apache/hive/raw/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java?ref=fb79870592d775cd836d5611e21ab1c7030aadba",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java",
                "deletions": 1,
                "sha": "6ce72f77037d49571eb1bc5fb647bed0559119cf",
                "blob_url": "https://github.com/apache/hive/blob/fb79870592d775cd836d5611e21ab1c7030aadba/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java",
                "patch": "@@ -18,6 +18,11 @@\n \n package org.apache.hadoop.hive.ql.udf.generic;\n \n+import java.sql.Timestamp;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.apache.hadoop.hive.ql.exec.Description;\n@@ -37,14 +42,34 @@\n public class GenericUDFUnixTimeStamp extends GenericUDFToUnixTimeStamp {\n   private static final Logger LOG = LoggerFactory.getLogger(GenericUDFUnixTimeStamp.class);\n   private LongWritable currentTimestamp; // retValue is transient so store this separately.\n+  private Configuration conf;\n+\n+  @Override\n+  public void configure(MapredContext context) {\n+    super.configure(context);\n+    conf = context.getJobConf();\n+  }\n+\n   @Override\n   protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentException {\n     if (arguments.length > 0) {\n       super.initializeInput(arguments);\n     } else {\n       if (currentTimestamp == null) {\n         currentTimestamp = new LongWritable(0);\n-        setValueFromTs(currentTimestamp, SessionState.get().getQueryCurrentTimestamp());\n+        SessionState ss = SessionState.get();\n+        Timestamp queryTimestamp;\n+        if (ss == null) {\n+          if (conf == null) {\n+            queryTimestamp = new Timestamp(System.currentTimeMillis());\n+          } else {\n+            queryTimestamp = new Timestamp(\n+                    HiveConf.getLongVar(conf, HiveConf.ConfVars.HIVE_QUERY_TIMESTAMP));\n+          }\n+        } else {\n+          queryTimestamp = ss.getQueryCurrentTimestamp();\n+        }\n+        setValueFromTs(currentTimestamp, queryTimestamp);\n         String msg = \"unix_timestamp(void) is deprecated. Use current_timestamp instead.\";\n         SessionState.getConsole().printInfo(msg, false);\n       }",
                "changes": 27
            }
        ],
        "unit_tests": [
            "TestHiveConf.java",
            "TestSessionState.java"
        ]
    },
    {
        "buggy": false,
        "test_file": "common/src/test/org/apache/hadoop/hive/conf/TestHiveConf.java",
        "buggy_files": [
            "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
            "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java"
        ],
        "fixed": true
    },
    {
        "buggy": false,
        "test_file": "ql/src/test/org/apache/hadoop/hive/ql/session/TestSessionState.java",
        "buggy_files": [
            "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
            "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java"
        ],
        "fixed": true
    }
]