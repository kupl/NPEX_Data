[
    {
        "repo": "asterixdb-hyracks",
        "message": "fix NPE when no custom aggregator is set",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/9ac5e40654b712dcd491aef2605d0e0b3b30957e",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/fc1224ecbee1dd917caa6e6c1362d5f7d8476569",
        "bug_id": "asterixdb-hyracks_1",
        "file": [
            {
                "sha": "d303969c4b662f99d243dd8f25af3228f13541a3",
                "filename": "pregelix/pregelix-api/src/main/java/edu/uci/ics/pregelix/api/util/BspUtils.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/9ac5e40654b712dcd491aef2605d0e0b3b30957e/pregelix/pregelix-api/src/main/java/edu/uci/ics/pregelix/api/util/BspUtils.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/9ac5e40654b712dcd491aef2605d0e0b3b30957e/pregelix/pregelix-api/src/main/java/edu/uci/ics/pregelix/api/util/BspUtils.java",
                "status": "modified",
                "changes": 7,
                "additions": 6,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/pregelix/pregelix-api/src/main/java/edu/uci/ics/pregelix/api/util/BspUtils.java?ref=9ac5e40654b712dcd491aef2605d0e0b3b30957e",
                "patch": "@@ -123,7 +123,12 @@\n     public static <I extends WritableComparable, V extends Writable, E extends Writable, M extends WritableSizable, P extends Writable, F extends Writable> List<Class<? extends GlobalAggregator<I, V, E, M, P, F>>> getGlobalAggregatorClasses(\n             Configuration conf) {\n         String aggStrs = conf.get(PregelixJob.GLOBAL_AGGREGATOR_CLASS);\n-        String[] classnames = aggStrs.split(PregelixJob.COMMA_STR);\n+        String[] classnames;\n+        if (aggStrs == null) {\n+            classnames = new String[0];\n+        } else {\n+            classnames = aggStrs.split(PregelixJob.COMMA_STR);\n+        }\n         try {\n             List<Class<? extends GlobalAggregator<I, V, E, M, P, F>>> classes = new ArrayList<Class<? extends GlobalAggregator<I, V, E, M, P, F>>>();\n             for (String defaultClass : PregelixJob.DEFAULT_GLOBAL_AGGREGATOR_CLASSES) {",
                "deletions": 1
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Changes to fix NPE in tpch SF=1 with OptzHHJ",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/0f63d8bf4dc96d106ef237d227807edfbda0046b",
        "bug_id": "asterixdb-hyracks_2",
        "file": [
            {
                "sha": "f44d2f1101c7a5b72475a575bea0ceb5c8036d98",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/InMemoryHashJoin.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/InMemoryHashJoin.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/InMemoryHashJoin.java",
                "status": "modified",
                "changes": 20,
                "additions": 19,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/InMemoryHashJoin.java?ref=da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8",
                "patch": "@@ -119,7 +119,16 @@ public void join(ByteBuffer buffer, IFrameWriter writer) throws HyracksDataExcep\n                     accessorBuild.reset(buffers.get(bIndex));\n                     int c = tpComparator.compare(accessorProbe, i, accessorBuild, tIndex);\n                     if (c == 0) {\n-                    \tboolean predEval = ( (predEvaluator == null) || predEvaluator.evaluate(accessorProbe, i, accessorBuild, tIndex) );\n+                    \tboolean predEval = evaluatePredicate(i, tIndex);\n+\t\t\t\t\t\t/*\n+                    \ttry {\n+\t\t\t\t\t\t\tpredEval = ( (predEvaluator == null) || predEvaluator.evaluate(accessorProbe, i, accessorBuild, tIndex) );\n+\t\t\t\t\t\t} catch (ArrayIndexOutOfBoundsException e) {\n+\t\t\t\t\t\t\tSystem.out.println(\"Hit Array Index out of bound - now we swap\");\n+\t\t\t\t\t\t\te.printStackTrace();\n+\t\t\t\t\t\t\tpredEval = predEvaluator.evaluate(accessorBuild, i, accessorProbe, tIndex);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\t*/\n                     \tif(predEval){\n                     \t\tmatchFound = true;\n                             appendToResult(i, tIndex, writer);\n@@ -155,6 +164,15 @@ private void flushFrame(ByteBuffer buffer, IFrameWriter writer) throws HyracksDa\n         buffer.position(0);\n         buffer.limit(buffer.capacity());\n     }\n+    \n+    private boolean evaluatePredicate(int tIx1, int tIx2){\n+    \tif(reverseOutputOrder){\t\t//Role Reversal Optimization is triggered\n+    \t\treturn ( (predEvaluator == null) || predEvaluator.evaluate(accessorBuild, tIx2, accessorProbe, tIx1) );\n+    \t}\n+    \telse {\n+    \t\treturn ( (predEvaluator == null) || predEvaluator.evaluate(accessorProbe, tIx1, accessorBuild, tIx2) );\n+    \t}\n+    }\n \n     private void appendToResult(int probeSidetIx, int buildSidetIx, IFrameWriter writer) throws HyracksDataException {\n         if (!reverseOutputOrder) {",
                "deletions": 1
            },
            {
                "sha": "979ef5912d2adbe54657e7946782cfd983e9e785",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/NestedLoopJoin.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/NestedLoopJoin.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/NestedLoopJoin.java",
                "status": "modified",
                "changes": 18,
                "additions": 17,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/NestedLoopJoin.java?ref=da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8",
                "patch": "@@ -49,6 +49,8 @@\n     private final boolean isLeftOuter;\n     private final ArrayTupleBuilder nullTupleBuilder;\n     private final IPredicateEvaluator predEvaluator;\n+    private boolean isReversed;\t\t//Added for handling correct calling for predicate-evaluator upon recursive calls (in OptimizedHybridHashJoin) that cause role-reversal\n+\n     \n     public NestedLoopJoin(IHyracksTaskContext ctx, FrameTupleAccessor accessor0, FrameTupleAccessor accessor1,\n             ITuplePairComparator comparators, int memSize, IPredicateEvaluator predEval, boolean isLeftOuter, INullWriter[] nullWriters1)\n@@ -63,6 +65,7 @@ public NestedLoopJoin(IHyracksTaskContext ctx, FrameTupleAccessor accessor0, Fra\n         this.outBuffers = new ArrayList<ByteBuffer>();\n         this.memSize = memSize;\n         this.predEvaluator = predEval;\n+        this.isReversed = false;\n         this.ctx = ctx;\n \n         this.isLeftOuter = isLeftOuter;\n@@ -133,7 +136,7 @@ private void blockJoin(ByteBuffer outerBuffer, ByteBuffer innerBuffer, IFrameWri\n             boolean matchFound = false;\n             for (int j = 0; j < tupleCount1; ++j) {\n                 int c = compare(accessorOuter, i, accessorInner, j);\n-                boolean prdEval = (predEvaluator == null) || (predEvaluator.evaluate(accessorOuter, i, accessorInner, j));\n+                boolean prdEval = evaluatePredicate(i, j);\n                 if (c == 0 && prdEval) {\n                 \tmatchFound = true;\n                     if (!appender.appendConcat(accessorOuter, i, accessorInner, j)) {\n@@ -165,6 +168,15 @@ private void blockJoin(ByteBuffer outerBuffer, ByteBuffer innerBuffer, IFrameWri\n             }\n         }\n     }\n+    \n+    private boolean evaluatePredicate(int tIx1, int tIx2){\n+    \tif(isReversed){\t\t//Role Reversal Optimization is triggered\n+    \t\treturn ( (predEvaluator == null) || predEvaluator.evaluate(accessorInner, tIx2, accessorOuter, tIx1) );\n+    \t}\n+    \telse {\n+    \t\treturn ( (predEvaluator == null) || predEvaluator.evaluate(accessorOuter, tIx1, accessorInner, tIx2) );\n+    \t}\n+    }\n \n     public void closeCache() throws HyracksDataException {\n         if (runFileWriter != null) {\n@@ -206,4 +218,8 @@ private int compare(FrameTupleAccessor accessor0, int tIndex0, FrameTupleAccesso\n         }\n         return 0;\n     }\n+    \n+    public void setIsReversed(boolean b){\n+    \tthis.isReversed = b;\n+    }\n }",
                "deletions": 1
            },
            {
                "sha": "6bc810ef02a982a784c7023ad8f4ac13979022d0",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoin.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoin.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoin.java",
                "status": "modified",
                "changes": 11,
                "additions": 9,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoin.java?ref=da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8",
                "patch": "@@ -99,6 +99,7 @@\n     private int freeFramesCounter; //Used for partition tuning\n     \n     private boolean isTableEmpty;\t//Added for handling the case, where build side is empty (tableSize is 0)\n+    private boolean isReversed;\t\t//Added for handling correct calling for predicate-evaluator upon recursive calls that cause role-reversal\n     \n     public OptimizedHybridHashJoin(IHyracksTaskContext ctx, int memForJoin, int numOfPartitions, String rel0Name,\n             String rel1Name, int[] keys0, int[] keys1, IBinaryComparator[] comparators, RecordDescriptor buildRd,\n@@ -125,6 +126,7 @@ public OptimizedHybridHashJoin(IHyracksTaskContext ctx, int memForJoin, int numO\n         this.predEvaluator = predEval;\n         this.isLeftOuter = false;\n         this.nullWriters1 = null;\n+        this.isReversed = false;\n \n     }\n \n@@ -153,7 +155,8 @@ public OptimizedHybridHashJoin(IHyracksTaskContext ctx, int memForJoin, int numO\n         \n         this.predEvaluator = predEval;\n         this.isLeftOuter = isLeftOuter;\n-\n+        this.isReversed = false;\n+        \n         this.nullWriters1 = isLeftOuter ? new INullWriter[nullWriterFactories1.length] : null;\n         if (isLeftOuter) {\n             for (int i = 0; i < nullWriterFactories1.length; i++) {\n@@ -441,7 +444,7 @@ private void createInMemoryJoiner(int inMemTupCount) throws HyracksDataException\n         this.inMemJoiner = new InMemoryHashJoin(ctx, inMemTupCount,\n                 new FrameTupleAccessor(ctx.getFrameSize(), probeRd), probeHpc, new FrameTupleAccessor(\n                         ctx.getFrameSize(), buildRd), buildHpc, new FrameTuplePairComparator(probeKeys, buildKeys,\n-                        comparators), isLeftOuter, nullWriters1, table, predEvaluator);\n+                        comparators), isLeftOuter, nullWriters1, table, predEvaluator, isReversed);\n     }\n \n     private void cacheInMemJoin() throws HyracksDataException {\n@@ -639,4 +642,8 @@ public String debugGetStats() {\n     public boolean isTableEmpty() {\n         return this.isTableEmpty;\n     }\n+    \n+    public void setIsReversed(boolean b){\n+    \tthis.isReversed = b;\n+    }\n }",
                "deletions": 2
            },
            {
                "sha": "2d3185f401d5fb2b379cc7bcb1f6e74152b2ae48",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoinOperatorDescriptor.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoinOperatorDescriptor.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoinOperatorDescriptor.java",
                "status": "modified",
                "changes": 37,
                "additions": 23,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/edu/uci/ics/hyracks/dataflow/std/join/OptimizedHybridHashJoinOperatorDescriptor.java?ref=da0a4e56bffa7c7cb5fd14b5e4d21b4bee8dc5e8",
                "patch": "@@ -19,6 +19,8 @@\n import java.io.IOException;\n import java.nio.ByteBuffer;\n import java.util.BitSet;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n import edu.uci.ics.hyracks.api.context.IHyracksTaskContext;\n import edu.uci.ics.hyracks.api.dataflow.ActivityId;\n@@ -117,6 +119,8 @@\n     \n     private final boolean isLeftOuter;\n     private final INullWriterFactory[] nullWriterFactories1;\n+    \n+    private static final Logger LOGGER = Logger.getLogger(OptimizedHybridHashJoinOperatorDescriptor.class.getName());\n \n     public OptimizedHybridHashJoinOperatorDescriptor(IOperatorDescriptorRegistry spec, int memsize, int inputsize0,\n             double factor, int[] keys0, int[] keys1, IBinaryHashFunctionFamily[] hashFunctionGeneratorFactories,\n@@ -139,8 +143,6 @@ public OptimizedHybridHashJoinOperatorDescriptor(IOperatorDescriptorRegistry spe\n         this.predEvaluatorFactory = predEvaluatorFactory;\n         this.isLeftOuter = isLeftOuter;\n         this.nullWriterFactories1 = nullWriterFactories1;\n-        \n-\n     }\n \n     public OptimizedHybridHashJoinOperatorDescriptor(IOperatorDescriptorRegistry spec, int memsize, int inputsize0,\n@@ -207,7 +209,7 @@ private int getNumberOfPartitions(int memorySize, int buildSize, double factor,\n     }\n \n     public static class BuildAndPartitionTaskState extends AbstractStateObject {\n-\n+    \t\n         private int memForJoin;\n         private int numOfPartitions;\n         private OptimizedHybridHashJoin hybridHJ;\n@@ -303,6 +305,7 @@ public void nextFrame(ByteBuffer buffer) throws HyracksDataException {\n                 public void close() throws HyracksDataException {\n                     state.hybridHJ.closeBuild();\n                     ctx.setStateObject(state);\n+                    LOGGER.log(Level.WARNING, \"OptimizedHybridHashJoin closed its build phase\");\n                 }\n \n                 @Override\n@@ -323,7 +326,7 @@ public void fail() throws HyracksDataException {\n      * Hybrid Hash Join recursively on them.\n      */\n     private class ProbeAndJoinActivityNode extends AbstractActivityNode {\n-\n+    \t\n         private static final long serialVersionUID = 1L;\n \n         private final ActivityId buildAid;\n@@ -423,9 +426,11 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                             hashFunctionGeneratorFactories).createPartitioner(level);\n                     ITuplePartitionComputer buildHpc = new FieldHashPartitionComputerFamily(buildKeys,\n                             hashFunctionGeneratorFactories).createPartitioner(level);\n-\n+                    \n                     long buildPartSize = ohhj.getBuildPartitionSize(pid) / ctx.getFrameSize();\n                     long probePartSize = ohhj.getProbePartitionSize(pid) / ctx.getFrameSize();\n+                    \n+                    LOGGER.log(Level.WARNING,\"Joining Partition Pairs (pid \"+pid+\") - (level \"+level+\") - BuildSize:\\t\"+buildPartSize+\"\\tProbeSize:\\t\"+probePartSize+\" - MemForJoin \"+(state.memForJoin));\n \n                     //Apply in-Mem HJ if possible\n                     if ((buildPartSize < state.memForJoin) || (probePartSize < state.memForJoin)) {\n@@ -460,7 +465,7 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                     else {\n                         OptimizedHybridHashJoin rHHj;\n                         if (isLeftOuter || buildPartSize < probePartSize) { //Build Side is smaller\n-\n+                        \tLOGGER.log(Level.WARNING,\"\\tApply RecursiveHHJ for (pid \"+pid+\") - (level \"+level+\") [buildSize is smaller]\");\n                             int n = getNumberOfPartitions(state.memForJoin, (int) buildPartSize, fudgeFactor,\n                                     nPartitions);\n                            \n@@ -503,6 +508,7 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                                 }\n \n                             } else { //Switch to NLJ (Further recursion seems not to be useful)\n+                            \tLOGGER.log(Level.WARNING,\"\\tSwitched to NLJ for (pid \"+pid+\") - (level \"+level+\") (reverse false) [coming from buildSize was smaller]\");\n                                 for (int rPid = rPStatus.nextSetBit(0); rPid >= 0; rPid = rPStatus.nextSetBit(rPid + 1)) {\n                                     RunFileReader rbrfw = rHHj.getBuildRFReader(rPid);\n                                     RunFileReader rprfw = rHHj.getProbeRFReader(rPid);\n@@ -515,19 +521,21 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                                     int probeSideInTups = rHHj.getProbePartitionSizeInTup(rPid);\n                                     if (isLeftOuter || buildSideInTups < probeSideInTups) {\n                                         applyNestedLoopJoin(probeRd, buildRd, state.memForJoin, rbrfw, rprfw,\n-                                                nljComparator0);\n+                                                nljComparator0, false);\n                                     } else {\n                                         applyNestedLoopJoin(buildRd, probeRd, state.memForJoin, rprfw, rbrfw,\n-                                                nljComparator1);\n+                                                nljComparator1, false);\n                                     }\n                                 }\n                             }\n                         } else { //Role Reversal (Probe Side is smaller)\n+                        \tLOGGER.log(Level.WARNING,\"\\tApply RecursiveHHJ for (pid \"+pid+\") - (level \"+level+\") WITH REVERSAL [probeSize is smaller]\");\n                             int n = getNumberOfPartitions(state.memForJoin, (int) probePartSize, fudgeFactor,\n                                     nPartitions);\n                             \n                             rHHj = new OptimizedHybridHashJoin(ctx, state.memForJoin, n, BUILD_REL, PROBE_REL,\n                                     buildKeys, probeKeys, comparators, buildRd, probeRd, buildHpc, probeHpc, predEvaluator);\n+                            rHHj.setIsReversed(true);\t//Added to use predicateEvaluator (for inMemoryHashJoin) correctly\n \n                             probeSideReader.open();\n                             rHHj.initBuild();\n@@ -561,7 +569,8 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                                     joinPartitionPair(rHHj, rprfw, rbrfw, rPid, afterMax, (level + 1));\n                                 }\n                             } else { //Switch to NLJ (Further recursion seems not to be effective)\n-                                for (int rPid = rPStatus.nextSetBit(0); rPid >= 0; rPid = rPStatus.nextSetBit(rPid + 1)) {\n+                            \tLOGGER.log(Level.WARNING,\"\\tSwitched to NLJ for (pid \"+pid+\") - (level \"+level+\") (reverse true) [coming from probeSize was smaller]\");\n+                            \tfor (int rPid = rPStatus.nextSetBit(0); rPid >= 0; rPid = rPStatus.nextSetBit(rPid + 1)) {\n                                     RunFileReader rbrfw = rHHj.getBuildRFReader(rPid);\n                                     RunFileReader rprfw = rHHj.getProbeRFReader(rPid);\n                                     \n@@ -573,10 +582,10 @@ private void joinPartitionPair(OptimizedHybridHashJoin ohhj, RunFileReader build\n                                     long probeSideSize = rprfw.getFileSize();\n                                     if (buildSideSize > probeSideSize) {\n                                         applyNestedLoopJoin(buildRd, probeRd, state.memForJoin, rbrfw, rprfw,\n-                                                nljComparator1);\n+                                                nljComparator1, true);\n                                     } else {\n                                         applyNestedLoopJoin(probeRd, buildRd, state.memForJoin, rprfw, rbrfw,\n-                                                nljComparator0);\n+                                                nljComparator0, true);\n                                     }\n                                 }\n                             }\n@@ -590,7 +599,7 @@ private void applyInMemHashJoin(int[] bKeys, int[] pKeys, int tabSize, RecordDes\n                         RecordDescriptor probeRDesc, ITuplePartitionComputer hpcRepLarger,\n                         ITuplePartitionComputer hpcRepSmaller, RunFileReader bReader, RunFileReader pReader, boolean reverse, int pid)\n                         throws HyracksDataException {\n-\n+                \tLOGGER.log(Level.WARNING,\"\\t(pid \"+pid+\") - applyInMemHashJoin (reversal \"+reverse+\")\");\n                     ISerializableTable table = new SerializableHashTable(tabSize, ctx);\n                     InMemoryHashJoin joiner = new InMemoryHashJoin(ctx, tabSize, new FrameTupleAccessor(\n                             ctx.getFrameSize(), probeRDesc), hpcRepLarger, new FrameTupleAccessor(ctx.getFrameSize(),\n@@ -619,9 +628,9 @@ private void applyInMemHashJoin(int[] bKeys, int[] pKeys, int tabSize, RecordDes\n                 }\n \n                 private void applyNestedLoopJoin(RecordDescriptor outerRd, RecordDescriptor innerRd, int memorySize,\n-                        RunFileReader outerReader, RunFileReader innerReader, ITuplePairComparator nljComparator)\n+                        RunFileReader outerReader, RunFileReader innerReader, ITuplePairComparator nljComparator, boolean reverse)\n                         throws HyracksDataException {\n-\n+                \t\n                     NestedLoopJoin nlj = new NestedLoopJoin(ctx, new FrameTupleAccessor(ctx.getFrameSize(), outerRd),\n                             new FrameTupleAccessor(ctx.getFrameSize(), innerRd), nljComparator, memorySize, predEvaluator, false, null);\n ",
                "deletions": 14
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Add null guards to avoid NPE when there is no result distribution enabled.",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/25b8e9cbcfa487e398f4233509eb7617b0617d72",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/1e8df9fbc0258c3436e0cbd5cb663d9bfa00848d",
        "bug_id": "asterixdb-hyracks_3",
        "file": [
            {
                "sha": "54ac99a4b44fef50bcec53c00bfae96e1a8ab04d",
                "filename": "hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/AbortTasksWork.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/25b8e9cbcfa487e398f4233509eb7617b0617d72/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/AbortTasksWork.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/25b8e9cbcfa487e398f4233509eb7617b0617d72/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/AbortTasksWork.java",
                "status": "modified",
                "changes": 7,
                "additions": 6,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/AbortTasksWork.java?ref=25b8e9cbcfa487e398f4233509eb7617b0617d72",
                "patch": "@@ -20,6 +20,7 @@\n import java.util.logging.Logger;\n \n import edu.uci.ics.hyracks.api.dataflow.TaskAttemptId;\n+import edu.uci.ics.hyracks.api.dataset.IDatasetPartitionManager;\n import edu.uci.ics.hyracks.api.job.JobId;\n import edu.uci.ics.hyracks.control.common.work.AbstractWork;\n import edu.uci.ics.hyracks.control.nc.Joblet;\n@@ -46,7 +47,11 @@ public void run() {\n         if (LOGGER.isLoggable(Level.INFO)) {\n             LOGGER.info(\"Aborting Tasks: \" + jobId + \":\" + tasks);\n         }\n-        ncs.getDatasetPartitionManager().abortReader(jobId);\n+        IDatasetPartitionManager dpm = ncs.getDatasetPartitionManager();\n+        if (dpm != null) {\n+            ncs.getDatasetPartitionManager().abortReader(jobId);\n+        }\n+\n         Map<JobId, Joblet> jobletMap = ncs.getJobletMap();\n         Joblet ji = jobletMap.get(jobId);\n         if (ji != null) {",
                "deletions": 1
            },
            {
                "sha": "013544d0264a5a4ed2dfa7c85230b10186dd8ab3",
                "filename": "hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/NotifyTaskFailureWork.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/25b8e9cbcfa487e398f4233509eb7617b0617d72/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/NotifyTaskFailureWork.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/25b8e9cbcfa487e398f4233509eb7617b0617d72/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/NotifyTaskFailureWork.java",
                "status": "modified",
                "changes": 6,
                "additions": 5,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/work/NotifyTaskFailureWork.java?ref=25b8e9cbcfa487e398f4233509eb7617b0617d72",
                "patch": "@@ -14,6 +14,7 @@\n  */\n package edu.uci.ics.hyracks.control.nc.work;\n \n+import edu.uci.ics.hyracks.api.dataset.IDatasetPartitionManager;\n import edu.uci.ics.hyracks.api.job.JobId;\n import edu.uci.ics.hyracks.control.common.work.AbstractWork;\n import edu.uci.ics.hyracks.control.nc.NodeControllerService;\n@@ -34,7 +35,10 @@ public NotifyTaskFailureWork(NodeControllerService ncs, Task task, String detail\n     public void run() {\n         try {\n             JobId jobId = task.getJobletContext().getJobId();\n-            ncs.getDatasetPartitionManager().abortReader(jobId);\n+            IDatasetPartitionManager dpm = ncs.getDatasetPartitionManager();\n+            if (dpm != null) {\n+                dpm.abortReader(jobId);\n+            }\n             ncs.getClusterController().notifyTaskFailure(jobId, task.getTaskAttemptId(), ncs.getId(), details);\n         } catch (Exception e) {\n             e.printStackTrace();",
                "deletions": 1
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "ASTERIXDB-1330: fix NPE in ExternalGroupByOperator.\n\nChange-Id: I2279221abbef1440179a31df180a24f6a642c641\nReviewed-on: https://asterix-gerrit.ics.uci.edu/687\nTested-by: Jenkins <jenkins@fulliautomatix.ics.uci.edu>\nReviewed-by: Ian Maxon <imaxon@apache.org>",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/fb530551b5f5efd8d2dba350bf9958a40b4a63a7",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/a672f4421761f27b8b9f3974855c40bc70e76a52",
        "bug_id": "asterixdb-hyracks_4",
        "file": [
            {
                "sha": "852a1601e0a252a6b11b91de79486fd398855959",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupBuildOperatorNodePushable.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/fb530551b5f5efd8d2dba350bf9958a40b4a63a7/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupBuildOperatorNodePushable.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/fb530551b5f5efd8d2dba350bf9958a40b4a63a7/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupBuildOperatorNodePushable.java",
                "status": "modified",
                "changes": 3,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupBuildOperatorNodePushable.java?ref=fb530551b5f5efd8d2dba350bf9958a40b4a63a7",
                "patch": "@@ -71,7 +71,8 @@ public ExternalGroupBuildOperatorNodePushable(IHyracksTaskContext ctx, Object st\n         for (int i = 0; i < comparatorFactories.length; ++i) {\n             comparators[i] = comparatorFactories[i].createBinaryComparator();\n         }\n-        this.firstNormalizerComputer = firstNormalizerFactory.createNormalizedKeyComputer();\n+        this.firstNormalizerComputer = firstNormalizerFactory == null ? null\n+                : firstNormalizerFactory.createNormalizedKeyComputer();\n         this.spillableTableFactory = spillableTableFactory;\n         this.inRecordDescriptor = inRecordDescriptor;\n         this.outRecordDescriptor = outRecordDescriptor;",
                "deletions": 1
            },
            {
                "sha": "0dbb06390677b2ac9b44f716181f4580eb2448b8",
                "filename": "hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupWriteOperatorNodePushable.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/fb530551b5f5efd8d2dba350bf9958a40b4a63a7/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupWriteOperatorNodePushable.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/fb530551b5f5efd8d2dba350bf9958a40b4a63a7/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupWriteOperatorNodePushable.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-dataflow-std/src/main/java/org/apache/hyracks/dataflow/std/group/external/ExternalGroupWriteOperatorNodePushable.java?ref=fb530551b5f5efd8d2dba350bf9958a40b4a63a7",
                "patch": "@@ -64,7 +64,7 @@ public ExternalGroupWriteOperatorNodePushable(IHyracksTaskContext ctx, Object st\n         this.stateId = stateId;\n         this.spillableTableFactory = spillableTableFactory;\n         this.frameLimit = framesLimit;\n-        this.nmkComputer = nmkFactory.createNormalizedKeyComputer();\n+        this.nmkComputer = nmkFactory == null ? null : nmkFactory.createNormalizedKeyComputer();\n \n         this.partialAggRecordDesc = partialAggRecordDesc;\n         this.outRecordDesc = outRecordDesc;",
                "deletions": 1
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "checkpoint: fixed a issue when introducing the HashMergeExcnahge but\nhave not compute its delivered property, which could cause a NPE when\nits delivered property by other operator.",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/05fedfc8c6ff0909137879a40b8a5dcf9cd13cdc",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/ece0fd13262e39eb983e0a28d9c98eba0d909152",
        "bug_id": "asterixdb-hyracks_5",
        "file": [
            {
                "sha": "82e69702ca7b7414539780a3a954626c36cdc799",
                "filename": "algebricks/algebricks-rewriter/src/main/java/edu/uci/ics/hyracks/algebricks/rewriter/rules/IntroHashPartitionMergeExchange.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/05fedfc8c6ff0909137879a40b8a5dcf9cd13cdc/algebricks/algebricks-rewriter/src/main/java/edu/uci/ics/hyracks/algebricks/rewriter/rules/IntroHashPartitionMergeExchange.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/05fedfc8c6ff0909137879a40b8a5dcf9cd13cdc/algebricks/algebricks-rewriter/src/main/java/edu/uci/ics/hyracks/algebricks/rewriter/rules/IntroHashPartitionMergeExchange.java",
                "status": "modified",
                "changes": 2,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/algebricks/algebricks-rewriter/src/main/java/edu/uci/ics/hyracks/algebricks/rewriter/rules/IntroHashPartitionMergeExchange.java?ref=05fedfc8c6ff0909137879a40b8a5dcf9cd13cdc",
                "patch": "@@ -28,6 +28,7 @@\n import edu.uci.ics.hyracks.algebricks.core.algebra.operators.physical.HashPartitionMergeExchangePOperator;\n import edu.uci.ics.hyracks.algebricks.core.algebra.operators.physical.SortMergeExchangePOperator;\n import edu.uci.ics.hyracks.algebricks.core.algebra.properties.OrderColumn;\n+import edu.uci.ics.hyracks.algebricks.core.algebra.util.OperatorPropertiesUtil;\n import edu.uci.ics.hyracks.algebricks.core.rewriter.base.IAlgebraicRewriteRule;\n \n public class IntroHashPartitionMergeExchange implements IAlgebraicRewriteRule {\n@@ -60,6 +61,7 @@ public boolean rewritePost(Mutable<ILogicalOperator> opRef, IOptimizationContext\n                 hpe.getDomain());\n         op1.setPhysicalOperator(hpme);\n         op1.getInputs().get(0).setValue(op2.getInputs().get(0).getValue());\n+        op1.computeDeliveredPhysicalProperties(context);\n         return true;\n     }\n ",
                "deletions": 0
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Fixed NPE on fail when other failures occur\n\ngit-svn-id: https://hyracks.googlecode.com/svn/branches/hyracks_dev_next@1215 123451ca-8445-de46-9d55-352943316053",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/f6df6e4a0776beca227a5383e46405aefb27f3bb",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/5b857450ba71f42b46aabbf91240731bd5ed6020",
        "bug_id": "asterixdb-hyracks_6",
        "file": [
            {
                "sha": "92dc0b2efc8d22c3928cfc451182b7f90d35df14",
                "filename": "hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/partitions/PipelinedPartition.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/f6df6e4a0776beca227a5383e46405aefb27f3bb/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/partitions/PipelinedPartition.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/f6df6e4a0776beca227a5383e46405aefb27f3bb/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/partitions/PipelinedPartition.java",
                "status": "modified",
                "changes": 4,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/partitions/PipelinedPartition.java?ref=f6df6e4a0776beca227a5383e46405aefb27f3bb",
                "patch": "@@ -91,7 +91,9 @@ private void ensureConnected() throws HyracksDataException {\n     public void fail() throws HyracksDataException {\n         ensureConnected();\n         failed = true;\n-        delegate.fail();\n+        if (delegate != null) {\n+            delegate.fail();\n+        }\n     }\n \n     @Override",
                "deletions": 1
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Fixed NPE in LSMBTreeUpdateTest.\n\ngit-svn-id: https://hyracks.googlecode.com/svn/branches/hyracks_lsm_tree@1184 123451ca-8445-de46-9d55-352943316053",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/78a50b9794230245b1d8c1d13a7421290cc18742",
        "bug_id": "asterixdb-hyracks_7",
        "file": [
            {
                "sha": "02d821be53136273f75f383ae5c975b193ed9e11",
                "filename": "hyracks-tests/hyracks-storage-am-lsm-btree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/btree/util/LSMBTreeTestHarness.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1/hyracks-tests/hyracks-storage-am-lsm-btree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/btree/util/LSMBTreeTestHarness.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1/hyracks-tests/hyracks-storage-am-lsm-btree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/btree/util/LSMBTreeTestHarness.java",
                "status": "modified",
                "changes": 9,
                "additions": 5,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks-tests/hyracks-storage-am-lsm-btree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/btree/util/LSMBTreeTestHarness.java?ref=2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1",
                "patch": "@@ -45,7 +45,6 @@\n     private static final long RANDOM_SEED = 50;\n     private static final int DEFAULT_DISK_PAGE_SIZE = 256;\n     private static final int DEFAULT_DISK_NUM_PAGES = 1000;\n-    //private static final int DEFAULT_DISK_NUM_PAGES = 100;\n     private static final int DEFAULT_DISK_MAX_OPEN_FILES = 200;\n     private static final int DEFAULT_MEM_PAGE_SIZE = 256;\n     private static final int DEFAULT_MEM_NUM_PAGES = 100;\n@@ -113,9 +112,11 @@ public boolean accept(File dir, String name) {\n                 }\n             };\n             String[] files = dir.list(filter);\n-            for (String fileName : files) {\n-                File file = new File(dir.getPath() + File.separator + fileName);\n-                file.delete();\n+            if (files != null) {\n+                for (String fileName : files) {\n+                    File file = new File(dir.getPath() + File.separator + fileName);\n+                    file.delete();\n+                }\n             }\n             dir.delete();\n         }",
                "deletions": 4
            },
            {
                "sha": "23ad4385966ad90d2552b9ab327a2c9037160e37",
                "filename": "hyracks-tests/hyracks-storage-am-lsm-rtree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/rtree/util/LSMRTreeTestHarness.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1/hyracks-tests/hyracks-storage-am-lsm-rtree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/rtree/util/LSMRTreeTestHarness.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1/hyracks-tests/hyracks-storage-am-lsm-rtree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/rtree/util/LSMRTreeTestHarness.java",
                "status": "modified",
                "changes": 8,
                "additions": 5,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks-tests/hyracks-storage-am-lsm-rtree-test/src/test/java/edu/uci/ics/hyracks/storage/am/lsm/rtree/util/LSMRTreeTestHarness.java?ref=2fc93e5609ef648e083e8fcb3b7ac1c29f149ae1",
                "patch": "@@ -111,9 +111,11 @@ public boolean accept(File dir, String name) {\n                 }\n             };\n             String[] files = dir.list(filter);\n-            for (String fileName : files) {\n-                File file = new File(dir.getPath() + File.separator + fileName);\n-                file.delete();\n+            if (files != null) {\n+            \tfor (String fileName : files) {\n+            \t\tFile file = new File(dir.getPath() + File.separator + fileName);\n+            \t\tfile.delete();\n+            \t}\n             }\n             dir.delete();\n         }",
                "deletions": 3
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Fixed NPE in Stagelet Completion. Added success flag to finishJoblet() call\n\ngit-svn-id: https://hyracks.googlecode.com/svn/trunk@577 123451ca-8445-de46-9d55-352943316053",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/16f9be39731b880a40a078745c91704a7a78e067",
        "bug_id": "asterixdb-hyracks_8",
        "file": [
            {
                "sha": "a90eaec401bb8f60ba57291f8a73e9f267ffa8b7",
                "filename": "hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/control/INodeController.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/control/INodeController.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/control/INodeController.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/control/INodeController.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -43,7 +43,7 @@ public void initializeJobletPhase2(String appName, UUID jobId, byte[] plan, UUID\n \n     public void abortJoblet(UUID jobId, int attempt) throws Exception;\n \n-    public void cleanUpJob(UUID jobId) throws Exception;\n+    public void cleanUpJob(UUID jobId, boolean success) throws Exception;\n \n     public void startStage(UUID jobId, UUID stageId) throws Exception;\n ",
                "deletions": 1
            },
            {
                "sha": "4827c258bcc0f84c17af0417725d87793721a7c7",
                "filename": "hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/job/IJobletEventListener.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/job/IJobletEventListener.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/job/IJobletEventListener.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/job/IJobletEventListener.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -17,5 +17,5 @@\n public interface IJobletEventListener {\n     public void jobletStart();\n \n-    public void jobletFinish();\n+    public void jobletFinish(boolean success);\n }\n\\ No newline at end of file",
                "deletions": 1
            },
            {
                "sha": "9ec8760aa8e58923b3cfd4d5108593b854e22a7f",
                "filename": "hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/JobCleanupEvent.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/JobCleanupEvent.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/JobCleanupEvent.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/JobCleanupEvent.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -49,7 +49,7 @@ public void run() {\n         final JobCompleteNotifier[] jcns = new JobCompleteNotifier[targetNodes.size()];\n         int i = 0;\n         for (String n : targetNodes) {\n-            jcns[i++] = new JobCompleteNotifier(n, jobId);\n+            jcns[i++] = new JobCompleteNotifier(n, jobId, status == JobStatus.TERMINATED);\n         }\n         ccs.getExecutor().execute(new Runnable() {\n             @Override",
                "deletions": 1
            },
            {
                "sha": "8742ff3acb015d85255f7fbe9b356b619b18e421",
                "filename": "hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/StageletFailureEvent.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/StageletFailureEvent.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/StageletFailureEvent.java",
                "status": "modified",
                "changes": 9,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/job/manager/events/StageletFailureEvent.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -30,16 +30,12 @@\n public class StageletFailureEvent implements Runnable {\n     private final ClusterControllerService ccs;\n     private final UUID jobId;\n-    private final UUID stageId;\n     private final int attempt;\n-    private final String nodeId;\n \n     public StageletFailureEvent(ClusterControllerService ccs, UUID jobId, UUID stageId, int attempt, String nodeId) {\n         this.ccs = ccs;\n         this.jobId = jobId;\n-        this.stageId = stageId;\n         this.attempt = attempt;\n-        this.nodeId = nodeId;\n     }\n \n     @Override\n@@ -50,7 +46,10 @@ public void run() {\n         final Set<String> targetNodes = new HashSet<String>(ja.getParticipatingNodeIds());\n         Map<String, NodeControllerState> nodeMap = new HashMap<String, NodeControllerState>();\n         for (String nodeId : targetNodes) {\n-            nodeMap.get(nodeId).getActiveJobIds().remove(jobId);\n+            NodeControllerState ncState = nodeMap.get(nodeId);\n+            if (ncState != null) {\n+                ncState.getActiveJobIds().remove(jobId);\n+            }\n         }\n         ccs.getExecutor().execute(new Runnable() {\n             @Override",
                "deletions": 5
            },
            {
                "sha": "563e883f7b30dc8144e9c0fd8f158df3e259f714",
                "filename": "hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/remote/ops/JobCompleteNotifier.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/remote/ops/JobCompleteNotifier.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/remote/ops/JobCompleteNotifier.java",
                "status": "modified",
                "changes": 6,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control-cc/src/main/java/edu/uci/ics/hyracks/control/cc/remote/ops/JobCompleteNotifier.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -22,15 +22,17 @@\n public class JobCompleteNotifier implements RemoteOp<Void> {\n     private String nodeId;\n     private UUID jobId;\n+    private boolean status;\n \n-    public JobCompleteNotifier(String nodeId, UUID jobId) {\n+    public JobCompleteNotifier(String nodeId, UUID jobId, boolean status) {\n         this.nodeId = nodeId;\n         this.jobId = jobId;\n+        this.status = status;\n     }\n \n     @Override\n     public Void execute(INodeController node) throws Exception {\n-        node.cleanUpJob(jobId);\n+        node.cleanUpJob(jobId, status);\n         return null;\n     }\n ",
                "deletions": 2
            },
            {
                "sha": "163d79214302591599eadb2fa55ca3c8fbf117b7",
                "filename": "hyracks/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/NodeControllerService.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/NodeControllerService.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/769cf65be04bcc128c8da47a03dd7cb8524b4ec1/hyracks/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/NodeControllerService.java",
                "status": "modified",
                "changes": 4,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-control-nc/src/main/java/edu/uci/ics/hyracks/control/nc/NodeControllerService.java?ref=769cf65be04bcc128c8da47a03dd7cb8524b4ec1",
                "patch": "@@ -466,15 +466,15 @@ public Executor getExecutor() {\n     }\n \n     @Override\n-    public void cleanUpJob(UUID jobId) throws Exception {\n+    public void cleanUpJob(UUID jobId, boolean success) throws Exception {\n         if (LOGGER.isLoggable(Level.INFO)) {\n             LOGGER.info(\"Cleaning up after job: \" + jobId);\n         }\n         Joblet joblet = jobletMap.remove(jobId);\n         if (joblet != null) {\n             IJobletEventListener listener = joblet.getJobletEventListener();\n             if (listener != null) {\n-                listener.jobletFinish();\n+                listener.jobletFinish(success);\n             }\n             joblet.close();\n         }",
                "deletions": 2
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "Fix for ASTERIXDB-1200\n\nFixes an issue where in the Hyracks integration tests,\nif the result size is 0, a NPE is thrown instead of\nan assert passing or failing.\n\nChange-Id: Ib519882b9cbca941addcd66232c176a2eaeecc4b\nReviewed-on: https://asterix-gerrit.ics.uci.edu/524\nTested-by: Jenkins <jenkins@fulliautomatix.ics.uci.edu>\nReviewed-by: Till Westmann <tillw@apache.org>",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/84ddcb998e908cf4f8f27275aa6855063c14b3f0",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/c10677f36fd1de1ce1a984419e29718a1cd82f55",
        "bug_id": "asterixdb-hyracks_9",
        "file": [
            {
                "sha": "7a339b774c393ab10d8df1f01b11c56961d45d13",
                "filename": "hyracks/hyracks-examples/hyracks-integration-tests/src/test/java/org/apache/hyracks/tests/integration/AbstractIntegrationTest.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/84ddcb998e908cf4f8f27275aa6855063c14b3f0/hyracks/hyracks-examples/hyracks-integration-tests/src/test/java/org/apache/hyracks/tests/integration/AbstractIntegrationTest.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/84ddcb998e908cf4f8f27275aa6855063c14b3f0/hyracks/hyracks-examples/hyracks-integration-tests/src/test/java/org/apache/hyracks/tests/integration/AbstractIntegrationTest.java",
                "status": "modified",
                "changes": 10,
                "additions": 7,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-examples/hyracks-integration-tests/src/test/java/org/apache/hyracks/tests/integration/AbstractIntegrationTest.java?ref=84ddcb998e908cf4f8f27275aa6855063c14b3f0",
                "patch": "@@ -145,7 +145,6 @@ protected void runTest(JobSpecification spec) throws Exception {\n         hcc.waitForCompletion(jobId);\n     }\n \n-\n     protected List<String> readResults(JobSpecification spec, JobId jobId, ResultSetId resultSetId) throws Exception {\n         int nReaders = 1;\n \n@@ -190,13 +189,18 @@ protected boolean runTestAndCompareResults(JobSpecification spec, String[] expec\n             results = readResults(spec, jobId, spec.getResultSetIds().get(i));\n             BufferedReader expectedFile = new BufferedReader(new FileReader(expectedFileNames[i]));\n \n+            //We're expecting some sort of result.\n+            Assert.assertTrue(results != null);\n+            Assert.assertTrue(results.size() > 0);\n+\n             String expectedLine, actualLine;\n             int j = 0;\n             while ((expectedLine = expectedFile.readLine()) != null) {\n                 actualLine = results.get(j).trim();\n                 Assert.assertEquals(expectedLine, actualLine);\n                 j++;\n             }\n+            //We also expect the same amount of results.\n             Assert.assertEquals(j, results.size());\n             expectedFile.close();\n         }\n@@ -212,7 +216,7 @@ protected void runTestAndStoreResult(JobSpecification spec, File file) throws Ex\n         List<String> results;\n         for (int i = 0; i < spec.getResultSetIds().size(); i++) {\n             results = readResults(spec, jobId, spec.getResultSetIds().get(i));\n-            for(String str : results) {\n+            for (String str : results) {\n                 output.write(str);\n             }\n         }\n@@ -229,4 +233,4 @@ protected File createTempFile() throws IOException {\n         outputFiles.add(tempFile);\n         return tempFile;\n     }\n-}\n\\ No newline at end of file\n+}",
                "deletions": 3
            }
        ]
    },
    {
        "repo": "asterixdb-hyracks",
        "message": "This change allows setting a local ordering property for assign operators. it is needed when variables that are created in the assign operator are sorted\n\nThe following commits from your working branch will be included:\n\ncommit 9e4abb36e6f50e0f73406f4603cdc79590ca7b06\nAuthor: Abdullah Alamoudi <bamousaa@gmail.com>\nDate:   Mon Feb 2 16:53:45 2015 +0300\n\n    added a TODO for deserialization\n\ncommit 78f7ee6fb04358d36156658202fb4478e47059e2\nAuthor: Abdullah Alamoudi <bamousaa@gmail.com>\nDate:   Mon Feb 2 16:30:56 2015 +0300\n\n    fixed NPE in substitue variable visitor\n\ncommit 6bb101e072e03aae2732613385589e1ae52b510c\nAuthor: Abdullah Alamoudi <bamousaa@gmail.com>\nDate:   Mon Feb 2 15:07:14 2015 +0300\n\n    Allow assign operator to have explicitly set ordering properties\n\nChange-Id: If995b47aa3c97ce60be952141699268341d31eea\nReviewed-on: http://fulliautomatix.ics.uci.edu:8443/214\nTested-by: Jenkins <jenkins@fulliautomatix.ics.uci.edu>\nReviewed-by: Taewoo Kim <wangsaeu@gmail.com>",
        "commit": "https://github.com/apache/asterixdb-hyracks/commit/81b15019fec73d29c0757cc36afd516360fce34c",
        "parent": "https://github.com/apache/asterixdb-hyracks/commit/9b3b54672a3a0215c6e1da827a30588e19fc1cd2",
        "bug_id": "asterixdb-hyracks_10",
        "file": [
            {
                "sha": "9a8c428eefb8fb10968b545ec9ffe4837ffa6335",
                "filename": "algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/AssignOperator.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/AssignOperator.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/AssignOperator.java",
                "status": "modified",
                "changes": 13,
                "additions": 12,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/AssignOperator.java?ref=81b15019fec73d29c0757cc36afd516360fce34c",
                "patch": "@@ -15,7 +15,6 @@\n package edu.uci.ics.hyracks.algebricks.core.algebra.operators.logical;\n \n import java.util.List;\n-\n import org.apache.commons.lang3.mutable.Mutable;\n \n import edu.uci.ics.hyracks.algebricks.common.exceptions.AlgebricksException;\n@@ -25,6 +24,7 @@\n import edu.uci.ics.hyracks.algebricks.core.algebra.base.LogicalVariable;\n import edu.uci.ics.hyracks.algebricks.core.algebra.expressions.IVariableTypeEnvironment;\n import edu.uci.ics.hyracks.algebricks.core.algebra.expressions.VariableReferenceExpression;\n+import edu.uci.ics.hyracks.algebricks.core.algebra.properties.LocalOrderProperty;\n import edu.uci.ics.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy;\n import edu.uci.ics.hyracks.algebricks.core.algebra.typing.ITypingContext;\n import edu.uci.ics.hyracks.algebricks.core.algebra.typing.PropagatingTypeEnvironment;\n@@ -37,6 +37,8 @@\n  */\n \n public class AssignOperator extends AbstractAssignOperator {\n+\t\n+\tprivate LocalOrderProperty explicitOrderingProperty;\n \n     public AssignOperator(List<LogicalVariable> vars, List<Mutable<ILogicalExpression>> exprs) {\n         super(vars, exprs);\n@@ -105,4 +107,13 @@ public IVariableTypeEnvironment computeOutputTypeEnvironment(ITypingContext ctx)\n     public boolean requiresVariableReferenceExpressions() {\n         return false;\n     }\n+\n+    public LocalOrderProperty getExplicitOrderingProperty() {\n+\t\treturn explicitOrderingProperty;\n+\t}\n+\n+\tpublic void setExplicitOrderingProperty(\n+\t\t\tLocalOrderProperty explicitOrderingProperty) {\n+\t\tthis.explicitOrderingProperty = explicitOrderingProperty;\n+\t}\n }\n\\ No newline at end of file",
                "deletions": 1
            },
            {
                "sha": "695078a1a7ba00e24fb4c0977d1d7747173d27ff",
                "filename": "algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/visitors/SubstituteVariableVisitor.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/visitors/SubstituteVariableVisitor.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/visitors/SubstituteVariableVisitor.java",
                "status": "modified",
                "changes": 11,
                "additions": 11,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/logical/visitors/SubstituteVariableVisitor.java?ref=81b15019fec73d29c0757cc36afd516360fce34c",
                "patch": "@@ -61,6 +61,7 @@\n import edu.uci.ics.hyracks.algebricks.core.algebra.operators.logical.UnnestOperator;\n import edu.uci.ics.hyracks.algebricks.core.algebra.operators.logical.WriteOperator;\n import edu.uci.ics.hyracks.algebricks.core.algebra.operators.logical.WriteResultOperator;\n+import edu.uci.ics.hyracks.algebricks.core.algebra.properties.OrderColumn;\n import edu.uci.ics.hyracks.algebricks.core.algebra.typing.ITypingContext;\n import edu.uci.ics.hyracks.algebricks.core.algebra.util.OperatorManipulationUtil;\n import edu.uci.ics.hyracks.algebricks.core.algebra.visitors.ILogicalOperatorVisitor;\n@@ -103,6 +104,16 @@ public Void visitAssignOperator(AssignOperator op, Pair<LogicalVariable, Logical\n                 op.getExpressions().get(i).getValue().substituteVar(pair.first, pair.second);\n             }\n         }\n+        // Substitute variables stored in ordering property\n+        if (op.getExplicitOrderingProperty() != null) {\n+            List<OrderColumn> orderColumns = op.getExplicitOrderingProperty().getOrderColumns();\n+            for (int i = 0; i < orderColumns.size(); i++) {\n+                OrderColumn oc = orderColumns.get(i);\n+                if (oc.getColumn().equals(pair.first)) {\n+                    orderColumns.set(i, new OrderColumn(pair.second, oc.getOrder()));\n+                }\n+            }\n+        }\n         substVarTypes(op, pair);\n         return null;\n     }",
                "deletions": 0
            },
            {
                "sha": "26313fbf0aaab3f485fad5e7cc2346362c0dee96",
                "filename": "algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/physical/AssignPOperator.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/physical/AssignPOperator.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/81b15019fec73d29c0757cc36afd516360fce34c/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/physical/AssignPOperator.java",
                "status": "modified",
                "changes": 4,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/algebricks/algebricks-core/src/main/java/edu/uci/ics/hyracks/algebricks/core/algebra/operators/physical/AssignPOperator.java?ref=81b15019fec73d29c0757cc36afd516360fce34c",
                "patch": "@@ -47,8 +47,12 @@ public PhysicalOperatorTag getOperatorTag() {\n \n     @Override\n     public void computeDeliveredProperties(ILogicalOperator op, IOptimizationContext context) {\n+        AssignOperator assignOp = (AssignOperator) op;\n         ILogicalOperator op2 = op.getInputs().get(0).getValue();\n         deliveredProperties = op2.getDeliveredPhysicalProperties().clone();\n+        if (assignOp.getExplicitOrderingProperty() != null) {\n+            deliveredProperties.getLocalProperties().add(assignOp.getExplicitOrderingProperty());\n+        }\n     }\n \n     @Override",
                "deletions": 0
            },
            {
                "sha": "197fda799d0d936e5b32d6e4739296343a90325b",
                "filename": "hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/dataflow/value/ISerializerDeserializer.java",
                "blob_url": "https://github.com/apache/asterixdb-hyracks/blob/81b15019fec73d29c0757cc36afd516360fce34c/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/dataflow/value/ISerializerDeserializer.java",
                "raw_url": "https://github.com/apache/asterixdb-hyracks/raw/81b15019fec73d29c0757cc36afd516360fce34c/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/dataflow/value/ISerializerDeserializer.java",
                "status": "modified",
                "changes": 6,
                "additions": 6,
                "contents_url": "https://api.github.com/repos/apache/asterixdb-hyracks/contents/hyracks/hyracks-api/src/main/java/edu/uci/ics/hyracks/api/dataflow/value/ISerializerDeserializer.java?ref=81b15019fec73d29c0757cc36afd516360fce34c",
                "patch": "@@ -39,4 +39,10 @@\n      *            - Stream to write data to.\n      */\n     public void serialize(T instance, DataOutput out) throws HyracksDataException;\n+    \n+    /*\n+     * TODO: Add a new method:\n+     * T deserialize(DataInput in, T mutable)\n+     * to provide deserialization without creating objects\n+     */\n }\n\\ No newline at end of file",
                "deletions": 0
            }
        ]
    }
]