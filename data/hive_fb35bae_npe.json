[
    {
        "repo": "hive",
        "commit": "https://github.com/apache/hive/commit/fb35bae5ae2fad93de3deef9023f52cba8e4783b",
        "bug_id": "hive_fb35bae",
        "message": "HIVE-14109: query execuction throws NPE when hive.exec.submitviachild is set to true (Aihua Xu, reviewed by Sergio Pe\u00f1a)",
        "parent": "https://github.com/apache/hive/commit/72cea13e4d968fad86be733c1f1aa65aafbb1fc4",
        "patched_files": [
            "ExecDriver.java"
        ],
        "file": [
            {
                "status": "modified",
                "additions": 5,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java",
                "deletions": 3,
                "sha": "285f9ad76e07b66dc338c5d33859ff47ac08d9a8",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java",
                "patch": "@@ -126,7 +126,8 @@\n   public ExecDriver() {\n     super();\n     console = new LogHelper(LOG);\n-    this.jobExecHelper = new HadoopJobExecHelper(queryState, job, console, this, this);\n+    job = new JobConf(ExecDriver.class);\n+    this.jobExecHelper = new HadoopJobExecHelper(job, console, this, this);\n   }\n \n   @Override\n@@ -175,7 +176,7 @@ public void initialize(QueryState queryState, QueryPlan queryPlan, DriverContext\n     initializeFiles(\"tmparchives\", getResource(conf, SessionState.ResourceType.ARCHIVE));\n \n     conf.stripHiddenConfigurations(job);\n-    this.jobExecHelper = new HadoopJobExecHelper(queryState, job, console, this, this);\n+    this.jobExecHelper = new HadoopJobExecHelper(job, console, this, this);\n   }\n \n   /**\n@@ -185,7 +186,7 @@ public ExecDriver(MapredWork plan, JobConf job, boolean isSilent) throws HiveExc\n     setWork(plan);\n     this.job = job;\n     console = new LogHelper(LOG, isSilent);\n-    this.jobExecHelper = new HadoopJobExecHelper(queryState, job, console, this, this);\n+    this.jobExecHelper = new HadoopJobExecHelper(job, console, this, this);\n   }\n \n   /**\n@@ -671,6 +672,7 @@ public static void main(String[] args) throws IOException, HiveException {\n     String queryId = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID, \"\").trim();\n     if(queryId.isEmpty()) {\n       queryId = \"unknown-\" + System.currentTimeMillis();\n+      HiveConf.setVar(conf, HiveConf.ConfVars.HIVEQUERYID, queryId);\n     }\n     System.setProperty(HiveConf.ConfVars.HIVEQUERYID.toString(), queryId);\n ",
                "changes": 8
            },
            {
                "status": "modified",
                "additions": 8,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java",
                "deletions": 10,
                "sha": "cfb4a2816817925fe7351f7d17bd8ab35742890b",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java",
                "patch": "@@ -34,7 +34,6 @@\n import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n import org.apache.hadoop.hive.ql.Context;\n import org.apache.hadoop.hive.ql.MapRedStats;\n-import org.apache.hadoop.hive.ql.QueryState;\n import org.apache.hadoop.hive.ql.exec.Operator;\n import org.apache.hadoop.hive.ql.exec.Task;\n import org.apache.hadoop.hive.ql.exec.TaskHandle;\n@@ -78,7 +77,7 @@\n   public transient JobID jobId;\n   private final LogHelper console;\n   private final HadoopJobExecHook callBackObj;\n-  private final QueryState queryState;\n+  private final String queryId;\n \n   /**\n    * Update counters relevant to this task.\n@@ -139,9 +138,9 @@ public void setJobId(JobID jobId) {\n     this.jobId = jobId;\n   }\n \n-  public HadoopJobExecHelper(QueryState queryState, JobConf job, LogHelper console,\n+  public HadoopJobExecHelper(JobConf job, LogHelper console,\n       Task<? extends Serializable> task, HadoopJobExecHook hookCallBack) {\n-    this.queryState = queryState;\n+    this.queryId = HiveConf.getVar(job, HiveConf.ConfVars.HIVEQUERYID, \"unknown-\" + System.currentTimeMillis());\n     this.job = job;\n     this.console = console;\n     this.task = task;\n@@ -259,7 +258,6 @@ private MapRedStats progress(ExecDriverTaskHandle th) throws IOException, LockEx\n \n           String logMapper;\n           String logReducer;\n-          String queryId = queryState.getQueryId();\n           TaskReport[] mappers = jc.getMapTaskReports(rj.getID());\n           if (mappers == null) {\n             logMapper = \"no information for number of mappers; \";\n@@ -364,11 +362,11 @@ private MapRedStats progress(ExecDriverTaskHandle th) throws IOException, LockEx\n       String output = report.toString();\n       SessionState ss = SessionState.get();\n       if (ss != null) {\n-        ss.getHiveHistory().setTaskCounters(queryState.getQueryId(), getId(), ctrs);\n-        ss.getHiveHistory().setTaskProperty(queryState.getQueryId(), getId(),\n+        ss.getHiveHistory().setTaskCounters(queryId, getId(), ctrs);\n+        ss.getHiveHistory().setTaskProperty(queryId, getId(),\n             Keys.TASK_HADOOP_PROGRESS, output);\n         if (ss.getConf().getBoolVar(HiveConf.ConfVars.HIVE_LOG_INCREMENTAL_PLAN_PROGRESS)) {\n-          ss.getHiveHistory().progressTask(queryState.getQueryId(), this.task);\n+          ss.getHiveHistory().progressTask(queryId, this.task);\n           this.callBackObj.logPlanProgress(ss);\n         }\n       }\n@@ -397,7 +395,7 @@ private MapRedStats progress(ExecDriverTaskHandle th) throws IOException, LockEx\n       } else {\n         SessionState ss = SessionState.get();\n         if (ss != null) {\n-          ss.getHiveHistory().setTaskCounters(queryState.getQueryId(), getId(), ctrs);\n+          ss.getHiveHistory().setTaskCounters(queryId, getId(), ctrs);\n         }\n         success = rj.isSuccessful();\n       }\n@@ -441,7 +439,7 @@ public void jobInfo(RunningJob rj) {\n       console.printInfo(\"Job running in-process (local Hadoop)\");\n     } else {\n       if (SessionState.get() != null) {\n-        SessionState.get().getHiveHistory().setTaskProperty(queryState.getQueryId(),\n+        SessionState.get().getHiveHistory().setTaskProperty(queryId,\n             getId(), Keys.TASK_HADOOP_ID, rj.getID().toString());\n       }\n       console.printInfo(getJobStartMsg(rj.getID()) + \", Tracking URL = \"",
                "changes": 18
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java",
                "deletions": 1,
                "sha": "23a13d66c2dc1434c96164a7e2a8869fd5b4fcae",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java",
                "patch": "@@ -128,7 +128,7 @@ public void initialize(QueryState queryState, QueryPlan queryPlan, DriverContext\n     job = new JobConf(conf, ExecDriver.class);\n     execContext = new ExecMapperContext(job);\n     //we don't use the HadoopJobExecHooks for local tasks\n-    this.jobExecHelper = new HadoopJobExecHelper(queryState, job, console, this, null);\n+    this.jobExecHelper = new HadoopJobExecHelper(job, console, this, null);\n   }\n \n   public static String now() {",
                "changes": 2
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/merge/MergeFileTask.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/io/merge/MergeFileTask.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/io/merge/MergeFileTask.java",
                "deletions": 1,
                "sha": "376bab2c39f775a6d6c931f55f60c90c87e41957",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/merge/MergeFileTask.java",
                "patch": "@@ -65,7 +65,7 @@ public void initialize(QueryState queryState, QueryPlan queryPlan,\n       DriverContext driverContext, CompilationOpContext opContext) {\n     super.initialize(queryState, queryPlan, driverContext, opContext);\n     job = new JobConf(conf, MergeFileTask.class);\n-    jobExecHelper = new HadoopJobExecHelper(queryState, job, this.console, this, this);\n+    jobExecHelper = new HadoopJobExecHelper(job, this.console, this, this);\n   }\n \n   @Override",
                "changes": 2
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java",
                "deletions": 1,
                "sha": "6131581b1965adccd3f49f8fd730648acffbc78e",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java",
                "patch": "@@ -89,7 +89,7 @@ public void initialize(QueryState queryState, QueryPlan queryPlan,\n       DriverContext driverContext, CompilationOpContext opContext) {\n     super.initialize(queryState, queryPlan, driverContext, opContext);\n     job = new JobConf(conf, PartialScanTask.class);\n-    jobExecHelper = new HadoopJobExecHelper(queryState, job, this.console, this, this);\n+    jobExecHelper = new HadoopJobExecHelper(job, this.console, this, this);\n   }\n \n   @Override",
                "changes": 2
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/hive/raw/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java",
                "contents_url": "https://api.github.com/repos/apache/hive/contents/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java?ref=fb35bae5ae2fad93de3deef9023f52cba8e4783b",
                "filename": "ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java",
                "deletions": 1,
                "sha": "2d29afcbac0fcc6ce7e9554ad78d2b98127103a5",
                "blob_url": "https://github.com/apache/hive/blob/fb35bae5ae2fad93de3deef9023f52cba8e4783b/ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java",
                "patch": "@@ -64,7 +64,7 @@ public void initialize(QueryState queryState, QueryPlan queryPlan,\n       DriverContext driverContext, CompilationOpContext opContext) {\n     super.initialize(queryState, queryPlan, driverContext, opContext);\n     job = new JobConf(conf, ColumnTruncateTask.class);\n-    jobExecHelper = new HadoopJobExecHelper(queryState, job, this.console, this, this);\n+    jobExecHelper = new HadoopJobExecHelper(job, this.console, this, this);\n   }\n \n   @Override",
                "changes": 2
            }
        ],
        "unit_tests": [
            "TestExecDriver.java"
        ]
    },
    {
        "buggy": false,
        "test_file": "ql/src/test/org/apache/hadoop/hive/ql/exec/TestExecDriver.java",
        "buggy_files": [
            "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java"
        ],
        "fixed": true
    }
]