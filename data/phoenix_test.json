{
    "phoenix_b8f32ae": {
        "repo": "phoenix",
        "message": "PHOENIX-1360: NPE in SpoolingResultIterator",
        "commit": "https://github.com/apache/phoenix/commit/b8f32aeaa735689f231268d7c790efbd6051d7f4",
        "parent": "https://github.com/apache/phoenix/commit/cf41cc63594ac7d8f3d831511215519fe43afea0",
        "bug_id": "phoenix_b8f32ae",
        "file": [
            {
                "sha": "0ba6554077bb5a434ea84fef64cc1a4a1b16bd10",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java",
                "blob_url": "https://github.com/apache/phoenix/blob/b8f32aeaa735689f231268d7c790efbd6051d7f4/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java",
                "raw_url": "https://github.com/apache/phoenix/raw/b8f32aeaa735689f231268d7c790efbd6051d7f4/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/SpoolingResultIterator.java?ref=b8f32aeaa735689f231268d7c790efbd6051d7f4",
                "patch": "@@ -132,7 +132,7 @@ protected void thresholdReached() throws IOException {\n                 scanner.close();\n             } finally {\n                 try {\n-                    if (!usedOnDiskIterator) {\n+                    if (!usedOnDiskIterator && tempFile != null) {\n                         tempFile.delete();\n                     }\n                 } finally {",
                "deletions": 1
            }
        ],
        "patched_files": [
            "SpoolingResultIterator.java"
        ],
        "unit_tests": [
            "SpoolingResultIteratorTest.java"
        ]
    },
    "phoenix_0b5eddc": {
        "repo": "phoenix",
        "message": "PHOENIX-5415: NPE in getting conf from addHbaseResources in IndexUpgradeTool",
        "commit": "https://github.com/apache/phoenix/commit/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0",
        "parent": "https://github.com/apache/phoenix/commit/665e224e4d9a0e991e38083b983ec38989dfd5e7",
        "bug_id": "phoenix_0b5eddc",
        "file": [
            {
                "sha": "daac60456c320fa583d961a65af8bd4f40d7a3ee",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java",
                "blob_url": "https://github.com/apache/phoenix/blob/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java",
                "raw_url": "https://github.com/apache/phoenix/raw/0b5eddc38a566b2c83cc30aff5a1b9f679efdad0/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java",
                "status": "modified",
                "changes": 141,
                "additions": 88,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexUpgradeTool.java?ref=0b5eddc38a566b2c83cc30aff5a1b9f679efdad0",
                "patch": "@@ -18,6 +18,7 @@\n package org.apache.phoenix.mapreduce.index;\n \n import com.google.common.annotations.VisibleForTesting;\n+import com.google.gson.Gson;\n import org.apache.commons.cli.CommandLine;\n import org.apache.commons.cli.CommandLineParser;\n import org.apache.commons.cli.DefaultParser;\n@@ -26,6 +27,8 @@\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.hadoop.conf.Configured;\n+import org.apache.hadoop.util.Tool;\n+import org.apache.hadoop.util.ToolRunner;\n \n import org.apache.hadoop.hbase.HBaseConfiguration;\n import org.apache.hadoop.hbase.TableName;\n@@ -55,6 +58,7 @@\n import java.util.logging.Logger;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.StringUtil;\n \n import java.io.IOException;\n import java.nio.file.Files;\n@@ -70,7 +74,7 @@\n \n import static org.apache.phoenix.query.QueryServicesOptions.GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN;\n \n-public class IndexUpgradeTool extends Configured {\n+public class IndexUpgradeTool extends Configured implements Tool {\n \n     private static final Logger LOGGER = Logger.getLogger(IndexUpgradeTool.class.getName());\n \n@@ -145,21 +149,6 @@ public String getOperation() {\n         return operation;\n     }\n \n-    public static void main (String[] args) {\n-        CommandLine cmdLine = null;\n-\n-        IndexUpgradeTool iut = new IndexUpgradeTool();\n-        try {\n-            cmdLine = iut.parseOptions(args);\n-            LOGGER.info(\"Index Upgrade tool initiated: \"+ String.join(\",\", args));\n-        } catch (IllegalStateException e) {\n-            iut.printHelpAndExit(e.getMessage(), iut.getOptions());\n-        }\n-        iut.initializeTool(cmdLine);\n-        iut.prepareToolSetup();\n-        iut.executeTool();\n-    }\n-\n     public IndexUpgradeTool(String mode, String tables, String inputFile,\n             String outputFile, boolean dryRun, IndexTool indexTool) {\n         this.operation = mode;\n@@ -172,6 +161,21 @@ public IndexUpgradeTool(String mode, String tables, String inputFile,\n \n     public IndexUpgradeTool () { }\n \n+    @Override\n+    public int run(String[] args) throws Exception {\n+        CommandLine cmdLine = null;\n+        try {\n+            cmdLine = parseOptions(args);\n+            LOGGER.info(\"Index Upgrade tool initiated: \" + String.join(\",\", args));\n+        } catch (IllegalStateException e) {\n+            printHelpAndExit(e.getMessage(), getOptions());\n+        }\n+        initializeTool(cmdLine);\n+        prepareToolSetup();\n+        executeTool();\n+        return 0;\n+    }\n+\n     /**\n      * Parses the commandline arguments, throws IllegalStateException if mandatory arguments are\n      * missing.\n@@ -329,7 +333,7 @@ private int executeTool(Connection conn, ConnectionQueryServices queryServices,\n                 boolean mutable = !(dataTable.isImmutableRows());\n                 if (!mutable) {\n                     LOGGER.fine(\"Data table is immutable, waiting for \"\n-                            + GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN + 1\n+                            + (GLOBAL_INDEX_CHECKER_ENABLED_MAP_EXPIRATION_MIN + 1)\n                             + \" minutes for client cache to expire\");\n                     if (!test) {\n                         Thread.sleep(\n@@ -368,7 +372,7 @@ private void disableTable(Admin admin, String dataTable, HashSet<String>indexes)\n             }\n             LOGGER.info(\"Disabled data table \" + dataTable);\n         } else {\n-            LOGGER.info( \"Data table \" + dataTable +\" is already disabled\");\n+            LOGGER.info( \"Data table \" + dataTable + \" is already disabled\");\n         }\n         for (String indexName : indexes) {\n             if (admin.isTableEnabled(TableName.valueOf(indexName))) {\n@@ -377,7 +381,7 @@ private void disableTable(Admin admin, String dataTable, HashSet<String>indexes)\n                 }\n                 LOGGER.info(\"Disabled index table \" + indexName);\n             } else {\n-                LOGGER.info( \"Index table \" + indexName +\" is already disabled\");\n+                LOGGER.info( \"Index table \" + indexName + \" is already disabled\");\n             }\n         }\n     }\n@@ -390,7 +394,7 @@ private void enableTable(Admin admin, String dataTable, HashSet<String>indexes)\n             }\n             LOGGER.info(\"Enabled data table \" + dataTable);\n         } else {\n-            LOGGER.info( \"Data table \" + dataTable +\" is already enabled\");\n+            LOGGER.info( \"Data table \" + dataTable + \" is already enabled\");\n         }\n         for (String indexName : indexes) {\n             if(!admin.isTableEnabled(TableName.valueOf(indexName))) {\n@@ -399,7 +403,7 @@ private void enableTable(Admin admin, String dataTable, HashSet<String>indexes)\n                 }\n                 LOGGER.info(\"Enabled index table \" + indexName);\n             } else {\n-                LOGGER.info( \"Index table \" + indexName +\" is already enabled\");\n+                LOGGER.info( \"Index table \" + indexName + \" is already enabled\");\n             }\n         }\n     }\n@@ -431,26 +435,28 @@ private void modifyDataTable(Admin admin, String tableName)\n         }\n     }\n \n-    private void addCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder, String coprocName) throws IOException {\n+    private void addCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder,\n+            String coprocName) throws IOException {\n         if (!admin.getDescriptor(TableName.valueOf(tableName)).hasCoprocessor(coprocName)) {\n             if (!dryRun) {\n                 tableDescBuilder.addCoprocessor(coprocName,\n                         null, QueryServicesOptions.DEFAULT_COPROCESSOR_PRIORITY, prop);\n             }\n-            LOGGER.info(\"Loaded \"+coprocName+\" coprocessor on table \" + tableName);\n+            LOGGER.info(\"Loaded \" + coprocName + \" coprocessor on table \" + tableName);\n         } else {\n-            LOGGER.info(coprocName+\" coprocessor on table \" + tableName + \"is already loaded\");\n+            LOGGER.info(coprocName + \" coprocessor on table \" + tableName + \"is already loaded\");\n         }\n     }\n \n-    private void removeCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder, String coprocName) throws IOException {\n+    private void removeCoprocessor(Admin admin, String tableName, TableDescriptorBuilder tableDescBuilder,\n+            String coprocName) throws IOException {\n         if (admin.getDescriptor(TableName.valueOf(tableName)).hasCoprocessor(coprocName)) {\n             if (!dryRun) {\n                 tableDescBuilder.removeCoprocessor(coprocName);\n             }\n             LOGGER.info(\"Unloaded \"+ coprocName +\"coprocessor on table \" + tableName);\n         } else {\n-            LOGGER.info(coprocName+\" coprocessor on table \" + tableName + \" is already unloaded\");\n+            LOGGER.info(coprocName + \" coprocessor on table \" + tableName + \" is already unloaded\");\n         }\n     }\n \n@@ -534,7 +540,7 @@ private boolean extractTablesAndIndexes(PhoenixConnection conn) {\n                     //for upgrade or rollback\n                     tablesAndIndexes.put(physicalTableName, physicalIndexes);\n                 } else {\n-                    LOGGER.info(\"Skipping Table \" + tableName + \" because it is \"+\n+                    LOGGER.info(\"Skipping Table \" + tableName + \" because it is \" +\n                             (dataTable.isTransactional() ? \"transactional\" : \"not a data table\"));\n                 }\n             }\n@@ -550,13 +556,13 @@ private boolean extractTablesAndIndexes(PhoenixConnection conn) {\n \n     private void prepareToRebuildIndexes(Connection conn, String dataTableFullName) {\n         try {\n+            Gson gson = new Gson();\n             HashMap<String, IndexInfo> rebuildIndexes = new HashMap<>();\n             HashSet<String> physicalIndexes = tablesAndIndexes.get(dataTableFullName);\n \n             String viewIndexPhysicalName = MetaDataUtil\n                     .getViewIndexPhysicalName(dataTableFullName);\n             boolean hasViewIndex =  physicalIndexes.contains(viewIndexPhysicalName);\n-\n             String schemaName = SchemaUtil.getSchemaNameFromFullName(dataTableFullName);\n             String tableName = SchemaUtil.getTableNameFromFullName(dataTableFullName);\n \n@@ -572,40 +578,64 @@ private void prepareToRebuildIndexes(Connection conn, String dataTableFullName)\n             }\n \n             if (hasViewIndex) {\n-                ResultSet\n-                        rs =\n-                        conn.createStatement().executeQuery(\n-                                \"SELECT DISTINCT TABLE_NAME, TENANT_ID FROM \"\n-                                        + \"SYSTEM.CATALOG WHERE COLUMN_FAMILY = \\'\"\n-                                        + viewIndexPhysicalName\n-                                        + \"\\' AND TABLE_TYPE = \\'i\\' AND \" + \"LINK_TYPE = \"\n-                                        + PTable.LinkType.PHYSICAL_TABLE.getSerializedValue());\n+                String viewSql = \"SELECT DISTINCT TABLE_NAME, TENANT_ID FROM \"\n+                        + \"SYSTEM.CATALOG \"\n+                        + \"WHERE COLUMN_FAMILY = \\'\" + dataTableFullName + \"\\' \"\n+                        + (!StringUtil.EMPTY_STRING.equals(schemaName) ? \"AND TABLE_SCHEM = \\'\"\n+                        + schemaName + \"\\' \" : \"\")\n+                        + \"AND LINK_TYPE = \"\n+                        + PTable.LinkType.PHYSICAL_TABLE.getSerializedValue();\n+\n+                ResultSet rs = conn.createStatement().executeQuery(viewSql);\n+\n                 while (rs.next()) {\n-                    String viewIndexName = rs.getString(1);\n+                    String viewName = rs.getString(1);\n                     String tenantId = rs.getString(2);\n-                    ResultSet\n-                            innerRS =\n-                            conn.createStatement().executeQuery(\n-                                    \"SELECT DISTINCT TABLE_NAME FROM \"\n-                                            + \"SYSTEM.CATALOG WHERE COLUMN_FAMILY = \\'\"\n-                                            + viewIndexName\n-                                            + \"\\' AND TABLE_TYPE = \\'i\\' AND \" + \"LINK_TYPE = \"\n-                                            + PTable.LinkType.INDEX_TABLE.getSerializedValue());\n-                    innerRS.next();\n-                    String viewName = innerRS.getString(1);\n-                    IndexInfo indexInfo = new IndexInfo(schemaName, viewName, tenantId == null ?\n-                            GLOBAL_INDEX_ID: tenantId, viewIndexName);\n-                    rebuildIndexes.put(viewIndexName, indexInfo);\n+                    ArrayList<String> viewIndexes = findViewIndexes(conn, schemaName, viewName,\n+                           tenantId);\n+                    for (String viewIndex : viewIndexes) {\n+                        IndexInfo indexInfo = new IndexInfo(schemaName, viewName,\n+                               tenantId == null ? GLOBAL_INDEX_ID : tenantId, viewIndex);\n+                        rebuildIndexes.put(viewIndex, indexInfo);\n+                    }\n                 }\n             }\n-            //for rebuilding indexes in case of upgrade.\n-            rebuildMap.put(dataTableFullName, rebuildIndexes);\n+            //for rebuilding indexes in case of upgrade and if there are indexes on the table/view.\n+            if (!rebuildIndexes.isEmpty()) {\n+                rebuildMap.put(dataTableFullName, rebuildIndexes);\n+                String json = gson.toJson(rebuildMap);\n+                LOGGER.info(\"Index rebuild map \" + json);\n+            } else {\n+                LOGGER.info(\"No indexes to rebuild for table \" + dataTableFullName);\n+            }\n+\n         } catch (SQLException e) {\n-            LOGGER.severe(\"Failed to prepare the map for index rebuilds \"+e);\n+            LOGGER.severe(\"Failed to prepare the map for index rebuilds \" + e);\n             throw new RuntimeException(\"Failed to prepare the map for index rebuilds\");\n         }\n     }\n \n+    private ArrayList<String> findViewIndexes(Connection conn, String schemaName, String viewName,\n+            String tenantId) throws SQLException {\n+\n+        String viewIndexesSql = \"SELECT DISTINCT COLUMN_FAMILY FROM \"\n+                + \"SYSTEM.CATALOG \"\n+                + \"WHERE TABLE_NAME = \\'\" + viewName + \"\\'\"\n+                + (!StringUtil.EMPTY_STRING.equals(schemaName) ? \"AND TABLE_SCHEM = \\'\"\n+                + schemaName + \"\\' \" : \"\")\n+                + \"AND LINK_TYPE = \" + PTable.LinkType.INDEX_TABLE.getSerializedValue()\n+                + (tenantId != null ? \" AND TENANT_ID = \\'\" + tenantId + \"\\'\" : \"\");\n+        ArrayList<String> viewIndexes = new ArrayList<>();\n+        ResultSet\n+                rs =\n+                conn.createStatement().executeQuery(viewIndexesSql);\n+        while(rs.next()) {\n+            String viewIndexName = rs.getString(1);\n+            viewIndexes.add(viewIndexName);\n+        }\n+        return viewIndexes;\n+    }\n+\n     private class IndexInfo {\n         final private String schemaName;\n         final private String baseTable;\n@@ -635,4 +665,9 @@ public String getIndexName() {\n             return indexName;\n         }\n     }\n+\n+    public static void main (String[] args) throws Exception {\n+        int result = ToolRunner.run(new IndexUpgradeTool(), args);\n+        System.exit(result);\n+    }\n }",
                "deletions": 53
            }
        ],
        "patched_files": [
            "IndexUpgradeTool.java"
        ],
        "unit_tests": [
            "IndexUpgradeToolTest.java"
        ]
    },
    "phoenix_54b3ef9": {
        "repo": "phoenix",
        "message": "PHOENIX-1474 NPE when RVC between combined with key part comparison",
        "commit": "https://github.com/apache/phoenix/commit/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee",
        "parent": "https://github.com/apache/phoenix/commit/0398178617cb2aeac3661510395635b9d00f814d",
        "bug_id": "phoenix_54b3ef9",
        "file": [
            {
                "sha": "8d67fa41aaab932491017ca9e9de23d2fbee7489",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "status": "modified",
                "changes": 15,
                "additions": 15,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java?ref=54b3ef98dd7a375c31e65873f8fb7eafc39f82ee",
                "patch": "@@ -1311,6 +1311,21 @@ public void testComparisonAgainstRVCCombinedWithOrAnd_1() throws Exception {\n         assertEquals(\"helo3\", rs.getString(1));\n         assertEquals(3, rs.getInt(2));\n         assertFalse(rs.next());\n+        \n+        stmt = conn.prepareStatement(\"select pk2, pk3 from RVC1 WHERE tenantId = ? AND (tenantId, pk2, pk3) BETWEEN (?, ?, ?) AND (?, ?, ?) LIMIT 100\");\n+        stmt.setString(1, \"ABC\");\n+        stmt.setString(2, \"ABC\");\n+        stmt.setString(3, \"helo2\");\n+        stmt.setInt(4, 2);\n+        stmt.setString(5, \"DEF\");\n+        stmt.setString(6, \"helo3\");\n+        stmt.setInt(7, 3);\n+        \n+        rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo2\", rs.getString(1));\n+        assertEquals(2, rs.getInt(2));\n+        assertFalse(rs.next());\n     }\n     \n     // query against tenant specific view. Salted base table.",
                "deletions": 0
            },
            {
                "sha": "f70ba21eda1e6aa756baf1bbcdf3dd2cecdfede8",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "blob_url": "https://github.com/apache/phoenix/blob/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "raw_url": "https://github.com/apache/phoenix/raw/54b3ef98dd7a375c31e65873f8fb7eafc39f82ee/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "status": "modified",
                "changes": 4,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=54b3ef98dd7a375c31e65873f8fb7eafc39f82ee",
                "patch": "@@ -643,7 +643,9 @@ private KeySlots andKeySlots(AndExpression andExpression, List<KeySlots> childSl\n                     // with our minMaxRange, since it spans columns and this would mess up our skip scan.\n                     minMaxRange = minMaxRange.intersect(childSlot.getMinMaxRange());\n                     for (KeySlot slot : childSlot) {\n-                        minMaxExtractNodes.addAll(slot.getKeyPart().getExtractNodes());\n+                        if (slot != null) {\n+                    \t    minMaxExtractNodes.addAll(slot.getKeyPart().getExtractNodes());\n+                        }\n                     }\n                 } else {\n                     for (KeySlot slot : childSlot) {",
                "deletions": 1
            }
        ],
        "patched_files": [
            "WhereOptimizer.java"
        ],
        "unit_tests": [
            "WhereOptimizerTest.java"
        ]
    },
    "phoenix_dd97d44": {
        "repo": "phoenix",
        "message": "PHOENIX-1131 Fix NPE in PhoenixRuntime.encodePk padding of row key values to max column length",
        "commit": "https://github.com/apache/phoenix/commit/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113",
        "parent": "https://github.com/apache/phoenix/commit/eeac05afa257a7e733298a5680efede4abcd5355",
        "bug_id": "phoenix_dd97d44",
        "file": [
            {
                "sha": "c2fcbf0006ba4537a65b9d6d1119f0fc029f9e09",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java",
                "blob_url": "https://github.com/apache/phoenix/blob/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java",
                "raw_url": "https://github.com/apache/phoenix/raw/dd97d44e779bc34c1edfb2bb3fd6dd91514d0113/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PDataType.java?ref=dd97d44e779bc34c1edfb2bb3fd6dd91514d0113",
                "patch": "@@ -180,7 +180,7 @@ public String toStringLiteral(byte[] b, int offset, int length, Format formatter\n      */\n     CHAR(\"CHAR\", Types.CHAR, String.class, null) { // Delegate to VARCHAR\n         @Override\n-        public Object pad(Object object, int maxLength) {\n+        public Object pad(Object object, Integer maxLength) {\n             String s = (String) object;\n             if (s == null) {\n                 return s;\n@@ -3124,7 +3124,7 @@ public String toStringLiteral(byte[] b, int o, int length, Format formatter) {\n     },\n     BINARY(\"BINARY\", Types.BINARY, byte[].class, null) {\n         @Override\n-        public Object pad(Object object, int maxLength) {\n+        public Object pad(Object object, Integer maxLength) {\n             byte[] b = (byte[]) object;\n             if (b == null) {\n                 return null;\n@@ -7132,7 +7132,7 @@ public long getMillis(ImmutableBytesWritable ptr, SortOrder sortOrder) {\n         throw new UnsupportedOperationException(\"Operation not supported for type \" + this);\n     }\n \n-    public Object pad(Object object, int maxLength) {\n+    public Object pad(Object object, Integer maxLength) {\n         return object;\n     }\n     ",
                "deletions": 3
            }
        ],
        "patched_files": [
            "PDataType.java"
        ],
        "unit_tests": [
            "PDataTypeTest.java"
        ]
    },
    "phoenix_31bd423": {
        "repo": "phoenix",
        "message": "PHOENIX-1397 RVC combined with OR on first row key column results in NPE (Samarth Jain)",
        "commit": "https://github.com/apache/phoenix/commit/31bd42301cad35f0e1f0b0e363dcf13726d84fd1",
        "parent": "https://github.com/apache/phoenix/commit/880fd9f9447da2bf435af2031c9468797558bb79",
        "bug_id": "phoenix_31bd423",
        "file": [
            {
                "sha": "9e3a5b07c9393efd0af2ce1ceb35f298e462fc27",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java",
                "status": "modified",
                "changes": 69,
                "additions": 69,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/RowValueConstructorIT.java?ref=31bd42301cad35f0e1f0b0e363dcf13726d84fd1",
                "patch": "@@ -1280,5 +1280,74 @@ public void testForceSkipScan() throws Exception {\n             conn.close();\n         }\n     }\n+    \n+    // query against non-multitenant table. Salted - yes \n+    @Test\n+    public void testComparisonAgainstRVCCombinedWithOrAnd_1() throws Exception {\n+    \tString tableDDL = \"CREATE TABLE RVC1 (tenantId char(15) NOT NULL, pk2 char(15) NOT NULL, pk3 INTEGER NOT NULL, c1 INTEGER constraint pk primary key (tenantId,pk2,pk3)) SALT_BUCKETS = 4\";\n+        createTestTable(getUrl(), tableDDL, null, nextTimestamp());\n+\n+        Connection conn = nextConnection(getUrl());\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('ABC', 'helo1', 1, 1)\");\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('ABC', 'helo2', 2, 2)\");\n+        conn.createStatement().executeUpdate(\"upsert into RVC1 (tenantId, pk2, pk3, c1) values ('DEF', 'helo3', 3, 3)\");\n+        conn.commit();\n+        conn.close();\n+\n+        conn = nextConnection(getUrl());\n+        PreparedStatement stmt = conn.prepareStatement(\"select pk2, pk3 from RVC1 WHERE (tenantId = ? OR tenantId = ?) AND (tenantId, pk2, pk3) > (?, ?, ?) LIMIT 100\");\n+        stmt.setString(1, \"ABC\");\n+        stmt.setString(2, \"DEF\");\n+        \n+        // give back all rows after row 1 - ABC|helo1|1\n+        stmt.setString(3, \"ABC\");\n+        stmt.setString(4, \"helo1\");\n+        stmt.setInt(5, 1);\n+        \n+        ResultSet rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo2\", rs.getString(1));\n+        assertEquals(2, rs.getInt(2));\n+        assertTrue(rs.next());\n+        assertEquals(\"helo3\", rs.getString(1));\n+        assertEquals(3, rs.getInt(2));\n+        assertFalse(rs.next());\n+    }\n+    \n+    // query against tenant specific view. Salted base table.\n+    @Test\n+    public void testComparisonAgainstRVCCombinedWithOrAnd_2() throws Exception {\n+        String tenantId = \"ABC\";\n+        String tenantSpecificUrl = getUrl() + \";\" + PhoenixRuntime.TENANT_ID_ATTRIB + '=' + tenantId;\n+        String baseTableDDL = \"CREATE TABLE RVC2 (tenant_id char(15) NOT NULL, pk2 char(15) NOT NULL, pk3 INTEGER NOT NULL, c1 INTEGER constraint pk primary key (tenant_id,pk2,pk3)) MULTI_TENANT=true, SALT_BUCKETS = 4\";\n+        createTestTable(getUrl(), baseTableDDL, null, nextTimestamp());\n+        String tenantTableDDL = \"CREATE VIEW t_view AS SELECT * FROM RVC2\";\n+        createTestTable(tenantSpecificUrl, tenantTableDDL, null, nextTimestamp());\n+\n+        Connection conn = nextConnection(tenantSpecificUrl);\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo1', 1, 1)\");\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo2', 2, 2)\");\n+        conn.createStatement().executeUpdate(\"upsert into t_view (pk2, pk3, c1) values ('helo3', 3, 3)\");\n+        conn.commit();\n+        conn.close();\n+\n+        conn = nextConnection(tenantSpecificUrl);\n+        PreparedStatement stmt = conn.prepareStatement(\"select pk2, pk3 from t_view WHERE (pk2 = ? OR pk2 = ?) AND (pk2, pk3) > (?, ?) LIMIT 100\");\n+        stmt.setString(1, \"helo1\");\n+        stmt.setString(2, \"helo3\");\n+        \n+        // return rows after helo1|1 \n+        stmt.setString(3, \"helo1\");\n+        stmt.setInt(4, 1);\n+\n+        ResultSet rs = stmt.executeQuery();\n+        assertTrue(rs.next());\n+        assertEquals(\"helo3\", rs.getString(1));\n+        assertEquals(3, rs.getInt(2));\n+        assertFalse(rs.next());\n+        conn.close();\n+    }\n+\n+\n \n }",
                "deletions": 0
            },
            {
                "sha": "6a46a7b4a4fb0c87a6948b72267d58360214a0ee",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "blob_url": "https://github.com/apache/phoenix/blob/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "raw_url": "https://github.com/apache/phoenix/raw/31bd42301cad35f0e1f0b0e363dcf13726d84fd1/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "status": "modified",
                "changes": 21,
                "additions": 13,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=31bd42301cad35f0e1f0b0e363dcf13726d84fd1",
                "patch": "@@ -105,6 +105,14 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             Expression whereClause, Set<Expression> extractNodes) {\n         PName tenantId = context.getConnection().getTenantId();\n         PTable table = context.getCurrentTable().getTable();\n+    \tInteger nBuckets = table.getBucketNum();\n+    \tboolean isSalted = nBuckets != null;\n+    \tRowKeySchema schema = table.getRowKeySchema();\n+    \tboolean isMultiTenant = tenantId != null && table.isMultiTenant();\n+    \tif (isMultiTenant) {\n+    \t\ttenantId = ScanUtil.padTenantIdIfNecessary(schema, isSalted, tenantId);\n+    \t}\n+\n         if (whereClause == null && (tenantId == null || !table.isMultiTenant()) && table.getViewIndexId() == null) {\n             context.setScanRanges(ScanRanges.EVERYTHING);\n             return whereClause;\n@@ -145,8 +153,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         int nPKColumns = table.getPKColumns().size();\n         int[] slotSpan = new int[nPKColumns];\n         List<Expression> removeFromExtractNodes = null;\n-        Integer nBuckets = table.getBucketNum();\n-        RowKeySchema schema = table.getRowKeySchema();\n         List<List<KeyRange>> cnf = Lists.newArrayListWithExpectedSize(schema.getMaxFields());\n         KeyRange minMaxRange = keySlots.getMinMaxRange();\n         if (minMaxRange == null) {\n@@ -155,8 +161,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         boolean hasMinMaxRange = (minMaxRange != KeyRange.EVERYTHING_RANGE);\n         int minMaxRangeOffset = 0;\n         byte[] minMaxRangePrefix = null;\n-        boolean isSalted = nBuckets != null;\n-        boolean isMultiTenant = tenantId != null && table.isMultiTenant();\n         boolean hasViewIndex = table.getViewIndexId() != null;\n         if (hasMinMaxRange) {\n             int minMaxRangeSize = (isSalted ? SaltingUtil.NUM_SALTING_BYTES : 0)\n@@ -181,7 +185,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n         \n         // Add tenant data isolation for tenant-specific tables\n         if (isMultiTenant) {\n-            tenantId = ScanUtil.padTenantIdIfNecessary(schema, isSalted, tenantId);\n             byte[] tenantIdBytes = tenantId.getBytes();\n             KeyRange tenantIdKeyRange = KeyRange.getKeyRange(tenantIdBytes);\n             cnf.add(singletonList(tenantIdKeyRange));\n@@ -703,9 +706,11 @@ private KeySlots orKeySlots(OrExpression orExpression, List<KeySlots> childSlots\n                     minMaxRange = minMaxRange.union(childSlot.getMinMaxRange());\n                     thePosition = initialPos;\n                     for (KeySlot slot : childSlot) {\n-                        List<Expression> extractNodes = slot.getKeyPart().getExtractNodes();\n-                        extractAll &= !extractNodes.isEmpty();\n-                        slotExtractNodes.addAll(extractNodes);\n+                    \tif (slot != null) {\n+                    \t\tList<Expression> extractNodes = slot.getKeyPart().getExtractNodes();\n+                    \t\textractAll &= !extractNodes.isEmpty();\n+                    \t\tslotExtractNodes.addAll(extractNodes);\n+                    \t}\n                     }\n                 } else {\n                     // TODO: Do the same optimization that we do for IN if the childSlots specify a fully qualified row key",
                "deletions": 8
            }
        ],
        "patched_files": [
            "WhereOptimizer.java"
        ],
        "unit_tests": [
            "WhereOptimizerTest.java"
        ]
    },
    "phoenix_b355c2a": {
        "repo": "phoenix",
        "message": "PHOENIX-106 NPE when adding dynamic columns to a salted table (JamesTaylor)",
        "commit": "https://github.com/apache/phoenix/commit/b355c2a08f92763f1d7272f2a2300e024e70d756",
        "parent": "https://github.com/apache/phoenix/commit/7b7ad1c1b8432c067754e94ff73d8ed2124999b8",
        "bug_id": "phoenix_b355c2a",
        "file": [
            {
                "sha": "a987798f2065b5483cdcb31d13ac2036f477f92f",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java",
                "status": "modified",
                "changes": 7,
                "additions": 5,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/FromCompiler.java?ref=b355c2a08f92763f1d7272f2a2300e024e70d756",
                "patch": "@@ -312,8 +312,11 @@ protected PTable addDynamicColumns(List<ColumnDef> dynColumns, PTable theTable)\n                 throws SQLException {\n             if (!dynColumns.isEmpty()) {\n                 List<PColumn> allcolumns = new ArrayList<PColumn>();\n-                allcolumns.addAll(theTable.getColumns());\n-                int position = allcolumns.size();\n+                List<PColumn> existingColumns = theTable.getColumns();\n+                // Need to skip the salting column, as it's added in the makePTable call below\n+                allcolumns.addAll(theTable.getBucketNum() == null ? existingColumns : existingColumns.subList(1, existingColumns.size()));\n+                // Position still based on with the salting columns\n+                int position = existingColumns.size();\n                 PName defaultFamilyName = PNameFactory.newName(SchemaUtil.getEmptyColumnFamily(theTable));\n                 for (ColumnDef dynColumn : dynColumns) {\n                     PName familyName = defaultFamilyName;",
                "deletions": 2
            },
            {
                "sha": "ef68847e0f2bc257555f9f479b2efb1c9fa67a22",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/b355c2a08f92763f1d7272f2a2300e024e70d756/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java",
                "status": "modified",
                "changes": 49,
                "additions": 49,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/end2end/UpsertSelectAutoCommitTest.java?ref=b355c2a08f92763f1d7272f2a2300e024e70d756",
                "patch": "@@ -25,6 +25,7 @@\n import static org.junit.Assert.assertTrue;\n \n import java.sql.Connection;\n+import java.sql.Date;\n import java.sql.DriverManager;\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n@@ -83,4 +84,52 @@ public void testAutoCommitUpsertSelect() throws Exception {\n         assertFalse(rs.next());\n         \n     }\n+\n+    @Test\n+    public void testDynamicUpsertSelect() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        String cursorDDL = \" CREATE TABLE IF NOT EXISTS CURSOR (ORGANIZATION_ID VARCHAR(15) NOT NULL, \\n\"\n+                + \"QUERY_ID VARCHAR(15) NOT NULL, \\n\"\n+                + \"CURSOR_ORDER UNSIGNED_LONG NOT NULL, \\n\"\n+                + \"CONSTRAINT API_HBASE_CURSOR_STORAGE_PK PRIMARY KEY (ORGANIZATION_ID, QUERY_ID, CURSOR_ORDER))\\n\"\n+                + \"SALT_BUCKETS = 4\";\n+        conn.createStatement().execute(cursorDDL);\n+        \n+        String dataTableDDL = \"CREATE TABLE IF NOT EXISTS PLINYTEST\" +\n+                \"(\" +\n+                \"ORGANIZATION_ID CHAR(15) NOT NULL, \" +\n+                \"PLINY_ID CHAR(15) NOT NULL, \" +\n+                \"CREATED_DATE DATE NOT NULL, \" + \n+                \"TEXT VARCHAR, \" +\n+                \"CONSTRAINT PK PRIMARY KEY \" +\n+                \"(\" +\n+                \"ORGANIZATION_ID, \" +\n+                \"PLINY_ID, \"  +\n+                \"CREATED_DATE\" +\n+                \")\" +\n+                \")\";\n+        \n+        conn.createStatement().execute(dataTableDDL);\n+        PreparedStatement stmt = null;\n+        String upsert = \"UPSERT INTO PLINYTEST VALUES (?, ?, ?, ?)\";\n+        stmt = conn.prepareStatement(upsert);\n+        stmt.setString(1, getOrganizationId());\n+        stmt.setString(2, \"aaaaaaaaaaaaaaa\");\n+        stmt.setDate(3, new Date(System.currentTimeMillis()));\n+        stmt.setString(4, \"text\");\n+        stmt.executeUpdate();\n+        conn.commit();\n+        \n+        String upsertSelect = \"UPSERT INTO CURSOR (ORGANIZATION_ID, QUERY_ID, CURSOR_ORDER, PLINY_ID CHAR(15),CREATED_DATE DATE) SELECT ?, ?, ?, PLINY_ID, CREATED_DATE FROM PLINYTEST WHERE ORGANIZATION_ID = ?\";\n+        stmt = conn.prepareStatement(upsertSelect);\n+        String orgId = getOrganizationId();\n+        stmt.setString(1, orgId);\n+        stmt.setString(2, \"queryqueryquery\");\n+\n+        stmt.setInt(3, 1);\n+        stmt.setString(4, orgId);\n+        stmt.executeUpdate();\n+        conn.commit();\n+    }\n+    \n }",
                "deletions": 0
            }
        ],
        "patched_files": [
            "FromCompiler.java"
        ],
        "unit_tests": [
            "UpsertSelectAutoCommitTest.java"
        ]
    },
    "phoenix_5d1fd55": {
        "repo": "phoenix",
        "message": "PHOENIX-30 NPE on PTable.getColumn(String) if column with same name used in the PK and non PK (JamesTaylor)",
        "commit": "https://github.com/apache/phoenix/commit/5d1fd559b27ea04d677b5a77fb26ab1d685053ee",
        "parent": "https://github.com/apache/phoenix/commit/a977a7529f5c5bce9b38610cc6b0c534ee3a88d0",
        "bug_id": "phoenix_5d1fd55",
        "file": [
            {
                "sha": "f2a3e7685e12f099b01de3954756c7ce0b98610e",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java",
                "status": "modified",
                "changes": 6,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PTableImpl.java?ref=5d1fd559b27ea04d677b5a77fb26ab1d685053ee",
                "patch": "@@ -468,8 +468,10 @@ public PColumn getColumn(String name) throws ColumnNotFoundException, AmbiguousC\n         }\n         if (size > 1) {\n             for (PColumn column : columns) {\n-                if (QueryConstants.DEFAULT_COLUMN_FAMILY.equals(column.getFamilyName().getString())) {\n-                    // Allow ambiguity with default column, since a user would not know how to prefix it.\n+                if (column.getFamilyName() == null || QueryConstants.DEFAULT_COLUMN_FAMILY.equals(column.getFamilyName().getString())) {\n+                    // Allow ambiguity with PK column or column in the default column family,\n+                    // since a PK column cannot be prefixed and a user would not know how to\n+                    // prefix a column in the default column family.\n                     return column;\n                 }\n             }",
                "deletions": 2
            },
            {
                "sha": "e9c34e0005c09ffd59e2d0aa514ad6a13a9b448f",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5d1fd559b27ea04d677b5a77fb26ab1d685053ee/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java",
                "status": "modified",
                "changes": 17,
                "additions": 16,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompileTest.java?ref=5d1fd559b27ea04d677b5a77fb26ab1d685053ee",
                "patch": "@@ -23,10 +23,10 @@\n import static org.apache.phoenix.util.TestUtil.assertDegenerate;\n import static org.junit.Assert.assertArrayEquals;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertNotNull;\n import static org.junit.Assert.assertNull;\n import static org.junit.Assert.assertTrue;\n-import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.fail;\n \n import java.sql.Connection;\n@@ -45,12 +45,14 @@\n import org.apache.phoenix.expression.aggregator.CountAggregator;\n import org.apache.phoenix.expression.aggregator.ServerAggregators;\n import org.apache.phoenix.expression.function.TimeUnit;\n+import org.apache.phoenix.jdbc.PhoenixConnection;\n import org.apache.phoenix.jdbc.PhoenixPreparedStatement;\n import org.apache.phoenix.query.BaseConnectionlessQueryTest;\n import org.apache.phoenix.query.QueryConstants;\n import org.apache.phoenix.schema.AmbiguousColumnException;\n import org.apache.phoenix.schema.ColumnAlreadyExistsException;\n import org.apache.phoenix.schema.ColumnNotFoundException;\n+import org.apache.phoenix.schema.PColumn;\n import org.apache.phoenix.util.ByteUtil;\n import org.apache.phoenix.util.PhoenixRuntime;\n import org.apache.phoenix.util.SchemaUtil;\n@@ -138,6 +140,19 @@ public void testFamilyNameInPK() throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testSameColumnNameInPKAndNonPK() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        try {\n+            String query = \"CREATE TABLE t1 (k integer not null primary key, a.k decimal, b.k decimal)\";\n+            conn.createStatement().execute(query);\n+            PColumn c = conn.unwrap(PhoenixConnection.class).getPMetaData().getTable(\"T1\").getColumn(\"K\");\n+            assertTrue(SchemaUtil.isPKColumn(c));\n+        } finally {\n+            conn.close();\n+        }\n+    }\n+\n     @Test\n     public void testVarBinaryInMultipartPK() throws Exception {\n         Connection conn = DriverManager.getConnection(getUrl());",
                "deletions": 1
            }
        ],
        "patched_files": [
            "PTableImpl.java"
        ],
        "unit_tests": [
            "QueryCompileTest.java"
        ]
    },
    "phoenix_dc3083f": {
        "repo": "phoenix",
        "message": "PHOENIX-2016 Some Phoenix tests failed with NPE(Alicia Ying Shu)",
        "commit": "https://github.com/apache/phoenix/commit/dc3083fec11720a3b92f3edf98a679406004550f",
        "parent": "https://github.com/apache/phoenix/commit/82df3b97a9ca88605f78b59e547819ff3bf9cd7a",
        "bug_id": "phoenix_dc3083f",
        "file": [
            {
                "sha": "fa78656ae3f0f3ef9d5fe63c55cb45dacdaa4755",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/dc3083fec11720a3b92f3edf98a679406004550f/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/dc3083fec11720a3b92f3edf98a679406004550f/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java",
                "status": "modified",
                "changes": 1,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/query/BaseTest.java?ref=dc3083fec11720a3b92f3edf98a679406004550f",
                "patch": "@@ -1627,6 +1627,7 @@ protected static void initJoinTableValues(String url, byte[][] splits, Long ts)\n      * Disable and drop all the tables except SYSTEM.CATALOG and SYSTEM.SEQUENCE\n      */\n     private static void disableAndDropNonSystemTables() throws Exception {\n+        if (driver == null) return;\n         HBaseAdmin admin = driver.getConnectionQueryServices(null, null).getAdmin();\n         try {\n             HTableDescriptor[] tables = admin.listTables();",
                "deletions": 0
            }
        ],
        "patched_files": [],
        "unit_tests": [
            "BaseTest.java"
        ]
    },
    "phoenix_cd444d9": {
        "repo": "phoenix",
        "message": "PHOENIX-3765 NPE in IndexMaintainer when using old client and 4.10 server",
        "commit": "https://github.com/apache/phoenix/commit/cd444d9a6a8e560889826bc491db7d71ad1960e5",
        "parent": "https://github.com/apache/phoenix/commit/92e728e09ace5dfac93cd04a747f3db8043569ee",
        "bug_id": "phoenix_cd444d9",
        "file": [
            {
                "sha": "26c24217c1f50b5a677c05900a145c749b06edae",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "blob_url": "https://github.com/apache/phoenix/blob/cd444d9a6a8e560889826bc491db7d71ad1960e5/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "raw_url": "https://github.com/apache/phoenix/raw/cd444d9a6a8e560889826bc491db7d71ad1960e5/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "status": "modified",
                "changes": 3,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java?ref=cd444d9a6a8e560889826bc491db7d71ad1960e5",
                "patch": "@@ -1308,6 +1308,9 @@ public PDataType getDataType() {\n         int encodedEstimatedIndexRowKeyBytesAndImmutableRows = WritableUtils.readVInt(input);\n         this.immutableRows = encodedEstimatedIndexRowKeyBytesAndImmutableRows < 0;\n         this.estimatedIndexRowKeyBytes = Math.abs(encodedEstimatedIndexRowKeyBytesAndImmutableRows);\n+        // Needed for backward compatibility. Clients older than 4.10 will have non-encoded tables.\n+        this.immutableStorageScheme = ImmutableStorageScheme.ONE_CELL_PER_COLUMN;\n+        this.encodingScheme = QualifierEncodingScheme.NON_ENCODED_QUALIFIERS;\n         initCachedState();\n     }\n     ",
                "deletions": 0
            }
        ],
        "patched_files": [
            "IndexMaintainer.java"
        ],
        "unit_tests": [
            "IndexMaintainerTest.java"
        ]
    },
    "phoenix_d762c6a": {
        "repo": "phoenix",
        "message": "PHOENIX-4072 Prevent NPE for PreparedStatement.setObject of null",
        "commit": "https://github.com/apache/phoenix/commit/d762c6a83e8260297fd8d6afcb51bc1c49dce23f",
        "parent": "https://github.com/apache/phoenix/commit/1e74895ad83dfe1ada90897f95fb5c93e2cc8eee",
        "bug_id": "phoenix_d762c6a",
        "file": [
            {
                "sha": "71ecb8d3c56d4dac7689ad101a3ca1e9007f51ed",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java",
                "blob_url": "https://github.com/apache/phoenix/blob/d762c6a83e8260297fd8d6afcb51bc1c49dce23f/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java",
                "raw_url": "https://github.com/apache/phoenix/raw/d762c6a83e8260297fd8d6afcb51bc1c49dce23f/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java",
                "status": "modified",
                "changes": 6,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixPreparedStatement.java?ref=d762c6a83e8260297fd8d6afcb51bc1c49dce23f",
                "patch": "@@ -444,8 +444,10 @@ public void setObject(int parameterIndex, Object o) throws SQLException {\n     @Override\n     public void setObject(int parameterIndex, Object o, int targetSqlType) throws SQLException {\n         PDataType targetType = PDataType.fromTypeId(targetSqlType);\n-        PDataType sourceType = PDataType.fromLiteral(o);\n-        o = targetType.toObject(o, sourceType);\n+        if (o != null) {\n+            PDataType sourceType = PDataType.fromLiteral(o);\n+            o = targetType.toObject(o, sourceType);\n+        }\n         setParameter(parameterIndex, o);\n     }\n ",
                "deletions": 2
            }
        ],
        "patched_files": [
            "PhoenixPreparedStatement.java"
        ],
        "unit_tests": [
            "PhoenixPreparedStatementTest.java"
        ]
    },
    "phoenix_0c21539": {
        "repo": "phoenix",
        "message": "PHOENIX-2658 When using QueryRunner API UNION ALL queries fail with NPE (Alicia Ying Shu)",
        "commit": "https://github.com/apache/phoenix/commit/0c21539cc331b8d6ca144604cf899068ad74fb25",
        "parent": "https://github.com/apache/phoenix/commit/18f7a69452eec7fd5fde38953510600c4a060151",
        "bug_id": "phoenix_0c21539",
        "file": [
            {
                "sha": "b391dcc1e3885ceca4ed9e83f578244ff4a39329",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java",
                "status": "modified",
                "changes": 49,
                "additions": 48,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UnionAllIT.java?ref=0c21539cc331b8d6ca144604cf899068ad74fb25",
                "patch": "@@ -40,7 +40,6 @@\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n-\n public class UnionAllIT extends BaseOwnClusterHBaseManagedTimeIT {\n \n     @BeforeClass\n@@ -679,4 +678,52 @@ public void testBug2295() throws Exception {\n             conn.close();\n         }\n     }\n+\n+    @Test\n+    public void testParameterMetaDataNotNull() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+    \n+        String ddl = \"CREATE TABLE test_table \" +\n+                \"  (a_string varchar not null, col1 integer\" +\n+                \"  CONSTRAINT pk PRIMARY KEY (a_string))\\n\";\n+        createTestTable(getUrl(), ddl);\n+        String dml = \"UPSERT INTO test_table VALUES(?, ?)\";\n+        PreparedStatement stmt = conn.prepareStatement(dml);\n+        stmt.setString(1, \"a\");\n+        stmt.setInt(2, 10);\n+        stmt.execute();\n+        conn.commit();\n+\n+        ddl = \"CREATE TABLE b_table \" +\n+                \"  (a_string varchar not null, col1 integer\" +\n+                \"  CONSTRAINT pk PRIMARY KEY (a_string))\\n\";\n+        createTestTable(getUrl(), ddl);\n+        dml = \"UPSERT INTO b_table VALUES(?, ?)\";\n+        stmt = conn.prepareStatement(dml);\n+        stmt.setString(1, \"b\");\n+        stmt.setInt(2, 20);\n+        stmt.execute();\n+        conn.commit();\n+\n+        String query = \"select * from test_table union all select * from b_table\";\n+\n+        try{\n+            PreparedStatement pstmt = conn.prepareStatement(query);\n+            assertTrue(pstmt.getParameterMetaData() != null);\n+            ResultSet rs = pstmt.executeQuery();\n+            assertTrue(rs.next());\n+            assertEquals(\"a\",rs.getString(1));\n+            assertEquals(10,rs.getInt(2));\n+            assertTrue(rs.next());\n+            assertEquals(\"b\",rs.getString(1));\n+            assertEquals(20,rs.getInt(2));\n+            assertFalse(rs.next()); \n+        } catch (Exception ex) {\n+            ex.printStackTrace();\n+        } finally {\n+            conn.close();\n+        }\n+    } \n+\n }",
                "deletions": 1
            },
            {
                "sha": "9e756c8d009bae851d14a8c5a538b11deac009d6",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/0c21539cc331b8d6ca144604cf899068ad74fb25/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java",
                "status": "modified",
                "changes": 3,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/QueryCompiler.java?ref=0c21539cc331b8d6ca144604cf899068ad74fb25",
                "patch": "@@ -182,7 +182,8 @@ public QueryPlan compileUnionAll(SelectStatement select) throws SQLException {\n         StatementContext context = new StatementContext(statement, resolver, scan, sequenceManager);\n \n         QueryPlan plan = compileSingleFlatQuery(context, select, statement.getParameters(), false, false, null, null, false);\n-        plan =  new UnionPlan(context, select, tableRef, plan.getProjector(), plan.getLimit(), plan.getOrderBy(), GroupBy.EMPTY_GROUP_BY, plans, null); \n+        plan =  new UnionPlan(context, select, tableRef, plan.getProjector(), plan.getLimit(), plan.getOrderBy(), GroupBy.EMPTY_GROUP_BY, \n+                plans, context.getBindManager().getParameterMetaData()); \n         return plan;\n     }\n ",
                "deletions": 1
            }
        ],
        "patched_files": [
            "QueryCompiler.java"
        ],
        "unit_tests": [
            "QueryCompilerTest.java"
        ]
    },
    "phoenix_e23634a": {
        "repo": "phoenix",
        "message": "PHOENIX-3505 Avoid NPE on close() in OrderedResultIterator",
        "commit": "https://github.com/apache/phoenix/commit/e23634a358929516ce210fe06d668ce475eccccb",
        "parent": "https://github.com/apache/phoenix/commit/c5046047a78e0365d75bc696dff4870304c2b5b2",
        "bug_id": "phoenix_e23634a",
        "file": [
            {
                "sha": "da75bb7bd7cb9e5f309a231c8618a04fff851b62",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java",
                "status": "modified",
                "changes": 5,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/iterate/OrderedResultIterator.java?ref=e23634a358929516ce210fe06d668ce475eccccb",
                "patch": "@@ -279,7 +279,10 @@ public Tuple peek() throws SQLException {\n \n     @Override\n     public void close() throws SQLException {\n-        resultIterator.close();\n+        // Guard against resultIterator being null\n+        if (null != resultIterator) {\n+            resultIterator.close();\n+        }\n         resultIterator = PeekingResultIterator.EMPTY_ITERATOR;\n     }\n ",
                "deletions": 1
            },
            {
                "sha": "50ed8e9df79907c35b0fcc1847732e05b3d6f8c0",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e23634a358929516ce210fe06d668ce475eccccb/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java",
                "status": "added",
                "changes": 41,
                "additions": 41,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/iterate/OrderedResultIteratorTest.java?ref=e23634a358929516ce210fe06d668ce475eccccb",
                "patch": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.iterate;\n+\n+import java.sql.SQLException;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.phoenix.expression.OrderByExpression;\n+import org.junit.Test;\n+\n+/**\n+ * Test class for {@link OrderedResultIterator}.\n+ */\n+public class OrderedResultIteratorTest {\n+\n+  @Test\n+  public void testNullIteratorOnClose() throws SQLException {\n+      ResultIterator delegate =  ResultIterator.EMPTY_ITERATOR;\n+      List<OrderByExpression> orderByExpressions = Collections.singletonList(null);\n+      int thresholdBytes = Integer.MAX_VALUE;\n+      OrderedResultIterator iterator = new OrderedResultIterator(delegate, orderByExpressions, thresholdBytes);\n+      // Should not throw an exception\n+      iterator.close();\n+  }\n+\n+}",
                "deletions": 0
            }
        ],
        "patched_files": [
            "OrderedResultIterator.java"
        ],
        "unit_tests": [
            "OrderedResultIteratorTest.java"
        ]
    },
    "phoenix_00ee941": {
        "repo": "phoenix",
        "message": "PHOENIX-2402 NPE when using UPSERT SELECT with a char array (Julian Jaffe)",
        "commit": "https://github.com/apache/phoenix/commit/00ee9415a95668c34e95b43003354fc898f6b4ea",
        "parent": "https://github.com/apache/phoenix/commit/49be33e71b592e330f1304cfa20bbffc8bd18637",
        "bug_id": "phoenix_00ee941",
        "file": [
            {
                "sha": "689562af42c48c1050fc2d05fd849e59b52d57a8",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "status": "modified",
                "changes": 55,
                "additions": 55,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea",
                "patch": "@@ -1318,6 +1318,61 @@ public void testDisallowNegativeValuesForRowTsColumn() throws Exception {\n         }\n     }\n     \n+    @Test\n+    public void testUpsertSelectWithFixedWidthNullByteSizeArray() throws Exception {\n+        long ts = nextTimestamp();\n+        Properties props = new Properties();\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"create table t1 (id bigint not null primary key, ca char(3)[])\");\n+        conn.close();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 10));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\"upsert into t1 values (1, ARRAY['aaa', 'bbb'])\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 15));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"upsert into t1(id, ca) select id, ARRAY['ccc', 'ddd'] from t1 WHERE id = 1\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 20));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        ResultSet rs = conn.createStatement().executeQuery(\"select * from t1\");\n+\n+        assertTrue(rs.next());\n+        assertEquals(1, rs.getLong(1));\n+        assertEquals(\"['ccc', 'ddd']\", rs.getArray(2).toString());\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 25));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"create table t2 (id bigint not null primary key, ba binary(4)[])\");\n+        conn.close();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 30));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\"upsert into t2 values (2, ARRAY[1, 27])\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 35));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        conn.createStatement().execute(\n+                \"upsert into t2(id, ba) select id, ARRAY[54, 1024] from t2 WHERE id = 2\");\n+        conn.commit();\n+\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts + 40));\n+        conn = DriverManager.getConnection(getUrl(), props);\n+        rs = conn.createStatement().executeQuery(\"select * from t2\");\n+\n+        assertTrue(rs.next());\n+        assertEquals(2, rs.getLong(1));\n+        assertEquals(\"[[128,0,0,54], [128,0,4,0]]\", rs.getArray(2).toString());\n+    }\n+\n     private static Connection getConnection(long ts) throws SQLException {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));",
                "deletions": 0
            },
            {
                "sha": "7cc2e6638782e89bf6c346a8abbc93dcef155ea3",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "status": "modified",
                "changes": 4,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea",
                "patch": "@@ -78,12 +78,12 @@\n import org.apache.phoenix.schema.PDatum;\n import org.apache.phoenix.schema.PName;\n import org.apache.phoenix.schema.PTable;\n-import org.apache.phoenix.schema.TableNotFoundException;\n import org.apache.phoenix.schema.PTable.IndexType;\n import org.apache.phoenix.schema.PTable.ViewType;\n import org.apache.phoenix.schema.PTableKey;\n import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.schema.RowKeySchema;\n+import org.apache.phoenix.schema.TableNotFoundException;\n import org.apache.phoenix.schema.TableRef;\n import org.apache.phoenix.schema.ValueBitSet;\n import org.apache.phoenix.schema.tuple.Tuple;\n@@ -323,7 +323,7 @@ private static Expression coerceIfNecessary(int index, List<? extends PDatum> ta\n                 if (expression.getDataType() != null && !expression.getDataType().isCastableTo(targetType)) {\n                     throw new ArgumentTypeMismatchException(targetType, expression.getDataType(), \"column: \" + targetColumn);\n                 }\n-                expression = CoerceExpression.create(expression, targetType);\n+                expression = CoerceExpression.create(expression, targetType, targetColumn.getSortOrder(), targetColumn.getMaxLength());\n             }\n         }\n         return expression;",
                "deletions": 2
            },
            {
                "sha": "c31cb0a4df1cabbe1fdf7ae7aa27efd2d446771b",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java",
                "blob_url": "https://github.com/apache/phoenix/blob/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java",
                "raw_url": "https://github.com/apache/phoenix/raw/00ee9415a95668c34e95b43003354fc898f6b4ea/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java",
                "status": "modified",
                "changes": 8,
                "additions": 7,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/CoerceExpression.java?ref=00ee9415a95668c34e95b43003354fc898f6b4ea",
                "patch": "@@ -50,8 +50,14 @@ public static Expression create(Expression expression, PDataType toType) throws\n         return new CoerceExpression(expression, toType);\n     }\n     \n+    public static Expression create(Expression expression, PDataType toType, SortOrder toSortOrder, Integer maxLength) throws SQLException {\n+        return create(expression, toType, toSortOrder, maxLength, true);\n+    }\n+    \n     public static Expression create(Expression expression, PDataType toType, SortOrder toSortOrder, Integer maxLength, boolean rowKeyOrderOptimizable) throws SQLException {\n-        if (toType == expression.getDataType() && toSortOrder == expression.getSortOrder()) {\n+        if (    toType == expression.getDataType() && \n+                toSortOrder == expression.getSortOrder() && \n+                (maxLength == null || maxLength.equals(expression.getMaxLength()))   ) {\n             return expression;\n         }\n         return new CoerceExpression(expression, toType, toSortOrder, maxLength, rowKeyOrderOptimizable);",
                "deletions": 1
            }
        ],
        "patched_files": [
            "CoerceExpression.java"
        ],
        "unit_tests": [
            "CoerceExpressionTest.java"
        ]
    },
    "phoenix_21c12b1": {
        "repo": "phoenix",
        "message": "PHOENIX-2425 Invalid sql syntax produces NPE instead of meaningful error message",
        "commit": "https://github.com/apache/phoenix/commit/21c12b11b1bc1b18ac667666dd715ed91d48ed4f",
        "parent": "https://github.com/apache/phoenix/commit/27a152eb03279cd30e6a633d5adbe06363c696a6",
        "bug_id": "phoenix_21c12b1",
        "file": [
            {
                "sha": "e4770096d1deee70fc14fdfcdd1ea2ad6f281aea",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java",
                "status": "modified",
                "changes": 6,
                "additions": 6,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ProjectionCompiler.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f",
                "patch": "@@ -364,6 +364,9 @@ public static RowProjector compile(StatementContext context, SelectStatement sta\n                 if (statement.isAggregate()) {\n                     ExpressionCompiler.throwNonAggExpressionInAggException(node.toString());\n                 }\n+                if (tableRef == TableRef.EMPTY_TABLE_REF) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT).build().buildException();\n+                }\n                 isWildcard = true;\n                 if (tableRef.getTable().getType() == PTableType.INDEX && ((WildcardParseNode)node).isRewrite()) {\n                 \tprojectAllIndexColumns(context, tableRef, resolveColumn, projectedExpressions, projectedColumns, targetColumns);\n@@ -382,6 +385,9 @@ public static RowProjector compile(StatementContext context, SelectStatement sta\n                     projectAllTableColumns(context, tRef, true, projectedExpressions, projectedColumns, targetColumns);\n                 }                \n             } else if (node instanceof  FamilyWildcardParseNode){\n+                if (tableRef == TableRef.EMPTY_TABLE_REF) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT).build().buildException();\n+                }\n                 // Project everything for SELECT cf.*\n                 String cfName = ((FamilyWildcardParseNode) node).getName();\n                 // Delay projecting to scan, as when any other column in the column family gets",
                "deletions": 0
            },
            {
                "sha": "bb76ccb4dfcc34d68e1ea5e8ee5c017a12890cae",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "status": "modified",
                "changes": 1,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f",
                "patch": "@@ -226,6 +226,7 @@ public SQLException newException(SQLExceptionInfo info) {\n     AGGREGATE_WITH_NOT_GROUP_BY_COLUMN(1018, \"42Y27\", \"Aggregate may not contain columns not in GROUP BY.\"),\n     ONLY_AGGREGATE_IN_HAVING_CLAUSE(1019, \"42Y26\", \"Only aggregate maybe used in the HAVING clause.\"),\n     UPSERT_COLUMN_NUMBERS_MISMATCH(1020, \"42Y60\", \"Number of columns upserting must match number of values.\"),\n+    NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT(1057, \"42Y10\", \"No table specified for wildcard select.\"),\n     // Table properties exception.\n     INVALID_BUCKET_NUM(1021, \"42Y80\", \"Salt bucket numbers should be with 1 and 256.\"),\n     NO_SPLITS_ON_SALTED_TABLE(1022, \"42Y81\", \"Should not specify split points on salted table with default row key order.\"),",
                "deletions": 0
            },
            {
                "sha": "23eb147107c50dea9e169bc2fe5c5118b2100a12",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/21c12b11b1bc1b18ac667666dd715ed91d48ed4f/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java",
                "status": "modified",
                "changes": 24,
                "additions": 21,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryCompilerTest.java?ref=21c12b11b1bc1b18ac667666dd715ed91d48ed4f",
                "patch": "@@ -1985,9 +1985,27 @@ public void testNoFromClauseSelect() throws Exception {\n      public void testFailNoFromClauseSelect() throws Exception {\n          Connection conn = DriverManager.getConnection(getUrl());\n          try {\n-             conn.createStatement().executeQuery(\"SELECT foo, bar\");\n-             fail(\"Should have got ColumnNotFoundException\");\n-         } catch (ColumnNotFoundException e) {            \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT foo, bar\");\n+                 fail(\"Should have got ColumnNotFoundException\");\n+             } catch (ColumnNotFoundException e) {            \n+             }\n+             \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT *\");\n+                 fail(\"Should have got SQLException\");\n+             } catch (SQLException e) {\n+                 assertEquals(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT.getErrorCode(), e.getErrorCode());\n+             }\n+             \n+             try {\n+                 conn.createStatement().executeQuery(\"SELECT A.*\");\n+                 fail(\"Should have got SQLException\");\n+             } catch (SQLException e) {\n+                 assertEquals(SQLExceptionCode.NO_TABLE_SPECIFIED_FOR_WILDCARD_SELECT.getErrorCode(), e.getErrorCode());\n+             }\n+         } finally {\n+             conn.close();\n          }\n      }\n ",
                "deletions": 3
            }
        ],
        "patched_files": [
            "ProjectionCompiler.java",
            "SQLExceptionCode.java",
            "QueryCompiler.java"
        ],
        "unit_tests": [
            "QueryCompilerTest.java"
        ]
    },
    "phoenix_41c16a0": {
        "repo": "phoenix",
        "message": "PHOENIX-3386 PhoenixStorageHandler throws NPE if local tasks executed via child\n\nSigned-off-by: Sergey Soldatov <ssa@apache.org>",
        "commit": "https://github.com/apache/phoenix/commit/41c16a020fcd1cb143675ea17e2d9d3a56750a8a",
        "parent": "https://github.com/apache/phoenix/commit/c83d272b565447d39c42a4a8d3b0687bb2b5a16c",
        "bug_id": "phoenix_41c16a0",
        "file": [
            {
                "sha": "2264acd54e1ecbf43d104eeb9640e8a7eef61295",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java",
                "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java",
                "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java",
                "status": "modified",
                "changes": 2,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixConfigurationUtil.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a",
                "patch": "@@ -55,6 +55,8 @@\n public final class PhoenixConfigurationUtil {\n \n     private static final Log LOG = LogFactory.getLog(PhoenixInputFormat.class);\n+\n+    public static final String SESSION_ID = \"phoenix.sessionid\";\n     \n     public static final String UPSERT_STATEMENT = \"phoenix.upsert.stmt\";\n     ",
                "deletions": 0
            },
            {
                "sha": "bda2282e5f41d15b31b739876697537e3bd89b01",
                "filename": "phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java",
                "status": "modified",
                "changes": 4,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-hive/src/main/java/org/apache/phoenix/hive/PhoenixStorageHandler.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a",
                "patch": "@@ -31,6 +31,7 @@\n import org.apache.hadoop.hive.ql.metadata.InputEstimator;\n import org.apache.hadoop.hive.ql.plan.ExprNodeDesc;\n import org.apache.hadoop.hive.ql.plan.TableDesc;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n import org.apache.hadoop.hive.serde2.Deserializer;\n import org.apache.hadoop.hive.serde2.SerDe;\n import org.apache.hadoop.mapred.InputFormat;\n@@ -142,7 +143,10 @@ protected void configureJobProperties(TableDesc tableDesc, Map<String, String> j\n             tableProperties.setProperty(PhoenixStorageHandlerConstants.PHOENIX_TABLE_NAME,\n                     tableName);\n         }\n+        SessionState sessionState = SessionState.get();\n \n+        String sessionId = sessionState.getSessionId();\n+        jobProperties.put(PhoenixConfigurationUtil.SESSION_ID, sessionId);\n         jobProperties.put(PhoenixConfigurationUtil.INPUT_TABLE_NAME, tableName);\n         jobProperties.put(PhoenixStorageHandlerConstants.ZOOKEEPER_QUORUM, tableProperties\n                 .getProperty(PhoenixStorageHandlerConstants.ZOOKEEPER_QUORUM,",
                "deletions": 0
            },
            {
                "sha": "1313fdb704309e5a6dcecc85a48184b273563a50",
                "filename": "phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java",
                "blob_url": "https://github.com/apache/phoenix/blob/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java",
                "raw_url": "https://github.com/apache/phoenix/raw/41c16a020fcd1cb143675ea17e2d9d3a56750a8a/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java",
                "status": "modified",
                "changes": 5,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-hive/src/main/java/org/apache/phoenix/hive/util/PhoenixStorageHandlerUtil.java?ref=41c16a020fcd1cb143675ea17e2d9d3a56750a8a",
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.hadoop.net.DNS;\n import org.apache.phoenix.hive.constants.PhoenixStorageHandlerConstants;\n import org.apache.phoenix.hive.ql.index.IndexSearchCondition;\n+import org.apache.phoenix.mapreduce.util.PhoenixConfigurationUtil;\n \n import javax.naming.NamingException;\n import java.io.ByteArrayInputStream;\n@@ -182,10 +183,8 @@ private static String reverseDNS(InetAddress ipAddress) throws NamingException,\n     }\n \n     public static String getTableKeyOfSession(JobConf jobConf, String tableName) {\n-        SessionState sessionState = SessionState.get();\n-\n-        String sessionId = sessionState.getSessionId();\n \n+        String sessionId = jobConf.get(PhoenixConfigurationUtil.SESSION_ID);\n         return new StringBuilder(\"[\").append(sessionId).append(\"]-\").append(tableName).toString();\n     }\n ",
                "deletions": 3
            }
        ],
        "patched_files": [
            "PhoenixConfigurationUtil.java"
        ],
        "unit_tests": [
            "PhoenixConfigurationUtilTest.java"
        ]
    },
    "phoenix_119f86e": {
        "repo": "phoenix",
        "message": "PHOENIX-4265 NPE when ROW_TIMESTAMP is SQL timestamp column",
        "commit": "https://github.com/apache/phoenix/commit/119f86e0c29ed6331df35028d37f6964393f122b",
        "parent": "https://github.com/apache/phoenix/commit/aaa41a33d025ad6daa832fe8b42fc235e7154648",
        "bug_id": "phoenix_119f86e",
        "file": [
            {
                "sha": "275d72dc31ddb1ba2088849e90cd831ff36dd0a1",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "status": "modified",
                "changes": 66,
                "additions": 66,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=119f86e0c29ed6331df35028d37f6964393f122b",
                "patch": "@@ -42,10 +42,12 @@\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n import java.sql.SQLException;\n+import java.sql.Timestamp;\n import java.util.Properties;\n \n import org.apache.phoenix.compile.QueryPlan;\n import org.apache.phoenix.exception.SQLExceptionCode;\n+import org.apache.phoenix.jdbc.PhoenixResultSet;\n import org.apache.phoenix.jdbc.PhoenixStatement;\n import org.apache.phoenix.query.QueryConstants;\n import org.apache.phoenix.query.QueryServices;\n@@ -1420,6 +1422,70 @@ public void testParallelUpsertSelect() throws Exception {\n         conn.close();\n     }\n \n+    @Test // See https://issues.apache.org/jira/browse/PHOENIX-4265\n+    public void testLongCodecUsedForRowTimestamp() throws Exception {\n+        String tableName = generateUniqueName();\n+        String indexName = generateUniqueName();\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.createStatement().execute(\"CREATE IMMUTABLE TABLE \" + tableName\n+                    + \" (k1 TIMESTAMP not null, k2 bigint not null, v bigint, constraint pk primary key (k1 row_timestamp, k2)) SALT_BUCKETS = 9\");\n+            conn.createStatement().execute(\n+                \"CREATE INDEX \" + indexName + \" ON \" + tableName + \" (v) INCLUDE (k2)\");\n+            PreparedStatement stmt =\n+                    conn.prepareStatement(\"UPSERT INTO \" + tableName + \" VALUES (?, ?, ?) \");\n+            stmt.setTimestamp(1, new Timestamp(1000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 1000);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(2000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(3000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(4000));\n+            stmt.setLong(2, 5000);\n+            stmt.setLong(3, 5);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(5000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 10);\n+            stmt.executeUpdate();\n+            stmt.setTimestamp(1, new Timestamp(6000));\n+            stmt.setLong(2, 2000);\n+            stmt.setLong(3, 20);\n+            stmt.executeUpdate();\n+            conn.commit();\n+            ResultSet rs = conn.createStatement().executeQuery(\"SELECT \" +\n+                    \" K2 FROM \" + tableName + \" WHERE V = 5\");\n+            assertTrue(\"Index \" + indexName + \" should have been used\",\n+                rs.unwrap(PhoenixResultSet.class).getStatement().getQueryPlan().getTableRef()\n+                        .getTable().getName().getString().equals(indexName));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertFalse(rs.next());\n+            rs =\n+                    conn.createStatement().executeQuery(\"SELECT /*+ INDEX(\" + tableName + \" \"\n+                            + indexName + \") */ \" + \" K2 FROM \" + tableName + \" WHERE V = 5\");\n+            assertTrue(\"Index \" + indexName + \" should have been used\",\n+                rs.unwrap(PhoenixResultSet.class).getStatement().getQueryPlan().getTableRef()\n+                        .getTable().getName().getString().equals(indexName));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertTrue(rs.next());\n+            assertEquals(5000, rs.getLong(\"k2\"));\n+            assertFalse(rs.next());\n+        }\n+    }\n+\n     private static Connection getTenantConnection(String tenantId) throws Exception {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(TENANT_ID_ATTRIB, tenantId);",
                "deletions": 0
            },
            {
                "sha": "79bf3b9d8b20faffc366002d0d6033ffe7ff9f17",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java",
                "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java",
                "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java",
                "status": "modified",
                "changes": 14,
                "additions": 9,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/ScanRanges.java?ref=119f86e0c29ed6331df35028d37f6964393f122b",
                "patch": "@@ -41,7 +41,10 @@\n import org.apache.phoenix.schema.SaltingUtil;\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.ValueSchema.Field;\n+import org.apache.phoenix.schema.types.PDataType.PDataCodec;\n+import org.apache.phoenix.schema.types.PLong;\n import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.util.DateUtil;\n import org.apache.phoenix.util.ScanUtil;\n import org.apache.phoenix.util.ScanUtil.BytesComparator;\n import org.apache.phoenix.util.SchemaUtil;\n@@ -668,16 +671,17 @@ private static TimeRange getAscTimeRange(KeyRange lowestRange, KeyRange highestR\n             throws IOException {\n         long low;\n         long high;\n+        PDataCodec codec = PLong.INSTANCE.getCodec();\n         if (lowestRange.lowerUnbound()) {\n             low = 0;\n         } else {\n-            long lowerRange = f.getDataType().getCodec().decodeLong(lowestRange.getLowerRange(), 0, SortOrder.ASC);\n+            long lowerRange = codec.decodeLong(lowestRange.getLowerRange(), 0, SortOrder.ASC);\n             low = lowestRange.isLowerInclusive() ? lowerRange : safelyIncrement(lowerRange);\n         }\n         if (highestRange.upperUnbound()) {\n             high = HConstants.LATEST_TIMESTAMP;\n         } else {\n-            long upperRange = f.getDataType().getCodec().decodeLong(highestRange.getUpperRange(), 0, SortOrder.ASC);\n+            long upperRange = codec.decodeLong(highestRange.getUpperRange(), 0, SortOrder.ASC);\n             if (highestRange.isUpperInclusive()) {\n                 high = safelyIncrement(upperRange);\n             } else {\n@@ -692,9 +696,9 @@ public static TimeRange getDescTimeRange(KeyRange lowestKeyRange, KeyRange highe\n         boolean lowerInclusive = lowestKeyRange.isLowerInclusive();\n         boolean upperUnbound = highestKeyRange.upperUnbound();\n         boolean upperInclusive = highestKeyRange.isUpperInclusive();\n-\n-        long low = lowerUnbound ? -1 : f.getDataType().getCodec().decodeLong(lowestKeyRange.getLowerRange(), 0, SortOrder.DESC);\n-        long high = upperUnbound ? -1 : f.getDataType().getCodec().decodeLong(highestKeyRange.getUpperRange(), 0, SortOrder.DESC);\n+        PDataCodec codec = PLong.INSTANCE.getCodec();\n+        long low = lowerUnbound ? -1 : codec.decodeLong(lowestKeyRange.getLowerRange(), 0, SortOrder.DESC);\n+        long high = upperUnbound ? -1 : codec.decodeLong(highestKeyRange.getUpperRange(), 0, SortOrder.DESC);\n         long newHigh;\n         long newLow;\n         if (!lowerUnbound && !upperUnbound) {",
                "deletions": 5
            },
            {
                "sha": "0402c6e92cb49e49a60e11f5d54cb91088d8a612",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java",
                "blob_url": "https://github.com/apache/phoenix/blob/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java",
                "raw_url": "https://github.com/apache/phoenix/raw/119f86e0c29ed6331df35028d37f6964393f122b/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java",
                "status": "modified",
                "changes": 6,
                "additions": 5,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/types/PLong.java?ref=119f86e0c29ed6331df35028d37f6964393f122b",
                "patch": "@@ -230,7 +230,11 @@ public Object toObject(String value) {\n \n     @Override\n     public Object getSampleValue(Integer maxLength, Integer arrayLength) {\n-        return RANDOM.get().nextLong();\n+        long val = RANDOM.get().nextLong();\n+        if (val == Long.MIN_VALUE) {\n+            return Long.MAX_VALUE;\n+        }\n+        return Math.abs(val);\n     }\n \n     static class LongCodec extends BaseCodec {",
                "deletions": 1
            }
        ],
        "patched_files": [
            "ScanRanges.java"
        ],
        "unit_tests": [
            "ScanRangesTest.java"
        ]
    },
    "phoenix_28007f8": {
        "repo": "phoenix",
        "message": "PHOENIX-2304 NullPointerException when using an index and a char array (Julian Jaffe, Navis, James Taylor)",
        "commit": "https://github.com/apache/phoenix/commit/28007f804dd3d132d39169f532be050717c3526d",
        "parent": "https://github.com/apache/phoenix/commit/18d063353d8857898b29f68aa7789d33c16b1960",
        "bug_id": "phoenix_28007f8",
        "file": [
            {
                "sha": "53a13be1a7d6a200b1b692fc67fa26e36838d5ba",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "blob_url": "https://github.com/apache/phoenix/blob/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "raw_url": "https://github.com/apache/phoenix/raw/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java",
                "status": "modified",
                "changes": 76,
                "additions": 37,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/exception/SQLExceptionCode.java?ref=28007f804dd3d132d39169f532be050717c3526d",
                "patch": "@@ -46,9 +46,9 @@\n \n \n /**\n- * Various SQLException Information. Including a vender-specific errorcode and a standard SQLState.\n- * \n- * \n+ * Various SQLException Information. Including a vendor-specific errorcode and a standard SQLState.\n+ *\n+ *\n  * @since 1.0\n  */\n public enum SQLExceptionCode {\n@@ -59,7 +59,7 @@\n     IO_EXCEPTION(101, \"08000\", \"Unexpected IO exception.\"),\n     MALFORMED_CONNECTION_URL(102, \"08001\", \"Malformed connection url.\"),\n     CANNOT_ESTABLISH_CONNECTION(103, \"08004\", \"Unable to establish connection.\"),\n-    \n+\n     /**\n      * Data Exception (errorcode 02, sqlstate 22)\n      */\n@@ -74,19 +74,17 @@ public SQLException newException(SQLExceptionInfo info) {\n     VALUE_IN_UPSERT_NOT_CONSTANT(204, \"22008\", \"Values in UPSERT must evaluate to a constant.\"),\n     MALFORMED_URL(205, \"22009\", \"Malformed URL.\"),\n     DATA_EXCEEDS_MAX_CAPACITY(206, \"22003\", \"The data exceeds the max capacity for the data type.\"),\n-    MISSING_CHAR_LENGTH(207, \"22003\", \"Missing length for CHAR.\"),\n-    NONPOSITIVE_CHAR_LENGTH(208, \"22003\", \"CHAR or VARCHAR must have a positive length.\"),\n+    MISSING_MAX_LENGTH(207, \"22004\", \"Max length must be specified for type.\"),\n+    NONPOSITIVE_MAX_LENGTH(208, \"22006\", \"Max length must have a positive length for type.\"),\n     DECIMAL_PRECISION_OUT_OF_RANGE(209, \"22003\", \"Decimal precision outside of range. Should be within 1 and \" + PDataType.MAX_PRECISION + \".\"),\n-    MISSING_BINARY_LENGTH(210, \"22003\", \"Missing length for BINARY.\"),\n-    NONPOSITIVE_BINARY_LENGTH(211, \"22003\", \"BINARY must have a positive length.\"),\n     SERVER_ARITHMETIC_ERROR(212, \"22012\", \"Arithmetic error on server.\"),\n     VALUE_OUTSIDE_RANGE(213,\"22003\",\"Value outside range.\"),\n     VALUE_IN_LIST_NOT_CONSTANT(214, \"22008\", \"Values in IN must evaluate to a constant.\"),\n     SINGLE_ROW_SUBQUERY_RETURNS_MULTIPLE_ROWS(215, \"22015\", \"Single-row sub-query returns more than one row.\"),\n     SUBQUERY_RETURNS_DIFFERENT_NUMBER_OF_FIELDS(216, \"22016\", \"Sub-query must return the same number of fields as the left-hand-side expression of 'IN'.\"),\n-    AMBIGUOUS_JOIN_CONDITION(217, \"22017\", \"Amibiguous or non-equi join condition specified. Consider using table list with where clause.\"),\n-    CONSTRAINT_VIOLATION(218, \"22018\", \"Constraint violatioin.\"),\n-    \n+    AMBIGUOUS_JOIN_CONDITION(217, \"22017\", \"Ambiguous or non-equi join condition specified. Consider using table list with where clause.\"),\n+    CONSTRAINT_VIOLATION(218, \"22018\", \"Constraint violation.\"),\n+\n     /**\n      * Constraint Violation (errorcode 03, sqlstate 23)\n      */\n@@ -97,13 +95,13 @@ public SQLException newException(SQLExceptionInfo info) {\n         }\n     }),\n     CANNOT_INDEX_COLUMN_ON_TYPE(302, \"23100\", \"The column cannot be index due to its type.\"),\n-    \n+\n     /**\n      * Invalid Cursor State (errorcode 04, sqlstate 24)\n      */\n     CURSOR_BEFORE_FIRST_ROW(401, \"24015\",\"Cursor before first row.\"),\n     CURSOR_PAST_LAST_ROW(402, \"24016\", \"Cursor past last row.\"),\n-    \n+\n     /**\n      * Syntax Error or Access Rule Violation (errorcode 05, sqlstate 42)\n      */\n@@ -152,22 +150,22 @@ public SQLException newException(SQLExceptionInfo info) {\n      *  Invalid Transaction State (errorcode 05, sqlstate 25)\n      */\n      READ_ONLY_CONNECTION(518,\"25502\",\"Mutations are not permitted for a read-only connection.\"),\n- \n+\n      VARBINARY_ARRAY_NOT_SUPPORTED(519, \"42896\", \"VARBINARY ARRAY is not supported\"),\n-    \n+\n      /**\n       *  Expression Index exceptions.\n       */\n-     AGGREGATE_EXPRESSION_NOT_ALLOWED_IN_INDEX(520, \"42897\", \"Aggreagaate expression not allowed in an index\"),\n+     AGGREGATE_EXPRESSION_NOT_ALLOWED_IN_INDEX(520, \"42897\", \"Aggregate expression not allowed in an index\"),\n      NON_DETERMINISTIC_EXPRESSION_NOT_ALLOWED_IN_INDEX(521, \"42898\", \"Non-deterministic expression not allowed in an index\"),\n      STATELESS_EXPRESSION_NOT_ALLOWED_IN_INDEX(522, \"42899\", \"Stateless expression not allowed in an index\"),\n \n-     /** \n+     /**\n       * Union All related errors\n       */\n      SELECT_COLUMN_NUM_IN_UNIONALL_DIFFS(525, \"42902\", \"SELECT column number differs in a Union All query is not allowed\"),\n      SELECT_COLUMN_TYPE_IN_UNIONALL_DIFFS(526, \"42903\", \"SELECT column types differ in a Union All query is not allowed\"),\n-     \n+\n      /**\n       * Row timestamp column related errors\n       */\n@@ -177,10 +175,10 @@ public SQLException newException(SQLExceptionInfo info) {\n      ROWTIMESTAMP_COL_INVALID_TYPE(530, \"42907\", \"A column can be added as ROW_TIMESTAMP only if it is of type DATE, BIGINT, TIME OR TIMESTAMP\"),\n      ROWTIMESTAMP_NOT_ALLOWED_ON_VIEW(531, \"42908\", \"Declaring a column as row_timestamp is not allowed for views\"),\n      INVALID_SCN(532, \"42909\", \"Value of SCN cannot be less than zero\"),\n-     /** \n+     /**\n      * HBase and Phoenix specific implementation defined sub-classes.\n      * Column family related exceptions.\n-     * \n+     *\n      * For the following exceptions, use errorcode 10.\n      */\n     SINGLE_PK_MAY_NOT_BE_NULL(1000, \"42I00\", \"Single column primary key may not be NULL.\"),\n@@ -237,11 +235,11 @@ public SQLException newException(SQLExceptionInfo info) {\n     NO_MUTABLE_INDEXES(1026, \"42Y85\", \"Mutable secondary indexes are only supported for HBase version \" + MetaDataUtil.decodeHBaseVersionAsString(PhoenixDatabaseMetaData.MUTABLE_SI_VERSION_THRESHOLD) + \" and above.\"),\n     INVALID_FILTER_ON_IMMUTABLE_ROWS(1027, \"42Y86\", \"All columns referenced in a WHERE clause must be available in every index for a table with immutable rows.\"),\n     INVALID_INDEX_STATE_TRANSITION(1028, \"42Y87\", \"Invalid index state transition.\"),\n-    INVALID_MUTABLE_INDEX_CONFIG(1029, \"42Y88\", \"Mutable secondary indexes must have the \" \n-            + IndexManagementUtil.WAL_EDIT_CODEC_CLASS_KEY + \" property set to \" \n+    INVALID_MUTABLE_INDEX_CONFIG(1029, \"42Y88\", \"Mutable secondary indexes must have the \"\n+            + IndexManagementUtil.WAL_EDIT_CODEC_CLASS_KEY + \" property set to \"\n             +  IndexManagementUtil.INDEX_WAL_EDIT_CODEC_CLASS_NAME + \" in the hbase-sites.xml of every region server\"),\n-            \n-            \n+\n+\n     CANNOT_CREATE_TENANT_SPECIFIC_TABLE(1030, \"42Y89\", \"Cannot create table for tenant-specific connection\"),\n     DEFAULT_COLUMN_FAMILY_ONLY_ON_CREATE_TABLE(1034, \"42Y93\", \"Default column family may only be specified when creating a table.\"),\n     INSUFFICIENT_MULTI_TENANT_COLUMNS(1040, \"42Y96\", \"A MULTI_TENANT table must have two or more PK columns with the first column being NOT NULL.\"),\n@@ -255,8 +253,8 @@ public SQLException newException(SQLExceptionInfo info) {\n     CANNOT_ALTER_PROPERTY(1051, \"43A08\", \"Property can be specified or changed only when creating a table\"),\n     CANNOT_SET_PROPERTY_FOR_COLUMN_NOT_ADDED(1052, \"43A09\", \"Property cannot be specified for a column family that is not being added or modified\"),\n     CANNOT_SET_TABLE_PROPERTY_ADD_COLUMN(1053, \"43A10\", \"Table level property cannot be set when adding a column\"),\n-    \n-    NO_LOCAL_INDEXES(1054, \"43A11\", \"Local secondary indexes are not supported for HBase versions \" + \n+\n+    NO_LOCAL_INDEXES(1054, \"43A11\", \"Local secondary indexes are not supported for HBase versions \" +\n         MetaDataUtil.decodeHBaseVersionAsString(PhoenixDatabaseMetaData.MIN_LOCAL_SI_VERSION_DISALLOW) + \" through \" + MetaDataUtil.decodeHBaseVersionAsString(PhoenixDatabaseMetaData.MAX_LOCAL_SI_VERSION_DISALLOW) + \" inclusive.\"),\n     UNALLOWED_LOCAL_INDEXES(1055, \"43A12\", \"Local secondary indexes are configured to not be allowed.\"),\n     DESC_VARBINARY_NOT_SUPPORTED(1056, \"43A13\", \"Descending VARBINARY columns not supported\"),\n@@ -288,18 +286,18 @@ public SQLException newException(SQLExceptionInfo info) {\n     SEQUENCE_VAL_REACHED_MAX_VALUE(1212, \"42Z12\", \"Reached MAXVALUE of sequence\"),\n     SEQUENCE_VAL_REACHED_MIN_VALUE(1213, \"42Z13\", \"Reached MINVALUE of sequence\"),\n     INCREMENT_BY_MUST_NOT_BE_ZERO(1214, \"42Z14\", \"Sequence INCREMENT BY value cannot be zero\"),\n-    NUM_SEQ_TO_ALLOCATE_MUST_BE_CONSTANT(1215, \"42Z15\", \"Sequence NEXT n VALUES FOR must be a postive integer or constant.\" ),\n+    NUM_SEQ_TO_ALLOCATE_MUST_BE_CONSTANT(1215, \"42Z15\", \"Sequence NEXT n VALUES FOR must be a positive integer or constant.\" ),\n     NUM_SEQ_TO_ALLOCATE_NOT_SUPPORTED(1216, \"42Z16\", \"Sequence NEXT n VALUES FOR is not supported for Sequences with the CYCLE flag\" ),\n-                    \n+\n     /** Parser error. (errorcode 06, sqlState 42P) */\n-    PARSER_ERROR(601, \"42P00\", \"Syntax error.\", Factory.SYTAX_ERROR),\n-    MISSING_TOKEN(602, \"42P00\", \"Syntax error.\", Factory.SYTAX_ERROR),\n-    UNWANTED_TOKEN(603, \"42P00\", \"Syntax error.\", Factory.SYTAX_ERROR),\n-    MISMATCHED_TOKEN(604, \"42P00\", \"Syntax error.\", Factory.SYTAX_ERROR),\n-    UNKNOWN_FUNCTION(605, \"42P00\", \"Syntax error.\", Factory.SYTAX_ERROR),\n-    \n+    PARSER_ERROR(601, \"42P00\", \"Syntax error.\", Factory.SYNTAX_ERROR),\n+    MISSING_TOKEN(602, \"42P00\", \"Syntax error.\", Factory.SYNTAX_ERROR),\n+    UNWANTED_TOKEN(603, \"42P00\", \"Syntax error.\", Factory.SYNTAX_ERROR),\n+    MISMATCHED_TOKEN(604, \"42P00\", \"Syntax error.\", Factory.SYNTAX_ERROR),\n+    UNKNOWN_FUNCTION(605, \"42P00\", \"Syntax error.\", Factory.SYNTAX_ERROR),\n+\n     /**\n-     * Implementation defined class. Execution exceptions (errorcode 11, sqlstate XCL). \n+     * Implementation defined class. Execution exceptions (errorcode 11, sqlstate XCL).\n      */\n     RESULTSET_CLOSED(1101, \"XCL01\", \"ResultSet is closed.\"),\n     GET_TABLE_REGIONS_FAIL(1102, \"XCL02\", \"Cannot get all table regions\"),\n@@ -316,7 +314,7 @@ public SQLException newException(SQLExceptionInfo info) {\n     }),\n     CANNOT_SPLIT_LOCAL_INDEX(1109,\"XCL09\", \"Local index may not be pre-split\"),\n     CANNOT_SALT_LOCAL_INDEX(1110,\"XCL10\", \"Local index may not be salted\"),\n-    \n+\n     /**\n      * Implementation defined class. Phoenix internal error. (errorcode 20, sqlstate INT).\n      */\n@@ -359,7 +357,7 @@ public SQLException newException(SQLExceptionInfo info) {\n     private final Factory factory;\n \n     private SQLExceptionCode(int errorCode, String sqlState, String message) {\n-        this(errorCode, sqlState, message, Factory.DEFAULTY);\n+        this(errorCode, sqlState, message, Factory.DEFAULT);\n     }\n \n     private SQLExceptionCode(int errorCode, String sqlState, String message, Factory factory) {\n@@ -391,15 +389,15 @@ public Factory getExceptionFactory() {\n     }\n \n     public static interface Factory {\n-        public static final Factory DEFAULTY = new Factory() {\n+        public static final Factory DEFAULT = new Factory() {\n \n             @Override\n             public SQLException newException(SQLExceptionInfo info) {\n                 return new SQLException(info.toString(), info.getCode().getSQLState(), info.getCode().getErrorCode(), info.getRootCause());\n             }\n             \n         };\n-        public static final Factory SYTAX_ERROR = new Factory() {\n+        public static final Factory SYNTAX_ERROR = new Factory() {\n \n             @Override\n             public SQLException newException(SQLExceptionInfo info) {",
                "deletions": 39
            },
            {
                "sha": "278b4aa7c7716f3b25dd9580b7a4a042584ebfd1",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/parse/ColumnDef.java",
                "blob_url": "https://github.com/apache/phoenix/blob/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/main/java/org/apache/phoenix/parse/ColumnDef.java",
                "raw_url": "https://github.com/apache/phoenix/raw/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/main/java/org/apache/phoenix/parse/ColumnDef.java",
                "status": "modified",
                "changes": 228,
                "additions": 109,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/parse/ColumnDef.java?ref=28007f804dd3d132d39169f532be050717c3526d",
                "patch": "@@ -22,12 +22,9 @@\n import org.apache.phoenix.exception.SQLExceptionCode;\n import org.apache.phoenix.exception.SQLExceptionInfo;\n import org.apache.phoenix.schema.SortOrder;\n-import org.apache.phoenix.schema.types.PBinary;\n-import org.apache.phoenix.schema.types.PChar;\n import org.apache.phoenix.schema.types.PDataType;\n import org.apache.phoenix.schema.types.PDecimal;\n import org.apache.phoenix.schema.types.PVarbinary;\n-import org.apache.phoenix.schema.types.PVarchar;\n import org.apache.phoenix.util.SchemaUtil;\n \n import com.google.common.base.Preconditions;\n@@ -42,7 +39,7 @@\n  */\n public class ColumnDef {\n     private final ColumnName columnDefName;\n-    private PDataType dataType;\n+    private final PDataType dataType;\n     private final Boolean isNull;\n     private final Integer maxLength;\n     private final Integer scale;\n@@ -52,98 +49,91 @@\n     private final Integer arrSize;\n     private final String expressionStr;\n     private final boolean isRowTimestamp;\n- \n+\n     ColumnDef(ColumnName columnDefName, String sqlTypeName, boolean isArray, Integer arrSize, Boolean isNull, Integer maxLength,\n-    \t\t            Integer scale, boolean isPK, SortOrder sortOrder, String expressionStr, boolean isRowTimestamp) {\n-   \t try {\n-         Preconditions.checkNotNull(sortOrder);\n-   \t     PDataType localType = null;\n-         this.columnDefName = columnDefName;\n-         this.isArray = isArray;\n-         // TODO : Add correctness check for arrSize.  Should this be ignored as in postgres\n-         // Also add what is the limit that we would support.  Are we going to support a\n-         //  fixed size or like postgres allow infinite.  May be the data types max limit can \n-         // be used for the array size (May be too big)\n-         if(this.isArray) {\n-        \t localType = sqlTypeName == null ? null : PDataType.fromTypeId(PDataType.sqlArrayType(SchemaUtil.normalizeIdentifier(sqlTypeName)));\n-        \t this.dataType = sqlTypeName == null ? null : PDataType.fromSqlTypeName(SchemaUtil.normalizeIdentifier(sqlTypeName));\n-             this.arrSize = arrSize; // Can only be non negative based on parsing\n-             if (this.dataType == PVarbinary.INSTANCE) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.VARBINARY_ARRAY_NOT_SUPPORTED)\n-                 .setColumnName(columnDefName.getColumnName()).build().buildException();\n-             }\n-         } else {\n-             this.dataType = sqlTypeName == null ? null : PDataType.fromSqlTypeName(SchemaUtil.normalizeIdentifier(sqlTypeName));\n-             this.arrSize = null;\n-         }\n-         \n-         this.isNull = isNull;\n-         if (this.dataType == PChar.INSTANCE) {\n-             if (maxLength == null) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.MISSING_CHAR_LENGTH)\n-                     .setColumnName(columnDefName.getColumnName()).build().buildException();\n-             }\n-             if (maxLength < 1) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.NONPOSITIVE_CHAR_LENGTH)\n-                     .setColumnName(columnDefName.getColumnName()).build().buildException();\n-             }\n-             scale = null;\n-         } else if (this.dataType == PVarchar.INSTANCE) {\n-             if (maxLength != null && maxLength < 1) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.NONPOSITIVE_CHAR_LENGTH)\n-                     .setColumnName(columnDefName.getColumnName()).build().buildException(); \n-             }\n-             scale = null;\n-         } else if (this.dataType == PDecimal.INSTANCE) {\n-             // for deciaml, 1 <= maxLength <= PDataType.MAX_PRECISION;\n-             if (maxLength != null) {\n-                 if (maxLength < 1 || maxLength > PDataType.MAX_PRECISION) {\n-                     throw new SQLExceptionInfo.Builder(SQLExceptionCode.DECIMAL_PRECISION_OUT_OF_RANGE)\n-                         .setColumnName(columnDefName.getColumnName()).build().buildException();\n-                 }\n-                 // When a precision is specified and a scale is not specified, it is set to 0. \n-                 // \n-                 // This is the standard as specified in\n-                 // http://docs.oracle.com/cd/B28359_01/server.111/b28318/datatype.htm#CNCPT1832\n-                 // and \n-                 // http://docs.oracle.com/javadb/10.6.2.1/ref/rrefsqlj15260.html.\n-                 // Otherwise, if scale is bigger than maxLength, just set it to the maxLength;\n-                 //\n-                 // When neither a precision nor a scale is specified, the precision and scale is\n-                 // ignored. All decimal are stored with as much decimal points as possible.\n-                 scale = scale == null ? PDataType.DEFAULT_SCALE : scale > maxLength ? maxLength : scale; \n-             }\n-         } else if (this.dataType == PBinary.INSTANCE) {\n-             if (maxLength == null) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.MISSING_BINARY_LENGTH)\n-                     .setColumnName(columnDefName.getColumnName()).build().buildException();\n-             }\n-             if (maxLength < 1) {\n-                 throw new SQLExceptionInfo.Builder(SQLExceptionCode.NONPOSITIVE_BINARY_LENGTH)\n-                     .setColumnName(columnDefName.getColumnName()).build().buildException();\n-             }\n-             scale = null;\n-         } else {\n-             // ignore maxLength and scale for other types.\n-             maxLength = null;\n-             scale = null;\n-         }\n-         this.maxLength = maxLength;\n-         this.scale = scale;\n-         this.isPK = isPK;\n-         this.sortOrder = sortOrder;\n-         if(this.isArray) {\n-             this.dataType = localType;\n-         }\n-         this.expressionStr = expressionStr;\n-         this.isRowTimestamp = isRowTimestamp;\n-     } catch (SQLException e) {\n-         throw new ParseException(e);\n-     }\n+            Integer scale, boolean isPK, SortOrder sortOrder, String expressionStr, boolean isRowTimestamp) {\n+        try {\n+            Preconditions.checkNotNull(sortOrder);\n+            PDataType baseType;\n+            PDataType dataType;\n+            this.columnDefName = columnDefName;\n+            // TODO : Add correctness check for arrSize.  Should this be ignored as in postgres\n+            // Also add what is the limit that we would support.  Are we going to support a\n+            //  fixed size or like postgres allow infinite.  May be the data types max limit can \n+            // be used for the array size (May be too big)\n+            if (isArray) {\n+                this.isArray = true;\n+                dataType = sqlTypeName == null ? null : PDataType.fromTypeId(PDataType.sqlArrayType(SchemaUtil.normalizeIdentifier(sqlTypeName)));\n+                baseType = sqlTypeName == null ? null : PDataType.fromSqlTypeName(SchemaUtil.normalizeIdentifier(sqlTypeName));\n+                this.arrSize = arrSize; // Can only be non negative based on parsing\n+                if (baseType == PVarbinary.INSTANCE) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.VARBINARY_ARRAY_NOT_SUPPORTED)\n+                    .setColumnName(columnDefName.getColumnName()).build().buildException();\n+                }\n+            } else {\n+                baseType = dataType = sqlTypeName == null ? null : PDataType.fromSqlTypeName(SchemaUtil.normalizeIdentifier(sqlTypeName));\n+                if (this.isArray = dataType != null && dataType.isArrayType()) {\n+                    baseType = PDataType.arrayBaseType(dataType);\n+                }\n+                this.arrSize = null;\n+            }\n+\n+            this.isNull = isNull;\n+            if (baseType == PDecimal.INSTANCE) {\n+                // for deciaml, 1 <= maxLength <= PDataType.MAX_PRECISION;\n+                if (maxLength == null) {\n+                    scale = null;\n+                } else {\n+                    if (maxLength < 1 || maxLength > PDataType.MAX_PRECISION) {\n+                        throw new SQLExceptionInfo.Builder(SQLExceptionCode.DECIMAL_PRECISION_OUT_OF_RANGE)\n+                        .setColumnName(columnDefName.getColumnName()).build().buildException();\n+                    }\n+                    // When a precision is specified and a scale is not specified, it is set to 0. \n+                    // \n+                    // This is the standard as specified in\n+                    // http://docs.oracle.com/cd/B28359_01/server.111/b28318/datatype.htm#CNCPT1832\n+                    // and \n+                    // http://docs.oracle.com/javadb/10.6.2.1/ref/rrefsqlj15260.html.\n+                    // Otherwise, if scale is bigger than maxLength, just set it to the maxLength;\n+                    //\n+                    // When neither a precision nor a scale is specified, the precision and scale is\n+                    // ignored. All decimal are stored with as much decimal points as possible.\n+                    scale = scale == null ? PDataType.DEFAULT_SCALE : scale > maxLength ? maxLength : scale; \n+                }\n+            } else {\n+                if (maxLength != null && maxLength < 1) {\n+                    throw new SQLExceptionInfo.Builder(SQLExceptionCode.NONPOSITIVE_MAX_LENGTH)\n+                    .setColumnName(columnDefName.getColumnName()).build().buildException();\n+                }\n+                scale = null;\n+                if (baseType == null) {\n+                    maxLength = null;\n+                } else if (baseType.isFixedWidth()) {\n+                    if (baseType.getByteSize() == null) {\n+                        if (maxLength == null) {\n+                            throw new SQLExceptionInfo.Builder(SQLExceptionCode.MISSING_MAX_LENGTH)\n+                            .setColumnName(columnDefName.getColumnName()).build().buildException();\n+                        }\n+                    } else {\n+                        maxLength = null;\n+                    }\n+                }\n+            }\n+            this.maxLength = maxLength;\n+            this.scale = scale;\n+            this.isPK = isPK;\n+            this.sortOrder = sortOrder;\n+            this.dataType = dataType;\n+            this.expressionStr = expressionStr;\n+            this.isRowTimestamp = isRowTimestamp;\n+        } catch (SQLException e) {\n+            throw new ParseException(e);\n+        }\n     }\n+\n     ColumnDef(ColumnName columnDefName, String sqlTypeName, Boolean isNull, Integer maxLength,\n             Integer scale, boolean isPK, SortOrder sortOrder, String expressionStr, boolean isRowTimestamp) {\n-    \tthis(columnDefName, sqlTypeName, false, 0, isNull, maxLength, scale, isPK, sortOrder, expressionStr, isRowTimestamp);\n+        this(columnDefName, sqlTypeName, false, 0, isNull, maxLength, scale, isPK, sortOrder, expressionStr, isRowTimestamp);\n     }\n \n     public ColumnName getColumnDefName() {\n@@ -175,45 +165,45 @@ public Integer getScale() {\n     public boolean isPK() {\n         return isPK;\n     }\n-    \n+\n     public SortOrder getSortOrder() {\n-    \treturn sortOrder;\n+        return sortOrder;\n+    }\n+\n+    public boolean isArray() {\n+        return isArray;\n     }\n-        \n-\tpublic boolean isArray() {\n-\t\treturn isArray;\n-\t}\n-\n-\tpublic Integer getArraySize() {\n-\t\treturn arrSize;\n-\t}\n-\n-\tpublic String getExpression() {\n-\t\treturn expressionStr;\n-\t}\n-\t\n-\tpublic boolean isRowTimestamp() {\n-\t    return isRowTimestamp;\n-\t}\n-\t@Override\n+\n+    public Integer getArraySize() {\n+        return arrSize;\n+    }\n+\n+    public String getExpression() {\n+        return expressionStr;\n+    }\n+\n+    public boolean isRowTimestamp() {\n+        return isRowTimestamp;\n+    }\n+    @Override\n     public String toString() {\n-\t    StringBuilder buf = new StringBuilder(columnDefName.getColumnNode().toString());\n-\t    buf.append(' ');\n+        StringBuilder buf = new StringBuilder(columnDefName.getColumnNode().toString());\n+        buf.append(' ');\n         buf.append(dataType.getSqlTypeName());\n         if (maxLength != null) {\n             buf.append('(');\n             buf.append(maxLength);\n             if (scale != null) {\n-              buf.append(',');\n-              buf.append(scale); // has both max length and scale. For ex- decimal(10,2)\n+                buf.append(',');\n+                buf.append(scale); // has both max length and scale. For ex- decimal(10,2)\n             }       \n             buf.append(')');\n-       }\n+        }\n         if (isArray) {\n             buf.append(' ');\n             buf.append(PDataType.ARRAY_TYPE_SUFFIX);\n             buf.append(' ');\n         }\n-\t    return buf.toString();\n-\t}\n-}\n+        return buf.toString();\n+    }\n+}\n\\ No newline at end of file",
                "deletions": 119
            },
            {
                "sha": "e528d3ba4941156deb5f5211e2e6516c44080b6c",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/QueryOptimizerTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryOptimizerTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryOptimizerTest.java",
                "status": "modified",
                "changes": 17,
                "additions": 17,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/QueryOptimizerTest.java?ref=28007f804dd3d132d39169f532be050717c3526d",
                "patch": "@@ -38,6 +38,7 @@\n import org.apache.phoenix.jdbc.PhoenixStatement;\n import org.apache.phoenix.query.BaseConnectionlessQueryTest;\n import org.apache.phoenix.query.QueryConstants;\n+import org.apache.phoenix.schema.PColumn;\n import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.util.PhoenixRuntime;\n import org.apache.phoenix.util.QueryUtil;\n@@ -390,6 +391,22 @@ public void testQueryOptimizerShouldSelectThePlanWithMoreNumberOfPKColumns() thr\n         assertEquals(\"CLIENT PARALLEL 1-WAY SKIP SCAN ON 15 KEYS OVER INDEX_TEST_TABLE_INDEX_F ['1','1111'] - ['5','3333']\", QueryUtil.getExplainPlan(rs));\n     }\n \n+    @Test\n+    public void testCharArrayLength() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        conn.createStatement().execute(\n+                \"CREATE TABLE TEST.TEST (testInt INTEGER, testCharArray CHAR(3)[], testByteArray BINARY(7)[], \" +\n+                \"CONSTRAINT test_pk PRIMARY KEY(testInt)) DEFAULT_COLUMN_FAMILY='T'\");\n+        conn.createStatement().execute(\"CREATE INDEX TEST_INDEX ON TEST.TEST (testInt) INCLUDE (testCharArray, testByteArray)\");\n+        PhoenixStatement stmt = conn.createStatement().unwrap(PhoenixStatement.class);\n+\n+        QueryPlan plan = stmt.optimizeQuery(\"SELECT /*+ INDEX(TEST.TEST TEST_INDEX)*/ testCharArray,testByteArray FROM TEST.TEST\");\n+        List<PColumn> columns = plan.getTableRef().getTable().getColumns();\n+        assertEquals(3, columns.size());\n+        assertEquals(3, columns.get(1).getMaxLength().intValue());\n+        assertEquals(7, columns.get(2).getMaxLength().intValue());\n+    }\n+\n     private void testAssertQueryPlanDetails(boolean multitenant, boolean useIndex, boolean salted) throws Exception {\n         String sql;\n         PreparedStatement stmt;",
                "deletions": 0
            },
            {
                "sha": "5363042b956e7e0307df69c8253042a934dab908",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/parse/QueryParserTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/test/java/org/apache/phoenix/parse/QueryParserTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/28007f804dd3d132d39169f532be050717c3526d/phoenix-core/src/test/java/org/apache/phoenix/parse/QueryParserTest.java",
                "status": "modified",
                "changes": 99,
                "additions": 50,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/parse/QueryParserTest.java?ref=28007f804dd3d132d39169f532be050717c3526d",
                "patch": "@@ -376,41 +376,41 @@ public void testParsingStatementWithExtraToken() throws Exception {\n \n     @Test\n     public void testParseCreateTableInlinePrimaryKeyWithOrder() throws Exception {\n-    \tfor (String order : new String[]{\"asc\", \"desc\"}) {\n+        for (String order : new String[]{\"asc\", \"desc\"}) {\n             String s = \"create table core.entity_history_archive (id char(15) primary key ${o})\".replace(\"${o}\", order);\n-    \t\tCreateTableStatement stmt = (CreateTableStatement)new SQLParser((s)).parseStatement();\n-    \t\tList<ColumnDef> columnDefs = stmt.getColumnDefs();\n-    \t\tassertEquals(1, columnDefs.size());\n-    \t\tassertEquals(SortOrder.fromDDLValue(order), columnDefs.iterator().next().getSortOrder()); \n-    \t}\n+            CreateTableStatement stmt = (CreateTableStatement)new SQLParser((s)).parseStatement();\n+            List<ColumnDef> columnDefs = stmt.getColumnDefs();\n+            assertEquals(1, columnDefs.size());\n+            assertEquals(SortOrder.fromDDLValue(order), columnDefs.iterator().next().getSortOrder()); \n+        }\n     }\n     \n     @Test\n     public void testParseCreateTableOrderWithoutPrimaryKeyFails() throws Exception {\n-    \tfor (String order : new String[]{\"asc\", \"desc\"}) {\n-    \t\tString stmt = \"create table core.entity_history_archive (id varchar(20) ${o})\".replace(\"${o}\", order);\n-    \t\ttry {\n-    \t\t\tnew SQLParser((stmt)).parseStatement();\n-    \t\t\tfail(\"Expected parse exception to be thrown\");\n-    \t\t} catch (SQLException e) {\n-    \t\t\tString errorMsg = \"ERROR 603 (42P00): Syntax error. Unexpected input. Expecting \\\"RPAREN\\\", got \\\"${o}\\\"\".replace(\"${o}\", order);\n-    \t\t\tassertTrue(\"Expected message to contain \\\"\" + errorMsg + \"\\\" but got \\\"\" + e.getMessage() + \"\\\"\", e.getMessage().contains(errorMsg));\n-    \t\t}\n-    \t}\n+        for (String order : new String[]{\"asc\", \"desc\"}) {\n+            String stmt = \"create table core.entity_history_archive (id varchar(20) ${o})\".replace(\"${o}\", order);\n+            try {\n+                new SQLParser((stmt)).parseStatement();\n+                fail(\"Expected parse exception to be thrown\");\n+            } catch (SQLException e) {\n+                String errorMsg = \"ERROR 603 (42P00): Syntax error. Unexpected input. Expecting \\\"RPAREN\\\", got \\\"${o}\\\"\".replace(\"${o}\", order);\n+                assertTrue(\"Expected message to contain \\\"\" + errorMsg + \"\\\" but got \\\"\" + e.getMessage() + \"\\\"\", e.getMessage().contains(errorMsg));\n+            }\n+        }\n     }\n     \n     @Test\n     public void testParseCreateTablePrimaryKeyConstraintWithOrder() throws Exception {\n-    \tfor (String order : new String[]{\"asc\", \"desc\"}) {\n-    \t\tString s = \"create table core.entity_history_archive (id CHAR(15), name VARCHAR(150), constraint pk primary key (id ${o}, name ${o}))\".replace(\"${o}\", order);\n-    \t\tCreateTableStatement stmt = (CreateTableStatement)new SQLParser((s)).parseStatement();\n-    \t\tPrimaryKeyConstraint pkConstraint = stmt.getPrimaryKeyConstraint();\n-    \t\tList<Pair<ColumnName,SortOrder>> columns = pkConstraint.getColumnNames();\n-    \t\tassertEquals(2, columns.size());\n-    \t\tfor (Pair<ColumnName,SortOrder> pair : columns) {\n-    \t\t\tassertEquals(SortOrder.fromDDLValue(order), pkConstraint.getColumnWithSortOrder(pair.getFirst()).getSecond());\n-    \t\t}    \t\t\n-    \t}\n+        for (String order : new String[]{\"asc\", \"desc\"}) {\n+            String s = \"create table core.entity_history_archive (id CHAR(15), name VARCHAR(150), constraint pk primary key (id ${o}, name ${o}))\".replace(\"${o}\", order);\n+            CreateTableStatement stmt = (CreateTableStatement)new SQLParser((s)).parseStatement();\n+            PrimaryKeyConstraint pkConstraint = stmt.getPrimaryKeyConstraint();\n+            List<Pair<ColumnName,SortOrder>> columns = pkConstraint.getColumnNames();\n+            assertEquals(2, columns.size());\n+            for (Pair<ColumnName,SortOrder> pair : columns) {\n+                assertEquals(SortOrder.fromDDLValue(order), pkConstraint.getColumnWithSortOrder(pair.getFirst()).getSecond());\n+            }           \n+        }\n     }\n \n     @Test\n@@ -439,46 +439,47 @@ public void testInvalidTrailingCommaOnCreateTable() throws Exception {\n     }\n \n     @Test\n-\tpublic void testCreateSequence() throws Exception {\n-\t\tString sql = ((\n-\t\t\t\t\"create sequence foo.bar\\n\" + \n-\t\t\t\t\t\t\"start with 0\\n\"\t+ \n-\t\t\t\t\t\t\"increment by 1\\n\"));\n-\t\tparseQuery(sql);\n-\t}\n-\t\n-\t@Test\n-\tpublic void testNextValueForSelect() throws Exception {\n-\t\tString sql = ((\n-\t\t\t\t\"select next value for foo.bar \\n\" + \n-\t\t\t\t\t\t\"from core.custom_entity_data\\n\"));\t\t\t\t\t\t\n-\t\tparseQuery(sql);\n-\t}\n-\t\n-\t@Test\n+    public void testCreateSequence() throws Exception {\n+        String sql = ((\n+                \"create sequence foo.bar\\n\" + \n+                        \"start with 0\\n\"    + \n+                        \"increment by 1\\n\"));\n+        parseQuery(sql);\n+    }\n+    \n+    @Test\n+    public void testNextValueForSelect() throws Exception {\n+        String sql = ((\n+                \"select next value for foo.bar \\n\" + \n+                        \"from core.custom_entity_data\\n\"));                     \n+        parseQuery(sql);\n+    }\n+    \n+    @Test\n     public void testNextValueForWhere() throws Exception {\n         String sql = ((\n                 \"upsert into core.custom_entity_data\\n\" + \n                         \"select next value for foo.bar from core.custom_entity_data\\n\"));                    \n         parseQuery(sql);\n     }\n-\t\n+\n+    @Test\n     public void testBadCharDef() throws Exception {\n         try {\n             String sql = (\"CREATE TABLE IF NOT EXISTS testBadVarcharDef\" + \n                     \"  (pk VARCHAR NOT NULL PRIMARY KEY, col CHAR(0))\");\n             parseQuery(sql);\n             fail(\"Should have caught bad char definition.\");\n         } catch (SQLException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"ERROR 208 (22003): CHAR or VARCHAR must have a positive length. columnName=COL\"));\n+            assertEquals(SQLExceptionCode.NONPOSITIVE_MAX_LENGTH.getErrorCode(), e.getErrorCode());\n         }\n         try {\n             String sql = (\"CREATE TABLE IF NOT EXISTS testBadVarcharDef\" + \n                     \"  (pk VARCHAR NOT NULL PRIMARY KEY, col CHAR)\");\n             parseQuery(sql);\n             fail(\"Should have caught bad char definition.\");\n         } catch (SQLException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"ERROR 207 (22003): Missing length for CHAR. columnName=COL\"));\n+            assertEquals(SQLExceptionCode.MISSING_MAX_LENGTH.getErrorCode(), e.getErrorCode());\n         }\n     }\n \n@@ -490,7 +491,7 @@ public void testBadVarcharDef() throws Exception {\n             parseQuery(sql);\n             fail(\"Should have caught bad varchar definition.\");\n         } catch (SQLException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"ERROR 208 (22003): CHAR or VARCHAR must have a positive length. columnName=COL\"));\n+            assertEquals(SQLExceptionCode.NONPOSITIVE_MAX_LENGTH.getErrorCode(), e.getErrorCode());\n         }\n     }\n \n@@ -522,15 +523,15 @@ public void testBadBinaryDef() throws Exception {\n             parseQuery(sql);\n             fail(\"Should have caught bad binary definition.\");\n         } catch (SQLException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"ERROR 211 (22003): BINARY must have a positive length. columnName=COL\"));\n+            assertEquals(SQLExceptionCode.NONPOSITIVE_MAX_LENGTH.getErrorCode(), e.getErrorCode());\n         }\n         try {\n             String sql = (\"CREATE TABLE IF NOT EXISTS testBadVarcharDef\" + \n                     \"  (pk VARCHAR NOT NULL PRIMARY KEY, col BINARY)\");\n             parseQuery(sql);\n             fail(\"Should have caught bad char definition.\");\n         } catch (SQLException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"ERROR 210 (22003): Missing length for BINARY. columnName=COL\"));\n+            assertEquals(SQLExceptionCode.MISSING_MAX_LENGTH.getErrorCode(), e.getErrorCode());\n         }\n     }\n ",
                "deletions": 49
            }
        ],
        "patched_files": [
            "ColumnDef.java",
            "SQLExceptionCode.java",
            "QueryOptimizer.java"
        ],
        "unit_tests": [
            "QueryParserTest.java",
            "QueryOptimizerTest.java"
        ]
    },
    "phoenix_e25d7d0": {
        "repo": "phoenix",
        "message": "PHOENIX-1870 Fix NPE occurring during regex processing when joni library not used",
        "commit": "https://github.com/apache/phoenix/commit/e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
        "parent": "https://github.com/apache/phoenix/commit/035e315794427e0914be6d0a84fb6bac5331d6a8",
        "bug_id": "phoenix_e25d7d0",
        "file": [
            {
                "sha": "ea80b11fce372f8e9761aac96bfab5fc789ed295",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java",
                "status": "modified",
                "changes": 97,
                "additions": 61,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSubstrFunction.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
                "patch": "@@ -22,15 +22,16 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBasePattern;\n import org.apache.phoenix.parse.FunctionParseNode.Argument;\n import org.apache.phoenix.parse.FunctionParseNode.BuiltInFunction;\n import org.apache.phoenix.parse.RegexpSubstrParseNode;\n import org.apache.phoenix.schema.SortOrder;\n import org.apache.phoenix.schema.tuple.Tuple;\n import org.apache.phoenix.schema.types.PDataType;\n+import org.apache.phoenix.schema.types.PInteger;\n import org.apache.phoenix.schema.types.PLong;\n import org.apache.phoenix.schema.types.PVarchar;\n \n@@ -56,11 +57,11 @@\n     public static final String NAME = \"REGEXP_SUBSTR\";\n \n     private AbstractBasePattern pattern;\n-    private boolean isOffsetConstant;\n+    private Integer offset;\n     private Integer maxLength;\n \n     private static final PDataType TYPE = PVarchar.INSTANCE;\n-\n+    \n     public RegexpSubstrFunction() { }\n \n     public RegexpSubstrFunction(List<Expression> children) {\n@@ -71,51 +72,76 @@ public RegexpSubstrFunction(List<Expression> children) {\n     protected abstract AbstractBasePattern compilePatternSpec(String value);\n \n     private void init() {\n-        Object patternString = ((LiteralExpression)children.get(1)).getValue();\n-        if (patternString != null) {\n-            pattern = compilePatternSpec((String) patternString);\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n+        Expression patternExpr = getPatternExpression();\n+        if (patternExpr.isStateless() && patternExpr.getDeterminism() == Determinism.ALWAYS && patternExpr.evaluate(null, ptr)) {\n+            String patternStr = (String) patternExpr.getDataType().toObject(ptr, patternExpr.getSortOrder());\n+            if (patternStr != null) {\n+                pattern = compilePatternSpec(patternStr);\n+            }\n         }\n         // If the source string has a fixed width, then the max length would be the length \n         // of the source string minus the offset, or the absolute value of the offset if \n         // it's negative. Offset number is a required argument. However, if the source string\n         // is not fixed width, the maxLength would be null.\n-        isOffsetConstant = getOffsetExpression() instanceof LiteralExpression;\n-        Number offsetNumber = (Number)((LiteralExpression)getOffsetExpression()).getValue();\n-        if (offsetNumber != null) {\n-            int offset = offsetNumber.intValue();\n-            PDataType type = getSourceStrExpression().getDataType();\n-            if (type.isFixedWidth()) {\n-                if (offset >= 0) {\n-                    Integer maxLength = getSourceStrExpression().getMaxLength();\n-                    this.maxLength = maxLength - offset - (offset == 0 ? 0 : 1);\n-                } else {\n-                    this.maxLength = -offset;\n+        Expression offsetExpr = getOffsetExpression();\n+        if (offsetExpr.isStateless() && offsetExpr.getDeterminism() == Determinism.ALWAYS && offsetExpr.evaluate(null, ptr)) {\n+            offset = (Integer)PInteger.INSTANCE.toObject(ptr, offsetExpr.getDataType(), offsetExpr.getSortOrder());\n+            if (offset != null) {\n+                PDataType type = getSourceStrExpression().getDataType();\n+                if (type.isFixedWidth()) {\n+                    if (offset >= 0) {\n+                        Integer maxLength = getSourceStrExpression().getMaxLength();\n+                        this.maxLength = maxLength - offset - (offset == 0 ? 0 : 1);\n+                    } else {\n+                        this.maxLength = -offset;\n+                    }\n                 }\n             }\n         }\n     }\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n+        AbstractBasePattern pattern = this.pattern;\n         if (pattern == null) {\n-            return false;\n+            Expression patternExpr = getPatternExpression();\n+            if (!patternExpr.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            if (ptr.getLength() == 0) {\n+                return true;\n+            }\n+            pattern = compilePatternSpec((String) patternExpr.getDataType().toObject(ptr, patternExpr.getSortOrder()));\n         }\n-        ImmutableBytesWritable srcPtr = new ImmutableBytesWritable();\n-        if (!getSourceStrExpression().evaluate(tuple, srcPtr)) {\n-            return false;\n+        int offset;\n+        if (this.offset == null) {\n+            Expression offsetExpression = getOffsetExpression();\n+            if (!offsetExpression.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            if (ptr.getLength() == 0) {\n+                return true;\n+            }\n+            offset = offsetExpression.getDataType().getCodec().decodeInt(ptr, offsetExpression.getSortOrder());\n+        } else {\n+            offset = this.offset;\n         }\n-        TYPE.coerceBytes(srcPtr, TYPE, getSourceStrExpression().getSortOrder(), SortOrder.ASC);\n-\n-        Expression offsetExpression = getOffsetExpression();\n-        if (!offsetExpression.evaluate(tuple, ptr)) {\n+        Expression strExpression = getSourceStrExpression();\n+        if (!strExpression.evaluate(tuple, ptr)) {\n             return false;\n         }\n-        int offset = offsetExpression.getDataType().getCodec().decodeInt(ptr, offsetExpression.getSortOrder());\n+        if (ptr.get().length == 0) {\n+            return true;\n+        }\n+\n+        TYPE.coerceBytes(ptr, strExpression.getDataType(), strExpression.getSortOrder(), SortOrder.ASC);\n \n         // Account for 1 versus 0-based offset\n         offset = offset - (offset <= 0 ? 0 : 1);\n \n-        return pattern.substr(srcPtr, offset, ptr);\n+        pattern.substr(ptr, offset);\n+        return true;\n     }\n \n     @Override\n@@ -125,14 +151,9 @@ public Integer getMaxLength() {\n \n     @Override\n     public OrderPreserving preservesOrder() {\n-        if (isOffsetConstant) {\n-            LiteralExpression literal = (LiteralExpression) getOffsetExpression();\n-            Number offsetNumber = (Number) literal.getValue();\n-            if (offsetNumber != null) { \n-                int offset = offsetNumber.intValue();\n-                if (offset == 0 || offset == 1) {\n-                    return OrderPreserving.YES_IF_LAST;\n-                }\n+        if (offset != null) {\n+            if (offset == 0 || offset == 1) {\n+                return OrderPreserving.YES_IF_LAST;\n             }\n         }\n         return OrderPreserving.NO;\n@@ -153,6 +174,10 @@ private Expression getOffsetExpression() {\n         return children.get(2);\n     }\n \n+    private Expression getPatternExpression() {\n+        return children.get(1);\n+    }\n+\n     private Expression getSourceStrExpression() {\n         return children.get(0);\n     }\n@@ -161,7 +186,7 @@ private Expression getSourceStrExpression() {\n     public PDataType getDataType() {\n         // ALways VARCHAR since we do not know in advanced how long the \n         // matched string will be.\n-        return PVarchar.INSTANCE;\n+        return TYPE;\n     }\n \n     @Override",
                "deletions": 36
            },
            {
                "sha": "5287fd760f7c1e6a81d381e5613bb9ed0c836997",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "status": "modified",
                "changes": 3,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
                "patch": "@@ -26,8 +26,7 @@\n     public abstract void replaceAll(ImmutableBytesWritable srcPtr,\n             ImmutableBytesWritable replacePtr, ImmutableBytesWritable outPtr);\n \n-    public abstract boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr);\n+    public abstract void substr(ImmutableBytesWritable srcPtr, int offsetInStr);\n \n     public abstract String pattern();\n }",
                "deletions": 2
            },
            {
                "sha": "b17e8a7446c87efba060457257fe5be4cd2b4169",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "status": "modified",
                "changes": 18,
                "additions": 9,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
                "patch": "@@ -130,15 +130,15 @@ public PairInt(int begin, int end) {\n     }\n \n     @Override\n-    public boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr) {\n-        Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n-        int offsetInBytes = StringUtil.calculateUTF8Offset(srcPtr.get(), srcPtr.getOffset(),\n-            srcPtr.getLength(), SortOrder.ASC, offsetInStr);\n-        if (offsetInBytes < 0) return false;\n-        substr(srcPtr.get(), offsetInBytes, srcPtr.getOffset() + srcPtr.getLength(), outPtr);\n-        return true;\n+    public void substr(ImmutableBytesWritable ptr, int offsetInStr) {\n+        Preconditions.checkNotNull(ptr);\n+        int offsetInBytes = StringUtil.calculateUTF8Offset(ptr.get(), ptr.getOffset(),\n+                ptr.getLength(), SortOrder.ASC, offsetInStr);\n+        if (offsetInBytes < 0) {\n+            ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+        } else {\n+            substr(ptr.get(), offsetInBytes, ptr.getOffset() + ptr.getLength(), ptr);\n+        }\n     }\n \n     private boolean substr(byte[] srcBytes, int offset, int range, ImmutableBytesWritable outPtr) {",
                "deletions": 9
            },
            {
                "sha": "f4bd239f6996be1352f3835bfae48e4f0ba9e28b",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "status": "modified",
                "changes": 31,
                "additions": 17,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
                "patch": "@@ -73,21 +73,24 @@ public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable rep\n     }\n \n     @Override\n-    public boolean substr(ImmutableBytesWritable srcPtr, int offsetInStr,\n-            ImmutableBytesWritable outPtr) {\n-        Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n-        String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n-        if (srcPtr.get().length == 0 && sourceStr == null) sourceStr = \"\";\n-        if (offsetInStr < 0) offsetInStr += sourceStr.length();\n-        if (offsetInStr < 0 || offsetInStr >= sourceStr.length()) return false;\n-        Matcher matcher = pattern.matcher(sourceStr);\n-        boolean ret = matcher.find(offsetInStr);\n-        if (ret) {\n-            outPtr.set(PVarchar.INSTANCE.toBytes(matcher.group()));\n+    public void substr(ImmutableBytesWritable ptr, int offsetInStr) {\n+        Preconditions.checkNotNull(ptr);\n+        String sourceStr = (String) PVarchar.INSTANCE.toObject(ptr);\n+        if (sourceStr == null) {\n+            ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n         } else {\n-            outPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            if (offsetInStr < 0) offsetInStr += sourceStr.length();\n+            if (offsetInStr < 0 || offsetInStr >= sourceStr.length()) {\n+                ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            } else {\n+                Matcher matcher = pattern.matcher(sourceStr);\n+                boolean ret = matcher.find(offsetInStr);\n+                if (ret) {\n+                    ptr.set(PVarchar.INSTANCE.toBytes(matcher.group()));\n+                } else {\n+                    ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+                }\n+            }\n         }\n-        return true;\n     }\n }",
                "deletions": 14
            },
            {
                "sha": "4275687f0a09c336d4fa85bd0182ac90c1f7c99e",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/e25d7d098c7d537fe8f3ee36838664c26f52a5ac/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "status": "modified",
                "changes": 7,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java?ref=e25d7d098c7d537fe8f3ee36838664c26f52a5ac",
                "patch": "@@ -101,10 +101,11 @@ public void testLike() {\n     private void testSubstr(AbstractBasePattern pattern, String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            boolean ret = pattern.substr(dataPtr[i % 3], 0, resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(),ptr.getOffset(),ptr.getLength());\n+            pattern.substr(resultPtr, 0);\n             if (ENABLE_ASSERT) {\n-                assertTrue(ret\n-                        && (i % 3 != 2 || \":THU\".equals(PVarchar.INSTANCE.toObject(resultPtr))));\n+                assertTrue((i % 3 != 2 || \":THU\".equals(PVarchar.INSTANCE.toObject(resultPtr))));\n             }\n         }\n         timer.printTime(name);",
                "deletions": 3
            }
        ],
        "patched_files": [
            "RegexpSubstrFunction.java",
            "JavaPattern.java",
            "JONIPattern.java",
            "AbstractBasePattern.java"
        ],
        "unit_tests": [
            "RegexpSubstrFunctionTest.java",
            "PatternPerformanceTest.java"
        ]
    },
    "phoenix_04504c3": {
        "repo": "phoenix",
        "message": "PHOENIX-2600 NPE on immutable index creation over transactional table",
        "commit": "https://github.com/apache/phoenix/commit/04504c34ffb2e39f38e1b37ee0d7f8f909537616",
        "parent": "https://github.com/apache/phoenix/commit/763a3566ed7ade82b7ffbd56cf90ff264cdbe20a",
        "bug_id": "phoenix_04504c3",
        "file": [
            {
                "sha": "364b4232c88bee9e4b0a87498bf944750c345100",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java",
                "status": "modified",
                "changes": 23,
                "additions": 23,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/UpsertSelectIT.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616",
                "patch": "@@ -1373,6 +1373,29 @@ public void testUpsertSelectWithFixedWidthNullByteSizeArray() throws Exception {\n         assertEquals(\"[[128,0,0,54], [128,0,4,0]]\", rs.getArray(2).toString());\n     }\n \n+\n+    @Test\n+    public void testParallelUpsertSelect() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(QueryServices.MUTATE_BATCH_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_CACHE_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_RESULT_CHUNK_SIZE, Integer.toString(3));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.setAutoCommit(false);\n+        conn.createStatement().execute(\"CREATE SEQUENCE S1\");\n+        conn.createStatement().execute(\"CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4\");\n+        conn.createStatement().execute(\"CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER)\");\n+\n+        for (int i = 0; i < 100; i++) {\n+            conn.createStatement().execute(\"UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, \" + (i%10) + \")\");\n+        }\n+        conn.commit();\n+        conn.setAutoCommit(true);\n+        int upsertCount = conn.createStatement().executeUpdate(\"UPSERT INTO T2 SELECT pk, val FROM SALTEDT1\");\n+        assertEquals(100,upsertCount);\n+        conn.close();\n+    }\n+\n     private static Connection getConnection(long ts) throws SQLException {\n         Properties props = PropertiesUtil.deepCopy(TestUtil.TEST_PROPERTIES);\n         props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(ts));",
                "deletions": 0
            },
            {
                "sha": "2794c477af4b0fd12e422b81999a2401a162eae6",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java",
                "status": "modified",
                "changes": 442,
                "additions": 232,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/tx/TransactionIT.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616",
                "patch": "@@ -36,6 +36,12 @@\n import java.util.Map;\n import java.util.Properties;\n \n+import co.cask.tephra.TransactionContext;\n+import co.cask.tephra.TransactionSystemClient;\n+import co.cask.tephra.TxConstants;\n+import co.cask.tephra.hbase11.TransactionAwareHTable;\n+import co.cask.tephra.hbase11.coprocessor.TransactionProcessor;\n+\n import org.apache.hadoop.hbase.HColumnDescriptor;\n import org.apache.hadoop.hbase.HTableDescriptor;\n import org.apache.hadoop.hbase.TableName;\n@@ -68,16 +74,10 @@\n import com.google.common.collect.Lists;\n import com.google.common.collect.Maps;\n \n-import co.cask.tephra.TransactionContext;\n-import co.cask.tephra.TransactionSystemClient;\n-import co.cask.tephra.TxConstants;\n-import co.cask.tephra.hbase11.TransactionAwareHTable;\n-import co.cask.tephra.hbase11.coprocessor.TransactionProcessor;\n-\n public class TransactionIT extends BaseHBaseManagedTimeIT {\n-\t\n-\tprivate static final String FULL_TABLE_NAME = INDEX_DATA_SCHEMA + QueryConstants.NAME_SEPARATOR + TRANSACTIONAL_DATA_TABLE;\n-\t\n+    \n+    private static final String FULL_TABLE_NAME = INDEX_DATA_SCHEMA + QueryConstants.NAME_SEPARATOR + TRANSACTIONAL_DATA_TABLE;\n+    \n     @Before\n     public void setUp() throws SQLException {\n         ensureTableCreated(getUrl(), TRANSACTIONAL_DATA_TABLE);\n@@ -90,73 +90,73 @@ public static void doSetup() throws Exception {\n         props.put(QueryServices.TRANSACTIONS_ENABLED, Boolean.toString(true));\n         setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n     }\n-\t\t\n-\t@Test\n-\tpublic void testReadOwnWrites() throws Exception {\n-\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 2);\n-\t\t\tstmt.execute();\n-\t        \n-\t        // verify rows can be read even though commit has not been called\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 1);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t        \n-\t        conn.commit();\n-\t        \n-\t        // verify rows can be read after commit\n-\t        rs = conn.createStatement().executeQuery(selectSql);\n-\t        TestUtil.validateRowKeyColumns(rs, 1);\n-\t        TestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t\t}\n-\t}\n-\t\n-\t@Test\n-\tpublic void testTxnClosedCorrecty() throws Exception {\n-\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 2);\n-\t\t\tstmt.execute();\n-\t        \n-\t        // verify rows can be read even though commit has not been called\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 1);\n-\t\t\tTestUtil.validateRowKeyColumns(rs, 2);\n-\t        assertFalse(rs.next());\n-\t        \n-\t        conn.close();\n-\t        // wait for any open txns to time out\n-\t        Thread.sleep(DEFAULT_TXN_TIMEOUT_SECONDS*1000+10000);\n-\t        assertTrue(\"There should be no invalid transactions\", txManager.getInvalidSize()==0);\n-\t\t}\n-\t}\n-\t\n+        \n+    @Test\n+    public void testReadOwnWrites() throws Exception {\n+        String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            TestUtil.setRowKeyColumns(stmt, 2);\n+            stmt.execute();\n+            \n+            // verify rows can be read even though commit has not been called\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+            \n+            conn.commit();\n+            \n+            // verify rows can be read after commit\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+        }\n+    }\n+    \n+    @Test\n+    public void testTxnClosedCorrecty() throws Exception {\n+        String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            TestUtil.setRowKeyColumns(stmt, 2);\n+            stmt.execute();\n+            \n+            // verify rows can be read even though commit has not been called\n+            rs = conn.createStatement().executeQuery(selectSql);\n+            TestUtil.validateRowKeyColumns(rs, 1);\n+            TestUtil.validateRowKeyColumns(rs, 2);\n+            assertFalse(rs.next());\n+            \n+            conn.close();\n+            // wait for any open txns to time out\n+            Thread.sleep(DEFAULT_TXN_TIMEOUT_SECONDS*1000+10000);\n+            assertTrue(\"There should be no invalid transactions\", txManager.getInvalidSize()==0);\n+        }\n+    }\n+    \n     @Test\n     public void testDelete() throws Exception {\n         String selectSQL = \"SELECT * FROM \" + FULL_TABLE_NAME;\n         try (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n             conn1.setAutoCommit(false);\n             ResultSet rs = conn1.createStatement().executeQuery(selectSQL);\n             assertFalse(rs.next());\n@@ -188,107 +188,107 @@ public void testDelete() throws Exception {\n         }\n     }\n     \n-\t@Test\n-\tpublic void testAutoCommitQuerySingleTable() throws Exception {\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(true);\n-\t\t\t// verify no rows returned\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME);\n-\t\t\tassertFalse(rs.next());\n-\t\t}\n-\t}\n-\t\n+    @Test\n+    public void testAutoCommitQuerySingleTable() throws Exception {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(true);\n+            // verify no rows returned\n+            ResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME);\n+            assertFalse(rs.next());\n+        }\n+    }\n+    \n     @Test\n     public void testAutoCommitQueryMultiTables() throws Exception {\n-    \ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n             conn.setAutoCommit(true);\n             // verify no rows returned\n             ResultSet rs = conn.createStatement().executeQuery(\"SELECT * FROM \" + FULL_TABLE_NAME + \" a JOIN \" + FULL_TABLE_NAME + \" b ON (a.long_pk = b.int_pk)\");\n             assertFalse(rs.next());\n         } \n     }\n     \n-\t@Test\n-\tpublic void testColConflicts() throws Exception {\n-\t\ttry (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tconn2.setAutoCommit(false);\n-\t\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tResultSet rs = conn1.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t\t\t// upsert row using conn1\n-\t\t\tString upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n-\t\t\tPreparedStatement stmt = conn1.prepareStatement(upsertSql);\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 10);\n-\t        stmt.execute();\n-\t        // upsert row using conn2\n- \t\t\tstmt = conn2.prepareStatement(upsertSql);\n- \t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 11);\n-\t        stmt.execute();\n- \t        \n- \t        conn1.commit();\n-\t        //second commit should fail\n- \t        try {\n- \t \t        conn2.commit();\n- \t \t        fail();\n- \t        }\t\n- \t        catch (SQLException e) {\n- \t        \tassertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n- \t        }\n-\t\t}\n-\t}\n-\t\n-\tprivate void testRowConflicts() throws Exception {\n-\t\ttry (Connection conn1 = DriverManager.getConnection(getUrl()); \n-        \t\tConnection conn2 = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tconn2.setAutoCommit(false);\n-\t\t\tString selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n-\t\t\tconn1.setAutoCommit(false);\n-\t\t\tResultSet rs = conn1.createStatement().executeQuery(selectSql);\n-\t\t\tboolean immutableRows = conn1.unwrap(PhoenixConnection.class).getTable(new PTableKey(null, FULL_TABLE_NAME)).isImmutableRows();\n-\t     \tassertFalse(rs.next());\n-\t\t\t// upsert row using conn1\n-\t\t\tString upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n-\t\t\tPreparedStatement stmt = conn1.prepareStatement(upsertSql);\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 10);\n-\t        stmt.execute();\n-\t        // upsert row using conn2\n-\t        upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, b.int_col2) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n- \t\t\tstmt = conn2.prepareStatement(upsertSql);\n- \t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.setInt(7, 11);\n- \t        stmt.execute();\n- \t        \n- \t        conn1.commit();\n-\t        //second commit should fail\n- \t        try {\n- \t \t        conn2.commit();\n- \t \t        if (!immutableRows) fail();\n- \t        }\t\n- \t        catch (SQLException e) {\n- \t        \tif (immutableRows) fail();\n- \t        \tassertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n- \t        }\n-\t\t}\n-\t}\n-\t\n-\t@Test\n-\tpublic void testRowConflictDetected() throws Exception {\n-\t\ttestRowConflicts();\n-\t}\n-\t\n-\t@Test\n-\tpublic void testNoConflictDetectionForImmutableRows() throws Exception {\n-\t\tConnection conn = DriverManager.getConnection(getUrl());\n-\t\tconn.createStatement().execute(\"ALTER TABLE \" + FULL_TABLE_NAME + \" SET IMMUTABLE_ROWS=true\");\n-\t\ttestRowConflicts();\n-\t}\n+    @Test\n+    public void testColConflicts() throws Exception {\n+        try (Connection conn1 = DriverManager.getConnection(getUrl()); \n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n+            conn1.setAutoCommit(false);\n+            conn2.setAutoCommit(false);\n+            String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+            conn1.setAutoCommit(false);\n+            ResultSet rs = conn1.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            // upsert row using conn1\n+            String upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn1.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 10);\n+            stmt.execute();\n+            // upsert row using conn2\n+            stmt = conn2.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 11);\n+            stmt.execute();\n+            \n+            conn1.commit();\n+            //second commit should fail\n+            try {\n+                conn2.commit();\n+                fail();\n+            }   \n+            catch (SQLException e) {\n+                assertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n+            }\n+        }\n+    }\n+    \n+    private void testRowConflicts() throws Exception {\n+        try (Connection conn1 = DriverManager.getConnection(getUrl()); \n+                Connection conn2 = DriverManager.getConnection(getUrl())) {\n+            conn1.setAutoCommit(false);\n+            conn2.setAutoCommit(false);\n+            String selectSql = \"SELECT * FROM \"+FULL_TABLE_NAME;\n+            conn1.setAutoCommit(false);\n+            ResultSet rs = conn1.createStatement().executeQuery(selectSql);\n+            boolean immutableRows = conn1.unwrap(PhoenixConnection.class).getTable(new PTableKey(null, FULL_TABLE_NAME)).isImmutableRows();\n+            assertFalse(rs.next());\n+            // upsert row using conn1\n+            String upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, a.int_col1) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn1.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 10);\n+            stmt.execute();\n+            // upsert row using conn2\n+            upsertSql = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk, b.int_col2) VALUES(?, ?, ?, ?, ?, ?, ?)\";\n+            stmt = conn2.prepareStatement(upsertSql);\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.setInt(7, 11);\n+            stmt.execute();\n+            \n+            conn1.commit();\n+            //second commit should fail\n+            try {\n+                conn2.commit();\n+                if (!immutableRows) fail();\n+            }   \n+            catch (SQLException e) {\n+                if (immutableRows) fail();\n+                assertEquals(e.getErrorCode(), SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode());\n+            }\n+        }\n+    }\n+    \n+    @Test\n+    public void testRowConflictDetected() throws Exception {\n+        testRowConflicts();\n+    }\n+    \n+    @Test\n+    public void testNoConflictDetectionForImmutableRows() throws Exception {\n+        Connection conn = DriverManager.getConnection(getUrl());\n+        conn.createStatement().execute(\"ALTER TABLE \" + FULL_TABLE_NAME + \" SET IMMUTABLE_ROWS=true\");\n+        testRowConflicts();\n+    }\n     \n     @Test\n     public void testNonTxToTxTable() throws Exception {\n@@ -514,33 +514,33 @@ public void testCreateTableToBeTransactional() throws Exception {\n     }\n \n     public void testCurrentDate() throws Exception {\n-\t\tString selectSql = \"SELECT current_date() FROM \"+FULL_TABLE_NAME;\n-\t\ttry (Connection conn = DriverManager.getConnection(getUrl())) {\n-\t\t\tconn.setAutoCommit(false);\n-\t\t\tResultSet rs = conn.createStatement().executeQuery(selectSql);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t        String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n-\t        PreparedStatement stmt = conn.prepareStatement(upsert);\n-\t\t\t// upsert two rows\n-\t\t\tTestUtil.setRowKeyColumns(stmt, 1);\n-\t\t\tstmt.execute();\n-\t\t\tconn.commit();\n-\t\t\t\n-\t\t\trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tassertTrue(rs.next());\n-\t\t\tDate date1 = rs.getDate(1);\n-\t     \tassertFalse(rs.next());\n-\t     \t\n-\t     \tThread.sleep(1000);\n-\t     \t\n-\t     \trs = conn.createStatement().executeQuery(selectSql);\n-\t\t\tassertTrue(rs.next());\n-\t\t\tDate date2 = rs.getDate(1);\n-\t     \tassertFalse(rs.next());\n-\t     \tassertTrue(\"current_date() should change while executing multiple statements\", date2.getTime() > date1.getTime());\n-\t\t}\n-\t}\n+        String selectSql = \"SELECT current_date() FROM \"+FULL_TABLE_NAME;\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.setAutoCommit(false);\n+            ResultSet rs = conn.createStatement().executeQuery(selectSql);\n+            assertFalse(rs.next());\n+            \n+            String upsert = \"UPSERT INTO \" + FULL_TABLE_NAME + \"(varchar_pk, char_pk, int_pk, long_pk, decimal_pk, date_pk) VALUES(?, ?, ?, ?, ?, ?)\";\n+            PreparedStatement stmt = conn.prepareStatement(upsert);\n+            // upsert two rows\n+            TestUtil.setRowKeyColumns(stmt, 1);\n+            stmt.execute();\n+            conn.commit();\n+            \n+            rs = conn.createStatement().executeQuery(selectSql);\n+            assertTrue(rs.next());\n+            Date date1 = rs.getDate(1);\n+            assertFalse(rs.next());\n+            \n+            Thread.sleep(1000);\n+            \n+            rs = conn.createStatement().executeQuery(selectSql);\n+            assertTrue(rs.next());\n+            Date date2 = rs.getDate(1);\n+            assertFalse(rs.next());\n+            assertTrue(\"current_date() should change while executing multiple statements\", date2.getTime() > date1.getTime());\n+        }\n+    }\n     \n     @Test\n     public void testReCreateTxnTableAfterDroppingExistingNonTxnTable() throws SQLException {\n@@ -558,32 +558,32 @@ public void testReCreateTxnTableAfterDroppingExistingNonTxnTable() throws SQLExc\n     \n     @Test\n     public void testRowTimestampDisabled() throws SQLException {\n-    \tProperties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n         try (Connection conn = DriverManager.getConnection(getUrl(), props)) {\n-\t        conn.setAutoCommit(false);\n-\t        Statement stmt = conn.createStatement();\n-\t        try {\n-\t        \tstmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP)) TRANSACTIONAL=true\");\n-\t        \tfail();\n-\t        }\n-        \tcatch(SQLException e) {\n-        \t\tassertEquals(SQLExceptionCode.CANNOT_CREATE_TXN_TABLE_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n-        \t}\n-\t        stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP))\");\n-\t        try {\n-\t        \tstmt.execute(\"ALTER TABLE DEMO SET TRANSACTIONAL=true\");\n-\t        \tfail();\n-\t        }\n-        \tcatch(SQLException e) {\n-        \t\tassertEquals(SQLExceptionCode.CANNOT_ALTER_TO_BE_TXN_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n-        \t}\n+            conn.setAutoCommit(false);\n+            Statement stmt = conn.createStatement();\n+            try {\n+                stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP)) TRANSACTIONAL=true\");\n+                fail();\n+            }\n+            catch(SQLException e) {\n+                assertEquals(SQLExceptionCode.CANNOT_CREATE_TXN_TABLE_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n+            }\n+            stmt.execute(\"CREATE TABLE DEMO(k VARCHAR, v VARCHAR, d DATE NOT NULL, CONSTRAINT PK PRIMARY KEY(k,d ROW_TIMESTAMP))\");\n+            try {\n+                stmt.execute(\"ALTER TABLE DEMO SET TRANSACTIONAL=true\");\n+                fail();\n+            }\n+            catch(SQLException e) {\n+                assertEquals(SQLExceptionCode.CANNOT_ALTER_TO_BE_TXN_WITH_ROW_TIMESTAMP.getErrorCode(), e.getErrorCode());\n+            }\n         }\n     }\n     \n     @Test\n     public void testReadOnlyView() throws Exception {\n         Connection conn = DriverManager.getConnection(getUrl());\n-\t\tString ddl = \"CREATE TABLE t (k INTEGER NOT NULL PRIMARY KEY, v1 DATE) TRANSACTIONAL=true\";\n+        String ddl = \"CREATE TABLE t (k INTEGER NOT NULL PRIMARY KEY, v1 DATE) TRANSACTIONAL=true\";\n         conn.createStatement().execute(ddl);\n         ddl = \"CREATE VIEW v (v2 VARCHAR) AS SELECT * FROM t where k>4\";\n         conn.createStatement().execute(ddl);\n@@ -870,4 +870,26 @@ public void testInflightDeleteNotSeen() throws Exception {\n             assertFalse(rs.next());\n         }\n     }\n+\n+    @Test\n+    public void testParallelUpsertSelect() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        props.setProperty(QueryServices.MUTATE_BATCH_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_CACHE_SIZE_ATTRIB, Integer.toString(3));\n+        props.setProperty(QueryServices.SCAN_RESULT_CHUNK_SIZE, Integer.toString(3));\n+        Connection conn = DriverManager.getConnection(getUrl(), props);\n+        conn.setAutoCommit(false);\n+        conn.createStatement().execute(\"CREATE SEQUENCE S1\");\n+        conn.createStatement().execute(\"CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4,TRANSACTIONAL=true\");\n+        conn.createStatement().execute(\"CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER) TRANSACTIONAL=true\");\n+\n+        for (int i = 0; i < 100; i++) {\n+            conn.createStatement().execute(\"UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, \" + (i%10) + \")\");\n+        }\n+        conn.commit();\n+        conn.setAutoCommit(true);\n+        int upsertCount = conn.createStatement().executeUpdate(\"UPSERT INTO T2 SELECT pk, val FROM SALTEDT1\");\n+        assertEquals(100,upsertCount);\n+        conn.close();\n+    }\n }",
                "deletions": 210
            },
            {
                "sha": "4c41f82ca3d44238447d32a6c336baad6a08d613",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "status": "modified",
                "changes": 1,
                "additions": 0,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616",
                "patch": "@@ -395,7 +395,6 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n             break;\n         }\n         final QueryPlan dataPlan = dataPlanToBe;\n-        final ColumnResolver resolver = resolverToBe;\n         final boolean hasImmutableIndexes = !immutableIndex.isEmpty();\n         // tableRefs is parallel with queryPlans\n         TableRef[] tableRefs = new TableRef[hasImmutableIndexes ? immutableIndex.size() : 1];",
                "deletions": 1
            },
            {
                "sha": "35a36e60141d6483a82bd9964eea85b7aae1dfa5",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java",
                "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java",
                "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java",
                "status": "modified",
                "changes": 40,
                "additions": 25,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/execute/MutationState.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616",
                "patch": "@@ -37,6 +37,18 @@\n import javax.annotation.Nonnull;\n import javax.annotation.concurrent.Immutable;\n \n+import co.cask.tephra.Transaction;\n+import co.cask.tephra.Transaction.VisibilityLevel;\n+import co.cask.tephra.TransactionAware;\n+import co.cask.tephra.TransactionCodec;\n+import co.cask.tephra.TransactionConflictException;\n+import co.cask.tephra.TransactionContext;\n+import co.cask.tephra.TransactionFailureException;\n+import co.cask.tephra.TransactionSystemClient;\n+import co.cask.tephra.hbase11.TransactionAwareHTable;\n+import co.cask.tephra.visibility.FenceWait;\n+import co.cask.tephra.visibility.VisibilityFence;\n+\n import org.apache.hadoop.hbase.HConstants;\n import org.apache.hadoop.hbase.client.Delete;\n import org.apache.hadoop.hbase.client.HTableInterface;\n@@ -98,18 +110,6 @@\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n \n-import co.cask.tephra.Transaction;\n-import co.cask.tephra.Transaction.VisibilityLevel;\n-import co.cask.tephra.TransactionAware;\n-import co.cask.tephra.TransactionCodec;\n-import co.cask.tephra.TransactionConflictException;\n-import co.cask.tephra.TransactionContext;\n-import co.cask.tephra.TransactionFailureException;\n-import co.cask.tephra.TransactionSystemClient;\n-import co.cask.tephra.hbase11.TransactionAwareHTable;\n-import co.cask.tephra.visibility.FenceWait;\n-import co.cask.tephra.visibility.VisibilityFence;\n-\n /**\n  * \n  * Tracks the uncommitted state\n@@ -242,7 +242,18 @@ public void commitWriteFence(PTable dataTable) throws SQLException {\n         }\n     }\n     \n-    private void addReadFence(PTable dataTable) throws SQLException {\n+    /**\n+     * Add an entry to the change set representing the DML operation that is starting.\n+     * These entries will not conflict with each other, but they will conflict with a\n+     * DDL operation of creating an index. See {@link #addReadFence(PTable)} and TEPHRA-157\n+     * for more information.\n+     * @param dataTable the table which is doing DML\n+     * @throws SQLException\n+     */\n+    public void addReadFence(PTable dataTable) throws SQLException {\n+        if (this.txContext == null) {\n+            throw new SQLExceptionInfo.Builder(SQLExceptionCode.NULL_TRANSACTION_CONTEXT).build().buildException();\n+        }\n         byte[] logicalKey = SchemaUtil.getTableKey(dataTable);\n         this.txContext.addTransactionAware(VisibilityFence.create(logicalKey));\n         byte[] physicalKey = dataTable.getPhysicalName().getBytes();\n@@ -848,8 +859,7 @@ private void send(Iterator<TableRef> tableRefIterator) throws SQLException {\n \t            final PTable table = tableRef.getTable();\n \t            // Track tables to which we've sent uncommitted data\n \t            if (isTransactional = table.isTransactional()) {\n-\t                addReadFence(table);\n-                    txTableRefs.add(tableRef);\n+\t                txTableRefs.add(tableRef);\n \t                uncommittedPhysicalNames.add(table.getPhysicalName().getString());\n \t            }\n \t            boolean isDataTable = true;",
                "deletions": 15
            },
            {
                "sha": "6bb57224b260af6cb82e945abb6523a953a04ef8",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java",
                "blob_url": "https://github.com/apache/phoenix/blob/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java",
                "raw_url": "https://github.com/apache/phoenix/raw/04504c34ffb2e39f38e1b37ee0d7f8f909537616/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java",
                "status": "modified",
                "changes": 1,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixStatement.java?ref=04504c34ffb2e39f38e1b37ee0d7f8f909537616",
                "patch": "@@ -331,6 +331,7 @@ public Integer call() throws SQLException {\n                                 MutationPlan plan = stmt.compilePlan(PhoenixStatement.this, Sequence.ValueOp.VALIDATE_SEQUENCE);\n                                 if (plan.getTargetRef() != null && plan.getTargetRef().getTable() != null && plan.getTargetRef().getTable().isTransactional()) {\n                                     state.startTransaction();\n+                                    state.addReadFence(plan.getTargetRef().getTable());\n                                 }\n                                 Iterator<TableRef> tableRefs = plan.getSourceRefs().iterator();\n                                 state.sendUncommitted(tableRefs);",
                "deletions": 0
            }
        ],
        "patched_files": [
            "MutationState.java"
        ],
        "unit_tests": [
            "MutationStateTest.java"
        ]
    },
    "phoenix_692b8cb": {
        "repo": "phoenix",
        "message": "PHOENIX-1385 Adding, dropping and adding columns fails with NPE (Samarth Jain, James Taylor)",
        "commit": "https://github.com/apache/phoenix/commit/692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
        "parent": "https://github.com/apache/phoenix/commit/c0b617f554938ea31832a921b8caa579e87749aa",
        "bug_id": "phoenix_692b8cb",
        "file": [
            {
                "sha": "5745bf03f1c17adbc1289cb0420a03e1acaafcaa",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java",
                "status": "modified",
                "changes": 22,
                "additions": 21,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/AlterTableIT.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -892,4 +892,24 @@ public void alterTableFromDifferentClient() throws Exception {\n         pstmt2.close();\n         conn1.close();\n     }\n-}\n+    \n+    @Test\n+    public void testAddColumnsUsingNewConnection() throws Exception {\n+        Properties props = PropertiesUtil.deepCopy(TEST_PROPERTIES);\n+        String ddl = \"CREATE TABLE T (\\n\"\n+                +\"ID1 VARCHAR(15) NOT NULL,\\n\"\n+                +\"ID2 VARCHAR(15) NOT NULL,\\n\"\n+                +\"CREATED_DATE DATE,\\n\"\n+                +\"CREATION_TIME BIGINT,\\n\"\n+                +\"LAST_USED DATE,\\n\"\n+                +\"CONSTRAINT PK PRIMARY KEY (ID1, ID2))\";\n+        Connection conn1 = DriverManager.getConnection(getUrl(), props);\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T ADD STRING VARCHAR, STRING_DATA_TYPES VARCHAR\";\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T DROP COLUMN STRING, STRING_DATA_TYPES\";\n+        conn1.createStatement().execute(ddl);\n+        ddl = \"ALTER TABLE T ADD STRING_ARRAY1 VARCHAR[]\";\n+        conn1.createStatement().execute(ddl);\n+        conn1.close();\n+    }}",
                "deletions": 1
            },
            {
                "sha": "4c57d0983b7a472b2fcc6aaf6475ab31fe05419a",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java",
                "status": "modified",
                "changes": 8,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/jdbc/PhoenixConnection.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -742,11 +742,11 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        metaData = metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        metaData = metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n         //Cascade through to connectionQueryServices too\n-        getQueryServices().removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+        getQueryServices().removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n         return metaData;\n     }\n ",
                "deletions": 4
            },
            {
                "sha": "dbf786a17d2dc57eb6414d81b1e01e305b41f3da",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "status": "modified",
                "changes": 4,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -512,12 +512,12 @@ public PMetaData removeTable(PName tenantId, final String tableName, String pare\n     }\n \n     @Override\n-    public PMetaData removeColumn(final PName tenantId, final String tableName, final String familyName, final String columnName, final long tableTimeStamp, final long tableSeqNum) throws SQLException {\n+    public PMetaData removeColumn(final PName tenantId, final String tableName, final List<PColumn> columnsToRemove, final long tableTimeStamp, final long tableSeqNum) throws SQLException {\n         return metaDataMutated(tenantId, tableName, tableSeqNum, new Mutator() {\n             @Override\n             public PMetaData mutate(PMetaData metaData) throws SQLException {\n                 try {\n-                    return metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+                    return metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n                 } catch (TableNotFoundException e) {\n                     // The DROP TABLE may have been processed first, so just ignore.\n                     return metaData;",
                "deletions": 2
            },
            {
                "sha": "386050c6ebc049079ecdcf2147b79fec65bb85c9",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionlessQueryServicesImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -152,9 +152,9 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        return metaData = metaData.removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        return metaData = metaData.removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n     }\n \n     ",
                "deletions": 3
            },
            {
                "sha": "defad5b045372d3809d8b74be6d2b21ed932647a",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/DelegateConnectionQueryServices.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -88,9 +88,9 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName,\n-            long tableTimeStamp, long tableSeqNum) throws SQLException {\n-        return getDelegate().removeColumn(tenantId, tableName, familyName, columnName, tableTimeStamp, tableSeqNum);\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp,\n+            long tableSeqNum) throws SQLException {\n+        return getDelegate().removeColumn(tenantId, tableName, columnsToRemove, tableTimeStamp, tableSeqNum);\n     }\n \n     @Override",
                "deletions": 3
            },
            {
                "sha": "cd4e2dedbfb4fb98d87563d23f910ecbb0131024",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/MetaDataMutated.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -37,5 +37,5 @@\n     PMetaData addTable(PTable table) throws SQLException;\n     PMetaData removeTable(PName tenantId, String tableName, String parentTableName, long tableTimeStamp) throws SQLException;\n     PMetaData addColumn(PName tenantId, String tableName, List<PColumn> columns, long tableTimeStamp, long tableSeqNum, boolean isImmutableRows) throws SQLException;\n-    PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName, long tableTimeStamp, long tableSeqNum) throws SQLException;\n+    PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp, long tableSeqNum) throws SQLException;\n }",
                "deletions": 1
            },
            {
                "sha": "afe21e866569ffba848acc3d2d373564631f8f61",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "status": "modified",
                "changes": 6,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -2308,10 +2308,8 @@ public MutationState dropColumn(DropColumnStatement statement) throws SQLExcepti\n                     // If we've done any index metadata updates, don't bother trying to update\n                     // client-side cache as it would be too painful. Just let it pull it over from\n                     // the server when needed.\n-                    if (columnsToDrop.size() > 0 && indexesToDrop.isEmpty()) {\n-                        for(PColumn columnToDrop : tableColumnsToDrop) {\n-                            connection.removeColumn(tenantId, SchemaUtil.getTableName(schemaName, tableName) , columnToDrop.getFamilyName().getString(), columnToDrop.getName().getString(), result.getMutationTime(), seqNum);\n-                        }\n+                    if (tableColumnsToDrop.size() > 0 && indexesToDrop.isEmpty()) {\n+                        connection.removeColumn(tenantId, SchemaUtil.getTableName(schemaName, tableName) , tableColumnsToDrop, result.getMutationTime(), seqNum);\n                     }\n                     // If we have a VIEW, then only delete the metadata, and leave the table data alone\n                     if (table.getType() != PTableType.VIEW) {",
                "deletions": 4
            },
            {
                "sha": "0d75aa29bcdc9e0ec11a97256a599d4c0dca678d",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java",
                "blob_url": "https://github.com/apache/phoenix/blob/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java",
                "raw_url": "https://github.com/apache/phoenix/raw/692b8cb1e653b0b7c9329ee1e2890f79d781ea50/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java",
                "status": "modified",
                "changes": 53,
                "additions": 28,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/PMetaDataImpl.java?ref=692b8cb1e653b0b7c9329ee1e2890f79d781ea50",
                "patch": "@@ -365,38 +365,41 @@ public PMetaData removeTable(PName tenantId, String tableName, String parentTabl\n     }\n     \n     @Override\n-    public PMetaData removeColumn(PName tenantId, String tableName, String familyName, String columnName, long tableTimeStamp, long tableSeqNum) throws SQLException {\n+    public PMetaData removeColumn(PName tenantId, String tableName, List<PColumn> columnsToRemove, long tableTimeStamp, long tableSeqNum) throws SQLException {\n         PTableRef tableRef = metaData.get(new PTableKey(tenantId, tableName));\n         if (tableRef == null) {\n             return this;\n         }\n         PTable table = tableRef.table;\n         PTableCache tables = metaData.clone();\n-        PColumn column;\n-        if (familyName == null) {\n-            column = table.getPKColumn(columnName);\n-        } else {\n-            column = table.getColumnFamily(familyName).getColumn(columnName);\n-        }\n-        int positionOffset = 0;\n-        int position = column.getPosition();\n-        List<PColumn> oldColumns = table.getColumns();\n-        if (table.getBucketNum() != null) {\n-            position--;\n-            positionOffset = 1;\n-            oldColumns = oldColumns.subList(positionOffset, oldColumns.size());\n-        }\n-        List<PColumn> columns = Lists.newArrayListWithExpectedSize(oldColumns.size() - 1);\n-        columns.addAll(oldColumns.subList(0, position));\n-        // Update position of columns that follow removed column\n-        for (int i = position+1; i < oldColumns.size(); i++) {\n-            PColumn oldColumn = oldColumns.get(i);\n-            PColumn newColumn = new PColumnImpl(oldColumn.getName(), oldColumn.getFamilyName(), oldColumn.getDataType(), oldColumn.getMaxLength(), oldColumn.getScale(), oldColumn.isNullable(), i-1+positionOffset, oldColumn.getSortOrder(), oldColumn.getArraySize(), oldColumn.getViewConstant(), oldColumn.isViewReferenced());\n-            columns.add(newColumn);\n+        for (PColumn columnToRemove : columnsToRemove) {\n+            PColumn column;\n+            String familyName = columnToRemove.getFamilyName().getString();\n+            if (familyName == null) {\n+                column = table.getPKColumn(columnToRemove.getName().getString());\n+            } else {\n+                column = table.getColumnFamily(familyName).getColumn(columnToRemove.getName().getString());\n+            }\n+            int positionOffset = 0;\n+            int position = column.getPosition();\n+            List<PColumn> oldColumns = table.getColumns();\n+            if (table.getBucketNum() != null) {\n+                position--;\n+                positionOffset = 1;\n+                oldColumns = oldColumns.subList(positionOffset, oldColumns.size());\n+            }\n+            List<PColumn> columns = Lists.newArrayListWithExpectedSize(oldColumns.size() - 1);\n+            columns.addAll(oldColumns.subList(0, position));\n+            // Update position of columns that follow removed column\n+            for (int i = position+1; i < oldColumns.size(); i++) {\n+                PColumn oldColumn = oldColumns.get(i);\n+                PColumn newColumn = new PColumnImpl(oldColumn.getName(), oldColumn.getFamilyName(), oldColumn.getDataType(), oldColumn.getMaxLength(), oldColumn.getScale(), oldColumn.isNullable(), i-1+positionOffset, oldColumn.getSortOrder(), oldColumn.getArraySize(), oldColumn.getViewConstant(), oldColumn.isViewReferenced());\n+                columns.add(newColumn);\n+            }\n+            \n+            table = PTableImpl.makePTable(table, tableTimeStamp, tableSeqNum, columns);\n         }\n-        \n-        PTable newTable = PTableImpl.makePTable(table, tableTimeStamp, tableSeqNum, columns);\n-        tables.put(newTable.getKey(), newTable);\n+        tables.put(table.getKey(), table);\n         return new PMetaDataImpl(tables);\n     }\n ",
                "deletions": 25
            }
        ],
        "patched_files": [
            "PMetaDataImpl.java"
        ],
        "unit_tests": [
            "PMetaDataImplTest.java"
        ]
    },
    "phoenix_3f294aa": {
        "repo": "phoenix",
        "message": "PHOENIX-1870 Fix NPE occurring during regex processing when joni library not used (Shuxiong Ye)",
        "commit": "https://github.com/apache/phoenix/commit/3f294aa962dc9e31ffe19200f78623590eb68a36",
        "parent": "https://github.com/apache/phoenix/commit/5a63c6360e53ec0bb52fc41b4f1856f1cc757257",
        "bug_id": "phoenix_3f294aa",
        "file": [
            {
                "sha": "ec4aa3a538aaaa82c8074299d8002c5d548098d4",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java",
                "status": "modified",
                "changes": 8,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/LikeExpression.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -236,10 +236,10 @@ private void init() {\n             LiteralExpression likeTypeExpression = (LiteralExpression)children.get(LIKE_TYPE_INDEX);\n             this.likeType = LikeType.valueOf((String)likeTypeExpression.getValue());\n         }\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n         Expression e = getPatternExpression();\n-        if (e instanceof LiteralExpression) {\n-            LiteralExpression patternExpression = (LiteralExpression)e;\n-            String value = (String)patternExpression.getValue();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, ptr)) {\n+            String value = (String) PVarchar.INSTANCE.toObject(ptr, e.getDataType(), e.getSortOrder());\n             pattern = compilePattern(value);\n         }\n     }\n@@ -294,7 +294,7 @@ public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n             value = (String) strDataType.toObject(ptr, strSortOrder);\n         }\n         strDataType.coerceBytes(ptr, strDataType, strSortOrder, SortOrder.ASC);\n-        pattern.matches(ptr, ptr);\n+        pattern.matches(ptr);\n         if (logger.isTraceEnabled()) {\n             boolean matched = ((Boolean) PBoolean.INSTANCE.toObject(ptr)).booleanValue();\n             logger.trace(\"LIKE(value='\" + value + \"'pattern='\" + pattern.pattern() + \"' is \" + matched);",
                "deletions": 4
            },
            {
                "sha": "b5a3d39005063ca38e899c301110d073bc17562d",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java",
                "status": "modified",
                "changes": 74,
                "additions": 51,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpReplaceFunction.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -22,8 +22,8 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBasePattern;\n import org.apache.phoenix.parse.FunctionParseNode.Argument;\n import org.apache.phoenix.parse.FunctionParseNode.BuiltInFunction;\n@@ -57,9 +57,11 @@\n public abstract class RegexpReplaceFunction extends ScalarFunction {\n     public static final String NAME = \"REGEXP_REPLACE\";\n \n-    private boolean hasReplaceStr;\n+    private static final PVarchar TYPE = PVarchar.INSTANCE;\n+    private byte [] rStrBytes;\n+    private int rStrOffset, rStrLen;\n     private AbstractBasePattern pattern;\n-    \n+\n     public RegexpReplaceFunction() { }\n \n     // Expect 1 arguments, the pattern. \n@@ -71,44 +73,70 @@ public RegexpReplaceFunction(List<Expression> children) {\n     protected abstract AbstractBasePattern compilePatternSpec(String value);\n \n     private void init() {\n-        hasReplaceStr = ((LiteralExpression)getReplaceStrExpression()).getValue() != null;\n-        Object patternString = ((LiteralExpression)children.get(1)).getValue();\n-        if (patternString != null) {\n-            pattern = compilePatternSpec((String) patternString);\n+        ImmutableBytesWritable tmpPtr = new ImmutableBytesWritable();\n+        Expression e = getPatternStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, tmpPtr)) {\n+            String patternStr = (String) TYPE.toObject(tmpPtr, e.getDataType(), e.getSortOrder());\n+            if (patternStr != null) pattern = compilePatternSpec(patternStr);\n+        }\n+        e = getReplaceStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, tmpPtr)) {\n+            TYPE.coerceBytes(tmpPtr, TYPE, e.getSortOrder(), SortOrder.ASC);\n+            rStrBytes = tmpPtr.get();\n+            rStrOffset = tmpPtr.getOffset();\n+            rStrLen = tmpPtr.getLength();\n+        } else {\n+            rStrBytes = null;\n         }\n     }\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n-        // Can't parse if there is no replacement pattern.\n+        AbstractBasePattern pattern = this.pattern;\n         if (pattern == null) {\n-            return false;\n-        }\n-        Expression sourceStrExpression = getSourceStrExpression();\n-        if (!sourceStrExpression.evaluate(tuple, ptr)) {\n-            return false;\n+            Expression e = getPatternStrExpression();\n+            if (!e.evaluate(tuple, ptr)) {\n+                return false;\n+            }\n+            String patternStr = (String) TYPE.toObject(ptr, e.getDataType(), e.getSortOrder());\n+            if (patternStr == null) {\n+                return false;\n+            } else {\n+                pattern = compilePatternSpec(patternStr);\n+            }\n         }\n-        if (ptr == null) return false;\n-        PVarchar type = PVarchar.INSTANCE;\n-        type.coerceBytes(ptr, type, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n-        ImmutableBytesWritable replacePtr = new ImmutableBytesWritable();\n-        if (hasReplaceStr) {\n+\n+        byte[] rStrBytes = this.rStrBytes;\n+        int rStrOffset = this.rStrOffset, rStrLen = this.rStrLen;\n+        if (rStrBytes == null) {\n             Expression replaceStrExpression = getReplaceStrExpression();\n-            if (!replaceStrExpression.evaluate(tuple, replacePtr)) {\n+            if (!replaceStrExpression.evaluate(tuple, ptr)) {\n                 return false;\n             }\n-            type.coerceBytes(replacePtr, type, replaceStrExpression.getSortOrder(), SortOrder.ASC);\n-        } else {\n-            replacePtr.set(type.toBytes(\"\"));\n+            TYPE.coerceBytes(ptr, TYPE, replaceStrExpression.getSortOrder(), SortOrder.ASC);\n+            rStrBytes = ptr.get();\n+            rStrOffset = ptr.getOffset();\n+            rStrLen = ptr.getLength();\n         }\n-        pattern.replaceAll(ptr, replacePtr, ptr);\n+\n+        Expression sourceStrExpression = getSourceStrExpression();\n+        if (!sourceStrExpression.evaluate(tuple, ptr)) {\n+            return false;\n+        }\n+        TYPE.coerceBytes(ptr, TYPE, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n+\n+        pattern.replaceAll(ptr, rStrBytes, rStrOffset, rStrLen);\n         return true;\n     }\n \n     private Expression getSourceStrExpression() {\n         return children.get(0);\n     }\n \n+    private Expression getPatternStrExpression() {\n+        return children.get(1);\n+    }\n+\n     private Expression getReplaceStrExpression() {\n         return children.get(2);\n     }",
                "deletions": 23
            },
            {
                "sha": "c663188f62f26e51ddb353fa448ff161121b03a6",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java",
                "status": "modified",
                "changes": 59,
                "additions": 34,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/function/RegexpSplitFunction.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -22,8 +22,8 @@\n import java.util.List;\n \n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.phoenix.expression.Determinism;\n import org.apache.phoenix.expression.Expression;\n-import org.apache.phoenix.expression.LiteralExpression;\n import org.apache.phoenix.expression.util.regex.AbstractBaseSplitter;\n import org.apache.phoenix.parse.FunctionParseNode;\n import org.apache.phoenix.parse.RegexpSplitParseNode;\n@@ -53,6 +53,8 @@\n \n     public static final String NAME = \"REGEXP_SPLIT\";\n \n+    private static final PVarchar TYPE = PVarchar.INSTANCE;\n+\n     private AbstractBaseSplitter initializedSplitter = null;\n \n     public RegexpSplitFunction() {}\n@@ -63,11 +65,12 @@ public RegexpSplitFunction(List<Expression> children) {\n     }\n \n     private void init() {\n-        Expression patternExpression = children.get(1);\n-        if (patternExpression instanceof LiteralExpression) {\n-            Object patternValue = ((LiteralExpression) patternExpression).getValue();\n-            if (patternValue != null) {\n-                initializedSplitter = compilePatternSpec(patternValue.toString());\n+        ImmutableBytesWritable ptr = new ImmutableBytesWritable();\n+        Expression e = getPatternStrExpression();\n+        if (e.isStateless() && e.getDeterminism() == Determinism.ALWAYS && e.evaluate(null, ptr)) {\n+            String pattern = (String) TYPE.toObject(ptr, TYPE, e.getSortOrder());\n+            if (pattern != null) {\n+                initializedSplitter = compilePatternSpec(pattern);\n             }\n         }\n     }\n@@ -87,31 +90,37 @@ public String getName() {\n \n     @Override\n     public boolean evaluate(Tuple tuple, ImmutableBytesWritable ptr) {\n-        if (!children.get(0).evaluate(tuple, ptr)) {\n-            return false;\n-        }\n-\n-        Expression sourceStrExpression = children.get(0);\n-        PVarchar type = PVarchar.INSTANCE;\n-        type.coerceBytes(ptr, type, sourceStrExpression.getSortOrder(), SortOrder.ASC);\n-\n         AbstractBaseSplitter splitter = initializedSplitter;\n         if (splitter == null) {\n-            ImmutableBytesWritable tmpPtr = new ImmutableBytesWritable();\n-            Expression patternExpression = children.get(1);\n-            if (!patternExpression.evaluate(tuple, tmpPtr)) {\n+            Expression e = getPatternStrExpression();\n+            if (e.evaluate(tuple, ptr)) {\n+                String pattern = (String) TYPE.toObject(ptr, TYPE, e.getSortOrder());\n+                if (pattern != null) {\n+                    splitter = compilePatternSpec(pattern);\n+                } else {\n+                    ptr.set(ByteUtil.EMPTY_BYTE_ARRAY); // set ptr to null\n+                    return true;\n+                }\n+            } else {\n                 return false;\n             }\n-            if (tmpPtr.getLength() == 0) {\n-                ptr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n-                return true; // set ptr to null\n-            }\n-            String patternStr =\n-                    (String) PVarchar.INSTANCE.toObject(tmpPtr, patternExpression.getSortOrder());\n-            splitter = compilePatternSpec(patternStr);\n         }\n \n-        return splitter.split(ptr, ptr);\n+        Expression e = getSourceStrExpression();\n+        if (!e.evaluate(tuple, ptr)) {\n+            return false;\n+        }\n+        TYPE.coerceBytes(ptr, TYPE, e.getSortOrder(), SortOrder.ASC);\n+\n+        return splitter.split(ptr);\n+    }\n+\n+    private Expression getSourceStrExpression() {\n+        return children.get(0);\n+    }\n+\n+    private Expression getPatternStrExpression() {\n+        return children.get(1);\n     }\n \n     @Override",
                "deletions": 25
            },
            {
                "sha": "922c7c94bcbe173e61c93e5a0cec3bb707830d6b",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBasePattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -21,10 +21,10 @@\n \n public abstract class AbstractBasePattern {\n \n-    public abstract void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr);\n+    public abstract void matches(ImmutableBytesWritable srcPtr);\n \n-    public abstract void replaceAll(ImmutableBytesWritable srcPtr,\n-            ImmutableBytesWritable replacePtr, ImmutableBytesWritable outPtr);\n+    public abstract void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes,\n+            int rStrOffset, int rStrLen);\n \n     public abstract void substr(ImmutableBytesWritable srcPtr, int offsetInStr);\n ",
                "deletions": 3
            },
            {
                "sha": "756533895e2aaa81bf9c44a2cfa79e8361ea0def",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/AbstractBaseSplitter.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -20,5 +20,5 @@\n import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n \n public abstract interface AbstractBaseSplitter {\n-    public abstract boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr);\n+    public abstract boolean split(ImmutableBytesWritable srcPtr);\n }",
                "deletions": 1
            },
            {
                "sha": "1f53526801585f33b024b802ea1ce2df2c367ba1",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/GuavaSplitter.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -40,14 +40,14 @@ public GuavaSplitter(String patternString) {\n     }\n \n     @Override\n-    public boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public boolean split(ImmutableBytesWritable srcPtr) {\n         String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n         if (sourceStr == null) { // sourceStr evaluated to null\n-            outPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n+            srcPtr.set(ByteUtil.EMPTY_BYTE_ARRAY);\n         } else {\n             List<String> splitStrings = Lists.newArrayList(splitter.split(sourceStr));\n             PhoenixArray splitArray = new PhoenixArray(PVarchar.INSTANCE, splitStrings.toArray());\n-            outPtr.set(PVarcharArray.INSTANCE.toBytes(splitArray));\n+            srcPtr.set(PVarcharArray.INSTANCE.toBytes(splitArray));\n         }\n         return true;\n     }",
                "deletions": 3
            },
            {
                "sha": "69f9eaf0cd7554da2d4ce89739dd77c206693cb3",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java",
                "status": "modified",
                "changes": 22,
                "additions": 10,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JONIPattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -60,11 +60,10 @@ public JONIPattern(String patternString, int flags, Encoding coding) {\n     }\n \n     @Override\n-    public void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public void matches(ImmutableBytesWritable srcPtr) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n         boolean ret = matches(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength());\n-        outPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n+        srcPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n     }\n \n     private boolean matches(byte[] bytes, int offset, int len) {\n@@ -80,15 +79,14 @@ public String pattern() {\n     }\n \n     @Override\n-    public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable replacePtr,\n-            ImmutableBytesWritable replacedPtr) {\n+    public void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes, int rStrOffset,\n+            int rStrLen) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(replacePtr);\n-        Preconditions.checkNotNull(replacedPtr);\n+        Preconditions.checkNotNull(rStrBytes);\n         byte[] replacedBytes =\n-                replaceAll(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), replacePtr.get(),\n-                    replacePtr.getOffset(), replacePtr.getLength());\n-        replacedPtr.set(replacedBytes);\n+                replaceAll(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), rStrBytes,\n+                    rStrOffset, rStrLen);\n+        srcPtr.set(replacedBytes);\n     }\n \n     private byte[] replaceAll(byte[] srcBytes, int srcOffset, int srcLen, byte[] replaceBytes,\n@@ -154,8 +152,8 @@ private boolean substr(byte[] srcBytes, int offset, int range, ImmutableBytesWri\n     }\n \n     @Override\n-    public boolean split(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n-        return split(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), outPtr);\n+    public boolean split(ImmutableBytesWritable srcPtr) {\n+        return split(srcPtr.get(), srcPtr.getOffset(), srcPtr.getLength(), srcPtr);\n     }\n \n     private boolean",
                "deletions": 12
            },
            {
                "sha": "707bced65e5ef919e00d0ee32d0fb0685693de23",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java",
                "status": "modified",
                "changes": 20,
                "additions": 9,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/expression/util/regex/JavaPattern.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -44,13 +44,12 @@ public JavaPattern(String patternString, int flags) {\n     }\n \n     @Override\n-    public void matches(ImmutableBytesWritable srcPtr, ImmutableBytesWritable outPtr) {\n+    public void matches(ImmutableBytesWritable srcPtr) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(outPtr);\n         String matcherSourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n         if (srcPtr.get().length == 0 && matcherSourceStr == null) matcherSourceStr = \"\";\n         boolean ret = pattern.matcher(matcherSourceStr).matches();\n-        outPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n+        srcPtr.set(ret ? PDataType.TRUE_BYTES : PDataType.FALSE_BYTES);\n     }\n \n     @Override\n@@ -59,17 +58,16 @@ public String pattern() {\n     }\n \n     @Override\n-    public void replaceAll(ImmutableBytesWritable srcPtr, ImmutableBytesWritable replacePtr,\n-            ImmutableBytesWritable replacedPtr) {\n+    public void replaceAll(ImmutableBytesWritable srcPtr, byte[] rStrBytes, int rStrOffset,\n+            int rStrLen) {\n         Preconditions.checkNotNull(srcPtr);\n-        Preconditions.checkNotNull(replacePtr);\n-        Preconditions.checkNotNull(replacedPtr);\n+        Preconditions.checkNotNull(rStrBytes);\n         String sourceStr = (String) PVarchar.INSTANCE.toObject(srcPtr);\n-        String replaceStr = (String) PVarchar.INSTANCE.toObject(replacePtr);\n-        if (srcPtr.get().length == 0 && sourceStr == null) sourceStr = \"\";\n-        if (replacePtr.get().length == 0 && replaceStr == null) replaceStr = \"\";\n+        String replaceStr = (String) PVarchar.INSTANCE.toObject(rStrBytes, rStrOffset, rStrLen);\n+        if (srcPtr.getLength() == 0 && sourceStr == null) sourceStr = \"\";\n+        if (rStrLen == 0 && replaceStr == null) replaceStr = \"\";\n         String replacedStr = pattern.matcher(sourceStr).replaceAll(replaceStr);\n-        replacedPtr.set(PVarchar.INSTANCE.toBytes(replacedStr));\n+        srcPtr.set(PVarchar.INSTANCE.toBytes(replacedStr));\n     }\n \n     @Override",
                "deletions": 11
            },
            {
                "sha": "6722a71fb78aace3a3869f0e63dd021b2f3fac75",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/3f294aa962dc9e31ffe19200f78623590eb68a36/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java",
                "status": "modified",
                "changes": 13,
                "additions": 10,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/expression/util/regex/PatternPerformanceTest.java?ref=3f294aa962dc9e31ffe19200f78623590eb68a36",
                "patch": "@@ -63,7 +63,10 @@ private void testReplaceAll(ImmutableBytesWritable replacePtr, AbstractBasePatte\n             String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            pattern.replaceAll(dataPtr[i % 3], replacePtr, resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            pattern.replaceAll(resultPtr, replacePtr.get(), replacePtr.getOffset(),\n+                replacePtr.getLength());\n             if (ENABLE_ASSERT) {\n                 String result = (String) PVarchar.INSTANCE.toObject(resultPtr);\n                 assertTrue((i % 3 == 1 && \":\".equals(result))\n@@ -83,7 +86,9 @@ public void testReplaceAll() {\n     private void testLike(AbstractBasePattern pattern, String name) {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            pattern.matches(dataPtr[i % 3], resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            pattern.matches(resultPtr);\n             if (ENABLE_ASSERT) {\n                 Boolean b = (Boolean) PBoolean.INSTANCE.toObject(resultPtr);\n                 assertTrue(i % 3 != 2 || b.booleanValue());\n@@ -120,7 +125,9 @@ public void testSubstr() {\n     private void testSplit(AbstractBaseSplitter pattern, String name) throws SQLException {\n         timer.reset();\n         for (int i = 0; i < maxTimes; ++i) {\n-            boolean ret = pattern.split(dataPtr[i % 3], resultPtr);\n+            ImmutableBytesWritable ptr = dataPtr[i % 3];\n+            resultPtr.set(ptr.get(), ptr.getOffset(), ptr.getLength());\n+            boolean ret = pattern.split(resultPtr);\n             if (ENABLE_ASSERT) {\n                 PhoenixArray array = (PhoenixArray) PVarcharArray.INSTANCE.toObject(resultPtr);\n                 assertTrue(ret && (i % 3 != 1 || ((String[]) array.getArray()).length == 2));",
                "deletions": 3
            }
        ],
        "patched_files": [
            "GuavaSplitter.java",
            "LikeExpression.java",
            "AbstractBaseSplitter.java",
            "RegexpReplaceFunction.java",
            "JavaPattern.java",
            "RegexpSplitFunction.java",
            "JONIPattern.java",
            "AbstractBasePattern.java"
        ],
        "unit_tests": [
            "RegexpReplaceFunctionTest.java",
            "LikeExpressionTest.java",
            "RegexpSplitFunctionTest.java",
            "PatternPerformanceTest.java"
        ]
    },
    "phoenix_5097982": {
        "repo": "phoenix",
        "message": "PHOENIX-2276 Creating index on a global view on a multi-tenant table fails with NPE",
        "commit": "https://github.com/apache/phoenix/commit/5097982b00b36b74fb328afaab02159e81b21af0",
        "parent": "https://github.com/apache/phoenix/commit/4f6ee74c0a7b94282575300cfd698e78198685fb",
        "bug_id": "phoenix_5097982",
        "file": [
            {
                "sha": "0703e82aab2aedbe097613c3d0dd5eb139741d3a",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java",
                "status": "modified",
                "changes": 4,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/BaseTenantSpecificViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -140,9 +140,9 @@ private void createAndVerifyIndex(Connection conn, Integer saltBuckets, String t\n                             + \"CLIENT MERGE SORT\", QueryUtil.getExplainPlan(rs));\n         } else {\n             String expected = saltBuckets == null ? \n-                    \"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['\" + tenantId + \"',-32768,'\" + valuePrefix + \"v2-1']\\n\"\n+                    \"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32768,'\" + tenantId + \"','\" + valuePrefix + \"v2-1']\\n\"\n                             + \"    SERVER FILTER BY FIRST KEY ONLY\" :\n-                    \"CLIENT PARALLEL 3-WAY RANGE SCAN OVER _IDX_T [0,'\" + tenantId + \"',-32768,'\" + valuePrefix + \"v2-1']\\n\"\n+                    \"CLIENT PARALLEL 3-WAY RANGE SCAN OVER _IDX_T [0,-32768,'\" + tenantId + \"','\" + valuePrefix + \"v2-1']\\n\"\n                   + \"    SERVER FILTER BY FIRST KEY ONLY\\n\"\n                   + \"CLIENT MERGE SORT\";\n             assertEquals(expected, QueryUtil.getExplainPlan(rs));",
                "deletions": 2
            },
            {
                "sha": "f468d2003bf28bc79499c3d9e53a8676499d517a",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/TenantSpecificViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -206,7 +206,7 @@ private void createViewAndIndexesWithTenantId(String tableName,String baseViewNa\n             assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER \"\n                     + Bytes.toString(MetaDataUtil.getViewIndexPhysicalName(SchemaUtil\n                             .getPhysicalHBaseTableName(tableName, isNamespaceMapped, PTableType.TABLE).getBytes()))\n-                    + \" ['\" + tenantId + \"',-32768,'f']\\n\" + \"    SERVER FILTER BY FIRST KEY ONLY\",\n+                    + \" [-32768,'\" + tenantId + \"','f']\\n\" + \"    SERVER FILTER BY FIRST KEY ONLY\",\n                     QueryUtil.getExplainPlan(rs));\n         }\n ",
                "deletions": 1
            },
            {
                "sha": "4da62de659fa9197452eb406626e0c35a1e1d32e",
                "filename": "phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java",
                "status": "modified",
                "changes": 34,
                "additions": 34,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/it/java/org/apache/phoenix/end2end/index/ViewIndexIT.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -22,6 +22,7 @@\n import static org.junit.Assert.assertTrue;\n \n import java.sql.Connection;\n+import java.sql.Date;\n import java.sql.DriverManager;\n import java.sql.PreparedStatement;\n import java.sql.ResultSet;\n@@ -33,9 +34,11 @@\n \n import org.apache.hadoop.hbase.TableName;\n import org.apache.hadoop.hbase.client.HBaseAdmin;\n+import org.apache.phoenix.compile.QueryPlan;\n import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n import org.apache.phoenix.end2end.Shadower;\n import org.apache.phoenix.jdbc.PhoenixDatabaseMetaData;\n+import org.apache.phoenix.jdbc.PhoenixStatement;\n import org.apache.phoenix.query.QueryServices;\n import org.apache.phoenix.schema.PNameFactory;\n import org.apache.phoenix.util.MetaDataUtil;\n@@ -191,4 +194,35 @@ public void testMultiTenantViewLocalIndex() throws Exception {\n         assertTrue(rs.next());\n         assertFalse(rs.next());\n     }\n+    \n+    @Test\n+    public void testCreatingIndexOnGlobalView() throws Exception {\n+        String baseTable = \"testCreatingIndexOnGlobalView\".toUpperCase();\n+        String globalView = \"globalView\".toUpperCase();\n+        String globalViewIdx = \"globalView_idx\".toUpperCase();\n+        try (Connection conn = DriverManager.getConnection(getUrl())) {\n+            conn.createStatement().execute(\"CREATE TABLE \" + baseTable + \" (TENANT_ID CHAR(15) NOT NULL, PK2 DATE NOT NULL, PK3 INTEGER NOT NULL, KV1 VARCHAR, KV2 VARCHAR, KV3 CHAR(15) CONSTRAINT PK PRIMARY KEY(TENANT_ID, PK2 ROW_TIMESTAMP, PK3)) MULTI_TENANT=true\");\n+            conn.createStatement().execute(\"CREATE VIEW \" + globalView + \" AS SELECT * FROM \" + baseTable);\n+            conn.createStatement().execute(\"CREATE INDEX \" + globalViewIdx + \" ON \" + globalView + \" (PK3 DESC, KV3) INCLUDE (KV1)\");\n+            PreparedStatement stmt = conn.prepareStatement(\"UPSERT INTO  \" + globalView + \" (TENANT_ID, PK2, PK3, KV1, KV3) VALUES (?, ?, ?, ?, ?)\");\n+            stmt.setString(1, \"tenantId\");\n+            stmt.setDate(2, new Date(100));\n+            stmt.setInt(3, 1);\n+            stmt.setString(4, \"KV1\");\n+            stmt.setString(5, \"KV3\");\n+            stmt.executeUpdate();\n+            conn.commit();\n+            \n+            // Verify that query against the global view index works\n+            stmt = conn.prepareStatement(\"SELECT KV1 FROM  \" + globalView + \" WHERE PK3 = ? AND KV3 = ?\");\n+            stmt.setInt(1, 1);\n+            stmt.setString(2, \"KV3\");\n+            ResultSet rs = stmt.executeQuery();\n+            QueryPlan plan = stmt.unwrap(PhoenixStatement.class).getQueryPlan();\n+            assertTrue(plan.getTableRef().getTable().getName().getString().equals(globalViewIdx));\n+            assertTrue(rs.next());\n+            assertEquals(\"KV1\", rs.getString(1));\n+            assertFalse(rs.next());\n+        }\n+    }\n }\n\\ No newline at end of file",
                "deletions": 0
            },
            {
                "sha": "d88b094644dc96c12bbb98594d2d2653d5080db7",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java",
                "status": "modified",
                "changes": 40,
                "additions": 24,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/cache/ServerCacheClient.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -195,18 +195,22 @@ public AddServerCacheResponse call(ServerCachingService instance) throws IOExcep\n                                                     BlockingRpcCallback<AddServerCacheResponse> rpcCallback =\n                                                             new BlockingRpcCallback<AddServerCacheResponse>();\n                                                     AddServerCacheRequest.Builder builder = AddServerCacheRequest.newBuilder();\n-                                                    if(connection.getTenantId() != null){\n+                                                    final byte[] tenantIdBytes;\n+                                                    if(cacheUsingTable.isMultiTenant()) {\n                                                         try {\n-                                                            byte[] tenantIdBytes =\n+                                                            tenantIdBytes = connection.getTenantId() == null ? null :\n                                                                     ScanUtil.getTenantIdBytes(\n                                                                             cacheUsingTable.getRowKeySchema(),\n-                                                                            cacheUsingTable.getBucketNum()!=null,\n-                                                                            connection.getTenantId(),\n-                                                                            cacheUsingTable.isMultiTenant());\n-                                                            builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                                                            cacheUsingTable.getBucketNum() != null,\n+                                                                            connection.getTenantId(), cacheUsingTable.getViewIndexId() != null);\n                                                         } catch (SQLException e) {\n-                                                            new IOException(e);\n+                                                            throw new IOException(e);\n                                                         }\n+                                                    } else {\n+                                                        tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n+                                                    }\n+                                                    if (tenantIdBytes != null) {\n+                                                        builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n                                                     }\n                                                     builder.setCacheId(ByteStringer.wrap(cacheId));\n                                                     builder.setCachePtr(org.apache.phoenix.protobuf.ProtobufUtil.toProto(cachePtr));\n@@ -325,20 +329,24 @@ public RemoveServerCacheResponse call(ServerCachingService instance) throws IOEx\n     \t\t\t\t\t\t\tBlockingRpcCallback<RemoveServerCacheResponse> rpcCallback =\n     \t\t\t\t\t\t\t\t\tnew BlockingRpcCallback<RemoveServerCacheResponse>();\n     \t\t\t\t\t\t\tRemoveServerCacheRequest.Builder builder = RemoveServerCacheRequest.newBuilder();\n-    \t\t\t\t\t\t\tif(connection.getTenantId() != null){\n+                                final byte[] tenantIdBytes;\n+                                if(cacheUsingTable.isMultiTenant()) {\n                                     try {\n-                                        byte[] tenantIdBytes =\n+                                        tenantIdBytes = connection.getTenantId() == null ? null :\n                                                 ScanUtil.getTenantIdBytes(\n                                                         cacheUsingTable.getRowKeySchema(),\n-                                                        cacheUsingTable.getBucketNum()!=null,\n-                                                        connection.getTenantId(),\n-                                                        cacheUsingTable.isMultiTenant());\n-                                        builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                                        cacheUsingTable.getBucketNum() != null,\n+                                                        connection.getTenantId(), cacheUsingTable.getViewIndexId() != null);\n                                     } catch (SQLException e) {\n-                                        new IOException(e);\n+                                        throw new IOException(e);\n                                     }\n-    \t\t\t\t\t\t\t}\n-    \t\t\t\t\t\t\tbuilder.setCacheId(ByteStringer.wrap(cacheId));\n+                                } else {\n+                                    tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n+                                }\n+                                if (tenantIdBytes != null) {\n+                                    builder.setTenantId(ByteStringer.wrap(tenantIdBytes));\n+                                }\n+                                builder.setCacheId(ByteStringer.wrap(cacheId));\n     \t\t\t\t\t\t\tinstance.removeServerCache(controller, builder.build(), rpcCallback);\n     \t\t\t\t\t\t\tif(controller.getFailedOn() != null) {\n     \t\t\t\t\t\t\t\tthrow controller.getFailedOn();",
                "deletions": 16
            },
            {
                "sha": "504f9948675caa0e5db5937d4662884ca14b0f04",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java",
                "status": "modified",
                "changes": 8,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/DeleteCompiler.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -107,7 +107,7 @@ private static MutationState deleteRows(StatementContext childContext, TableRef\n         PName tenantId = connection.getTenantId();\n         byte[] tenantIdBytes = null;\n         if (tenantId != null) {\n-            tenantIdBytes = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId);\n+            tenantIdBytes = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId, table.getViewIndexId() != null);\n         }\n         final boolean isAutoCommit = connection.getAutoCommit();\n         ConnectionQueryServices services = connection.getQueryServices();\n@@ -125,12 +125,12 @@ private static MutationState deleteRows(StatementContext childContext, TableRef\n         boolean isSharedViewIndex = table.getViewIndexId() != null;\n         int offset = (table.getBucketNum() == null ? 0 : 1);\n         byte[][] values = new byte[pkColumns.size()][];\n-        if (isMultiTenant) {\n-            values[offset++] = tenantIdBytes;\n-        }\n         if (isSharedViewIndex) {\n             values[offset++] = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n         }\n+        if (isMultiTenant) {\n+            values[offset++] = tenantIdBytes;\n+        }\n         try (PhoenixResultSet rs = new PhoenixResultSet(iterator, projector, childContext)) {\n             int rowCount = 0;\n             while (rs.next()) {",
                "deletions": 4
            },
            {
                "sha": "be6499bf1702d805080fd6de74c9341d1f688775",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java",
                "status": "modified",
                "changes": 40,
                "additions": 20,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/UpsertCompiler.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -334,18 +334,18 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                     targetColumns = Lists.newArrayListWithExpectedSize(columnIndexesToBe.length);\n                     targetColumns.addAll(Collections.<PColumn>nCopies(columnIndexesToBe.length, null));\n                     int minPKPos = 0;\n-                    if (isTenantSpecific) {\n-                        PColumn tenantColumn = table.getPKColumns().get(minPKPos);\n-                        columnIndexesToBe[minPKPos] = tenantColumn.getPosition();\n-                        targetColumns.set(minPKPos, tenantColumn);\n-                        minPKPos++;\n-                    }\n                     if (isSharedViewIndex) {\n                         PColumn indexIdColumn = table.getPKColumns().get(minPKPos);\n                         columnIndexesToBe[minPKPos] = indexIdColumn.getPosition();\n                         targetColumns.set(minPKPos, indexIdColumn);\n                         minPKPos++;\n                     }\n+                    if (isTenantSpecific) {\n+                        PColumn tenantColumn = table.getPKColumns().get(minPKPos);\n+                        columnIndexesToBe[minPKPos] = tenantColumn.getPosition();\n+                        targetColumns.set(minPKPos, tenantColumn);\n+                        minPKPos++;\n+                    }\n                     for (int i = posOffset, j = 0; i < allColumnsToBe.size(); i++) {\n                         PColumn column = allColumnsToBe.get(i);\n                         if (SchemaUtil.isPKColumn(column)) {\n@@ -375,6 +375,13 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                     Arrays.fill(pkSlotIndexesToBe, -1); // TODO: necessary? So we'll get an AIOB exception if it's not replaced\n                     BitSet pkColumnsSet = new BitSet(table.getPKColumns().size());\n                     int i = 0;\n+                    if (isSharedViewIndex) {\n+                        PColumn indexIdColumn = table.getPKColumns().get(i + posOffset);\n+                        columnIndexesToBe[i] = indexIdColumn.getPosition();\n+                        pkColumnsSet.set(pkSlotIndexesToBe[i] = i + posOffset);\n+                        targetColumns.set(i, indexIdColumn);\n+                        i++;\n+                    }\n                     // Add tenant column directly, as we don't want to resolve it as this will fail\n                     if (isTenantSpecific) {\n                         PColumn tenantColumn = table.getPKColumns().get(i + posOffset);\n@@ -383,13 +390,6 @@ else if (table.isTransactional() && connection.getSCN() != null) {\n                         targetColumns.set(i, tenantColumn);\n                         i++;\n                     }\n-                    if (isSharedViewIndex) {\n-                        PColumn indexIdColumn = table.getPKColumns().get(i + posOffset);\n-                        columnIndexesToBe[i] = indexIdColumn.getPosition();\n-                        pkColumnsSet.set(pkSlotIndexesToBe[i] = i + posOffset);\n-                        targetColumns.set(i, indexIdColumn);\n-                        i++;\n-                    }\n                     for (ColumnName colName : columnNodes) {\n                         ColumnRef ref = resolver.resolveColumn(null, colName.getFamilyName(), colName.getColumnName());\n                         PColumn column = ref.getColumn();\n@@ -820,13 +820,13 @@ public ExplainPlan getExplainPlan() throws SQLException {\n         /////////////////////////////////////////////////////////////////////\n         final byte[][] values = new byte[nValuesToSet][];\n         int nodeIndex = 0;\n-        if (isTenantSpecific) {\n-            PName tenantId = connection.getTenantId();\n-            values[nodeIndex++] = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId);\n-        }\n         if (isSharedViewIndex) {\n             values[nodeIndex++] = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n         }\n+        if (isTenantSpecific) {\n+            PName tenantId = connection.getTenantId();\n+            values[nodeIndex++] = ScanUtil.getTenantIdBytes(table.getRowKeySchema(), table.getBucketNum() != null, tenantId, isSharedViewIndex);\n+        }\n         \n         final int nodeIndexOffset = nodeIndex;\n         // Allocate array based on size of all columns in table,\n@@ -1015,12 +1015,12 @@ private static SelectStatement prependTenantAndViewConstants(PTable table, Selec\n             return select;\n         }\n         List<AliasedNode> selectNodes = newArrayListWithCapacity(select.getSelect().size() + 1 + addViewColumns.size());\n-        if (table.isMultiTenant() && tenantId != null) {\n-            selectNodes.add(new AliasedNode(null, new LiteralParseNode(tenantId)));\n-        }\n         if (table.getViewIndexId() != null) {\n             selectNodes.add(new AliasedNode(null, new LiteralParseNode(table.getViewIndexId())));\n         }\n+        if (table.isMultiTenant() && tenantId != null) {\n+            selectNodes.add(new AliasedNode(null, new LiteralParseNode(tenantId)));\n+        }\n         selectNodes.addAll(select.getSelect());\n         for (PColumn column : addViewColumns) {\n             byte[] byteValue = column.getViewConstant();",
                "deletions": 20
            },
            {
                "sha": "8c2a216b59781593aaa26d017e3b3418165fac8f",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java",
                "status": "modified",
                "changes": 29,
                "additions": 16,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/compile/WhereOptimizer.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -114,8 +114,10 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n     \tboolean isSalted = nBuckets != null;\n     \tRowKeySchema schema = table.getRowKeySchema();\n     \tboolean isMultiTenant = tenantId != null && table.isMultiTenant();\n+    \tboolean isSharedIndex = table.getViewIndexId() != null;\n+    \t\n     \tif (isMultiTenant) {\n-            tenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId);\n+            tenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId, isSharedIndex);\n     \t}\n \n         if (whereClause == null && (tenantId == null || !table.isMultiTenant()) && table.getViewIndexId() == null) {\n@@ -187,6 +189,19 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             pkPos++;\n         }\n         \n+        // Add unique index ID for shared indexes on views. This ensures\n+        // that different indexes don't interleave.\n+        if (hasViewIndex) {\n+            byte[] viewIndexBytes = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n+            KeyRange indexIdKeyRange = KeyRange.getKeyRange(viewIndexBytes);\n+            cnf.add(singletonList(indexIdKeyRange));\n+            if (hasMinMaxRange) {\n+                System.arraycopy(viewIndexBytes, 0, minMaxRangePrefix, minMaxRangeOffset, viewIndexBytes.length);\n+                minMaxRangeOffset += viewIndexBytes.length;\n+            }\n+            pkPos++;\n+        }\n+        \n         // Add tenant data isolation for tenant-specific tables\n         if (isMultiTenant) {\n             KeyRange tenantIdKeyRange = KeyRange.getKeyRange(tenantIdBytes);\n@@ -202,18 +217,6 @@ public static Expression pushKeyExpressionsToScan(StatementContext context, Filt\n             }\n             pkPos++;\n         }\n-        // Add unique index ID for shared indexes on views. This ensures\n-        // that different indexes don't interleave.\n-        if (hasViewIndex) {\n-            byte[] viewIndexBytes = MetaDataUtil.getViewIndexIdDataType().toBytes(table.getViewIndexId());\n-            KeyRange indexIdKeyRange = KeyRange.getKeyRange(viewIndexBytes);\n-            cnf.add(singletonList(indexIdKeyRange));\n-            if (hasMinMaxRange) {\n-                System.arraycopy(viewIndexBytes, 0, minMaxRangePrefix, minMaxRangeOffset, viewIndexBytes.length);\n-                minMaxRangeOffset += viewIndexBytes.length;\n-            }\n-            pkPos++;\n-        }\n         \n         // Prepend minMaxRange with fixed column values so we can properly intersect the\n         // range with the other range.",
                "deletions": 13
            },
            {
                "sha": "b940084a934d846ffd5645d4c059ad4a13b55c90",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java",
                "status": "modified",
                "changes": 4,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/execute/BaseQueryPlan.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -278,8 +278,8 @@ public final ResultIterator iterator(final List<? extends SQLCloseable> dependen\n             tenantIdBytes = connection.getTenantId() == null ? null :\n                     ScanUtil.getTenantIdBytes(\n                             table.getRowKeySchema(),\n-                            table.getBucketNum()!=null,\n-                            connection.getTenantId());\n+                            table.getBucketNum() != null,\n+                            connection.getTenantId(), table.getViewIndexId() != null);\n         } else {\n             tenantIdBytes = connection.getTenantId() == null ? null : connection.getTenantId().getBytes();\n         }",
                "deletions": 2
            },
            {
                "sha": "db823deec60351db49f17d7ddc1b12b12289954c",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java",
                "status": "modified",
                "changes": 18,
                "additions": 10,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/index/IndexMaintainer.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -476,6 +476,11 @@ private IndexMaintainer(PTable dataTable, PTable index, PhoenixConnection connec\n             // Skip data table salt byte\n             int maxRowKeyOffset = rowKeyPtr.getOffset() + rowKeyPtr.getLength();\n             dataRowKeySchema.iterator(rowKeyPtr, ptr, dataPosOffset);\n+            \n+            if (viewIndexId != null) {\n+                output.write(viewIndexId);\n+            }\n+            \n             if (isMultiTenant) {\n                 dataRowKeySchema.next(ptr, dataPosOffset, maxRowKeyOffset);\n                 output.write(ptr.get(), ptr.getOffset(), ptr.getLength());\n@@ -484,9 +489,6 @@ private IndexMaintainer(PTable dataTable, PTable index, PhoenixConnection connec\n                 }\n                 dataPosOffset++;\n             }\n-            if (viewIndexId != null) {\n-                output.write(viewIndexId);\n-            }\n             \n             // Write index row key\n             for (int i = dataPosOffset; i < dataRowKeySchema.getFieldCount(); i++) {\n@@ -714,11 +716,6 @@ private RowKeySchema generateIndexRowKeySchema() {\n             nIndexedColumns--;\n         }\n         int dataPosOffset = isDataTableSalted ? 1 : 0 ;\n-        if (isMultiTenant) {\n-            Field field = dataRowKeySchema.getField(dataPosOffset++);\n-            builder.addField(field, field.isNullable(), field.getSortOrder());\n-            nIndexedColumns--;\n-        }\n         if (viewIndexId != null) {\n             nIndexedColumns--;\n             builder.addField(new PDatum() {\n@@ -750,6 +747,11 @@ public SortOrder getSortOrder() {\n                 \n             }, false, SortOrder.getDefault());\n         }\n+        if (isMultiTenant) {\n+            Field field = dataRowKeySchema.getField(dataPosOffset++);\n+            builder.addField(field, field.isNullable(), field.getSortOrder());\n+            nIndexedColumns--;\n+        }\n         \n         Field[] indexFields = new Field[nIndexedColumns];\n         BitSet viewConstantColumnBitSet = this.rowKeyMetaData.getViewConstantColumnBitSet();",
                "deletions": 8
            },
            {
                "sha": "d1cbdfc2022797a1f47f7fb418f22aa10f806e67",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java",
                "status": "modified",
                "changes": 194,
                "additions": 189,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/query/ConnectionQueryServicesImpl.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -21,7 +21,17 @@\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_MAJOR_VERSION;\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_MINOR_VERSION;\n import static org.apache.phoenix.coprocessor.MetaDataProtocol.PHOENIX_PATCH_NUMBER;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.COLUMN_FAMILY;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.COLUMN_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.DATA_TABLE_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.INDEX_TYPE;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.ORDINAL_POSITION;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME;\n import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME_BYTES;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TABLE_NAME;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TABLE_SCHEM;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TENANT_ID;\n+import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.VIEW_INDEX_ID;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_DROP_METADATA;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_RENEW_LEASE_ENABLED;\n import static org.apache.phoenix.query.QueryServicesOptions.DEFAULT_RENEW_LEASE_THREAD_POOL_SIZE;\n@@ -31,6 +41,8 @@\n \n import java.io.IOException;\n import java.lang.ref.WeakReference;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n import java.sql.SQLException;\n import java.util.ArrayList;\n import java.util.Arrays;\n@@ -156,6 +168,7 @@\n import org.apache.phoenix.schema.PName;\n import org.apache.phoenix.schema.PNameFactory;\n import org.apache.phoenix.schema.PTable;\n+import org.apache.phoenix.schema.PTable.IndexType;\n import org.apache.phoenix.schema.PTableKey;\n import org.apache.phoenix.schema.PTableType;\n import org.apache.phoenix.schema.ReadOnlyTableException;\n@@ -893,15 +906,15 @@ private void addCoprocessors(byte[] tableName, HTableDescriptor descriptor, PTab\n \n     private static interface RetriableOperation {\n         boolean checkForCompletion() throws TimeoutException, IOException;\n-        String getOperatioName();\n+        String getOperationName();\n     }\n \n     private void pollForUpdatedTableDescriptor(final HBaseAdmin admin, final HTableDescriptor newTableDescriptor,\n             final byte[] tableName) throws InterruptedException, TimeoutException {\n         checkAndRetry(new RetriableOperation() {\n \n             @Override\n-            public String getOperatioName() {\n+            public String getOperationName() {\n                 return \"UpdateOrNewTableDescriptor\";\n             }\n \n@@ -932,7 +945,7 @@ private void checkAndRetry(RetriableOperation op) throws InterruptedException, T\n                 // Else, we swallow the exception and retry till we reach maxRetries.\n                 if (numTries == 1 || numTries == maxRetries) {\n                     watch.stop();\n-                    TimeoutException toThrow = new TimeoutException(\"Operation \" + op.getOperatioName()\n+                    TimeoutException toThrow = new TimeoutException(\"Operation \" + op.getOperationName()\n                             + \" didn't complete because of exception. Time elapsed: \" + watch.elapsedMillis());\n                     toThrow.initCause(ex);\n                     throw toThrow;\n@@ -945,13 +958,13 @@ private void checkAndRetry(RetriableOperation op) throws InterruptedException, T\n         watch.stop();\n \n         if (!success) {\n-            throw new TimeoutException(\"Operation  \" + op.getOperatioName() + \" didn't complete within \"\n+            throw new TimeoutException(\"Operation  \" + op.getOperationName() + \" didn't complete within \"\n                     + watch.elapsedMillis() + \" ms \"\n                     + (numTries > 1 ? (\"after trying \" + numTries + (numTries > 1 ? \"times.\" : \"time.\")) : \"\"));\n         } else {\n             if (logger.isDebugEnabled()) {\n                 logger.debug(\"Operation \"\n-                        + op.getOperatioName()\n+                        + op.getOperationName()\n                         + \" completed within \"\n                         + watch.elapsedMillis()\n                         + \"ms \"\n@@ -2493,6 +2506,7 @@ public Void call() throws Exception {\n                                             MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP_4_8_0,\n                                             PhoenixDatabaseMetaData.APPEND_ONLY_SCHEMA + \" \"\n                                                     + PBoolean.INSTANCE.getSqlTypeName());\n+                                    metaConnection = disableViewIndexes(metaConnection);\n                                     ConnectionQueryServicesImpl.this.removeTable(null,\n                                             PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME, null,\n                                             MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP_4_8_0);\n@@ -2710,6 +2724,176 @@ private PhoenixConnection setImmutableTableIndexesImmutable(PhoenixConnection ol\n         }\n         return metaConnection;\n     }\n+    \n+    private PhoenixConnection disableViewIndexes(PhoenixConnection connParam) throws SQLException, IOException, InterruptedException, TimeoutException {\n+        Properties props = PropertiesUtil.deepCopy(connParam.getClientInfo());\n+        Long originalScn = null;\n+        String str = props.getProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB);\n+        if (str != null) {\n+            originalScn = Long.valueOf(str);\n+        }\n+        // don't use the passed timestamp as scn because we want to query all view indexes up to now.\n+        props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(HConstants.LATEST_TIMESTAMP));\n+        Set<String> physicalTables = new HashSet<>();\n+        SQLException sqlEx = null;\n+        PhoenixConnection globalConnection = null;\n+        PhoenixConnection toReturn = null;\n+        try {\n+            globalConnection = new PhoenixConnection(connParam, this, props);\n+            String tenantId = null;\n+            try (HBaseAdmin admin = getAdmin()) {\n+                String fetchViewIndexes = \"SELECT \" + TENANT_ID + \", \" + TABLE_SCHEM + \", \" + TABLE_NAME + \n+                        \", \" + DATA_TABLE_NAME + \" FROM \" + SYSTEM_CATALOG_NAME + \" WHERE \" + VIEW_INDEX_ID\n+                        + \" IS NOT NULL AND \" + INDEX_TYPE + \"<>\" + IndexType.LOCAL.getSerializedValue();\n+                String disableIndexDDL = \"ALTER INDEX %s ON %s DISABLE\"; \n+                try (ResultSet rs = globalConnection.createStatement().executeQuery(fetchViewIndexes)) {\n+                    while (rs.next()) {\n+                        tenantId = rs.getString(1);\n+                        String indexSchema = rs.getString(2);\n+                        String indexName = rs.getString(3);\n+                        String viewName = rs.getString(4);\n+                        String fullIndexName = SchemaUtil.getTableName(indexSchema, indexName);\n+                        PTable viewPTable = null;\n+                        // Disable the view index and truncate the underlying hbase table. \n+                        // Users would need to rebuild the view indexes. \n+                        if (tenantId != null && !tenantId.isEmpty()) {\n+                            Properties newProps = PropertiesUtil.deepCopy(globalConnection.getClientInfo());\n+                            newProps.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB, tenantId);\n+                            PTable indexPTable = null;\n+                            try (PhoenixConnection tenantConnection = new PhoenixConnection(globalConnection, this, newProps)) {\n+                                viewPTable = PhoenixRuntime.getTable(tenantConnection, viewName);\n+                                tenantConnection.createStatement().execute(String.format(disableIndexDDL, fullIndexName, viewName));\n+                                indexPTable = PhoenixRuntime.getTable(tenantConnection, fullIndexName);\n+                            }\n+\n+                            int offset = indexPTable.getBucketNum() != null ? 1 : 0;\n+                            int existingTenantIdPosition = ++offset; // positions are stored 1 based\n+                            int existingViewIdxIdPosition = ++offset;\n+                            int newTenantIdPosition = existingViewIdxIdPosition;\n+                            int newViewIdxPosition = existingTenantIdPosition;\n+                            String tenantIdColumn = indexPTable.getColumns().get(existingTenantIdPosition - 1).getName().getString();\n+                            int index = 0;\n+                            String updatePosition =\n+                                    \"UPSERT INTO \"\n+                                            + SYSTEM_CATALOG_NAME\n+                                            + \" ( \"\n+                                            + TENANT_ID\n+                                            + \",\"\n+                                            + TABLE_SCHEM\n+                                            + \",\"\n+                                            + TABLE_NAME\n+                                            + \",\"\n+                                            + COLUMN_NAME\n+                                            + \",\"\n+                                            + COLUMN_FAMILY\n+                                            + \",\"\n+                                            + ORDINAL_POSITION\n+                                            + \") SELECT \"\n+                                            + TENANT_ID\n+                                            + \",\"\n+                                            + TABLE_SCHEM\n+                                            + \",\"\n+                                            + TABLE_NAME\n+                                            + \",\"\n+                                            + COLUMN_NAME\n+                                            + \",\"\n+                                            + COLUMN_FAMILY\n+                                            + \",\"\n+                                            + \"?\"\n+                                            + \" FROM \"\n+                                            + SYSTEM_CATALOG_NAME\n+                                            + \" WHERE \"\n+                                            + TENANT_ID\n+                                            + \" = ? \"\n+                                            + \" AND \"\n+                                            + TABLE_NAME\n+                                            + \" = ? \"\n+                                            + \" AND \"\n+                                            + (indexSchema == null ? TABLE_SCHEM + \" IS NULL\" : TABLE_SCHEM + \" = ? \") \n+                                            + \" AND \"\n+                                            + COLUMN_NAME \n+                                            + \" = ? \";\n+                            // update view index position\n+                            try (PreparedStatement s = globalConnection.prepareStatement(updatePosition)) {\n+                                index = 0;\n+                                s.setInt(++index, newViewIdxPosition);\n+                                s.setString(++index, tenantId);\n+                                s.setString(++index, indexName);\n+                                if (indexSchema != null) {\n+                                    s.setString(++index, indexSchema);\n+                                }\n+                                s.setString(++index, MetaDataUtil.getViewIndexIdColumnName());\n+                                s.executeUpdate();\n+                            }\n+                            // update tenant id position\n+                            try (PreparedStatement s = globalConnection.prepareStatement(updatePosition)) {\n+                                index = 0;\n+                                s.setInt(++index, newTenantIdPosition);\n+                                s.setString(++index, tenantId);\n+                                s.setString(++index, indexName);\n+                                if (indexSchema != null) {\n+                                    s.setString(++index, indexSchema);\n+                                }\n+                                s.setString(++index, tenantIdColumn);\n+                                s.executeUpdate();\n+                            }\n+                            globalConnection.commit();\n+                        } else {\n+                            viewPTable = PhoenixRuntime.getTable(globalConnection, viewName);\n+                            globalConnection.createStatement().execute(String.format(disableIndexDDL, fullIndexName, viewName));\n+                        }\n+                        String indexPhysicalTableName = MetaDataUtil.getViewIndexTableName(viewPTable.getPhysicalName().getString());\n+                        if (physicalTables.add(indexPhysicalTableName)) {\n+                            final TableName tableName = TableName.valueOf(indexPhysicalTableName);\n+                            admin.disableTableAsync(tableName);\n+                            checkAndRetry(new RetriableOperation() {\n+                                @Override\n+                                public boolean checkForCompletion() throws TimeoutException,\n+                                IOException {\n+                                    return admin.isTableDisabled(tableName);\n+                                }\n+\n+                                @Override\n+                                public String getOperationName() {\n+                                    return \"Disable table: \" + tableName.getNameAsString();\n+                                }\n+\n+                            });\n+                            admin.truncateTable(tableName, false);\n+                        }\n+                    }\n+                }\n+            }\n+            if (originalScn != null) {\n+                props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB, Long.toString(originalScn));\n+            }\n+            toReturn = new PhoenixConnection(globalConnection, this, props);\n+        } catch (SQLException e) {\n+            sqlEx = e;\n+        } finally {\n+            sqlEx = closeConnection(connParam, sqlEx);\n+            sqlEx = closeConnection(globalConnection, sqlEx);\n+            if (sqlEx != null) {\n+                throw sqlEx;\n+            }\n+        }\n+        return toReturn;\n+    }\n+    \n+    \n+    private static SQLException closeConnection(PhoenixConnection conn, SQLException sqlEx) {\n+        SQLException toReturn = sqlEx;\n+        try {\n+            conn.close();\n+        } catch (SQLException e) {\n+            if (toReturn != null) {\n+                toReturn.setNextException(e);\n+            } else {\n+                toReturn = e;\n+            }\n+        }\n+        return toReturn;\n+    }\n \n     /**\n      * Forces update of SYSTEM.CATALOG by setting column to existing value",
                "deletions": 5
            },
            {
                "sha": "3a4010bab3a93a4c5071b51b7a8fd1cdb5dd5198",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java",
                "status": "modified",
                "changes": 21,
                "additions": 10,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/schema/MetaDataClient.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -1316,30 +1316,29 @@ public MutationState createIndex(CreateIndexStatement statement, byte[][] splits\n                 List<ColumnDefInPkConstraint> allPkColumns = Lists.newArrayListWithExpectedSize(unusedPkColumns.size());\n                 List<ColumnDef> columnDefs = Lists.newArrayListWithExpectedSize(includedColumns.size() + indexParseNodeAndSortOrderList.size());\n                 \n-                if (dataTable.isMultiTenant()) {\n-                    // Add tenant ID column as first column in index\n-                    PColumn col = dataTable.getPKColumns().get(posOffset);\n-                    RowKeyColumnExpression columnExpression = new RowKeyColumnExpression(col, new RowKeyValueAccessor(pkColumns, posOffset), col.getName().getString());\n-                    unusedPkColumns.remove(columnExpression);\n-                    PDataType dataType = IndexUtil.getIndexColumnDataType(col);\n-                    ColumnName colName = ColumnName.caseSensitiveColumnName(IndexUtil.getIndexColumnName(col));\n-                    allPkColumns.add(new ColumnDefInPkConstraint(colName, col.getSortOrder(), false));\n-                    columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), col.isNullable(), col.getMaxLength(), col.getScale(), false, SortOrder.getDefault(), col.getName().getString(), col.isRowTimestamp()));\n-                }\n                 /*\n                  * Allocate an index ID in two circumstances:\n                  * 1) for a local index, as all local indexes will reside in the same HBase table\n                  * 2) for a view on an index.\n                  */\n                 if (isLocalIndex || (dataTable.getType() == PTableType.VIEW && dataTable.getViewType() != ViewType.MAPPED)) {\n                     allocateIndexId = true;\n-                    // Next add index ID column\n                     PDataType dataType = MetaDataUtil.getViewIndexIdDataType();\n                     ColumnName colName = ColumnName.caseSensitiveColumnName(MetaDataUtil.getViewIndexIdColumnName());\n                     allPkColumns.add(new ColumnDefInPkConstraint(colName, SortOrder.getDefault(), false));\n                     columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), false, null, null, false, SortOrder.getDefault(), null, false));\n                 }\n                 \n+                if (dataTable.isMultiTenant()) {\n+                    PColumn col = dataTable.getPKColumns().get(posOffset);\n+                    RowKeyColumnExpression columnExpression = new RowKeyColumnExpression(col, new RowKeyValueAccessor(pkColumns, posOffset), col.getName().getString());\n+                    unusedPkColumns.remove(columnExpression);\n+                    PDataType dataType = IndexUtil.getIndexColumnDataType(col);\n+                    ColumnName colName = ColumnName.caseSensitiveColumnName(IndexUtil.getIndexColumnName(col));\n+                    allPkColumns.add(new ColumnDefInPkConstraint(colName, col.getSortOrder(), false));\n+                    columnDefs.add(FACTORY.columnDef(colName, dataType.getSqlTypeName(), col.isNullable(), col.getMaxLength(), col.getScale(), false, SortOrder.getDefault(), col.getName().getString(), col.isRowTimestamp()));\n+                }\n+                \n                 PhoenixStatement phoenixStatment = new PhoenixStatement(connection);\n                 StatementContext context = new StatementContext(phoenixStatment, resolver);\n                 IndexExpressionCompiler expressionIndexCompiler = new IndexExpressionCompiler(context);",
                "deletions": 11
            },
            {
                "sha": "ae81d378a11678ddb1f999d4524713b90e6f0ceb",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/MetaDataUtil.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -93,7 +93,7 @@\n     public static final String VIEW_INDEX_SEQUENCE_PREFIX = \"_SEQ_\";\n     public static final String VIEW_INDEX_SEQUENCE_NAME_PREFIX = \"_ID_\";\n     public static final byte[] VIEW_INDEX_SEQUENCE_PREFIX_BYTES = Bytes.toBytes(VIEW_INDEX_SEQUENCE_PREFIX);\n-    public static final String VIEW_INDEX_ID_COLUMN_NAME = \"_INDEX_ID\";\n+    private static final String VIEW_INDEX_ID_COLUMN_NAME = \"_INDEX_ID\";\n     public static final String PARENT_TABLE_KEY = \"PARENT_TABLE\";\n     public static final byte[] PARENT_TABLE_KEY_BYTES = Bytes.toBytes(\"PARENT_TABLE\");\n     ",
                "deletions": 1
            },
            {
                "sha": "e68c8d4078b4b459b15be79dcabe5d9ef871c056",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java",
                "status": "modified",
                "changes": 3,
                "additions": 2,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/PhoenixRuntime.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -1056,7 +1056,8 @@ private static Expression getFirstPKColumnExpression(PTable table) throws SQLExc\n             throw new SQLFeatureNotSupportedException();\n         }\n         \n-        int pkPosition = table.getBucketNum() == null ? 0 : 1;\n+        // skip salt and viewIndexId columns.\n+        int pkPosition = table.getBucketNum() == null ? 0 : 1 + (table.getViewIndexId() == null ? 0 : 1);\n         List<PColumn> pkColumns = table.getPKColumns();\n         return new RowKeyColumnExpression(pkColumns.get(pkPosition), new RowKeyValueAccessor(pkColumns, pkPosition));\n     }",
                "deletions": 1
            },
            {
                "sha": "7a3014ba2cf800fa9a6b159080a7f442c1f8b640",
                "filename": "phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java",
                "status": "modified",
                "changes": 8,
                "additions": 4,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/main/java/org/apache/phoenix/util/ScanUtil.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -766,16 +766,16 @@ private static boolean hasNonZeroLeadingBytes(byte[] key, int nBytesToCheck) {\n         return Bytes.compareTo(key, 0, nBytesToCheck, ZERO_BYTE_ARRAY, 0, nBytesToCheck) != 0;\n     }\n \n-    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isMultiTenantTable)\n+    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isMultiTenantTable, boolean isSharedIndex)\n             throws SQLException {\n         return isMultiTenantTable ?\n-                  getTenantIdBytes(schema, isSalted, tenantId)\n+                  getTenantIdBytes(schema, isSalted, tenantId, isSharedIndex)\n                 : tenantId.getBytes();\n     }\n \n-    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId)\n+    public static byte[] getTenantIdBytes(RowKeySchema schema, boolean isSalted, PName tenantId, boolean isSharedIndex)\n             throws SQLException {\n-        int pkPos = isSalted ? 1 : 0;\n+        int pkPos = (isSalted ? 1 : 0) + (isSharedIndex ? 1 : 0); \n         Field field = schema.getField(pkPos);\n         PDataType dataType = field.getDataType();\n         byte[] convertedValue;",
                "deletions": 4
            },
            {
                "sha": "27c30fc02f11dd0fc6fd989aa581e7a9bb9b50a2",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java",
                "status": "modified",
                "changes": 6,
                "additions": 3,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/compile/TenantSpecificViewIndexCompileTest.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -50,7 +50,7 @@ public void testOrderByOptimizedOut() throws Exception {\n         conn.createStatement().execute(\"CREATE INDEX i1 ON v(v2) INCLUDE(v1)\");\n         \n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v1,v2 FROM v WHERE v2 > 'a' ORDER BY v2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32768,'a'] - ['me',-32768,*]\",\n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32768,'me','a'] - [-32768,'me',*]\",\n                 QueryUtil.getExplainPlan(rs));\n     }\n \n@@ -194,7 +194,7 @@ public void testViewConstantsOptimizedOut() throws Exception {\n         conn.createStatement().execute(\"CREATE INDEX i1 ON v(v2)\");\n         \n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v2 FROM v WHERE v2 > 'a' and k2 = 'a' ORDER BY v2,k2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32766,'a'] - ['me',-32766,*]\\n\" + \n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32766,'me','a'] - [-32766,'me',*]\\n\" + \n                 \"    SERVER FILTER BY FIRST KEY ONLY\",\n                 QueryUtil.getExplainPlan(rs));\n         \n@@ -227,7 +227,7 @@ public void testViewConstantsOptimizedOutOnReadOnlyView() throws Exception {\n         \n         // Confirm that a read-only view on an updatable view still optimizes out the read-only parts of the updatable view\n         ResultSet rs = conn.createStatement().executeQuery(\"EXPLAIN SELECT v2 FROM v2 WHERE v3 > 'a' and k2 = 'a' ORDER BY v3,k2\");\n-        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T ['me',-32767,'a'] - ['me',-32767,*]\",\n+        assertEquals(\"CLIENT PARALLEL 1-WAY RANGE SCAN OVER _IDX_T [-32767,'me','a'] - [-32767,'me',*]\",\n                 QueryUtil.getExplainPlan(rs));\n     }\n     ",
                "deletions": 3
            },
            {
                "sha": "fb70d228796d6af48a0137b469cffe86359f8cb6",
                "filename": "phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java",
                "blob_url": "https://github.com/apache/phoenix/blob/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java",
                "raw_url": "https://github.com/apache/phoenix/raw/5097982b00b36b74fb328afaab02159e81b21af0/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java",
                "status": "modified",
                "changes": 2,
                "additions": 1,
                "contents_url": "https://api.github.com/repos/apache/phoenix/contents/phoenix-core/src/test/java/org/apache/phoenix/util/TenantIdByteConversionTest.java?ref=5097982b00b36b74fb328afaab02159e81b21af0",
                "patch": "@@ -61,7 +61,7 @@ public TenantIdByteConversionTest(\n     @Test\n     public void test() {\n         try {\n-            byte[] actualTenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId);\n+            byte[] actualTenantIdBytes = ScanUtil.getTenantIdBytes(schema, isSalted, tenantId, false);\n             assertArrayEquals(expectedTenantIdBytes, actualTenantIdBytes);\n         } catch (SQLException ex) {\n             fail(ex.getMessage());",
                "deletions": 1
            }
        ],
        "patched_files": [
            "TenantSpecificViewIndexIT.java",
            "PhoenixRuntime.java",
            "MetaDataUtil.java",
            "ServerCacheClient.java",
            "ScanUtil.java",
            "WhereOptimizer.java",
            "IndexMaintainer.java",
            "BaseQueryPlan.java",
            "ConnectionQueryServicesImpl.java",
            "BaseTenantSpecificViewIndexIT.java",
            "DeleteCompiler.java",
            "MetaDataClient.java",
            "ViewIndexIT.java",
            "UpsertCompiler.java"
        ],
        "unit_tests": [
            "MetaDataUtilTest.java",
            "PhoenixRuntimeTest.java",
            "TenantSpecificViewIndexCompileTest.java",
            "IndexMaintainerTest.java",
            "WhereOptimizerTest.java",
            "ScanUtilTest.java",
            "TenantIdByteConversionTest.java"
        ]
    }
}