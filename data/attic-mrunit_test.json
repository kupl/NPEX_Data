{
    "attic-mrunit_12d6df9": {
        "bug_id": "attic-mrunit_12d6df9",
        "commit": "https://github.com/apache/attic-mrunit/commit/12d6df971de68b4560c044947f307ecf01d9a3dd",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/attic-mrunit/blob/12d6df971de68b4560c044947f307ecf01d9a3dd/src/main/java/org/apache/hadoop/mrunit/mapreduce/MapDriver.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/attic-mrunit/contents/src/main/java/org/apache/hadoop/mrunit/mapreduce/MapDriver.java?ref=12d6df971de68b4560c044947f307ecf01d9a3dd",
                "deletions": 1,
                "filename": "src/main/java/org/apache/hadoop/mrunit/mapreduce/MapDriver.java",
                "patch": "@@ -28,9 +28,11 @@\n import org.apache.commons.logging.LogFactory;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.InputSplit;\n import org.apache.hadoop.mapreduce.Mapper;\n import org.apache.hadoop.mrunit.MapDriverBase;\n import org.apache.hadoop.mrunit.counters.CounterWrapper;\n+import org.apache.hadoop.mrunit.mapreduce.mock.MockInputSplit;\n import org.apache.hadoop.mrunit.mapreduce.mock.MockMapContextWrapper;\n import org.apache.hadoop.mrunit.types.Pair;\n \n@@ -209,9 +211,11 @@ public void setCounters(final Counters ctrs) {\n     final List<Pair<K1, V1>> inputs = new ArrayList<Pair<K1, V1>>();\n     inputs.add(new Pair<K1, V1>(inputKey, inputVal));\n \n+    final InputSplit inputSplit = new MockInputSplit();\n+    \n     try {\n       final MockMapContextWrapper<K1, V1, K2, V2> wrapper = new MockMapContextWrapper<K1, V1, K2, V2>(\n-          inputs, getCounters(), getConfiguration());\n+          inputs, getCounters(), getConfiguration(), inputSplit);\n \n       final Mapper<K1, V1, K2, V2>.Context context = wrapper.getMockContext();\n       myMapper.run(context);",
                "raw_url": "https://github.com/apache/attic-mrunit/raw/12d6df971de68b4560c044947f307ecf01d9a3dd/src/main/java/org/apache/hadoop/mrunit/mapreduce/MapDriver.java",
                "sha": "01fb9d66e2b49b7c260020a22f268e8646ac1947",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/attic-mrunit/blob/12d6df971de68b4560c044947f307ecf01d9a3dd/src/main/java/org/apache/hadoop/mrunit/mapreduce/mock/MockMapContextWrapper.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/attic-mrunit/contents/src/main/java/org/apache/hadoop/mrunit/mapreduce/mock/MockMapContextWrapper.java?ref=12d6df971de68b4560c044947f307ecf01d9a3dd",
                "deletions": 3,
                "filename": "src/main/java/org/apache/hadoop/mrunit/mapreduce/mock/MockMapContextWrapper.java",
                "patch": "@@ -28,6 +28,7 @@\n import org.apache.commons.logging.LogFactory;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.InputSplit;\n import org.apache.hadoop.mapreduce.Mapper;\n import org.apache.hadoop.mrunit.types.Pair;\n import org.mockito.invocation.InvocationOnMock;\n@@ -50,12 +51,14 @@\n   protected final List<Pair<KEYIN, VALUEIN>> inputs;\n   protected Pair<KEYIN, VALUEIN> currentKeyValue;\n   protected final Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT>.Context context;\n-\n+  protected InputSplit inputSplit;\n+  \n   public MockMapContextWrapper(final List<Pair<KEYIN, VALUEIN>> inputs,\n-      final Counters counters, final Configuration conf) throws IOException,\n-      InterruptedException {\n+      final Counters counters, final Configuration conf, final InputSplit inputSplit) \n+      throws IOException, InterruptedException {\n     super(counters, conf);\n     this.inputs = inputs;\n+    this.inputSplit = inputSplit;\n     context = create();\n   }\n \n@@ -94,6 +97,12 @@ public VALUEIN answer(final InvocationOnMock invocation) {\n         return currentKeyValue.getSecond();\n       }\n     });\n+    when(context.getInputSplit()).thenAnswer(new Answer<InputSplit>() {\n+      @Override\n+      public InputSplit answer(InvocationOnMock invocation) throws Throwable {\n+        return inputSplit;\n+      }\n+    });\n     return context;\n   }\n ",
                "raw_url": "https://github.com/apache/attic-mrunit/raw/12d6df971de68b4560c044947f307ecf01d9a3dd/src/main/java/org/apache/hadoop/mrunit/mapreduce/mock/MockMapContextWrapper.java",
                "sha": "0fd02faacd42a5e1d7b0f3d5e9ed921e842f7599",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/attic-mrunit/blob/12d6df971de68b4560c044947f307ecf01d9a3dd/src/test/java/org/apache/hadoop/mrunit/mapreduce/TestMapDriver.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/attic-mrunit/contents/src/test/java/org/apache/hadoop/mrunit/mapreduce/TestMapDriver.java?ref=12d6df971de68b4560c044947f307ecf01d9a3dd",
                "deletions": 0,
                "filename": "src/test/java/org/apache/hadoop/mrunit/mapreduce/TestMapDriver.java",
                "patch": "@@ -26,9 +26,11 @@\n \n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n import org.apache.hadoop.io.NullWritable;\n import org.apache.hadoop.io.Text;\n import org.apache.hadoop.mapreduce.Mapper;\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit;\n import org.apache.hadoop.mapreduce.lib.map.InverseMapper;\n import org.apache.hadoop.mrunit.ExpectedSuppliedException;\n import org.apache.hadoop.mrunit.types.Pair;\n@@ -243,6 +245,24 @@ protected void setup(final Context context) throws IOException,\n     }\n   }\n \n+  @Test\n+  public void testInputSplitDetails() {\n+    final MapDriver<NullWritable, NullWritable, Text, LongWritable> driver = \n+        MapDriver.newMapDriver(new InputSplitDetailMapper());\n+    driver.withInput(NullWritable.get(), NullWritable.get())\n+      .withOutput(new Text(\"somefile\"), new LongWritable(0L)).runTest();\n+  }\n+  \n+  public static class InputSplitDetailMapper\n+    extends Mapper<NullWritable, NullWritable, Text, LongWritable> {\n+    protected void map(NullWritable key, NullWritable value, Context context) \n+        throws IOException, InterruptedException {\n+      FileSplit split = (FileSplit)context.getInputSplit();\n+      context.write(new Text(split.getPath().toString()), \n+          new LongWritable(split.getLength()));\n+    }\n+  }\n+\n   @Test\n   public void testNoMapper() {\n     driver = MapDriver.newMapDriver();",
                "raw_url": "https://github.com/apache/attic-mrunit/raw/12d6df971de68b4560c044947f307ecf01d9a3dd/src/test/java/org/apache/hadoop/mrunit/mapreduce/TestMapDriver.java",
                "sha": "66cdc5ec3e26b8a4f9c9af1474b8c81b3b71b206",
                "status": "modified"
            }
        ],
        "message": "MRUNIT-97: InputSplit causes NullPointerException in mapreduce api\n\ngit-svn-id: https://svn.apache.org/repos/asf/incubator/mrunit/trunk@1325959 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/attic-mrunit/commit/7d228077bb2912174e8037ba0905e44d571924d8",
        "patched_files": [
            "MockMapContextWrapper.java",
            "MapDriver.java"
        ],
        "repo": "attic-mrunit",
        "unit_tests": [
            "TestMapDriver.java"
        ]
    },
    "attic-mrunit_57196c3": {
        "bug_id": "attic-mrunit_57196c3",
        "commit": "https://github.com/apache/attic-mrunit/commit/57196c39a73cf2251e0f2ba7da225731362407ba",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/attic-mrunit/blob/57196c39a73cf2251e0f2ba7da225731362407ba/src/main/java/org/apache/hadoop/mrunit/internal/io/Serialization.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/attic-mrunit/contents/src/main/java/org/apache/hadoop/mrunit/internal/io/Serialization.java?ref=57196c39a73cf2251e0f2ba7da225731362407ba",
                "deletions": 3,
                "filename": "src/main/java/org/apache/hadoop/mrunit/internal/io/Serialization.java",
                "patch": "@@ -17,6 +17,8 @@\n  */\n package org.apache.hadoop.mrunit.internal.io;\n \n+import com.google.common.base.Preconditions;\n+\n import java.io.IOException;\n \n import org.apache.hadoop.conf.Configuration;\n@@ -58,16 +60,20 @@ public Serialization(Configuration conf) {\n     final Class<?> clazz = orig.getClass();\n     final Serializer<Object> serializer;\n     final Deserializer<Object> deserializer;\n+    String errorMsg = \"No applicable class implementing Serialization in conf \"\n+                      + \"at io.serializations: \" + clazz;\n     try {\n       serializer = (Serializer<Object>) serializationFactory\n           .getSerializer(clazz);\n       deserializer = (Deserializer<Object>) serializationFactory\n           .getDeserializer(clazz);\n+    // hadoop 1.x will throw\n     } catch (NullPointerException e) {\n-      throw new IllegalStateException(\n-          \"No applicable class implementing Serialization in conf at io.serializations for \"\n-              + orig.getClass(), e);\n+      throw new IllegalStateException(errorMsg, e);\n     }\n+    // hadoop 2.x will return a null\n+    Preconditions.checkState(serializer != null, errorMsg);\n+    Preconditions.checkState(deserializer != null, errorMsg);\n     try {\n       final DataOutputBuffer outputBuffer = new DataOutputBuffer();\n       serializer.open(outputBuffer);",
                "raw_url": "https://github.com/apache/attic-mrunit/raw/57196c39a73cf2251e0f2ba7da225731362407ba/src/main/java/org/apache/hadoop/mrunit/internal/io/Serialization.java",
                "sha": "8301d41b7320c6723c8d14f37bf799289a5a3040",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/attic-mrunit/blob/57196c39a73cf2251e0f2ba7da225731362407ba/src/test/java/org/apache/hadoop/mrunit/internal/io/TestSerialization.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/attic-mrunit/contents/src/test/java/org/apache/hadoop/mrunit/internal/io/TestSerialization.java?ref=57196c39a73cf2251e0f2ba7da225731362407ba",
                "deletions": 3,
                "filename": "src/test/java/org/apache/hadoop/mrunit/internal/io/TestSerialization.java",
                "patch": "@@ -17,13 +17,14 @@\n  */\n package org.apache.hadoop.mrunit.internal.io;\n \n-import static org.junit.Assert.assertEquals;\n-\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.io.IntWritable;\n-import org.apache.hadoop.mrunit.internal.io.Serialization;\n+import org.apache.hadoop.io.Writable;\n import org.junit.Test;\n \n+import static org.junit.Assert.assertEquals;\n+import static org.mockito.Mockito.mock;\n+\n public class TestSerialization {\n \n   @Test\n@@ -58,4 +59,12 @@ public void testDontChangeStateOfCopyArgument() {\n     assertEquals(new Integer(2), int2);\n   }\n \n+  @Test(expected = IllegalStateException.class)\n+  public void testCopyExceptionIfNoSerializer() {\n+    final Configuration conf = new Configuration();\n+    Serialization serialization = new Serialization(conf);\n+    // there's no implicit serializer for Integer, so it should throw ISE\n+    serialization.copy(1, 1);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/attic-mrunit/raw/57196c39a73cf2251e0f2ba7da225731362407ba/src/test/java/org/apache/hadoop/mrunit/internal/io/TestSerialization.java",
                "sha": "ac530ab80a180aba4be712940eb26d3da3dfb629",
                "status": "modified"
            }
        ],
        "message": "MRUNIT-193 - Serialization.copy throws NPE instead of ISE (missing serilization impl) for Hadoop 2.x (Cosmin Lehen via Brock Noland)",
        "parent": "https://github.com/apache/attic-mrunit/commit/2c24ab2af152bc7b41c4d52cba4883aacba40764",
        "patched_files": [
            "Serialization.java"
        ],
        "repo": "attic-mrunit",
        "unit_tests": [
            "TestSerialization.java"
        ]
    }
}