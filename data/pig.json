{
    "pig_1a1e5e3": {
        "bug_id": "pig_1a1e5e3",
        "commit": "https://github.com/apache/pig/commit/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -197,6 +197,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1596: NPE's thrown when attempting to load hbase columns containing null values (zjffdu)\n+\n PIG-1597: Development snapshot jar no longer picked up by bin/pig (dvryaboy)\n \n PIG-1599: pig gives generic message for few cases (nrai via rding)",
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/CHANGES.txt",
                "sha": "e59239caf1aa17a8cd0217f612d6f5c160bed6db",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c",
                "deletions": 1,
                "filename": "src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "patch": "@@ -247,7 +247,11 @@ public Tuple getNext() throws IOException {\n                     startIndex++;\n                 }\n                 for (int i=0;i<columnList_.size();++i){\n-                    tuple.set(i+startIndex, new DataByteArray(result.getValue(columnList_.get(i))));\n+                \tbyte[] cell=result.getValue(columnList_.get(i));\n+                \tif (cell!=null)\n+                \t    tuple.set(i+startIndex, new DataByteArray(cell));\n+                \telse\n+                \t    tuple.set(i+startIndex, null);\n                 }\n                 return tuple;\n             }",
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "sha": "1b4e5a28ffa6f23f3e08911203c4729b86dda88f",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/test/org/apache/pig/test/TestHBaseStorage.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestHBaseStorage.java?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c",
                "deletions": 3,
                "filename": "test/org/apache/pig/test/TestHBaseStorage.java",
                "patch": "@@ -171,8 +171,8 @@ public void testLoadFromHBase() throws IOException {\n \t\tprepareTable(TESTTABLE_1, true, DataFormat.UTF8PlainText);\n \t\tpig.registerQuery(\"a = load 'hbase://\" + TESTTABLE_1 + \"' using \"\n \t\t\t\t+ \"org.apache.pig.backend.hadoop.hbase.HBaseStorage('\"\n-\t\t\t\t+ TESTCOLUMN_A + \" \" + TESTCOLUMN_B + \" \" + TESTCOLUMN_C\n-\t\t\t\t+ \"') as (col_a, col_b, col_c);\");\n+\t\t\t\t+ TESTCOLUMN_A + \" \" + TESTCOLUMN_B + \" \" + TESTCOLUMN_C +\" pig:col_d\"\n+\t\t\t\t+ \"') as (col_a, col_b, col_c, col_d);\");\n \t\tIterator<Tuple> it = pig.openIterator(\"a\");\n \t\tint count = 0;\n \t\tLOG.info(\"LoadFromHBase Starting\");\n@@ -182,10 +182,11 @@ public void testLoadFromHBase() throws IOException {\n \t\t\tString col_a = ((DataByteArray) t.get(0)).toString();\n \t\t\tString col_b = ((DataByteArray) t.get(1)).toString();\n \t\t\tString col_c = ((DataByteArray) t.get(2)).toString();\n-\n+\t\t\tObject col_d = t.get(3);       // empty cell\n \t\t\tAssert.assertEquals(count, Integer.parseInt(col_a));\n \t\t\tAssert.assertEquals(count + 0.0, Double.parseDouble(col_b), 1e-6);\n \t\t\tAssert.assertEquals(\"Text_\" + count, col_c);\n+\t\t\tAssert.assertNull(col_d);\n \t\t\tcount++;\n \t\t}\n \t\tAssert.assertEquals(TEST_ROW_COUNT, count);",
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/test/org/apache/pig/test/TestHBaseStorage.java",
                "sha": "d8f5f6e5bb4a197d77d82815850b1b3f16df7549",
                "status": "modified"
            }
        ],
        "message": "PIG-1596: NPE's thrown when attempting to load hbase columns containing null values (zjffdu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@992926 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/e08f4375537ebf0e4b4a2672444894db0c9a78c5",
        "repo": "pig",
        "unit_tests": [
            "TestHBaseStorage.java"
        ]
    },
    "pig_1d64916": {
        "bug_id": "pig_1d64916",
        "commit": "https://github.com/apache/pig/commit/1d64916466db0da7c57a00a49f3235e7b190a074",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/1d64916466db0da7c57a00a49f3235e7b190a074/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=1d64916466db0da7c57a00a49f3235e7b190a074",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -44,6 +44,8 @@ PIG-626: Add access to hadoop counters (shubhamc via gates).\n \n BUG FIXES\n \n+PIG-810: Fixed NPE in PigStats (gates)\n+\n PIG-804: problem with lineage with double map redirection (pradeepkth)\n \n PIG-733: Order by sampling dumps entire sample to hdfs which causes dfs",
                "raw_url": "https://github.com/apache/pig/raw/1d64916466db0da7c57a00a49f3235e7b190a074/CHANGES.txt",
                "sha": "7175634f5ea7e879154ab9c4e3b01273594f21fe",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/1d64916466db0da7c57a00a49f3235e7b190a074/src/org/apache/pig/tools/pigstats/PigStats.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/tools/pigstats/PigStats.java?ref=1d64916466db0da7c57a00a49f3235e7b190a074",
                "deletions": 1,
                "filename": "src/org/apache/pig/tools/pigstats/PigStats.java",
                "patch": "@@ -172,7 +172,7 @@ else if(mode == ExecType.LOCAL)\n             \n         }\n         \n-        lastJobID = lastJob.getAssignedJobID().toString();\n+        if (lastJob != null) lastJobID = lastJob.getAssignedJobID().toString();\n         return stats;\n     }\n     ",
                "raw_url": "https://github.com/apache/pig/raw/1d64916466db0da7c57a00a49f3235e7b190a074/src/org/apache/pig/tools/pigstats/PigStats.java",
                "sha": "f0b87c7074e838c8a3fd0cb4aedc9a874f71ce09",
                "status": "modified"
            }
        ],
        "message": "PIG-810: Fixed NPE in PigStats (gates)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@774989 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/6c0cdfeb9d2daf997df8ccea091873706ef3b160",
        "repo": "pig",
        "unit_tests": [
            "TestPigStats.java"
        ]
    },
    "pig_20eac9b": {
        "bug_id": "pig_20eac9b",
        "commit": "https://github.com/apache/pig/commit/20eac9b2672f80eb24502a176a9df2024ba70fbe",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/20eac9b2672f80eb24502a176a9df2024ba70fbe/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=20eac9b2672f80eb24502a176a9df2024ba70fbe",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -193,6 +193,8 @@ PIG-3882: Multiquery off mode execution is not done in batch and very inefficien\n  \n BUG FIXES\n \n+PIG-4017: NPE thrown from JobControlCompiler.shipToHdfs (cheolsoo)\n+\n PIG-3997: Issue on Pig docs: Testing and Diagnostics (zjffdu via cheolsoo)\n \n PIG-3998: Documentation fix: invalid page links, wrong Groovy udf example (lbendig via cheolsoo)",
                "raw_url": "https://github.com/apache/pig/raw/20eac9b2672f80eb24502a176a9df2024ba70fbe/CHANGES.txt",
                "sha": "dba86c9ade6aa95d040f79ba8e05a19186f49384",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/pig/blob/20eac9b2672f80eb24502a176a9df2024ba70fbe/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java?ref=20eac9b2672f80eb24502a176a9df2024ba70fbe",
                "deletions": 1,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "patch": "@@ -1687,7 +1687,9 @@ private static Path shipToHDFS(\n         } finally {\n             org.apache.commons.io.IOUtils.closeQuietly(is);\n             // IOUtils should not close stream to HDFS quietly\n-            os.close();\n+            if (os != null) {\n+                os.close();\n+            }\n         }\n         return dst;\n     }",
                "raw_url": "https://github.com/apache/pig/raw/20eac9b2672f80eb24502a176a9df2024ba70fbe/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "sha": "37341ce948d89c3b66d7a4860e5ba83a98d3c4a8",
                "status": "modified"
            }
        ],
        "message": "PIG-4017: NPE thrown from JobControlCompiler.shipToHdfs (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1603315 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/63efe61aa797cb65b470019b2a6beb6c74826e61",
        "repo": "pig",
        "unit_tests": [
            "TestJobControlCompiler.java"
        ]
    },
    "pig_20f7c2c": {
        "bug_id": "pig_20f7c2c",
        "commit": "https://github.com/apache/pig/commit/20f7c2c14519092b727904d57171b4d8a0a4732f",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=20f7c2c14519092b727904d57171b4d8a0a4732f",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -299,6 +299,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1843: NPE in schema generation (daijy)\n+\n PIG-1820: New logical plan: FilterLogicExpressionSimplifier fail to deal with UDF (daijy)\n \n PIG-1854: Pig returns exit code 0 for the failed Pig script (rding)",
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/CHANGES.txt",
                "sha": "d796576317136fe0291a8cac7459ba4b49b030af",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/src/org/apache/pig/EvalFunc.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/EvalFunc.java?ref=20f7c2c14519092b727904d57171b4d8a0a4732f",
                "deletions": 1,
                "filename": "src/org/apache/pig/EvalFunc.java",
                "patch": "@@ -73,7 +73,7 @@\n     private static int nextSchemaId; // for assigning unique ids to UDF columns\n     protected String getSchemaName(String name, Schema input) {\n         String alias = name + \"_\";\n-        if (input.getAliases().size() > 0){\n+        if (input!=null && input.getAliases().size() > 0){\n             alias += input.getAliases().iterator().next() + \"_\";\n         }\n ",
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/src/org/apache/pig/EvalFunc.java",
                "sha": "13640657c4258336dd1469007b39db5d77c8d3b3",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/test/org/apache/pig/test/TestEvalPipeline2.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestEvalPipeline2.java?ref=20f7c2c14519092b727904d57171b4d8a0a4732f",
                "deletions": 4,
                "filename": "test/org/apache/pig/test/TestEvalPipeline2.java",
                "patch": "@@ -973,13 +973,13 @@ public void testBinStorageByteCast() throws Exception{\n     \n     // See PIG-1761\n     @Test\n-    public void testBagDereferenceInMiddle() throws Exception{\n+    public void testBagDereferenceInMiddle1() throws Exception{\n         String[] input1 = {\n                 \"foo@apache#44\",\n         };\n         \n-        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle\", input1);\n-        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle' as (a0:chararray);\");\n+        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle1\", input1);\n+        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle1' as (a0:chararray);\");\n         pigServer.registerQuery(\"b = foreach a generate UPPER(REGEX_EXTRACT_ALL(a0, '.*@(.*)#.*').$0);\");\n         \n         Iterator<Tuple> iter = pigServer.openIterator(\"b\");\n@@ -988,6 +988,23 @@ public void testBagDereferenceInMiddle() throws Exception{\n         assertTrue(t.get(0).equals(\"APACHE\"));\n     }\n     \n+    // See PIG-1843\n+    @Test\n+    public void testBagDereferenceInMiddle2() throws Exception{\n+        String[] input1 = {\n+                \"foo apache\",\n+        };\n+        \n+        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle2\", input1);\n+        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle2' as (a0:chararray);\");\n+        pigServer.registerQuery(\"b = foreach a generate \" + MapGenerate.class.getName() + \" (STRSPLIT(a0).$0);\");\n+        \n+        Iterator<Tuple> iter = pigServer.openIterator(\"b\");\n+        Tuple t = iter.next();\n+        assertTrue(t.size()==1);\n+        assertTrue(t.toString().equals(\"([key#1])\"));\n+    }\n+    \n     // See PIG-1766\n     @Test\n     public void testForEachSameOriginColumn1() throws Exception{\n@@ -1048,7 +1065,7 @@ public Map exec(Tuple input) throws IOException {\n         \n         @Override\n         public Schema outputSchema(Schema input) {\n-            return new Schema(new Schema.FieldSchema(null, DataType.MAP));\n+            return new Schema(new Schema.FieldSchema(getSchemaName(\"parselong\", input), DataType.MAP));\n         }\n     }\n     ",
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/test/org/apache/pig/test/TestEvalPipeline2.java",
                "sha": "9d285f9499223426d8a38116e73767712cd63443",
                "status": "modified"
            }
        ],
        "message": "PIG-1843: NPE in schema generation\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1071857 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/8c7e23cc630a3127d80cb6764d4d5e05d6d765ca",
        "repo": "pig",
        "unit_tests": [
            "TestEvalFunc.java"
        ]
    },
    "pig_23dc5ce": {
        "bug_id": "pig_23dc5ce",
        "commit": "https://github.com/apache/pig/commit/23dc5ce42e783a32fd5713de05e9e330cc429731",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/23dc5ce42e783a32fd5713de05e9e330cc429731/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=23dc5ce42e783a32fd5713de05e9e330cc429731",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -99,6 +99,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3806: PigServer constructor throws NPE after PIG-3765 (aniket486)\n+\n PIG-3801: Auto local mode does not call storeSchema (aniket486)\n \n PIG-3754: InputSizeReducerEstimator.getTotalInputFileSize reports incorrect size (aniket486)",
                "raw_url": "https://github.com/apache/pig/raw/23dc5ce42e783a32fd5713de05e9e330cc429731/CHANGES.txt",
                "sha": "70b6d59884318e7be39758c61b14231baeb4a70c",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/23dc5ce42e783a32fd5713de05e9e330cc429731/src/org/apache/pig/PigServer.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/PigServer.java?ref=23dc5ce42e783a32fd5713de05e9e330cc429731",
                "deletions": 2,
                "filename": "src/org/apache/pig/PigServer.java",
                "patch": "@@ -233,6 +233,8 @@ public PigServer(PigContext context, boolean connect) throws ExecException {\n         if (connect) {\n             pigContext.connect();\n         }\n+        \n+        this.filter = new BlackAndWhitelistFilter(this);\n \n         addJarsFromProperties();\n         markPredeployedJarsFromProperties();\n@@ -244,8 +246,6 @@ public PigServer(PigContext context, boolean connect) throws ExecException {\n         if (ScriptState.get() == null) {\n             ScriptState.start(pigContext.getExecutionEngine().instantiateScriptState());\n         }\n-\n-        this.filter = new BlackAndWhitelistFilter(this);\n     }\n \n     private void addJarsFromProperties() throws ExecException {",
                "raw_url": "https://github.com/apache/pig/raw/23dc5ce42e783a32fd5713de05e9e330cc429731/src/org/apache/pig/PigServer.java",
                "sha": "54515206ca52220ccb68faf19ff54c6a034d2255",
                "status": "modified"
            }
        ],
        "message": "PIG-3806: PigServer constructor throws NPE after PIG-3765 (aniket486)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1576549 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/c2aedcc66486ddc721a32dc4984547f049aa5541",
        "repo": "pig",
        "unit_tests": [
            "TestPigServer.java"
        ]
    },
    "pig_3505a42": {
        "bug_id": "pig_3505a42",
        "commit": "https://github.com/apache/pig/commit/3505a4289fc9114f214e8e20d5cb59cfd78b16e9",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/CHANGES.txt",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9",
                "deletions": 1,
                "filename": "CHANGES.txt",
                "patch": "@@ -188,6 +188,9 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-2018: NPE for co-group with group-by column having complex schema and \n+ different load functions for each input (thejas)\n+\n PIG-2015: Explain writes out logical plan twice (alangates)\n \n PIG-2017: consumeMap() fails with EmptyStackException (thedatachef via daijy)\n@@ -845,7 +848,7 @@ PIG-1414: Problem with parameter substitution (rding)\n PIG-1407: Logging starts before being configured (azaroth via daijy)\n \n PIG-1391: pig unit tests leave behind files in temp directory because \n-MiniCluster files don't get deleted (tejas)\n+ MiniCluster files don't get deleted (thejas)\n \n PIG-1211: Pig script runs half way after which it reports syntax error\n (pradeepkth)",
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/CHANGES.txt",
                "sha": "5fe7c28bc906dd8856c97de0c088c2771130a4ad",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9",
                "deletions": 1,
                "filename": "src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "patch": "@@ -507,7 +507,6 @@ void mapMatchLoadFuncToUid(\n                 //check if all func spec match\n                 if(!funcSpec1.equals(uid2LoadFuncMap.get(fs.uid))){\n                     allMatch = false;\n-                    break;\n                 }\n                 //check if all inner schema match for use later\n                 if(outFS.schema == null ||  !outFS.schema.isEqual(fs.schema)){",
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "sha": "51cc7ab6af96faaaad81247b3556c201985ac06a",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9",
                "deletions": 0,
                "filename": "test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "patch": "@@ -4106,4 +4106,17 @@ public void testUDFNoInnerSchema() throws FrontendException {\n             checkLastForeachCastLoadFunc(query, null, 0);\n         }\n \n+        //see PIG-2018\n+        @Test\n+        public void testCoGroupComplex(){\n+            String query = \n+                \"l1 = load 'x' using PigStorage(':') as (a : (i : int),b,c);\"\n+                + \"l2 = load 'x' as (a,b,c);\"\n+                + \"cg = cogroup l1 by a, l2 by a;\";\n+            try {\n+                createAndProcessLPlan(query);\n+            } catch (FrontendException e) {\n+                fail(\"caught exception creating lp\");\n+            }\n+        }\n }",
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "sha": "adf3c68527f77b173cf2cc670dfd7695dc77905f",
                "status": "modified"
            }
        ],
        "message": "PIG-2018: NPE for co-group with group-by column having complex schema and\n different load functions for each input (thejas)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1098027 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/ff92a6d6eeec56d455ddd3472b3947a8d8bc3e2c",
        "repo": "pig",
        "unit_tests": [
            "TestLineageFindRelVisitor.java"
        ]
    },
    "pig_35fb1ea": {
        "bug_id": "pig_35fb1ea",
        "commit": "https://github.com/apache/pig/commit/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -192,6 +192,8 @@ PIG-3013: BinInterSedes improve chararray sort performance (rohini)\n \n BUG FIXES\n \n+PIG-3322: AvroStorage give NPE on reading file with union as top level schema (viraj via rohini)\n+\n PIG-2828: Handle nulls in DataType.compare (aniket486)\n \n PIG-3335: TestErrorHandling.tesNegative7 fails on MR2 (xuefuz)",
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/CHANGES.txt",
                "sha": "78f65afae8d4995f4f59f8ff83e1c6272f1e3104",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
                "deletions": 1,
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "patch": "@@ -534,7 +534,6 @@ else if (inputs.containsKey(\"schema_file\")) {\n                 AvroStorageLog.details(\"data path=\" + path.toUri().toString());\n                 FileSystem fs = FileSystem.get(path.toUri(), new Configuration());\n                 outputAvroSchema = getAvroSchema(path, fs);\n-                userSpecifiedAvroSchema = outputAvroSchema;\n             } else if (name.equalsIgnoreCase(\"nullable\")) {\n                 nullable = (Boolean) value;\n             } else if (name.equalsIgnoreCase(\"schema\")) {",
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "sha": "997cf4c182dc0b45c402caeee4e970a7015a3ca9",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
                "deletions": 1,
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "patch": "@@ -141,7 +141,12 @@ public Writable getCurrentValue() throws IOException, InterruptedException {\n             AvroStorageLog.details(\"Class =\" + obj.getClass());\n             result = (Tuple) obj;\n         } else {\n-            AvroStorageLog.details(\"Wrap calss \" + obj.getClass() + \" as a tuple.\");\n+            if (obj != null) {\n+                AvroStorageLog.details(\"Wrap class \" + obj.getClass() + \" as a tuple.\");\n+            }\n+            else {\n+                AvroStorageLog.details(\"Wrap null as a tuple.\");\n+            }\n             result = wrapAsTuple(obj);\n         }\n         if (schemaToMergedSchemaMap != null) {",
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "sha": "531030467ea8d2b92394103b903d8a99ad4c9694",
                "status": "modified"
            },
            {
                "additions": 40,
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
                "deletions": 0,
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "patch": "@@ -16,6 +16,10 @@\n  */\n package org.apache.pig.piggybank.test.storage.avro;\n \n+import static org.apache.pig.builtin.mock.Storage.resetData;\n+import static org.apache.pig.builtin.mock.Storage.schema;\n+import static org.apache.pig.builtin.mock.Storage.tuple;\n+\n import org.apache.avro.file.DataFileStream;\n import org.apache.avro.generic.GenericDatumReader;\n import org.apache.commons.logging.Log;\n@@ -33,6 +37,8 @@\n import org.apache.pig.backend.executionengine.ExecJob;\n import org.apache.pig.backend.executionengine.ExecJob.JOB_STATUS;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobCreationException;\n+import org.apache.pig.builtin.mock.Storage.Data;\n+import org.apache.pig.data.Tuple;\n import org.apache.pig.impl.io.FileLocalizer;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n import org.apache.pig.piggybank.storage.avro.AvroStorage;\n@@ -181,6 +187,7 @@ private static String getInputFile(String file) {\n     final private String testMultipleSchemas1File = getInputFile(\"test_primitive_types/*\");\n     final private String testMultipleSchemas2File = getInputFile(\"test_complex_types/*\");\n     final private String testUserDefinedLoadSchemaFile = getInputFile(\"test_user_defined_load_schema/*\");\n+    final private String testLoadwithNullValues = getInputFile(\"test_loadavrowithnulls.avro\");\n \n     @BeforeClass\n     public static void setup() throws ExecException, IOException {\n@@ -1075,6 +1082,39 @@ public void testCorruptedFile2() throws IOException {\n         verifyResults(output, expected);\n     }\n \n+    @Test\n+    // Schema for the generated avro file test_loadavrowithnulls.avro\n+    // [\"null\",{\"type\":\"record\",\"name\":\"TUPLE_0\",\n+    // \"fields\":[\n+    // {\"name\":\"name\",\"type\":[\"null\",\"string\"],\"doc\":\"autogenerated from Pig Field Schema\"},\n+    // {\"name\":\"age\",\"type\":[\"null\",\"int\"],\"doc\":\"autogenerated from Pig Field Schema\"},\n+    // {\"name\":\"gpa\",\"type\":[\"null\",\"double\"],\"doc\":\"autogenerated from Pig Field Schema\"}]}]\n+    public void testLoadwithNullValues() throws IOException {\n+    //Input is supposed to have empty tuples\n+    PigSchema2Avro.setTupleIndex(0);\n+    Data data = resetData(pigServerLocal);\n+    String output = outbasedir + \"testLoadwithNulls\";\n+    deleteDirectory(new File(output));\n+    String [] queries = {\n+       \" A = load '\" +  testLoadwithNullValues + \"' USING \" +\n+          \" org.apache.pig.piggybank.storage.avro.AvroStorage(); \",\n+       \" B = order A by name;\",\n+       \" store B into '\" +  output +\"' USING mock.Storage();\"\n+       };\n+    testAvroStorage(queries);\n+    List<Tuple> out = data.get(output);\n+    assertEquals(out + \" size\", 4, out.size());\n+\n+    assertEquals(schema(\"name:chararray,age:int,gpa:double\"), data.getSchema(output));\n+\n+    // sorted data ordered by name\n+    assertEquals(tuple((String)null),out.get(0));\n+    assertEquals(tuple((String)null),out.get(1));\n+    assertEquals(tuple(\"calvin ellison\", 24, 0.71), out.get(2));\n+    assertEquals(tuple(\"wendy johnson\", 60, 0.07), out.get(3));\n+\n+   }\n+\n     private static void deleteDirectory (File path) {\n         if ( path.exists()) {\n             File [] files = path.listFiles();",
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "sha": "dad54449161c84100cf2b77b5cf1255f9f849224",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
                "deletions": 0,
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "sha": "1fcaf4c2d277c82af23e4bb1fd79b98ae26ff4a1",
                "status": "added"
            }
        ],
        "message": "PIG-3322: AvroStorage give NPE on reading file with union as top level schema (viraj via rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1489264 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/a13db1bc664c212177353daae9e204fd9da679bd",
        "repo": "pig",
        "unit_tests": [
            "TestAvroStorage.java"
        ]
    },
    "pig_5a9b9eb": {
        "bug_id": "pig_5a9b9eb",
        "commit": "https://github.com/apache/pig/commit/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/pig/blob/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java?ref=5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9",
                "deletions": 6,
                "filename": "src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "patch": "@@ -26,8 +26,8 @@\n \n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;\n+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigHadoopLogger;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n@@ -149,15 +149,14 @@ protected void execute(LogicalExpression op) throws FrontendException {\n                     PhysicalOperator root = expPhysicalPlan.getLeaves().get(0);\n                     try {\n                         UDFContext.getUDFContext().addJobConf(ConfigurationUtil.toConfiguration(pc.getProperties(), true));\n-                        Result ret= root.getNext(root.getResultType());\n-                        if (ret.result != null) {\n-                            val = ret.result;\n-                            valSet = true;\n-                        }\n+                        PigHadoopLogger pigHadoopLogger = PigHadoopLogger.getInstance();\n+                        PhysicalOperator.setPigLogger(pigHadoopLogger);\n+                        val = root.getNext(root.getResultType()).result;\n                         UDFContext.getUDFContext().addJobConf(null);\n                     } catch (ExecException e) {\n                         throw new FrontendException(e);\n                     }\n+                    valSet = true;\n                 } else if (op instanceof UserFuncExpression) {\n                     // If solo UDF, calculate UDF\n                     UserFuncExpression udf = (UserFuncExpression)op;",
                "raw_url": "https://github.com/apache/pig/raw/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "sha": "860fa474ea59bf6126a37d46740fc9d6d3df0f06",
                "status": "modified"
            }
        ],
        "message": "PIG-4169: NPE in ConstantCalculator\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1625205 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/f919fc3b742dae415a59539ab3abd08c6b8a0400",
        "repo": "pig",
        "unit_tests": [
            "TestConstantCalculator.java"
        ]
    },
    "pig_6e19aa5": {
        "bug_id": "pig_6e19aa5",
        "commit": "https://github.com/apache/pig/commit/6e19aa5c51829f525149c5ef6de69395599deacb",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/6e19aa5c51829f525149c5ef6de69395599deacb/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=6e19aa5c51829f525149c5ef6de69395599deacb",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -127,6 +127,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4873: InputSplit.getLocations return null and result a NPE in Pig (daijy)\n+\n PIG-4895: User UDFs relying on mapreduce.job.maps broken in Tez (rohini)\n \n PIG-4883: MapKeyType of splitter was set wrongly in specific multiquery case (kellyzly via rohini)",
                "raw_url": "https://github.com/apache/pig/raw/6e19aa5c51829f525149c5ef6de69395599deacb/CHANGES.txt",
                "sha": "5d917b0533962ce629770571128ad9920ba996d9",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/pig/blob/6e19aa5c51829f525149c5ef6de69395599deacb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java?ref=6e19aa5c51829f525149c5ef6de69395599deacb",
                "deletions": 3,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "patch": "@@ -463,9 +463,11 @@ public String toString() {\n             for (int i = 0; i < wrappedSplits.length; i++) {\n                 st.append(\"Input split[\"+i+\"]:\\n   Length = \"+ wrappedSplits[i].getLength()+\"\\n   ClassName: \" +\n                     wrappedSplits[i].getClass().getName() + \"\\n   Locations:\\n\");\n-                for (String location :  wrappedSplits[i].getLocations())\n-                    st.append(\"    \"+location+\"\\n\");\n-                st.append(\"\\n-----------------------\\n\");\n+                if (wrappedSplits[i]!=null && wrappedSplits[i].getLocations()!=null) {\n+                    for (String location :  wrappedSplits[i].getLocations())\n+                        st.append(\"    \"+location+\"\\n\");\n+                    st.append(\"\\n-----------------------\\n\");\n+                }\n           }\n         } catch (IOException e) {\n           return null;",
                "raw_url": "https://github.com/apache/pig/raw/6e19aa5c51829f525149c5ef6de69395599deacb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "sha": "e866b28c1bcdadcb5c0201d80c9648868dd6b3ca",
                "status": "modified"
            }
        ],
        "message": "PIG-4873: InputSplit.getLocations return null and result a NPE in Pig\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1744313 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/a58d3088c37a153fe565f0b9dd7cb208e6c5ac56",
        "repo": "pig",
        "unit_tests": [
            "TestPigSplit.java"
        ]
    },
    "pig_779945c": {
        "bug_id": "pig_779945c",
        "commit": "https://github.com/apache/pig/commit/779945ca83b00b13835184b8da25548cd5e0e0c7",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/779945ca83b00b13835184b8da25548cd5e0e0c7/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=779945ca83b00b13835184b8da25548cd5e0e0c7",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -70,6 +70,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4169: NPE in ConstantCalculator (cheolsoo)\n+\n PIG-4161: check for latest Hive snapshot dependencies (daijy)\n \n PIG-4102: Adding e2e tests and several improvements for Orc predicate pushdown (daijy)",
                "raw_url": "https://github.com/apache/pig/raw/779945ca83b00b13835184b8da25548cd5e0e0c7/CHANGES.txt",
                "sha": "234073e4fd15efb3ec54f8e6b265b3f6811d607d",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/pig/blob/779945ca83b00b13835184b8da25548cd5e0e0c7/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java?ref=779945ca83b00b13835184b8da25548cd5e0e0c7",
                "deletions": 2,
                "filename": "src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "patch": "@@ -27,6 +27,7 @@\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n@@ -148,12 +149,15 @@ protected void execute(LogicalExpression op) throws FrontendException {\n                     PhysicalOperator root = expPhysicalPlan.getLeaves().get(0);\n                     try {\n                         UDFContext.getUDFContext().addJobConf(ConfigurationUtil.toConfiguration(pc.getProperties(), true));\n-                        val = root.getNext(root.getResultType()).result;\n+                        Result ret= root.getNext(root.getResultType());\n+                        if (ret.result != null) {\n+                            val = ret.result;\n+                            valSet = true;\n+                        }\n                         UDFContext.getUDFContext().addJobConf(null);\n                     } catch (ExecException e) {\n                         throw new FrontendException(e);\n                     }\n-                    valSet = true;\n                 } else if (op instanceof UserFuncExpression) {\n                     // If solo UDF, calculate UDF\n                     UserFuncExpression udf = (UserFuncExpression)op;",
                "raw_url": "https://github.com/apache/pig/raw/779945ca83b00b13835184b8da25548cd5e0e0c7/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "sha": "761781c1e3ab01b84316b45a7c23d6c873592ee8",
                "status": "modified"
            }
        ],
        "message": "PIG-4169: NPE in ConstantCalculator (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1624611 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/484de09de12b17bed1d76fef8958f38163822e0c",
        "repo": "pig",
        "unit_tests": [
            "TestConstantCalculator.java"
        ]
    },
    "pig_9bdf3e1": {
        "bug_id": "pig_9bdf3e1",
        "commit": "https://github.com/apache/pig/commit/9bdf3e10dcd1d78c32911488df61c7a200532824",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=9bdf3e10dcd1d78c32911488df61c7a200532824",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -57,6 +57,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4712: [Pig on Tez] NPE in Bloom UDF after Union (rohini)\n+\n PIG-4707: [Pig on Tez] Streaming job hangs with pig.exec.mapPartAgg=true (rohini)\n \n PIG-4703: TezOperator.stores shall not ship to backend (daijy)",
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/CHANGES.txt",
                "sha": "1227b5d828077b56466c32c5b94709e99baceb2a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java?ref=9bdf3e10dcd1d78c32911488df61c7a200532824",
                "deletions": 0,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "patch": "@@ -566,6 +566,8 @@ public POUserFunc clone() throws CloneNotSupportedException {\n             requestedParallelism, null, funcSpec.clone());\n         clone.setResultType(resultType);\n         clone.signature = signature;\n+        clone.cacheFiles = cacheFiles;\n+        clone.shipFiles = shipFiles;\n         return clone;\n     }\n ",
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "sha": "818bb4c01fee40bd4a05dfa1387ed1f6c4b643f1",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/test/e2e/pig/tests/nightly.conf",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/e2e/pig/tests/nightly.conf?ref=9bdf3e10dcd1d78c32911488df61c7a200532824",
                "deletions": 0,
                "filename": "test/e2e/pig/tests/nightly.conf",
                "patch": "@@ -5148,6 +5148,30 @@ store C into ':OUTPATH:';\\,\n                                 C = load ':INPATH:/singlefile/votertab10k'as (name:chararray, age:int, reg:chararray, contrib:float);\n                                 D = join C by name, B by name;\n                                 store D into ':OUTPATH:';\",\n+                    },{\n+                        'num' => 4,\n+                        'pig' => \"set pig.optimizer.rules.disabled PushUpFilter;\n+                                define bb BuildBloom('Hash.JENKINS_HASH', 'fixed', '128', '3');\n+                                A = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                B = filter A by name == 'alice allen';\n+                                C = group B all;\n+                                D = foreach C generate bb(B.name);\n+                                store D into ':HDFSTMP:/mybloom_4';\n+                                exec;\n+                                define bloom Bloom(':HDFSTMP:/mybloom_4');\n+                                E = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                F = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                G = union E, F;\n+                                -- PushUpFilter is disabled to avoid filter being pushed before union\n+                                H = filter G by bloom(name);\n+                                store H into ':OUTPATH:';\",\n+                        'notmq' => 1,\n+                        'verify_pig_script' => \"\n+                                A = LOAD ':INPATH:/singlefile/studenttab10k' AS (name, age:int ,gpa:double);\n+                                B = LOAD ':INPATH:/singlefile/studenttab10k' AS (name, age:int ,gpa:double);\n+                                C = UNION A,B;\n+                                D = filter C by name == 'alice allen';\n+                                store D into ':OUTPATH:';\",\n                     }\n                 ],\n             },{",
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/test/e2e/pig/tests/nightly.conf",
                "sha": "644de3bd92b48c1325309eed88b546ecb0e695b1",
                "status": "modified"
            }
        ],
        "message": "PIG-4712: [Pig on Tez] NPE in Bloom UDF after Union (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1710672 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/ea8fd2df27c0a3b20bfc52f6c1a308f9f944a7d4",
        "repo": "pig",
        "unit_tests": [
            "TestPOUserFunc.java"
        ]
    },
    "pig_9c4d366": {
        "bug_id": "pig_9c4d366",
        "commit": "https://github.com/apache/pig/commit/9c4d36691393bd0f024d7de5f79c2492cf9469ad",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/CHANGES.txt",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -39,6 +39,9 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1366: PigStorage's pushProjection implementation results in NPE under\n+certain data conditions (pradeepkth)\n+\n PIG-1365: WrappedIOException is missing from Pig.jar (pradeepkth)\n \n PIG-1313: PigServer leaks memory over time (billgraham via daijy)",
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/CHANGES.txt",
                "sha": "65cdc4e1b4b077c66a5de982a765cedf9c449f58",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/src/org/apache/pig/builtin/PigStorage.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/PigStorage.java?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad",
                "deletions": 5,
                "filename": "src/org/apache/pig/builtin/PigStorage.java",
                "patch": "@@ -97,6 +97,7 @@ public PigStorage(String delimiter) {\n \n     @Override\n     public Tuple getNext() throws IOException {\n+        mProtoTuple = new ArrayList<Object>();\n         if (!mRequiredColumnsInitialized) {\n             if (signature!=null) {\n                 Properties p = UDFContext.getUDFContext().getUDFProperties(this.getClass());\n@@ -127,7 +128,6 @@ public Tuple getNext() throws IOException {\n                 readField(buf, start, len);\n             }\n             Tuple t =  mTupleFactory.newTupleNoCopy(mProtoTuple);\n-            mProtoTuple = null;\n             return t;\n         } catch (InterruptedException e) {\n             int errCode = 6018;\n@@ -171,10 +171,6 @@ public void putNext(Tuple f) throws IOException {\n     }\n \n     private void readField(byte[] buf, int start, int end) {\n-        if (mProtoTuple == null) {\n-            mProtoTuple = new ArrayList<Object>();\n-        }\n-\n         if (start == end) {\n             // NULL value\n             mProtoTuple.add(null);",
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/src/org/apache/pig/builtin/PigStorage.java",
                "sha": "de877f55ecfab3b0de9fa955bcc9bb5d304989e8",
                "status": "modified"
            },
            {
                "additions": 47,
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/test/org/apache/pig/test/TestPigStorage.java",
                "changes": 66,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigStorage.java?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad",
                "deletions": 19,
                "filename": "test/org/apache/pig/test/TestPigStorage.java",
                "patch": "@@ -26,46 +26,47 @@\n import java.io.IOException;\n import java.io.PrintWriter;\n import java.util.Iterator;\n+import java.util.Properties;\n+import java.util.Map.Entry;\n \n import junit.framework.Assert;\n \n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n+import org.apache.pig.ExecType;\n import org.apache.pig.PigServer;\n import org.apache.pig.backend.executionengine.ExecException;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject;\n import org.apache.pig.data.Tuple;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n+import org.apache.pig.impl.io.FileLocalizer;\n+import org.junit.Before;\n import org.junit.Test;\n \n-public class TestPigStorage {\n+public class TestPigStorage  {\n         \n     protected final Log log = LogFactory.getLog(getClass());\n     \n     private static MiniCluster cluster = MiniCluster.buildCluster();\n-    private static PigServer pigServer = null;\n     \n-    \n-    @BeforeClass\n-    public static void setup() {\n-        try {\n-            pigServer = new PigServer(MAPREDUCE, cluster.getProperties());\n-        } catch (ExecException e) {\n-            e.printStackTrace();\n-            Assert.fail();\n-        }\n-    }\n-    \n-    @AfterClass\n-    public static void shutdown() {\n-        pigServer.shutdown();\n+    @Before\n+    public void setup() {\n+        // some tests are in map-reduce mode and some in local - so before\n+        // each test, we will de-initialize FileLocalizer so that temp files\n+        // are created correctly depending on the ExecType in the test.\n+        FileLocalizer.setInitialized(false);\n     }\n     \n     @Test\n-    public void testBlockBoundary() {\n+    public void testBlockBoundary() throws ExecException {\n         \n         // This tests PigStorage loader with records exectly \n         // on the boundary of the file blocks.\n+        Properties props = new Properties();\n+        for (Entry<Object, Object> entry : cluster.getProperties().entrySet()) {\n+            props.put(entry.getKey(), entry.getValue());\n+        }\n+        props.setProperty(\"mapred.max.split.size\", \"20\");\n+        PigServer pigServer = new PigServer(MAPREDUCE, props);\n         String[] inputs = {\n                 \"abcdefgh1\", \"abcdefgh2\", \"abcdefgh3\", \n                 \"abcdefgh4\", \"abcdefgh5\", \"abcdefgh6\",\n@@ -115,5 +116,32 @@ public void testBlockBoundary() {\n             }\n         }\n     } \n+    \n+    /**\n+     * Test to verify that PigStorage works fine in the following scenario:\n+     * The column prune optimization determines only columns 2 and 3 are needed\n+     * and there are records in the data which have only 1 column (malformed data).\n+     * In this case, PigStorage should return an empty tuple to represent columns\n+     * 2 and 3 and {@link POProject} would handle catching any \n+     * {@link IndexOutOfBoundsException} resulting from accessing a field in the\n+     * tuple and substitute a null. \n+     */\n+    @Test\n+    public void testPruneColumnsWithMissingFields() throws IOException {\n+        String inputFileName = \"TestPigStorage-testPruneColumnsWithMissingFields-input.txt\";\n+        Util.createLocalInputFile(\n+                inputFileName, \n+                new String[] {\"1\\t2\\t3\", \"4\", \"5\\t6\\t7\"});\n+        PigServer ps = new PigServer(ExecType.LOCAL);\n+        String script = \"a = load '\" + inputFileName + \"' as (i:int, j:int, k:int);\" +\n+        \t\t\"b = foreach a generate j, k;\";\n+        Util.registerMultiLineQuery(ps, script);\n+        Iterator<Tuple> it = ps.openIterator(\"b\");\n+        assertEquals(Util.createTuple(new Integer[] { 2, 3}), it.next());\n+        assertEquals(Util.createTuple(new Integer[] { null, null}), it.next());\n+        assertEquals(Util.createTuple(new Integer[] { 6, 7}), it.next());\n+        assertFalse(it.hasNext());\n+                \n+    }\n \n }",
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/test/org/apache/pig/test/TestPigStorage.java",
                "sha": "356b082d8aa0bee9ef02022c664b311990f91ef4",
                "status": "modified"
            }
        ],
        "message": "PIG-1366: PigStorage's pushProjection implementation results in NPE under certain data conditions (pradeepkth)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@932144 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/28f0849b88b81e2703c633af5082744f1a7bcc45",
        "repo": "pig",
        "unit_tests": [
            "TestPigStorage.java"
        ]
    },
    "pig_aba9f47": {
        "bug_id": "pig_aba9f47",
        "commit": "https://github.com/apache/pig/commit/aba9f47589d8a11b8d6ad428343eb780464496af",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/aba9f47589d8a11b8d6ad428343eb780464496af/src/org/apache/pig/LoadFunc.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/LoadFunc.java?ref=aba9f47589d8a11b8d6ad428343eb780464496af",
                "deletions": 1,
                "filename": "src/org/apache/pig/LoadFunc.java",
                "patch": "@@ -303,6 +303,7 @@ public void setUDFContextSignature(String signature) {\n      */\n     public final void warn(String msg, Enum warningEnum) {\n         Counter counter = PigStatusReporter.getInstance().getCounter(warningEnum);\n-        counter.increment(1);\n+        if (counter!=null)\n+            counter.increment(1);\n     }\n }",
                "raw_url": "https://github.com/apache/pig/raw/aba9f47589d8a11b8d6ad428343eb780464496af/src/org/apache/pig/LoadFunc.java",
                "sha": "1cae5cf820b2b4137484b6ac7dedf34a3409b9cb",
                "status": "modified"
            }
        ],
        "message": "Tiny fix: NPE introduced by PIG-2332\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1208338 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/369b81c18afad938b9d33915cb63d5591cbe38c1",
        "repo": "pig",
        "unit_tests": [
            "TestLoadFunc.java"
        ]
    },
    "pig_d332485": {
        "bug_id": "pig_d332485",
        "commit": "https://github.com/apache/pig/commit/d3324852207252e156d13fc6ee75d26149ff6731",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/d3324852207252e156d13fc6ee75d26149ff6731/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=d3324852207252e156d13fc6ee75d26149ff6731",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -40,6 +40,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3377: New AvroStorage throws NPE when storing untyped map/array/bag (jadler via cheolsoo)\n+\n PIG-3542: Javadoc of REGEX_EXTRACT_ALL (nyigitba via daijy)\n \n PIG-3518: Need to ship jruby.jar in the release (daijy)",
                "raw_url": "https://github.com/apache/pig/raw/d3324852207252e156d13fc6ee75d26149ff6731/CHANGES.txt",
                "sha": "5897047b19536b3afaea6d64045740c3330e4b51",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/pig/blob/d3324852207252e156d13fc6ee75d26149ff6731/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java?ref=d3324852207252e156d13fc6ee75d26149ff6731",
                "deletions": 2,
                "filename": "src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "patch": "@@ -427,6 +427,9 @@ private static Schema resourceFieldSchemaToAvroSchema(\n           schema.getFields()[0].getSchema(), name, null,\n           definedRecordNames,\n           doubleColonsToDoubleUnderscores);\n+      if (innerBagSchema == null) {\n+        throw new IOException(\"AvroStorage can't save bags with untyped values; please specify a value type or a schema.\");\n+      }\n       return createNullableUnion(Schema.createArray(innerBagSchema));\n     case DataType.BIGCHARARRAY:\n       return createNullableUnion(Type.STRING);\n@@ -457,10 +460,15 @@ private static Schema resourceFieldSchemaToAvroSchema(\n     case DataType.LONG:\n       return createNullableUnion(Type.LONG);\n     case DataType.MAP:\n+      if (schema == null) {\n+        throw new IOException(\"AvroStorage can't save maps with untyped values; please specify a value type or a schema.\");\n+      }\n       byte innerType = schema.getFields()[0].getType();\n       String desc = schema.getFields()[0].getDescription();\n-      if (desc.equals(\"autogenerated from Pig Field Schema\")) {\n-        desc = null;\n+      if (desc != null) {\n+        if (desc.equals(\"autogenerated from Pig Field Schema\")) {\n+          desc = null;\n+        }\n       }\n       Schema innerSchema;\n       if (DataType.isComplex(innerType)) {\n@@ -480,6 +488,9 @@ private static Schema resourceFieldSchemaToAvroSchema(\n     case DataType.NULL:\n       return Schema.create(Type.NULL);\n     case DataType.TUPLE:\n+      if (schema == null) {\n+        throw new IOException(\"AvroStorage can't save tuples with untyped values; please specify a value type or a schema.\");\n+      }\n       Schema returnSchema = createNullableUnion(\n           resourceSchemaToAvroSchema(schema, name, null,\n               definedRecordNames, doubleColonsToDoubleUnderscores));",
                "raw_url": "https://github.com/apache/pig/raw/d3324852207252e156d13fc6ee75d26149ff6731/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "sha": "fb89e9c766de24eccd2d7485d39f799cfd0397f8",
                "status": "modified"
            }
        ],
        "message": "PIG-3377: New AvroStorage throws NPE when storing untyped map/bag/tuple (jadler via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1536044 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/5358546758669c04fcf109210997424eadfc216c",
        "repo": "pig",
        "unit_tests": [
            "TestAvroStorageSchemaConversionUtilities.java"
        ]
    },
    "pig_edc5ec1": {
        "bug_id": "pig_edc5ec1",
        "commit": "https://github.com/apache/pig/commit/edc5ec1d076a05591ab8cdfa2881eb317f98e202",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -142,6 +142,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-1988: Importing an empty macro file causing NPE (rding)\n+\n PIG-1977: \"Stream closed\" error while reading Pig temp files (results of intermediate jobs) (rding)\n \n PIG-1963: in nested foreach, accumutive udf taking input from order-by does not get results in order (thejas)",
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/CHANGES.txt",
                "sha": "15d13c4258b9b1e7db03a202956ee40b9c310c68",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/src/org/apache/pig/parser/QueryParserUtils.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/parser/QueryParserUtils.java?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202",
                "deletions": 1,
                "filename": "src/org/apache/pig/parser/QueryParserUtils.java",
                "patch": "@@ -191,7 +191,10 @@ static void replaceNodeWithNodeList(Tree oldNode, CommonTree newTree,\n \n         for (int i = 0; i < count; i++) {\n             if (i == idx) {\n-                parent.addChildren(macroList);\n+                // add only there is something to add\n+                if (macroList != null) {\n+                    parent.addChildren(macroList);\n+                }\n             } else {\n                 parent.addChild((Tree) childList.get(i));\n             }",
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/src/org/apache/pig/parser/QueryParserUtils.java",
                "sha": "9a3f26db7746e5a96a41f4fc5d6957d869f6c987",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/test/org/apache/pig/test/TestMacroExpansion.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestMacroExpansion.java?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202",
                "deletions": 1,
                "filename": "test/org/apache/pig/test/TestMacroExpansion.java",
                "patch": "@@ -1663,6 +1663,31 @@ public void test35() throws Exception {\n         testMacro( query, expected );\n     }\n     \n+    // PIG-1988\n+    @Test\n+    public void test36() throws Exception {\n+        File f = new File(\"mymacro.pig\");\n+        f.deleteOnExit();\n+        \n+        FileWriter fw = new FileWriter(f);\n+        fw.append(\" \");\n+        fw.close();\n+\n+        String query = \"import 'mymacro.pig';\" +\n+            \"define macro1() returns dummy {}; \" + \n+            \"A = load '1.txt' as (a0:int, a1:chararray);\" +\n+            \"dummy = macro1();\" +\n+            \"B = group A by a0;\" + \n+            \"store B into 'output';\";\n+        \n+        String expected = \n+            \"A = load '1.txt' as (a0:int, a1:chararray);\\n\" +\n+            \"B = group A by (a0);\\n\" +\n+            \"store B INTO 'output';\\n\";\n+        \n+        verify(query, expected);\n+    }\n+    \n     @Test\n     public void testCommentInMacro() throws Exception {\n         String query = \"a = load 'testComplexCast' as (m);\\n\" +\n@@ -1734,7 +1759,11 @@ private void verify(String s, String expected) throws Exception {\n         \n         String[] args = { \"-Dpig.import.search.path=/tmp\", \"-x\", \"local\", \"-c\", \"myscript.pig\" };\n         PigStats stats = PigRunner.run(args, null);\n- \n+        \n+        if (!stats.isSuccessful()) {\n+            System.out.println(\"error msg: \" + stats.getErrorMessage());\n+        }\n+        \n         assertTrue(stats.isSuccessful());\n         \n         String[] args2 = { \"-Dpig.import.search.path=/tmp\", \"-x\", \"local\", \"-r\", \"myscript.pig\" };",
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/test/org/apache/pig/test/TestMacroExpansion.java",
                "sha": "3536751e15982f9c3fecb03112b099337fc31197",
                "status": "modified"
            }
        ],
        "message": "PIG-1988: Importing an empty macro file causing NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1091242 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/ce385ecec65e9ac62cec3410046dc41ec66645a5",
        "repo": "pig",
        "unit_tests": [
            "TestQueryParserUtils.java"
        ]
    },
    "pig_f878f90": {
        "bug_id": "pig_f878f90",
        "commit": "https://github.com/apache/pig/commit/f878f90c267ec45ef1091d98b7d92e77020d5ea4",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -249,6 +249,8 @@ OPTIMIZATIONS\n \n BUG FIXES\n \n+PIG-3132: NPE when illustrating a relation with HCatLoader (daijy)\n+\n PIG-3194: Changes to ObjectSerializer.java break compatibility with Hadoop 0.20.2 (prkommireddi via dvryaboy)\n \n PIG-3241: ConcurrentModificationException in POPartialAgg (dvryaboy)",
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/CHANGES.txt",
                "sha": "3cfdf3bf19430b05c51a10a420746257790707dc",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4",
                "deletions": 1,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "patch": "@@ -93,7 +93,7 @@ public void setUp() throws IOException{\n         loader = new ReadToEndLoader((LoadFunc)\n                 PigContext.instantiateFuncFromSpec(lFile.getFuncSpec()), \n                 ConfigurationUtil.toConfiguration(pc.getProperties()), \n-                lFile.getFileName(),0);\n+                lFile.getFileName(),0, signature);\n     }\n     \n     /**",
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "sha": "55bd896245c8e3c42b8c25d2d8d78e12f853ea58",
                "status": "modified"
            },
            {
                "additions": 19,
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/io/ReadToEndLoader.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4",
                "deletions": 1,
                "filename": "src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "patch": "@@ -106,6 +106,8 @@\n     private InputFormat inputFormat = null;\n     \n     private PigContext pigContext;\n+    \n+    private String udfContextSignature = null;\n \n     /**\n      * @param wrappedLoadFunc\n@@ -133,6 +135,16 @@ public ReadToEndLoader(LoadFunc wrappedLoadFunc, Configuration conf,\n         this.pigContext = pigContext;\n         init();\n     }\n+    \n+    public ReadToEndLoader(LoadFunc wrappedLoadFunc, Configuration conf,\n+            String inputLocation, int splitIndex, String signature) throws IOException {\n+        this.udfContextSignature = signature;\n+        this.wrappedLoadFunc = wrappedLoadFunc;\n+        this.inputLocation = inputLocation;\n+        this.conf = conf;\n+        this.curSplitIndex = splitIndex;\n+        init();\n+    }\n \n     /**\n      * This constructor takes an array of split indexes (toReadSplitIdxs) of the \n@@ -167,6 +179,7 @@ private void init() throws IOException {\n \n         // let's initialize the wrappedLoadFunc \n         Job job = new Job(conf);\n+        wrappedLoadFunc.setUDFContextSignature(this.udfContextSignature);\n         wrappedLoadFunc.setLocation(inputLocation, \n                 job);\n         // The above setLocation call could write to the conf within\n@@ -277,7 +290,7 @@ public void prepareToRead(RecordReader reader, PigSplit split) {\n \n     @Override\n     public void setLocation(String location, Job job) throws IOException {\n-        //no-op\n+        wrappedLoadFunc.setLocation(location, job);\n     }\n \n     @Override\n@@ -313,4 +326,9 @@ public void setPartitionFilter(Expression partitionFilter) throws IOException {\n              ((LoadMetadata) wrappedLoadFunc).setPartitionFilter(partitionFilter);\n         }\n     }\n+    \n+    @Override\n+    public void setUDFContextSignature(String signature) {\n+        this.udfContextSignature = signature;\n+    }\n }",
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "sha": "8435a3590e79f51b2e6043fe08bf8e22251a4edf",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/pen/LocalMapReduceSimulator.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4",
                "deletions": 0,
                "filename": "src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "patch": "@@ -105,6 +105,7 @@ public void launchPig(PhysicalPlan php, Map<LOLoad, DataBag> baseData,\n         // jc is null only when mrp.size == 0\n         boolean needFileInput;\n         final ArrayList<OperatorKey> emptyInpTargets = new ArrayList<OperatorKey>();\n+        pc.getProperties().setProperty(\"pig.illustrating\", \"true\");\n         while(mrp.size() != 0) {\n             jc = jcc.compile(mrp, \"Illustrator\");\n             if(jc == null) {",
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "sha": "416c78fd0a3fbb0d5b9d5ec9e5b60ca282557639",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/test/org/apache/pig/test/TestExampleGenerator.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestExampleGenerator.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4",
                "deletions": 0,
                "filename": "test/org/apache/pig/test/TestExampleGenerator.java",
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.pig.data.DataBag;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.newplan.Operator;\n+import org.apache.pig.test.utils.UDFContextTestLoaderWithSignature;\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n@@ -394,5 +395,14 @@ public void testFilterGroupCountStore() throws Exception {\n     \n         assertNotNull(derivedData);\n     }\n+    \n+    @Test\n+    public void testLoaderWithContext() throws Exception {\n+        PigServer pigServer = new PigServer(pigContext);\n+        pigServer.registerQuery(\"A = load \" + A.toString() + \" using \" + UDFContextTestLoaderWithSignature.class.getName() + \"('a') as (x, y);\");\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"A\");\n+        \n+        assertNotNull(derivedData);\n+    }\n \n }",
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/test/org/apache/pig/test/TestExampleGenerator.java",
                "sha": "f9b5203c4329b963f500136cb9e2e76bdd607f43",
                "status": "modified"
            }
        ],
        "message": "PIG-3132: NPE when illustrating a relation with HCatLoader\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1457884 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/e59573212a5c450ace0e8de8077bfef6f148fbff",
        "repo": "pig",
        "unit_tests": [
            "TestReadToEndLoader.java"
        ]
    },
    "pig_f947c43": {
        "bug_id": "pig_f947c43",
        "commit": "https://github.com/apache/pig/commit/f947c43b34904297f2e5fd967604631cc0c366cb",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/CHANGES.txt",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=f947c43b34904297f2e5fd967604631cc0c366cb",
                "deletions": 0,
                "filename": "CHANGES.txt",
                "patch": "@@ -56,6 +56,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4112: NPE in packager when union + group-by followed by replicated join in Tez (rohini via cheolsoo)\n+\n PIG-4113: TEZ-1386 breaks hadoop 2 compilation in trunk (cheolsoo)\n \n PIG-4110: TEZ-1382 breaks Hadoop 2 compilation (cheolsoo)",
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/CHANGES.txt",
                "sha": "3dc0179f7e52f0de9d243c7f6d808c3b8801ae87",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java?ref=f947c43b34904297f2e5fd967604631cc0c366cb",
                "deletions": 3,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "patch": "@@ -137,9 +137,6 @@ public void run() {\n             task.setUncaughtExceptionHandler(jctExceptionHandler);\n             task.setContextClassLoader(PigContext.getClassLoader());\n \n-            // TezJobControl always holds a single TezJob. We use JobControl\n-            // only because it is convenient to launch the job via\n-            // ControlledJob.submit().\n             tezStats.setTezJob(runningJob);\n \n             // Mark the times that the jobs were submitted so it's reflected in job",
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "sha": "725ffd9ceb1c0a3182bb09a81ce0411f19343630",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java?ref=f947c43b34904297f2e5fd967604631cc0c366cb",
                "deletions": 1,
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "patch": "@@ -140,7 +140,7 @@ public LoRearrangeDiscoverer(PhysicalPlan plan, TezOperator pkgTezOp, POPackage\n         @Override\n         public void visitLocalRearrange(POLocalRearrange lrearrange) throws VisitorException {\n             POLocalRearrangeTez lr = (POLocalRearrangeTez) lrearrange;\n-            if (!lr.getOutputKey().equals(pkgTezOp.getOperatorKey().toString())) {\n+            if (!(lr.isConnectedToPackage() && lr.getOutputKey().equals(pkgTezOp.getOperatorKey().toString()))) {\n                 return;\n             }\n             loRearrangeFound++;",
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "sha": "94122a5dae612c818d33ccfbbb4cafa194ddde60",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/test/e2e/pig/tests/nightly.conf",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/e2e/pig/tests/nightly.conf?ref=f947c43b34904297f2e5fd967604631cc0c366cb",
                "deletions": 0,
                "filename": "test/e2e/pig/tests/nightly.conf",
                "patch": "@@ -1493,6 +1493,16 @@ c = union a, b;\n d = foreach c generate (name is not NULL? UPPER(name) : 'FNU LNU') as name, (age < 30 ? -1 : age) as age, (gpa is NULL ? 0.0 : ((gpa > 0.5 AND gpa < 1.0) ? 1 : gpa)) as gpa;\n e = filter d by (name matches '.*MIKE.*') OR (NOT (gpa + 1.5 > 4));\n store e into ':OUTPATH:';\\,\n+            },\n+            {\n+            'num' => 13,\n+            'pig' => q\\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);\n+b = load ':INPATH:/singlefile/studentcolon10k' using PigStorage(':') as (name, age, gpa);\n+c = union a, b;\n+d = group c by name;\n+e = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);\n+f = join d by group, e by name using 'replicated';\n+store f into ':OUTPATH:';\\,\n             },\n \t\t]\n \t\t},",
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/test/e2e/pig/tests/nightly.conf",
                "sha": "bc288d99d086483d045dbeac7fdc76571e9745a8",
                "status": "modified"
            }
        ],
        "message": "PIG-4112: NPE in packager when union + group-by followed by replicated join in Tez (rohini via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1617200 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/cb3e95936576278a486eae07dda93bb71c0490cd",
        "repo": "pig",
        "unit_tests": [
            "TestTezLauncher.java"
        ]
    },
    "pig_f9a24a9": {
        "bug_id": "pig_f9a24a9",
        "commit": "https://github.com/apache/pig/commit/f9a24a9b9140444e7a0559eb727b66bc036792de",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/pig/blob/f9a24a9b9140444e7a0559eb727b66bc036792de/src/org/apache/pig/builtin/PigStorage.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/PigStorage.java?ref=f9a24a9b9140444e7a0559eb727b66bc036792de",
                "deletions": 2,
                "filename": "src/org/apache/pig/builtin/PigStorage.java",
                "patch": "@@ -28,7 +28,6 @@\n import org.apache.commons.cli.GnuParser;\n import org.apache.commons.cli.HelpFormatter;\n import org.apache.commons.cli.Option;\n-import org.apache.commons.cli.OptionBuilder;\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.commons.logging.Log;\n@@ -166,7 +165,7 @@ private Options populateValidOptions() {\n         validOptions.addOption(TAG_SOURCE_FILE, false, \"Appends input source file name to beginning of each tuple.\");\n         validOptions.addOption(TAG_SOURCE_PATH, false, \"Appends input source file path to beginning of each tuple.\");\n         validOptions.addOption(\"tagsource\", false, \"Appends input source file name to beginning of each tuple.\");\n-        Option overwrite = new Option(null, \"Overwrites the destination.\");\n+        Option overwrite = new Option(\" \", \"Overwrites the destination.\");\n         overwrite.setLongOpt(\"overwrite\");\n         overwrite.setOptionalArg(true);\n         overwrite.setArgs(1);",
                "raw_url": "https://github.com/apache/pig/raw/f9a24a9b9140444e7a0559eb727b66bc036792de/src/org/apache/pig/builtin/PigStorage.java",
                "sha": "675f138fc36e2595b430225c2dca3853ed82656e",
                "status": "modified"
            }
        ],
        "message": "PIG-3988: PigStorage: CommandLineParser is not thread safe (tmwoodruff via rohini) - Fix NPE with commons-cli-1.0.jar\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1601993 13f79535-47bb-0310-9956-ffa450edef68",
        "parent": "https://github.com/apache/pig/commit/beaca12dc346df325f98cd01911b4ae7d51a23e1",
        "repo": "pig",
        "unit_tests": [
            "TestPigStorage.java"
        ]
    }
}