{
    "storm_01f7a02": {
        "bug_id": "storm_01f7a02",
        "commit": "https://github.com/apache/storm/commit/01f7a02bd0971eb40322d4ab63fd8bc948192544",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/01f7a02bd0971eb40322d4ab63fd8bc948192544/external/storm-kafka/src/jvm/storm/kafka/KafkaUtils.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka/src/jvm/storm/kafka/KafkaUtils.java?ref=01f7a02bd0971eb40322d4ab63fd8bc948192544",
                "deletions": 0,
                "filename": "external/storm-kafka/src/jvm/storm/kafka/KafkaUtils.java",
                "patch": "@@ -202,6 +202,9 @@ public static ByteBufferMessageSet fetchMessages(KafkaConfig config, SimpleConsu\n     public static Iterable<List<Object>> generateTuples(KafkaConfig kafkaConfig, Message msg) {\n         Iterable<List<Object>> tups;\n         ByteBuffer payload = msg.payload();\n+        if (payload == null) {\n+            return null;\n+        }\n         ByteBuffer key = msg.key();\n         if (key != null && kafkaConfig.scheme instanceof KeyValueSchemeAsMultiScheme) {\n             tups = ((KeyValueSchemeAsMultiScheme) kafkaConfig.scheme).deserializeKeyAndValue(Utils.toByteArray(key), Utils.toByteArray(payload));",
                "raw_url": "https://github.com/apache/storm/raw/01f7a02bd0971eb40322d4ab63fd8bc948192544/external/storm-kafka/src/jvm/storm/kafka/KafkaUtils.java",
                "sha": "4b9d11336c5672a652281549a8bdfd41b37e7a3e",
                "status": "modified"
            }
        ],
        "message": "external/storm-kafka: avoid NPE on null message payloads",
        "parent": "https://github.com/apache/storm/commit/97608671d59c8d8267822c62481e4a40963834c8",
        "patched_files": [
            "KafkaUtils.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "KafkaUtilsTest.java"
        ]
    },
    "storm_0267d54": {
        "bug_id": "storm_0267d54",
        "commit": "https://github.com/apache/storm/commit/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/coordination/BatchSubtopologyBuilder.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/coordination/BatchSubtopologyBuilder.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 18,
                "filename": "storm-client/src/jvm/org/apache/storm/coordination/BatchSubtopologyBuilder.java",
                "patch": "@@ -450,17 +450,7 @@ private void addDeclaration(InputDeclaration declaration) {\n         @Override\n         public BoltDeclarer addConfigurations(Map<String, Object> conf) {\n             if (conf != null) {\n-                component.componentConf.putAll(conf);\n-            }\n-            return this;\n-        }\n-\n-        @Override\n-        public BoltDeclarer addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n+                getComponentConfiguration().putAll(conf);\n             }\n             return this;\n         }\n@@ -471,14 +461,9 @@ public BoltDeclarer addSharedMemory(SharedMemory request) {\n             return this;\n         }\n \n-        @SuppressWarnings(\"unchecked\")\n         @Override\n-        public BoltDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return component.componentConf;\n         }\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/coordination/BatchSubtopologyBuilder.java",
                "sha": "c1efb46053eb6a57e0a8e8e0dcb8ee9e32d085d3",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/drpc/LinearDRPCTopologyBuilder.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/drpc/LinearDRPCTopologyBuilder.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 17,
                "filename": "storm-client/src/jvm/org/apache/storm/drpc/LinearDRPCTopologyBuilder.java",
                "patch": "@@ -407,24 +407,14 @@ public LinearDRPCInputDeclarer addConfigurations(Map<String, Object> conf) {\n             return this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n         @Override\n-        public LinearDRPCInputDeclarer addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n-            }\n-            return this;\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        @Override\n-        public LinearDRPCInputDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return component.componentConf;\n         }\n \n         @Override",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/drpc/LinearDRPCTopologyBuilder.java",
                "sha": "7d6a6be1c7a804d030f8445f9c281251d95e31f5",
                "status": "modified"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/BaseConfigurationDeclarer.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/BaseConfigurationDeclarer.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 0,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/BaseConfigurationDeclarer.java",
                "patch": "@@ -86,4 +86,30 @@ public T setCPULoad(Number amount) {\n         }\n         return (T) this;\n     }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    public T addResource(String resourceName, Number resourceValue) {\n+        Map<String, Double> resourcesMap = (Map<String, Double>) getComponentConfiguration().computeIfAbsent(Config.TOPOLOGY_COMPONENT_RESOURCES_MAP,\n+            (x) -> new HashMap<String, Double>());\n+        resourcesMap.put(resourceName, resourceValue.doubleValue());\n+\n+        return (T) this;\n+    }\n+\n+    /**\n+     * Add generic resources for this component.\n+     *\n+     * @param resources\n+     */\n+    @Override\n+    public T addResources(Map<String, Double> resources) {\n+        if (resources != null) {\n+            Map<String, Double> currentResources = (Map<String, Double>) getComponentConfiguration().computeIfAbsent(\n+                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n+            currentResources.putAll(resources);\n+        }\n+        return (T) this;\n+    }\n+\n+\n }",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/BaseConfigurationDeclarer.java",
                "sha": "ea78e2a78adb5f7ec84788d23014115652a3cdaa",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/ComponentConfigurationDeclarer.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/ComponentConfigurationDeclarer.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 0,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/ComponentConfigurationDeclarer.java",
                "patch": "@@ -28,6 +28,13 @@\n      */\n     T addConfigurations(Map<String, Object> conf);\n \n+    /**\n+     * return the current component configuration.\n+     *\n+     * @return the current configuration.\n+     */\n+    Map<String, Object> getComponentConfiguration();\n+\n     /**\n      * Add in a single config.\n      * @param config the key for the config",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/ComponentConfigurationDeclarer.java",
                "sha": "28c44186765ae137430a98fdd727a083e2b3d46f",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/TopologyBuilder.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/TopologyBuilder.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 0,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/TopologyBuilder.java",
                "patch": "@@ -585,6 +585,16 @@ public T addConfigurations(Map<String, Object> conf) {\n             return (T) this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n+        @Override\n+        public Map<String, Object> getComponentConfiguration() {\n+            return parseJson(commons.get(id).get_json_conf());\n+        }\n+\n         @Override\n         public T addResources(Map<String, Double> resources) {\n             if (resources != null && !resources.isEmpty()) {",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/topology/TopologyBuilder.java",
                "sha": "60a7eb351a514ceee33a72270703801c4e94e75e",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/transactional/TransactionalTopologyBuilder.java",
                "changes": 51,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/transactional/TransactionalTopologyBuilder.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 35,
                "filename": "storm-client/src/jvm/org/apache/storm/transactional/TransactionalTopologyBuilder.java",
                "patch": "@@ -230,31 +230,21 @@ public SpoutDeclarer addConfigurations(Map<String, Object> conf) {\n             return this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n         @Override\n-        public SpoutDeclarerImpl addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) spoutConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n-            }\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return spoutConf;\n         }\n \n         @Override\n         public SpoutDeclarer addSharedMemory(SharedMemory request) {\n             spoutSharedMemory.add(request);\n             return this;\n         }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        @Override\n-        public SpoutDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) spoutConf.computeIfAbsent(Config.TOPOLOGY_COMPONENT_RESOURCES_MAP,\n-                (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n-        }\n     }\n     \n     private static class BoltDeclarerImpl extends BaseConfigurationDeclarer<BoltDeclarer> implements BoltDeclarer {\n@@ -553,34 +543,25 @@ private void addDeclaration(InputDeclaration declaration) {\n         @Override\n         public BoltDeclarer addConfigurations(Map<String, Object> conf) {\n             if (conf != null) {\n-                component.componentConf.putAll(conf);\n+                getComponentConfiguration().putAll(conf);\n             }\n             return this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n         @Override\n-        public BoltDeclarer addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n-            }\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return component.componentConf;\n         }\n+\n         @Override\n         public BoltDeclarer addSharedMemory(SharedMemory request) {\n             component.sharedMemory.add(request);\n             return this;\n         }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        @Override\n-        public BoltDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n-        }\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/transactional/TransactionalTopologyBuilder.java",
                "sha": "a6602b1ba2c7c2027db91ab7fc6769ad66d4e35a",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/storm/blob/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/trident/topology/TridentTopologyBuilder.java",
                "changes": 50,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/trident/topology/TridentTopologyBuilder.java?ref=0267d549a96c1e7aefa3cb5d23e1cca559dd8e74",
                "deletions": 35,
                "filename": "storm-client/src/jvm/org/apache/storm/trident/topology/TridentTopologyBuilder.java",
                "patch": "@@ -366,24 +366,14 @@ public SpoutDeclarer addConfigurations(Map<String, Object> conf) {\n             return this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n         @Override\n-        public SpoutDeclarer addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n-            }\n-            return this;\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        @Override\n-        public SpoutDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return component.componentConf;\n         }\n \n         @Override\n@@ -779,30 +769,20 @@ public BoltDeclarer addConfigurations(Map<String, Object> conf) {\n             return this;\n         }\n \n+        /**\n+         * return the current component configuration.\n+         *\n+         * @return the current configuration.\n+         */\n         @Override\n-        public BoltDeclarer addResources(Map<String, Double> resources) {\n-            if (resources != null) {\n-                Map<String, Double> currentResources = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                    Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-                currentResources.putAll(resources);\n-            }\n-            return this;\n+        public Map<String, Object> getComponentConfiguration() {\n+            return component.componentConf;\n         }\n \n-        @Override\n+       @Override\n         public BoltDeclarer addSharedMemory(SharedMemory request) {\n             component.sharedMemory.add(request);\n             return this;\n         }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        @Override\n-        public BoltDeclarer addResource(String resourceName, Number resourceValue) {\n-            Map<String, Double> resourcesMap = (Map<String, Double>) component.componentConf.computeIfAbsent(\n-                Config.TOPOLOGY_COMPONENT_RESOURCES_MAP, (k) -> new HashMap<>());\n-\n-            resourcesMap.put(resourceName, resourceValue.doubleValue());\n-            return this;\n-        }\n     }    \n }",
                "raw_url": "https://github.com/apache/storm/raw/0267d549a96c1e7aefa3cb5d23e1cca559dd8e74/storm-client/src/jvm/org/apache/storm/trident/topology/TridentTopologyBuilder.java",
                "sha": "fcf8174deeb7de3abc043911f5e36235954f744f",
                "status": "modified"
            }
        ],
        "message": "Refactor addResource and addResources Method and avoid NPEs",
        "parent": "https://github.com/apache/storm/commit/09e01231cc427004bab475c9c70f21fa79cfedef",
        "patched_files": [
            "TopologyBuilder.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TopologyBuilderTest.java"
        ]
    },
    "storm_07c795a": {
        "bug_id": "storm_07c795a",
        "commit": "https://github.com/apache/storm/commit/07c795af5dd398832049262d25858ecc846f4ac5",
        "file": [
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/storm/blob/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "changes": 63,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java?ref=07c795af5dd398832049262d25858ecc846f4ac5",
                "deletions": 24,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "patch": "@@ -22,56 +22,53 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.ConcurrentHashMap;\n-import org.apache.storm.Constants;\n import org.apache.storm.messaging.netty.BackPressureStatus;\n import org.apache.storm.utils.JCQueue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import static org.apache.storm.Constants.SYSTEM_TASK_ID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import java.util.stream.Collectors;\n+import org.apache.storm.shade.org.apache.commons.lang.builder.ToStringBuilder;\n+import org.apache.storm.shade.org.apache.commons.lang.builder.ToStringStyle;\n \n /***\n- *   Tracks the BackPressure status using a Map<TaskId, JCQueue>.\n- *   Special value NONE, is used to indicate that the task is not under BackPressure\n- *   ConcurrentHashMap does not allow storing null values, so we use the special value NONE instead.\n+ *   Tracks the BackPressure status.\n  */\n public class BackPressureTracker {\n     static final Logger LOG = LoggerFactory.getLogger(BackPressureTracker.class);\n-    private static final JCQueue NONE = new JCQueue(\"NoneQ\", 2, 0, 1, null,\n-                                                    \"none\", Constants.SYSTEM_COMPONENT_ID, -1, 0) {\n-    };\n-    private final Map<Integer, JCQueue> tasks = new ConcurrentHashMap<>(); // updates are more frequent than iteration\n+    private final Map<Integer, BackpressureState> tasks;\n     private final String workerId;\n \n-    public BackPressureTracker(String workerId, List<Integer> allLocalTasks) {\n+    public BackPressureTracker(String workerId, Map<Integer, JCQueue> localTasksToQueues) {\n         this.workerId = workerId;\n-        for (Integer taskId : allLocalTasks) {\n-            if (taskId != SYSTEM_TASK_ID) {\n-                tasks.put(taskId, NONE);  // all tasks are considered to be not under BP initially\n-            }\n-        }\n+        this.tasks = localTasksToQueues.entrySet().stream()\n+            .collect(Collectors.toMap(\n+                entry -> entry.getKey(),\n+                entry -> new BackpressureState(entry.getValue())));\n     }\n \n     private void recordNoBackPressure(Integer taskId) {\n-        tasks.put(taskId, NONE);\n+        tasks.get(taskId).backpressure.set(false);\n     }\n \n     /***\n      * Record BP for a task.\n      * This is called by transferLocalBatch() on NettyWorker thread\n      * @return true if an update was recorded, false if taskId is already under BP\n      */\n-    public boolean recordBackPressure(Integer taskId, JCQueue recvQ) {\n-        return tasks.put(taskId, recvQ) == NONE;\n+    public boolean recordBackPressure(Integer taskId) {\n+        return tasks.get(taskId).backpressure.getAndSet(true) == false;\n     }\n \n     // returns true if there was a change in the BP situation\n     public boolean refreshBpTaskList() {\n         boolean changed = false;\n         LOG.debug(\"Running Back Pressure status change check\");\n-        for (Entry<Integer, JCQueue> entry : tasks.entrySet()) {\n-            if (entry.getValue() != NONE && entry.getValue().isEmptyOverflow()) {\n+        for (Entry<Integer, BackpressureState> entry : tasks.entrySet()) {\n+            BackpressureState state = entry.getValue();\n+            if (state.backpressure.get() && state.queue.isEmptyOverflow()) {\n                 recordNoBackPressure(entry.getKey());\n                 changed = true;\n             }\n@@ -83,14 +80,32 @@ public BackPressureStatus getCurrStatus() {\n         ArrayList<Integer> bpTasks = new ArrayList<>(tasks.size());\n         ArrayList<Integer> nonBpTasks = new ArrayList<>(tasks.size());\n \n-        for (Entry<Integer, JCQueue> entry : tasks.entrySet()) {\n-            JCQueue q = entry.getValue();\n-            if (q != NONE) {\n+        for (Entry<Integer, BackpressureState> entry : tasks.entrySet()) {\n+            boolean backpressure = entry.getValue().backpressure.get();\n+            if (backpressure) {\n                 bpTasks.add(entry.getKey());\n             } else {\n                 nonBpTasks.add(entry.getKey());\n             }\n         }\n         return new BackPressureStatus(workerId, bpTasks, nonBpTasks);\n     }\n+    \n+    private static class BackpressureState {\n+        private final JCQueue queue;\n+        //No task is under backpressure initially\n+        private final AtomicBoolean backpressure = new AtomicBoolean(false);\n+\n+        public BackpressureState(JCQueue queue) {\n+            this.queue = queue;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return new ToStringBuilder(this, ToStringStyle.SHORT_PREFIX_STYLE)\n+                .append(queue)\n+                .append(backpressure)\n+                .toString();\n+        }\n+    }\n }",
                "raw_url": "https://github.com/apache/storm/raw/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "sha": "a4e87bae623f64d483ae9f5e54863d40d5513cbb",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/storm/blob/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java?ref=07c795af5dd398832049262d25858ecc846f4ac5",
                "deletions": 20,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "patch": "@@ -114,11 +114,9 @@\n     final ReentrantReadWriteLock endpointSocketLock;\n     final AtomicReference<Map<Integer, NodeInfo>> cachedTaskToNodePort;\n     final AtomicReference<Map<NodeInfo, IConnection>> cachedNodeToPortSocket;\n-    final Map<List<Long>, JCQueue> executorReceiveQueueMap;\n     // executor id is in form [start_task_id end_task_id]\n-    // short executor id is start_task_id\n-    final Map<Integer, JCQueue> shortExecutorReceiveQueueMap;\n-    final Map<Integer, Integer> taskToShortExecutor;\n+    final Map<List<Long>, JCQueue> executorReceiveQueueMap;\n+    final Map<Integer, JCQueue> taskToExecutorQueue;\n     final Runnable suicideCallback;\n     final Utils.UptimeComputer uptime;\n     final Map<String, Object> defaultSharedResources;\n@@ -166,12 +164,15 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         this.isTopologyActive = new AtomicBoolean(false);\n         this.stormComponentToDebug = new AtomicReference<>();\n         this.executorReceiveQueueMap = mkReceiveQueueMap(topologyConf, localExecutors);\n-        this.shortExecutorReceiveQueueMap = new HashMap<>();\n         this.localTaskIds = new ArrayList<>();\n+        this.taskToExecutorQueue = new HashMap<>();\n         this.blobToLastKnownVersion = new ConcurrentHashMap<>();\n         for (Map.Entry<List<Long>, JCQueue> entry : executorReceiveQueueMap.entrySet()) {\n-            this.shortExecutorReceiveQueueMap.put(entry.getKey().get(0).intValue(), entry.getValue());\n-            this.localTaskIds.addAll(StormCommon.executorIdToTasks(entry.getKey()));\n+            List<Integer> taskIds = StormCommon.executorIdToTasks(entry.getKey());\n+            for (Integer taskId : taskIds) {\n+                this.taskToExecutorQueue.put(taskId, entry.getValue());\n+            }\n+            this.localTaskIds.addAll(taskIds);\n         }\n         Collections.sort(localTaskIds);\n         this.topologyConf = topologyConf;\n@@ -192,12 +193,6 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         this.endpointSocketLock = new ReentrantReadWriteLock();\n         this.cachedNodeToPortSocket = new AtomicReference<>(new HashMap<>());\n         this.cachedTaskToNodePort = new AtomicReference<>(new HashMap<>());\n-        this.taskToShortExecutor = new HashMap<>();\n-        for (List<Long> executor : this.localExecutors) {\n-            for (Integer task : StormCommon.executorIdToTasks(executor)) {\n-                taskToShortExecutor.put(task, executor.get(0).intValue());\n-            }\n-        }\n         this.suicideCallback = Utils.mkSuicideFn();\n         this.uptime = Utils.makeUptimeComputer();\n         this.defaultSharedResources = makeDefaultResources();\n@@ -212,7 +207,7 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         }\n         int maxTaskId = getMaxTaskId(componentToSortedTasks);\n         this.workerTransfer = new WorkerTransfer(this, topologyConf, maxTaskId);\n-        this.bpTracker = new BackPressureTracker(workerId, localTaskIds);\n+        this.bpTracker = new BackPressureTracker(workerId, taskToExecutorQueue);\n         this.deserializedWorkerHooks = deserializeWorkerHooks();\n     }\n \n@@ -323,10 +318,6 @@ public StormTopology getSystemTopology() {\n         return executorReceiveQueueMap;\n     }\n \n-    public Map<Integer, JCQueue> getShortExecutorReceiveQueueMap() {\n-        return shortExecutorReceiveQueueMap;\n-    }\n-\n     public Runnable getSuicideCallback() {\n         return suicideCallback;\n     }\n@@ -531,7 +522,7 @@ private void transferLocalBatch(ArrayList<AddressedTuple> tupleBatch) {\n \n         for (int i = 0; i < tupleBatch.size(); i++) {\n             AddressedTuple tuple = tupleBatch.get(i);\n-            JCQueue queue = shortExecutorReceiveQueueMap.get(tuple.dest);\n+            JCQueue queue = taskToExecutorQueue.get(tuple.dest);\n \n             // 1- try adding to main queue if its overflow is not empty\n             if (queue.isEmptyOverflow()) {\n@@ -542,7 +533,7 @@ private void transferLocalBatch(ArrayList<AddressedTuple> tupleBatch) {\n \n             // 2- BP detected (i.e MainQ is full). So try adding to overflow\n             int currOverflowCount = queue.getOverflowCount();\n-            if (bpTracker.recordBackPressure(tuple.dest, queue)) {\n+            if (bpTracker.recordBackPressure(tuple.dest)) {\n                 receiver.sendBackPressureStatus(bpTracker.getCurrStatus());\n                 lastOverflowCount = currOverflowCount;\n             } else {",
                "raw_url": "https://github.com/apache/storm/raw/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "sha": "9510bc0e0a422f452c6f41ed25b62079313c8288",
                "status": "modified"
            },
            {
                "additions": 119,
                "blob_url": "https://github.com/apache/storm/blob/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/test/jvm/org/apache/storm/daemon/worker/BackPressureTrackerTest.java",
                "changes": 119,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/test/jvm/org/apache/storm/daemon/worker/BackPressureTrackerTest.java?ref=07c795af5dd398832049262d25858ecc846f4ac5",
                "deletions": 0,
                "filename": "storm-client/test/jvm/org/apache/storm/daemon/worker/BackPressureTrackerTest.java",
                "patch": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2018 The Apache Software Foundation.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.daemon.worker;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.empty;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+import org.apache.storm.messaging.netty.BackPressureStatus;\n+import org.apache.storm.shade.org.apache.curator.shaded.com.google.common.collect.ImmutableMap;\n+import org.apache.storm.utils.JCQueue;\n+import org.junit.Test;\n+\n+public class BackPressureTrackerTest {\n+\n+    private static final String WORKER_ID = \"worker\";\n+\n+    @Test\n+    public void testGetBackpressure() {\n+        int taskIdNoBackPressure = 1;\n+        JCQueue noBackPressureQueue = mock(JCQueue.class);\n+        BackPressureTracker tracker = new BackPressureTracker(WORKER_ID,\n+            Collections.singletonMap(taskIdNoBackPressure, noBackPressureQueue));\n+\n+        BackPressureStatus status = tracker.getCurrStatus();\n+\n+        assertThat(status.workerId, is(WORKER_ID));\n+        assertThat(status.nonBpTasks, contains(taskIdNoBackPressure));\n+        assertThat(status.bpTasks, is(empty()));\n+    }\n+\n+    @Test\n+    public void testSetBackpressure() {\n+        int taskIdNoBackPressure = 1;\n+        JCQueue noBackPressureQueue = mock(JCQueue.class);\n+        int taskIdBackPressure = 2;\n+        JCQueue backPressureQueue = mock(JCQueue.class);\n+        BackPressureTracker tracker = new BackPressureTracker(WORKER_ID, ImmutableMap.of(\n+            taskIdNoBackPressure, noBackPressureQueue,\n+            taskIdBackPressure, backPressureQueue));\n+\n+        boolean backpressureChanged = tracker.recordBackPressure(taskIdBackPressure);\n+        BackPressureStatus status = tracker.getCurrStatus();\n+\n+        assertThat(backpressureChanged, is(true));\n+        assertThat(status.workerId, is(WORKER_ID));\n+        assertThat(status.nonBpTasks, contains(taskIdNoBackPressure));\n+        assertThat(status.bpTasks, contains(taskIdBackPressure));\n+    }\n+\n+    @Test\n+    public void testSetBackpressureWithExistingBackpressure() {\n+        int taskId = 1;\n+        JCQueue queue = mock(JCQueue.class);\n+        BackPressureTracker tracker = new BackPressureTracker(WORKER_ID, ImmutableMap.of(\n+            taskId, queue));\n+        tracker.recordBackPressure(taskId);\n+\n+        boolean backpressureChanged = tracker.recordBackPressure(taskId);\n+        BackPressureStatus status = tracker.getCurrStatus();\n+\n+        assertThat(backpressureChanged, is(false));\n+        assertThat(status.workerId, is(WORKER_ID));\n+        assertThat(status.bpTasks, contains(taskId));\n+    }\n+\n+    @Test\n+    public void testRefreshBackpressureWithEmptyOverflow() {\n+        int taskId = 1;\n+        JCQueue queue = mock(JCQueue.class);\n+        when(queue.isEmptyOverflow()).thenReturn(true);\n+        BackPressureTracker tracker = new BackPressureTracker(WORKER_ID, ImmutableMap.of(\n+            taskId, queue));\n+        tracker.recordBackPressure(taskId);\n+\n+        boolean backpressureChanged = tracker.refreshBpTaskList();\n+        BackPressureStatus status = tracker.getCurrStatus();\n+\n+        assertThat(backpressureChanged, is(true));\n+        assertThat(status.workerId, is(WORKER_ID));\n+        assertThat(status.nonBpTasks, contains(taskId));\n+    }\n+\n+    @Test\n+    public void testRefreshBackPressureWithNonEmptyOverflow() {\n+        int taskId = 1;\n+        JCQueue queue = mock(JCQueue.class);\n+        when(queue.isEmptyOverflow()).thenReturn(false);\n+        BackPressureTracker tracker = new BackPressureTracker(WORKER_ID, ImmutableMap.of(\n+            taskId, queue));\n+        tracker.recordBackPressure(taskId);\n+\n+        boolean backpressureChanged = tracker.refreshBpTaskList();\n+        BackPressureStatus status = tracker.getCurrStatus();\n+\n+        assertThat(backpressureChanged, is(false));\n+        assertThat(status.workerId, is(WORKER_ID));\n+        assertThat(status.bpTasks, contains(taskId));\n+    }\n+\n+}",
                "raw_url": "https://github.com/apache/storm/raw/07c795af5dd398832049262d25858ecc846f4ac5/storm-client/test/jvm/org/apache/storm/daemon/worker/BackPressureTrackerTest.java",
                "sha": "7e891b5c48ca0ad784f99674184b0c4ecc1328f7",
                "status": "added"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/storm/blob/07c795af5dd398832049262d25858ecc846f4ac5/storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/test/java/org/apache/storm/MessagingTest.java?ref=07c795af5dd398832049262d25858ecc846f4ac5",
                "deletions": 0,
                "filename": "storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "patch": "@@ -58,4 +58,38 @@ public void testLocalTransport() throws Exception {\n             Assert.assertEquals(6 * 4, Testing.readTuples(results, \"2\").size());\n         }\n     }\n+    \n+    @Test\n+    public void testRemoteTransportWithManyTasksInReceivingExecutor() throws Exception {\n+        //STORM-3141 regression test\n+        //Verify that remote worker can handle many tasks in one executor\n+        Config topoConf = new Config();\n+        topoConf.put(Config.TOPOLOGY_WORKERS, 2);\n+        topoConf.put(Config.STORM_MESSAGING_TRANSPORT, \"org.apache.storm.messaging.netty.Context\");\n+\n+        try (ILocalCluster cluster = new LocalCluster.Builder().withSimulatedTime()\n+                                                               .withSupervisors(1).withPortsPerSupervisor(2)\n+                                                               .withDaemonConf(topoConf).build()) {\n+\n+            TopologyBuilder builder = new TopologyBuilder();\n+            builder.setSpout(\"1\", new TestWordSpout(true), 1);\n+            builder.setBolt(\"2\", new TestGlobalCount(), 1)\n+                .setNumTasks(10)\n+                .shuffleGrouping(\"1\");\n+            StormTopology stormTopology = builder.createTopology();\n+\n+            List<FixedTuple> fixedTuples = new ArrayList<>();\n+            for (int i = 0; i < 12; i++) {\n+                fixedTuples.add(new FixedTuple(Collections.singletonList(\"a\")));\n+                fixedTuples.add(new FixedTuple(Collections.singletonList(\"b\")));\n+            }\n+            Map<String, List<FixedTuple>> data = new HashMap<>();\n+            data.put(\"1\", fixedTuples);\n+            MockedSources mockedSources = new MockedSources(data);\n+            CompleteTopologyParam completeTopologyParam = new CompleteTopologyParam();\n+            completeTopologyParam.setMockedSources(mockedSources);\n+            Map<String, List<FixedTuple>> results = Testing.completeTopology(cluster, stormTopology, completeTopologyParam);\n+            Assert.assertEquals(6 * 4, Testing.readTuples(results, \"2\").size());\n+        }\n+    }\n }",
                "raw_url": "https://github.com/apache/storm/raw/07c795af5dd398832049262d25858ecc846f4ac5/storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "sha": "74b73883c96aea07cbc9de8804dca679a390a1bd",
                "status": "modified"
            }
        ],
        "message": "Merge branch 'STORM-3141' of https://github.com/srdo/storm into STORM-3141\n\nSTORM-3141: Fix NPE in WorkerState.transferLocalBatch\n\nThis closes #2750",
        "parent": "https://github.com/apache/storm/commit/2d7c7d31679b16a8797f39ff3f1c8df2b63952d7",
        "patched_files": [
            "WorkerState.java",
            "BackPressureTracker.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "BackPressureTrackerTest.java",
            "MessagingTest.java"
        ]
    },
    "storm_08938c2": {
        "bug_id": "storm_08938c2",
        "commit": "https://github.com/apache/storm/commit/08938c222e0f81f40c3d9bd3e5231bb86ae6e815",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/08938c222e0f81f40c3d9bd3e5231bb86ae6e815/storm-core/src/jvm/org/apache/storm/tuple/Fields.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/jvm/org/apache/storm/tuple/Fields.java?ref=08938c222e0f81f40c3d9bd3e5231bb86ae6e815",
                "deletions": 2,
                "filename": "storm-core/src/jvm/org/apache/storm/tuple/Fields.java",
                "patch": "@@ -59,8 +59,8 @@ public Fields(List<String> fields) {\n      */\n     public List<Object> select(Fields selector, List<Object> tuple) {\n         List<Object> ret = new ArrayList<>(selector.size());\n-        for(String s: selector) {\n-            ret.add(tuple.get(_index.get(s)));\n+        for (String s : selector) {\n+            ret.add(tuple.get(fieldIndex(s))); \n         }\n         return ret;\n     }",
                "raw_url": "https://github.com/apache/storm/raw/08938c222e0f81f40c3d9bd3e5231bb86ae6e815/storm-core/src/jvm/org/apache/storm/tuple/Fields.java",
                "sha": "840b2d32e2e47996e8982ac418ecd43b3d20e496",
                "status": "modified"
            }
        ],
        "message": "STORM-1594 org.apache.storm.tuple.Fields can throw NPE if given invalid field in selector\n\n* Closes #1522",
        "parent": "https://github.com/apache/storm/commit/883a76b4d3b4d12b1a468597d5e358495cacf632",
        "patched_files": [
            "Fields.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "FieldsTest.java"
        ]
    },
    "storm_1308f89": {
        "bug_id": "storm_1308f89",
        "commit": "https://github.com/apache/storm/commit/1308f89dc7316ea8b1483136cd5ca1209790ef81",
        "file": [
            {
                "additions": 43,
                "blob_url": "https://github.com/apache/storm/blob/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/clj/backtype/storm/stats.clj",
                "changes": 88,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/clj/backtype/storm/stats.clj?ref=1308f89dc7316ea8b1483136cd5ca1209790ef81",
                "deletions": 45,
                "filename": "storm-core/src/clj/backtype/storm/stats.clj",
                "patch": "@@ -287,29 +287,52 @@\n       specific-stats\n       rate)))\n \n+(defn valid-number?\n+  \"Returns true if x is a number that is not NaN or Infinity, false otherwise\"\n+  [x]\n+  (and (number? x)\n+       (not (Double/isNaN x))\n+       (not (Double/isInfinite x))))\n+\n+(defn apply-default\n+  [f defaulting-fn & args]\n+  (apply f (map defaulting-fn args)))\n+\n+(defn apply-or-0\n+  [f & args]\n+  (apply apply-default\n+         f\n+         #(if (valid-number? %) % 0)\n+         args))\n+\n+(defn sum-or-0\n+  [& args]\n+  (apply apply-or-0 + args))\n+\n+(defn product-or-0\n+  [& args]\n+  (apply apply-or-0 * args))\n+\n+(defn max-or-0\n+  [& args]\n+  (apply apply-or-0 max args))\n+\n (defn- agg-bolt-lat-and-count\n   \"Aggregates number executed, process latency, and execute latency across all\n   streams.\"\n   [idk->exec-avg idk->proc-avg idk->num-executed]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->exec-avg\n-                       idk->proc-avg\n-                       idk->num-executed]))}\n-  (letfn [(weight-avg [[id avg]] (let [num-e (get idk->num-executed id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [[id avg]]\n+            (let [num-e (get idk->num-executed id)]\n+              (product-or-0 avg num-e)))]\n     {:executeLatencyTotal (sum (map weight-avg idk->exec-avg))\n      :processLatencyTotal (sum (map weight-avg idk->proc-avg))\n      :executed (sum (vals idk->num-executed))}))\n \n (defn- agg-spout-lat-and-count\n   \"Aggregates number acked and complete latencies across all streams.\"\n   [sid->comp-avg sid->num-acked]\n-  {:pre (apply = (map #(set (keys %))\n-                      [sid->comp-avg\n-                       sid->num-acked]))}\n-  (letfn [(weight-avg [[id avg]] (* avg (get sid->num-acked id)))]\n+  (letfn [(weight-avg [[id avg]]\n+            (product-or-0 avg (get sid->num-acked id)))]\n     {:completeLatencyTotal (sum (map weight-avg sid->comp-avg))\n      :acked (sum (vals sid->num-acked))}))\n \n@@ -335,30 +358,21 @@\n (defn- agg-bolt-streams-lat-and-count\n   \"Aggregates number executed and process & execute latencies.\"\n   [idk->exec-avg idk->proc-avg idk->executed]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->exec-avg\n-                       idk->proc-avg\n-                       idk->executed]))}\n-  (letfn [(weight-avg [id avg] (let [num-e (idk->executed id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [id avg]\n+            (let [num-e (idk->executed id)]\n+              (product-or-0 avg num-e)))]\n     (into {}\n       (for [k (keys idk->exec-avg)]\n-        [k {:executeLatencyTotal (weight-avg k (idk->exec-avg k))\n-            :processLatencyTotal (weight-avg k (idk->proc-avg k))\n+        [k {:executeLatencyTotal (weight-avg k (get idk->exec-avg k))\n+            :processLatencyTotal (weight-avg k (get idk->proc-avg k))\n             :executed (idk->executed k)}]))))\n \n (defn- agg-spout-streams-lat-and-count\n   \"Aggregates number acked and complete latencies.\"\n   [idk->comp-avg idk->acked]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->comp-avg\n-                       idk->acked]))}\n-  (letfn [(weight-avg [id avg] (let [num-e (get idk->acked id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [id avg]\n+            (let [num-e (get idk->acked id)]\n+              (product-or-0 avg num-e)))]\n     (into {}\n       (for [k (keys idk->comp-avg)]\n         [k {:completeLatencyTotal (weight-avg k (get idk->comp-avg k))\n@@ -596,22 +610,6 @@\n                     vals\n                     sum)})}))\n \n-(defn apply-default\n-  [f defaulting-fn & args]\n-  (apply f (map defaulting-fn args)))\n-\n-(defn apply-or-0\n-  [f & args]\n-  (apply apply-default f #(or % 0) args))\n-\n-(defn sum-or-0\n-  [& args]\n-  (apply apply-or-0 + args))\n-\n-(defn max-or-0\n-  [& args]\n-  (apply apply-or-0 max args))\n-\n (defn merge-agg-comp-stats-comp-page-bolt\n   [{acc-in :cid+sid->input-stats\n     acc-out :sid->output-stats",
                "raw_url": "https://github.com/apache/storm/raw/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/clj/backtype/storm/stats.clj",
                "sha": "ea4efe41310b5f473d8f7af5cb01d637756db149",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/storm/blob/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java?ref=1308f89dc7316ea8b1483136cd5ca1209790ef81",
                "deletions": 5,
                "filename": "storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "patch": "@@ -19,11 +19,10 @@\n \n import java.util.Map;\n import java.util.HashMap;\n-import java.util.Timer;\n import java.util.TimerTask;\n-import java.util.concurrent.atomic.AtomicLong;\n \n import backtype.storm.metric.api.IMetric;\n+import backtype.storm.utils.Utils;\n \n /**\n  * Acts as a Latency Metric, but also keeps track of approximate latency\n@@ -145,7 +144,9 @@ synchronized Object getValueAndReset(long now) {\n         }\n \n         long timeSpent = now - _bucketStart;\n-        double ret = ((double)(lat + _exactExtraLat))/(count + _exactExtraCount);\n+        long exactExtraCountSum = count + _exactExtraCount;\n+        double ret = Utils.zeroIfNaNOrInf(\n+                ((double) (lat + _exactExtraLat)) / exactExtraCountSum);\n         _bucketStart = now;\n         _exactExtraLat = 0;\n         _exactExtraCount = 0;\n@@ -227,7 +228,9 @@ private synchronized void rotate(long lat, long count, long timeSpent, long targ\n         ret.put(\"600\", readApproximateLatAvg(lat, count, timeSpent, _tmTime, _tmLatBuckets, _tmCountBuckets, 600 * 1000));\n         ret.put(\"10800\", readApproximateLatAvg(lat, count, timeSpent, _thTime, _thLatBuckets, _thCountBuckets, 10800 * 1000));\n         ret.put(\"86400\", readApproximateLatAvg(lat, count, timeSpent, _odTime, _odLatBuckets, _odCountBuckets, 86400 * 1000));\n-        ret.put(\":all-time\", ((double)lat + _allTimeLat)/(count + _allTimeCount));\n+        long allTimeCountSum = count + _allTimeCount;\n+        ret.put(\":all-time\", Utils.zeroIfNaNOrInf(\n+                (double) lat + _allTimeLat)/allTimeCountSum);\n         return ret;\n     }\n \n@@ -242,7 +245,7 @@ private synchronized void rotate(long lat, long count, long timeSpent, long targ\n             totalCount += countBuckets[i];\n             timeNeeded -= bucketTime[i];\n         }\n-        return ((double)totalLat)/totalCount;\n+        return Utils.zeroIfNaNOrInf(((double) totalLat) / totalCount);\n     }\n \n     public void close() {",
                "raw_url": "https://github.com/apache/storm/raw/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "sha": "614f95ef24d11f25573b8c379fdeabb228cdb961",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/jvm/backtype/storm/utils/Utils.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/jvm/backtype/storm/utils/Utils.java?ref=1308f89dc7316ea8b1483136cd5ca1209790ef81",
                "deletions": 0,
                "filename": "storm-core/src/jvm/backtype/storm/utils/Utils.java",
                "patch": "@@ -760,5 +760,9 @@ public static long zipFileSize(File myFile) throws IOException{\n         raf.close();\n         return val;\n     }\n+\n+    public static double zeroIfNaNOrInf(double x) {\n+        return (Double.isNaN(x) || Double.isInfinite(x)) ? 0.0 : x;\n+    }\n }\n ",
                "raw_url": "https://github.com/apache/storm/raw/1308f89dc7316ea8b1483136cd5ca1209790ef81/storm-core/src/jvm/backtype/storm/utils/Utils.java",
                "sha": "00af36736fae1b905e3ae94cc6e2adee538eff38",
                "status": "modified"
            }
        ],
        "message": "Merge branch 'storm-1208-ui-npe-nan' of https://github.com/d2r/storm",
        "parent": "https://github.com/apache/storm/commit/1afa5a27cb7ab5191905d0cfafdb46f542a7c039",
        "patched_files": [
            "stats.clj",
            "LatencyStatAndMetric.java",
            "Utils.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestUtils.java",
            "LatencyStatAndMetricTest.java"
        ]
    },
    "storm_1613206": {
        "bug_id": "storm_1613206",
        "commit": "https://github.com/apache/storm/commit/1613206802ffa00f1b6b9ab56a741e86aeff6a5e",
        "file": [
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/storm/blob/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "changes": 63,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java?ref=1613206802ffa00f1b6b9ab56a741e86aeff6a5e",
                "deletions": 24,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "patch": "@@ -22,56 +22,53 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.ConcurrentHashMap;\n-import org.apache.storm.Constants;\n import org.apache.storm.messaging.netty.BackPressureStatus;\n import org.apache.storm.utils.JCQueue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import static org.apache.storm.Constants.SYSTEM_TASK_ID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import java.util.stream.Collectors;\n+import org.apache.storm.shade.org.apache.commons.lang.builder.ToStringBuilder;\n+import org.apache.storm.shade.org.apache.commons.lang.builder.ToStringStyle;\n \n /***\n- *   Tracks the BackPressure status using a Map<TaskId, JCQueue>.\n- *   Special value NONE, is used to indicate that the task is not under BackPressure\n- *   ConcurrentHashMap does not allow storing null values, so we use the special value NONE instead.\n+ *   Tracks the BackPressure status.\n  */\n public class BackPressureTracker {\n     static final Logger LOG = LoggerFactory.getLogger(BackPressureTracker.class);\n-    private static final JCQueue NONE = new JCQueue(\"NoneQ\", 2, 0, 1, null,\n-                                                    \"none\", Constants.SYSTEM_COMPONENT_ID, -1, 0) {\n-    };\n-    private final Map<Integer, JCQueue> tasks = new ConcurrentHashMap<>(); // updates are more frequent than iteration\n+    private final Map<Integer, BackpressureState> tasks;\n     private final String workerId;\n \n-    public BackPressureTracker(String workerId, List<Integer> allLocalTasks) {\n+    public BackPressureTracker(String workerId, Map<Integer, JCQueue> localTasksToQueues) {\n         this.workerId = workerId;\n-        for (Integer taskId : allLocalTasks) {\n-            if (taskId != SYSTEM_TASK_ID) {\n-                tasks.put(taskId, NONE);  // all tasks are considered to be not under BP initially\n-            }\n-        }\n+        this.tasks = localTasksToQueues.entrySet().stream()\n+            .collect(Collectors.toMap(\n+                entry -> entry.getKey(),\n+                entry -> new BackpressureState(entry.getValue())));\n     }\n \n     private void recordNoBackPressure(Integer taskId) {\n-        tasks.put(taskId, NONE);\n+        tasks.get(taskId).backpressure.set(false);\n     }\n \n     /***\n      * Record BP for a task.\n      * This is called by transferLocalBatch() on NettyWorker thread\n      * @return true if an update was recorded, false if taskId is already under BP\n      */\n-    public boolean recordBackPressure(Integer taskId, JCQueue recvQ) {\n-        return tasks.put(taskId, recvQ) == NONE;\n+    public boolean recordBackPressure(Integer taskId) {\n+        return tasks.get(taskId).backpressure.getAndSet(true);\n     }\n \n     // returns true if there was a change in the BP situation\n     public boolean refreshBpTaskList() {\n         boolean changed = false;\n         LOG.debug(\"Running Back Pressure status change check\");\n-        for (Entry<Integer, JCQueue> entry : tasks.entrySet()) {\n-            if (entry.getValue() != NONE && entry.getValue().isEmptyOverflow()) {\n+        for (Entry<Integer, BackpressureState> entry : tasks.entrySet()) {\n+            BackpressureState state = entry.getValue();\n+            if (state.backpressure.get() && state.queue.isEmptyOverflow()) {\n                 recordNoBackPressure(entry.getKey());\n                 changed = true;\n             }\n@@ -83,14 +80,32 @@ public BackPressureStatus getCurrStatus() {\n         ArrayList<Integer> bpTasks = new ArrayList<>(tasks.size());\n         ArrayList<Integer> nonBpTasks = new ArrayList<>(tasks.size());\n \n-        for (Entry<Integer, JCQueue> entry : tasks.entrySet()) {\n-            JCQueue q = entry.getValue();\n-            if (q != NONE) {\n+        for (Entry<Integer, BackpressureState> entry : tasks.entrySet()) {\n+            boolean backpressure = entry.getValue().backpressure.get();\n+            if (backpressure) {\n                 bpTasks.add(entry.getKey());\n             } else {\n                 nonBpTasks.add(entry.getKey());\n             }\n         }\n         return new BackPressureStatus(workerId, bpTasks, nonBpTasks);\n     }\n+    \n+    private static class BackpressureState {\n+        private final JCQueue queue;\n+        //No task is under backpressure initially\n+        private final AtomicBoolean backpressure = new AtomicBoolean(false);\n+\n+        public BackpressureState(JCQueue queue) {\n+            this.queue = queue;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return new ToStringBuilder(this, ToStringStyle.SHORT_PREFIX_STYLE)\n+                .append(queue)\n+                .append(backpressure)\n+                .toString();\n+        }\n+    }\n }",
                "raw_url": "https://github.com/apache/storm/raw/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-client/src/jvm/org/apache/storm/daemon/worker/BackPressureTracker.java",
                "sha": "8d96447b8e53ed424e44479c4eb6fd36aca59ad3",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/storm/blob/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java?ref=1613206802ffa00f1b6b9ab56a741e86aeff6a5e",
                "deletions": 20,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "patch": "@@ -114,11 +114,9 @@\n     final ReentrantReadWriteLock endpointSocketLock;\n     final AtomicReference<Map<Integer, NodeInfo>> cachedTaskToNodePort;\n     final AtomicReference<Map<NodeInfo, IConnection>> cachedNodeToPortSocket;\n-    final Map<List<Long>, JCQueue> executorReceiveQueueMap;\n     // executor id is in form [start_task_id end_task_id]\n-    // short executor id is start_task_id\n-    final Map<Integer, JCQueue> shortExecutorReceiveQueueMap;\n-    final Map<Integer, Integer> taskToShortExecutor;\n+    final Map<List<Long>, JCQueue> executorReceiveQueueMap;\n+    final Map<Integer, JCQueue> taskToExecutorQueue;\n     final Runnable suicideCallback;\n     final Utils.UptimeComputer uptime;\n     final Map<String, Object> defaultSharedResources;\n@@ -166,12 +164,15 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         this.isTopologyActive = new AtomicBoolean(false);\n         this.stormComponentToDebug = new AtomicReference<>();\n         this.executorReceiveQueueMap = mkReceiveQueueMap(topologyConf, localExecutors);\n-        this.shortExecutorReceiveQueueMap = new HashMap<>();\n         this.localTaskIds = new ArrayList<>();\n+        this.taskToExecutorQueue = new HashMap<>();\n         this.blobToLastKnownVersion = new ConcurrentHashMap<>();\n         for (Map.Entry<List<Long>, JCQueue> entry : executorReceiveQueueMap.entrySet()) {\n-            this.shortExecutorReceiveQueueMap.put(entry.getKey().get(0).intValue(), entry.getValue());\n-            this.localTaskIds.addAll(StormCommon.executorIdToTasks(entry.getKey()));\n+            List<Integer> taskIds = StormCommon.executorIdToTasks(entry.getKey());\n+            for (Integer taskId : taskIds) {\n+                this.taskToExecutorQueue.put(taskId, entry.getValue());\n+            }\n+            this.localTaskIds.addAll(taskIds);\n         }\n         Collections.sort(localTaskIds);\n         this.topologyConf = topologyConf;\n@@ -192,12 +193,6 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         this.endpointSocketLock = new ReentrantReadWriteLock();\n         this.cachedNodeToPortSocket = new AtomicReference<>(new HashMap<>());\n         this.cachedTaskToNodePort = new AtomicReference<>(new HashMap<>());\n-        this.taskToShortExecutor = new HashMap<>();\n-        for (List<Long> executor : this.localExecutors) {\n-            for (Integer task : StormCommon.executorIdToTasks(executor)) {\n-                taskToShortExecutor.put(task, executor.get(0).intValue());\n-            }\n-        }\n         this.suicideCallback = Utils.mkSuicideFn();\n         this.uptime = Utils.makeUptimeComputer();\n         this.defaultSharedResources = makeDefaultResources();\n@@ -212,7 +207,7 @@ public WorkerState(Map<String, Object> conf, IContext mqContext, String topology\n         }\n         int maxTaskId = getMaxTaskId(componentToSortedTasks);\n         this.workerTransfer = new WorkerTransfer(this, topologyConf, maxTaskId);\n-        this.bpTracker = new BackPressureTracker(workerId, localTaskIds);\n+        this.bpTracker = new BackPressureTracker(workerId, taskToExecutorQueue);\n         this.deserializedWorkerHooks = deserializeWorkerHooks();\n     }\n \n@@ -323,10 +318,6 @@ public StormTopology getSystemTopology() {\n         return executorReceiveQueueMap;\n     }\n \n-    public Map<Integer, JCQueue> getShortExecutorReceiveQueueMap() {\n-        return shortExecutorReceiveQueueMap;\n-    }\n-\n     public Runnable getSuicideCallback() {\n         return suicideCallback;\n     }\n@@ -531,7 +522,7 @@ private void transferLocalBatch(ArrayList<AddressedTuple> tupleBatch) {\n \n         for (int i = 0; i < tupleBatch.size(); i++) {\n             AddressedTuple tuple = tupleBatch.get(i);\n-            JCQueue queue = shortExecutorReceiveQueueMap.get(tuple.dest);\n+            JCQueue queue = taskToExecutorQueue.get(tuple.dest);\n \n             // 1- try adding to main queue if its overflow is not empty\n             if (queue.isEmptyOverflow()) {\n@@ -542,7 +533,7 @@ private void transferLocalBatch(ArrayList<AddressedTuple> tupleBatch) {\n \n             // 2- BP detected (i.e MainQ is full). So try adding to overflow\n             int currOverflowCount = queue.getOverflowCount();\n-            if (bpTracker.recordBackPressure(tuple.dest, queue)) {\n+            if (bpTracker.recordBackPressure(tuple.dest)) {\n                 receiver.sendBackPressureStatus(bpTracker.getCurrStatus());\n                 lastOverflowCount = currOverflowCount;\n             } else {",
                "raw_url": "https://github.com/apache/storm/raw/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "sha": "9510bc0e0a422f452c6f41ed25b62079313c8288",
                "status": "modified"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/storm/blob/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/test/java/org/apache/storm/MessagingTest.java?ref=1613206802ffa00f1b6b9ab56a741e86aeff6a5e",
                "deletions": 0,
                "filename": "storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "patch": "@@ -58,4 +58,38 @@ public void testLocalTransport() throws Exception {\n             Assert.assertEquals(6 * 4, Testing.readTuples(results, \"2\").size());\n         }\n     }\n+    \n+    @Test\n+    public void testRemoteTransportWithManyTasksInReceivingExecutor() throws Exception {\n+        //STORM-3141 regression test\n+        //Verify that remote worker can handle many tasks in one executor\n+        Config topoConf = new Config();\n+        topoConf.put(Config.TOPOLOGY_WORKERS, 2);\n+        topoConf.put(Config.STORM_MESSAGING_TRANSPORT, \"org.apache.storm.messaging.netty.Context\");\n+\n+        try (ILocalCluster cluster = new LocalCluster.Builder().withSimulatedTime()\n+                                                               .withSupervisors(1).withPortsPerSupervisor(2)\n+                                                               .withDaemonConf(topoConf).build()) {\n+\n+            TopologyBuilder builder = new TopologyBuilder();\n+            builder.setSpout(\"1\", new TestWordSpout(true), 1);\n+            builder.setBolt(\"2\", new TestGlobalCount(), 1)\n+                .setNumTasks(10)\n+                .shuffleGrouping(\"1\");\n+            StormTopology stormTopology = builder.createTopology();\n+\n+            List<FixedTuple> fixedTuples = new ArrayList<>();\n+            for (int i = 0; i < 12; i++) {\n+                fixedTuples.add(new FixedTuple(Collections.singletonList(\"a\")));\n+                fixedTuples.add(new FixedTuple(Collections.singletonList(\"b\")));\n+            }\n+            Map<String, List<FixedTuple>> data = new HashMap<>();\n+            data.put(\"1\", fixedTuples);\n+            MockedSources mockedSources = new MockedSources(data);\n+            CompleteTopologyParam completeTopologyParam = new CompleteTopologyParam();\n+            completeTopologyParam.setMockedSources(mockedSources);\n+            Map<String, List<FixedTuple>> results = Testing.completeTopology(cluster, stormTopology, completeTopologyParam);\n+            Assert.assertEquals(6 * 4, Testing.readTuples(results, \"2\").size());\n+        }\n+    }\n }",
                "raw_url": "https://github.com/apache/storm/raw/1613206802ffa00f1b6b9ab56a741e86aeff6a5e/storm-server/src/test/java/org/apache/storm/MessagingTest.java",
                "sha": "74b73883c96aea07cbc9de8804dca679a390a1bd",
                "status": "modified"
            }
        ],
        "message": "STORM-3141: Fix NPE in WorkerState.transferLocalBatch, and refactor BackpressureTracker to get rid of placeholder JCQueue",
        "parent": "https://github.com/apache/storm/commit/26d2f955251c0fa56520f6fe08cb35ef5171f321",
        "patched_files": [
            "WorkerState.java",
            "BackPressureTracker.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "MessagingTest.java"
        ]
    },
    "storm_1a83267": {
        "bug_id": "storm_1a83267",
        "commit": "https://github.com/apache/storm/commit/1a83267f5cacdff7db3934e3b0f00123357e2a4d",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/1a83267f5cacdff7db3934e3b0f00123357e2a4d/storm-core/src/jvm/org/apache/storm/command/CLI.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/jvm/org/apache/storm/command/CLI.java?ref=1a83267f5cacdff7db3934e3b0f00123357e2a4d",
                "deletions": 3,
                "filename": "storm-core/src/jvm/org/apache/storm/command/CLI.java",
                "patch": "@@ -238,10 +238,13 @@ public CLIBuilder arg(String name, Parse parse, Assoc assoc) {\n             DefaultParser parser = new DefaultParser();\n             CommandLine cl = parser.parse(options, rawArgs);\n             HashMap<String, Object> ret = new HashMap<>();\n-            for (Opt opt: opts) {\n+            for (Opt opt : opts) {\n                 Object current = null;\n-                for (String val: cl.getOptionValues(opt.shortName)) {\n-                    current = opt.process(current, val);\n+                String[] strings = cl.getOptionValues(opt.shortName);\n+                if (strings != null) {\n+                    for (String val : cl.getOptionValues(opt.shortName)) {\n+                        current = opt.process(current, val);\n+                    }\n                 }\n                 if (current == null) {\n                     current = opt.defaultValue;",
                "raw_url": "https://github.com/apache/storm/raw/1a83267f5cacdff7db3934e3b0f00123357e2a4d/storm-core/src/jvm/org/apache/storm/command/CLI.java",
                "sha": "2bad836afafe14c41dd48aef2841ea9ae8e6b0c8",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/1a83267f5cacdff7db3934e3b0f00123357e2a4d/storm-core/test/jvm/org/apache/storm/command/TestCLI.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/test/jvm/org/apache/storm/command/TestCLI.java?ref=1a83267f5cacdff7db3934e3b0f00123357e2a4d",
                "deletions": 1,
                "filename": "storm-core/test/jvm/org/apache/storm/command/TestCLI.java",
                "patch": "@@ -32,13 +32,15 @@ public void testSimple() throws Exception {\n            .opt(\"b\", \"bb\", 1, CLI.AS_INT)\n            .opt(\"c\", \"cc\", 1, CLI.AS_INT, CLI.FIRST_WINS)\n            .opt(\"d\", \"dd\", null, CLI.AS_STRING, CLI.INTO_LIST)\n+           .opt(\"e\", \"ee\", null, CLI.AS_INT)\n            .arg(\"A\")\n            .arg(\"B\", CLI.AS_INT)\n            .parse(\"-a100\", \"--aa\", \"200\", \"-c2\", \"-b\", \"50\", \"--cc\", \"100\", \"A-VALUE\", \"1\", \"2\", \"3\", \"-b40\", \"-d1\", \"-d2\", \"-d3\");\n-        assertEquals(6, values.size());\n+        assertEquals(7, values.size());\n         assertEquals(\"200\", (String)values.get(\"a\"));\n         assertEquals((Integer)40, (Integer)values.get(\"b\"));\n         assertEquals((Integer)2, (Integer)values.get(\"c\"));\n+        assertEquals(null, values.get(\"e\"));\n \n         List<String> d = (List<String>)values.get(\"d\");\n         assertEquals(3, d.size());",
                "raw_url": "https://github.com/apache/storm/raw/1a83267f5cacdff7db3934e3b0f00123357e2a4d/storm-core/test/jvm/org/apache/storm/command/TestCLI.java",
                "sha": "5b2f220d0bedd67833a9c28858bd4ecf35844c58",
                "status": "modified"
            }
        ],
        "message": "Merge branch '0223' of https://github.com/hustfxj/storm into STORM-1572\n\nSTORM-1572: throw NPE when parsing the command line arguments by CLI",
        "parent": "https://github.com/apache/storm/commit/71d615b7cc9a96b6667b976a25dc86ef54a66169",
        "patched_files": [
            "CLI.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestCLI.java"
        ]
    },
    "storm_2a1a417": {
        "bug_id": "storm_2a1a417",
        "commit": "https://github.com/apache/storm/commit/2a1a417f922cbce6239b5c85eb75363b92b9a2d0",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/2a1a417f922cbce6239b5c85eb75363b92b9a2d0/external/storm-kafka/src/jvm/storm/kafka/ZkCoordinator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka/src/jvm/storm/kafka/ZkCoordinator.java?ref=2a1a417f922cbce6239b5c85eb75363b92b9a2d0",
                "deletions": 1,
                "filename": "external/storm-kafka/src/jvm/storm/kafka/ZkCoordinator.java",
                "patch": "@@ -33,7 +33,7 @@\n     int _totalTasks;\n     String _topologyInstanceId;\n     Map<Partition, PartitionManager> _managers = new HashMap();\n-    List<PartitionManager> _cachedList;\n+    List<PartitionManager> _cachedList = new ArrayList<PartitionManager>();\n     Long _lastRefreshTime = null;\n     int _refreshFreqMs;\n     DynamicPartitionConnections _connections;",
                "raw_url": "https://github.com/apache/storm/raw/2a1a417f922cbce6239b5c85eb75363b92b9a2d0/external/storm-kafka/src/jvm/storm/kafka/ZkCoordinator.java",
                "sha": "3af648c59aaae646a5201ef8388ecc34f294b263",
                "status": "modified"
            }
        ],
        "message": "STORM-933:NullPointerException during KafkaSpout deactivation",
        "parent": "https://github.com/apache/storm/commit/14fdab8b188080e5f1095ed422c807493ad6fd01",
        "patched_files": [
            "ZkCoordinator.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "ZkCoordinatorTest.java"
        ]
    },
    "storm_3370b2d": {
        "bug_id": "storm_3370b2d",
        "commit": "https://github.com/apache/storm/commit/3370b2d6495be770989c048a35cd3998e899bd60",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java?ref=3370b2d6495be770989c048a35cd3998e899bd60",
                "deletions": 3,
                "filename": "external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java",
                "patch": "@@ -486,9 +486,11 @@ private boolean emitOrRetryTuple(ConsumerRecord<K, V> record) {\n                 /*if a null tuple is not configured to be emitted, it should be marked as emitted and acked immediately\n                 * to allow its offset to be commited to Kafka*/\n                 LOG.debug(\"Not emitting null tuple for record [{}] as defined in configuration.\", record);\n-                msgId.setNullTuple(true);\n-                offsetManagers.get(tp).addToEmitMsgs(msgId.offset());\n-                ack(msgId);\n+                if (isAtLeastOnceProcessing()) {\n+                    msgId.setNullTuple(true);\n+                    offsetManagers.get(tp).addToEmitMsgs(msgId.offset());\n+                    ack(msgId);\n+                }\n             }\n         }\n         return false;",
                "raw_url": "https://github.com/apache/storm/raw/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java",
                "sha": "4c2a6ffa391ec9dc5b66102b171e7963e1185474",
                "status": "modified"
            },
            {
                "additions": 37,
                "blob_url": "https://github.com/apache/storm/blob/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/NullRecordTranslator.java",
                "changes": 37,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/NullRecordTranslator.java?ref=3370b2d6495be770989c048a35cd3998e899bd60",
                "deletions": 0,
                "filename": "external/storm-kafka-client/src/test/java/org/apache/storm/kafka/NullRecordTranslator.java",
                "patch": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright 2018 The Apache Software Foundation.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.kafka;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.storm.kafka.spout.RecordTranslator;\n+import org.apache.storm.tuple.Fields;\n+\n+public class NullRecordTranslator<K, V> implements RecordTranslator<K, V> {\n+\n+    @Override\n+    public List<Object> apply(ConsumerRecord<K, V> record) {\n+        return null;\n+\n+    }\n+\n+    @Override\n+    public Fields getFieldsFor(String stream) {\n+        return new Fields(\"topic\", \"key\", \"value\");\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/NullRecordTranslator.java",
                "sha": "065244e1c54b18aee6d4df33e53c4d32dd10581b",
                "status": "added"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/storm/blob/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutMessagingGuaranteeTest.java",
                "changes": 58,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutMessagingGuaranteeTest.java?ref=3370b2d6495be770989c048a35cd3998e899bd60",
                "deletions": 14,
                "filename": "external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutMessagingGuaranteeTest.java",
                "patch": "@@ -21,6 +21,7 @@\n import static org.hamcrest.CoreMatchers.not;\n import static org.hamcrest.CoreMatchers.nullValue;\n import static org.junit.Assert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.ArgumentMatchers.anyList;\n import static org.mockito.ArgumentMatchers.anyLong;\n import static org.mockito.ArgumentMatchers.argThat;\n@@ -42,6 +43,7 @@\n import org.apache.kafka.clients.consumer.KafkaConsumer;\n import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n import org.apache.kafka.common.TopicPartition;\n+import org.apache.storm.kafka.NullRecordTranslator;\n import org.apache.storm.kafka.spout.config.builder.SingleTopicKafkaSpoutConfiguration;\n import org.apache.storm.kafka.spout.internal.CommitMetadataManager;\n import org.apache.storm.kafka.spout.subscription.ManualPartitioner;\n@@ -63,7 +65,7 @@\n \n     @Captor\n     private ArgumentCaptor<Map<TopicPartition, OffsetAndMetadata>> commitCapture;\n-    \n+\n     private final TopologyContext contextMock = mock(TopologyContext.class);\n     private final SpoutOutputCollector collectorMock = mock(SpoutOutputCollector.class);\n     private final Map<String, Object> conf = new HashMap<>();\n@@ -95,7 +97,7 @@ public void testAtMostOnceModeCommitsBeforeEmit() throws Exception {\n         inOrder.verify(consumerMock).poll(anyLong());\n         inOrder.verify(consumerMock).commitSync(commitCapture.capture());\n         inOrder.verify(collectorMock).emit(eq(SingleTopicKafkaSpoutConfiguration.STREAM), anyList());\n-        \n+\n         CommitMetadataManager metadataManager = new CommitMetadataManager(contextMock, KafkaSpoutConfig.ProcessingGuarantee.AT_MOST_ONCE);\n         Map<TopicPartition, OffsetAndMetadata> committedOffsets = commitCapture.getValue();\n         assertThat(committedOffsets.get(partition).offset(), is(0L));\n@@ -190,7 +192,7 @@ public void testAtMostOnceModeDoesNotCommitAckedTuples() throws Exception {\n             .setTupleTrackingEnforced(true)\n             .build();\n         try (SimulatedTime time = new SimulatedTime()) {\n-            KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock,partition);\n+            KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock, partition);\n \n             when(consumerMock.poll(anyLong())).thenReturn(new ConsumerRecords<>(Collections.singletonMap(partition,\n                 SpoutWithMockedConsumerSetupHelper.createRecords(partition, 0, 1))));\n@@ -203,13 +205,13 @@ public void testAtMostOnceModeDoesNotCommitAckedTuples() throws Exception {\n             assertThat(\"Should have captured a message id\", msgIdCaptor.getValue(), not(nullValue()));\n \n             spout.ack(msgIdCaptor.getValue());\n-            \n+\n             Time.advanceTime(KafkaSpout.TIMER_DELAY_MS + spoutConfig.getOffsetsCommitPeriodMs());\n-            \n+\n             when(consumerMock.poll(anyLong())).thenReturn(new ConsumerRecords<>(Collections.emptyMap()));\n-            \n+\n             spout.nextTuple();\n-            \n+\n             verify(consumerMock, never()).commitSync(argThat(arg -> {\n                 return !arg.containsKey(partition);\n             }));\n@@ -223,32 +225,60 @@ public void testNoGuaranteeModeCommitsPolledTuples() throws Exception {\n             .setProcessingGuarantee(KafkaSpoutConfig.ProcessingGuarantee.NO_GUARANTEE)\n             .setTupleTrackingEnforced(true)\n             .build();\n-        \n+\n         try (SimulatedTime time = new SimulatedTime()) {\n-            KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock,partition);\n+            KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock, partition);\n \n             when(consumerMock.poll(anyLong())).thenReturn(new ConsumerRecords<>(Collections.singletonMap(partition,\n                 SpoutWithMockedConsumerSetupHelper.createRecords(partition, 0, 1))));\n \n             spout.nextTuple();\n-            \n+\n             when(consumerMock.position(partition)).thenReturn(1L);\n \n             ArgumentCaptor<KafkaSpoutMessageId> msgIdCaptor = ArgumentCaptor.forClass(KafkaSpoutMessageId.class);\n             verify(collectorMock).emit(eq(SingleTopicKafkaSpoutConfiguration.STREAM), anyList(), msgIdCaptor.capture());\n             assertThat(\"Should have captured a message id\", msgIdCaptor.getValue(), not(nullValue()));\n-            \n+\n             Time.advanceTime(KafkaSpout.TIMER_DELAY_MS + spoutConfig.getOffsetsCommitPeriodMs());\n-            \n+\n             spout.nextTuple();\n-            \n+\n             verify(consumerMock).commitAsync(commitCapture.capture(), isNull());\n-            \n+\n             CommitMetadataManager metadataManager = new CommitMetadataManager(contextMock, KafkaSpoutConfig.ProcessingGuarantee.NO_GUARANTEE);\n             Map<TopicPartition, OffsetAndMetadata> committedOffsets = commitCapture.getValue();\n             assertThat(committedOffsets.get(partition).offset(), is(1L));\n             assertThat(committedOffsets.get(partition).metadata(), is(metadataManager.getCommitMetadata()));\n         }\n     }\n \n+    private void doFilterNullTupleTest(KafkaSpoutConfig.ProcessingGuarantee processingGuaranteee) {\n+        //STORM-3059\n+        KafkaSpoutConfig<String, String> spoutConfig = createKafkaSpoutConfigBuilder(mock(TopicFilter.class), mock(ManualPartitioner.class), -1)\n+            .setProcessingGuarantee(processingGuaranteee)\n+            .setTupleTrackingEnforced(true)\n+            .setRecordTranslator(new NullRecordTranslator<>())\n+            .build();\n+        \n+        KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock, partition);\n+\n+        when(consumerMock.poll(anyLong())).thenReturn(new ConsumerRecords<>(Collections.singletonMap(partition,\n+            SpoutWithMockedConsumerSetupHelper.createRecords(partition, 0, 1))));\n+\n+        spout.nextTuple();\n+        \n+        verify(collectorMock, never()).emit(any(), any(), any());\n+    }\n+    \n+    @Test\n+    public void testAtMostOnceModeCanFilterNullTuples() {\n+        doFilterNullTupleTest(KafkaSpoutConfig.ProcessingGuarantee.AT_MOST_ONCE);\n+    }\n+    \n+    @Test\n+    public void testNoGuaranteeModeCanFilterNullTuples() {\n+        doFilterNullTupleTest(KafkaSpoutConfig.ProcessingGuarantee.NO_GUARANTEE);\n+    }\n+\n }",
                "raw_url": "https://github.com/apache/storm/raw/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutMessagingGuaranteeTest.java",
                "sha": "1d2c1718aefb5239e62fc133a7269a55dde1129a",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutNullTupleTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutNullTupleTest.java?ref=3370b2d6495be770989c048a35cd3998e899bd60",
                "deletions": 25,
                "filename": "external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutNullTupleTest.java",
                "patch": "@@ -18,19 +18,18 @@\n package org.apache.storm.kafka.spout;\n \n \n-import org.apache.kafka.clients.consumer.ConsumerRecord;\n import org.apache.storm.kafka.spout.config.builder.SingleTopicKafkaSpoutConfiguration;\n-import org.apache.storm.tuple.Fields;\n import org.apache.storm.utils.Time;\n import org.junit.Test;\n \n-import java.util.List;\n import java.util.regex.Pattern;\n \n import static org.mockito.ArgumentMatchers.*;\n import static org.mockito.Mockito.never;\n import static org.mockito.Mockito.verify;\n \n+import org.apache.storm.kafka.NullRecordTranslator;\n+\n public class KafkaSpoutNullTupleTest extends KafkaSpoutAbstractTest {\n \n     public KafkaSpoutNullTupleTest() {\n@@ -40,11 +39,10 @@ public KafkaSpoutNullTupleTest() {\n \n     @Override\n     KafkaSpoutConfig<String, String> createSpoutConfig() {\n-\n         return KafkaSpoutConfig.builder(\"127.0.0.1:\" + kafkaUnitRule.getKafkaUnit().getKafkaPort(),\n                 Pattern.compile(SingleTopicKafkaSpoutConfiguration.TOPIC))\n                 .setOffsetCommitPeriodMs(commitOffsetPeriodMs)\n-                .setRecordTranslator(new NullRecordExtractor())\n+                .setRecordTranslator(new NullRecordTranslator<>())\n                 .build();\n     }\n \n@@ -70,24 +68,4 @@ public void testShouldCommitAllMessagesIfNotSetToEmitNullTuples() throws Excepti\n         verifyAllMessagesCommitted(messageCount);\n     }\n \n-    private class NullRecordExtractor implements RecordTranslator {\n-\n-        @Override\n-        public List<Object> apply(ConsumerRecord record) {\n-            return null;\n-\n-        }\n-\n-        @Override\n-        public Fields getFieldsFor(String stream) {\n-            return new Fields(\"topic\", \"key\", \"value\");\n-        }\n-\n-        @Override\n-        public Object apply(Object record) {\n-            return null;\n-        }\n-    }\n-\n-\n }",
                "raw_url": "https://github.com/apache/storm/raw/3370b2d6495be770989c048a35cd3998e899bd60/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/KafkaSpoutNullTupleTest.java",
                "sha": "ce93ea2ef58c1bb437de55596376e952d9f42007",
                "status": "modified"
            }
        ],
        "message": "STORM-3059: Fix NPE when the processing guarantee is not AT_LEAST_ONCE and the spout filters out a null tuple",
        "parent": "https://github.com/apache/storm/commit/02639f4f07140fdc3248a9ef869d62654d378d24",
        "patched_files": [
            "KafkaSpout.java",
            "NullRecordTranslator.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "KafkaSpoutMessagingGuaranteeTest.java",
            "KafkaSpoutNullTupleTest.java"
        ]
    },
    "storm_38028cf": {
        "bug_id": "storm_38028cf",
        "commit": "https://github.com/apache/storm/commit/38028cfc53d36d00775d030dd311b0afa1ae4a29",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/SimpleRecordTranslator.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/SimpleRecordTranslator.java?ref=38028cfc53d36d00775d030dd311b0afa1ae4a29",
                "deletions": 1,
                "filename": "external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/SimpleRecordTranslator.java",
                "patch": "@@ -47,8 +47,12 @@ public SimpleRecordTranslator(Func<ConsumerRecord<K, V>, List<Object>> func, Fie\n     \n     @Override\n     public List<Object> apply(ConsumerRecord<K, V> record) {\n+        List<Object> vals = func.apply(record);\n+        if (vals == null) {\n+            return null;\n+        }\n         KafkaTuple ret = new KafkaTuple();\n-        ret.addAll(func.apply(record));\n+        ret.addAll(vals);\n         return ret.routedTo(stream);\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/SimpleRecordTranslator.java",
                "sha": "a451afe1e2a13f365bd6f9f3a03c816f9f82ec6c",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/storm/blob/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/ByTopicRecordTranslatorTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/ByTopicRecordTranslatorTest.java?ref=38028cfc53d36d00775d030dd311b0afa1ae4a29",
                "deletions": 0,
                "filename": "external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/ByTopicRecordTranslatorTest.java",
                "patch": "@@ -52,6 +52,14 @@ public void testBasic() {\n         assertEquals(new Fields(\"key\", \"value\"), trans.getFieldsFor(\"key-value-stream\"));\n         assertEquals(Arrays.asList(\"THE KEY\", \"THE VALUE\"), trans.apply(cr3));\n     }\n+\n+    @Test\n+    public void testNullTranslation() {\n+        ByTopicRecordTranslator<String, String> trans =\n+                new ByTopicRecordTranslator<>((r) -> null, new Fields(\"key\"));\n+        ConsumerRecord<String, String> cr = new ConsumerRecord<>(\"TOPIC 1\", 100, 100, \"THE KEY\", \"THE VALUE\");\n+        assertEquals(null, trans.apply(cr));\n+    }\n     \n     @Test(expected = IllegalArgumentException.class)\n     public void testFieldCollision() {",
                "raw_url": "https://github.com/apache/storm/raw/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/ByTopicRecordTranslatorTest.java",
                "sha": "9a4806d1eb5a6b52be3879e399fd8d7abbc8c32b",
                "status": "modified"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/storm/blob/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SimpleRecordTranslatorTest.java",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SimpleRecordTranslatorTest.java?ref=38028cfc53d36d00775d030dd311b0afa1ae4a29",
                "deletions": 0,
                "filename": "external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SimpleRecordTranslatorTest.java",
                "patch": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+package org.apache.storm.kafka.spout;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Arrays;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.storm.tuple.Fields;\n+import org.apache.storm.tuple.Values;\n+import org.junit.Test;\n+\n+public class SimpleRecordTranslatorTest {\n+    @Test\n+    public void testBasic() {\n+        SimpleRecordTranslator<String, String> trans =\n+                new SimpleRecordTranslator<>((r) -> new Values(r.value()), new Fields(\"value\"));\n+        assertEquals(Arrays.asList(\"default\"), trans.streams());\n+        ConsumerRecord<String, String> cr = new ConsumerRecord<>(\"TOPIC\", 100, 100, \"THE KEY\", \"THE VALUE\");\n+        assertEquals(Arrays.asList(\"THE VALUE\"), trans.apply(cr));\n+    }\n+\n+    @Test\n+    public void testNullTranslation() {\n+        SimpleRecordTranslator<String, String> trans =\n+                new SimpleRecordTranslator<>((r) -> null, new Fields(\"key\"));\n+        assertEquals(null, trans.apply(null));\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/38028cfc53d36d00775d030dd311b0afa1ae4a29/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/SimpleRecordTranslatorTest.java",
                "sha": "f523257c57304c7570e75b56943fbd6273187a4e",
                "status": "added"
            }
        ],
        "message": "[STORM-3043] Fix NullPointerException when apply() returns null",
        "parent": "https://github.com/apache/storm/commit/b26a62fde8e903819e89d0addbd3ce53d59bf2d0",
        "patched_files": [
            "ByTopicRecordTranslator.java",
            "SimpleRecordTranslator.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "ByTopicRecordTranslatorTest.java",
            "SimpleRecordTranslatorTest.java"
        ]
    },
    "storm_3857644": {
        "bug_id": "storm_3857644",
        "commit": "https://github.com/apache/storm/commit/3857644b4c459cbe42b78ca8a13bd55ef704fd30",
        "file": [
            {
                "additions": 42,
                "blob_url": "https://github.com/apache/storm/blob/3857644b4c459cbe42b78ca8a13bd55ef704fd30/storm-core/src/clj/backtype/storm/stats.clj",
                "changes": 87,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/clj/backtype/storm/stats.clj?ref=3857644b4c459cbe42b78ca8a13bd55ef704fd30",
                "deletions": 45,
                "filename": "storm-core/src/clj/backtype/storm/stats.clj",
                "patch": "@@ -287,29 +287,51 @@\n       specific-stats\n       rate)))\n \n+(defn valid-number?\n+  \"Returns true if x is a number that is not NaN, false otherwise\"\n+  [x]\n+  (and (number? x)\n+       (not (Double/isNaN x))))\n+\n+(defn apply-default\n+  [f defaulting-fn & args]\n+  (apply f (map defaulting-fn args)))\n+\n+(defn apply-or-0\n+  [f & args]\n+  (apply apply-default\n+         f\n+         #(if (valid-number? %) % 0)\n+         args))\n+\n+(defn sum-or-0\n+  [& args]\n+  (apply apply-or-0 + args))\n+\n+(defn product-or-0\n+  [& args]\n+  (apply apply-or-0 * args))\n+\n+(defn max-or-0\n+  [& args]\n+  (apply apply-or-0 max args))\n+\n (defn- agg-bolt-lat-and-count\n   \"Aggregates number executed, process latency, and execute latency across all\n   streams.\"\n   [idk->exec-avg idk->proc-avg idk->num-executed]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->exec-avg\n-                       idk->proc-avg\n-                       idk->num-executed]))}\n-  (letfn [(weight-avg [[id avg]] (let [num-e (get idk->num-executed id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [[id avg]]\n+            (let [num-e (get idk->num-executed id)]\n+              (product-or-0 avg num-e)))]\n     {:executeLatencyTotal (sum (map weight-avg idk->exec-avg))\n      :processLatencyTotal (sum (map weight-avg idk->proc-avg))\n      :executed (sum (vals idk->num-executed))}))\n \n (defn- agg-spout-lat-and-count\n   \"Aggregates number acked and complete latencies across all streams.\"\n   [sid->comp-avg sid->num-acked]\n-  {:pre (apply = (map #(set (keys %))\n-                      [sid->comp-avg\n-                       sid->num-acked]))}\n-  (letfn [(weight-avg [[id avg]] (* avg (get sid->num-acked id)))]\n+  (letfn [(weight-avg [[id avg]]\n+            (product-or-0 avg (get sid->num-acked id)))]\n     {:completeLatencyTotal (sum (map weight-avg sid->comp-avg))\n      :acked (sum (vals sid->num-acked))}))\n \n@@ -335,30 +357,21 @@\n (defn- agg-bolt-streams-lat-and-count\n   \"Aggregates number executed and process & execute latencies.\"\n   [idk->exec-avg idk->proc-avg idk->executed]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->exec-avg\n-                       idk->proc-avg\n-                       idk->executed]))}\n-  (letfn [(weight-avg [id avg] (let [num-e (idk->executed id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [id avg]\n+            (let [num-e (idk->executed id)]\n+              (product-or-0 avg num-e)))]\n     (into {}\n       (for [k (keys idk->exec-avg)]\n-        [k {:executeLatencyTotal (weight-avg k (idk->exec-avg k))\n-            :processLatencyTotal (weight-avg k (idk->proc-avg k))\n+        [k {:executeLatencyTotal (weight-avg k (get idk->exec-avg k))\n+            :processLatencyTotal (weight-avg k (get idk->proc-avg k))\n             :executed (idk->executed k)}]))))\n \n (defn- agg-spout-streams-lat-and-count\n   \"Aggregates number acked and complete latencies.\"\n   [idk->comp-avg idk->acked]\n-  {:pre (apply = (map #(set (keys %))\n-                      [idk->comp-avg\n-                       idk->acked]))}\n-  (letfn [(weight-avg [id avg] (let [num-e (get idk->acked id)]\n-                                   (if (and avg num-e)\n-                                     (* avg num-e)\n-                                     0)))]\n+  (letfn [(weight-avg [id avg]\n+            (let [num-e (get idk->acked id)]\n+              (product-or-0 avg num-e)))]\n     (into {}\n       (for [k (keys idk->comp-avg)]\n         [k {:completeLatencyTotal (weight-avg k (get idk->comp-avg k))\n@@ -596,22 +609,6 @@\n                     vals\n                     sum)})}))\n \n-(defn apply-default\n-  [f defaulting-fn & args]\n-  (apply f (map defaulting-fn args)))\n-\n-(defn apply-or-0\n-  [f & args]\n-  (apply apply-default f #(or % 0) args))\n-\n-(defn sum-or-0\n-  [& args]\n-  (apply apply-or-0 + args))\n-\n-(defn max-or-0\n-  [& args]\n-  (apply apply-or-0 max args))\n-\n (defn merge-agg-comp-stats-comp-page-bolt\n   [{acc-in :cid+sid->input-stats\n     acc-out :sid->output-stats",
                "raw_url": "https://github.com/apache/storm/raw/3857644b4c459cbe42b78ca8a13bd55ef704fd30/storm-core/src/clj/backtype/storm/stats.clj",
                "sha": "cb77bb717d30a5efc630e7a436e934c0bf90d260",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/storm/blob/3857644b4c459cbe42b78ca8a13bd55ef704fd30/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java?ref=3857644b4c459cbe42b78ca8a13bd55ef704fd30",
                "deletions": 3,
                "filename": "storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "patch": "@@ -145,7 +145,10 @@ synchronized Object getValueAndReset(long now) {\n         }\n \n         long timeSpent = now - _bucketStart;\n-        double ret = ((double)(lat + _exactExtraLat))/(count + _exactExtraCount);\n+        long exactExtraCountSum = count + _exactExtraCount;\n+        double ret = exactExtraCountSum > 0 ?\n+                ((double)(lat + _exactExtraLat))/exactExtraCountSum :\n+                0.0;\n         _bucketStart = now;\n         _exactExtraLat = 0;\n         _exactExtraCount = 0;\n@@ -227,7 +230,10 @@ private synchronized void rotate(long lat, long count, long timeSpent, long targ\n         ret.put(\"600\", readApproximateLatAvg(lat, count, timeSpent, _tmTime, _tmLatBuckets, _tmCountBuckets, 600 * 1000));\n         ret.put(\"10800\", readApproximateLatAvg(lat, count, timeSpent, _thTime, _thLatBuckets, _thCountBuckets, 10800 * 1000));\n         ret.put(\"86400\", readApproximateLatAvg(lat, count, timeSpent, _odTime, _odLatBuckets, _odCountBuckets, 86400 * 1000));\n-        ret.put(\":all-time\", ((double)lat + _allTimeLat)/(count + _allTimeCount));\n+        long allTimeCountSum = count + _allTimeCount;\n+        ret.put(\":all-time\", allTimeCountSum > 0 ?\n+                ((double)lat + _allTimeLat)/allTimeCountSum :\n+                0.0);\n         return ret;\n     }\n \n@@ -242,7 +248,7 @@ private synchronized void rotate(long lat, long count, long timeSpent, long targ\n             totalCount += countBuckets[i];\n             timeNeeded -= bucketTime[i];\n         }\n-        return ((double)totalLat)/totalCount;\n+        return totalCount > 0 ? ((double)totalLat)/totalCount : 0.0;\n     }\n \n     public void close() {",
                "raw_url": "https://github.com/apache/storm/raw/3857644b4c459cbe42b78ca8a13bd55ef704fd30/storm-core/src/jvm/backtype/storm/metric/internal/LatencyStatAndMetric.java",
                "sha": "8c472bd7cc3761f5a6da97618e12ac866d203d39",
                "status": "modified"
            }
        ],
        "message": "Guard against NPE, and avoid using NaN values",
        "parent": "https://github.com/apache/storm/commit/5a79ba5f9b509d575e374e7dce58e286c1387430",
        "patched_files": [
            "stats.clj",
            "LatencyStatAndMetric.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "LatencyStatAndMetricTest.java"
        ]
    },
    "storm_3ad1937": {
        "bug_id": "storm_3ad1937",
        "commit": "https://github.com/apache/storm/commit/3ad1937ab019eff9cb5c74fa6b51785dffd46529",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/3ad1937ab019eff9cb5c74fa6b51785dffd46529/storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/ConstraintSolverStrategy.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/ConstraintSolverStrategy.java?ref=3ad1937ab019eff9cb5c74fa6b51785dffd46529",
                "deletions": 0,
                "filename": "storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/ConstraintSolverStrategy.java",
                "patch": "@@ -99,6 +99,7 @@ public static boolean validateSolution(Cluster cluster, TopologyDetails td) {\n      */\n     private static boolean checkConstraintsSatisfied(Cluster cluster, TopologyDetails topo) {\n         LOG.info(\"Checking constraints...\");\n+        assert (cluster.getAssignmentById(topo.getId()) != null);\n         Map<ExecutorDetails, WorkerSlot> result = cluster.getAssignmentById(topo.getId()).getExecutorToSlot();\n         Map<ExecutorDetails, String> execToComp = topo.getExecutorToComponent();\n         //get topology constraints\n@@ -136,6 +137,7 @@ private static boolean checkConstraintsSatisfied(Cluster cluster, TopologyDetail\n \n     private static boolean checkSpreadSchedulingValid(Cluster cluster, TopologyDetails topo) {\n         LOG.info(\"Checking for a valid scheduling...\");\n+        assert (cluster.getAssignmentById(topo.getId()) != null);\n         Map<ExecutorDetails, WorkerSlot> result = cluster.getAssignmentById(topo.getId()).getExecutorToSlot();\n         Map<ExecutorDetails, String> execToComp = topo.getExecutorToComponent();\n         Map<WorkerSlot, HashSet<ExecutorDetails>> workerExecMap = new HashMap<>();\n@@ -174,6 +176,7 @@ private static boolean checkSpreadSchedulingValid(Cluster cluster, TopologyDetai\n      */\n     private static boolean checkResourcesCorrect(Cluster cluster, TopologyDetails topo) {\n         LOG.info(\"Checking Resources...\");\n+        assert (cluster.getAssignmentById(topo.getId()) != null);\n         Map<ExecutorDetails, WorkerSlot> result = cluster.getAssignmentById(topo.getId()).getExecutorToSlot();\n         Map<RAS_Node, Collection<ExecutorDetails>> nodeToExecs = new HashMap<>();\n         Map<ExecutorDetails, WorkerSlot> mergedExecToWorker = new HashMap<>();",
                "raw_url": "https://github.com/apache/storm/raw/3ad1937ab019eff9cb5c74fa6b51785dffd46529/storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/ConstraintSolverStrategy.java",
                "sha": "bf527560175cc75fdbffd7a18c674a066828667c",
                "status": "modified"
            }
        ],
        "message": "STORM-3048 Fix a Potential NPE\n\n* Commits squashed by Jungtaek Lim <kabhwan@gmail.com>\n\nThis closes #2657",
        "parent": "https://github.com/apache/storm/commit/41f977a9e1e10a53633fabd77b30852c052dba3f",
        "patched_files": [
            "ConstraintSolverStrategy.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestConstraintSolverStrategy.java"
        ]
    },
    "storm_3fb289b": {
        "bug_id": "storm_3fb289b",
        "commit": "https://github.com/apache/storm/commit/3fb289b87c7d72bfe01ee1c7028adbc69f012439",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/3fb289b87c7d72bfe01ee1c7028adbc69f012439/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java?ref=3fb289b87c7d72bfe01ee1c7028adbc69f012439",
                "deletions": 0,
                "filename": "storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "patch": "@@ -830,6 +830,9 @@ private static TopologyPageInfo postAggregateTopoStats(Map task2comp, Map exec2n\n         Map<String, Map<K, Double>> ret = new HashMap<>();\n \n         Map<String, Map<K, List>> expands = expandAveragesSeq(avgSeq, countSeq);\n+        if (expands == null) {\n+            return ret;\n+        }\n         for (Map.Entry<String, Map<K, List>> entry : expands.entrySet()) {\n             String k = entry.getKey();\n \n@@ -2305,6 +2308,9 @@ private static Map swapMapOrder(Map m) {\n                 initVal = mergeWithAddPair(initVal, expandAverages(avg, count));\n             }\n         }\n+        if (initVal == null) {\n+            initVal = new HashMap<>();\n+        }\n         return initVal;\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/3fb289b87c7d72bfe01ee1c7028adbc69f012439/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "sha": "acca1f905cccec6fdd2940ff19418ca1b912426e",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/3fb289b87c7d72bfe01ee1c7028adbc69f012439/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java?ref=3fb289b87c7d72bfe01ee1c7028adbc69f012439",
                "deletions": 1,
                "filename": "storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "patch": "@@ -214,7 +214,7 @@ public Response getHistorySummary(@QueryParam(callbackParameterName) String call\n     }\n \n     /**\n-     * /api/v1/supervisor/summary -> topo history.\n+     * /api/v1/supervisor/summary -> supervisor summary.\n      */\n     @GET\n     @Path(\"/supervisor/summary\")\n@@ -402,6 +402,9 @@ public Response getTopologyVisualization(@PathParam(\"id\") String id,\n                     UIHelpers.getVisualizationData(nimbusClient.getClient(), window, id, sys),\n                     callback\n             );\n+        } catch (RuntimeException e) {\n+            LOG.error(\"Failure getting topology visualization\", e);\n+            throw e;\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/3fb289b87c7d72bfe01ee1c7028adbc69f012439/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "sha": "c13a4c30cb42c80a90c1c658d1c178e6e3e9a4c3",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #3202 from agresch/agresch_storm_3572\n\nSTORM-3572 prevent NPEs when doing visualization with restarting exec\u2026",
        "parent": "https://github.com/apache/storm/commit/36204eda00bca7e03ac3979d9c0d3527d1f08330",
        "patched_files": [
            "StatsUtil.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestStatsUtil.java"
        ]
    },
    "storm_55f346c": {
        "bug_id": "storm_55f346c",
        "commit": "https://github.com/apache/storm/commit/55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java?ref=55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f",
                "deletions": 1,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "patch": "@@ -16,6 +16,7 @@\n import static org.apache.storm.topology.base.BaseWindowedBolt.Duration;\n \n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashSet;\n import java.util.Iterator;\n import java.util.List;\n@@ -345,7 +346,7 @@ public void declareOutputFields(OutputFieldsDeclarer declarer) {\n \n     @Override\n     public Map<String, Object> getComponentConfiguration() {\n-        return bolt.getComponentConfiguration();\n+        return bolt.getComponentConfiguration() != null ? bolt.getComponentConfiguration() : Collections.emptyMap();\n     }\n \n     protected WindowLifecycleListener<Tuple> newWindowLifecycleListener() {",
                "raw_url": "https://github.com/apache/storm/raw/55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "sha": "4713e95d39b7ca69904893abd3bc156a16f125de",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/storm/blob/55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java?ref=55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f",
                "deletions": 0,
                "filename": "storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "patch": "@@ -39,6 +39,7 @@\n import static org.junit.Assert.assertArrayEquals;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n \n /**\n@@ -214,6 +215,14 @@ public void testExecuteWithLateTupleStream() throws Exception {\n         Mockito.verify(outputCollector).emit(\"$late\", Arrays.asList(tuple), new Values(tuple));\n     }\n \n+    @Test\n+    public void testEmptyConfigOnWrappedBolt() {\n+        IWindowedBolt wrappedBolt = Mockito.mock(IWindowedBolt.class);\n+        Mockito.when(wrappedBolt.getComponentConfiguration()).thenReturn(null);\n+        executor = new WindowedBoltExecutor(wrappedBolt);\n+        assertTrue(\"Configuration is not empty\", executor.getComponentConfiguration().isEmpty());\n+    }\n+\n     private static class TestWindowedBolt extends BaseWindowedBolt {\n         List<TupleWindow> tupleWindows = new ArrayList<>();\n ",
                "raw_url": "https://github.com/apache/storm/raw/55f346cb093d4f219ecb43b1e6b1a7c2ea5d9a5f/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "sha": "0e388388ae2716d7ee9c14add836b841f694aad9",
                "status": "modified"
            }
        ],
        "message": "STORM-3211: Fix NPE in WindowedBoltExecutor on getComponentConfiguration",
        "parent": "https://github.com/apache/storm/commit/7b1a98fc10fad516ef9ed0b3afc53a1d7be8a169",
        "patched_files": [
            "WindowedBoltExecutor.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "WindowedBoltExecutorTest.java"
        ]
    },
    "storm_5b89af3": {
        "bug_id": "storm_5b89af3",
        "commit": "https://github.com/apache/storm/commit/5b89af3d4430483ef40f9fec7cdf960e3647059e",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/5b89af3d4430483ef40f9fec7cdf960e3647059e/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java?ref=5b89af3d4430483ef40f9fec7cdf960e3647059e",
                "deletions": 0,
                "filename": "storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "patch": "@@ -830,6 +830,9 @@ private static TopologyPageInfo postAggregateTopoStats(Map task2comp, Map exec2n\n         Map<String, Map<K, Double>> ret = new HashMap<>();\n \n         Map<String, Map<K, List>> expands = expandAveragesSeq(avgSeq, countSeq);\n+        if (expands == null) {\n+            return ret;\n+        }\n         for (Map.Entry<String, Map<K, List>> entry : expands.entrySet()) {\n             String k = entry.getKey();\n \n@@ -2305,6 +2308,9 @@ private static Map swapMapOrder(Map m) {\n                 initVal = mergeWithAddPair(initVal, expandAverages(avg, count));\n             }\n         }\n+        if (initVal == null) {\n+            initVal = new HashMap<>();\n+        }\n         return initVal;\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/5b89af3d4430483ef40f9fec7cdf960e3647059e/storm-server/src/main/java/org/apache/storm/stats/StatsUtil.java",
                "sha": "acca1f905cccec6fdd2940ff19418ca1b912426e",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/5b89af3d4430483ef40f9fec7cdf960e3647059e/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java?ref=5b89af3d4430483ef40f9fec7cdf960e3647059e",
                "deletions": 1,
                "filename": "storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "patch": "@@ -214,7 +214,7 @@ public Response getHistorySummary(@QueryParam(callbackParameterName) String call\n     }\n \n     /**\n-     * /api/v1/supervisor/summary -> topo history.\n+     * /api/v1/supervisor/summary -> supervisor summary.\n      */\n     @GET\n     @Path(\"/supervisor/summary\")\n@@ -402,6 +402,9 @@ public Response getTopologyVisualization(@PathParam(\"id\") String id,\n                     UIHelpers.getVisualizationData(nimbusClient.getClient(), window, id, sys),\n                     callback\n             );\n+        } catch (RuntimeException e) {\n+            LOG.error(\"Failure getting topology visualization\", e);\n+            throw e;\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/5b89af3d4430483ef40f9fec7cdf960e3647059e/storm-webapp/src/main/java/org/apache/storm/daemon/ui/resources/StormApiResource.java",
                "sha": "c13a4c30cb42c80a90c1c658d1c178e6e3e9a4c3",
                "status": "modified"
            }
        ],
        "message": "STORM-3572 prevent NPEs when doing visualization with restarting executors",
        "parent": "https://github.com/apache/storm/commit/73737748f3800d948e53b882c4880ae06ff62720",
        "patched_files": [
            "StatsUtil.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestStatsUtil.java"
        ]
    },
    "storm_88fc18b": {
        "bug_id": "storm_88fc18b",
        "commit": "https://github.com/apache/storm/commit/88fc18b2f2d031e9915b852e16cd406fbc21a91e",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/storm/blob/88fc18b2f2d031e9915b852e16cd406fbc21a91e/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java?ref=88fc18b2f2d031e9915b852e16cd406fbc21a91e",
                "deletions": 4,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "patch": "@@ -213,10 +213,14 @@ public void cleanUpForRestart() throws IOException {\n         super.cleanUpForRestart();\n         synchronized (_localState) {\n             Map<String, Integer> workersToPort = _localState.getApprovedWorkers();\n-            workersToPort.remove(origWorkerId);\n-            removeWorkersOn(workersToPort, _port);\n-            _localState.setApprovedWorkers(workersToPort);\n-            LOG.info(\"Removed Worker ID {}\", origWorkerId);\n+            if (workersToPort != null) {\n+                workersToPort.remove(origWorkerId);\n+                removeWorkersOn(workersToPort, _port);\n+                _localState.setApprovedWorkers(workersToPort);\n+                LOG.info(\"Removed Worker ID {}\", origWorkerId);\n+            } else {\n+                LOG.warn(\"No approved workers exists\");\n+            }\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/88fc18b2f2d031e9915b852e16cd406fbc21a91e/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "sha": "9a6e5264e93ac9e80efb2c12e1cc95260ca3ba53",
                "status": "modified"
            }
        ],
        "message": "Merge branch 'agresch_storm-3208' of https://github.com/agresch/storm into STORM-3208\n\nSTORM-3208 fix worker kill NPE\n\nThis closes #2816",
        "parent": "https://github.com/apache/storm/commit/8ea2679d47dd14443f44944fed98b9e7b6c6c516",
        "patched_files": [
            "BasicContainer.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "BasicContainerTest.java"
        ]
    },
    "storm_91458a3": {
        "bug_id": "storm_91458a3",
        "commit": "https://github.com/apache/storm/commit/91458a32cded87fb64dbb1b22db8059edd6af99d",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/91458a32cded87fb64dbb1b22db8059edd6af99d/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java?ref=91458a32cded87fb64dbb1b22db8059edd6af99d",
                "deletions": 4,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "patch": "@@ -213,10 +213,12 @@ public void cleanUpForRestart() throws IOException {\n         super.cleanUpForRestart();\n         synchronized (_localState) {\n             Map<String, Integer> workersToPort = _localState.getApprovedWorkers();\n-            workersToPort.remove(origWorkerId);\n-            removeWorkersOn(workersToPort, _port);\n-            _localState.setApprovedWorkers(workersToPort);\n-            LOG.info(\"Removed Worker ID {}\", origWorkerId);\n+            if (workersToPort != null) {\n+                workersToPort.remove(origWorkerId);\n+                removeWorkersOn(workersToPort, _port);\n+                _localState.setApprovedWorkers(workersToPort);\n+                LOG.info(\"Removed Worker ID {}\", origWorkerId);\n+            }\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/91458a32cded87fb64dbb1b22db8059edd6af99d/storm-server/src/main/java/org/apache/storm/daemon/supervisor/BasicContainer.java",
                "sha": "082fc3b2bd68b0bcd0ae03b42627173a1d0707db",
                "status": "modified"
            }
        ],
        "message": "STORM-3208 fix worker kill NPE",
        "parent": "https://github.com/apache/storm/commit/aa6bc4d2cc49a36f65dcf9c4792c426f17fff069",
        "patched_files": [
            "BasicContainer.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "BasicContainerTest.java"
        ]
    },
    "storm_9165a78": {
        "bug_id": "storm_9165a78",
        "commit": "https://github.com/apache/storm/commit/9165a783590a65e935e5ee229abbad2942b12333",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/9165a783590a65e935e5ee229abbad2942b12333/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java?ref=9165a783590a65e935e5ee229abbad2942b12333",
                "deletions": 1,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "patch": "@@ -16,6 +16,7 @@\n import static org.apache.storm.topology.base.BaseWindowedBolt.Duration;\n \n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashSet;\n import java.util.Iterator;\n import java.util.List;\n@@ -345,7 +346,7 @@ public void declareOutputFields(OutputFieldsDeclarer declarer) {\n \n     @Override\n     public Map<String, Object> getComponentConfiguration() {\n-        return bolt.getComponentConfiguration();\n+        return bolt.getComponentConfiguration() != null ? bolt.getComponentConfiguration() : Collections.emptyMap();\n     }\n \n     protected WindowLifecycleListener<Tuple> newWindowLifecycleListener() {",
                "raw_url": "https://github.com/apache/storm/raw/9165a783590a65e935e5ee229abbad2942b12333/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "sha": "4713e95d39b7ca69904893abd3bc156a16f125de",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/storm/blob/9165a783590a65e935e5ee229abbad2942b12333/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java?ref=9165a783590a65e935e5ee229abbad2942b12333",
                "deletions": 0,
                "filename": "storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "patch": "@@ -39,6 +39,7 @@\n import static org.junit.Assert.assertArrayEquals;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n \n /**\n@@ -214,6 +215,14 @@ public void testExecuteWithLateTupleStream() throws Exception {\n         Mockito.verify(outputCollector).emit(\"$late\", Arrays.asList(tuple), new Values(tuple));\n     }\n \n+    @Test\n+    public void testEmptyConfigOnWrappedBolt() {\n+        IWindowedBolt wrappedBolt = Mockito.mock(IWindowedBolt.class);\n+        Mockito.when(wrappedBolt.getComponentConfiguration()).thenReturn(null);\n+        executor = new WindowedBoltExecutor(wrappedBolt);\n+        assertTrue(\"Configuration is not empty\", executor.getComponentConfiguration().isEmpty());\n+    }\n+\n     private static class TestWindowedBolt extends BaseWindowedBolt {\n         List<TupleWindow> tupleWindows = new ArrayList<>();\n ",
                "raw_url": "https://github.com/apache/storm/raw/9165a783590a65e935e5ee229abbad2942b12333/storm-client/test/jvm/org/apache/storm/topology/WindowedBoltExecutorTest.java",
                "sha": "0e388388ae2716d7ee9c14add836b841f694aad9",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #3156 from efgpinto/STORM-3211\n\nSTORM-3211: Fix NPE in WindowedBoltExecutor on getComponentConfiguration",
        "parent": "https://github.com/apache/storm/commit/dfb9b55e10b60e8755c8552eee4563ec3c86aa77",
        "patched_files": [
            "WindowedBoltExecutor.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "WindowedBoltExecutorTest.java"
        ]
    },
    "storm_917be55": {
        "bug_id": "storm_917be55",
        "commit": "https://github.com/apache/storm/commit/917be55a5bd6be8baa4811c6684897da949c3bb1",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/917be55a5bd6be8baa4811c6684897da949c3bb1/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java?ref=917be55a5bd6be8baa4811c6684897da949c3bb1",
                "deletions": 4,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "patch": "@@ -487,14 +487,16 @@ public Nimbus(Map<String, Object> conf, INimbus inimbus, IStormClusterState stor\n             blobStore = ServerUtils.getNimbusBlobStore(conf, this.nimbusHostPortInfo, null);\n         }\n         this.blobStore = blobStore;\n+\n+        if (topoCache == null) {\n+            topoCache = new TopoCache(blobStore, conf);\n+        }\n         if (leaderElector == null) {\n             leaderElector = Zookeeper.zkLeaderElector(conf, zkClient, blobStore, topoCache, stormClusterState, getNimbusAcls(conf));\n         }\n         this.leaderElector = leaderElector;\n         this.blobStore.setLeaderElector(this.leaderElector);\n-        if (topoCache == null) {\n-            topoCache = new TopoCache(blobStore, conf);\n-        }\n+\n         this.topoCache = topoCache;\n         this.assignmentsDistributer = AssignmentDistributionService.getInstance(conf);\n         this.idToSchedStatus = new AtomicReference<>(new HashMap<>());\n@@ -2136,7 +2138,7 @@ private void mkAssignments(String scratchTopoId) throws Exception {\n                 LOG.info(\"Fragmentation after scheduling is: {} MB, {} PCore CPUs\", fragmentedMemory(), fragmentedCpu());\n                 nodeIdToResources.get().forEach((id, node) ->\n                                                     LOG.info(\n-                                                        \"Node Id: {} Total Mem: {}, Used Mem: {}, Avialble Mem: {}, Total CPU: {}, Used \" +\n+                                                        \"Node Id: {} Total Mem: {}, Used Mem: {}, Available Mem: {}, Total CPU: {}, Used \" +\n                                                         \"CPU: {}, Available CPU: {}, fragmented: {}\",\n                                                         id, node.getTotalMem(), node.getUsedMem(), node.getAvailableMem(),\n                                                         node.getTotalCpu(), node.getUsedCpu(), node.getAvailableCpu(), isFragmented(node)));",
                "raw_url": "https://github.com/apache/storm/raw/917be55a5bd6be8baa4811c6684897da949c3bb1/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "sha": "48e8c210a2e1dd26730b02da683f898a736ce83e",
                "status": "modified"
            }
        ],
        "message": "STORM-3075 fix NPE",
        "parent": "https://github.com/apache/storm/commit/14b0b4fc5e0945456769fd58a3595188e3dea234",
        "patched_files": [
            "Nimbus.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "NimbusTest.java"
        ]
    },
    "storm_95a1055": {
        "bug_id": "storm_95a1055",
        "commit": "https://github.com/apache/storm/commit/95a10557ca9eed5f193841e0a72b5032b627aceb",
        "file": [
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/storm/blob/95a10557ca9eed5f193841e0a72b5032b627aceb/external/storm-kafka/src/jvm/storm/kafka/DynamicBrokersReader.java",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka/src/jvm/storm/kafka/DynamicBrokersReader.java?ref=95a10557ca9eed5f193841e0a72b5032b627aceb",
                "deletions": 16,
                "filename": "external/storm-kafka/src/jvm/storm/kafka/DynamicBrokersReader.java",
                "patch": "@@ -19,6 +19,7 @@\n \n import backtype.storm.Config;\n import backtype.storm.utils.Utils;\n+import com.google.common.base.Preconditions;\n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n import org.apache.curator.retry.RetryNTimes;\n@@ -42,12 +43,13 @@\n \n     public DynamicBrokersReader(Map conf, String zkStr, String zkPath, String topic) {\n         // Check required parameters\n-        if(conf == null) {LOG.error(\"conf cannot be null\");}\n+        Preconditions.checkNotNull(conf, \"conf cannot be null\");\n+\n         validateConfig(conf);\n \n-        if(zkStr == null) {LOG.error(\"zkString cannot be null\");}\n-        if(zkPath == null) {LOG.error(\"zkPath cannot be null\");}\n-        if(topic == null) {LOG.error(\"topic cannot be null\");}\n+        Preconditions.checkNotNull(zkStr,\"zkString cannot be null\");\n+        Preconditions.checkNotNull(zkPath, \"zkPath cannot be null\");\n+        Preconditions.checkNotNull(topic, \"topic cannot be null\");\n \n         _zkPath = zkPath;\n         _topic = topic;\n@@ -158,19 +160,19 @@ private Broker getBrokerHost(byte[] contents) {\n         }\n     }\n \n+    /**\n+     * Validate required parameters in the input configuration Map\n+     * @param conf\n+     */\n     private void validateConfig(final Map conf) {\n-        if(conf.get(Config.STORM_ZOOKEEPER_SESSION_TIMEOUT) == null) {\n-            LOG.error(\"{} cannot be null\", Config.STORM_ZOOKEEPER_SESSION_TIMEOUT);\n-        }\n-        if(conf.get(Config.STORM_ZOOKEEPER_CONNECTION_TIMEOUT) == null) {\n-            LOG.error(\"{} cannot be null\", Config.STORM_ZOOKEEPER_CONNECTION_TIMEOUT);\n-        }\n-        if(conf.get(Config.STORM_ZOOKEEPER_RETRY_TIMES) == null) {\n-            LOG.error(\"{} cannot be null\", Config.STORM_ZOOKEEPER_RETRY_TIMES);\n-        }\n-        if(conf.get(Config.STORM_ZOOKEEPER_RETRY_INTERVAL) == null) {\n-            LOG.error(\"{} cannot be null\", Config.STORM_ZOOKEEPER_RETRY_INTERVAL);\n-        }\n+        Preconditions.checkNotNull(conf.get(Config.STORM_ZOOKEEPER_SESSION_TIMEOUT),\n+                \"%s cannot be null\", Config.STORM_ZOOKEEPER_SESSION_TIMEOUT);\n+        Preconditions.checkNotNull(conf.get(Config.STORM_ZOOKEEPER_CONNECTION_TIMEOUT),\n+                \"%s cannot be null\", Config.STORM_ZOOKEEPER_CONNECTION_TIMEOUT);\n+        Preconditions.checkNotNull(conf.get(Config.STORM_ZOOKEEPER_RETRY_TIMES),\n+                \"%s cannot be null\", Config.STORM_ZOOKEEPER_RETRY_TIMES);\n+        Preconditions.checkNotNull(conf.get(Config.STORM_ZOOKEEPER_RETRY_INTERVAL),\n+                \"%s cannot be null\", Config.STORM_ZOOKEEPER_RETRY_INTERVAL);\n     }\n \n }",
                "raw_url": "https://github.com/apache/storm/raw/95a10557ca9eed5f193841e0a72b5032b627aceb/external/storm-kafka/src/jvm/storm/kafka/DynamicBrokersReader.java",
                "sha": "d379061bae106aab935cc5ae77ebf166f2902a4e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/95a10557ca9eed5f193841e0a72b5032b627aceb/external/storm-kafka/src/test/storm/kafka/DynamicBrokersReaderTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-kafka/src/test/storm/kafka/DynamicBrokersReaderTest.java?ref=95a10557ca9eed5f193841e0a72b5032b627aceb",
                "deletions": 1,
                "filename": "external/storm-kafka/src/test/storm/kafka/DynamicBrokersReaderTest.java",
                "patch": "@@ -171,7 +171,7 @@ public void testSwitchHostForPartition() throws Exception {\n         assertEquals(newHost, brokerInfo.getBrokerFor(partition).host);\n     }\n \n-    @Test(expected = RuntimeException.class)\n+    @Test(expected = NullPointerException.class)\n     public void testErrorLogsWhenConfigIsMissing() throws Exception {\n         String connectionString = server.getConnectString();\n         Map conf = new HashMap();",
                "raw_url": "https://github.com/apache/storm/raw/95a10557ca9eed5f193841e0a72b5032b627aceb/external/storm-kafka/src/test/storm/kafka/DynamicBrokersReaderTest.java",
                "sha": "941ac9e89fc2f1fd5107d2777cc801e60aa334b7",
                "status": "modified"
            }
        ],
        "message": "Rather then just log errors when required parameters are missing, throw a NullPointerException as soon as a required value is missing.",
        "parent": "https://github.com/apache/storm/commit/326cc1c796d073c768de4b5aced1669bd47c6891",
        "patched_files": [
            "DynamicBrokersReader.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "DynamicBrokersReaderTest.java"
        ]
    },
    "storm_9833f54": {
        "bug_id": "storm_9833f54",
        "commit": "https://github.com/apache/storm/commit/9833f5449e598b7f257a229e64ed2f479c4d07ac",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/9833f5449e598b7f257a229e64ed2f479c4d07ac/storm-core/test/clj/org/apache/storm/nimbus_test.clj",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/test/clj/org/apache/storm/nimbus_test.clj?ref=9833f5449e598b7f257a229e64ed2f479c4d07ac",
                "deletions": 0,
                "filename": "storm-core/test/clj/org/apache/storm/nimbus_test.clj",
                "patch": "@@ -537,6 +537,10 @@\n                                 (TestPlannerSpout. true) (Integer. 4))}\n                          {}))\n         (bind state (.getClusterState cluster))\n+        ; get topology history when there's no topology history\n+        (let [hist-topo-ids (vec (sort (.get_topo_ids (.getTopologyHistory (.getNimbus cluster) (System/getProperty \"user.name\")))))]\n+             (log-message \"Checking user \" (System/getProperty \"user.name\") \" \" hist-topo-ids)\n+             (is (= 0 (count hist-topo-ids))))\n         (.submitTopology cluster \"test\" {TOPOLOGY-MESSAGE-TIMEOUT-SECS 20, LOGS-USERS [\"alice\", (System/getProperty \"user.name\")]} topology)\n         (bind storm-id (StormCommon/getStormId state \"test\"))\n         (.advanceClusterTime cluster 5)",
                "raw_url": "https://github.com/apache/storm/raw/9833f5449e598b7f257a229e64ed2f479c4d07ac/storm-core/test/clj/org/apache/storm/nimbus_test.clj",
                "sha": "c4f3fadc0228ceab8011fa26f1278290229f590f",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/storm/blob/9833f5449e598b7f257a229e64ed2f479c4d07ac/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java?ref=9833f5449e598b7f257a229e64ed2f479c4d07ac",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "patch": "@@ -2116,9 +2116,13 @@ private boolean isUserPartOf(String user, Collection<String> groupsToCheck) thro\n \n     private List<String> readTopologyHistory(String user, Collection<String> adminUsers) throws IOException {\n         LocalState state = topologyHistoryState;\n+        List<LSTopoHistory> topoHistoryList = state.getTopoHistoryList();\n+        if (topoHistoryList == null || topoHistoryList.isEmpty()) {\n+            return Collections.emptyList();\n+        }\n+\n         List<String> ret = new ArrayList<>();\n-        for (LSTopoHistory history: state.getTopoHistoryList()) {\n-            \n+        for (LSTopoHistory history: topoHistoryList) {\n             if (user == null || //Security off\n                     adminUsers.contains(user) || //is admin\n                     isUserPartOf(user, history.get_groups()) || //is in allowed group",
                "raw_url": "https://github.com/apache/storm/raw/9833f5449e598b7f257a229e64ed2f479c4d07ac/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "sha": "5fcf1ec3c9b3889be8f195ead6b5b9f305e7a7ad",
                "status": "modified"
            }
        ],
        "message": "STORM-2635 Deep log search doesn\u2019t work when there\u2019s no topology in topology history\n\n* just fix the NPE issue",
        "parent": "https://github.com/apache/storm/commit/e1dd247ce97ad560c72554ed612e1ec8e69e9777",
        "patched_files": [
            "nimbus_test.clj",
            "Nimbus.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "NimbusTest.java"
        ]
    },
    "storm_9d6761e": {
        "bug_id": "storm_9d6761e",
        "commit": "https://github.com/apache/storm/commit/9d6761efb72f372d44e36088b0ddc51a38a00dfa",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/drpc/DRPCSpout.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/src/jvm/backtype/storm/drpc/DRPCSpout.java?ref=9d6761efb72f372d44e36088b0ddc51a38a00dfa",
                "deletions": 1,
                "filename": "src/jvm/backtype/storm/drpc/DRPCSpout.java",
                "patch": "@@ -149,6 +149,6 @@ public void declareOutputFields(OutputFieldsDeclarer declarer) {\n \n     @Override\n     public Map<String, Object> getComponentConfiguration() {\n-        return new HashMap<String, Object>();\n+        return null;\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/drpc/DRPCSpout.java",
                "sha": "d8aa512c17e771001bf15df16ed51efea1585e06",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/storm/blob/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/task/TopologyContext.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/src/jvm/backtype/storm/task/TopologyContext.java?ref=9d6761efb72f372d44e36088b0ddc51a38a00dfa",
                "deletions": 4,
                "filename": "src/jvm/backtype/storm/task/TopologyContext.java",
                "patch": "@@ -332,10 +332,13 @@ public int maxTopologyMessageTimeout(Map<String, Object> topologyConfig) {\n         Integer max = Utils.getInt(topologyConfig.get(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS));\n         for(String spout: getRawTopology().get_spouts().keySet()) {\n             ComponentCommon common = getComponentCommon(spout);\n-            Map conf = (Map) JSONValue.parse(common.get_json_conf());\n-            Object comp = conf.get(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS);\n-            if(comp!=null) {\n-                max = Math.max(Utils.getInt(comp), max);\n+            String jsonConf = common.get_json_conf();\n+            if(jsonConf!=null) {\n+                Map conf = (Map) JSONValue.parse(jsonConf);\n+                Object comp = conf.get(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS);\n+                if(comp!=null) {\n+                    max = Math.max(Utils.getInt(comp), max);\n+                }\n             }\n         }\n         return max;",
                "raw_url": "https://github.com/apache/storm/raw/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/task/TopologyContext.java",
                "sha": "667d36eeba6be5dfd86d3714e42fdb7e26c28433",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/testing/TestWordSpout.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/src/jvm/backtype/storm/testing/TestWordSpout.java?ref=9d6761efb72f372d44e36088b0ddc51a38a00dfa",
                "deletions": 2,
                "filename": "src/jvm/backtype/storm/testing/TestWordSpout.java",
                "patch": "@@ -57,10 +57,12 @@ public void declareOutputFields(OutputFieldsDeclarer declarer) {\n \n     @Override\n     public Map<String, Object> getComponentConfiguration() {\n-        Map<String, Object> ret = new HashMap<String, Object>();\n         if(!_isDistributed) {\n+            Map<String, Object> ret = new HashMap<String, Object>();\n             ret.put(Config.TOPOLOGY_MAX_TASK_PARALLELISM, 1);\n+            return ret;\n+        } else {\n+            return null;\n         }\n-        return ret;\n     }    \n }\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/9d6761efb72f372d44e36088b0ddc51a38a00dfa/src/jvm/backtype/storm/testing/TestWordSpout.java",
                "sha": "68560a1cc8e5f1f45367bc71ad0933ee5234cbd4",
                "status": "modified"
            }
        ],
        "message": "fix npe when component configuration for spout is null",
        "parent": "https://github.com/apache/storm/commit/b10ebde2a514491df60b746234061fbc04e742b2",
        "patched_files": [
            "TopologyContext.java",
            "DRPCSpout.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestWordSpout.java"
        ]
    },
    "storm_b25d580": {
        "bug_id": "storm_b25d580",
        "commit": "https://github.com/apache/storm/commit/b25d580780d31598f568bbe8dde800fe4b0d6f61",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/b25d580780d31598f568bbe8dde800fe4b0d6f61/storm-core/src/clj/org/apache/storm/ui/core.clj",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-core/src/clj/org/apache/storm/ui/core.clj?ref=b25d580780d31598f568bbe8dde800fe4b0d6f61",
                "deletions": 5,
                "filename": "storm-core/src/clj/org/apache/storm/ui/core.clj",
                "patch": "@@ -46,7 +46,7 @@\n   (:import [org.apache.storm.generated AuthorizationException ProfileRequest ProfileAction NodeInfo])\n   (:import [org.apache.storm.security.auth AuthUtils])\n   (:import [org.apache.storm.utils VersionInfo ConfigUtils Utils WebAppUtils])\n-  (:import [org.apache.storm Config])\n+  (:import [org.apache.storm Config Constants])\n   (:import [java.io File])\n   (:import [java.net URLEncoder URLDecoder])\n   (:import [org.json.simple JSONValue])\n@@ -425,8 +425,8 @@\n            resourceSummary (if (> (.size sups) 0)\n                              (reduce #(map + %1 %2)\n                                (for [^SupervisorSummary s sups\n-                                     :let [sup-total-mem (get (.get_total_resources s) Config/SUPERVISOR_MEMORY_CAPACITY_MB)\n-                                           sup-total-cpu (get (.get_total_resources s) Config/SUPERVISOR_CPU_CAPACITY)\n+                                     :let [sup-total-mem (get (.get_total_resources s) Constants/COMMON_TOTAL_MEMORY_RESOURCE_NAME)\n+                                           sup-total-cpu (get (.get_total_resources s) Constants/COMMON_CPU_RESOURCE_NAME)\n                                            sup-avail-mem (max (- sup-total-mem (.get_used_mem s)) 0.0)\n                                            sup-avail-cpu (max (- sup-total-cpu (.get_used_cpu s)) 0.0)\n                                            sup-fragmented-cpu (.get_fragmented_cpu s)\n@@ -518,8 +518,8 @@\n   (let [slotsTotal (.get_num_workers summary)\n         slotsUsed (.get_num_used_workers summary)\n         slotsFree (max (- slotsTotal slotsUsed) 0)\n-        totalMem (get (.get_total_resources summary) Config/SUPERVISOR_MEMORY_CAPACITY_MB)\n-        totalCpu (get (.get_total_resources summary) Config/SUPERVISOR_CPU_CAPACITY)\n+        totalMem (get (.get_total_resources summary) Constants/COMMON_TOTAL_MEMORY_RESOURCE_NAME)\n+        totalCpu (get (.get_total_resources summary) Constants/COMMON_CPU_RESOURCE_NAME)\n         usedMem (.get_used_mem summary)\n         usedCpu (.get_used_cpu summary)\n         availMem (max (- totalMem usedMem) 0)",
                "raw_url": "https://github.com/apache/storm/raw/b25d580780d31598f568bbe8dde800fe4b0d6f61/storm-core/src/clj/org/apache/storm/ui/core.clj",
                "sha": "d12ff749832753013b22d7edab56cf5815d00d99",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/b25d580780d31598f568bbe8dde800fe4b0d6f61/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java?ref=b25d580780d31598f568bbe8dde800fe4b0d6f61",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "patch": "@@ -958,8 +958,8 @@ private static void setLoggerTimeouts(LogLevel level) {\n             List<DataPoint> metrics = new ArrayList<>();\n             metrics.add(new DataPoint(\"slotsTotal\", sup.get_num_workers()));\n             metrics.add(new DataPoint(\"slotsUsed\", sup.get_num_used_workers()));\n-            metrics.add(new DataPoint(\"totalMem\", sup.get_total_resources().get(Config.SUPERVISOR_MEMORY_CAPACITY_MB)));\n-            metrics.add(new DataPoint(\"totalCpu\", sup.get_total_resources().get(Config.SUPERVISOR_CPU_CAPACITY)));\n+            metrics.add(new DataPoint(\"totalMem\", sup.get_total_resources().get(Constants.COMMON_TOTAL_MEMORY_RESOURCE_NAME)));\n+            metrics.add(new DataPoint(\"totalCpu\", sup.get_total_resources().get(Constants.COMMON_CPU_RESOURCE_NAME)));\n             metrics.add(new DataPoint(\"usedMem\", sup.get_used_mem()));\n             metrics.add(new DataPoint(\"usedCpu\", sup.get_used_cpu()));\n             ret.put(info, metrics);",
                "raw_url": "https://github.com/apache/storm/raw/b25d580780d31598f568bbe8dde800fe4b0d6f61/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java",
                "sha": "f878cf052dd45b5de4a6b89dc830d840a19bfd86",
                "status": "modified"
            }
        ],
        "message": "STORM-2808: Fix for NPE in UI",
        "parent": "https://github.com/apache/storm/commit/ee1be2b73fffff05e32cfd15857561c24655d90c",
        "patched_files": [
            "core.clj",
            "Nimbus.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "NimbusTest.java"
        ]
    },
    "storm_c985695": {
        "bug_id": "storm_c985695",
        "commit": "https://github.com/apache/storm/commit/c985695e0728eb3af171ca6d346c51cc4e0b083a",
        "file": [
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/daemon/worker/Worker.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/Worker.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 6,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/Worker.java",
                "patch": "@@ -14,6 +14,7 @@\n \n import java.io.File;\n import java.io.IOException;\n+import java.net.UnknownHostException;\n import java.nio.charset.Charset;\n import java.security.PrivilegedExceptionAction;\n import java.util.ArrayList;\n@@ -22,6 +23,7 @@\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n import java.util.stream.Collectors;\n@@ -45,6 +47,7 @@\n import org.apache.storm.generated.ExecutorStats;\n import org.apache.storm.generated.LSWorkerHeartbeat;\n import org.apache.storm.generated.LogConfig;\n+import org.apache.storm.generated.Supervisor;\n import org.apache.storm.generated.SupervisorWorkerHeartbeat;\n import org.apache.storm.messaging.IConnection;\n import org.apache.storm.messaging.IContext;\n@@ -61,6 +64,7 @@\n import org.apache.storm.utils.NimbusClient;\n import org.apache.storm.utils.ObjectReader;\n import org.apache.storm.utils.SupervisorClient;\n+import org.apache.storm.utils.SupervisorIfaceFactory;\n import org.apache.storm.utils.Time;\n import org.apache.storm.utils.Utils;\n import org.slf4j.Logger;\n@@ -87,6 +91,7 @@\n     private AtomicReference<Credentials> credentialsAtom;\n     private Subject subject;\n     private Collection<IAutoCredentials> autoCreds;\n+    private final Supplier<SupervisorIfaceFactory> supervisorIfaceSupplier;\n \n \n     /**\n@@ -103,7 +108,7 @@\n      */\n \n     public Worker(Map<String, Object> conf, IContext context, String topologyId, String assignmentId,\n-                  int supervisorPort, int port, String workerId) {\n+                  int supervisorPort, int port, String workerId, Supplier<SupervisorIfaceFactory> supervisorIfaceSupplier) {\n         this.conf = conf;\n         this.context = context;\n         this.topologyId = topologyId;\n@@ -113,6 +118,7 @@ public Worker(Map<String, Object> conf, IContext context, String topologyId, Str\n         this.workerId = workerId;\n         this.logConfigManager = new LogConfigManager();\n         this.metricRegistry = new StormMetricRegistry();\n+        this.supervisorIfaceSupplier = supervisorIfaceSupplier;\n     }\n \n     public static void main(String[] args) throws Exception {\n@@ -125,8 +131,16 @@ public static void main(String[] args) throws Exception {\n         Map<String, Object> conf = ConfigUtils.readStormConfig();\n         Utils.setupDefaultUncaughtExceptionHandler();\n         StormCommon.validateDistributedMode(conf);\n-        Worker worker = new Worker(conf, null, stormId, assignmentId, Integer.parseInt(supervisorPort),\n-                                   Integer.parseInt(portStr), workerId);\n+        int supervisorPortInt = Integer.parseInt(supervisorPort);\n+        Supplier<SupervisorIfaceFactory> supervisorIfaceSuppler = () -> {\n+            try {\n+                return SupervisorClient.getConfiguredClient(conf, Utils.hostname(), supervisorPortInt);\n+            } catch (UnknownHostException e) {\n+                throw Utils.wrapInRuntime(e);\n+            }\n+        };\n+        Worker worker = new Worker(conf, null, stormId, assignmentId, supervisorPortInt,\n+                                   Integer.parseInt(portStr), workerId, supervisorIfaceSuppler);\n         worker.start();\n         int workerShutdownSleepSecs = ObjectReader.getInt(conf.get(Config.SUPERVISOR_WORKER_SHUTDOWN_SLEEP_SECS));\n         LOG.info(\"Adding shutdown hook with kill in {} secs\", workerShutdownSleepSecs);\n@@ -172,7 +186,7 @@ public void start() throws Exception {\n     private Object loadWorker(Map<String, Object> topologyConf, IStateStorage stateStorage, IStormClusterState stormClusterState,\n                               Map<String, String> initCreds, Credentials initialCredentials)\n         throws Exception {\n-        workerState = new WorkerState(conf, context, topologyId, assignmentId, supervisorPort, port, workerId,\n+        workerState = new WorkerState(conf, context, topologyId, assignmentId, supervisorIfaceSupplier, port, workerId,\n                                       topologyConf, stateStorage, stormClusterState, autoCreds, metricRegistry);\n \n         // Heartbeat here so that worker process dies if this fails\n@@ -425,8 +439,8 @@ private void heartbeatToMasterIfLocalbeatFail(LSWorkerHeartbeat lsWorkerHeartbea\n         SupervisorWorkerHeartbeat workerHeartbeat = new SupervisorWorkerHeartbeat(lsWorkerHeartbeat.get_topology_id(),\n                                                                                   lsWorkerHeartbeat.get_executors(),\n                                                                                   lsWorkerHeartbeat.get_time_secs());\n-        try (SupervisorClient client = SupervisorClient.getConfiguredClient(conf, Utils.hostname(), supervisorPort)) {\n-            client.getClient().sendSupervisorWorkerHeartbeat(workerHeartbeat);\n+        try (SupervisorIfaceFactory fac = supervisorIfaceSupplier.get()) {\n+            fac.getIface().sendSupervisorWorkerHeartbeat(workerHeartbeat);\n         } catch (Exception tr1) {\n             //If any error/exception thrown, report directly to nimbus.\n             LOG.warn(\"Exception when send heartbeat to local supervisor\", tr1.getMessage());",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/daemon/worker/Worker.java",
                "sha": "175a91adee5a8f305f64e7a8dfaa26aa8c1d0ade",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 18,
                "filename": "storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "patch": "@@ -69,13 +69,15 @@\n import org.apache.storm.serialization.KryoTupleSerializer;\n import org.apache.storm.shade.com.google.common.collect.ImmutableMap;\n import org.apache.storm.shade.com.google.common.collect.Sets;\n+import org.apache.storm.shade.org.apache.commons.lang.Validate;\n import org.apache.storm.task.WorkerTopologyContext;\n import org.apache.storm.tuple.AddressedTuple;\n import org.apache.storm.tuple.Fields;\n import org.apache.storm.utils.ConfigUtils;\n import org.apache.storm.utils.JCQueue;\n import org.apache.storm.utils.ObjectReader;\n import org.apache.storm.utils.SupervisorClient;\n+import org.apache.storm.utils.SupervisorIfaceFactory;\n import org.apache.storm.utils.ThriftTopologyUtils;\n import org.apache.storm.utils.Utils;\n import org.apache.storm.utils.Utils.SmartThread;\n@@ -92,7 +94,7 @@\n     final IConnection receiver;\n     final String topologyId;\n     final String assignmentId;\n-    final int supervisorPort;\n+    private final Supplier<SupervisorIfaceFactory> supervisorIfaceSupplier;\n     final int port;\n     final String workerId;\n     final IStateStorage stateStorage;\n@@ -151,18 +153,18 @@\n     private final StormMetricRegistry metricRegistry;\n \n     public WorkerState(Map<String, Object> conf, IContext mqContext, String topologyId, String assignmentId,\n-                       int supervisorPort, int port, String workerId, Map<String, Object> topologyConf, IStateStorage stateStorage,\n+                       Supplier<SupervisorIfaceFactory> supervisorIfaceSupplier, int port, String workerId, Map<String, Object> topologyConf, IStateStorage stateStorage,\n                        IStormClusterState stormClusterState, Collection<IAutoCredentials> autoCredentials,\n                        StormMetricRegistry metricRegistry) throws IOException,\n         InvalidTopologyException {\n         this.metricRegistry = metricRegistry;\n         this.autoCredentials = autoCredentials;\n         this.conf = conf;\n+        this.supervisorIfaceSupplier = supervisorIfaceSupplier;\n         this.localExecutors = new HashSet<>(readWorkerExecutors(stormClusterState, topologyId, assignmentId, port));\n         this.mqContext = (null != mqContext) ? mqContext : TransportFactory.makeContext(topologyConf);\n         this.topologyId = topologyId;\n         this.assignmentId = assignmentId;\n-        this.supervisorPort = supervisorPort;\n         this.port = port;\n         this.workerId = workerId;\n         this.stateStorage = stateStorage;\n@@ -370,9 +372,14 @@ public StormTimer getUserTimer() {\n     public SmartThread makeTransferThread() {\n         return workerTransfer.makeTransferThread();\n     }\n-\n+    \n     public void refreshConnections() {\n-        Assignment assignment = getLocalAssignment(conf, stormClusterState, topologyId);\n+        Assignment assignment = null;\n+        try {\n+            assignment = getLocalAssignment(stormClusterState, topologyId);\n+        } catch (Exception e) {\n+            LOG.warn(\"Failed to read assignment. This should only happen when topology is shutting down.\", e);\n+        }\n \n         Set<NodeInfo> neededConnections = new HashSet<>();\n         Map<Integer, NodeInfo> newTaskToNodePort = new HashMap<>();\n@@ -393,14 +400,16 @@ public void refreshConnections() {\n         Set<NodeInfo> newConnections = Sets.difference(neededConnections, currentConnections);\n         Set<NodeInfo> removeConnections = Sets.difference(currentConnections, neededConnections);\n \n+        Map<String, String> nodeHost = assignment != null ? assignment.get_node_host() : null;\n         // Add new connections atomically\n         cachedNodeToPortSocket.getAndUpdate(prev -> {\n             Map<NodeInfo, IConnection> next = new HashMap<>(prev);\n             for (NodeInfo nodeInfo : newConnections) {\n                 next.put(nodeInfo,\n                          mqContext.connect(\n                              topologyId,\n-                             assignment.get_node_host().get(nodeInfo.get_node()),    // Host\n+                             //nodeHost is not null here, as newConnections is only non-empty if assignment was not null above.\n+                             nodeHost.get(nodeInfo.get_node()),    // Host\n                              nodeInfo.get_port().iterator().next().intValue(),       // Port\n                              workerTransfer.getRemoteBackPressureStatus()));\n             }\n@@ -625,7 +634,8 @@ public boolean areAllConnectionsReady() {\n         LOG.info(\"Reading assignments\");\n         List<List<Long>> executorsAssignedToThisWorker = new ArrayList<>();\n         executorsAssignedToThisWorker.add(Constants.SYSTEM_EXECUTOR_ID);\n-        Map<List<Long>, NodeInfo> executorToNodePort = getLocalAssignment(conf, stormClusterState, topologyId).get_executor_node_port();\n+        Map<List<Long>, NodeInfo> executorToNodePort = \n+            getLocalAssignment(stormClusterState, topologyId).get_executor_node_port();\n         for (Map.Entry<List<Long>, NodeInfo> entry : executorToNodePort.entrySet()) {\n             NodeInfo nodeInfo = entry.getValue();\n             if (nodeInfo.get_node().equals(assignmentId) && nodeInfo.get_port().iterator().next() == port) {\n@@ -635,18 +645,17 @@ public boolean areAllConnectionsReady() {\n         return executorsAssignedToThisWorker;\n     }\n \n-    private Assignment getLocalAssignment(Map<String, Object> conf, IStormClusterState stormClusterState, String topologyId) {\n-        if (!ConfigUtils.isLocalMode(conf)) {\n-            try (SupervisorClient supervisorClient = SupervisorClient.getConfiguredClient(conf, Utils.hostname(),\n-                                                                                          supervisorPort)) {\n-                Assignment assignment = supervisorClient.getClient().getLocalAssignmentForStorm(topologyId);\n-                return assignment;\n-            } catch (Throwable tr1) {\n+    private Assignment getLocalAssignment(IStormClusterState stormClusterState, String topologyId) {\n+        try (SupervisorIfaceFactory fac = supervisorIfaceSupplier.get()) {\n+            return fac.getIface().getLocalAssignmentForStorm(topologyId);\n+        } catch (Throwable e) {\n                 //if any error/exception thrown, fetch it from zookeeper\n-                return stormClusterState.remoteAssignmentInfo(topologyId, null);\n+            Assignment assignment = stormClusterState.remoteAssignmentInfo(topologyId, null);\n+            if (assignment == null) {\n+                throw new RuntimeException(\"Failed to read worker assignment.\"\n+                    + \" Supervisor client threw exception, and assignment in Zookeeper was null\", e);\n             }\n-        } else {\n-            return stormClusterState.remoteAssignmentInfo(topologyId, null);\n+            return assignment;\n         }\n     }\n \n@@ -666,7 +675,7 @@ private Assignment getLocalAssignment(Map<String, Object> conf, IStormClusterSta\n         for (List<Long> executor : executors) {\n             int port = this.getPort();\n             receiveQueueMap.put(executor, new JCQueue(\"receive-queue\" + executor.toString(),\n-                recvQueueSize, overflowLimit, recvBatchSize, backPressureWaitStrategy,\n+                                                      recvQueueSize, overflowLimit, recvBatchSize, backPressureWaitStrategy,\n                 this.getTopologyId(), Constants.SYSTEM_COMPONENT_ID, -1, this.getPort(), metricRegistry));\n \n         }",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/daemon/worker/WorkerState.java",
                "sha": "913261d24088438698ceb97d5b86afaeb90de622",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/security/auth/workertoken/WorkerTokenAuthorizer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/security/auth/workertoken/WorkerTokenAuthorizer.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 1,
                "filename": "storm-client/src/jvm/org/apache/storm/security/auth/workertoken/WorkerTokenAuthorizer.java",
                "patch": "@@ -152,4 +152,4 @@ public void close() {\n             state.disconnect();\n         }\n     }\n-}\n\\ No newline at end of file\n+}",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/security/auth/workertoken/WorkerTokenAuthorizer.java",
                "sha": "c225e2742f6564db0abb966f125860c5a3521491",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/utils/SupervisorClient.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/utils/SupervisorClient.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 2,
                "filename": "storm-client/src/jvm/org/apache/storm/utils/SupervisorClient.java",
                "patch": "@@ -28,7 +28,7 @@\n  * <li>nimbus -> supervisor: assign assignments for a node.</li>\n  * </ul>\n  */\n-public class SupervisorClient extends ThriftClient {\n+public class SupervisorClient extends ThriftClient implements SupervisorIfaceFactory {\n     private static final Logger LOG = LoggerFactory.getLogger(SupervisorClient.class);\n     private Supervisor.Client client;\n \n@@ -76,7 +76,8 @@ public static SupervisorClient getConfiguredClientAs(Map conf, String host, int\n         }\n     }\n \n-    public Supervisor.Client getClient() {\n+    @Override\n+    public Supervisor.Client getIface() {\n         return client;\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/utils/SupervisorClient.java",
                "sha": "64d5aceffa0873f93f2afb03730a1e738bd71701",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/utils/SupervisorIfaceFactory.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/utils/SupervisorIfaceFactory.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 0,
                "filename": "storm-client/src/jvm/org/apache/storm/utils/SupervisorIfaceFactory.java",
                "patch": "@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.utils;\n+\n+import java.io.Closeable;\n+\n+public interface SupervisorIfaceFactory extends Closeable {\n+\n+    org.apache.storm.generated.Supervisor.Iface getIface();\n+\n+    @Override\n+    default void close() {\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-client/src/jvm/org/apache/storm/utils/SupervisorIfaceFactory.java",
                "sha": "eddfa7332e56f8a82e1892ce4219d5215fd57865",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Container.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Container.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/Container.java",
                "patch": "@@ -309,7 +309,7 @@ private boolean isPosixProcessAlive(long pid, String user) throws IOException {\n         }\n         return ret;\n     }\n-\n+    \n     @Override\n     public boolean areAllProcessesDead() throws IOException {\n         Set<Long> pids = getAllPids();\n@@ -325,7 +325,7 @@ public boolean areAllProcessesDead() throws IOException {\n                 break;\n             }\n         }\n-\n+        \n         if (allDead && shutdownTimer != null) {\n             shutdownTimer.stop();\n             shutdownTimer = null;",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Container.java",
                "sha": "8b58483477967b80769321358a55419004740df2",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ContainerLauncher.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ContainerLauncher.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/ContainerLauncher.java",
                "patch": "@@ -46,14 +46,17 @@ protected ContainerLauncher() {\n      * @param sharedContext Used in local mode to let workers talk together without netty\n      * @param metricsRegistry The metrics registry.\n      * @param containerMemoryTracker The shared memory tracker for the supervisor's containers\n+     * @param localSupervisor The local supervisor Thrift interface. Only used for local clusters, distributed clusters use Thrift directly.\n      * @return the proper container launcher\n      * @throws IOException on any error\n      */\n     public static ContainerLauncher make(Map<String, Object> conf, String supervisorId, int supervisorPort,\n                                          IContext sharedContext, StormMetricsRegistry metricsRegistry, \n-                                         ContainerMemoryTracker containerMemoryTracker) throws IOException {\n+                                         ContainerMemoryTracker containerMemoryTracker,\n+                                         org.apache.storm.generated.Supervisor.Iface localSupervisor) throws IOException {\n         if (ConfigUtils.isLocalMode(conf)) {\n-            return new LocalContainerLauncher(conf, supervisorId, supervisorPort, sharedContext, metricsRegistry, containerMemoryTracker);\n+            return new LocalContainerLauncher(conf, supervisorId, supervisorPort, sharedContext, metricsRegistry, containerMemoryTracker,\n+                localSupervisor);\n         }\n \n         ResourceIsolationInterface resourceIsolationManager = null;",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ContainerLauncher.java",
                "sha": "b3100180a46ca6db1730db35d7a90f01b76bbb15",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainer.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainer.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainer.java",
                "patch": "@@ -27,15 +27,18 @@\n public class LocalContainer extends Container {\n     private static final Logger LOG = LoggerFactory.getLogger(LocalContainer.class);\n     private final IContext _sharedContext;\n+    private final org.apache.storm.generated.Supervisor.Iface localSupervisor;\n     private volatile boolean _isAlive = false;\n \n     public LocalContainer(Map<String, Object> conf, String supervisorId, int supervisorPort, int port,\n                           LocalAssignment assignment, IContext sharedContext, StormMetricsRegistry metricsRegistry,\n-                          ContainerMemoryTracker containerMemoryTracker) throws IOException {\n+                          ContainerMemoryTracker containerMemoryTracker,\n+                          org.apache.storm.generated.Supervisor.Iface localSupervisor) throws IOException {\n         super(ContainerType.LAUNCH, conf, supervisorId, supervisorPort, port, assignment, null, null, null, null, metricsRegistry, \n             containerMemoryTracker);\n         _sharedContext = sharedContext;\n         _workerId = Utils.uuid();\n+        this.localSupervisor = localSupervisor;\n     }\n \n     @Override\n@@ -50,7 +53,10 @@ protected void createBlobstoreLinks() {\n \n     @Override\n     public void launch() throws IOException {\n-        Worker worker = new Worker(_conf, _sharedContext, _topologyId, _supervisorId, _supervisorPort, _port, _workerId);\n+        Worker worker = new Worker(_conf, _sharedContext, _topologyId, _supervisorId, _supervisorPort, _port, _workerId,\n+            () -> {\n+                return () -> localSupervisor;\n+            });\n         try {\n             worker.start();\n         } catch (Exception e) {",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainer.java",
                "sha": "228da8434d863fcc70342c8aa0fd3f83dc29c3f8",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainerLauncher.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainerLauncher.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainerLauncher.java",
                "patch": "@@ -29,22 +29,25 @@\n     private final IContext _sharedContext;\n     private final StormMetricsRegistry metricsRegistry;\n     private final ContainerMemoryTracker containerMemoryTracker;\n+    private final org.apache.storm.generated.Supervisor.Iface localSupervisor;\n \n     public LocalContainerLauncher(Map<String, Object> conf, String supervisorId, int supervisorPort,\n                                   IContext sharedContext, StormMetricsRegistry metricsRegistry, \n-                                  ContainerMemoryTracker containerMemoryTracker) {\n+                                  ContainerMemoryTracker containerMemoryTracker,\n+                                  org.apache.storm.generated.Supervisor.Iface localSupervisor) {\n         _conf = conf;\n         _supervisorId = supervisorId;\n         _supervisorPort = supervisorPort;\n         _sharedContext = sharedContext;\n         this.metricsRegistry = metricsRegistry;\n         this.containerMemoryTracker = containerMemoryTracker;\n+        this.localSupervisor = localSupervisor;\n     }\n \n     @Override\n     public Container launchContainer(int port, LocalAssignment assignment, LocalState state) throws IOException {\n         LocalContainer ret = new LocalContainer(_conf, _supervisorId, _supervisorPort,\n-            port, assignment, _sharedContext, metricsRegistry, containerMemoryTracker);\n+            port, assignment, _sharedContext, metricsRegistry, containerMemoryTracker, localSupervisor);\n         ret.setup();\n         ret.launch();\n         return ret;",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/LocalContainerLauncher.java",
                "sha": "d9f3f8d8957b93baff08f3814bad2da5d82fd183",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ReadClusterState.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ReadClusterState.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 1,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/ReadClusterState.java",
                "patch": "@@ -86,7 +86,8 @@ public ReadClusterState(Supervisor supervisor) throws Exception {\n         this.slotMetrics = supervisor.getSlotMetrics();\n \n         this.launcher = ContainerLauncher.make(superConf, assignmentId, supervisorPort,\n-            supervisor.getSharedContext(), supervisor.getMetricsRegistry(), supervisor.getContainerMemoryTracker());\n+            supervisor.getSharedContext(), supervisor.getMetricsRegistry(), supervisor.getContainerMemoryTracker(),\n+            supervisor.getSupervisorThriftInterface());\n \n         this.metricsProcessor = null;\n         try {",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/ReadClusterState.java",
                "sha": "6b18bbea7a1943a216d6cca3c63a1c040a5ec77d",
                "status": "modified"
            },
            {
                "additions": 60,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Supervisor.java",
                "changes": 108,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Supervisor.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 48,
                "filename": "storm-server/src/main/java/org/apache/storm/daemon/supervisor/Supervisor.java",
                "patch": "@@ -112,6 +112,8 @@\n     private ThriftServer thriftServer;\n     //used for local cluster heartbeating\n     private Nimbus.Iface localNimbus;\n+    //Passed to workers in local clusters, exposed by thrift server in distributed mode\n+    private org.apache.storm.generated.Supervisor.Iface supervisorThriftInterface;\n \n     private Supervisor(ISupervisor iSupervisor, StormMetricsRegistry metricsRegistry)\n         throws IOException, IllegalAccessException, InstantiationException, ClassNotFoundException {\n@@ -178,6 +180,8 @@ public Supervisor(Map<String, Object> conf, IContext sharedContext, ISupervisor\n         this.workerHeartbeatTimer = new StormTimer(null, new DefaultUncaughtExceptionHandler());\n \n         this.eventTimer = new StormTimer(null, new DefaultUncaughtExceptionHandler());\n+        \n+        this.supervisorThriftInterface = createSupervisorIface();\n     }\n \n     /**\n@@ -393,6 +397,59 @@ public void checkAuthorization(String topoName, Map<String, Object> topoConf, St\n         }\n     }\n \n+    private org.apache.storm.generated.Supervisor.Iface createSupervisorIface() {\n+        return new org.apache.storm.generated.Supervisor.Iface() {\n+            @Override\n+            public void sendSupervisorAssignments(SupervisorAssignments assignments)\n+                throws AuthorizationException, TException {\n+                checkAuthorization(\"sendSupervisorAssignments\");\n+                LOG.info(\"Got an assignments from master, will start to sync with assignments: {}\", assignments);\n+                SynchronizeAssignments syn = new SynchronizeAssignments(getSupervisor(), assignments,\n+                    getReadClusterState());\n+                getEventManger().add(syn);\n+            }\n+\n+            @Override\n+            public Assignment getLocalAssignmentForStorm(String id)\n+                throws NotAliveException, AuthorizationException, TException {\n+                Map<String, Object> topoConf = null;\n+                try {\n+                    topoConf = ConfigUtils.readSupervisorStormConf(conf, id);\n+                } catch (IOException e) {\n+                    LOG.warn(\"Topology config is not localized yet...\");\n+                }\n+                checkAuthorization(id, topoConf, \"getLocalAssignmentForStorm\");\n+                Assignment assignment = getStormClusterState().assignmentInfo(id, null);\n+                if (null == assignment) {\n+                    throw new WrappedNotAliveException(\"No local assignment assigned for storm: \"\n+                        + id\n+                        + \" for node: \"\n+                        + getHostName());\n+                }\n+                return assignment;\n+            }\n+\n+            @Override\n+            public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heartbeat)\n+                throws AuthorizationException, NotAliveException, TException {\n+                // do nothing except validate heartbeat for now.\n+                String id = heartbeat.get_storm_id();\n+                Map<String, Object> topoConf = null;\n+                try {\n+                    topoConf = ConfigUtils.readSupervisorStormConf(conf, id);\n+                } catch (IOException e) {\n+                    LOG.warn(\"Topology config is not localized yet...\");\n+                    throw new WrappedNotAliveException(id + \" does not appear to be alive, you should probably exit\");\n+                }\n+                checkAuthorization(id, topoConf, \"sendSupervisorWorkerHeartbeat\");\n+            }\n+        };\n+    }\n+\n+    public org.apache.storm.generated.Supervisor.Iface getSupervisorThriftInterface() {\n+        return supervisorThriftInterface;\n+    }\n+    \n     private void launchSupervisorThriftServer(Map<String, Object> conf) throws IOException {\n         // validate port\n         int port = getThriftServerPort();\n@@ -404,53 +461,7 @@ private void launchSupervisorThriftServer(Map<String, Object> conf) throws IOExc\n             throw new RuntimeException(e);\n         }\n \n-        TProcessor processor = new org.apache.storm.generated.Supervisor.Processor(\n-            new org.apache.storm.generated.Supervisor.Iface() {\n-                @Override\n-                public void sendSupervisorAssignments(SupervisorAssignments assignments)\n-                    throws AuthorizationException, TException {\n-                    checkAuthorization(\"sendSupervisorAssignments\");\n-                    LOG.info(\"Got an assignments from master, will start to sync with assignments: {}\", assignments);\n-                    SynchronizeAssignments syn = new SynchronizeAssignments(getSupervisor(), assignments,\n-                                                                            getReadClusterState());\n-                    getEventManger().add(syn);\n-                }\n-\n-                @Override\n-                public Assignment getLocalAssignmentForStorm(String id)\n-                    throws NotAliveException, AuthorizationException, TException {\n-                    Map<String, Object> topoConf = null;\n-                    try {\n-                        topoConf = ConfigUtils.readSupervisorStormConf(conf, id);\n-                    } catch (IOException e) {\n-                        LOG.warn(\"Topology config is not localized yet...\");\n-                    }\n-                    checkAuthorization(id, topoConf, \"getLocalAssignmentForStorm\");\n-                    Assignment assignment = getStormClusterState().assignmentInfo(id, null);\n-                    if (null == assignment) {\n-                        throw new WrappedNotAliveException(\"No local assignment assigned for storm: \"\n-                                                    + id\n-                                                    + \" for node: \"\n-                                                    + getHostName());\n-                    }\n-                    return assignment;\n-                }\n-\n-                @Override\n-                public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heartbeat)\n-                    throws AuthorizationException, NotAliveException, TException {\n-                    // do nothing except validate heartbeat for now.\n-                    String id = heartbeat.get_storm_id();\n-                    Map<String, Object> topoConf = null;\n-                    try {\n-                        topoConf = ConfigUtils.readSupervisorStormConf(conf, id);\n-                    } catch (IOException e) {\n-                        LOG.warn(\"Topology config is not localized yet...\");\n-                        throw new WrappedNotAliveException(id + \" does not appear to be alive, you should probably exit\");\n-                    }\n-                    checkAuthorization(id, topoConf, \"sendSupervisorWorkerHeartbeat\");\n-                }\n-            });\n+        TProcessor processor = new org.apache.storm.generated.Supervisor.Processor<>(supervisorThriftInterface);\n         this.thriftServer = new ThriftServer(conf, processor, ThriftConnectionType.SUPERVISOR);\n         this.thriftServer.serve();\n     }\n@@ -536,7 +547,8 @@ public void shutdownAllWorkers(BiConsumer<Slot, Long> onWarnTimeout, UniFunc<Slo\n         } else {\n             try {\n                 ContainerLauncher launcher = ContainerLauncher.make(getConf(), getId(), getThriftServerPort(),\n-                                                                    getSharedContext(), getMetricsRegistry(), getContainerMemoryTracker());\n+                                                                    getSharedContext(), getMetricsRegistry(), getContainerMemoryTracker(),\n+                                                                    supervisorThriftInterface);\n                 killWorkers(SupervisorUtils.supervisorWorkerIds(conf), launcher);\n             } catch (Exception e) {\n                 throw Utils.wrapInRuntime(e);",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/daemon/supervisor/Supervisor.java",
                "sha": "9bc4f7f5bca05ce2c56d51f32ccc9808d0b4280b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/nimbus/AssignmentDistributionService.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/nimbus/AssignmentDistributionService.java?ref=c985695e0728eb3af171ca6d346c51cc4e0b083a",
                "deletions": 1,
                "filename": "storm-server/src/main/java/org/apache/storm/nimbus/AssignmentDistributionService.java",
                "patch": "@@ -288,7 +288,7 @@ private void sendAssignmentsToNode(NodeAssignments assignments) {\n                 try (SupervisorClient client = SupervisorClient.getConfiguredClient(service.getConf(),\n                                                                                     assignments.getHost(), assignments.getServerPort())) {\n                     try {\n-                        client.getClient().sendSupervisorAssignments(assignments.getAssignments());\n+                        client.getIface().sendSupervisorAssignments(assignments.getAssignments());\n                     } catch (Exception e) {\n                         //just ignore the exception.\n                         LOG.error(\"Exception when trying to send assignments to node {}: {}\", assignments.getNode(), e.getMessage());",
                "raw_url": "https://github.com/apache/storm/raw/c985695e0728eb3af171ca6d346c51cc4e0b083a/storm-server/src/main/java/org/apache/storm/nimbus/AssignmentDistributionService.java",
                "sha": "05cb1dfa42228616e9833d192c2f9eb3a194368d",
                "status": "modified"
            }
        ],
        "message": "STORM-3379: Fix intermittent NPE during worker boot in local mode",
        "parent": "https://github.com/apache/storm/commit/aaf1113360ce151d86948860c2f290befa79abb8",
        "patched_files": [
            "Container.java",
            "Worker.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "WorkerTest.java",
            "ContainerTest.java"
        ]
    },
    "storm_d1912ae": {
        "bug_id": "storm_d1912ae",
        "commit": "https://github.com/apache/storm/commit/d1912ae98afe9f470a05e57835c41f056cebb311",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs-blobstore/pom.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs-blobstore/pom.xml?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 0,
                "filename": "external/storm-hdfs-blobstore/pom.xml",
                "patch": "@@ -208,6 +208,11 @@\n             <artifactId>guava</artifactId>\n             <version>${guava.version}</version>\n         </dependency>\n+        <dependency>\n+            <groupId>org.junit.jupiter</groupId>\n+            <artifactId>junit-jupiter-params</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n     </dependencies>\n     <build>\n         <plugins>",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs-blobstore/pom.xml",
                "sha": "ccc69a63ed0bde5d19dd2ec10c590cc9a85a30f8",
                "status": "modified"
            },
            {
                "additions": 127,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "changes": 266,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 139,
                "filename": "external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "patch": "@@ -18,6 +18,7 @@\n  */\n package org.apache.storm.hdfs.blobstore;\n \n+import org.apache.storm.hdfs.testing.MiniDFSClusterExtension;\n import org.apache.commons.io.FileUtils;\n import org.apache.storm.Config;\n import org.apache.storm.blobstore.AtomicOutputStream;\n@@ -28,14 +29,9 @@\n import org.apache.storm.generated.AuthorizationException;\n import org.apache.storm.generated.KeyNotFoundException;\n import org.apache.storm.generated.SettableBlobMeta;\n-import org.apache.storm.hdfs.testing.MiniDFSClusterRule;\n import org.apache.storm.security.auth.FixedGroupsMapping;\n import org.apache.storm.security.auth.NimbusPrincipal;\n import org.apache.storm.security.auth.SingleUserPrincipal;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.ClassRule;\n-import org.junit.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -55,30 +51,34 @@\n \n import static org.junit.Assert.*;\n \n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.EnumSource;\n+import org.junit.jupiter.params.provider.ValueSource;\n+\n public class BlobStoreTest {\n \n-    @ClassRule\n-    public static final MiniDFSClusterRule DFS_CLUSTER_RULE = new MiniDFSClusterRule();\n+    @RegisterExtension\n+    public static final MiniDFSClusterExtension DFS_CLUSTER_EXTENSION = new MiniDFSClusterExtension();\n \n     private static final Logger LOG = LoggerFactory.getLogger(BlobStoreTest.class);\n     URI base;\n-    File baseFile;\n     private static final Map<String, Object> CONF = new HashMap<>();\n     public static final int READ = 0x01;\n     public static final int WRITE = 0x02;\n     public static final int ADMIN = 0x04;\n \n-    @Before\n+    @BeforeEach\n     public void init() {\n         initializeConfigs();\n-        baseFile = new File(\"/tmp/blob-store-test-\" + UUID.randomUUID());\n-        base = baseFile.toURI();\n     }\n \n-    @After\n+    @AfterEach\n     public void cleanup()\n         throws IOException {\n-        FileUtils.deleteDirectory(baseFile);\n     }\n \n     // Method which initializes nimbus admin\n@@ -160,7 +160,7 @@ private AutoCloseableBlobStoreContainer initHdfs(String dirName)\n         conf.put(Config.STORM_PRINCIPAL_TO_LOCAL_PLUGIN, \"org.apache.storm.security.auth.DefaultPrincipalToLocal\");\n         conf.put(Config.STORM_BLOBSTORE_REPLICATION_FACTOR, 3);\n         HdfsBlobStore store = new HdfsBlobStore();\n-        store.prepareInternal(conf, null, DFS_CLUSTER_RULE.getDfscluster().getConfiguration(0));\n+        store.prepareInternal(conf, null, DFS_CLUSTER_EXTENSION.getDfscluster().getConfiguration(0));\n         return new AutoCloseableBlobStoreContainer(store);\n     }\n \n@@ -204,15 +204,6 @@ public void testMultipleHdfs()\n         }\n     }\n \n-    @Test\n-    public void testHdfsWithAuth()\n-        throws Exception {\n-        // use different blobstore dir so it doesn't conflict with other tests\n-        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore3\")) {\n-            testWithAuthentication(container.blobStore);\n-        }\n-    }\n-\n     // Test for replication.\n     public void testReplication(String path, BlobStore store)\n         throws Exception {\n@@ -289,133 +280,130 @@ public void testReplication(String path, BlobStore store)\n         store.deleteBlob(\"test\", getSubject(createSubject));\n     }\n \n-    public Subject getSubject(String name) {\n+    public static Subject getSubject(String name) {\n         Subject subject = new Subject();\n         SingleUserPrincipal user = new SingleUserPrincipal(name);\n         subject.getPrincipals().add(user);\n         return subject;\n     }\n-\n-    // Check for Blobstore with authentication\n-    public void testWithAuthentication(BlobStore store)\n-        throws Exception {\n-        //Test for Nimbus Admin\n-        Subject admin = getSubject(\"admin\");\n-        assertStoreHasExactly(store);\n-        SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, admin)) {\n-            assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+    \n+    static enum AuthenticationTestSubject {\n+        //Nimbus Admin\n+        ADMIN(getSubject(\"admin\")),\n+        //Nimbus groups admin\n+        ADMIN_GROUPS_USER(getSubject(\"adminGroupsUser\")),\n+        //Supervisor admin\n+        SUPERVISOR(getSubject(\"supervisor\")),\n+        //Nimbus itself\n+        NIMBUS(getNimbusSubject());\n+        \n+        private Subject subject;\n+\n+        private AuthenticationTestSubject(Subject subject) {\n+            this.subject = subject;\n         }\n-        store.deleteBlob(\"test\", admin);\n-\n-        //Test for Nimbus Groups Admin\n-        Subject adminsGroupsUser = getSubject(\"adminsGroupsUser\");\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, adminsGroupsUser)) {\n-            assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+    }\n+    \n+    @ParameterizedTest\n+    @EnumSource(value = AuthenticationTestSubject.class)\n+    void testWithAuthentication(AuthenticationTestSubject testSubject) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-\" + testSubject.name())) {\n+            BlobStore store = container.blobStore;\n+            assertStoreHasExactly(store);\n+            SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, testSubject.subject)) {\n+                assertStoreHasExactly(store, \"test\");\n+                out.write(1);\n+            }\n+            store.deleteBlob(\"test\", testSubject.subject);\n         }\n-        store.deleteBlob(\"test\", adminsGroupsUser);\n-\n-        //Test for Supervisor Admin\n-        Subject supervisor = getSubject(\"supervisor\");\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, supervisor)) {\n+    }\n+    \n+    @ParameterizedTest\n+    @ValueSource(booleans = {true, false})\n+    void testWithAuthenticationDummy(boolean securityEnabled) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-dummy-sec-\" + securityEnabled)) {\n+            BlobStore store = container.blobStore;\n+            Subject who = getSubject(\"test_subject\");\n+            assertStoreHasExactly(store);\n+\n+            // Tests for case when subject != null (security turned on) and\n+            // acls for the blob are set to WORLD_EVERYTHING\n+            SettableBlobMeta metadata = new SettableBlobMeta(securityEnabled ? BlobStoreAclHandler.DEFAULT : BlobStoreAclHandler.WORLD_EVERYTHING);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n             assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+            if (securityEnabled) {\n+                // Testing whether acls are set to WORLD_EVERYTHING. Here the acl should not contain WORLD_EVERYTHING because\n+                // the subject is neither null nor empty. The ACL should however contain USER_EVERYTHING as user needs to have\n+                // complete access to the blob\n+                assertTrue(\"ACL contains WORLD_EVERYTHING\", !metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            } else {\n+                // Testing whether acls are set to WORLD_EVERYTHING\n+                assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            }\n+            \n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n+\n+            LOG.info(\"Deleting test\");\n+            store.deleteBlob(\"test\", who);\n+            assertStoreHasExactly(store);\n         }\n-        store.deleteBlob(\"test\", supervisor);\n-\n-        //Test for Nimbus itself as a user\n-        Subject nimbus = getNimbusSubject();\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, nimbus)) {\n+    }\n+    \n+    @Test\n+    void testWithAuthenticationUpdate() throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-update\")) {\n+            BlobStore store = container.blobStore;\n+            Subject who = getSubject(\"test_subject\");\n+            assertStoreHasExactly(store);\n+\n+            SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n             assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n-        }\n-        store.deleteBlob(\"test\", nimbus);\n-\n-        // Test with a dummy test_subject for cases where subject !=null (security turned on)\n-        Subject who = getSubject(\"test_subject\");\n-        assertStoreHasExactly(store);\n-\n-        // Tests for case when subject != null (security turned on) and\n-        // acls for the blob are set to WORLD_EVERYTHING\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.WORLD_EVERYTHING);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n-            out.write(1);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test\", 1);\n-\n-        LOG.info(\"Deleting test\");\n-        store.deleteBlob(\"test\", who);\n-        assertStoreHasExactly(store);\n-\n-        // Tests for case when subject != null (security turned on) and\n-        // acls are not set for the blob (DEFAULT)\n-        LOG.info(\"Creating test again\");\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n-            out.write(2);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING. Here the acl should not contain WORLD_EVERYTHING because\n-        // the subject is neither null nor empty. The ACL should however contain USER_EVERYTHING as user needs to have\n-        // complete access to the blob\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", !metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test\", 2);\n-\n-        LOG.info(\"Updating test\");\n-        try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n-            out.write(3);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        readAssertEqualsWithAuth(store, who, \"test\", 3);\n-\n-        LOG.info(\"Updating test again\");\n-        try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n-            out.write(4);\n-        }\n-        LOG.info(\"SLEEPING\");\n-        Thread.sleep(2);\n-        assertStoreHasExactly(store, \"test\");\n-        readAssertEqualsWithAuth(store, who, \"test\", 3);\n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n+            \n+            try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n+                out.write(2);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            readAssertEqualsWithAuth(store, who, \"test\", 2);\n+            \n+            try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n+                out.write(3);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            readAssertEqualsWithAuth(store, who, \"test\", 3);\n \n-        //Test for subject with no principals and acls set to WORLD_EVERYTHING\n-        who = new Subject();\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.WORLD_EVERYTHING);\n-        LOG.info(\"Creating test\");\n-        try (AtomicOutputStream out = store.createBlob(\"test-empty-subject-WE\", metadata, who)) {\n-            out.write(2);\n+            LOG.info(\"Deleting test\");\n+            store.deleteBlob(\"test\", who);\n+            assertStoreHasExactly(store);\n         }\n-        assertStoreHasExactly(store, \"test-empty-subject-WE\", \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test-empty-subject-WE\", 2);\n-\n-        //Test for subject with no principals and acls set to DEFAULT\n-        who = new Subject();\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        LOG.info(\"Creating other\");\n-        try (AtomicOutputStream out = store.createBlob(\"test-empty-subject-DEF\", metadata, who)) {\n-            out.write(2);\n-        }\n-        assertStoreHasExactly(store, \"test-empty-subject-DEF\", \"test\", \"test-empty-subject-WE\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test-empty-subject-DEF\", 2);\n-\n-        if (store instanceof HdfsBlobStore) {\n-            ((HdfsBlobStore) store).fullCleanup(1);\n-        } else {\n-            fail(\"Error the blobstore is of unknowntype\");\n+    }\n+    \n+    @ParameterizedTest\n+    @ValueSource(booleans = {true, false})\n+    void testWithAuthenticationNoPrincipal(boolean securityEnabled) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-no-principal-sec-\" + securityEnabled)) {\n+            BlobStore store = container.blobStore;\n+            //Test for subject with no principals\n+            Subject who = new Subject();\n+            assertStoreHasExactly(store);\n+\n+            // Tests for case when subject != null (security turned on) and\n+            // acls for the blob are set to WORLD_EVERYTHING\n+            SettableBlobMeta metadata = new SettableBlobMeta(securityEnabled ? BlobStoreAclHandler.DEFAULT : BlobStoreAclHandler.WORLD_EVERYTHING);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            // With no principals in the subject ACL should always be set to WORLD_EVERYTHING\n+            assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            \n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n         }\n     }\n \n@@ -535,6 +523,6 @@ public void testMultiple(BlobStore store)\n             fail(\"Error the blobstore is of unknowntype\");\n         }\n         assertStoreHasExactly(store, \"test\");\n-        readAssertEquals(store, \"test\", 3);\n+        readAssertEquals(store, \"test\", 4);\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "sha": "53cca758f6173b3df8f863f7716ba5ff24e8136d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/pom.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/pom.xml?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 1,
                "filename": "external/storm-hdfs/pom.xml",
                "patch": "@@ -234,7 +234,7 @@\n             <plugin>\n                 <groupId>org.apache.maven.plugins</groupId>\n                 <artifactId>maven-surefire-plugin</artifactId>\n-\t\t<configuration>\n+                <configuration>\n                     <reuseForks>false</reuseForks>\n                     <forkCount>1</forkCount>\n                 </configuration>",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/pom.xml",
                "sha": "a19d821e623954b08142c75b96c9111c85e3564c",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 1,
                "filename": "external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "patch": "@@ -247,7 +247,9 @@ public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n     @Override\n     public void cleanup() {\n         doRotationAndRemoveAllWriters();\n-        this.rotationTimer.cancel();\n+        if (this.rotationTimer != null) {\n+            this.rotationTimer.cancel();\n+        }\n     }\n \n     private void doRotationAndRemoveAllWriters() {",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "sha": "a145274b187dfb121e8c6b04689a103c550832c9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "patch": "@@ -56,6 +56,7 @@\n import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.verifyZeroInteractions;\n \n+\n @RunWith(MockitoJUnitRunner.class)\n public class TestHdfsBolt {\n \n@@ -203,6 +204,17 @@ public void testTickTuples() throws IOException {\n         //Tick should have flushed it\n         Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n     }\n+    \n+    @Test\n+    public void testCleanupDoesNotThrowExceptionWhenRotationPolicyIsNotTimed() {\n+        //STORM-3372: Rotation policy other than TimedRotationPolicy causes NPE on cleanup\n+        FileRotationPolicy fieldsRotationPolicy =\n+            new FileSizeRotationPolicy(10_000, FileSizeRotationPolicy.Units.MB);\n+        HdfsBolt bolt = makeHdfsBolt(hdfsURI, 10, 10000f)\n+            .withRotationPolicy(fieldsRotationPolicy);\n+        bolt.prepare(new Config(), topologyContext, collector);\n+        bolt.cleanup();\n+    }\n \n     public void createBaseDirectory(FileSystem passedFs, String path) throws IOException {\n         Path p = new Path(path);",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "sha": "7f63cc0969aa80c401c2fa3c8bdde8c97c4d1ab9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 1,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "patch": "@@ -69,7 +69,7 @@ public void testTimeFormat() {\n     }\n \n     private TopologyContext createTopologyContext(Map<String, Object> topoConf) {\n-        Map<Integer, String> taskToComponent = new HashMap<Integer, String>();\n+        Map<Integer, String> taskToComponent = new HashMap<>();\n         taskToComponent.put(7, \"Xcom\");\n         return new TopologyContext(null, topoConf, taskToComponent, null, null, null, null, null, null, 7, 6703, null, null, null, null,\n                                    null, null, null);",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "sha": "f8e1e5e30208236b5cf307385b40048e8871c046",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 2,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "patch": "@@ -12,6 +12,8 @@\n \n package org.apache.storm.hdfs.spout;\n \n+import static org.hamcrest.core.IsNull.notNullValue;\n+\n import java.io.IOException;\n import org.apache.hadoop.fs.CommonConfigurationKeys;\n import org.apache.hadoop.fs.FSDataOutputStream;\n@@ -30,7 +32,6 @@\n \n import static org.junit.Assert.assertThat;\n import static org.junit.Assert.fail;\n-import static org.mockito.ArgumentMatchers.notNull;\n \n public class TestHdfsSemantics {\n \n@@ -124,7 +125,7 @@ public void testAppendSemantics() throws Exception {\n \n         //2 try to append to a closed file\n         try (FSDataOutputStream os2 = fs.append(file1)) {\n-            assertThat(os2, notNull());\n+            assertThat(os2, notNullValue());\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "sha": "3528a3df3d4184ed1e7164786e3e9ad69dcd1931",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 12,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "patch": "@@ -12,6 +12,9 @@\n \n package org.apache.storm.hdfs.spout;\n \n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+\n import java.io.BufferedReader;\n import java.io.File;\n import java.io.IOException;\n@@ -192,6 +195,9 @@ public void testEmptySimpleText_ACK() throws Exception {\n         Path file1 = new Path(source.toString() + \"/file_empty.txt\");\n         createTextFile(file1, 0);\n \n+        //Ensure the second file has a later modified timestamp, as the spout should pick the first file first.\n+        Thread.sleep(2);\n+\n         Path file2 = new Path(source.toString() + \"/file.txt\");\n         createTextFile(file2, 5);\n \n@@ -203,15 +209,13 @@ public void testEmptySimpleText_ACK() throws Exception {\n             conf.put(Config.TOPOLOGY_ACKER_EXECUTORS, \"1\"); // enable ACKing\n             openSpout(spout, 0, conf);\n \n-            // consume empty file\n-            runSpout(spout, \"r1\");\n-            Path arc1 = new Path(archive.toString() + \"/file_empty.txt\");\n-            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc1);\n-\n-            // consume file 2\n-            runSpout(spout, \"r5\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\");\n+            // Read once. Since the first file is empty, the spout should continue with file 2\n+            runSpout(spout, \"r6\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\");\n+            //File 1 should be moved to archive\n+            assertThat(fs.isFile(new Path(archive.toString() + \"/file_empty.txt\")), is(true));\n+            //File 2 should be read\n             Path arc2 = new Path(archive.toString() + \"/file.txt\");\n-            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc1, arc2);\n+            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc2);\n         }\n     }\n \n@@ -681,11 +685,8 @@ private void openSpout(HdfsSpout spout, int spoutId, Map<String, Object> topoCon\n \n     private void createTextFile(Path file, int lineCount) throws IOException {\n         FSDataOutputStream os = fs.create(file);\n-        int size = 0;\n         for (int i = 0; i < lineCount; i++) {\n             os.writeBytes(\"line \" + i + System.lineSeparator());\n-            String msg = \"line \" + i + System.lineSeparator();\n-            size += msg.getBytes().length;\n         }\n         os.close();\n     }\n@@ -772,7 +773,7 @@ public MockTextFailingReader(FileSystem fs, Path file, Map<String, Object> conf)\n         private final int componentId;\n \n         public MockTopologyContext(int componentId, Map<String, Object> topoConf) {\n-            super(null, topoConf, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);\n+            super(null, topoConf, null, null, null, null, null, null, null, 0, 0, null, null, null, null, null, null, null);\n             this.componentId = componentId;\n         }\n ",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "sha": "133de5d7a08aef3180c1dff50a7dbaf4cab41236",
                "status": "modified"
            },
            {
                "additions": 64,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "changes": 64,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "patch": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.storm.hdfs.testing;\n+\n+import java.util.function.Supplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.junit.jupiter.api.extension.AfterEachCallback;\n+import org.junit.jupiter.api.extension.BeforeEachCallback;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+\n+public class MiniDFSClusterExtension implements BeforeEachCallback, AfterEachCallback {\n+\n+    private static final String TEST_BUILD_DATA = \"test.build.data\";\n+\n+    private final Supplier<Configuration> hadoopConfSupplier;\n+    private Configuration hadoopConf;\n+    private MiniDFSCluster dfscluster;\n+\n+    public MiniDFSClusterExtension() {\n+        this(() -> new Configuration());\n+    }\n+\n+    public MiniDFSClusterExtension(Supplier<Configuration> hadoopConfSupplier) {\n+        this.hadoopConfSupplier = hadoopConfSupplier;\n+    }\n+\n+    public Configuration getHadoopConf() {\n+        return hadoopConf;\n+    }\n+\n+    public MiniDFSCluster getDfscluster() {\n+        return dfscluster;\n+    }\n+\n+    @Override\n+    public void beforeEach(ExtensionContext arg0) throws Exception {\n+        System.setProperty(TEST_BUILD_DATA, \"target/test/data\");\n+        hadoopConf = hadoopConfSupplier.get();\n+        dfscluster = new MiniDFSCluster.Builder(hadoopConf).numDataNodes(3).build();\n+        dfscluster.waitActive();\n+    }\n+\n+    @Override\n+    public void afterEach(ExtensionContext arg0) throws Exception {\n+        dfscluster.shutdown();\n+        System.clearProperty(TEST_BUILD_DATA);\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "sha": "f88fef5838697a3e9df3b64914f431ce927617f2",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "patch": "@@ -23,6 +23,10 @@\n import org.junit.runner.Description;\n import org.junit.runners.model.Statement;\n \n+/**\n+ * @deprecated Use {@link MiniDFSClusterExtension} instead, along with JUnit 5 for new tests.\n+ */\n+@Deprecated\n public class MiniDFSClusterRule implements TestRule {\n \n     private static final String TEST_BUILD_DATA = \"test.build.data\";\n@@ -57,6 +61,7 @@ public void evaluate() throws Throwable {\n                     hadoopConf = hadoopConfSupplier.get();\n                     dfscluster = new MiniDFSCluster.Builder(hadoopConf).numDataNodes(3).build();\n                     dfscluster.waitActive();\n+                    base.evaluate();\n                 } finally {\n                     if (dfscluster != null) {\n                         dfscluster.shutdown();",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "sha": "6265a52ee9556112500d34aeef3e0a649c3bfe95",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/resources/log4j.properties",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/resources/log4j.properties?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 4,
                "filename": "external/storm-hdfs/src/test/resources/log4j.properties",
                "patch": "@@ -20,7 +20,4 @@ log4j.rootLogger = WARN, out\n \n log4j.appender.out = org.apache.log4j.ConsoleAppender\n log4j.appender.out.layout = org.apache.log4j.PatternLayout\n-log4j.appender.out.layout.ConversionPattern = %d (%t) [%p - %l] %m%n\n-\n-log4j.logger.org.apache.storm.hdfs = INFO\n-\n+log4j.appender.out.layout.ConversionPattern = %d (%t) [%p - %l] %m%n\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/resources/log4j.properties",
                "sha": "c952abd128f4ccff65eff0682c2f6420cd4621e1",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/resources/log4j2.xml",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/resources/log4j2.xml?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/resources/log4j2.xml",
                "patch": "@@ -0,0 +1,32 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+<Configuration status=\"WARN\">\n+    <Appenders>\n+        <Console name=\"Console\" target=\"SYSTEM_OUT\">\n+            <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\" charset=\"UTF-8\"/>\n+        </Console>\n+    </Appenders>\n+    <Loggers>\n+        <Root level=\"WARN\">\n+            <AppenderRef ref=\"Console\"/>\n+        </Root>\n+        <Logger name=\"org.apache.storm\" level=\"INFO\" additivity=\"false\">\n+            <AppenderRef ref=\"Console\"/>\n+        </Logger>\n+    </Loggers>\n+</Configuration>\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/external/storm-hdfs/src/test/resources/log4j2.xml",
                "sha": "546b1b380865c6dd04e7006c5dcab07888a8dab9",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d1912ae98afe9f470a05e57835c41f056cebb311/pom.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/pom.xml?ref=d1912ae98afe9f470a05e57835c41f056cebb311",
                "deletions": 1,
                "filename": "pom.xml",
                "patch": "@@ -295,7 +295,7 @@\n         <servlet.version>3.1.0</servlet.version>\n         <joda-time.version>2.3</joda-time.version>\n         <thrift.version>0.12.0</thrift.version>\n-        <junit.jupiter.version>5.3.2</junit.jupiter.version>\n+        <junit.jupiter.version>5.5.0-M1</junit.jupiter.version>\n         <surefire.version>2.22.1</surefire.version>\n         <awaitility.version>3.1.0</awaitility.version>\n         <hdrhistogram.version>2.1.10</hdrhistogram.version>",
                "raw_url": "https://github.com/apache/storm/raw/d1912ae98afe9f470a05e57835c41f056cebb311/pom.xml",
                "sha": "3b587a7ff62e1c72d2acc15aa4b25e71b50253ce",
                "status": "modified"
            }
        ],
        "message": "STORM-3372: Fix NPE when shutting down HdfsBolt, fix storm-hdfs tests not running",
        "parent": "https://github.com/apache/storm/commit/9f10f8a14482e4eb1c1323ac86d3c373634539c2",
        "patched_files": [
            "pom.xml",
            "MiniDFSClusterRule.java",
            "log4j.properties",
            "SimpleFileNameFormat.java",
            "BlobStore.java",
            "HdfsBolt.java",
            "MiniDFSClusterExtension.java",
            "HdfsSpout.java",
            "log4j2.xml",
            "AbstractHdfsBolt.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestHdfsSemantics.java",
            "BlobStoreTest.java",
            "TestHdfsSpout.java",
            "TestHdfsBolt.java",
            "TestSimpleFileNameFormat.java"
        ]
    },
    "storm_d541e60": {
        "bug_id": "storm_d541e60",
        "commit": "https://github.com/apache/storm/commit/d541e60bc41f9cbe3ba1469966bd9031ebaec207",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-client/src/jvm/org/apache/storm/zookeeper/ClientZookeeper.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/zookeeper/ClientZookeeper.java?ref=d541e60bc41f9cbe3ba1469966bd9031ebaec207",
                "deletions": 4,
                "filename": "storm-client/src/jvm/org/apache/storm/zookeeper/ClientZookeeper.java",
                "patch": "@@ -77,14 +77,14 @@ public static CuratorFramework mkClient(Map<String, Object> conf, List<String> s\n     // Deletes the state inside the zookeeper for a key, for which the\n     // contents of the key starts with nimbus host port information\n     public static void deleteNodeBlobstore(CuratorFramework zk, String parentPath, String hostPortInfo) {\n-        String normalizedPatentPath = normalizePath(parentPath);\n+        String normalizedParentPath = normalizePath(parentPath);\n         List<String> childPathList = null;\n-        if (existsNode(zk, normalizedPatentPath, false)) {\n-            childPathList = getChildren(zk, normalizedPatentPath, false);\n+        if (existsNode(zk, normalizedParentPath, false)) {\n+            childPathList = getChildren(zk, normalizedParentPath, false);\n             for (String child : childPathList) {\n                 if (child.startsWith(hostPortInfo)) {\n                     LOG.debug(\"deleteNode child {}\", child);\n-                    deleteNode(zk, normalizedPatentPath + \"/\" + child);\n+                    deleteNode(zk, normalizedParentPath + \"/\" + child);\n                 }\n             }\n         }",
                "raw_url": "https://github.com/apache/storm/raw/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-client/src/jvm/org/apache/storm/zookeeper/ClientZookeeper.java",
                "sha": "d443984939ff20ca42999c94da213323681e6bdf",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/storm/blob/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/pom.xml",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/pom.xml?ref=d541e60bc41f9cbe3ba1469966bd9031ebaec207",
                "deletions": 0,
                "filename": "storm-server/pom.xml",
                "patch": "@@ -117,6 +117,13 @@\n             </testResource>\n         </testResources>\n         <plugins>\n+            <plugin>\n+                <groupId>org.apache.maven.plugins</groupId>\n+                <artifactId>maven-surefire-plugin</artifactId>\n+                <configuration>\n+                    <forkCount>1</forkCount>\n+                </configuration>\n+            </plugin>\n             <plugin>\n                 <groupId>org.apache.maven.plugins</groupId>\n                 <artifactId>maven-surefire-report-plugin</artifactId>",
                "raw_url": "https://github.com/apache/storm/raw/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/pom.xml",
                "sha": "d1b855cb627fb1041f5871a941a35d99a0e1d8f0",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/main/java/org/apache/storm/testing/InProcessZookeeper.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/testing/InProcessZookeeper.java?ref=d541e60bc41f9cbe3ba1469966bd9031ebaec207",
                "deletions": 6,
                "filename": "storm-server/src/main/java/org/apache/storm/testing/InProcessZookeeper.java",
                "patch": "@@ -26,21 +26,17 @@\n \n     private final TmpPath zkTmp;\n     private final NIOServerCnxnFactory zookeeper;\n-    private final long zkPort;\n \n     public InProcessZookeeper() throws Exception {\n         zkTmp = new TmpPath();\n-        @SuppressWarnings(\"unchecked\")\n-        List<Object> portAndHandle = Zookeeper.mkInprocessZookeeper(zkTmp.getPath(), null);\n-        zkPort = (Long) portAndHandle.get(0);\n-        zookeeper = (NIOServerCnxnFactory) portAndHandle.get(1);\n+        zookeeper = Zookeeper.mkInprocessZookeeper(zkTmp.getPath(), null);\n     }\n \n     /**\n      * @return the port ZK is listening on (localhost)\n      */\n     public long getPort() {\n-        return zkPort;\n+        return zookeeper.getLocalPort();\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/storm/raw/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/main/java/org/apache/storm/testing/InProcessZookeeper.java",
                "sha": "c18edccb36186434cb89b8c433af6ecb43556ae6",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/main/java/org/apache/storm/zookeeper/Zookeeper.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/main/java/org/apache/storm/zookeeper/Zookeeper.java?ref=d541e60bc41f9cbe3ba1469966bd9031ebaec207",
                "deletions": 2,
                "filename": "storm-server/src/main/java/org/apache/storm/zookeeper/Zookeeper.java",
                "patch": "@@ -72,7 +72,7 @@ public static void resetInstance() {\n         _instance = INSTANCE;\n     }\n \n-    public static List mkInprocessZookeeper(String localdir, Integer port) throws Exception {\n+    public static NIOServerCnxnFactory mkInprocessZookeeper(String localdir, Integer port) throws Exception {\n         File localfile = new File(localdir);\n         ZooKeeperServer zk = new ZooKeeperServer(localfile, localfile, 2000);\n         NIOServerCnxnFactory factory = null;\n@@ -96,7 +96,7 @@ public static List mkInprocessZookeeper(String localdir, Integer port) throws Ex\n         }\n         LOG.info(\"Starting inprocess zookeeper at port {} and dir {}\", report, localdir);\n         factory.startup(zk);\n-        return Arrays.asList((Object) new Long(report), (Object) factory);\n+        return factory;\n     }\n \n     public static void shutdownInprocessZookeeper(NIOServerCnxnFactory handle) {",
                "raw_url": "https://github.com/apache/storm/raw/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/main/java/org/apache/storm/zookeeper/Zookeeper.java",
                "sha": "7a060f8c1e91804766e089604a826e75f8cddc72",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/test/java/org/apache/storm/blobstore/LocalFsBlobStoreTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-server/src/test/java/org/apache/storm/blobstore/LocalFsBlobStoreTest.java?ref=d541e60bc41f9cbe3ba1469966bd9031ebaec207",
                "deletions": 4,
                "filename": "storm-server/src/test/java/org/apache/storm/blobstore/LocalFsBlobStoreTest.java",
                "patch": "@@ -46,7 +46,6 @@\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n-import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.spy;\n \n public class LocalFsBlobStoreTest {\n@@ -67,7 +66,7 @@ public void init() {\n     try {\n       zk = new InProcessZookeeper();\n     } catch (Exception e) {\n-      e.printStackTrace();\n+      throw new RuntimeException(e);\n     }\n   }\n \n@@ -77,7 +76,7 @@ public void cleanup() throws IOException {\n     try {\n       zk.close();\n     } catch (Exception e) {\n-      e.printStackTrace();\n+      throw new RuntimeException(e);\n     }\n   }\n \n@@ -100,7 +99,8 @@ private LocalFsBlobStore initLocalFs() {\n     conf.put(Config.STORM_ZOOKEEPER_PORT, zk.getPort());\n     conf.put(Config.STORM_LOCAL_DIR, baseFile.getAbsolutePath());\n     conf.put(Config.STORM_PRINCIPAL_TO_LOCAL_PLUGIN,\"org.apache.storm.security.auth.DefaultPrincipalToLocal\");\n-    spy.prepare(conf, null, mock(NimbusInfo.class), null);\n+    NimbusInfo nimbusInfo = new NimbusInfo(\"localhost\", 0, false);\n+    spy.prepare(conf, null, nimbusInfo, null);\n     return spy;\n   }\n ",
                "raw_url": "https://github.com/apache/storm/raw/d541e60bc41f9cbe3ba1469966bd9031ebaec207/storm-server/src/test/java/org/apache/storm/blobstore/LocalFsBlobStoreTest.java",
                "sha": "b2045bf1d685ef81b7336308616a5f05d47bb104",
                "status": "modified"
            }
        ],
        "message": "STORM-3065: Reduce storm-server test fork count to 1, fix some test-specific NPEs",
        "parent": "https://github.com/apache/storm/commit/290458c121181b6213e3efe71cfcd7b5025738c1",
        "patched_files": [
            "pom.xml",
            "InProcessZookeeper.java",
            "ClientZookeeper.java",
            "Zookeeper.java",
            "LocalFsBlobStore.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "LocalFsBlobStoreTest.java"
        ]
    },
    "storm_d568408": {
        "bug_id": "storm_d568408",
        "commit": "https://github.com/apache/storm/commit/d568408e4d284199cf53baed7dd1471ab9628ca4",
        "file": [
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/main/java/org/apache/storm/st/utils/StringDecorator.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/integration-test/src/main/java/org/apache/storm/st/utils/StringDecorator.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 1,
                "filename": "integration-test/src/main/java/org/apache/storm/st/utils/StringDecorator.java",
                "patch": "@@ -17,7 +17,6 @@\n \n package org.apache.storm.st.utils;\n \n-import java.nio.charset.StandardCharsets;\n import org.apache.commons.lang.StringUtils;\n \n public class StringDecorator {",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/main/java/org/apache/storm/st/utils/StringDecorator.java",
                "sha": "34c2b65592aa537bafaea2d8446c94e69fd5288e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/DemoTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/integration-test/src/test/java/org/apache/storm/st/DemoTest.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 0,
                "filename": "integration-test/src/test/java/org/apache/storm/st/DemoTest.java",
                "patch": "@@ -80,6 +80,7 @@ public void testExclamationTopology() throws Exception {\n     public void cleanup() throws Exception {\n         if (topo != null) {\n             topo.killOrThrow();\n+            topo = null;\n         }\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/DemoTest.java",
                "sha": "133014bfe27a95642efdedc5f018172481c87da5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/tests/window/SlidingWindowTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/integration-test/src/test/java/org/apache/storm/st/tests/window/SlidingWindowTest.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 0,
                "filename": "integration-test/src/test/java/org/apache/storm/st/tests/window/SlidingWindowTest.java",
                "patch": "@@ -188,6 +188,7 @@ static void runAndVerifyTime(int windowSec, int slideSec, TestableTopology testa\n     public void cleanup() throws Exception {\n         if (topo != null) {\n             topo.killOrThrow();\n+            topo = null;\n         }\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/tests/window/SlidingWindowTest.java",
                "sha": "83b981e3614462137b690c19ea4ccd225b25bb82",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/tests/window/TumblingWindowTest.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/integration-test/src/test/java/org/apache/storm/st/tests/window/TumblingWindowTest.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 1,
                "filename": "integration-test/src/test/java/org/apache/storm/st/tests/window/TumblingWindowTest.java",
                "patch": "@@ -30,7 +30,7 @@\n \n public final class TumblingWindowTest extends AbstractTest {\n     private static Logger log = LoggerFactory.getLogger(TumblingWindowTest.class);\n-    TopoWrap topo;\n+    private TopoWrap topo;\n \n     @DataProvider\n     public static Object[][] generateWindows() {\n@@ -94,6 +94,7 @@ public void testTumbleTime(int tumbleSec) throws Exception {\n     public void cleanup() throws Exception {\n         if (topo != null) {\n             topo.killOrThrow();\n+            topo = null;\n         }\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/tests/window/TumblingWindowTest.java",
                "sha": "28b3969ed6813a9b229b9d2a02e9e94bcf092018",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/wrapper/StormCluster.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/integration-test/src/test/java/org/apache/storm/st/wrapper/StormCluster.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 1,
                "filename": "integration-test/src/test/java/org/apache/storm/st/wrapper/StormCluster.java",
                "patch": "@@ -93,7 +93,7 @@ public void killOrThrow(String topologyName) throws Exception {\n                 client.killTopologyWithOpts(topologyName, killOptions);\n                 log.info(\"Topology killed: \" + topologyName);\n                 return;\n-            } catch (Throwable e) {\n+            } catch (TException e) {\n                 log.warn(\"Couldn't kill topology: \" + topologyName + \", going to retry soon. Exception: \" + ExceptionUtils.getFullStackTrace(e));\n                 Thread.sleep(TimeUnit.SECONDS.toMillis(2));\n             }",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/integration-test/src/test/java/org/apache/storm/st/wrapper/StormCluster.java",
                "sha": "4521b36bd34b092d9b6f2c7a82aad42dc5f7cbe5",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/storm/blob/d568408e4d284199cf53baed7dd1471ab9628ca4/storm-client/src/jvm/org/apache/storm/cluster/IStormClusterState.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/cluster/IStormClusterState.java?ref=d568408e4d284199cf53baed7dd1471ab9628ca4",
                "deletions": 2,
                "filename": "storm-client/src/jvm/org/apache/storm/cluster/IStormClusterState.java",
                "patch": "@@ -168,8 +168,8 @@\n     default Optional<String> getTopoId(final String topologyName) {\n         String ret = null;\n         for (String topoId: activeStorms()) {\n-            String name = stormBase(topoId, null).get_name();\n-            if (topologyName.equals(name)) {\n+            StormBase base = stormBase(topoId, null);\n+            if(base != null && topologyName.equals(base.get_name())) {\n                 ret = topoId;\n                 break;\n             }",
                "raw_url": "https://github.com/apache/storm/raw/d568408e4d284199cf53baed7dd1471ab9628ca4/storm-client/src/jvm/org/apache/storm/cluster/IStormClusterState.java",
                "sha": "051ccd537fba7df23eb1c0a8ac94f2669fb1b90e",
                "status": "modified"
            }
        ],
        "message": "STORM-2811: Fix NPE in Nimbus when killing the same topology multiple times, fix integration test killing the same topology multiple times",
        "parent": "https://github.com/apache/storm/commit/2657c25f232f9cf6f7d6580cd27c2d76a7b6c4c9",
        "patched_files": [
            "IStormClusterState.java",
            "StormCluster.java",
            "StringDecorator.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "DemoTest.java",
            "SlidingWindowTest.java",
            "TumblingWindowTest.java"
        ]
    },
    "storm_e55f67a": {
        "bug_id": "storm_e55f67a",
        "commit": "https://github.com/apache/storm/commit/e55f67a58210461abbbdb1318c3b2a73b448a645",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/pom.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/pom.xml?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 1,
                "filename": "pom.xml",
                "patch": "@@ -302,7 +302,7 @@\n         <!-- by default the clojure test set are all clojure tests that are not integration tests. This property is overridden in the profiles -->\n         <clojure.test.set>!integration.*</clojure.test.set>\n \n-        <aetherVersion>1.0.0.v20140518</aetherVersion>\n+        <aetherVersion>1.1.0</aetherVersion>\n         <mavenVersion>3.1.0</mavenVersion>\n         <wagonVersion>1.0</wagonVersion>\n         <qpid.version>0.32</qpid.version>",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/pom.xml",
                "sha": "e1a43549e9e6a40570d4b4988ee8963096105bb6",
                "status": "modified"
            },
            {
                "additions": 53,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/pom.xml",
                "changes": 132,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/pom.xml?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 79,
                "filename": "storm-submit-tools/pom.xml",
                "patch": "@@ -44,118 +44,86 @@\n \n         <!-- Aether :: maven dependency resolution -->\n         <dependency>\n-            <groupId>org.apache.maven</groupId>\n-            <artifactId>maven-plugin-api</artifactId>\n-            <version>3.0</version>\n-            <exclusions>\n-                <exclusion>\n-                    <groupId>org.codehaus.plexus</groupId>\n-                    <artifactId>plexus-utils</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.sonatype.sisu</groupId>\n-                    <artifactId>sisu-inject-plexus</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.apache.maven</groupId>\n-                    <artifactId>maven-model</artifactId>\n-                </exclusion>\n-            </exclusions>\n+            <groupId>org.eclipse.aether</groupId>\n+            <artifactId>aether-api</artifactId>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.sonatype.aether</groupId>\n-            <artifactId>aether-api</artifactId>\n-            <version>1.12</version>\n+            <groupId>org.eclipse.aether</groupId>\n+            <artifactId>aether-spi</artifactId>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.sonatype.aether</groupId>\n+            <groupId>org.eclipse.aether</groupId>\n             <artifactId>aether-util</artifactId>\n-            <version>1.12</version>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.sonatype.aether</groupId>\n+            <groupId>org.eclipse.aether</groupId>\n             <artifactId>aether-impl</artifactId>\n-            <version>1.12</version>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.apache.maven</groupId>\n-            <artifactId>maven-aether-provider</artifactId>\n-            <version>3.0.3</version>\n-            <exclusions>\n-                <exclusion>\n-                    <groupId>org.sonatype.aether</groupId>\n-                    <artifactId>aether-api</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.sonatype.aether</groupId>\n-                    <artifactId>aether-spi</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.sonatype.aether</groupId>\n-                    <artifactId>aether-util</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.sonatype.aether</groupId>\n-                    <artifactId>aether-impl</artifactId>\n-                </exclusion>\n-                <exclusion>\n-                    <groupId>org.codehaus.plexus</groupId>\n-                    <artifactId>plexus-utils</artifactId>\n-                </exclusion>\n-            </exclusions>\n+            <groupId>org.eclipse.aether</groupId>\n+            <artifactId>aether-connector-basic</artifactId>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.sonatype.aether</groupId>\n-            <artifactId>aether-connector-file</artifactId>\n-            <version>1.12</version>\n+            <groupId>org.eclipse.aether</groupId>\n+            <artifactId>aether-transport-file</artifactId>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.sonatype.aether</groupId>\n-            <artifactId>aether-connector-wagon</artifactId>\n-            <version>1.12</version>\n-            <exclusions>\n-                <exclusion>\n-                    <groupId>org.apache.maven.wagon</groupId>\n-                    <artifactId>wagon-provider-api</artifactId>\n-                </exclusion>\n-            </exclusions>\n+            <groupId>org.eclipse.aether</groupId>\n+            <artifactId>aether-transport-http</artifactId>\n+            <version>${aetherVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.apache.maven.wagon</groupId>\n-            <artifactId>wagon-provider-api</artifactId>\n-            <version>1.0</version>\n-            <exclusions>\n-                <exclusion>\n-                    <groupId>org.codehaus.plexus</groupId>\n-                    <artifactId>plexus-utils</artifactId>\n-                </exclusion>\n-            </exclusions>\n+            <groupId>org.apache.maven</groupId>\n+            <artifactId>maven-aether-provider</artifactId>\n+            <version>${mavenVersion}</version>\n         </dependency>\n \n         <dependency>\n-            <groupId>org.apache.maven.wagon</groupId>\n-            <artifactId>wagon-http-lightweight</artifactId>\n-            <version>1.0</version>\n+            <groupId>org.codehaus.plexus</groupId>\n+            <artifactId>plexus-utils</artifactId>\n+            <version>2.1</version>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.eclipse.sisu</groupId>\n+            <artifactId>org.eclipse.sisu.plexus</artifactId>\n+            <version>0.1.1</version>\n+            <optional>true</optional>\n             <exclusions>\n                 <exclusion>\n-                    <groupId>org.apache.maven.wagon</groupId>\n-                    <artifactId>wagon-http-shared</artifactId>\n+                    <groupId>javax.enterprise</groupId>\n+                    <artifactId>cdi-api</artifactId>\n                 </exclusion>\n             </exclusions>\n         </dependency>\n-\n         <dependency>\n-            <groupId>org.apache.maven.wagon</groupId>\n-            <artifactId>wagon-http</artifactId>\n-            <version>1.0</version>\n+            <groupId>org.sonatype.sisu</groupId>\n+            <artifactId>sisu-guice</artifactId>\n+            <version>3.1.6</version>\n+            <classifier>no_aop</classifier>\n+            <optional>true</optional>\n             <exclusions>\n+                <exclusion>\n+                    <groupId>aopalliance</groupId>\n+                    <artifactId>aopalliance</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>com.google.code.findbugs</groupId>\n+                    <artifactId>jsr305</artifactId>\n+                </exclusion>\n             </exclusions>\n         </dependency>\n \n@@ -166,6 +134,12 @@\n             <version>${project.version}</version>\n             <scope>test</scope>\n         </dependency>\n+        <dependency>\n+            <groupId>commons-io</groupId>\n+            <artifactId>commons-io</artifactId>\n+            <version>2.5</version>\n+            <scope>test</scope>\n+        </dependency>\n     </dependencies>\n \n     <build>",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/pom.xml",
                "sha": "f311de7bb5f77e36952fecf350d65644ea24f95a",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/command/DependencyResolverMain.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/main/java/org/apache/storm/submit/command/DependencyResolverMain.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 4,
                "filename": "storm-submit-tools/src/main/java/org/apache/storm/submit/command/DependencyResolverMain.java",
                "patch": "@@ -24,10 +24,10 @@\n import org.apache.storm.submit.dependency.AetherUtils;\n import org.apache.storm.submit.dependency.DependencyResolver;\n import org.json.simple.JSONValue;\n-import org.sonatype.aether.artifact.Artifact;\n-import org.sonatype.aether.graph.Dependency;\n-import org.sonatype.aether.repository.RemoteRepository;\n-import org.sonatype.aether.resolution.ArtifactResult;\n+import org.eclipse.aether.artifact.Artifact;\n+import org.eclipse.aether.graph.Dependency;\n+import org.eclipse.aether.repository.RemoteRepository;\n+import org.eclipse.aether.resolution.ArtifactResult;\n \n import java.io.File;\n import java.nio.file.Files;\n@@ -66,6 +66,10 @@ public static void main(String[] args) {\n \n         try {\n             String localMavenRepoPath = getOrDefaultLocalMavenRepositoryPath(\"local-repo\");\n+\n+            // create root directory if not exist\n+            Files.createDirectories(new File(localMavenRepoPath).toPath());\n+\n             DependencyResolver resolver = new DependencyResolver(localMavenRepoPath, repositories);\n \n             List<ArtifactResult> artifactResults = resolver.resolve(dependencies);",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/command/DependencyResolverMain.java",
                "sha": "300a202c815ed154dabc3ce61b1dbdd11557c0fb",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/AetherUtils.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/AetherUtils.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 7,
                "filename": "storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/AetherUtils.java",
                "patch": "@@ -17,12 +17,12 @@\n  */\n package org.apache.storm.submit.dependency;\n \n-import org.sonatype.aether.artifact.Artifact;\n-import org.sonatype.aether.graph.Dependency;\n-import org.sonatype.aether.graph.Exclusion;\n-import org.sonatype.aether.repository.RemoteRepository;\n-import org.sonatype.aether.util.artifact.DefaultArtifact;\n-import org.sonatype.aether.util.artifact.JavaScopes;\n+import org.eclipse.aether.artifact.Artifact;\n+import org.eclipse.aether.artifact.DefaultArtifact;\n+import org.eclipse.aether.graph.Dependency;\n+import org.eclipse.aether.graph.Exclusion;\n+import org.eclipse.aether.repository.RemoteRepository;\n+import org.eclipse.aether.util.artifact.JavaScopes;\n \n import java.util.ArrayList;\n import java.util.Arrays;\n@@ -86,6 +86,6 @@ public static RemoteRepository parseRemoteRepository(String repository) {\n             throw new IllegalArgumentException(\"Bad remote repository form: \" + repository);\n         }\n \n-        return new RemoteRepository(parts[0], \"default\", parts[1]);\n+        return new RemoteRepository.Builder(parts[0], \"default\", parts[1]).build();\n     }\n }\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/AetherUtils.java",
                "sha": "a0b71465ff2423c14b1c23d7bf122f2a20f478c0",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/Booter.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/Booter.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 10,
                "filename": "storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/Booter.java",
                "patch": "@@ -18,11 +18,12 @@\n \n package org.apache.storm.submit.dependency;\n \n-import org.apache.maven.repository.internal.MavenRepositorySystemSession;\n-import org.sonatype.aether.RepositorySystem;\n-import org.sonatype.aether.RepositorySystemSession;\n-import org.sonatype.aether.repository.LocalRepository;\n-import org.sonatype.aether.repository.RemoteRepository;\n+import org.apache.maven.repository.internal.MavenRepositorySystemUtils;\n+import org.eclipse.aether.DefaultRepositorySystemSession;\n+import org.eclipse.aether.RepositorySystem;\n+import org.eclipse.aether.RepositorySystemSession;\n+import org.eclipse.aether.repository.LocalRepository;\n+import org.eclipse.aether.repository.RemoteRepository;\n \n import java.io.File;\n \n@@ -35,17 +36,22 @@ public static RepositorySystem newRepositorySystem() {\n     }\n \n     public static RepositorySystemSession newRepositorySystemSession(\n-            RepositorySystem system, String localRepoPath) {\n-        MavenRepositorySystemSession session = new MavenRepositorySystemSession();\n+        RepositorySystem system, String localRepoPath) {\n+        DefaultRepositorySystemSession session = MavenRepositorySystemUtils.newSession();\n \n         LocalRepository localRepo =\n                 new LocalRepository(new File(localRepoPath).getAbsolutePath());\n-        session.setLocalRepositoryManager(system.newLocalRepositoryManager(localRepo));\n+        session.setLocalRepositoryManager(system.newLocalRepositoryManager(session, localRepo));\n \n         return session;\n     }\n \n     public static RemoteRepository newCentralRepository() {\n-        return new RemoteRepository(\"central\", \"default\", \"http://repo1.maven.org/maven2/\");\n+        return new RemoteRepository.Builder(\"central\", \"default\", \"http://repo1.maven.org/maven2/\").build();\n     }\n-}\n\\ No newline at end of file\n+\n+    public static RemoteRepository newLocalRepository() {\n+        return new RemoteRepository.Builder(\"local\",\n+                \"default\", \"file://\" + System.getProperty(\"user.home\") + \"/.m2/repository\").build();\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/Booter.java",
                "sha": "a9632e8d7dbc44d2b999a942cc7d27e35c6edcb5",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/DependencyResolver.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/DependencyResolver.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 12,
                "filename": "storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/DependencyResolver.java",
                "patch": "@@ -18,18 +18,18 @@\n \n package org.apache.storm.submit.dependency;\n \n-import org.sonatype.aether.RepositorySystem;\n-import org.sonatype.aether.RepositorySystemSession;\n-import org.sonatype.aether.collection.CollectRequest;\n-import org.sonatype.aether.graph.Dependency;\n-import org.sonatype.aether.graph.DependencyFilter;\n-import org.sonatype.aether.repository.RemoteRepository;\n-import org.sonatype.aether.resolution.ArtifactResolutionException;\n-import org.sonatype.aether.resolution.ArtifactResult;\n-import org.sonatype.aether.resolution.DependencyRequest;\n-import org.sonatype.aether.resolution.DependencyResolutionException;\n-import org.sonatype.aether.util.artifact.JavaScopes;\n-import org.sonatype.aether.util.filter.DependencyFilterUtils;\n+import org.eclipse.aether.RepositorySystem;\n+import org.eclipse.aether.RepositorySystemSession;\n+import org.eclipse.aether.collection.CollectRequest;\n+import org.eclipse.aether.graph.Dependency;\n+import org.eclipse.aether.graph.DependencyFilter;\n+import org.eclipse.aether.repository.RemoteRepository;\n+import org.eclipse.aether.resolution.ArtifactResolutionException;\n+import org.eclipse.aether.resolution.ArtifactResult;\n+import org.eclipse.aether.resolution.DependencyRequest;\n+import org.eclipse.aether.resolution.DependencyResolutionException;\n+import org.eclipse.aether.util.artifact.JavaScopes;\n+import org.eclipse.aether.util.filter.DependencyFilterUtils;\n \n import java.io.File;\n import java.net.MalformedURLException;",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/DependencyResolver.java",
                "sha": "a2241fa42068bc82a4711800a9fc2efc456e8d5d",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/RepositorySystemFactory.java",
                "changes": 61,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/RepositorySystemFactory.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 39,
                "filename": "storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/RepositorySystemFactory.java",
                "patch": "@@ -6,9 +6,9 @@\n  * to you under the Apache License, Version 2.0 (the\n  * \"License\"); you may not use this file except in compliance\n  * with the License.  You may obtain a copy of the License at\n- *\n+ * <p>\n  * http://www.apache.org/licenses/LICENSE-2.0\n- *\n+ * <p>\n  * Unless required by applicable law or agreed to in writing, software\n  * distributed under the License is distributed on an \"AS IS\" BASIS,\n  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n@@ -18,50 +18,33 @@\n \n package org.apache.storm.submit.dependency;\n \n-import org.apache.maven.repository.internal.DefaultServiceLocator;\n-import org.apache.maven.wagon.Wagon;\n-import org.apache.maven.wagon.providers.http.HttpWagon;\n-import org.apache.maven.wagon.providers.http.LightweightHttpWagon;\n-import org.sonatype.aether.RepositorySystem;\n-import org.sonatype.aether.connector.file.FileRepositoryConnectorFactory;\n-import org.sonatype.aether.connector.wagon.WagonProvider;\n-import org.sonatype.aether.connector.wagon.WagonRepositoryConnectorFactory;\n-import org.sonatype.aether.spi.connector.RepositoryConnectorFactory;\n+import org.eclipse.aether.connector.basic.BasicRepositoryConnectorFactory;\n+import org.eclipse.aether.impl.DefaultServiceLocator;\n+import org.apache.maven.repository.internal.MavenRepositorySystemUtils;\n+import org.eclipse.aether.RepositorySystem;\n+import org.eclipse.aether.spi.connector.transport.TransporterFactory;\n+import org.eclipse.aether.transport.file.FileTransporterFactory;\n+import org.eclipse.aether.transport.http.HttpTransporterFactory;\n+import org.eclipse.aether.spi.connector.RepositoryConnectorFactory;\n \n /**\n  * Get maven repository instance.\n  */\n public class RepositorySystemFactory {\n     public static RepositorySystem newRepositorySystem() {\n-        DefaultServiceLocator locator = new DefaultServiceLocator();\n-        locator.addService(RepositoryConnectorFactory.class, FileRepositoryConnectorFactory.class);\n-        locator.addService(RepositoryConnectorFactory.class, WagonRepositoryConnectorFactory.class);\n-        locator.setServices(WagonProvider.class, new ManualWagonProvider());\n+        DefaultServiceLocator locator = MavenRepositorySystemUtils.newServiceLocator();\n+        locator.addService(RepositoryConnectorFactory.class, BasicRepositoryConnectorFactory.class);\n+        locator.addService(TransporterFactory.class, FileTransporterFactory.class);\n+        locator.addService(TransporterFactory.class, HttpTransporterFactory.class);\n+\n+        locator.setErrorHandler(new DefaultServiceLocator.ErrorHandler() {\n+            @Override\n+            public void serviceCreationFailed(Class<?> type, Class<?> impl, Throwable exception) {\n+                exception.printStackTrace();\n+            }\n+        });\n \n         return locator.getService(RepositorySystem.class);\n     }\n \n-    /**\n-     * ManualWagonProvider\n-     */\n-    public static class ManualWagonProvider implements WagonProvider {\n-\n-        @Override\n-        public Wagon lookup(String roleHint) throws Exception {\n-            if (\"http\".equals(roleHint)) {\n-                return new LightweightHttpWagon();\n-            }\n-\n-            if (\"https\".equals(roleHint)) {\n-                return new HttpWagon();\n-            }\n-\n-            return null;\n-        }\n-\n-        @Override\n-        public void release(Wagon arg0) {\n-\n-        }\n-    }\n-}\n\\ No newline at end of file\n+}",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/main/java/org/apache/storm/submit/dependency/RepositorySystemFactory.java",
                "sha": "ae1c03a5528aeffdb6acc12bc126404d419758f0",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/AetherUtilsTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/AetherUtilsTest.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 5,
                "filename": "storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/AetherUtilsTest.java",
                "patch": "@@ -19,11 +19,11 @@\n \n import com.google.common.collect.Lists;\n import org.junit.Test;\n-import org.sonatype.aether.artifact.Artifact;\n-import org.sonatype.aether.graph.Dependency;\n-import org.sonatype.aether.graph.Exclusion;\n-import org.sonatype.aether.util.artifact.DefaultArtifact;\n-import org.sonatype.aether.util.artifact.JavaScopes;\n+import org.eclipse.aether.artifact.Artifact;\n+import org.eclipse.aether.graph.Dependency;\n+import org.eclipse.aether.graph.Exclusion;\n+import org.eclipse.aether.artifact.DefaultArtifact;\n+import org.eclipse.aether.util.artifact.JavaScopes;\n \n import java.util.List;\n ",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/AetherUtilsTest.java",
                "sha": "5b5ce3edf7976f1d9ad1c477f5bd87188f9282a1",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/storm/blob/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/DependencyResolverTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/DependencyResolverTest.java?ref=e55f67a58210461abbbdb1318c3b2a73b448a645",
                "deletions": 4,
                "filename": "storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/DependencyResolverTest.java",
                "patch": "@@ -23,10 +23,10 @@\n import org.junit.Before;\n import org.junit.BeforeClass;\n import org.junit.Test;\n-import org.sonatype.aether.graph.Dependency;\n-import org.sonatype.aether.resolution.ArtifactResult;\n-import org.sonatype.aether.util.artifact.DefaultArtifact;\n-import org.sonatype.aether.util.artifact.JavaScopes;\n+import org.eclipse.aether.graph.Dependency;\n+import org.eclipse.aether.resolution.ArtifactResult;\n+import org.eclipse.aether.artifact.DefaultArtifact;\n+import org.eclipse.aether.util.artifact.JavaScopes;\n \n import java.nio.file.Files;\n import java.nio.file.Path;",
                "raw_url": "https://github.com/apache/storm/raw/e55f67a58210461abbbdb1318c3b2a73b448a645/storm-submit-tools/src/test/java/org/apache/storm/submit/dependency/DependencyResolverTest.java",
                "sha": "8f7b750281af18880e026bc10943167ff16b58c3",
                "status": "modified"
            }
        ],
        "message": "STORM-2481 Upgrade Aether version to resolve Aether bug BUG-451566\n\n* this resolves NPE issue on Aether and helps showing proper error message\n* this also fixes the bug which dependencies root directorys does not exist\n  * after the patch it will create the directory if not found",
        "parent": "https://github.com/apache/storm/commit/c38d7950a347e906a8ebe7b2889c65c6e8e8c936",
        "patched_files": [
            "pom.xml",
            "DependencyResolverMain.java",
            "Booter.java",
            "DependencyResolver.java",
            "RepositorySystemFactory.java",
            "AetherUtils.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "AetherUtilsTest.java",
            "DependencyResolverTest.java"
        ]
    },
    "storm_e69fbc5": {
        "bug_id": "storm_e69fbc5",
        "commit": "https://github.com/apache/storm/commit/e69fbc51ada2fd542d717bbd7623c39f4f6a1cb8",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/e69fbc51ada2fd542d717bbd7623c39f4f6a1cb8/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java?ref=e69fbc51ada2fd542d717bbd7623c39f4f6a1cb8",
                "deletions": 1,
                "filename": "storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "patch": "@@ -327,7 +327,9 @@ public void execute(Tuple input) {\n \n     @Override\n     public void cleanup() {\n-        waterMarkEventGenerator.shutdown();\n+        if (waterMarkEventGenerator != null) {\n+            waterMarkEventGenerator.shutdown();\n+        }\n         windowManager.shutdown();\n         bolt.cleanup();\n     }",
                "raw_url": "https://github.com/apache/storm/raw/e69fbc51ada2fd542d717bbd7623c39f4f6a1cb8/storm-client/src/jvm/org/apache/storm/topology/WindowedBoltExecutor.java",
                "sha": "5089f64f807b5f6c6600d49709132b3abeed4f86",
                "status": "modified"
            }
        ],
        "message": "STORM-2779 NPE on shutting down WindowedBoltExecutor\n\n* waterMarkEventGenerator could be null when timestamp field is not specified",
        "parent": "https://github.com/apache/storm/commit/c8947c2fede62036c20472c9e0335ef90a06b536",
        "patched_files": [
            "WindowedBoltExecutor.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "WindowedBoltExecutorTest.java"
        ]
    },
    "storm_f015130": {
        "bug_id": "storm_f015130",
        "commit": "https://github.com/apache/storm/commit/f015130b0e4b33191f9fa84302f46f9a5e10c014",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs-blobstore/pom.xml",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs-blobstore/pom.xml?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 0,
                "filename": "external/storm-hdfs-blobstore/pom.xml",
                "patch": "@@ -208,6 +208,11 @@\n             <artifactId>guava</artifactId>\n             <version>${guava.version}</version>\n         </dependency>\n+        <dependency>\n+            <groupId>org.junit.jupiter</groupId>\n+            <artifactId>junit-jupiter-params</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n     </dependencies>\n     <build>\n         <plugins>",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs-blobstore/pom.xml",
                "sha": "ccc69a63ed0bde5d19dd2ec10c590cc9a85a30f8",
                "status": "modified"
            },
            {
                "additions": 127,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "changes": 266,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 139,
                "filename": "external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "patch": "@@ -18,6 +18,7 @@\n  */\n package org.apache.storm.hdfs.blobstore;\n \n+import org.apache.storm.hdfs.testing.MiniDFSClusterExtension;\n import org.apache.commons.io.FileUtils;\n import org.apache.storm.Config;\n import org.apache.storm.blobstore.AtomicOutputStream;\n@@ -28,14 +29,9 @@\n import org.apache.storm.generated.AuthorizationException;\n import org.apache.storm.generated.KeyNotFoundException;\n import org.apache.storm.generated.SettableBlobMeta;\n-import org.apache.storm.hdfs.testing.MiniDFSClusterRule;\n import org.apache.storm.security.auth.FixedGroupsMapping;\n import org.apache.storm.security.auth.NimbusPrincipal;\n import org.apache.storm.security.auth.SingleUserPrincipal;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.ClassRule;\n-import org.junit.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -55,30 +51,34 @@\n \n import static org.junit.Assert.*;\n \n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.EnumSource;\n+import org.junit.jupiter.params.provider.ValueSource;\n+\n public class BlobStoreTest {\n \n-    @ClassRule\n-    public static final MiniDFSClusterRule DFS_CLUSTER_RULE = new MiniDFSClusterRule();\n+    @RegisterExtension\n+    public static final MiniDFSClusterExtension DFS_CLUSTER_EXTENSION = new MiniDFSClusterExtension();\n \n     private static final Logger LOG = LoggerFactory.getLogger(BlobStoreTest.class);\n     URI base;\n-    File baseFile;\n     private static final Map<String, Object> CONF = new HashMap<>();\n     public static final int READ = 0x01;\n     public static final int WRITE = 0x02;\n     public static final int ADMIN = 0x04;\n \n-    @Before\n+    @BeforeEach\n     public void init() {\n         initializeConfigs();\n-        baseFile = new File(\"/tmp/blob-store-test-\" + UUID.randomUUID());\n-        base = baseFile.toURI();\n     }\n \n-    @After\n+    @AfterEach\n     public void cleanup()\n         throws IOException {\n-        FileUtils.deleteDirectory(baseFile);\n     }\n \n     // Method which initializes nimbus admin\n@@ -160,7 +160,7 @@ private AutoCloseableBlobStoreContainer initHdfs(String dirName)\n         conf.put(Config.STORM_PRINCIPAL_TO_LOCAL_PLUGIN, \"org.apache.storm.security.auth.DefaultPrincipalToLocal\");\n         conf.put(Config.STORM_BLOBSTORE_REPLICATION_FACTOR, 3);\n         HdfsBlobStore store = new HdfsBlobStore();\n-        store.prepareInternal(conf, null, DFS_CLUSTER_RULE.getDfscluster().getConfiguration(0));\n+        store.prepareInternal(conf, null, DFS_CLUSTER_EXTENSION.getDfscluster().getConfiguration(0));\n         return new AutoCloseableBlobStoreContainer(store);\n     }\n \n@@ -204,15 +204,6 @@ public void testMultipleHdfs()\n         }\n     }\n \n-    @Test\n-    public void testHdfsWithAuth()\n-        throws Exception {\n-        // use different blobstore dir so it doesn't conflict with other tests\n-        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore3\")) {\n-            testWithAuthentication(container.blobStore);\n-        }\n-    }\n-\n     // Test for replication.\n     public void testReplication(String path, BlobStore store)\n         throws Exception {\n@@ -289,133 +280,130 @@ public void testReplication(String path, BlobStore store)\n         store.deleteBlob(\"test\", getSubject(createSubject));\n     }\n \n-    public Subject getSubject(String name) {\n+    public static Subject getSubject(String name) {\n         Subject subject = new Subject();\n         SingleUserPrincipal user = new SingleUserPrincipal(name);\n         subject.getPrincipals().add(user);\n         return subject;\n     }\n-\n-    // Check for Blobstore with authentication\n-    public void testWithAuthentication(BlobStore store)\n-        throws Exception {\n-        //Test for Nimbus Admin\n-        Subject admin = getSubject(\"admin\");\n-        assertStoreHasExactly(store);\n-        SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, admin)) {\n-            assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+    \n+    static enum AuthenticationTestSubject {\n+        //Nimbus Admin\n+        ADMIN(getSubject(\"admin\")),\n+        //Nimbus groups admin\n+        ADMIN_GROUPS_USER(getSubject(\"adminGroupsUser\")),\n+        //Supervisor admin\n+        SUPERVISOR(getSubject(\"supervisor\")),\n+        //Nimbus itself\n+        NIMBUS(getNimbusSubject());\n+        \n+        private Subject subject;\n+\n+        private AuthenticationTestSubject(Subject subject) {\n+            this.subject = subject;\n         }\n-        store.deleteBlob(\"test\", admin);\n-\n-        //Test for Nimbus Groups Admin\n-        Subject adminsGroupsUser = getSubject(\"adminsGroupsUser\");\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, adminsGroupsUser)) {\n-            assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+    }\n+    \n+    @ParameterizedTest\n+    @EnumSource(value = AuthenticationTestSubject.class)\n+    void testWithAuthentication(AuthenticationTestSubject testSubject) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-\" + testSubject.name())) {\n+            BlobStore store = container.blobStore;\n+            assertStoreHasExactly(store);\n+            SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, testSubject.subject)) {\n+                assertStoreHasExactly(store, \"test\");\n+                out.write(1);\n+            }\n+            store.deleteBlob(\"test\", testSubject.subject);\n         }\n-        store.deleteBlob(\"test\", adminsGroupsUser);\n-\n-        //Test for Supervisor Admin\n-        Subject supervisor = getSubject(\"supervisor\");\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, supervisor)) {\n+    }\n+    \n+    @ParameterizedTest\n+    @ValueSource(booleans = {true, false})\n+    void testWithAuthenticationDummy(boolean securityEnabled) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-dummy-sec-\" + securityEnabled)) {\n+            BlobStore store = container.blobStore;\n+            Subject who = getSubject(\"test_subject\");\n+            assertStoreHasExactly(store);\n+\n+            // Tests for case when subject != null (security turned on) and\n+            // acls for the blob are set to WORLD_EVERYTHING\n+            SettableBlobMeta metadata = new SettableBlobMeta(securityEnabled ? BlobStoreAclHandler.DEFAULT : BlobStoreAclHandler.WORLD_EVERYTHING);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n             assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n+            if (securityEnabled) {\n+                // Testing whether acls are set to WORLD_EVERYTHING. Here the acl should not contain WORLD_EVERYTHING because\n+                // the subject is neither null nor empty. The ACL should however contain USER_EVERYTHING as user needs to have\n+                // complete access to the blob\n+                assertTrue(\"ACL contains WORLD_EVERYTHING\", !metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            } else {\n+                // Testing whether acls are set to WORLD_EVERYTHING\n+                assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            }\n+            \n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n+\n+            LOG.info(\"Deleting test\");\n+            store.deleteBlob(\"test\", who);\n+            assertStoreHasExactly(store);\n         }\n-        store.deleteBlob(\"test\", supervisor);\n-\n-        //Test for Nimbus itself as a user\n-        Subject nimbus = getNimbusSubject();\n-        assertStoreHasExactly(store);\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, nimbus)) {\n+    }\n+    \n+    @Test\n+    void testWithAuthenticationUpdate() throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-update\")) {\n+            BlobStore store = container.blobStore;\n+            Subject who = getSubject(\"test_subject\");\n+            assertStoreHasExactly(store);\n+\n+            SettableBlobMeta metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n             assertStoreHasExactly(store, \"test\");\n-            out.write(1);\n-        }\n-        store.deleteBlob(\"test\", nimbus);\n-\n-        // Test with a dummy test_subject for cases where subject !=null (security turned on)\n-        Subject who = getSubject(\"test_subject\");\n-        assertStoreHasExactly(store);\n-\n-        // Tests for case when subject != null (security turned on) and\n-        // acls for the blob are set to WORLD_EVERYTHING\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.WORLD_EVERYTHING);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n-            out.write(1);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test\", 1);\n-\n-        LOG.info(\"Deleting test\");\n-        store.deleteBlob(\"test\", who);\n-        assertStoreHasExactly(store);\n-\n-        // Tests for case when subject != null (security turned on) and\n-        // acls are not set for the blob (DEFAULT)\n-        LOG.info(\"Creating test again\");\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n-            out.write(2);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING. Here the acl should not contain WORLD_EVERYTHING because\n-        // the subject is neither null nor empty. The ACL should however contain USER_EVERYTHING as user needs to have\n-        // complete access to the blob\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", !metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test\", 2);\n-\n-        LOG.info(\"Updating test\");\n-        try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n-            out.write(3);\n-        }\n-        assertStoreHasExactly(store, \"test\");\n-        readAssertEqualsWithAuth(store, who, \"test\", 3);\n-\n-        LOG.info(\"Updating test again\");\n-        try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n-            out.write(4);\n-        }\n-        LOG.info(\"SLEEPING\");\n-        Thread.sleep(2);\n-        assertStoreHasExactly(store, \"test\");\n-        readAssertEqualsWithAuth(store, who, \"test\", 3);\n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n+            \n+            try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n+                out.write(2);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            readAssertEqualsWithAuth(store, who, \"test\", 2);\n+            \n+            try (AtomicOutputStream out = store.updateBlob(\"test\", who)) {\n+                out.write(3);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            readAssertEqualsWithAuth(store, who, \"test\", 3);\n \n-        //Test for subject with no principals and acls set to WORLD_EVERYTHING\n-        who = new Subject();\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.WORLD_EVERYTHING);\n-        LOG.info(\"Creating test\");\n-        try (AtomicOutputStream out = store.createBlob(\"test-empty-subject-WE\", metadata, who)) {\n-            out.write(2);\n+            LOG.info(\"Deleting test\");\n+            store.deleteBlob(\"test\", who);\n+            assertStoreHasExactly(store);\n         }\n-        assertStoreHasExactly(store, \"test-empty-subject-WE\", \"test\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test-empty-subject-WE\", 2);\n-\n-        //Test for subject with no principals and acls set to DEFAULT\n-        who = new Subject();\n-        metadata = new SettableBlobMeta(BlobStoreAclHandler.DEFAULT);\n-        LOG.info(\"Creating other\");\n-        try (AtomicOutputStream out = store.createBlob(\"test-empty-subject-DEF\", metadata, who)) {\n-            out.write(2);\n-        }\n-        assertStoreHasExactly(store, \"test-empty-subject-DEF\", \"test\", \"test-empty-subject-WE\");\n-        // Testing whether acls are set to WORLD_EVERYTHING\n-        assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n-        readAssertEqualsWithAuth(store, who, \"test-empty-subject-DEF\", 2);\n-\n-        if (store instanceof HdfsBlobStore) {\n-            ((HdfsBlobStore) store).fullCleanup(1);\n-        } else {\n-            fail(\"Error the blobstore is of unknowntype\");\n+    }\n+    \n+    @ParameterizedTest\n+    @ValueSource(booleans = {true, false})\n+    void testWithAuthenticationNoPrincipal(boolean securityEnabled) throws Exception {\n+        try (AutoCloseableBlobStoreContainer container = initHdfs(\"/storm/blobstore-auth-no-principal-sec-\" + securityEnabled)) {\n+            BlobStore store = container.blobStore;\n+            //Test for subject with no principals\n+            Subject who = new Subject();\n+            assertStoreHasExactly(store);\n+\n+            // Tests for case when subject != null (security turned on) and\n+            // acls for the blob are set to WORLD_EVERYTHING\n+            SettableBlobMeta metadata = new SettableBlobMeta(securityEnabled ? BlobStoreAclHandler.DEFAULT : BlobStoreAclHandler.WORLD_EVERYTHING);\n+            try (AtomicOutputStream out = store.createBlob(\"test\", metadata, who)) {\n+                out.write(1);\n+            }\n+            assertStoreHasExactly(store, \"test\");\n+            // With no principals in the subject ACL should always be set to WORLD_EVERYTHING\n+            assertTrue(\"ACL does not contain WORLD_EVERYTHING\", metadata.toString().contains(\"AccessControl(type:OTHER, access:7)\"));\n+            \n+            readAssertEqualsWithAuth(store, who, \"test\", 1);\n         }\n     }\n \n@@ -535,6 +523,6 @@ public void testMultiple(BlobStore store)\n             fail(\"Error the blobstore is of unknowntype\");\n         }\n         assertStoreHasExactly(store, \"test\");\n-        readAssertEquals(store, \"test\", 3);\n+        readAssertEquals(store, \"test\", 4);\n     }\n }",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs-blobstore/src/test/java/org/apache/storm/hdfs/blobstore/BlobStoreTest.java",
                "sha": "53cca758f6173b3df8f863f7716ba5ff24e8136d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/pom.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/pom.xml?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 1,
                "filename": "external/storm-hdfs/pom.xml",
                "patch": "@@ -234,7 +234,7 @@\n             <plugin>\n                 <groupId>org.apache.maven.plugins</groupId>\n                 <artifactId>maven-surefire-plugin</artifactId>\n-\t\t<configuration>\n+                <configuration>\n                     <reuseForks>false</reuseForks>\n                     <forkCount>1</forkCount>\n                 </configuration>",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/pom.xml",
                "sha": "a19d821e623954b08142c75b96c9111c85e3564c",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 1,
                "filename": "external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "patch": "@@ -247,7 +247,9 @@ public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n     @Override\n     public void cleanup() {\n         doRotationAndRemoveAllWriters();\n-        this.rotationTimer.cancel();\n+        if (this.rotationTimer != null) {\n+            this.rotationTimer.cancel();\n+        }\n     }\n \n     private void doRotationAndRemoveAllWriters() {",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java",
                "sha": "a145274b187dfb121e8c6b04689a103c550832c9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "patch": "@@ -56,6 +56,7 @@\n import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.verifyZeroInteractions;\n \n+\n @RunWith(MockitoJUnitRunner.class)\n public class TestHdfsBolt {\n \n@@ -203,6 +204,17 @@ public void testTickTuples() throws IOException {\n         //Tick should have flushed it\n         Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n     }\n+    \n+    @Test\n+    public void testCleanupDoesNotThrowExceptionWhenRotationPolicyIsNotTimed() {\n+        //STORM-3372: Rotation policy other than TimedRotationPolicy causes NPE on cleanup\n+        FileRotationPolicy fieldsRotationPolicy =\n+            new FileSizeRotationPolicy(10_000, FileSizeRotationPolicy.Units.MB);\n+        HdfsBolt bolt = makeHdfsBolt(hdfsURI, 10, 10000f)\n+            .withRotationPolicy(fieldsRotationPolicy);\n+        bolt.prepare(new Config(), topologyContext, collector);\n+        bolt.cleanup();\n+    }\n \n     public void createBaseDirectory(FileSystem passedFs, String path) throws IOException {\n         Path p = new Path(path);",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/TestHdfsBolt.java",
                "sha": "7f63cc0969aa80c401c2fa3c8bdde8c97c4d1ab9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 1,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "patch": "@@ -69,7 +69,7 @@ public void testTimeFormat() {\n     }\n \n     private TopologyContext createTopologyContext(Map<String, Object> topoConf) {\n-        Map<Integer, String> taskToComponent = new HashMap<Integer, String>();\n+        Map<Integer, String> taskToComponent = new HashMap<>();\n         taskToComponent.put(7, \"Xcom\");\n         return new TopologyContext(null, topoConf, taskToComponent, null, null, null, null, null, null, 7, 6703, null, null, null, null,\n                                    null, null, null);",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/bolt/format/TestSimpleFileNameFormat.java",
                "sha": "f8e1e5e30208236b5cf307385b40048e8871c046",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 2,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "patch": "@@ -12,6 +12,8 @@\n \n package org.apache.storm.hdfs.spout;\n \n+import static org.hamcrest.core.IsNull.notNullValue;\n+\n import java.io.IOException;\n import org.apache.hadoop.fs.CommonConfigurationKeys;\n import org.apache.hadoop.fs.FSDataOutputStream;\n@@ -30,7 +32,6 @@\n \n import static org.junit.Assert.assertThat;\n import static org.junit.Assert.fail;\n-import static org.mockito.ArgumentMatchers.notNull;\n \n public class TestHdfsSemantics {\n \n@@ -124,7 +125,7 @@ public void testAppendSemantics() throws Exception {\n \n         //2 try to append to a closed file\n         try (FSDataOutputStream os2 = fs.append(file1)) {\n-            assertThat(os2, notNull());\n+            assertThat(os2, notNullValue());\n         }\n     }\n ",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSemantics.java",
                "sha": "3528a3df3d4184ed1e7164786e3e9ad69dcd1931",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 12,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "patch": "@@ -12,6 +12,9 @@\n \n package org.apache.storm.hdfs.spout;\n \n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+\n import java.io.BufferedReader;\n import java.io.File;\n import java.io.IOException;\n@@ -192,6 +195,9 @@ public void testEmptySimpleText_ACK() throws Exception {\n         Path file1 = new Path(source.toString() + \"/file_empty.txt\");\n         createTextFile(file1, 0);\n \n+        //Ensure the second file has a later modified timestamp, as the spout should pick the first file first.\n+        Thread.sleep(2);\n+\n         Path file2 = new Path(source.toString() + \"/file.txt\");\n         createTextFile(file2, 5);\n \n@@ -203,15 +209,13 @@ public void testEmptySimpleText_ACK() throws Exception {\n             conf.put(Config.TOPOLOGY_ACKER_EXECUTORS, \"1\"); // enable ACKing\n             openSpout(spout, 0, conf);\n \n-            // consume empty file\n-            runSpout(spout, \"r1\");\n-            Path arc1 = new Path(archive.toString() + \"/file_empty.txt\");\n-            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc1);\n-\n-            // consume file 2\n-            runSpout(spout, \"r5\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\");\n+            // Read once. Since the first file is empty, the spout should continue with file 2\n+            runSpout(spout, \"r6\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\");\n+            //File 1 should be moved to archive\n+            assertThat(fs.isFile(new Path(archive.toString() + \"/file_empty.txt\")), is(true));\n+            //File 2 should be read\n             Path arc2 = new Path(archive.toString() + \"/file.txt\");\n-            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc1, arc2);\n+            checkCollectorOutput_txt((MockCollector) spout.getCollector(), arc2);\n         }\n     }\n \n@@ -681,11 +685,8 @@ private void openSpout(HdfsSpout spout, int spoutId, Map<String, Object> topoCon\n \n     private void createTextFile(Path file, int lineCount) throws IOException {\n         FSDataOutputStream os = fs.create(file);\n-        int size = 0;\n         for (int i = 0; i < lineCount; i++) {\n             os.writeBytes(\"line \" + i + System.lineSeparator());\n-            String msg = \"line \" + i + System.lineSeparator();\n-            size += msg.getBytes().length;\n         }\n         os.close();\n     }\n@@ -772,7 +773,7 @@ public MockTextFailingReader(FileSystem fs, Path file, Map<String, Object> conf)\n         private final int componentId;\n \n         public MockTopologyContext(int componentId, Map<String, Object> topoConf) {\n-            super(null, topoConf, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);\n+            super(null, topoConf, null, null, null, null, null, null, null, 0, 0, null, null, null, null, null, null, null);\n             this.componentId = componentId;\n         }\n ",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/spout/TestHdfsSpout.java",
                "sha": "133de5d7a08aef3180c1dff50a7dbaf4cab41236",
                "status": "modified"
            },
            {
                "additions": 64,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "changes": 64,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "patch": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.storm.hdfs.testing;\n+\n+import java.util.function.Supplier;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.junit.jupiter.api.extension.AfterEachCallback;\n+import org.junit.jupiter.api.extension.BeforeEachCallback;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+\n+public class MiniDFSClusterExtension implements BeforeEachCallback, AfterEachCallback {\n+\n+    private static final String TEST_BUILD_DATA = \"test.build.data\";\n+\n+    private final Supplier<Configuration> hadoopConfSupplier;\n+    private Configuration hadoopConf;\n+    private MiniDFSCluster dfscluster;\n+\n+    public MiniDFSClusterExtension() {\n+        this(() -> new Configuration());\n+    }\n+\n+    public MiniDFSClusterExtension(Supplier<Configuration> hadoopConfSupplier) {\n+        this.hadoopConfSupplier = hadoopConfSupplier;\n+    }\n+\n+    public Configuration getHadoopConf() {\n+        return hadoopConf;\n+    }\n+\n+    public MiniDFSCluster getDfscluster() {\n+        return dfscluster;\n+    }\n+\n+    @Override\n+    public void beforeEach(ExtensionContext arg0) throws Exception {\n+        System.setProperty(TEST_BUILD_DATA, \"target/test/data\");\n+        hadoopConf = hadoopConfSupplier.get();\n+        dfscluster = new MiniDFSCluster.Builder(hadoopConf).numDataNodes(3).build();\n+        dfscluster.waitActive();\n+    }\n+\n+    @Override\n+    public void afterEach(ExtensionContext arg0) throws Exception {\n+        dfscluster.shutdown();\n+        System.clearProperty(TEST_BUILD_DATA);\n+    }\n+}",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterExtension.java",
                "sha": "f88fef5838697a3e9df3b64914f431ce927617f2",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "patch": "@@ -23,6 +23,10 @@\n import org.junit.runner.Description;\n import org.junit.runners.model.Statement;\n \n+/**\n+ * @deprecated Use {@link MiniDFSClusterExtension} instead, along with JUnit 5 for new tests.\n+ */\n+@Deprecated\n public class MiniDFSClusterRule implements TestRule {\n \n     private static final String TEST_BUILD_DATA = \"test.build.data\";\n@@ -57,6 +61,7 @@ public void evaluate() throws Throwable {\n                     hadoopConf = hadoopConfSupplier.get();\n                     dfscluster = new MiniDFSCluster.Builder(hadoopConf).numDataNodes(3).build();\n                     dfscluster.waitActive();\n+                    base.evaluate();\n                 } finally {\n                     if (dfscluster != null) {\n                         dfscluster.shutdown();",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/java/org/apache/storm/hdfs/testing/MiniDFSClusterRule.java",
                "sha": "6265a52ee9556112500d34aeef3e0a649c3bfe95",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/resources/log4j.properties",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/resources/log4j.properties?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 4,
                "filename": "external/storm-hdfs/src/test/resources/log4j.properties",
                "patch": "@@ -20,7 +20,4 @@ log4j.rootLogger = WARN, out\n \n log4j.appender.out = org.apache.log4j.ConsoleAppender\n log4j.appender.out.layout = org.apache.log4j.PatternLayout\n-log4j.appender.out.layout.ConversionPattern = %d (%t) [%p - %l] %m%n\n-\n-log4j.logger.org.apache.storm.hdfs = INFO\n-\n+log4j.appender.out.layout.ConversionPattern = %d (%t) [%p - %l] %m%n\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/resources/log4j.properties",
                "sha": "c952abd128f4ccff65eff0682c2f6420cd4621e1",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/resources/log4j2.xml",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/external/storm-hdfs/src/test/resources/log4j2.xml?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 0,
                "filename": "external/storm-hdfs/src/test/resources/log4j2.xml",
                "patch": "@@ -0,0 +1,32 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+<Configuration status=\"WARN\">\n+    <Appenders>\n+        <Console name=\"Console\" target=\"SYSTEM_OUT\">\n+            <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\" charset=\"UTF-8\"/>\n+        </Console>\n+    </Appenders>\n+    <Loggers>\n+        <Root level=\"WARN\">\n+            <AppenderRef ref=\"Console\"/>\n+        </Root>\n+        <Logger name=\"org.apache.storm\" level=\"INFO\" additivity=\"false\">\n+            <AppenderRef ref=\"Console\"/>\n+        </Logger>\n+    </Loggers>\n+</Configuration>\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/external/storm-hdfs/src/test/resources/log4j2.xml",
                "sha": "546b1b380865c6dd04e7006c5dcab07888a8dab9",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/storm/blob/f015130b0e4b33191f9fa84302f46f9a5e10c014/pom.xml",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/storm/contents/pom.xml?ref=f015130b0e4b33191f9fa84302f46f9a5e10c014",
                "deletions": 1,
                "filename": "pom.xml",
                "patch": "@@ -295,7 +295,7 @@\n         <servlet.version>3.1.0</servlet.version>\n         <joda-time.version>2.3</joda-time.version>\n         <thrift.version>0.12.0</thrift.version>\n-        <junit.jupiter.version>5.3.2</junit.jupiter.version>\n+        <junit.jupiter.version>5.5.0-M1</junit.jupiter.version>\n         <surefire.version>2.22.1</surefire.version>\n         <awaitility.version>3.1.0</awaitility.version>\n         <hdrhistogram.version>2.1.10</hdrhistogram.version>",
                "raw_url": "https://github.com/apache/storm/raw/f015130b0e4b33191f9fa84302f46f9a5e10c014/pom.xml",
                "sha": "3b587a7ff62e1c72d2acc15aa4b25e71b50253ce",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #2990 from srdo/STORM-3372\n\nSTORM-3372: Fix NPE when shutting down HdfsBolt, fix storm-hdfs tests not running",
        "parent": "https://github.com/apache/storm/commit/94e5ad1fba57f991257e461b512114f5555f011b",
        "patched_files": [
            "pom.xml",
            "MiniDFSClusterRule.java",
            "log4j.properties",
            "SimpleFileNameFormat.java",
            "BlobStore.java",
            "HdfsBolt.java",
            "MiniDFSClusterExtension.java",
            "HdfsSpout.java",
            "log4j2.xml",
            "AbstractHdfsBolt.java"
        ],
        "repo": "storm",
        "unit_tests": [
            "TestHdfsSemantics.java",
            "BlobStoreTest.java",
            "TestHdfsSpout.java",
            "TestHdfsBolt.java",
            "TestSimpleFileNameFormat.java"
        ]
    }
}