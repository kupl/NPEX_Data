{
    "geode_030f881": {
        "bug_id": "geode_030f881",
        "commit": "https://github.com/apache/geode/commit/030f8815aeedcc9f00d2698f2c655fee6adf3f22",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/EntryEventImpl.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/EntryEventImpl.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/EntryEventImpl.java",
                "patch": "@@ -2929,6 +2929,7 @@ void testHookReleaseInProgress() {\n    * Make sure that this event will never own an off-heap value. Once this is called on an event it\n    * does not need to have release called.\n    */\n+  @Override\n   public void disallowOffHeapValues() {\n     if (isOffHeapReference(this.newValue) || isOffHeapReference(this.oldValue)) {\n       throw new IllegalStateException(\"This event already has off-heap values\");",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/EntryEventImpl.java",
                "sha": "a71dce8eb28d325fc7d73a3c4705f443cb8dd680",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalCacheEvent.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InternalCacheEvent.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InternalCacheEvent.java",
                "patch": "@@ -21,9 +21,9 @@\n \n /**\n  * A CacheEvent, but the isGenerateCallbacks() is hidden from public consumption\n- *\n  */\n public interface InternalCacheEvent extends CacheEvent {\n+\n   /**\n    * Answers true if this event should generate user callbacks.\n    *\n@@ -53,7 +53,6 @@\n \n   /**\n    * Returns the Operation type.\n-   *\n    */\n   EnumListenerEvent getEventType();\n \n@@ -71,8 +70,6 @@\n \n   /**\n    * set the client routing information for this event\n-   *\n-   * @param info TODO\n    */\n   void setLocalFilterInfo(FilterInfo info);\n ",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalCacheEvent.java",
                "sha": "a467d404b88e716889cdda6bb6a6fe3d9b85e5f5",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalEntryEvent.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InternalEntryEvent.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InternalEntryEvent.java",
                "patch": "@@ -28,4 +28,6 @@\n   void setCachedSerializedNewValue(byte[] v);\n \n   byte[] getCachedSerializedNewValue();\n+\n+  void disallowOffHeapValues();\n }",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalEntryEvent.java",
                "sha": "7d56263f09a0f5c255ef504d6803ed659ce9e4bd",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import java.io.IOException;\n import java.io.InputStream;\n+import java.util.Collection;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n@@ -439,4 +440,9 @@ default void unlockWhenRegionIsInitializing() {\n   Set<String> getVisibleAsyncEventQueueIds();\n \n   CachePerfStats getRegionPerfStats();\n+\n+  VersionedObjectList basicRemoveAll(Collection<Object> keys,\n+      DistributedRemoveAllOperation removeAllOp, List<VersionTag> retryVersions);\n+\n+  VersionTag getVersionTag(Object key);\n }",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "sha": "7adec6259e7b9a008a98c514040094ef17f39e48",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "patch": "@@ -773,6 +773,7 @@ public RegionEntry getRegionEntry(Object key) {\n    *\n    * @return the entry version information\n    */\n+  @Override\n   public VersionTag getVersionTag(Object key) {\n     Region.Entry entry = getEntry(key, true);\n     VersionTag tag = null;\n@@ -9101,7 +9102,8 @@ VersionedObjectList basicPutAll(final Map<?, ?> map,\n     return succeeded;\n   }\n \n-  VersionedObjectList basicRemoveAll(final Collection<Object> keys,\n+  @Override\n+  public VersionedObjectList basicRemoveAll(final Collection<Object> keys,\n       final DistributedRemoveAllOperation removeAllOp, final List<VersionTag> retryVersions) {\n \n     final boolean isDebugEnabled = logger.isDebugEnabled();",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "sha": "364cce73dad3d1176fd300b56ce0a1b9c4f5fa17",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/6426bf18b86bc33c2e36a7ba827d506ffcde4c00/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllCSDUnitTest.java",
                "changes": 4589,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllCSDUnitTest.java?ref=6426bf18b86bc33c2e36a7ba827d506ffcde4c00",
                "deletions": 4589,
                "filename": "geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllCSDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/6426bf18b86bc33c2e36a7ba827d506ffcde4c00/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllCSDUnitTest.java",
                "sha": "d8e06b48db2d311ede7b584886df6a4663c27a68",
                "status": "removed"
            },
            {
                "additions": 3377,
                "blob_url": "https://github.com/apache/geode/blob/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllClientServerDistributedTest.java",
                "changes": 3377,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllClientServerDistributedTest.java?ref=030f8815aeedcc9f00d2698f2c655fee6adf3f22",
                "deletions": 0,
                "filename": "geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllClientServerDistributedTest.java",
                "raw_url": "https://github.com/apache/geode/raw/030f8815aeedcc9f00d2698f2c655fee6adf3f22/geode-cq/src/distributedTest/java/org/apache/geode/internal/cache/PutAllClientServerDistributedTest.java",
                "sha": "db1a918af748ffd822bc92b189411267d25b1494",
                "status": "added"
            }
        ],
        "message": "GEODE-6818: Fix PutAllClientServerDistributedTest (#4363)\n\nOverhaul test and fix sources of flakiness (wait/notify and sleeps).\r\n\r\n* Rename PutAllCSDUnitTest\r\n* Replace object wait/notify with CountDownLatch(es)\r\n* Replace sleeps with Awaitility\r\n* Inline super-class and lots of methods\r\n* Remove unused or unnecessary code\r\n* Update deprecated API usage\r\n* Update to AssertJ and Awaitility\r\n* Improve tearDown to prevent NullPointerException\r\n* Add javadocs to testBug51725\r\n* Add await for client2 in testBug51725",
        "parent": "https://github.com/apache/geode/commit/6426bf18b86bc33c2e36a7ba827d506ffcde4c00",
        "patched_files": [
            "InternalEntryEvent.java",
            "EntryEventImpl.java",
            "InternalRegion.java",
            "LocalRegion.java",
            "InternalCacheEvent.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PutAllCSDUnitTest.java",
            "LocalRegionTest.java",
            "PutAllClientServerDistributedTest.java",
            "EntryEventImplTest.java"
        ]
    },
    "geode_03af545": {
        "bug_id": "geode_03af545",
        "commit": "https://github.com/apache/geode/commit/03af54539a49d43ff5a7aa99d306f999c04d2f97",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/03af54539a49d43ff5a7aa99d306f999c04d2f97/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommand.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommand.java?ref=03af54539a49d43ff5a7aa99d306f999c04d2f97",
                "deletions": 4,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommand.java",
                "patch": "@@ -102,9 +102,11 @@ private void fillResultData(RegionMapping mapping, CompositeResultData resultDat\n \n     TabularResultData tabularResultData = sectionResult.addTable(FIELD_TO_COLUMN_TABLE);\n     tabularResultData.setHeader(\"Field to Column Mappings:\");\n-    mapping.getFieldToColumnMap().entrySet().forEach((entry) -> {\n-      tabularResultData.accumulate(\"Field\", entry.getKey());\n-      tabularResultData.accumulate(\"Column\", entry.getValue());\n-    });\n+    if (mapping.getFieldToColumnMap() != null) {\n+      mapping.getFieldToColumnMap().entrySet().forEach((entry) -> {\n+        tabularResultData.accumulate(\"Field\", entry.getKey());\n+        tabularResultData.accumulate(\"Column\", entry.getValue());\n+      });\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/03af54539a49d43ff5a7aa99d306f999c04d2f97/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommand.java",
                "sha": "3076fa4098b5e4fd01ca561434d0b4ac7fc58305",
                "status": "modified"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/geode/blob/03af54539a49d43ff5a7aa99d306f999c04d2f97/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommandIntegrationTest.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommandIntegrationTest.java?ref=03af54539a49d43ff5a7aa99d306f999c04d2f97",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommandIntegrationTest.java",
                "patch": "@@ -110,4 +110,35 @@ public void displaysMappingInformationWhenMappingExists() throws Exception {\n       assertThat(tableContent.get(\"Column\").toString()).contains(entry.getValue());\n     });\n   }\n+\n+  @Test\n+  public void displaysMappingInformationWhenMappingWithNoFieldToColumnsExists() throws Exception {\n+    regionMapping = new RegionMappingBuilder().withRegionName(REGION_NAME)\n+        .withConnectionConfigName(\"connection\").withTableName(\"testTable\")\n+        .withPdxClassName(\"myPdxClass\").withPrimaryKeyInValue(true).withFieldToColumnMappings(null)\n+        .build();\n+    service.createRegionMapping(regionMapping);\n+    Result result = command.describeMapping(REGION_NAME);\n+\n+    assertThat(result.getStatus()).isSameAs(Result.Status.OK);\n+    CommandResult commandResult = (CommandResult) result;\n+    GfJsonObject sectionContent = commandResult.getTableContent()\n+        .getJSONObject(SECTION_DATA_ACCESSOR + \"-\" + RESULT_SECTION_NAME);\n+\n+    assertThat(sectionContent.get(CREATE_MAPPING__REGION_NAME))\n+        .isEqualTo(regionMapping.getRegionName());\n+    assertThat(sectionContent.get(CREATE_MAPPING__CONNECTION_NAME))\n+        .isEqualTo(regionMapping.getConnectionConfigName());\n+    assertThat(sectionContent.get(CREATE_MAPPING__TABLE_NAME))\n+        .isEqualTo(regionMapping.getTableName());\n+    assertThat(sectionContent.get(CREATE_MAPPING__PDX_CLASS_NAME))\n+        .isEqualTo(regionMapping.getPdxClassName());\n+    assertThat(sectionContent.get(CREATE_MAPPING__VALUE_CONTAINS_PRIMARY_KEY))\n+        .isEqualTo(regionMapping.isPrimaryKeyInValue());\n+\n+    GfJsonObject tableContent = sectionContent\n+        .getJSONObject(TABLE_DATA_ACCESSOR + \"-\" + FIELD_TO_COLUMN_TABLE).getJSONObject(\"content\");\n+    assertThat(tableContent.get(\"Field\")).isNull();\n+    assertThat(tableContent.get(\"Column\")).isNull();\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/03af54539a49d43ff5a7aa99d306f999c04d2f97/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeMappingCommandIntegrationTest.java",
                "sha": "3aadfa57124b712c4040d7ff39f02c53c27ae39e",
                "status": "modified"
            }
        ],
        "message": "GEODE-4161: fix gfsh describe jdbc-mapping\n\nIf the jdbc-mapping had no field to column items,\nthen describe jdbc-mapping would fail with an NPE.",
        "parent": "https://github.com/apache/geode/commit/07713e54147d6084f92d0486defe9ef7de1e86b5",
        "patched_files": [
            "DescribeMappingCommand.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "DescribeMappingCommandIntegrationTest.java"
        ]
    },
    "geode_03e214f": {
        "bug_id": "geode_03e214f",
        "commit": "https://github.com/apache/geode/commit/03e214f825cd0b66a7d03d5701a7b90e83e81aa9",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/03e214f825cd0b66a7d03d5701a7b90e83e81aa9/geode-core/src/main/java/org/apache/geode/cache/query/internal/index/CompactRangeIndex.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/query/internal/index/CompactRangeIndex.java?ref=03e214f825cd0b66a7d03d5701a7b90e83e81aa9",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/query/internal/index/CompactRangeIndex.java",
                "patch": "@@ -166,6 +166,9 @@ void removeMapping(RegionEntry entry, int opCode) throws IMQException {\n       // we also know that a regular remove won't work due to the entry no longer being present\n       // We know the old key so let's just remove mapping from the old key\n       if (oldKeyValue != null) {\n+        if (oldKeyValue.get() == null) {\n+          return;\n+        }\n         indexStore.removeMapping(oldKeyValue.get().getOldKey(), entry);\n       } else {\n         // rely on reverse map in the index store to figure out the real key",
                "raw_url": "https://github.com/apache/geode/raw/03e214f825cd0b66a7d03d5701a7b90e83e81aa9/geode-core/src/main/java/org/apache/geode/cache/query/internal/index/CompactRangeIndex.java",
                "sha": "9a83c1ce6adbf5c79546c77b7a00bfbc7dadbf3c",
                "status": "modified"
            },
            {
                "additions": 114,
                "blob_url": "https://github.com/apache/geode/blob/03e214f825cd0b66a7d03d5701a7b90e83e81aa9/geode-core/src/test/java/org/apache/geode/cache/query/internal/index/CompactRangeIndexTest.java",
                "changes": 114,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/internal/index/CompactRangeIndexTest.java?ref=03e214f825cd0b66a7d03d5701a7b90e83e81aa9",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/internal/index/CompactRangeIndexTest.java",
                "patch": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.query.internal.index;\n+\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.quality.Strictness.STRICT_STUBS;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import org.apache.geode.Statistics;\n+import org.apache.geode.cache.RegionAttributes;\n+import org.apache.geode.cache.query.internal.DefaultQueryService;\n+import org.apache.geode.cache.query.internal.index.AbstractIndex.InternalIndexStatistics;\n+import org.apache.geode.cache.query.types.ObjectType;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.cache.CachePerfStats;\n+import org.apache.geode.internal.cache.GemFireCacheImpl;\n+import org.apache.geode.internal.cache.LocalRegion;\n+import org.apache.geode.internal.cache.RegionEntry;\n+\n+public class CompactRangeIndexTest {\n+\n+  @Rule\n+  public MockitoRule mockitoRule = MockitoJUnit.rule().strictness(STRICT_STUBS);\n+\n+  private CompactRangeIndex index;\n+  private LocalRegion region = mock(LocalRegion.class);\n+  private GemFireCacheImpl cache = mock(GemFireCacheImpl.class);\n+  private InternalDistributedSystem ids = mock(InternalDistributedSystem.class);\n+  private Statistics stats = mock(Statistics.class);\n+  private InternalIndexStatistics indstats = mock(InternalIndexStatistics.class);\n+\n+  private RegionEntry entry = mock(RegionEntry.class);\n+  private IndexManager img = mock(IndexManager.class);\n+  private CachePerfStats cacheperfstat = mock(CachePerfStats.class);\n+\n+  private DefaultQueryService queryservice = mock(DefaultQueryService.class);\n+\n+  @Before\n+  public void setup() {\n+    when(region.getCache()).thenReturn(cache);\n+    when(region.getAttributes()).thenReturn(mock(RegionAttributes.class));\n+    when(cache.getDistributedSystem()).thenReturn(ids);\n+    when(ids.createAtomicStatistics(any(), eq(\"Index1\"))).thenReturn(stats);\n+    when(cache.getRegion(any())).thenReturn(region);\n+    when(img.putCanonicalizedIteratorNameIfAbsent(any())).thenReturn(\"index_iter\");\n+\n+    IndexCreationHelper helper = new FunctionalIndexCreationHelper(\"/exampleRegion\", \"status\",\n+        \"*\", null, cache, null, img);\n+\n+    index = new CompactRangeIndex(cache, \"Index1\", region, \"/exampleRegion\",\n+        \"status\", \"*\", null, null,\n+        null, indstats);\n+\n+    index.instantiateEvaluator(helper, mock(ObjectType.class));\n+  }\n+\n+  @Test\n+  public void testAddMapping() throws Exception {\n+    when(region.getCache()).thenReturn(cache);\n+    when(cache.getCachePerfStats()).thenReturn(cacheperfstat);\n+    when(cache.getQueryService()).thenReturn(queryservice);\n+    when(queryservice.getMethodInvocationAuthorizer()).thenReturn(null);\n+\n+    index.addMapping(entry);\n+    verify(indstats).incNumUpdates();\n+\n+  }\n+\n+  @Test\n+  public void testRemoveMapping() throws Exception {\n+    when(region.getCache()).thenReturn(cache);\n+    when(cache.getCachePerfStats()).thenReturn(cacheperfstat);\n+    when(cache.getQueryService()).thenReturn(queryservice);\n+    when(queryservice.getMethodInvocationAuthorizer()).thenReturn(null);\n+\n+    index.removeMapping(entry, 3);\n+\n+  }\n+\n+  @Test\n+  public void testRemoveUpdateRemoveMapping() throws Exception {\n+    when(region.getCache()).thenReturn(cache);\n+    when(cache.getCachePerfStats()).thenReturn(cacheperfstat);\n+    when(cache.getQueryService()).thenReturn(queryservice);\n+    when(queryservice.getMethodInvocationAuthorizer()).thenReturn(null);\n+\n+    index.removeMapping(entry, 1);\n+    index.addMapping(entry);\n+    verify(indstats).incNumUpdates();\n+    index.removeMapping(entry, 3);\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/03e214f825cd0b66a7d03d5701a7b90e83e81aa9/geode-core/src/test/java/org/apache/geode/cache/query/internal/index/CompactRangeIndexTest.java",
                "sha": "1dacbcdf46a5337c52081a4af7dc6c4a59095de1",
                "status": "added"
            }
        ],
        "message": "GEODE-6998: Fix for NPE at index update due to GII (#3834)\n\n  * No-op index update during gii when a tombstone is received and the current value in the region is not present or also a tombstone",
        "parent": "https://github.com/apache/geode/commit/671ba75cefeda953e393a43c86094704c9c8f79c",
        "patched_files": [
            "CompactRangeIndex.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "CompactRangeIndexTest.java"
        ]
    },
    "geode_0afb75b": {
        "bug_id": "geode_0afb75b",
        "commit": "https://github.com/apache/geode/commit/0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/InternalDistributedMember.java",
                "changes": 42,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/InternalDistributedMember.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 41,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/InternalDistributedMember.java",
                "patch": "@@ -153,7 +153,6 @@ public InternalDistributedMember(NetMember m) {\n \n     this.hostName = SocketCreator.resolve_dns ? SocketCreator.getHostName(m.getInetAddress())\n         : m.getInetAddress().getHostAddress();\n-    // checkHostName();\n \n     short version = m.getVersionOrdinal();\n     try {\n@@ -176,15 +175,6 @@ public void setNetMember(NetMember m) {\n     this.netMbr = m;\n   }\n \n-  // private void checkHostName() {\n-  // // bug #44858: debug method to find who is putting a host name instead of addr into an ID\n-  // if (!SocketCreator.resolve_dns\n-  // && this.hostName != null && this.hostName.length() > 0\n-  // && !Character.isDigit(this.hostName.charAt(0))) {\n-  // throw new RuntimeException(\"found hostname that doesn't start with a digit: \" + this.hostName);\n-  // }\n-  // }\n-\n   /**\n    * Create a InternalDistributedMember referring to the current host (as defined by the given\n    * string).\n@@ -466,14 +456,6 @@ public String getName() {\n     return result;\n   }\n \n-  /**\n-   * Returns this member's unique tag (such as randomly generated bytes) or null if no unique tag\n-   * was created.\n-   */\n-  public String getUniqueTag() {\n-    return this.uniqueTag;\n-  }\n-\n   /**\n    * Returns this client member's durable attributes or null if no durable attributes were created.\n    */\n@@ -743,11 +725,6 @@ public void addFixedToString(StringBuilder sb) {\n     sb.append(\":\");\n     sb.append(getPort());\n \n-    // if (dcPort > 0 && vmKind != DistributionManager.LONER_DM_TYPE) {\n-    // sb.append(\"/\");\n-    // sb.append(Integer.toString(dcPort));\n-    // }\n-\n     if (vmKind == ClusterDistributionManager.LONER_DM_TYPE) {\n       // add some more info that was added in 4.2.1 for loner bridge clients\n       // impact on non-bridge loners is ok\n@@ -1168,11 +1145,6 @@ public void setPort(int p) {\n     cachedToString = null;\n   }\n \n-  /** drop the cached toString rep of this ID */\n-  public void dropCachedString() {\n-    this.cachedToString = null;\n-  }\n-\n   public String getHost() {\n     return this.netMbr.getInetAddress().getCanonicalHostName();\n   }\n@@ -1184,18 +1156,6 @@ public int getProcessId() {\n   public String getId() {\n     return toString();\n   }\n-  /*\n-   * if (this.ipAddr == null) { return \"<null>\"; } else { StringBuffer sb = new StringBuffer();\n-   * InetAddress addr = this.ipAddr.getIpAddress(); if(addr.isMulticastAddress()) {\n-   * sb.append(addr.getHostAddress()); } else { appendShortName(addr.getHostName(), sb); } if\n-   * (this.vmPid != 0) { sb.append(\"(\"); sb.append(this.vmPid); sb.append(\")\"); } sb.append(\":\");\n-   * sb.append(this.ipAddr.getPort()); return sb.toString(); } }\n-   *\n-   * // Helper method for getId()... copied from IpAddress. private void appendShortName(String\n-   * hostname, StringBuffer sb) { if (hostname == null) return; int index = hostname.indexOf('.');\n-   * if(index > 0 && !Character.isDigit(hostname.charAt(0))) { sb.append(hostname.substring(0,\n-   * index)); } else { sb.append(hostname); } }\n-   */\n \n   public void setVersionObjectForTest(Version v) {\n     this.versionObj = v;\n@@ -1236,7 +1196,7 @@ public boolean equals(Object obj) {\n \n     @Override\n     public String toString() {\n-      return \"InternalDistrubtedMemberWrapper [mbr=\" + mbr + \"]\";\n+      return \"InternalDistributedMemberWrapper [mbr=\" + mbr + \"]\";\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/InternalDistributedMember.java",
                "sha": "ebe1e605aab4c409012ea46e059509a3d4fc62d7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "patch": "@@ -76,7 +76,7 @@\n   private InternalDistributedMember localAddress;\n \n   private final Set<InternalDistributedMember> registrants = new HashSet<>();\n-  public Map<InternalDistributedMemberWrapper, byte[]> registerMbrVsPK = new ConcurrentHashMap<>();\n+  private Map<InternalDistributedMemberWrapper, byte[]> registerMbrVsPK = new ConcurrentHashMap<>();\n \n   /**\n    * The current membership view, or one recovered from disk. This is a copy-on-write variable.",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "sha": "70d53083a184167098c5b28638a2144ec612a6ab",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 10,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "patch": "@@ -38,6 +38,7 @@\n import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Properties;\n import java.util.Set;\n import java.util.TimerTask;\n@@ -809,7 +810,7 @@ private void becomeCoordinator(InternalDistributedMember oldCoordinator) {\n       startViewBroadcaster();\n     } else {\n       // create and send out a new view\n-      NetView newView = addMemberToNetView(oldCoordinator);\n+      NetView newView = copyCurrentViewAndAddMyAddress(oldCoordinator);\n       createAndStartViewCreator(newView);\n       startViewBroadcaster();\n     }\n@@ -829,7 +830,7 @@ private void createAndStartViewCreator(NetView newView) {\n     }\n   }\n \n-  private NetView addMemberToNetView(InternalDistributedMember oldCoordinator) {\n+  private NetView copyCurrentViewAndAddMyAddress(InternalDistributedMember oldCoordinator) {\n     boolean testing = unitTesting.contains(\"noRandomViewChange\");\n     NetView newView;\n     Set<InternalDistributedMember> leaving = new HashSet<>();\n@@ -857,6 +858,7 @@ private NetView addMemberToNetView(InternalDistributedMember oldCoordinator) {\n       mbrs.removeAll(leaving);\n       newView = new NetView(this.localAddress, viewNumber, mbrs, leaving, removals);\n       newView.setFailureDetectionPorts(currentView);\n+      newView.setPublicKeys(currentView);\n       newView.setFailureDetectionPort(this.localAddress,\n           services.getHealthMonitor().getFailureDetectionPort());\n     }\n@@ -947,7 +949,7 @@ private boolean sendView(NetView view, boolean preparing, ViewReplyProcessor vie\n     viewReplyProcessor.initialize(id, responders);\n     viewReplyProcessor.processPendingRequests(pendingLeaves, pendingRemovals);\n     addPublicKeysToView(view);\n-    services.getMessenger().send(msg);\n+    services.getMessenger().send(msg, view);\n \n     // only wait for responses during preparation\n     if (preparing) {\n@@ -978,13 +980,11 @@ private boolean sendView(NetView view, boolean preparing, ViewReplyProcessor vie\n   private void addPublicKeysToView(NetView view) {\n     String sDHAlgo = services.getConfig().getDistributionConfig().getSecurityUDPDHAlgo();\n     if (sDHAlgo != null && !sDHAlgo.isEmpty()) {\n-      List<InternalDistributedMember> mbrs = view.getMembers();\n-      Iterator<InternalDistributedMember> itr = mbrs.iterator();\n-\n-      while (itr.hasNext()) {\n-        InternalDistributedMember mbr = itr.next();\n-        byte[] pk = services.getMessenger().getPublicKey(mbr);\n-        view.setPublicKey(mbr, pk);\n+      for (InternalDistributedMember mbr : view.getMembers()) {\n+        if (Objects.isNull(view.getPublicKey(mbr))) {\n+          byte[] pk = services.getMessenger().getPublicKey(mbr);\n+          view.setPublicKey(mbr, pk);\n+        }\n       }\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "sha": "8ff7596a2ac138bd70101a1cc8637b3eb4dd6821",
                "status": "modified"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncrypt.java",
                "changes": 81,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncrypt.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 50,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncrypt.java",
                "patch": "@@ -22,8 +22,7 @@\n import java.security.PublicKey;\n import java.security.spec.PKCS8EncodedKeySpec;\n import java.security.spec.X509EncodedKeySpec;\n-import java.util.Iterator;\n-import java.util.List;\n+import java.util.Arrays;\n import java.util.Map;\n import java.util.concurrent.ConcurrentHashMap;\n \n@@ -40,11 +39,7 @@\n import org.apache.geode.distributed.internal.membership.NetView;\n import org.apache.geode.distributed.internal.membership.gms.Services;\n \n-public class GMSEncrypt implements Cloneable {\n-\n-  public static long encodingsPerformed;\n-  public static long decodingsPerformed;\n-\n+public final class GMSEncrypt implements Cloneable {\n   // Parameters for the Diffie-Hellman key exchange\n   private static final BigInteger dhP =\n       new BigInteger(\"13528702063991073999718992897071702177131142188276542919088770094024269\"\n@@ -74,9 +69,8 @@\n \n   private NetView view;\n \n-  public static final int numberOfPeerEncryptorCopies =\n-      Integer.getInteger(\"GMSEncrypt.MAX_ENCRYPTORS\",\n-          Math.max(Runtime.getRuntime().availableProcessors() * 4, 16)).intValue();\n+  private static final int numberOfPeerEncryptorCopies = Integer.getInteger(\n+      \"GMSEncrypt.MAX_ENCRYPTORS\", Math.max(Runtime.getRuntime().availableProcessors() * 4, 16));\n   /**\n    * Keeps multiple copies for peer\n    */\n@@ -117,28 +111,28 @@ protected synchronized void addClusterKey(byte[] secretBytes) {\n     this.clusterEncryptor = new ClusterEncryptor(secretBytes);\n   }\n \n-  protected GMSEncrypt() {\n+  private GMSEncrypt() {\n     initEncryptors();\n   }\n \n   private byte[] getRegisteredPublicKey(InternalDistributedMember mbr) {\n     return services.getPublicKey(mbr);\n   }\n \n-  public GMSEncrypt(Services services) throws Exception {\n+  GMSEncrypt(Services services) throws Exception {\n     this.services = services;\n     initEncryptors();\n     initDHKeys(services.getConfig().getDistributionConfig());\n   }\n \n-  public GMSEncrypt(Services services, InternalDistributedMember mbr) throws Exception {\n+  GMSEncrypt(Services services, InternalDistributedMember mbr) throws Exception {\n     this.services = services;\n     this.localMember = mbr;\n     initEncryptors();\n     initDHKeys(services.getConfig().getDistributionConfig());\n   }\n \n-  void initEncryptors() {\n+  private void initEncryptors() {\n     copyOfPeerEncryptors = new ConcurrentHashMap[numberOfPeerEncryptorCopies];\n     copyOfClusterEncryptors = new ClusterEncryptor[numberOfPeerEncryptorCopies];\n   }\n@@ -183,7 +177,6 @@ void initEncryptors() {\n \n   protected void setPublicKey(byte[] publickey, InternalDistributedMember mbr) {\n     try {\n-      // createPeerEncryptor(mbr, publickey);\n       memberToPeerEncryptor.put(new InternalDistributedMemberWrapper(mbr), publickey);\n       synchronized (copyOfPeerEncryptors) {\n         // remove all the existing keys..\n@@ -198,7 +191,7 @@ protected void setPublicKey(byte[] publickey, InternalDistributedMember mbr) {\n   }\n \n   @Override\n-  protected GMSEncrypt clone() throws CloneNotSupportedException {\n+  protected GMSEncrypt clone() {\n     try {\n       GMSEncrypt gmsEncrypt = new GMSEncrypt();\n       gmsEncrypt.localMember = this.localMember;\n@@ -214,7 +207,6 @@ protected GMSEncrypt clone() throws CloneNotSupportedException {\n       PKCS8EncodedKeySpec x509KeySpecPKey = new PKCS8EncodedKeySpec(this.dhPrivateKey.getEncoded());\n \n       keyFact = KeyFactory.getInstance(\"DH\");\n-      // PublicKey pubKey = keyFact.generatePublic(x509KeySpec);\n       gmsEncrypt.dhPrivateKey = keyFact.generatePrivate(x509KeySpecPKey);\n \n       return gmsEncrypt;\n@@ -244,16 +236,15 @@ private void initDHKeys(DistributionConfig config) throws Exception {\n     }\n   }\n \n-  protected PeerEncryptor getPeerEncryptor(InternalDistributedMember member) throws Exception {\n+  private PeerEncryptor getPeerEncryptor(InternalDistributedMember member) throws Exception {\n     Map<InternalDistributedMember, PeerEncryptor> m = getPeerEncryptorMap();\n \n     PeerEncryptor result = m.get(member);\n     if (result == null) {\n       synchronized (this) {\n         result = m.get(member);\n         if (result == null) {\n-          byte[] pk =\n-              (byte[]) memberToPeerEncryptor.get(new InternalDistributedMemberWrapper(member));\n+          byte[] pk = memberToPeerEncryptor.get(new InternalDistributedMemberWrapper(member));\n           if (pk == null) {\n             pk = getRegisteredPublicKey(member);\n           }\n@@ -274,7 +265,7 @@ protected PeerEncryptor getPeerEncryptor(InternalDistributedMember member) throw\n       synchronized (copyOfPeerEncryptors) {\n         m = copyOfPeerEncryptors[h];\n         if (m == null) {\n-          m = new ConcurrentHashMap<InternalDistributedMember, PeerEncryptor>();\n+          m = new ConcurrentHashMap<>();\n           copyOfPeerEncryptors[h] = m;\n         }\n       }\n@@ -351,31 +342,30 @@ private static int getBlockSize(String skAlgo) {\n     return blocksize;\n   }\n \n-  public static byte[] encryptBytes(byte[] data, Cipher encrypt) throws Exception {\n+  private static byte[] encryptBytes(byte[] data, Cipher encrypt) throws Exception {\n     return encrypt.doFinal(data);\n   }\n \n-  public static byte[] decryptBytes(byte[] data, Cipher decrypt) throws Exception {\n+  private static byte[] decryptBytes(byte[] data, Cipher decrypt) throws Exception {\n     return decrypt.doFinal(data);\n   }\n \n+  private class PeerEncryptor {\n \n-  protected class PeerEncryptor {\n-\n-    private PublicKey peerPublicKey = null;\n+    private PublicKey peerPublicKey;\n \n     private String peerSKAlgo = null;\n \n     private Cipher encrypt;\n \n     private Cipher decrypt = null;\n \n-    protected PeerEncryptor(byte[] peerPublicKeyBytes) throws Exception {\n+    private PeerEncryptor(byte[] peerPublicKeyBytes) throws Exception {\n       this.peerPublicKey = getPublicKey(peerPublicKeyBytes);\n     }\n \n-    public synchronized byte[] encryptBytes(byte[] data) throws Exception {\n-      String algo = null;\n+    private synchronized byte[] encryptBytes(byte[] data) throws Exception {\n+      String algo;\n       if (this.peerSKAlgo != null) {\n         algo = this.peerSKAlgo;\n       } else {\n@@ -413,7 +403,7 @@ private Cipher getDecryptCipher(String dhSKAlgo, PublicKey publicKey) throws Exc\n   }\n \n   // this needs to synchronize as it uses private key of that member\n-  protected static synchronized Cipher getEncryptCipher(String dhSKAlgo, PrivateKey privateKey,\n+  private static synchronized Cipher getEncryptCipher(String dhSKAlgo, PrivateKey privateKey,\n       PublicKey peerPublicKey) throws Exception {\n     KeyAgreement ka = KeyAgreement.getInstance(\"DH\");\n     ka.init(privateKey);\n@@ -442,7 +432,7 @@ protected static synchronized Cipher getEncryptCipher(String dhSKAlgo, PrivateKe\n     return encrypt;\n   }\n \n-  protected static Cipher getEncryptCipher(String dhSKAlgo, byte[] secretBytes) throws Exception {\n+  private static Cipher getEncryptCipher(String dhSKAlgo, byte[] secretBytes) throws Exception {\n \n     Cipher encrypt = null;\n \n@@ -467,7 +457,7 @@ protected static Cipher getEncryptCipher(String dhSKAlgo, byte[] secretBytes) th\n   }\n \n   // this needs to synchronize as it uses private key of that member\n-  protected static synchronized Cipher getDecryptCipher(String dhSKAlgo, PrivateKey privateKey,\n+  private static synchronized Cipher getDecryptCipher(String dhSKAlgo, PrivateKey privateKey,\n       PublicKey publicKey) throws Exception {\n     KeyAgreement ka = KeyAgreement.getInstance(\"DH\");\n     ka.init(privateKey);\n@@ -495,8 +485,8 @@ protected static synchronized Cipher getDecryptCipher(String dhSKAlgo, PrivateKe\n     return decrypt;\n   }\n \n-  protected static Cipher getDecryptCipher(String dhSKAlgo, byte[] secretBytes) throws Exception {\n-    Cipher decrypt = null;\n+  private static Cipher getDecryptCipher(String dhSKAlgo, byte[] secretBytes) throws Exception {\n+    Cipher decrypt;\n \n     int keysize = getKeySize(dhSKAlgo);\n     int blocksize = getBlockSize(dhSKAlgo);\n@@ -517,7 +507,7 @@ protected static Cipher getDecryptCipher(String dhSKAlgo, byte[] secretBytes) th\n     return decrypt;\n   }\n \n-  protected static byte[] generateSecret(String dhSKAlgo, PrivateKey privateKey,\n+  private static byte[] generateSecret(String dhSKAlgo, PrivateKey privateKey,\n       PublicKey otherPublicKey) throws Exception {\n     KeyAgreement ka = KeyAgreement.getInstance(\"DH\");\n     ka.init(privateKey);\n@@ -534,40 +524,31 @@ protected static Cipher getDecryptCipher(String dhSKAlgo, byte[] secretBytes) th\n     }\n   }\n \n-  protected static PublicKey getPublicKey(byte[] publicKeyBytes) throws Exception {\n+  private static PublicKey getPublicKey(byte[] publicKeyBytes) throws Exception {\n     X509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(publicKeyBytes);\n     KeyFactory keyFact = KeyFactory.getInstance(\"DH\");\n-    // PublicKey pubKey = keyFact.generatePublic(x509KeySpec);\n     return keyFact.generatePublic(x509KeySpec);\n   }\n \n-  protected static void initEncryptCipher(KeyAgreement ka, List<PublicKey> publicKeys)\n-      throws Exception {\n-    Iterator<PublicKey> itr = publicKeys.iterator();\n-    while (itr.hasNext()) {\n-      ka.doPhase(itr.next(), !itr.hasNext());\n-    }\n-  }\n-\n   /***\n    * this will hold the common key for cluster\n    */\n-  protected class ClusterEncryptor {\n+  private class ClusterEncryptor {\n     byte[] secretBytes;\n     Cipher encrypt;\n     Cipher decrypt;\n \n-    public ClusterEncryptor(GMSEncrypt other) throws Exception {\n+    private ClusterEncryptor(GMSEncrypt other) throws Exception {\n       GMSEncrypt mine = new GMSEncrypt(other.services);\n       this.secretBytes =\n           GMSEncrypt.generateSecret(mine.dhSKAlgo, mine.dhPrivateKey, other.dhPublicKey);\n     }\n \n-    public ClusterEncryptor(byte[] sb) {\n+    private ClusterEncryptor(byte[] sb) {\n       this.secretBytes = sb;\n     }\n \n-    public synchronized byte[] encryptBytes(byte[] data) throws Exception {\n+    private synchronized byte[] encryptBytes(byte[] data) throws Exception {\n       String algo = dhSKAlgo;\n       return GMSEncrypt.encryptBytes(data, getEncryptCipher(algo));\n     }\n@@ -583,7 +564,7 @@ private Cipher getEncryptCipher(String dhSKAlgo) throws Exception {\n       return encrypt;\n     }\n \n-    public synchronized byte[] decryptBytes(byte[] data) throws Exception {\n+    private synchronized byte[] decryptBytes(byte[] data) throws Exception {\n       String algo = dhSKAlgo;\n       Cipher c = getDecryptCipher(algo);\n       return GMSEncrypt.decryptBytes(data, c);",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncrypt.java",
                "sha": "76fb1de5d921af1e5cc46d2487c057441a91aef0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 5,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "patch": "@@ -120,11 +120,6 @@ public LocatorDUnitTest() {\n     super();\n   }\n \n-  private static final String WAIT2_MS_NAME = \"LocatorDUnitTest.WAIT2_MS\";\n-  private static final int WAIT2_MS_DEFAULT = 5000; // 2000 -- see bug 36470\n-  private static final int WAIT2_MS =\n-      Integer.getInteger(WAIT2_MS_NAME, WAIT2_MS_DEFAULT).intValue();\n-\n   protected int port1;\n   private int port2;\n ",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "sha": "914fece1a34f373c8e247741a5423b39a290ed86",
                "status": "modified"
            },
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "changes": 67,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 10,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "patch": "@@ -31,7 +31,6 @@\n \n import java.io.IOException;\n import java.net.InetSocketAddress;\n-import java.net.UnknownHostException;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n@@ -102,19 +101,17 @@\n   private InternalDistributedMember removeMember = null;\n   private InternalDistributedMember leaveMember = null;\n \n-  public void initMocks() throws IOException {\n+  public void initMocks() {\n     initMocks(false);\n   }\n \n-  public void initMocks(boolean enableNetworkPartition) throws UnknownHostException {\n+  public void initMocks(boolean enableNetworkPartition) {\n     initMocks(enableNetworkPartition, false);\n   }\n \n-  public void initMocks(boolean enableNetworkPartition, boolean useTestGMSJoinLeave)\n-      throws UnknownHostException {\n+  public void initMocks(boolean enableNetworkPartition, boolean useTestGMSJoinLeave) {\n     mockDistConfig = mock(DistributionConfig.class);\n     when(mockDistConfig.getEnableNetworkPartitionDetection()).thenReturn(enableNetworkPartition);\n-    when(mockDistConfig.getLocators()).thenReturn(\"localhost[8888]\");\n     when(mockDistConfig.getSecurityUDPDHAlgo()).thenReturn(\"\");\n     mockConfig = mock(ServiceConfig.class);\n     when(mockDistConfig.getStartLocator()).thenReturn(\"localhost[12345]\");\n@@ -290,7 +287,7 @@ public void testProcessJoinMessageWithAuthenticationButNullCredentials() throws\n     verify(messenger).send(isA(JoinResponseMessage.class));\n   }\n \n-  // This test does not test the actual join process but rather that the join response gets logged\u00df\n+  // This test does not test the actual join process but rather that the join response gets logged\n   @Test\n   public void testProcessJoinResponseIsRecorded() throws IOException {\n     initMocks();\n@@ -332,6 +329,9 @@ private void prepareAndInstallView(InternalDistributedMember coordinator,\n \n     // prepare the view\n     NetView netView = new NetView(coordinator, viewId, members);\n+    for (InternalDistributedMember member : netView.getMembers()) {\n+      netView.setPublicKey(member, member.toString());\n+    }\n     InstallViewMessage installViewMessage = getInstallViewMessage(netView, credentials, true);\n     gmsJoinLeave.processMessage(installViewMessage);\n     verify(messenger).send(isA(ViewAckMessage.class));\n@@ -1204,6 +1204,53 @@ public void testPreparedViewFoundDuringBecomeCoordinator() throws Exception {\n     assertTrue(newView.getViewId() > preparedView.getViewId());\n   }\n \n+  @Test\n+  public void testPublicKeyForNewMemberFromPreparedViewIsInstalledInNewView() throws Exception {\n+    initMocks(false);\n+    InternalDistributedMember newMember = mockMembers[1];\n+\n+    prepareAndInstallView(gmsJoinLeaveMemberId,\n+        createMemberList(gmsJoinLeaveMemberId, mockMembers[0]));\n+    // a new member is joining\n+    NetView preparedView =\n+        new NetView(gmsJoinLeave.getView(), gmsJoinLeave.getView().getViewId() + 5);\n+    for (InternalDistributedMember member : preparedView.getMembers()) {\n+      preparedView.setPublicKey(member, member.toString());\n+    }\n+    newMember.setVmViewId(preparedView.getViewId());\n+    preparedView.add(newMember);\n+    preparedView.setPublicKey(newMember, newMember.toString());\n+\n+    InstallViewMessage msg = getInstallViewMessage(preparedView, null, true);\n+    gmsJoinLeave.processMessage(msg);\n+\n+    GMSJoinLeaveTestHelper.becomeCoordinatorForTest(gmsJoinLeave);\n+\n+    Thread.sleep(2000);\n+    ViewCreator vc = gmsJoinLeave.getViewCreator();\n+    int viewId = 0;\n+    if (gmsJoinLeave.getPreparedView() == null) {\n+      viewId = gmsJoinLeave.getView().getViewId();\n+    } else {\n+      viewId = gmsJoinLeave.getPreparedView().getViewId();\n+    }\n+    ViewAckMessage vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n+    vack.setSender(mockMembers[0]);\n+    gmsJoinLeave.processMessage(vack);\n+    vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n+    vack.setSender(newMember);\n+    gmsJoinLeave.processMessage(vack);\n+    vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n+    vack.setSender(gmsJoinLeaveMemberId);\n+    gmsJoinLeave.processMessage(vack);\n+\n+    Awaitility.await(\"view creator finishes\").atMost(30, SECONDS).until(() -> vc.waiting);\n+    NetView newView = gmsJoinLeave.getView();\n+    System.out.println(\"new view is \" + newView);\n+    assertTrue(newView.contains(newMember));\n+    assertNotNull(newView.getPublicKey(newMember));\n+  }\n+\n   private NetView createView() {\n     List<InternalDistributedMember> mbrs = new LinkedList<>();\n     Set<InternalDistributedMember> shutdowns = new HashSet<>();\n@@ -1280,7 +1327,7 @@ private void waitForViewAndFinalCheckInProgress(int viewId) throws InterruptedEx\n   }\n \n   class GMSJoinLeaveTest extends GMSJoinLeave {\n-    public GMSJoinLeaveTest() {\n+    GMSJoinLeaveTest() {\n       super();\n     }\n \n@@ -1292,7 +1339,7 @@ boolean checkIfAvailable(InternalDistributedMember fmbr) {\n             GMSJoinLeaveJUnitTest.this.processRemoveMessage(fmbr);\n             Thread.sleep(1000000);\n           }\n-        } catch (InterruptedException e) {\n+        } catch (InterruptedException ignore) {\n         }\n         return true;\n       } else if (leaveMember != null) {\n@@ -1301,7 +1348,7 @@ boolean checkIfAvailable(InternalDistributedMember fmbr) {\n             GMSJoinLeaveJUnitTest.this.processLeaveMessage(fmbr);\n             Thread.sleep(1000000);\n           }\n-        } catch (InterruptedException e) {\n+        } catch (InterruptedException ignore) {\n         }\n         return true;\n       } else {",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "sha": "0443b32ee9fac98c29f1fada44068f25d1c285de",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveTestHelper.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveTestHelper.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 11,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveTestHelper.java",
                "patch": "@@ -14,6 +14,8 @@\n  */\n package org.apache.geode.distributed.internal.membership.gms.membership;\n \n+import static org.junit.Assert.assertNotNull;\n+\n import org.apache.geode.distributed.Locator;\n import org.apache.geode.distributed.internal.DistributionManager;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n@@ -33,17 +35,8 @@ public static void becomeCoordinatorForTest(GMSJoinLeave gmsJoinLeave) {\n \n   public static boolean isViewCreator() {\n     GMSJoinLeave gmsJoinLeave = getGmsJoinLeave();\n-    if (gmsJoinLeave != null) {\n-      return gmsJoinLeave.getView().getCreator().equals(gmsJoinLeave.getMemberID());\n-      // GMSJoinLeave.ViewCreator viewCreator = gmsJoinLeave.getViewCreator();\n-      // if (viewCreator != null && !viewCreator.isShutdown()) {\n-      // return true;\n-      // } else {\n-      // return false;\n-      // }\n-    }\n-    throw new RuntimeException(\n-        \"This should not have happened. There should be a JoinLeave for every DS\");\n+    assertNotNull(\"There should be a JoinLeave for every DS\", gmsJoinLeave);\n+    return gmsJoinLeave.getView().getCreator().equals(gmsJoinLeave.getMemberID());\n   }\n \n   private static void waitCriterion() {",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveTestHelper.java",
                "sha": "7b1693edc4e04e138dd2567a764088444c26f2d8",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncryptJUnitTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncryptJUnitTest.java?ref=0afb75bbaef7dfba7bfba70d8de0617c30db99c2",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncryptJUnitTest.java",
                "patch": "@@ -343,7 +343,6 @@ public void run() {\n           try {\n             int count = 0;\n             for (int i = 0; i < runs; i++) {\n-              // System.out.println(\"run \" + i + \" threadid \" + Thread.currentThread().getId());\n               String ch = \"Hello world\";\n               byte[] challenge = ch.getBytes();\n               byte[] encryptedChallenge = sender.encryptData(challenge);",
                "raw_url": "https://github.com/apache/geode/raw/0afb75bbaef7dfba7bfba70d8de0617c30db99c2/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSEncryptJUnitTest.java",
                "sha": "4b1a929378a40e0880cbc0adb25d00d08f427e97",
                "status": "modified"
            }
        ],
        "message": "GEODE-4362: view preparation throws uncaught RuntimeException\n\nThe problem was happening when a new member joined with a coordinator that\nsuddenly shuts down before other members have been told to install the\nnew membership view.  They've received a \"prepare for view change\" message\ncontaining the new view but have not been told to commit that change.\n\nAnother member then becomes coordinator and sees that there was a new member\nin the prepared view.  It picks this up and adds it to the new view it\nsends out.\n\nThe problem was that the public encryption keys of the members weren't\nbeing transferred from the old view to the new view and when looking for\npublic keys we were fishing them out of GMSEncrypt instead of getting\nthem from the membership view.  This caused an NPE to be thrown when trying\nto fish out the public key of the new member - GMSEncrypt didn't know about\nthis new member because the view containing it was never installed - it\nwas only prepared.\n\nThe fix is to transfer the public keys from the old view to the new one and\nto look for public keys in the view instead of GMSEncrypt.\n\nThis closes #1520",
        "parent": "https://github.com/apache/geode/commit/4ad633773b1fffe9ce5a71ea95fc5410d54d90fc",
        "patched_files": [
            "GMSJoinLeave.java",
            "InternalDistributedMember.java",
            "GMSLocator.java",
            "GMSEncrypt.java",
            "GMSJoinLeaveTestHelper.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "LocatorDUnitTest.java",
            "GMSJoinLeaveJUnitTest.java",
            "GMSEncryptJUnitTest.java"
        ]
    },
    "geode_0ccf9fa": {
        "bug_id": "geode_0ccf9fa",
        "commit": "https://github.com/apache/geode/commit/0ccf9fab8c7ccf109b91f17272c9e29f0854545e",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/internal/cache/execute/FunctionContextImpl.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/execute/FunctionContextImpl.java?ref=0ccf9fab8c7ccf109b91f17272c9e29f0854545e",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/execute/FunctionContextImpl.java",
                "patch": "@@ -15,6 +15,7 @@\n package org.apache.geode.internal.cache.execute;\n \n import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.execute.Execution;\n import org.apache.geode.cache.execute.Function;\n import org.apache.geode.cache.execute.FunctionContext;\n@@ -99,7 +100,10 @@ public boolean isPossibleDuplicate() {\n   }\n \n   @Override\n-  public Cache getCache() {\n+  public Cache getCache() throws CacheClosedException {\n+    if (cache == null) {\n+      throw new CacheClosedException(\"FunctionContext does not have a valid Cache\");\n+    }\n     return cache;\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/internal/cache/execute/FunctionContextImpl.java",
                "sha": "985f12e8b38de13b466772b155a15fdc3062ffa3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionDescriptionFunction.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionDescriptionFunction.java?ref=0ccf9fab8c7ccf109b91f17272c9e29f0854545e",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionDescriptionFunction.java",
                "patch": "@@ -43,8 +43,6 @@ public void execute(FunctionContext context) {\n       } else {\n         context.getResultSender().lastResult(null);\n       }\n-    } catch (CacheClosedException e) {\n-      context.getResultSender().sendException(e);\n     } catch (Exception e) {\n       context.getResultSender().sendException(e);\n     }",
                "raw_url": "https://github.com/apache/geode/raw/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionDescriptionFunction.java",
                "sha": "afaeac507cbaf1a67b9674ff148fee408f7a6675",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/geode/blob/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunction.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunction.java?ref=0ccf9fab8c7ccf109b91f17272c9e29f0854545e",
                "deletions": 15,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunction.java",
                "patch": "@@ -23,7 +23,6 @@\n import org.apache.geode.cache.execute.FunctionContext;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.InternalEntity;\n-import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.InternalCache;\n import org.apache.geode.internal.cache.PartitionedRegion;\n import org.apache.geode.internal.cache.partitioned.ColocatedRegionDetails;\n@@ -65,23 +64,23 @@ public void execute(FunctionContext context) {\n           }\n         }\n       }\n+    } catch (Exception e) {\n+      context.getResultSender().sendException(e);\n+    }\n \n-      if (memberMissingIDs.isEmpty() && missingColocatedRegions.isEmpty()) {\n-        context.getResultSender().lastResult(null);\n-      } else {\n-        if (!memberMissingIDs.isEmpty()) {\n-          if (missingColocatedRegions.isEmpty()) {\n-            context.getResultSender().lastResult(memberMissingIDs);\n-          } else {\n-            context.getResultSender().sendResult(memberMissingIDs);\n-          }\n-        }\n-        if (!missingColocatedRegions.isEmpty()) {\n-          context.getResultSender().lastResult(missingColocatedRegions);\n+    if (memberMissingIDs.isEmpty() && missingColocatedRegions.isEmpty()) {\n+      context.getResultSender().lastResult(null);\n+    } else {\n+      if (!memberMissingIDs.isEmpty()) {\n+        if (missingColocatedRegions.isEmpty()) {\n+          context.getResultSender().lastResult(memberMissingIDs);\n+        } else {\n+          context.getResultSender().sendResult(memberMissingIDs);\n         }\n       }\n-    } catch (Exception e) {\n-      context.getResultSender().sendException(e);\n+      if (!missingColocatedRegions.isEmpty()) {\n+        context.getResultSender().lastResult(missingColocatedRegions);\n+      }\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunction.java",
                "sha": "656c0fd1c390480269552b3adbc54fd8d9bbce51",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunctionJUnitTest.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunctionJUnitTest.java?ref=0ccf9fab8c7ccf109b91f17272c9e29f0854545e",
                "deletions": 24,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunctionJUnitTest.java",
                "patch": "@@ -19,7 +19,6 @@\n import static org.mockito.Mockito.when;\n \n import java.net.InetAddress;\n-import java.net.UnknownHostException;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n@@ -30,7 +29,7 @@\n import java.util.Map;\n import java.util.Set;\n \n-import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.cache.CacheClosedException;\n import org.apache.logging.log4j.core.Appender;\n import org.apache.logging.log4j.core.LogEvent;\n import org.apache.logging.log4j.core.Logger;\n@@ -42,7 +41,6 @@\n import org.junit.rules.ExpectedException;\n import org.mockito.ArgumentCaptor;\n \n-import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.PartitionAttributes;\n import org.apache.geode.cache.execute.FunctionContext;\n import org.apache.geode.cache.execute.ResultSender;\n@@ -98,18 +96,13 @@ public void setUp() throws Exception {\n   }\n \n   @Test\n-  public void testExecute() {\n+  public void testExecute() throws Exception {\n     List<?> results = null;\n \n     when(cache.getPersistentMemberManager()).thenReturn(memberManager);\n \n     smdsFunc.execute(context);\n-    try {\n-      results = resultSender.getResults();\n-    } catch (Throwable e) {\n-      e.printStackTrace();\n-      fail(\"Unexpected exception\");\n-    }\n+    results = resultSender.getResults();\n     assertNotNull(results);\n   }\n \n@@ -118,23 +111,20 @@ public void testExecuteWithNullContextThrowsRuntimeException() {\n     expectedException.expect(RuntimeException.class);\n \n     smdsFunc.execute(null);\n-    fail(\"Missing expected RuntimeException\");\n   }\n \n   /**\n    * Test method for\n    * {@link org.apache.geode.management.internal.cli.functions.ShowMissingDiskStoresFunction#execute(org.apache.geode.cache.execute.FunctionContext)}.\n    */\n   @Test\n-  public void testExecuteWithNullCacheInstanceHasEmptyResults() throws Throwable {\n+  public void testExecuteWithNullCacheInstanceThrowsCacheClosedException() throws Throwable {\n+    expectedException.expect(CacheClosedException.class);\n     context = new FunctionContextImpl(null, \"testFunction\", null, resultSender);\n     List<?> results = null;\n \n     smdsFunc.execute(context);\n     results = resultSender.getResults();\n-    assertNotNull(results);\n-    assertEquals(1, results.size());\n-    assertNull(results.get(0));\n   }\n \n   @Test\n@@ -195,8 +185,6 @@ public void testExecuteReturnsMissingDiskStores() throws Throwable {\n         .equals(\"/diskStore2\")) {\n       assertEquals(\"/diskStore1\",\n           ((PersistentMemberPattern) detailSet.toArray()[1]).getDirectory());\n-    } else {\n-      fail(\"Incorrect missing colocated region results\");\n     }\n   }\n \n@@ -229,8 +217,6 @@ public void testExecuteReturnsMissingColocatedRegions() throws Throwable {\n       assertEquals(\"child2\", ((ColocatedRegionDetails) detailSet.toArray()[1]).getChild());\n     } else if (((ColocatedRegionDetails) detailSet.toArray()[0]).getChild().equals(\"child2\")) {\n       assertEquals(\"child1\", ((ColocatedRegionDetails) detailSet.toArray()[1]).getChild());\n-    } else {\n-      fail(\"Incorrect missing colocated region results\");\n     }\n   }\n \n@@ -277,8 +263,6 @@ public void testExecuteReturnsMissingStoresAndRegions() throws Throwable {\n             .equals(\"/diskStore2\")) {\n           assertEquals(\"/diskStore1\",\n               ((PersistentMemberPattern) detailSet.toArray()[1]).getDirectory());\n-        } else {\n-          fail(\"Incorrect missing colocated region results\");\n         }\n       } else if (detailSet.toArray()[0] instanceof ColocatedRegionDetails) {\n         assertEquals(2, detailSet.toArray().length);\n@@ -293,8 +277,6 @@ public void testExecuteReturnsMissingStoresAndRegions() throws Throwable {\n         } else {\n           fail(\"Incorrect missing colocated region results\");\n         }\n-      } else {\n-        fail(\"Unexpected result type: \" + detailSet.toArray()[0].getClass());\n       }\n     }\n   }\n@@ -307,7 +289,6 @@ public void testExecuteCatchesExceptions() throws Exception {\n \n     smdsFunc.execute(context);\n     List<?> results = resultSender.getResults();\n-    fail(\"Failed to catch expected RuntimeException\");\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/0ccf9fab8c7ccf109b91f17272c9e29f0854545e/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/ShowMissingDiskStoresFunctionJUnitTest.java",
                "sha": "235ae39d49e18e3d2be8b612c813f931a86c36cf",
                "status": "modified"
            }
        ],
        "message": "GEODE-3299: throw CacheClosedException in FunctionContext.getCache() (#975)\n\n* GEODE-3299: throw CacheClosedException when FunctionContext.getCache() == null\r\n\r\nGfsh functions handle CacheClosedException, whereas\r\nNullPointerExceptions that resulted from returning null are not.\r\n\r\n* GEODE-3299: Updates to ShowMissingDiskStoresFunction\r\n\r\nAdjusted test in ShowMissingDiskStoresDUniotTest to expect the exception instead of empty\r\nresults. Also removed redundant fail() assertions from the tests.",
        "parent": "https://github.com/apache/geode/commit/8ff23e06430721f82e2fe3ce36da7b8238c18633",
        "patched_files": [
            "GetRegionDescriptionFunction.java",
            "FunctionContextImpl.java",
            "ShowMissingDiskStoresFunction.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ShowMissingDiskStoresFunctionJUnitTest.java"
        ]
    },
    "geode_0df32bd": {
        "bug_id": "geode_0df32bd",
        "commit": "https://github.com/apache/geode/commit/0df32bd60cc6068648c334c36c0ea1c18ed61e8c",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/0df32bd60cc6068648c334c36c0ea1c18ed61e8c/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java?ref=0df32bd60cc6068648c334c36c0ea1c18ed61e8c",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "patch": "@@ -326,12 +326,16 @@ void removeMemberArtifacts(DistributedMember member, boolean crashed) {\n         // ignored\n       }\n       try {\n-        monitoringRegion.localDestroyRegion();\n+        if (monitoringRegion != null) {\n+          monitoringRegion.localDestroyRegion();\n+        }\n       } catch (CancelException | RegionDestroyedException ignore) {\n         // ignored\n       }\n       try {\n-        notificationRegion.localDestroyRegion();\n+        if (notificationRegion != null) {\n+          notificationRegion.localDestroyRegion();\n+        }\n       } catch (CancelException | RegionDestroyedException ignore) {\n         // ignored\n       }",
                "raw_url": "https://github.com/apache/geode/raw/0df32bd60cc6068648c334c36c0ea1c18ed61e8c/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "sha": "a885e300da09256d265739b61cad936ac319373d",
                "status": "modified"
            },
            {
                "additions": 37,
                "blob_url": "https://github.com/apache/geode/blob/0df32bd60cc6068648c334c36c0ea1c18ed61e8c/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java?ref=0df32bd60cc6068648c334c36c0ea1c18ed61e8c",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "patch": "@@ -15,6 +15,7 @@\n package org.apache.geode.management.internal;\n \n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.catchThrowable;\n import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.ArgumentMatchers.eq;\n import static org.mockito.Mockito.doThrow;\n@@ -250,8 +251,6 @@ public void removeMemberArtifactsDoesNotThrowIfMBeanProxyFactoryThrowsRegionDest\n         .removeAllProxies(member, monitoringRegion);\n   }\n \n-  // ----------\n-\n   @Test\n   public void removeMemberArtifactsProxyFactoryDoesNotThrowIfCacheClosed() {\n     InternalDistributedMember member = member();\n@@ -316,8 +315,6 @@ public void removeMemberArtifactsMonitoringRegionDoesNotThrowIfCacheClosed() {\n         .localDestroyRegion();\n   }\n \n-  // ----------\n-\n   @Test\n   public void removeMemberArtifactsProxyFactoryDoesNotThrowIfSystemDisconnected() {\n     InternalDistributedMember member = member();\n@@ -382,6 +379,42 @@ public void removeMemberArtifactsMonitoringRegionDoesNotThrowIfSystemDisconnecte\n         .localDestroyRegion();\n   }\n \n+  @Test\n+  public void removeMemberArtifactsDoesNotThrowIfNotificationRegionIsNull() {\n+    InternalDistributedMember member = member();\n+    when(repo.getEntryFromMonitoringRegionMap(eq(member)))\n+        .thenReturn(mock(Region.class));\n+    when(repo.getEntryFromNotifRegionMap(eq(member)))\n+        .thenReturn(null);\n+    when(system.getDistributedMember())\n+        .thenReturn(member);\n+    FederatingManager federatingManager = new FederatingManager(repo, system, service, cache,\n+        statisticsFactory, statisticsClock, proxyFactory, messenger, executorService);\n+\n+    Throwable thrown = catchThrowable(() -> federatingManager.removeMemberArtifacts(member, false));\n+\n+    assertThat(thrown)\n+        .isNull();\n+  }\n+\n+  @Test\n+  public void removeMemberArtifactsDoesNotThrowIfMonitoringRegionIsNull() {\n+    InternalDistributedMember member = member();\n+    when(repo.getEntryFromMonitoringRegionMap(eq(member)))\n+        .thenReturn(null);\n+    when(repo.getEntryFromNotifRegionMap(eq(member)))\n+        .thenReturn(mock(Region.class));\n+    when(system.getDistributedMember())\n+        .thenReturn(member);\n+    FederatingManager federatingManager = new FederatingManager(repo, system, service, cache,\n+        statisticsFactory, statisticsClock, proxyFactory, messenger, executorService);\n+\n+    Throwable thrown = catchThrowable(() -> federatingManager.removeMemberArtifacts(member, false));\n+\n+    assertThat(thrown)\n+        .isNull();\n+  }\n+\n   private InternalDistributedMember member() {\n     return member(1, 1);\n   }",
                "raw_url": "https://github.com/apache/geode/raw/0df32bd60cc6068648c334c36c0ea1c18ed61e8c/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "sha": "9b0254141309cce8ce81122d244d2d1c898b6116",
                "status": "modified"
            }
        ],
        "message": "GEODE-7297: Handle more exceptions in FederatingManager (#4208)\n\nHandle or prevent CancelException and NullPointerException in\r\nremoveMemberArtifacts.",
        "parent": "https://github.com/apache/geode/commit/6ae3f0bc431d681062bec3ad2883d1ef0203a88c",
        "patched_files": [
            "FederatingManager.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "FederatingManagerTest.java"
        ]
    },
    "geode_0f72d36": {
        "bug_id": "geode_0f72d36",
        "commit": "https://github.com/apache/geode/commit/0f72d363bae43a11f0c6d132076b99aedd8d834a",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/0f72d363bae43a11f0c6d132076b99aedd8d834a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommand.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommand.java?ref=0f72d363bae43a11f0c6d132076b99aedd8d834a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommand.java",
                "patch": "@@ -119,7 +119,9 @@ protected static void writeCommitResponse(TXCommitMessage response,\n     responseMsg.setMessageType(MessageType.RESPONSE);\n     responseMsg.setTransactionId(origMsg.getTransactionId());\n     responseMsg.setNumberOfParts(1);\n-    response.setClientVersion(servConn.getClientVersion());\n+    if( response != null ) {\n+    \tresponse.setClientVersion(servConn.getClientVersion());\n+    }\n     responseMsg.addObjPart(response, zipValues);\n     servConn.getCache().getCancelCriterion().checkCancelInProgress(null);\n     if (logger.isDebugEnabled()) {",
                "raw_url": "https://github.com/apache/geode/raw/0f72d363bae43a11f0c6d132076b99aedd8d834a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommand.java",
                "sha": "6caf89a7f7f863d60b709d07a2c49e004e39e157",
                "status": "modified"
            },
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/geode/blob/0f72d363bae43a11f0c6d132076b99aedd8d834a/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommandTest.java",
                "changes": 39,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommandTest.java?ref=0f72d363bae43a11f0c6d132076b99aedd8d834a",
                "deletions": 0,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommandTest.java",
                "patch": "@@ -0,0 +1,39 @@\n+package com.gemstone.gemfire.internal.cache.tier.sockets.command;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import com.gemstone.gemfire.CancelCriterion;\n+import com.gemstone.gemfire.cache.Cache;\n+import com.gemstone.gemfire.internal.cache.tier.sockets.Message;\n+import com.gemstone.gemfire.internal.cache.tier.sockets.ServerConnection;\n+\n+public class CommitCommandTest {\n+\n+\t/**\n+\t * Test for GEODE-537\n+\t * No NPE should be thrown from the {@link CommitCommand.writeCommitResponse()}\n+\t * if the response message is null as it is the case when JTA\n+\t * transaction is rolled back with TX_SYNCHRONIZATION AFTER_COMPLETION STATUS_ROLLEDBACK \n+\t * @throws IOException \n+\t * \n+\t */\n+\t@Test\n+\tpublic void testWriteNullResponse() throws IOException {\n+\t\t\n+\t\tCache cache = mock(Cache.class);\n+\t\tMessage origMsg = mock(Message.class);\n+\t\tServerConnection servConn = mock(ServerConnection.class);\n+\t\twhen(servConn.getResponseMessage()).thenReturn(mock(Message.class));\n+\t\twhen(servConn.getCache()).thenReturn(cache);\n+\t\twhen(cache.getCancelCriterion()).thenReturn(mock(CancelCriterion.class));\n+\t\t\n+\t\tCommitCommand.writeCommitResponse(null, origMsg, servConn);\n+\t\t\n+\t}\n+\t\n+}",
                "raw_url": "https://github.com/apache/geode/raw/0f72d363bae43a11f0c6d132076b99aedd8d834a/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/command/CommitCommandTest.java",
                "sha": "1f9ce54303480669c7b43a1ef6e665c8c411403e",
                "status": "added"
            }
        ],
        "message": "GEODE-537 Fix NPE in JTA AFTER_COMPLETION during rollback\n\nA fix for NullPointerException thrown on the server side and propagated to the Gemfire client in case when active JTA transaction gets rolled back.",
        "parent": "https://github.com/apache/geode/commit/cfbeaf241d6c77ad47ba062bb4268c88b798ce90",
        "patched_files": [
            "CommitCommand.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "CommitCommandTest.java"
        ]
    },
    "geode_1726669": {
        "bug_id": "geode_1726669",
        "commit": "https://github.com/apache/geode/commit/1726669bf1a0d304d962071da6cc69b7455c2f10",
        "file": [
            {
                "additions": 105,
                "blob_url": "https://github.com/apache/geode/blob/1726669bf1a0d304d962071da6cc69b7455c2f10/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "changes": 105,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java?ref=1726669bf1a0d304d962071da6cc69b7455c2f10",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "patch": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Properties;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n+import org.junit.rules.TestName;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+\n+\n+/**\n+ * junit test for detecting read conflicts\n+ */\n+public class TXDetectReadConflictJUnitTest {\n+\n+  @Rule\n+  public RestoreSystemProperties restoreSystemProperties = new RestoreSystemProperties();\n+\n+  @Rule\n+  public TestName name = new TestName();\n+\n+  protected Cache cache = null;\n+  protected Region region = null;\n+  protected Region regionpr = null;\n+\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"detectReadConflicts\", \"true\");\n+    createCache();\n+  }\n+\n+  protected void createCache() {\n+    Properties props = new Properties();\n+    props.put(MCAST_PORT, \"0\");\n+    props.put(LOCATORS, \"\");\n+    cache = new CacheFactory(props).create();\n+    region = cache.createRegionFactory(RegionShortcut.REPLICATE).create(\"testRegionRR\");\n+  }\n+\n+  protected void createCachePR() {\n+    Properties props = new Properties();\n+    props.put(MCAST_PORT, \"0\");\n+    props.put(LOCATORS, \"\");\n+    cache = new CacheFactory(props).create();\n+    regionpr = cache.createRegionFactory(RegionShortcut.PARTITION).create(\"testRegionPR\");\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    cache.close();\n+  }\n+\n+  @Test\n+  public void testReadConflictsRR() throws Exception {\n+    cache.close();\n+    createCache();\n+    region.put(\"key\", \"value\");\n+    region.put(\"key1\", \"value1\");\n+    TXManagerImpl mgr = (TXManagerImpl) cache.getCacheTransactionManager();\n+    mgr.begin();\n+    assertEquals(\"value\", region.get(\"key\"));\n+    assertEquals(\"value1\", region.get(\"key1\"));\n+    mgr.commit();\n+  }\n+\n+  @Test\n+  public void testReadConflictsPR() throws Exception {\n+    cache.close();\n+    createCachePR();\n+    regionpr.put(\"key\", \"value\");\n+    regionpr.put(\"key1\", \"value1\");\n+    TXManagerImpl mgr = (TXManagerImpl) cache.getCacheTransactionManager();\n+    mgr.begin();\n+    assertEquals(\"value\", regionpr.get(\"key\"));\n+    assertEquals(\"value1\", regionpr.get(\"key1\"));\n+    mgr.commit();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/1726669bf1a0d304d962071da6cc69b7455c2f10/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "sha": "810f148796fdb2f1bd849ff844963077bb42b7e5",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/1726669bf1a0d304d962071da6cc69b7455c2f10/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java?ref=1726669bf1a0d304d962071da6cc69b7455c2f10",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "patch": "@@ -1882,6 +1882,9 @@ void performRemoveAllAdjunctMessaging(DistributedRemoveAllOperation op,\n       Set<InternalDistributedMember> cacheOpReceivers, Set<InternalDistributedMember> twoMessages,\n       FilterRoutingInfo routing) {\n     Operation op = event.getOperation();\n+    if (op == null) {\n+      return Collections.emptySet();\n+    }\n     if (op.isUpdate() || op.isCreate() || op.isDestroy() || op.isInvalidate()) {\n       // this method can safely assume that the operation is being distributed from\n       // the primary bucket holder to other nodes",
                "raw_url": "https://github.com/apache/geode/raw/1726669bf1a0d304d962071da6cc69b7455c2f10/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "sha": "48530907cce9d69539155cafed2e8b79c50d046c",
                "status": "modified"
            }
        ],
        "message": "GEODE-6651: Fixed NPE",
        "parent": "https://github.com/apache/geode/commit/2b2fda692868b0096b17ce55bc084b2f3f9637f2",
        "patched_files": [
            "BucketRegion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "BucketRegionTest.java",
            "TXDetectReadConflictJUnitTest.java"
        ]
    },
    "geode_1dfbffa": {
        "bug_id": "geode_1dfbffa",
        "commit": "https://github.com/apache/geode/commit/1dfbffa71a377aa276729c80c35f0c25a2886b25",
        "file": [
            {
                "additions": 38,
                "blob_url": "https://github.com/apache/geode/blob/1dfbffa71a377aa276729c80c35f0c25a2886b25/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "changes": 114,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java?ref=1dfbffa71a377aa276729c80c35f0c25a2886b25",
                "deletions": 76,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "patch": "@@ -2107,40 +2107,23 @@ public Object updateHAEventWrapper(InternalDistributedMember sender,\n             continue;\n           }\n           synchronized (entryHaEventWrapper) {\n-            if (haContainer.getKey(entryHaEventWrapper) != null) {\n+            if ((HAEventWrapper) haContainer.getKey(entryHaEventWrapper) != null) {\n               entryHaEventWrapper.incAndGetReferenceCount();\n-              // If the input and entry HAEventWrappers are not the same (which is the normal\n-              // case), add the CQs and interest list from the input to the entry and create a new\n-              // value from the entry.\n-              if (entryHaEventWrapper != inputHaEventWrapper) { // See GEODE-4957\n-                addClientCQsAndInterestList(entryMessage, inputHaEventWrapper, haContainer,\n-                    regionName);\n-                inputHaEventWrapper.setClientUpdateMessage(null);\n-                newValueCd =\n-                    new VMCachedDeserializable(entryHaEventWrapper, newValueCd.getSizeInBytes());\n-              }\n-            } else {\n-              entryHaEventWrapper = null;\n-            }\n-          }\n-        } else { // putIfAbsent successful\n-          entryHaEventWrapper = (HAEventWrapper) haContainer.getKey(inputHaEventWrapper);\n-          synchronized (entryHaEventWrapper) {\n-            entryHaEventWrapper.incAndGetReferenceCount();\n-            entryHaEventWrapper.setHAContainer(haContainer);\n-            // If the input and entry HAEventWrappers are not the same (which is not the normal\n-            // case), get the entry message, add the CQs and interest list from the input to the\n-            // entry and create a new value from the entry.\n-            if (entryHaEventWrapper != inputHaEventWrapper) { // See GEODE-4957\n-              entryMessage = (ClientUpdateMessageImpl) haContainer.get(inputHaEventWrapper);\n               addClientCQsAndInterestList(entryMessage, inputHaEventWrapper, haContainer,\n                   regionName);\n               inputHaEventWrapper.setClientUpdateMessage(null);\n               newValueCd =\n                   new VMCachedDeserializable(entryHaEventWrapper, newValueCd.getSizeInBytes());\n+            } else {\n+              entryHaEventWrapper = null;\n             }\n-            entryHaEventWrapper.setClientUpdateMessage(null);\n-            entryHaEventWrapper.setIsRefFromHAContainer(true);\n+          }\n+        } else { // putIfAbsent successful\n+          synchronized (inputHaEventWrapper) {\n+            inputHaEventWrapper.incAndGetReferenceCount();\n+            inputHaEventWrapper.setHAContainer(haContainer);\n+            inputHaEventWrapper.setClientUpdateMessage(null);\n+            inputHaEventWrapper.setIsRefFromHAContainer(true);\n           }\n           break;\n         }\n@@ -3443,76 +3426,55 @@ public void destroy() throws CacheWriterException {\n    */\n   protected void putEventInHARegion(Conflatable event, Long position) {\n     if (event instanceof HAEventWrapper) {\n-      HAEventWrapper haEventWrapper = (HAEventWrapper) event;\n+      HAEventWrapper inputHaEventWrapper = (HAEventWrapper) event;\n       if (this.isQueueInitialized()) {\n-        if (haEventWrapper.getIsRefFromHAContainer()) {\n-          putEntryConditionallyIntoHAContainer(haEventWrapper);\n+        if (inputHaEventWrapper.getIsRefFromHAContainer()) {\n+          putEntryConditionallyIntoHAContainer(inputHaEventWrapper);\n         } else {\n-          // This means that the haEvenWrapper reference we have is not\n+          // This means that the haEventWrapper reference we have is not\n           // authentic, i.e. it doesn't refer to the HAEventWrapper instance\n           // in the haContainer, but to the one outside it.\n-          boolean entryFound;\n-          // synchronized (this.haContainer) {\n-          HAEventWrapper original = null;\n+          HAEventWrapper haContainerKey = null;\n           do {\n-            ClientUpdateMessageImpl old =\n+            ClientUpdateMessageImpl haContainerEntry =\n                 (ClientUpdateMessageImpl) ((HAContainerWrapper) this.haContainer)\n-                    .putIfAbsent(haEventWrapper, haEventWrapper.getClientUpdateMessage());\n-            if (old != null) {\n-              original =\n-                  (HAEventWrapper) ((HAContainerWrapper) this.haContainer).getKey(haEventWrapper);\n-              if (original == null) {\n+                    .putIfAbsent(inputHaEventWrapper, inputHaEventWrapper.getClientUpdateMessage());\n+            if (haContainerEntry != null) {\n+              haContainerKey = (HAEventWrapper) ((HAContainerWrapper) this.haContainer)\n+                  .getKey(inputHaEventWrapper);\n+              if (haContainerKey == null) {\n                 continue;\n               }\n-              synchronized (original) {\n+              synchronized (haContainerKey) {\n                 // assert the entry is still present\n-                if (((HAContainerWrapper) this.haContainer).getKey(original) != null) {\n-                  original.incAndGetReferenceCount();\n-                  addClientCQsAndInterestList(old, haEventWrapper, this.haContainer,\n-                      this.regionName);\n-                  haEventWrapper = original;\n+                if (((HAContainerWrapper) this.haContainer).getKey(haContainerKey) != null) {\n+                  haContainerKey.incAndGetReferenceCount();\n+                  addClientCQsAndInterestList(haContainerEntry, inputHaEventWrapper,\n+                      this.haContainer, this.regionName);\n+                  inputHaEventWrapper = haContainerKey;\n                 } else {\n-                  original = null;\n+                  haContainerKey = null;\n                 }\n               }\n             } else {\n-              synchronized (haEventWrapper) {\n-                haEventWrapper.incAndGetReferenceCount();\n-                haEventWrapper.setHAContainer(this.haContainer);\n-                if (!haEventWrapper.getPutInProgress()) {\n+              synchronized (inputHaEventWrapper) {\n+                inputHaEventWrapper.incAndGetReferenceCount();\n+                inputHaEventWrapper.setHAContainer(this.haContainer);\n+                if (!inputHaEventWrapper.getPutInProgress()) {\n                   // This means that this is a GII'ed event. Hence we must\n                   // explicitly set 'clientUpdateMessage' to null.\n-                  haEventWrapper.setClientUpdateMessage(null);\n+                  inputHaEventWrapper.setClientUpdateMessage(null);\n                 }\n-                haEventWrapper.setIsRefFromHAContainer(true);\n+                inputHaEventWrapper.setIsRefFromHAContainer(true);\n               }\n               break;\n             }\n-          } while (original == null);\n-          /*\n-           * entry = (Map.Entry)((HAContainerWrapper)this.haContainer) .getEntry(haEventWrapper); if\n-           * (entry == null) { entryFound = false;\n-           * putEntryConditionallyIntoHAContainer(haEventWrapper); } else { entryFound = true; // Do\n-           * not assign entry.getKey() to haEventWrapper right now.\n-           * ((HAEventWrapper)entry.getKey()).incAndGetReferenceCount(); } }//haContainer\n-           * synchronized ends if (entryFound) { addClientCQsAndInterestList(entry, haEventWrapper,\n-           * haContainer, regionName); haEventWrapper = (HAEventWrapper)entry.getKey(); } else { //\n-           * entry not found if (!haEventWrapper.getPutInProgress()) { // This means that this is a\n-           * GII'ed event. Hence we must // explicitly set 'clientUpdateMessage' to null.\n-           * haEventWrapper.setClientUpdateMessage(null); }\n-           * haEventWrapper.setIsRefFromHAContainer(true); }\n-           */\n-        }\n-      }\n-      // This has now been taken care of in AbstractRegionMap.initialImagePut()\n-      // else{\n-      // if(!haEventWrapper.getIsRefFromHAContainer()){\n-      // haEventWrapper =(HAEventWrapper)((HAContainerWrapper)haContainer).getKey(haEventWrapper);\n-      // }\n-      // }\n+          } while (haContainerKey == null);\n+        }\n+      }\n       // Put the reference to the HAEventWrapper instance into the\n       // HA queue.\n-      this.region.put(position, haEventWrapper);\n+      this.region.put(position, inputHaEventWrapper);\n       // logger.info(LocalizedStrings.DEBUG, \"added message at position \" + position);\n     } else { // (event instanceof ClientMarkerMessageImpl OR ConflatableObject OR\n              // ClientInstantiatorMessage)",
                "raw_url": "https://github.com/apache/geode/raw/1dfbffa71a377aa276729c80c35f0c25a2886b25/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "sha": "a49adfb8ec0b04a1a409ded7332b30e9d27fe694",
                "status": "modified"
            }
        ],
        "message": "GEODE-5166: NPE thrown while processing InitialImage of subscription region\n\n* Fix NPE in updateHAEventWrapper\n* Clean up code (renaming variables) in putEventInHARegion\n* Removing old/commented out code",
        "parent": "https://github.com/apache/geode/commit/4e53223979761a23a9e73a68ffbbe40d9ae75aaf",
        "patched_files": [
            "HARegionQueue.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "HARegionQueueTest.java"
        ]
    },
    "geode_1efbf58": {
        "bug_id": "geode_1efbf58",
        "commit": "https://github.com/apache/geode/commit/1efbf58f3a254a6e27bd63c2b676f216c35c9d9f",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/1efbf58f3a254a6e27bd63c2b676f216c35c9d9f/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/internal/filter/SessionReplicationIntegrationJUnitTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/internal/filter/SessionReplicationIntegrationJUnitTest.java?ref=1efbf58f3a254a6e27bd63c2b676f216c35c9d9f",
                "deletions": 2,
                "filename": "extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/internal/filter/SessionReplicationIntegrationJUnitTest.java",
                "patch": "@@ -85,15 +85,15 @@\n   @Before\n   public void setUp() throws Exception {\n \n-    Assume.assumeFalse(System.getProperty(\"os.name\").toLowerCase().contains(\"win\"));\n-\n     File gemfireLogFile = new File(tmpdir.newFolder(), \"gemfire_modules.log\");\n \n     request = HttpTester.newRequest();\n \n     tester = new MyServletTester();\n     tester.setContextPath(\"/test\");\n \n+    Assume.assumeFalse(System.getProperty(\"os.name\").toLowerCase().contains(\"win\"));\n+\n     filterHolder =\n         tester.addFilter(SessionCachingFilter.class, \"/*\", EnumSet.of(DispatcherType.REQUEST));\n     filterHolder.setInitParameter(DistributionConfig.GEMFIRE_PREFIX + \"property.mcast-port\", \"0\");",
                "raw_url": "https://github.com/apache/geode/raw/1efbf58f3a254a6e27bd63c2b676f216c35c9d9f/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/internal/filter/SessionReplicationIntegrationJUnitTest.java",
                "sha": "2679ecc08fe3cdda7bf78aaa7eb66b5e7c729717",
                "status": "modified"
            }
        ],
        "message": "GEODE-2226: SessionReplicationIntegrationTests do not run on windows\n\n- moved Assume(not windows) until tester variable set to avoid NPE on tearDown",
        "parent": "https://github.com/apache/geode/commit/b06f69f226924c1c13096011bfe29fc3a0ce8401",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "SessionReplicationIntegrationJUnitTest.java"
        ]
    },
    "geode_25e591c": {
        "bug_id": "geode_25e591c",
        "commit": "https://github.com/apache/geode/commit/25e591cf308474184dd8320ac0d6f602e504d075",
        "file": [
            {
                "additions": 83,
                "blob_url": "https://github.com/apache/geode/blob/25e591cf308474184dd8320ac0d6f602e504d075/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java?ref=25e591cf308474184dd8320ac0d6f602e504d075",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "patch": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.distributed.internal;\n+\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.test.dunit.IgnoredException;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class RestartOfMemberDistributedTest {\n+  public List<MemberVM> locators = new ArrayList<>();\n+  public List<MemberVM> servers = new ArrayList<>();\n+\n+\n+\n+  @Rule\n+  public ClusterStartupRule clusterStartupRule = new ClusterStartupRule();\n+\n+  @Before\n+  public void before() {\n+    Properties properties = new Properties();\n+\n+    locators.add(clusterStartupRule.startLocatorVM(0, properties));\n+    servers.add(clusterStartupRule.startServerVM(1, properties, locators.get(0).getPort()));\n+    locators.add(clusterStartupRule.startLocatorVM(2, properties, locators.get(0).getPort()));\n+    servers.add(clusterStartupRule.startServerVM(3, properties, locators.get(0).getPort()));\n+  }\n+\n+  @After\n+  public void after() {\n+    servers.clear();\n+    locators.clear();\n+  }\n+\n+  @Test\n+  public void restartofmembers() {\n+    IgnoredException exp1 =\n+        IgnoredException.addIgnoredException(ForcedDisconnectException.class.getName());\n+    IgnoredException exp2 =\n+        IgnoredException.addIgnoredException(\"Possible loss of quorum due to the loss\");\n+    IgnoredException exp3 =\n+        IgnoredException.addIgnoredException(\"Received invalid result from\");\n+    try {\n+      int locator2port = locators.get(1).getPort();\n+      Properties properties = new Properties();\n+      int locator0port = locators.get(0).getPort();\n+      clusterStartupRule.crashVM(1);\n+      clusterStartupRule.crashVM(0);\n+      clusterStartupRule.startLocatorVM(0, locator0port, properties, locator2port);\n+      clusterStartupRule.startServerVM(1, properties, locator2port);\n+      locators.get(1).waitTilFullyReconnected();\n+\n+    } finally {\n+      exp1.remove();\n+      exp2.remove();\n+      exp3.remove();\n+    }\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/25e591cf308474184dd8320ac0d6f602e504d075/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "sha": "8e1e9a15f664a6c424e85c704fdcee5a980dd7b7",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/25e591cf308474184dd8320ac0d6f602e504d075/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=25e591cf308474184dd8320ac0d6f602e504d075",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -1111,6 +1111,7 @@ private boolean attemptReconnect() throws InterruptedException, IOException {\n       InternalDistributedSystem newSystem =\n           (InternalDistributedSystem) system.getReconnectedSystem();\n       if (newSystem != null) {\n+        setLocator(this);\n         if (!tcpServerStarted) {\n           if (locatorListener != null) {\n             locatorListener.clearLocatorInfo();\n@@ -1125,7 +1126,6 @@ private boolean attemptReconnect() throws InterruptedException, IOException {\n           return false;\n         }\n \n-        setLocator(this);\n         restarted = true;\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/25e591cf308474184dd8320ac0d6f602e504d075/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "db1ccf5766bf646a55f1543f84daa1737c36257b",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/25e591cf308474184dd8320ac0d6f602e504d075/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java?ref=25e591cf308474184dd8320ac0d6f602e504d075",
                "deletions": 3,
                "filename": "geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "patch": "@@ -211,16 +211,21 @@ public MemberVM startLocatorVM(int index, Properties properties, int... locatorP\n         x -> x.withProperties(properties).withConnectionToLocator(locatorPort));\n   }\n \n+  public MemberVM startLocatorVM(int index, int port, Properties properties, int... locatorPort) {\n+    return startLocatorVM(index, port, VersionManager.CURRENT_VERSION,\n+        x -> x.withProperties(properties).withConnectionToLocator(locatorPort));\n+  }\n+\n   public MemberVM startLocatorVM(int index, String version) {\n-    return startLocatorVM(index, version, x -> x);\n+    return startLocatorVM(index, 0, version, x -> x);\n   }\n \n   public MemberVM startLocatorVM(int index,\n       SerializableFunction<LocatorStarterRule> ruleOperator) {\n-    return startLocatorVM(index, VersionManager.CURRENT_VERSION, ruleOperator);\n+    return startLocatorVM(index, 0, VersionManager.CURRENT_VERSION, ruleOperator);\n   }\n \n-  public MemberVM startLocatorVM(int index, String version,\n+  public MemberVM startLocatorVM(int index, int port, String version,\n       SerializableFunction<LocatorStarterRule> ruleOperator) {\n     final String defaultName = \"locator-\" + index;\n     VM locatorVM = getVM(index, version);\n@@ -233,6 +238,9 @@ public MemberVM startLocatorVM(int index, String version,\n       ruleOperator.apply(locatorStarter);\n       locatorStarter.withName(defaultName);\n       locatorStarter.withAutoStart();\n+      if (port != 0) {\n+        locatorStarter.withPort(port);\n+      }\n       locatorStarter.before();\n       return locatorStarter;\n     });",
                "raw_url": "https://github.com/apache/geode/raw/25e591cf308474184dd8320ac0d6f602e504d075/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "sha": "d021e553a7f466903e6c945341eab7089800b1fe",
                "status": "modified"
            }
        ],
        "message": "GEODE-7036: Fix for NPE caused by ex-coordinator joining quorum",
        "parent": "https://github.com/apache/geode/commit/e5c9c420f462149fd062847904e3435fbe99afb4",
        "patched_files": [
            "ClusterStartupRule.java",
            "InternalLocator.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "RestartOfMemberDistributedTest.java"
        ]
    },
    "geode_262e6ee": {
        "bug_id": "geode_262e6ee",
        "commit": "https://github.com/apache/geode/commit/262e6ee1c13df60c38ec373247a4b212f40440f7",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java?ref=262e6ee1c13df60c38ec373247a4b212f40440f7",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "patch": "@@ -621,8 +621,9 @@ protected LocalRegion(String regionName, RegionAttributes attrs, LocalRegion par\n     this.isUsedForParallelGatewaySenderQueue =\n         internalRegionArgs.isUsedForParallelGatewaySenderQueue();\n     this.serialGatewaySender = internalRegionArgs.getSerialGatewaySender();\n-    this.cacheServiceProfiles = internalRegionArgs.getCacheServiceProfiles() == null ? null\n-        : Collections.unmodifiableMap(internalRegionArgs.getCacheServiceProfiles());\n+    this.cacheServiceProfiles =\n+        internalRegionArgs.getCacheServiceProfiles() == null ? Collections.emptyMap()\n+            : Collections.unmodifiableMap(internalRegionArgs.getCacheServiceProfiles());\n \n     if (!isUsedForMetaRegion && !isUsedForPartitionedRegionAdmin\n         && !isUsedForPartitionedRegionBucket && !isUsedForSerialGatewaySenderQueue",
                "raw_url": "https://github.com/apache/geode/raw/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "sha": "00401e9ac7adfd5e3e8962476bddc6c9a8281af4",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java?ref=262e6ee1c13df60c38ec373247a4b212f40440f7",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "patch": "@@ -194,6 +194,7 @@ public void verifyDifferentIndexesFails1() {\n         .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_1));\n   }\n \n+\n   @Test\n   public void verifyDifferentIndexesFails2() {\n     SerializableRunnableIF createIndex1 = getFieldsIndexWithOneField();\n@@ -208,6 +209,17 @@ public void verifyDifferentIndexesFails2() {\n         .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_2));\n   }\n \n+  @Test\n+  public void verifyMemberWithoutIndexCreatedFirstFails() {\n+    SerializableRunnableIF createIndex1 = () -> {\n+      /* Do nothing */};\n+    dataStore1.invoke(() -> initDataStore(createIndex1));\n+\n+    SerializableRunnableIF createIndex2 = getFieldsIndexWithOneField();\n+    dataStore2\n+        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_3));\n+  }\n+\n   @Test\n   @Parameters(method = \"getIndexes\")\n   public void verifySameIndexesSucceeds(SerializableRunnableIF createIndex) {",
                "raw_url": "https://github.com/apache/geode/raw/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "sha": "e58f71399aedb7421e561af7334e0424167bc4d3",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java?ref=262e6ee1c13df60c38ec373247a4b212f40440f7",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "patch": "@@ -61,6 +61,8 @@\n       \"Cannot create Region /region with [] async event ids because another cache has the same region defined with [index#_region] async event ids\";\n   public static final String CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_2 =\n       \"Cannot create Region /region with [index#_region, index2#_region] async event ids because another cache has the same region defined with [index#_region] async event ids\";\n+  public static final String CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_3 =\n+      \"Cannot create Region /region with [index#_region] async event ids because another cache has the same region defined with [] async event ids\";\n \n   public static void verifyInternalRegions(LuceneService luceneService, Cache cache,\n       Consumer<LocalRegion> verify) {",
                "raw_url": "https://github.com/apache/geode/raw/262e6ee1c13df60c38ec373247a4b212f40440f7/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "sha": "d8816a3b22de97216153edda9cb74e81a4f04ce3",
                "status": "modified"
            }
        ],
        "message": "GEODE-2278: Fix an NPE with inconsistent lucene indexes\n\nIf a member without a lucene index is created first, we should throw a\nreasonable error rather than an NPE.",
        "parent": "https://github.com/apache/geode/commit/041a82f20257f43331f1bf0dfdff4c0ef06ba5fb",
        "patched_files": [
            "LocalRegion.java",
            "LuceneTestUtilities.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "LuceneIndexCreationDUnitTest.java"
        ]
    },
    "geode_29010e5": {
        "bug_id": "geode_29010e5",
        "commit": "https://github.com/apache/geode/commit/29010e5fe0effa33450126a8f98c30c169202be9",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/29010e5fe0effa33450126a8f98c30c169202be9/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommand.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommand.java?ref=29010e5fe0effa33450126a8f98c30c169202be9",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommand.java",
                "patch": "@@ -149,8 +149,12 @@ protected void accumulateListGatewayResult(CompositeResultData crd,\n         gatewayReceiverData.accumulate(CliStrings.RESULT_PORT, entry.getValue().getPort());\n         gatewayReceiverData.accumulate(CliStrings.RESULT_SENDERS_COUNT,\n             entry.getValue().getClientConnectionCount());\n-        gatewayReceiverData.accumulate(CliStrings.RESULT_SENDER_CONNECTED,\n-            Arrays.stream(entry.getValue().getConnectedGatewaySenders()).collect(joining(\", \")));\n+        if (entry.getValue() == null || entry.getValue().getConnectedGatewaySenders() == null) {\n+          gatewayReceiverData.accumulate(CliStrings.RESULT_SENDER_CONNECTED, \"\");\n+        } else {\n+          gatewayReceiverData.accumulate(CliStrings.RESULT_SENDER_CONNECTED,\n+              Arrays.stream(entry.getValue().getConnectedGatewaySenders()).collect(joining(\", \")));\n+        }\n       }\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/29010e5fe0effa33450126a8f98c30c169202be9/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommand.java",
                "sha": "6d9e44f86980e61104bdbfc26fd8583c99aa59b7",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/29010e5fe0effa33450126a8f98c30c169202be9/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommandTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommandTest.java?ref=29010e5fe0effa33450126a8f98c30c169202be9",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommandTest.java",
                "patch": "@@ -103,4 +103,17 @@ public void listGatewaysDisplaysGatewayReceiversWhenEmpty() {\n     assertThat(tableContent.get(\"content\").toString()).contains(\"[\\\"\\\"]\");\n   }\n \n+  @Test\n+  public void listGatewaysDisplaysGatewayReceiversWhenNull() {\n+    CompositeResultData crd = ResultBuilder.createCompositeResultData();\n+    crd.setHeader(CliStrings.HEADER_GATEWAYS);\n+\n+    doReturn(null).when(receiverMXBean).getConnectedGatewaySenders();\n+\n+    command.accumulateListGatewayResult(crd, Collections.EMPTY_MAP, receiverBeans);\n+    JSONObject tableContent = (JSONObject) crd.retrieveSectionByIndex(0).getSectionGfJsonObject()\n+        .get(\"__tables__-GatewayReceiver Table\");\n+\n+    assertThat(tableContent.get(\"content\").toString()).contains(\"[\\\"\\\"]\");\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/29010e5fe0effa33450126a8f98c30c169202be9/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ListGatewayCommandTest.java",
                "sha": "d25277a0292b357ef142f3a878501da1cf83322b",
                "status": "modified"
            }
        ],
        "message": "GEODE-5100: prevent NPE when listing the gateway senders. (#1845)",
        "parent": "https://github.com/apache/geode/commit/b490673e30fd096dbf2dd76e839ea497dac89122",
        "patched_files": [
            "ListGatewayCommand.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ListGatewayCommandTest.java"
        ]
    },
    "geode_29c71c9": {
        "bug_id": "geode_29c71c9",
        "commit": "https://github.com/apache/geode/commit/29c71c96f2933e8380e412e9d14b42beb30ae96b",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "patch": "@@ -100,6 +100,11 @@ public FederatingManager(MBeanJMXAdapter jmxAdapter, ManagementResourceRepo repo\n     this.messenger = new MemberMessenger(jmxAdapter, repo, system);\n   }\n \n+  @TestingOnly\n+  void setProxyFactory(MBeanProxyFactory newProxyFactory) {\n+    this.proxyFactory = newProxyFactory;\n+  }\n+\n   /**\n    * This method will be invoked whenever a member wants to be a managing node. The exception\n    * Management exception has to be handled by the caller.",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "sha": "fde2cd032ff010eacf92097c106a43d9ae4f39be",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanJMXAdapter.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/MBeanJMXAdapter.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/MBeanJMXAdapter.java",
                "patch": "@@ -97,6 +97,11 @@ public ObjectName registerMBean(Object object, ObjectName objectName, boolean is\n         newObjectName = ObjectName.getInstance(\n             OBJECTNAME__PREFIX + objectKeyProperty + KEYVAL_SEPARATOR + \"member=\" + member);\n       }\n+\n+      if (isRegistered(newObjectName)) {\n+        return newObjectName;\n+      }\n+\n       mbeanServer.registerMBean(object, newObjectName);\n       this.localGemFireMBean.put(newObjectName, object);\n ",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanJMXAdapter.java",
                "sha": "42a10509b6184d6ad194dbd4af604b350fa3e635",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyFactory.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyFactory.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 8,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyFactory.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import java.beans.IntrospectionException;\n import java.util.Iterator;\n+import java.util.Map;\n import java.util.Map.Entry;\n import java.util.Set;\n \n@@ -78,14 +79,13 @@ public void createProxy(DistributedMember member, ObjectName objectName,\n       Region<String, Object> monitoringRegion, Object newVal) {\n \n     try {\n-      String name = objectName.toString();\n-      FederationComponent federationComponent = (FederationComponent) monitoringRegion.get(name);\n+      FederationComponent federationComponent = (FederationComponent) newVal;\n       String interfaceClassName = federationComponent.getMBeanInterfaceClass();\n \n       Class interfaceClass = ClassLoadUtil.classFromName(interfaceClassName);\n \n       Object object = MBeanProxyInvocationHandler.newProxyInstance(member, monitoringRegion,\n-          objectName, interfaceClass);\n+          objectName, federationComponent, interfaceClass);\n \n       jmxAdapter.registerMBeanProxy(object, objectName);\n \n@@ -123,19 +123,18 @@ public void createAllProxies(DistributedMember member, Region<String, Object> mo\n       logger.debug(\"Creating proxy for: {}\", member.getId());\n     }\n \n-    Set<String> mbeanNames = monitoringRegion.keySet();\n+    Set<Map.Entry<String, Object>> mbeans = monitoringRegion.entrySet();\n \n-    for (String mbeanName : mbeanNames) {\n+    for (Map.Entry<String, Object> mbean : mbeans) {\n \n       ObjectName objectName = null;\n       try {\n-        objectName = ObjectName.getInstance(mbeanName);\n+        objectName = ObjectName.getInstance(mbean.getKey());\n         if (logger.isDebugEnabled()) {\n           logger.debug(\"Creating proxy for ObjectName: \" + objectName.toString());\n         }\n \n-        createProxy(member, objectName, monitoringRegion,\n-            monitoringRegion.get(objectName.toString()));\n+        createProxy(member, objectName, monitoringRegion, mbean.getValue());\n       } catch (Exception e) {\n         logger.warn(\"Create Proxy failed for {} with exception {}\", objectName, e.getMessage(), e);\n       }",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyFactory.java",
                "sha": "212ac65a7472dbda00f2335cbb723e6fd46248ec",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyInvocationHandler.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyInvocationHandler.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyInvocationHandler.java",
                "patch": "@@ -94,11 +94,11 @@\n    * @param interfaceClass on which interface the proxy to be exposed\n    */\n   public static Object newProxyInstance(DistributedMember member,\n-      Region<String, Object> monitoringRegion, ObjectName objectName, Class interfaceClass)\n+      Region<String, Object> monitoringRegion, ObjectName objectName,\n+      FederationComponent federationComponent, Class interfaceClass)\n       throws ClassNotFoundException, IntrospectionException {\n     boolean isMXBean = JMX.isMXBeanInterface(interfaceClass);\n-    boolean notificationBroadcaster =\n-        ((FederationComponent) monitoringRegion.get(objectName.toString())).isNotificationEmitter();\n+    boolean notificationBroadcaster = federationComponent.isNotificationEmitter();\n \n     InvocationHandler handler =\n         new MBeanProxyInvocationHandler(member, objectName, monitoringRegion, isMXBean);",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/main/java/org/apache/geode/management/internal/MBeanProxyInvocationHandler.java",
                "sha": "7855fffebc1e1622a83f13a2f54d5e72289bf68d",
                "status": "modified"
            },
            {
                "additions": 189,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/management/internal/JMXMBeanFederationDUnitTest.java",
                "changes": 189,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/JMXMBeanFederationDUnitTest.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/JMXMBeanFederationDUnitTest.java",
                "patch": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.management.internal;\n+\n+import static java.util.stream.Collectors.toList;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.management.MBeanServerConnection;\n+import javax.management.ObjectName;\n+import javax.management.remote.JMXConnector;\n+import javax.management.remote.JMXConnectorFactory;\n+import javax.management.remote.JMXServiceURL;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.distributed.ConfigurationProperties;\n+import org.apache.geode.distributed.DistributedMember;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.test.dunit.internal.InternalBlackboard;\n+import org.apache.geode.test.dunit.internal.InternalBlackboardImpl;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.apache.geode.test.junit.categories.JMXTest;\n+import org.apache.geode.test.junit.rules.GfshCommandRule;\n+import org.apache.geode.test.junit.rules.MBeanServerConnectionRule;\n+import org.apache.geode.test.junit.rules.serializable.SerializableTestName;\n+\n+@Category({DistributedTest.class, JMXTest.class})\n+public class JMXMBeanFederationDUnitTest {\n+  private static final String LOCATOR_1_NAME = \"locator-one\";\n+  private static final String LOCATOR_2_NAME = \"locator-two\";\n+  private static final String REGION_PATH = \"/test-region-1\";\n+  private static final int LOCATOR_1_VM_INDEX = 0;\n+  private static final int LOCATOR_2_VM_INDEX = 4;\n+  private static final int LOCATOR_COUNT = 1;\n+  private static final int SERVER_1_VM_INDEX = 1;\n+  private static final int SERVER_2_VM_INDEX = 2;\n+  private static final int SERVER_3_VM_INDEX = 3;\n+  private static int SERVER_COUNT = 2;\n+\n+  private int locator1JmxPort;\n+  private int locator2JmxPort;\n+\n+  private MemberVM locator1, locator2, server1, server2, server3;\n+\n+  private InternalBlackboard bb;\n+\n+  @Rule\n+  public ClusterStartupRule lsRule = new ClusterStartupRule();\n+\n+  @Rule\n+  public GfshCommandRule gfsh = new GfshCommandRule();\n+\n+  @Rule\n+  public MBeanServerConnectionRule jmxConnectionRule = new MBeanServerConnectionRule();\n+\n+  @Rule\n+  public SerializableTestName testName = new SerializableTestName();\n+\n+  @Before\n+  public void before() throws Exception {\n+    locator1JmxPort = AvailablePortHelper.getRandomAvailableTCPPorts(LOCATOR_COUNT)[0];\n+    locator1 = lsRule.startLocatorVM(LOCATOR_1_VM_INDEX, locator1Properties());\n+\n+    server1 = lsRule.startServerVM(SERVER_1_VM_INDEX, locator1.getPort());\n+    server2 = lsRule.startServerVM(SERVER_2_VM_INDEX, locator1.getPort());\n+\n+    gfsh.connectAndVerify(locator1);\n+    gfsh.executeAndAssertThat(\n+        \"create region --type=REPLICATE --name=\" + REGION_PATH + \" --enable-statistics=true\")\n+        .statusIsSuccess();\n+    gfsh.disconnect();\n+\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+\n+    bb = InternalBlackboardImpl.getInstance();\n+  }\n+\n+  @Test\n+  public void MBeanFederationAddRemoveServer() throws IOException {\n+    List<String> initialMBeans = getFederatedGemfireBeansFrom(locator1);\n+\n+    server3 = lsRule.startServerVM(SERVER_3_VM_INDEX, locator1.getPort());\n+    SERVER_COUNT++;\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+    List keyset = server3.invoke(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      DistributedMember member =\n+          InternalDistributedSystem.getConnectedInstance().getDistributedMember();\n+      String appender = MBeanJMXAdapter.getUniqueIDForMember(member);\n+      Region monitoringRegion =\n+          cache.getRegion(ManagementConstants.MONITORING_REGION + \"_\" + appender);\n+      List l = (List<String>) monitoringRegion.keySet().stream().collect(Collectors.toList());\n+      return l;\n+    });\n+\n+    List<String> intermediateMBeans = getFederatedGemfireBeansFrom(locator1);\n+    List<String> expectedMBeans = new ArrayList<>();\n+    expectedMBeans.addAll(initialMBeans);\n+    expectedMBeans.addAll(keyset);\n+    expectedMBeans = expectedMBeans.stream().sorted().collect(Collectors.toList());\n+    intermediateMBeans = intermediateMBeans.stream().sorted().collect(Collectors.toList());\n+    assertThat(intermediateMBeans).containsExactlyElementsOf(expectedMBeans);\n+\n+    lsRule.stopMember(SERVER_3_VM_INDEX);\n+    SERVER_COUNT--;\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+\n+    List<String> finalMBeans = getFederatedGemfireBeansFrom(locator1);\n+\n+    assertThat(finalMBeans).containsExactlyElementsOf(initialMBeans);\n+  }\n+\n+  private static List<String> getFederatedGemfireBeansFrom(MemberVM member)\n+      throws IOException {\n+    String url = jmxBeanLocalhostUrlString(member.getJmxPort());\n+    MBeanServerConnection remoteMBS = connectToMBeanServer(url);\n+    Set<ObjectName> allBeanNames = remoteMBS.queryNames(null, null);\n+    // Each locator will have a \"Manager\" bean that is a part of the above query,\n+    // representing the ManagementAdapter.\n+    // This bean is registered (and so included in its own queries),\n+    // but *not* federated (and so is not included in another locator's bean queries).\n+    // For the scope of this test, we do not consider these \"service=Manager\" beans.\n+    Set<String> allBeans = new HashSet<>();\n+    for (ObjectName bean : allBeanNames) {\n+      allBeans.add(bean.toString());\n+    }\n+\n+    return allBeans.stream()\n+        .filter(b -> b.contains(\"GemFire\"))\n+        .sorted()\n+        .collect(toList());\n+  }\n+\n+  private static MBeanServerConnection connectToMBeanServer(String url) throws IOException {\n+    final JMXServiceURL serviceURL = new JMXServiceURL(url);\n+    JMXConnector conn = JMXConnectorFactory.connect(serviceURL);\n+    return conn.getMBeanServerConnection();\n+  }\n+\n+  private static String jmxBeanLocalhostUrlString(int port) {\n+    return \"service:jmx:rmi:///jndi/rmi://localhost\"\n+        + \":\" + port + \"/jmxrmi\";\n+  }\n+\n+  private Properties locator1Properties() {\n+    Properties props = new Properties();\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_HOSTNAME_FOR_CLIENTS, \"localhost\");\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_PORT, \"\" + locator1JmxPort);\n+    props.setProperty(ConfigurationProperties.NAME, LOCATOR_1_NAME);\n+    return props;\n+  }\n+\n+  private Properties locator2Properties() {\n+    locator2JmxPort = AvailablePortHelper.getRandomAvailableTCPPorts(LOCATOR_COUNT)[0];\n+    Properties props = new Properties();\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_HOSTNAME_FOR_CLIENTS, \"localhost\");\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_PORT, \"\" + locator2JmxPort);\n+    props.setProperty(ConfigurationProperties.NAME, LOCATOR_2_NAME);\n+    return props;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/management/internal/JMXMBeanFederationDUnitTest.java",
                "sha": "e08975d505970f370fe9fd1b1cfaf91106d42a48",
                "status": "added"
            },
            {
                "additions": 128,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/management/internal/MBeanFederationErrorPathDUnitTest.java",
                "changes": 128,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/MBeanFederationErrorPathDUnitTest.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/MBeanFederationErrorPathDUnitTest.java",
                "patch": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.management.internal;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.spy;\n+\n+import java.rmi.RemoteException;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.management.MalformedObjectNameException;\n+import javax.management.ObjectName;\n+\n+import org.awaitility.Awaitility;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.mockito.invocation.InvocationOnMock;\n+import org.mockito.stubbing.Answer;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.management.ManagementService;\n+import org.apache.geode.test.dunit.internal.InternalBlackboard;\n+import org.apache.geode.test.dunit.internal.InternalBlackboardImpl;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.apache.geode.test.junit.categories.JMXTest;\n+import org.apache.geode.test.junit.rules.LocatorStarterRule;\n+\n+@Category({DistributedTest.class, JMXTest.class})\n+public class MBeanFederationErrorPathDUnitTest {\n+  private static final int SERVER_1_VM_INDEX = 1;\n+  private static final String REGION_NAME = \"test-region-1\";\n+\n+  public MemberVM server1, server2, server3;\n+\n+  @Rule\n+  public LocatorStarterRule locator1 = new LocatorStarterRule();\n+\n+  @Rule\n+  public ClusterStartupRule lsRule = new ClusterStartupRule();\n+\n+\n+  private InternalBlackboard bb;\n+\n+  @Before\n+  public void before() throws Exception {\n+    locator1.withJMXManager().startLocator();\n+\n+    bb = InternalBlackboardImpl.getInstance();\n+  }\n+\n+  @Test\n+  public void destroyMBeanBeforeFederationCompletes()\n+      throws MalformedObjectNameException, RemoteException {\n+    String bbKey = \"sync1\";\n+\n+    String beanName = \"GemFire:service=Region,name=\\\"/test-region-1\\\",type=Member,member=server-1\";\n+    ObjectName objectName = new ObjectName(beanName);\n+\n+    InternalCache cache = locator1.getCache();\n+    SystemManagementService service =\n+        (SystemManagementService) ManagementService.getManagementService(cache);\n+    FederatingManager federatingManager = service.getFederatingManager();\n+    MBeanProxyFactory mBeanProxyFactory = federatingManager.getProxyFactory();\n+    MBeanProxyFactory spy = spy(mBeanProxyFactory);\n+    service.getFederatingManager().setProxyFactory(spy);\n+\n+    Answer answer1 = new Answer<Object>() {\n+      @Override\n+      public Object answer(InvocationOnMock invocation) throws Throwable {\n+        server1.invoke(() -> {\n+          InternalCache serverCache = ClusterStartupRule.getCache();\n+          Region region = serverCache.getRegionByPath(\"/\" + REGION_NAME);\n+          region.destroyRegion();\n+        });\n+\n+        Region<String, Object> monitoringRegion = invocation.getArgument(2);\n+        monitoringRegion.destroy(objectName.toString());\n+\n+        assertThat((monitoringRegion).get(objectName.toString())).isNull();\n+\n+        try {\n+          invocation.callRealMethod();\n+        } catch (Exception e) {\n+          bb.setMailbox(bbKey, e);\n+          return null;\n+        }\n+        bb.setMailbox(bbKey, \"this is fine\");\n+        return null;\n+      }\n+    };\n+\n+    doAnswer(answer1).when(spy).createProxy(any(), eq(objectName), any(), any());\n+\n+    server1 = lsRule.startServerVM(SERVER_1_VM_INDEX, locator1.getPort());\n+\n+    server1.invoke(() -> {\n+      InternalCache cache1 = ClusterStartupRule.getCache();\n+      cache1.createRegionFactory(RegionShortcut.REPLICATE).create(REGION_NAME);\n+    });\n+\n+    Awaitility.waitAtMost(10, TimeUnit.SECONDS).until(() -> bb.getMailbox(bbKey) != null);\n+    Object e = bb.getMailbox(\"sync1\");\n+\n+    assertThat(e).isNotInstanceOf(NullPointerException.class);\n+    assertThat((String) e).contains(\"this is fine\");\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/management/internal/MBeanFederationErrorPathDUnitTest.java",
                "sha": "26e083ea56726c1a08de996ff4e34101446ae871",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java?ref=29c71c96f2933e8380e412e9d14b42beb30ae96b",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "patch": "@@ -264,7 +264,8 @@ public ManagementService getManagementService() {\n   public void waitTillRegionIsReadyOnServers(String regionName, int serverCount) {\n     await().atMost(30, TimeUnit.SECONDS).until(() -> getRegionMBean(regionName) != null);\n     await().atMost(30, TimeUnit.SECONDS)\n-        .until(() -> getRegionMBean(regionName).getMembers().length == serverCount);\n+        .until(() -> getRegionMBean(regionName).getMembers() != null\n+            && getRegionMBean(regionName).getMembers().length == serverCount);\n   }\n \n   private long getDiskStoreCount(String diskStoreName) {",
                "raw_url": "https://github.com/apache/geode/raw/29c71c96f2933e8380e412e9d14b42beb30ae96b/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "sha": "684f94b1298d9fbaf4f30ed7d6ab48e59bebf7ba",
                "status": "modified"
            }
        ],
        "message": "GEODE-5281: replicate failure and fix bug (#2096)\n\n* GEODE-5281: replicate failure and fix bug\r\n\r\n- replicate the bad timing using a DUnit test\r\n- fix the bug by only doing one lookup of MBeans\r\n- add more tests\r\n- fix potential NPE in waiting for regions to be ready on servers\r\n\r\nCo-authored-by: Kenneth Howe <khowe@pivotal.io>\r\n\r\n* add TestingOnly annotation to setter\r\n\r\nadd a TestingOnly annotation to setter for ProxyFactory in the\r\nFederatingManager for injecting test spies.",
        "parent": "https://github.com/apache/geode/commit/935743586a874dce4b4b780aefe0c653d42f8902",
        "patched_files": [
            "MBeanJMXAdapter.java",
            "MBeanProxyInvocationHandler.java",
            "FederatingManager.java",
            "MemberStarterRule.java",
            "MBeanProxyFactory.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "MemberStarterRuleTest.java",
            "MBeanFederationErrorPathDUnitTest.java",
            "JMXMBeanFederationDUnitTest.java"
        ]
    },
    "geode_2c1b8a4": {
        "bug_id": "geode_2c1b8a4",
        "commit": "https://github.com/apache/geode/commit/2c1b8a4edd99c3b5d25697a08b917de3310c31ae",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/2c1b8a4edd99c3b5d25697a08b917de3310c31ae/geode-core/src/test/java/org/apache/geode/distributed/internal/DlockAndTxlockRegressionTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/DlockAndTxlockRegressionTest.java?ref=2c1b8a4edd99c3b5d25697a08b917de3310c31ae",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/DlockAndTxlockRegressionTest.java",
                "patch": "@@ -218,7 +218,7 @@ public void performOps() {\n \n         region.put(\"TestKey\", \"TestValue\" + random.nextInt(100000));\n \n-        TXManagerImpl mgr = (TXManagerImpl) getCache().getCacheTransactionManager();\n+        TXManagerImpl mgr = (TXManagerImpl) cache.getCacheTransactionManager();\n         TXStateProxyImpl txProxy = (TXStateProxyImpl) mgr.getTXState();\n         TXState txState = (TXState) txProxy.getRealDeal(null, null);\n         txState.setBeforeSend(() -> {",
                "raw_url": "https://github.com/apache/geode/raw/2c1b8a4edd99c3b5d25697a08b917de3310c31ae/geode-core/src/test/java/org/apache/geode/distributed/internal/DlockAndTxlockRegressionTest.java",
                "sha": "3630dc6ed244949da9d6e70e556ea7753bdf6ba5",
                "status": "modified"
            }
        ],
        "message": "GEODE-5155 hang recovering transaction state for crashed server\n\nfixing an NPE caused by the test creating a new cache in between\nstarting a transaction and installing a test hook.",
        "parent": "https://github.com/apache/geode/commit/0d00432564d6e8ce17e6ab49dd38477a2ca5c52e",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "DlockAndTxlockRegressionTest.java"
        ]
    },
    "geode_2f81f40": {
        "bug_id": "geode_2f81f40",
        "commit": "https://github.com/apache/geode/commit/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
        "file": [
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/AcceptorImpl.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/AcceptorImpl.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 7,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/AcceptorImpl.java",
                "patch": "@@ -301,7 +301,6 @@\n   private long acceptorId;\n \n   private static boolean isAuthenticationRequired;\n-  private static boolean isIntegratedSecurity;\n \n   private static boolean isPostAuthzCallbackPresent;\n \n@@ -547,8 +546,6 @@ public AcceptorImpl(int port, String bindHostName, boolean notifyBySubscription,\n \n     isAuthenticationRequired = this.securityService.isClientSecurityRequired();\n \n-    isIntegratedSecurity = this.securityService.isIntegratedSecurity();\n-\n     String postAuthzFactoryName =\n         this.cache.getDistributedSystem().getProperties().getProperty(SECURITY_CLIENT_ACCESSOR_PP);\n \n@@ -1784,10 +1781,6 @@ public static boolean isAuthenticationRequired() {\n     return isAuthenticationRequired;\n   }\n \n-  public static boolean isIntegratedSecurity() {\n-    return isIntegratedSecurity;\n-  }\n-\n   public static boolean isPostAuthzCallbackPresent() {\n     return isPostAuthzCallbackPresent;\n   }",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/AcceptorImpl.java",
                "sha": "010e07c0c415a6cef1cdca398945fba31a8c69fb",
                "status": "modified"
            },
            {
                "additions": 107,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientHealthMonitor.java",
                "changes": 253,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientHealthMonitor.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 146,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientHealthMonitor.java",
                "patch": "@@ -25,7 +25,6 @@\n import java.util.Set;\n import java.util.concurrent.atomic.AtomicIntegerArray;\n \n-import org.apache.commons.lang.StringUtils;\n import org.apache.logging.log4j.Logger;\n \n import org.apache.geode.CancelException;\n@@ -69,16 +68,6 @@\n    */\n   private final Object _clientHeartbeatsLock = new Object();\n \n-  /**\n-   * The map of known client threads\n-   */\n-  private final Map _clientThreads;\n-\n-  /**\n-   * An object used to lock the map of client threads\n-   */\n-  private final Object _clientThreadsLock = new Object();\n-\n   /**\n    * THe GemFire <code>Cache</code>\n    */\n@@ -123,6 +112,12 @@ public int getMaximumTimeBetweenPings() {\n \n   private final HashMap cleanupProxyIdTable = new HashMap();\n \n+  /**\n+   * Used to track the connections for a particular client\n+   */\n+  private final HashMap<ClientProxyMembershipID, ServerConnectionCollection> proxyIdConnections =\n+      new HashMap<>();\n+\n   /**\n    * Gives, version-wise, the number of clients connected to the cache servers in this cache, which\n    * are capable of processing recieved deltas.\n@@ -349,18 +344,12 @@ public void removeAllConnectionsAndUnregisterClient(ClientProxyMembershipID prox\n    * @param proxyID The membership id of the client to be updated\n    * @param connection The thread processing client requests\n    */\n-  public void addConnection(ClientProxyMembershipID proxyID, ServerConnection connection) {\n-    // logger.info(\"ClientHealthMonitor: Adding \" + connection + \" to\n-    // client with member id \" + proxyID);\n-    synchronized (_clientThreadsLock) {\n-      Set serverConnections = (Set) this._clientThreads.get(proxyID);\n-      if (serverConnections == null) {\n-        serverConnections = new HashSet();\n-        this._clientThreads.put(proxyID, serverConnections);\n-      }\n-      serverConnections.add(connection);\n-      // logger.info(\"ClientHealthMonitor: The client with member id \" +\n-      // proxyID + \" contains \" + serverConnections.size() + \" threads\");\n+  public ServerConnectionCollection addConnection(ClientProxyMembershipID proxyID,\n+      ServerConnection connection) {\n+    synchronized (proxyIdConnections) {\n+      ServerConnectionCollection collection = getProxyIdCollection(proxyID);\n+      collection.addConnection(connection);\n+      return collection;\n     }\n   }\n \n@@ -371,18 +360,12 @@ public void addConnection(ClientProxyMembershipID proxyID, ServerConnection conn\n    * @param connection The thread processing client requests\n    */\n   public void removeConnection(ClientProxyMembershipID proxyID, ServerConnection connection) {\n-    // logger.info(\"ClientHealthMonitor: Removing \" + connection + \" from\n-    // client with member id \" + proxyID);\n-    synchronized (_clientThreadsLock) {\n-      Set serverConnections = (Set) this._clientThreads.get(proxyID);\n-      if (serverConnections != null) { // fix for bug 35343\n-        serverConnections.remove(connection);\n-        // logger.info(\"ClientHealthMonitor: The client with member id \" +\n-        // proxyID + \" contains \" + serverConnections.size() + \" threads\");\n-        if (serverConnections.isEmpty()) {\n-          // logger.info(\"ClientHealthMonitor: The client with member id \"\n-          // + proxyID + \" is being removed since it contains 0 threads\");\n-          this._clientThreads.remove(proxyID);\n+    synchronized (proxyIdConnections) {\n+      ServerConnectionCollection collection = proxyIdConnections.get(proxyID);\n+      if (collection != null) {\n+        collection.removeConnection(connection);\n+        if (collection.getConnections().isEmpty()) {\n+          proxyIdConnections.remove(proxyID);\n         }\n       }\n     }\n@@ -419,24 +402,21 @@ public void receivedPing(ClientProxyMembershipID proxyID) {\n    *        ConnectionProxies may be from same client member or different. If it is null this would\n    *        mean to fetch the Connections of all the ConnectionProxy objects.\n    */\n-  public Map getConnectedClients(Set filterProxies) {\n-    Map map = new HashMap(); // KEY=proxyID, VALUE=connectionCount (Integer)\n-    synchronized (_clientThreadsLock) {\n-      Iterator connectedClients = this._clientThreads.entrySet().iterator();\n-      while (connectedClients.hasNext()) {\n-        Map.Entry entry = (Map.Entry) connectedClients.next();\n-        ClientProxyMembershipID proxyID = (ClientProxyMembershipID) entry.getKey();// proxyID\n-                                                                                   // includes FQDN\n+  public Map<String, Object[]> getConnectedClients(Set filterProxies) {\n+    Map<String, Object[]> map = new HashMap<>(); // KEY=proxyID, VALUE=connectionCount (Integer)\n+    synchronized (proxyIdConnections) {\n+      for (Map.Entry<ClientProxyMembershipID, ServerConnectionCollection> entry : proxyIdConnections\n+          .entrySet()) {\n+        ClientProxyMembershipID proxyID = entry.getKey();// proxyID\n+        // includes FQDN\n         if (filterProxies == null || filterProxies.contains(proxyID)) {\n           String membershipID = null;\n-          Set connections = (Set) entry.getValue();\n+          Set<ServerConnection> connections = entry.getValue().getConnections();\n           int socketPort = 0;\n           InetAddress socketAddress = null;\n           /// *\n-          Iterator serverConnections = connections.iterator();\n           // Get data from one.\n-          while (serverConnections.hasNext()) {\n-            ServerConnection sc = (ServerConnection) serverConnections.next();\n+          for (ServerConnection sc : connections) {\n             socketPort = sc.getSocketPort();\n             socketAddress = sc.getSocketAddress();\n             membershipID = sc.getMembershipID();\n@@ -453,7 +433,7 @@ public Map getConnectedClients(Set filterProxies) {\n                 + \" client member id=\" + membershipID;\n           }\n           Object[] data = null;\n-          data = (Object[]) map.get(membershipID);\n+          data = map.get(membershipID);\n           if (data == null) {\n             map.put(membershipID, new Object[] {clientString, Integer.valueOf(connectionCount)});\n           } else {\n@@ -480,20 +460,17 @@ public Map getConnectedClients(Set filterProxies) {\n    *\n    * @return Map of ClientProxyMembershipID against CacheClientStatus objects.\n    */\n-  public Map getStatusForAllClients() {\n-    Map result = new HashMap();\n-    synchronized (_clientThreadsLock) {\n-      Iterator connectedClients = this._clientThreads.entrySet().iterator();\n-      while (connectedClients.hasNext()) {\n-        Map.Entry entry = (Map.Entry) connectedClients.next();\n-        ClientProxyMembershipID proxyID = (ClientProxyMembershipID) entry.getKey();\n+  public Map<ClientProxyMembershipID, CacheClientStatus> getStatusForAllClients() {\n+    Map<ClientProxyMembershipID, CacheClientStatus> result = new HashMap<>();\n+    synchronized (proxyIdConnections) {\n+      for (Map.Entry<ClientProxyMembershipID, ServerConnectionCollection> entry : proxyIdConnections\n+          .entrySet()) {\n+        ClientProxyMembershipID proxyID = entry.getKey();\n         CacheClientStatus cci = new CacheClientStatus(proxyID);\n-        Set connections = (Set) this._clientThreads.get(proxyID);\n+        Set<ServerConnection> connections = entry.getValue().getConnections();\n         if (connections != null) {\n           String memberId = null;\n-          Iterator connectionsIterator = connections.iterator();\n-          while (connectionsIterator.hasNext()) {\n-            ServerConnection sc = (ServerConnection) connectionsIterator.next();\n+          for (ServerConnection sc : connections) {\n             if (sc.isClientServerConnection()) {\n               memberId = sc.getMembershipID(); // each ServerConnection has the same member id\n               cci.setMemberId(memberId);\n@@ -508,30 +485,27 @@ public Map getStatusForAllClients() {\n     return result;\n   }\n \n-  public void fillInClientInfo(Map allClients) {\n+  public void fillInClientInfo(Map<ClientProxyMembershipID, CacheClientStatus> allClients) {\n     // The allClients parameter includes only actual clients (not remote\n     // gateways). This monitor will include remote gateway connections,\n     // so weed those out.\n-    synchronized (_clientThreadsLock) {\n-      Iterator allClientsIterator = allClients.entrySet().iterator();\n-      while (allClientsIterator.hasNext()) {\n-        Map.Entry entry = (Map.Entry) allClientsIterator.next();\n-        ClientProxyMembershipID proxyID = (ClientProxyMembershipID) entry.getKey();// proxyID\n-                                                                                   // includes FQDN\n-        CacheClientStatus cci = (CacheClientStatus) entry.getValue();\n-        Set connections = (Set) this._clientThreads.get(proxyID);\n+    synchronized (proxyIdConnections) {\n+      for (Map.Entry<ClientProxyMembershipID, CacheClientStatus> entry : allClients.entrySet()) {\n+        ClientProxyMembershipID proxyID = entry.getKey();// proxyID\n+        // includes FQDN\n+        CacheClientStatus cci = entry.getValue();\n+        ServerConnectionCollection collection = proxyIdConnections.get(proxyID);\n+        Set<ServerConnection> connections = collection != null ? collection.getConnections() : null;\n         if (connections != null) {\n           String memberId = null;\n           cci.setNumberOfConnections(connections.size());\n           List socketPorts = new ArrayList();\n           List socketAddresses = new ArrayList();\n-          Iterator connectionsIterator = connections.iterator();\n-          while (connectionsIterator.hasNext()) {\n-            ServerConnection sc = (ServerConnection) connectionsIterator.next();\n+          for (ServerConnection sc : connections) {\n             socketPorts.add(Integer.valueOf(sc.getSocketPort()));\n             socketAddresses.add(sc.getSocketAddress());\n             memberId = sc.getMembershipID(); // each ServerConnection has the\n-                                             // same member id\n+            // same member id\n           }\n           cci.setMemberId(memberId);\n           cci.setSocketPorts(socketPorts);\n@@ -541,17 +515,14 @@ public void fillInClientInfo(Map allClients) {\n     }\n   }\n \n-  public Map getConnectedIncomingGateways() {\n-    Map connectedIncomingGateways = new HashMap();\n-    synchronized (_clientThreadsLock) {\n-      Iterator connectedClients = this._clientThreads.entrySet().iterator();\n-      while (connectedClients.hasNext()) {\n-        Map.Entry entry = (Map.Entry) connectedClients.next();\n-        ClientProxyMembershipID proxyID = (ClientProxyMembershipID) entry.getKey();\n-        Set connections = (Set) entry.getValue();\n-        Iterator connectionsIterator = connections.iterator();\n-        while (connectionsIterator.hasNext()) {\n-          ServerConnection sc = (ServerConnection) connectionsIterator.next();\n+  public Map<String, IncomingGatewayStatus> getConnectedIncomingGateways() {\n+    Map<String, IncomingGatewayStatus> connectedIncomingGateways = new HashMap<>();\n+    synchronized (proxyIdConnections) {\n+      for (Map.Entry<ClientProxyMembershipID, ServerConnectionCollection> entry : proxyIdConnections\n+          .entrySet()) {\n+        ClientProxyMembershipID proxyID = entry.getKey();\n+        Set<ServerConnection> connections = entry.getValue().getConnections();\n+        for (ServerConnection sc : connections) {\n           if (sc.getCommunicationMode().isWAN()) {\n             IncomingGatewayStatus status = new IncomingGatewayStatus(proxyID.getDSMembership(),\n                 sc.getSocketAddress(), sc.getSocketPort());\n@@ -566,74 +537,69 @@ public Map getConnectedIncomingGateways() {\n   protected boolean cleanupClientThreads(ClientProxyMembershipID proxyID, boolean timedOut) {\n     boolean result = false;\n     Set serverConnections = null;\n-    synchronized (this._clientThreadsLock) {\n-      serverConnections = (Set) this._clientThreads.remove(proxyID);\n-      // It is ok to modify the set after releasing the sync\n-      // because it has been removed from the map while holding\n-      // the sync.\n-    } // end sync here to fix bug 37576 and 36740\n+    synchronized (proxyIdConnections) {\n+      ServerConnectionCollection collection = proxyIdConnections.remove(proxyID);\n+      if (collection != null) {\n+        serverConnections = collection.getConnections();\n+      }\n+    }\n     {\n       if (serverConnections != null) { // fix for bug 35343\n         result = true;\n-        // logger.warn(\"Terminating \" + serverConnections.size() + \" connections\");\n         for (Iterator it = serverConnections.iterator(); it.hasNext();) {\n           ServerConnection serverConnection = (ServerConnection) it.next();\n-          // logger.warn(\"Terminating \" + serverConnection);\n           serverConnection.handleTermination(timedOut);\n         }\n       }\n     }\n     return result;\n   }\n \n-  protected boolean isAnyThreadProcessingMessage(ClientProxyMembershipID proxyID) {\n-    boolean processingMessage = false;\n-    synchronized (this._clientThreadsLock) {\n-      Set serverConnections = (Set) this._clientThreads.get(proxyID);\n-      if (serverConnections != null) {\n-        for (Iterator it = serverConnections.iterator(); it.hasNext();) {\n-          ServerConnection serverConnection = (ServerConnection) it.next();\n-          if (serverConnection.isProcessingMessage()) {\n-            processingMessage = true;\n-            break;\n-          }\n-        }\n+  // This will return true if the proxyID is truly idle (or if no connections are found), or false\n+  // if there was a active connection.\n+  private boolean prepareToTerminateIfNoConnectionIsProcessing(ClientProxyMembershipID proxyID) {\n+    synchronized (proxyIdConnections) {\n+      ServerConnectionCollection collection = proxyIdConnections.get(proxyID);\n+      if (collection == null) {\n+        return true;\n+      }\n+      if (collection.connectionsProcessing.get() == 0) {\n+        collection.isTerminating = true;\n+        return true;\n+      } else {\n+        return false;\n       }\n     }\n-    return processingMessage;\n   }\n \n   protected void validateThreads(ClientProxyMembershipID proxyID) {\n-    Set serverConnections = null;\n-    synchronized (this._clientThreadsLock) {\n-      serverConnections = (Set) this._clientThreads.get(proxyID);\n-      if (serverConnections != null) {\n-        serverConnections = new HashSet(serverConnections);\n-      }\n+    Set<ServerConnection> serverConnections;\n+    synchronized (proxyIdConnections) {\n+      ServerConnectionCollection collection = proxyIdConnections.get(proxyID);\n+      serverConnections =\n+          collection != null ? new HashSet<>(collection.getConnections()) : Collections.emptySet();\n     }\n     // release sync and operation on copy to fix bug 37675\n-    if (serverConnections != null) {\n-      for (Iterator it = serverConnections.iterator(); it.hasNext();) {\n-        ServerConnection serverConnection = (ServerConnection) it.next();\n-        if (serverConnection.hasBeenTimedOutOnClient()) {\n-          logger.warn(LocalizedMessage.create(\n-              LocalizedStrings.ClientHealtMonitor_0_IS_BEING_TERMINATED_BECAUSE_ITS_CLIENT_TIMEOUT_OF_1_HAS_EXPIRED,\n-              new Object[] {serverConnection,\n-                  Integer.valueOf(serverConnection.getClientReadTimeout())}));\n-          try {\n-            serverConnection.handleTermination(true);\n-            // Not all the code in a ServerConnection correctly\n-            // handles interrupt. In particular it is possible to be doing\n-            // p2p distribution and to have sent a message to one peer but\n-            // to never send it to another due to interrupt.\n-            // serverConnection.interruptOwner();\n-          } finally {\n-            // Just to be sure we clean it up.\n-            // This call probably isn't needed.\n-            removeConnection(proxyID, serverConnection);\n-          }\n+    for (ServerConnection serverConnection : serverConnections) {\n+      if (serverConnection.hasBeenTimedOutOnClient()) {\n+        logger.warn(LocalizedMessage.create(\n+            LocalizedStrings.ClientHealtMonitor_0_IS_BEING_TERMINATED_BECAUSE_ITS_CLIENT_TIMEOUT_OF_1_HAS_EXPIRED,\n+            new Object[] {serverConnection,\n+                Integer.valueOf(serverConnection.getClientReadTimeout())}));\n+        try {\n+          serverConnection.handleTermination(true);\n+          // Not all the code in a ServerConnection correctly\n+          // handles interrupt. In particular it is possible to be doing\n+          // p2p distribution and to have sent a message to one peer but\n+          // to never send it to another due to interrupt.\n+          // serverConnection.interruptOwner();\n+        } finally {\n+          // Just to be sure we clean it up.\n+          // This call probably isn't needed.\n+          removeConnection(proxyID, serverConnection);\n         }\n       }\n+\n     }\n   }\n \n@@ -688,9 +654,6 @@ private ClientHealthMonitor(InternalCache cache, int maximumTimeBetweenPings,\n     this._cache = cache;\n     this.maximumTimeBetweenPings = maximumTimeBetweenPings;\n \n-    // Initialize the client threads map\n-    this._clientThreads = new HashMap();\n-\n     this.monitorInterval = Long.getLong(CLIENT_HEALTH_MONITOR_INTERVAL_PROPERTY,\n         DEFAULT_CLIENT_MONITOR_INTERVAL_IN_MILLIS);\n     logger.debug(\"Setting monitorInterval to {}\", this.monitorInterval);\n@@ -722,6 +685,10 @@ public String toString() {\n     return \"ClientHealthMonitor@\" + Integer.toHexString(System.identityHashCode(this));\n   }\n \n+  public ServerConnectionCollection getProxyIdCollection(ClientProxyMembershipID proxyID) {\n+    return proxyIdConnections.computeIfAbsent(proxyID, key -> new ServerConnectionCollection());\n+  }\n+\n   public Map getCleanupProxyIdTable() {\n     return cleanupProxyIdTable;\n   }\n@@ -828,8 +795,6 @@ public void run() {\n           if (logger.isTraceEnabled()) {\n             logger.trace(\"Monitoring {} client(s)\", getClientHeartbeats().size());\n           }\n-          // logger.warning(\"Monitoring \" + getClientHeartbeats().size() +\n-          // \" client(s).\");\n \n           // Get the current time\n           long currentTime = System.currentTimeMillis();\n@@ -863,30 +828,26 @@ public void run() {\n                 // This client has been idle for too long. Determine whether\n                 // any of its ServerConnection threads are currently processing\n                 // a message. If so, let it go. If not, disconnect it.\n-                if (isAnyThreadProcessingMessage(proxyID)) {\n-                  if (logger.isDebugEnabled()) {\n-                    logger.debug(\n-                        \"Monitoring client with member id {}. It has been {} ms since the latest heartbeat. This client would have been terminated but at least one of its threads is processing a message.\",\n-                        entry.getKey(), (currentTime - latestHeartbeat));\n-                  }\n-                } else {\n+                if (prepareToTerminateIfNoConnectionIsProcessing(proxyID)) {\n                   if (cleanupClientThreads(proxyID, true)) {\n                     logger.warn(LocalizedMessage.create(\n                         LocalizedStrings.ClientHealthMonitor_MONITORING_CLIENT_WITH_MEMBER_ID_0_IT_HAD_BEEN_1_MS_SINCE_THE_LATEST_HEARTBEAT_MAX_INTERVAL_IS_2_TERMINATED_CLIENT,\n                         new Object[] {entry.getKey(), currentTime - latestHeartbeat,\n                             this._maximumTimeBetweenPings}));\n                   }\n+                } else {\n+                  if (logger.isDebugEnabled()) {\n+                    logger.debug(\n+                        \"Monitoring client with member id {}. It has been {} ms since the latest heartbeat. This client would have been terminated but at least one of its threads is processing a message.\",\n+                        entry.getKey(), (currentTime - latestHeartbeat));\n+                  }\n                 }\n               } else {\n                 if (logger.isTraceEnabled()) {\n                   logger.trace(\n                       \"Monitoring client with member id {}. It has been {} ms since the latest heartbeat. This client is healthy.\",\n                       entry.getKey(), (currentTime - latestHeartbeat));\n                 }\n-                // logger.warning(\"Monitoring client with member id \" +\n-                // entry.getKey() + \". It has been \" + (currentTime -\n-                // latestHeartbeat) + \" ms since the latest heartbeat. This\n-                // client is healthy.\");\n               }\n             }\n           }",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientHealthMonitor.java",
                "sha": "d08902de87f3354ea878232e58575aa9b513cca4",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/HandShake.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/HandShake.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/HandShake.java",
                "patch": "@@ -1683,7 +1683,7 @@ public static Object verifyCredentials(String authenticatorMethod, Properties cr\n \n     Authenticator auth = null;\n     try {\n-      if (AcceptorImpl.isIntegratedSecurity()) {\n+      if (securityService.isIntegratedSecurity()) {\n         return securityService.login(credentials);\n       } else {\n         Method instanceGetter = ClassLoadUtil.methodFromName(authenticatorMethod);",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/HandShake.java",
                "sha": "4b1f2c7b48b1953f03bb70b363a345746e4faaf7",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnection.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnection.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 29,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnection.java",
                "patch": "@@ -42,7 +42,6 @@\n import org.apache.geode.cache.client.internal.AbstractOp;\n import org.apache.geode.cache.client.internal.Connection;\n import org.apache.geode.distributed.DistributedSystem;\n-import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.internal.Assert;\n import org.apache.geode.internal.HeapDataOutputStream;\n import org.apache.geode.internal.Version;\n@@ -97,7 +96,7 @@\n \n   private Map commands;\n \n-  private final SecurityService securityService;\n+  protected final SecurityService securityService;\n \n   protected final CacheServerStats stats;\n \n@@ -107,6 +106,7 @@\n   // The key is the size of each ByteBuffer. The value is a queue of byte buffers all of that size.\n   private static final ConcurrentHashMap<Integer, LinkedBlockingQueue<ByteBuffer>> commBufferMap =\n       new ConcurrentHashMap<>(4, 0.75f, 1);\n+  private ServerConnectionCollection serverConnectionCollection;\n \n   public static ByteBuffer allocateCommBuffer(int size, Socket sock) {\n     // I expect that size will almost always be the same value\n@@ -194,17 +194,8 @@ public static void emptyCommBufferPool() {\n    */\n   private int latestBatchIdReplied = -1;\n \n-  /*\n-   * Uniquely identifying the client's Distributed System\n-   *\n-   *\n-   * private String membershipId;\n-   *\n-   *\n-   * Uniquely identifying the client's ConnectionProxy object\n-   *\n-   *\n-   * private String proxyID ;\n+  /**\n+   * Client identity from handshake\n    */\n   ClientProxyMembershipID proxyId;\n \n@@ -333,7 +324,8 @@ private boolean verifyClientConnection() {\n     synchronized (this.handShakeMonitor) {\n       if (this.handshake == null) {\n         // synchronized (getCleanupTable()) {\n-        boolean readHandShake = ServerHandShakeProcessor.readHandShake(this, getSecurityService());\n+        boolean readHandShake =\n+            ServerHandShakeProcessor.readHandShake(this, getSecurityService(), acceptor);\n         if (readHandShake) {\n           if (this.handshake.isOK()) {\n             try {\n@@ -469,11 +461,7 @@ private Map getCleanupProxyIdTable() {\n     return acceptor.getClientHealthMonitor().getCleanupProxyIdTable();\n   }\n \n-  private ClientHealthMonitor getClientHealthMonitor() {\n-    return acceptor.getClientHealthMonitor();\n-  }\n-\n-  private boolean processHandShake() {\n+  protected boolean processHandShake() {\n     boolean result = false;\n     boolean clientJoined = false;\n     boolean registerClient = false;\n@@ -559,8 +547,6 @@ private boolean processHandShake() {\n           numRefs = new Counter();\n           numRefs.incr();\n           getCleanupProxyIdTable().put(this.proxyId, numRefs);\n-          InternalDistributedMember idm =\n-              (InternalDistributedMember) this.proxyId.getDistributedMember();\n         }\n         this.incedCleanupProxyIdTableRef = true;\n       }\n@@ -583,7 +569,7 @@ private boolean processHandShake() {\n         chm.registerClient(this.proxyId);\n       }\n       // hitesh:it will add client connection in set\n-      chm.addConnection(this.proxyId, this);\n+      serverConnectionCollection = chm.addConnection(this.proxyId, this);\n       this.acceptor.getConnectionListener().connectionOpened(registerClient, communicationMode);\n       // Hitesh: add user creds in map for single user case.\n     } // finally\n@@ -725,8 +711,22 @@ protected void doHandshake() {\n   }\n \n   protected void doNormalMsg() {\n+    if (serverConnectionCollection == null) {\n+      // return here if we haven't successfully completed handshake\n+      logger.warn(\"Continued processing ServerConnection after handshake failed\");\n+      this.processMessages = false;\n+      return;\n+    }\n     Message msg = null;\n     msg = BaseCommand.readRequest(this);\n+    synchronized (serverConnectionCollection) {\n+      if (serverConnectionCollection.isTerminating) {\n+        // Client is being disconnected, don't try to process message.\n+        this.processMessages = false;\n+        return;\n+      }\n+      serverConnectionCollection.connectionsProcessing.incrementAndGet();\n+    }\n     ThreadState threadState = null;\n     try {\n       if (msg != null) {\n@@ -775,7 +775,7 @@ protected void doNormalMsg() {\n \n         // if a subject exists for this uniqueId, binds the subject to this thread so that we can do\n         // authorization later\n-        if (AcceptorImpl.isIntegratedSecurity()\n+        if (securityService.isIntegratedSecurity()\n             && !isInternalMessage(this.requestMsg, allowInternalMessagesWithoutCredentials)\n             && !this.communicationMode.isWAN()) {\n           long uniqueId = getUniqueId();\n@@ -799,13 +799,13 @@ protected void doNormalMsg() {\n     } finally {\n       // Keep track of the fact that a message is no longer being\n       // processed.\n+      serverConnectionCollection.connectionsProcessing.decrementAndGet();\n       setNotProcessingMessage();\n       clearRequestMsg();\n       if (threadState != null) {\n         threadState.clear();\n       }\n     }\n-\n   }\n \n   private final Object terminationLock = new Object();\n@@ -874,8 +874,6 @@ void handleTermination(boolean timedOut) {\n             getCleanupProxyIdTable().remove(this.proxyId);\n             // here we can remove entry multiuser map for client\n             proxyIdVsClientUserAuths.remove(this.proxyId);\n-            InternalDistributedMember idm =\n-                (InternalDistributedMember) this.proxyId.getDistributedMember();\n           }\n         }\n       }\n@@ -937,7 +935,7 @@ static ClientUserAuths getClientUserAuths(ClientProxyMembershipID proxyId) {\n     return retCua;\n   }\n \n-  private void initializeCommands() {\n+  protected void initializeCommands() {\n     // The commands are cached here, but are just referencing the ones\n     // stored in the CommandInitializer\n     this.commands = CommandInitializer.getCommands(this);\n@@ -1499,6 +1497,7 @@ public boolean cleanup() {\n       logger.debug(\"{}: Closed connection\", this.name);\n     }\n     releaseCommBuffer();\n+    processMessages = false;\n     return true;\n   }\n \n@@ -1762,7 +1761,7 @@ public AuthorizeRequest getAuthzRequest() throws AuthenticationRequiredException\n       return null;\n     }\n \n-    if (AcceptorImpl.isIntegratedSecurity()) {\n+    if (securityService.isIntegratedSecurity()) {\n       return null;\n     }\n \n@@ -1796,7 +1795,7 @@ public AuthorizeRequestPP getPostAuthzRequest()\n       return null;\n     }\n \n-    if (AcceptorImpl.isIntegratedSecurity()) {\n+    if (securityService.isIntegratedSecurity()) {\n       return null;\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnection.java",
                "sha": "d4e59692b7e6b6bfcee38d4bb45ee531330d10cd",
                "status": "modified"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionCollection.java",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionCollection.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionCollection.java",
                "patch": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache.tier.sockets;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+// This is used to form of group of connections for a particular client. Note that these objects are\n+// managed by the ClientHealthMonitor, which also manages the synchronization of them.\n+public class ServerConnectionCollection {\n+  private Set<ServerConnection> connectionSet = new HashSet<ServerConnection>();\n+\n+  // Number of connections currently processing messages for this client\n+  final AtomicInteger connectionsProcessing = new AtomicInteger();\n+\n+  // Indicates that the server is soon to be or already in the process of terminating connections in\n+  // this collection.\n+  volatile boolean isTerminating = false;\n+\n+  public void addConnection(ServerConnection connection) {\n+    connectionSet.add(connection);\n+  }\n+\n+  public Set<ServerConnection> getConnections() {\n+    return connectionSet;\n+  }\n+\n+  public void removeConnection(ServerConnection connection) {\n+    connectionSet.remove(connection);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionCollection.java",
                "sha": "670b5a1543d0f8ed39d13ccd311bb3641c8baf26",
                "status": "added"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerHandShakeProcessor.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerHandShakeProcessor.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerHandShakeProcessor.java",
                "patch": "@@ -79,8 +79,8 @@ public static void setSeverVersionForTesting(short ver) {\n     currentServerVersion = Version.fromOrdinalOrCurrent(ver);\n   }\n \n-  public static boolean readHandShake(ServerConnection connection,\n-      SecurityService securityService) {\n+  public static boolean readHandShake(ServerConnection connection, SecurityService securityService,\n+      AcceptorImpl acceptorImpl) {\n     boolean validHandShake = false;\n     Version clientVersion = null;\n     try {\n@@ -123,7 +123,7 @@ public static boolean readHandShake(ServerConnection connection,\n \n       // Read the appropriate handshake\n       if (clientVersion.compareTo(Version.GFE_57) >= 0) {\n-        validHandShake = readGFEHandshake(connection, clientVersion, securityService);\n+        validHandShake = readGFEHandshake(connection, clientVersion, securityService, acceptorImpl);\n       } else {\n         connection.refuseHandshake(\n             \"Unsupported version \" + clientVersion + \"Server's current version \" + Acceptor.VERSION,\n@@ -200,7 +200,7 @@ protected static void writeServerMember(DistributedMember member, DataOutputStre\n   }\n \n   private static boolean readGFEHandshake(ServerConnection connection, Version clientVersion,\n-      SecurityService securityService) {\n+      SecurityService securityService, AcceptorImpl acceptorImpl) {\n     int handShakeTimeout = connection.getHandShakeTimeout();\n     InternalLogWriter securityLogWriter = connection.getSecurityLogWriter();\n     try {",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ServerHandShakeProcessor.java",
                "sha": "e292813eaeccd5e6230d8f80bc7f7a68fea1d08e",
                "status": "modified"
            },
            {
                "additions": 134,
                "blob_url": "https://github.com/apache/geode/blob/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionTest.java",
                "changes": 139,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionTest.java?ref=2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45",
                "deletions": 5,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionTest.java",
                "patch": "@@ -20,6 +20,7 @@\n import static org.apache.geode.internal.i18n.LocalizedStrings.HandShake_NO_SECURITY_CREDENTIALS_ARE_PROVIDED;\n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.junit.Assert.fail;\n import static org.mockito.Matchers.any;\n import static org.mockito.Matchers.anyLong;\n import static org.mockito.Mockito.mock;\n@@ -29,6 +30,10 @@\n import java.net.InetAddress;\n import java.net.Socket;\n import java.util.Locale;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n \n import org.junit.Before;\n import org.junit.Rule;\n@@ -38,10 +43,16 @@\n import org.mockito.Mock;\n import org.mockito.MockitoAnnotations;\n \n+import org.apache.geode.cache.client.internal.Connection;\n+import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.i18n.StringId;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.internal.cache.TXManagerImpl;\n+import org.apache.geode.internal.cache.tier.Acceptor;\n+import org.apache.geode.internal.cache.tier.CachedRegionHelper;\n import org.apache.geode.internal.cache.tier.CommunicationMode;\n+import org.apache.geode.internal.cache.tier.MessageType;\n import org.apache.geode.internal.security.SecurityService;\n import org.apache.geode.security.AuthenticationRequiredException;\n import org.apache.geode.test.junit.categories.UnitTest;\n@@ -70,21 +81,29 @@\n   @InjectMocks\n   private ServerConnection serverConnection;\n \n+  private AcceptorImpl acceptor;\n+  private Socket socket;\n+  private InternalCache cache;\n+  private SecurityService securityService;\n+  private CacheServerStats stats;\n+\n   @Before\n   public void setUp() throws IOException {\n-    AcceptorImpl acceptor = mock(AcceptorImpl.class);\n+    acceptor = mock(AcceptorImpl.class);\n \n     InetAddress inetAddress = mock(InetAddress.class);\n     when(inetAddress.getHostAddress()).thenReturn(\"localhost\");\n \n-    Socket socket = mock(Socket.class);\n+    socket = mock(Socket.class);\n     when(socket.getInetAddress()).thenReturn(inetAddress);\n \n-    InternalCache cache = mock(InternalCache.class);\n-    SecurityService securityService = mock(SecurityService.class);\n+    cache = mock(InternalCache.class);\n+    securityService = mock(SecurityService.class);\n+\n+    stats = mock(CacheServerStats.class);\n \n     serverConnection =\n-        new ServerConnectionFactory().makeServerConnection(socket, cache, null, null, 0, 0, null,\n+        new ServerConnectionFactory().makeServerConnection(socket, cache, null, stats, 0, 0, null,\n             CommunicationMode.PrimaryServerToClient.getModeNumber(), acceptor, securityService);\n     MockitoAnnotations.initMocks(this);\n   }\n@@ -139,4 +158,114 @@ public void post65NonSecureShouldThrow() {\n         .hasMessage(HandShake_NO_SECURITY_CREDENTIALS_ARE_PROVIDED.getRawText());\n   }\n \n+  class TestMessage extends Message {\n+    private final Lock lock = new ReentrantLock();\n+    private final Condition testGate = lock.newCondition();\n+    private boolean signalled = false;\n+\n+    public TestMessage() {\n+      super(3, Version.CURRENT);\n+      messageType = MessageType.REQUEST;\n+      securePart = new Part();\n+    }\n+\n+    @Override\n+    public void recv() throws IOException {\n+      try {\n+        lock.lock();\n+        testGate.await(10, TimeUnit.SECONDS);\n+      } catch (InterruptedException e) {\n+        throw new RuntimeException(e);\n+      } finally {\n+        lock.unlock();\n+        if (!signalled) {\n+          fail(\"Message never received continueProcessing call\");\n+        }\n+      }\n+    }\n+\n+    public void continueProcessing() {\n+      lock.lock();\n+      testGate.signal();\n+      signalled = true;\n+      lock.unlock();\n+    }\n+  }\n+\n+  class TestServerConnection extends LegacyServerConnection {\n+\n+    private TestMessage testMessage;\n+\n+    /**\n+     * Creates a new <code>ServerConnection</code> that processes messages received from an edge\n+     * client over a given <code>Socket</code>.\n+     */\n+    public TestServerConnection(Socket socket, InternalCache internalCache,\n+        CachedRegionHelper helper, CacheServerStats stats, int hsTimeout, int socketBufferSize,\n+        String communicationModeStr, byte communicationMode, Acceptor acceptor,\n+        SecurityService securityService) {\n+      super(socket, internalCache, helper, stats, hsTimeout, socketBufferSize, communicationModeStr,\n+          communicationMode, acceptor, securityService);\n+\n+      setClientDisconnectCleanly(); // Not clear where this is supposed to be set in the timeout\n+                                    // path\n+    }\n+\n+    @Override\n+    protected void doHandshake() {\n+      ClientProxyMembershipID proxyID = mock(ClientProxyMembershipID.class);\n+      when(proxyID.getDistributedMember()).thenReturn(mock(InternalDistributedMember.class));\n+      HandShake handShake = mock(HandShake.class);\n+      when(handShake.getMembership()).thenReturn(proxyID);\n+      when(handShake.getVersion()).thenReturn(Version.CURRENT);\n+\n+      setHandshake(handShake);\n+      setProxyId(proxyID);\n+\n+      processHandShake();\n+      initializeCommands();\n+\n+      setFakeRequest();\n+\n+      long fakeId = -1;\n+      MessageIdExtractor extractor = mock(MessageIdExtractor.class);\n+      when(extractor.getUniqueIdFromMessage(getRequestMessage(), handShake,\n+          Connection.DEFAULT_CONNECTION_ID)).thenReturn(fakeId);\n+      setMessageIdExtractor(extractor);\n+    }\n+\n+    @Override\n+    void handleTermination(boolean timedOut) {\n+      super.handleTermination(timedOut);\n+      testMessage.continueProcessing();\n+    }\n+\n+    private void setFakeRequest() {\n+      testMessage = new TestMessage();\n+      setRequestMsg(testMessage);\n+    }\n+  }\n+\n+  /**\n+   * This test sets up a TestConnection which will register with the ClientHealthMonitor and then\n+   * block waiting to receive a fake message. This message will arrive just after the health monitor\n+   * times out this connection and kills it. The test then makes sure that the connection correctly\n+   * handles the terminated state and exits.\n+   */\n+  @Test\n+  public void terminatingConnectionHandlesNewRequestsGracefully() throws Exception {\n+    when(cache.getCacheTransactionManager()).thenReturn(mock(TXManagerImpl.class));\n+    ClientHealthMonitor.createInstance(cache, 100, mock(CacheClientNotifierStats.class));\n+    ClientHealthMonitor clientHealthMonitor = ClientHealthMonitor.getInstance();\n+    when(acceptor.getClientHealthMonitor()).thenReturn(clientHealthMonitor);\n+    when(acceptor.getConnectionListener()).thenReturn(mock(ConnectionListener.class));\n+    when(securityService.isIntegratedSecurity()).thenReturn(true);\n+\n+    TestServerConnection testServerConnection =\n+        new TestServerConnection(socket, cache, mock(CachedRegionHelper.class), stats, 0, 0, null,\n+            CommunicationMode.PrimaryServerToClient.getModeNumber(), acceptor, securityService);\n+    MockitoAnnotations.initMocks(this);\n+\n+    testServerConnection.run();\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/2f81f40727cfd02296e9e0f041b6ae2bb9cd1a45/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ServerConnectionTest.java",
                "sha": "b7f0e7b40aa8c6e5dcbb77f0a44da61b115dc180",
                "status": "modified"
            }
        ],
        "message": "GEODE-4094: ClientHealthMonitor may cause an NPE in a ServerConnection (#1326)\n\n* GEODE-4094: ClientHealthMonitor may cause an NPE in a ServerConnection\r\n\r\n- minor refactoring of AcceptorImpl and Handshake to improve testability\r\n- added a unit test to demonstrate race condition\r\n- refactored connection map into a new object to prevent race",
        "parent": "https://github.com/apache/geode/commit/e63152ac0c2bb33a53897a26cb851ce16cda26ba",
        "patched_files": [
            "HandShake.java",
            "AcceptorImpl.java",
            "ServerHandShakeProcessor.java",
            "ServerConnection.java",
            "ServerConnectionCollection.java",
            "ClientHealthMonitor.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "HandShakeTest.java",
            "ServerConnectionTest.java"
        ]
    },
    "geode_306fda0": {
        "bug_id": "geode_306fda0",
        "commit": "https://github.com/apache/geode/commit/306fda0860218e5a80f3064c55b04396e9e653d1",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 2,
                "filename": "extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "patch": "@@ -309,17 +309,18 @@ public void invalidate() {\n   }\n \n   public void processExpired() {\n-    if (((DeltaSessionManager) getManager()).getLogger().isDebugEnabled()) {\n+    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n+    if (manager != null && manager.getLogger() != null && manager.getLogger().isDebugEnabled()) {\n       ((DeltaSessionManager) getManager()).getLogger().debug(this + \": Expired\");\n     }\n+\n     // Set expired (so region.destroy is not called again)\n     setExpired(true);\n \n     // Do expire processing\n     expire();\n \n     // Update statistics\n-    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n     if (manager != null) {\n       manager.getStatistics().incSessionsExpired();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "sha": "0b9f58fa7341eb12119f1f5701e68fe41ff37620",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "changes": 54,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 43,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "patch": "@@ -35,60 +35,28 @@\n import org.junit.Before;\n import org.junit.Test;\n \n+import com.gemstone.gemfire.cache.Cache;\n import com.gemstone.gemfire.cache.Region;\n-import com.gemstone.gemfire.internal.AvailablePortHelper;\n-import com.gemstone.gemfire.modules.session.catalina.ClientServerCacheLifecycleListener;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n-import com.gemstone.gemfire.modules.session.catalina.PeerToPeerCacheLifecycleListener;\n+import com.gemstone.gemfire.test.dunit.VM;\n+import com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase;\n \n-public abstract class TestSessionsTomcat8Base {\n+public abstract class TestSessionsTomcat8Base extends JUnit4DistributedTestCase{\n \n-  private static EmbeddedTomcat8 server;\n+  protected static EmbeddedTomcat8 server;\n \n-  private static Region<String, HttpSession> region;\n+  protected static Region<String, HttpSession> region;\n \n-  private static StandardWrapper servlet;\n+  protected static StandardWrapper servlet;\n \n-  private static DeltaSessionManager sessionManager;\n+  protected static DeltaSessionManager sessionManager;\n \n-  private static int port;\n+  protected static int port;\n \n-  // Set up the servers we need\n-  public static void setupServer(DeltaSessionManager manager) throws Exception {\n-    port = AvailablePortHelper.getRandomAvailableTCPPort();\n-    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+  protected Cache cache;\n \n-    PeerToPeerCacheLifecycleListener p2pListener = new PeerToPeerCacheLifecycleListener();\n-    p2pListener.setProperty(MCAST_PORT, \"0\");\n-    p2pListener.setProperty(LOG_LEVEL, \"config\");\n-    server.addLifecycleListener(p2pListener);\n-    sessionManager = manager;\n-    sessionManager.setEnableCommitValve(true);\n-    server.getRootContext().setManager(sessionManager);\n+  protected VM vm0;\n \n-    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n-    server.startContainer();\n-\n-    /*\n-     * Can only retrieve the region once the container has started up\n-     * (and the cache has started too).\n-     */\n-    region = sessionManager.getSessionCache().getSessionRegion();\n-  }\n-\n-  @AfterClass\n-  public static void teardownClass() throws Exception {\n-    server.stopContainer();\n-  }\n-\n-  /**\n-   * Reset some data\n-   */\n-  @Before\n-  public void setup() throws Exception {\n-    sessionManager.getTheContext().setSessionTimeout(30);\n-    region.clear();\n-  }\n \n   /**\n    * Check that the basics are working",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "sha": "f8604bf9d5707134f379008d5fd3547986bd7819",
                "status": "modified"
            },
            {
                "additions": 96,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "changes": 96,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 0,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "patch": "@@ -0,0 +1,96 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*      http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package com.gemstone.gemfire.modules.session;\n+\n+import static com.gemstone.gemfire.distributed.ConfigurationProperties.*;\n+import static com.gemstone.gemfire.internal.cache.CacheServerLauncher.serverPort;\n+\n+import java.util.Properties;\n+\n+import org.junit.experimental.categories.Category;\n+\n+import com.gemstone.gemfire.cache.Cache;\n+import com.gemstone.gemfire.cache.CacheFactory;\n+import com.gemstone.gemfire.cache.client.PoolFactory;\n+import com.gemstone.gemfire.cache.client.PoolManager;\n+import com.gemstone.gemfire.cache.server.CacheServer;\n+import com.gemstone.gemfire.internal.AvailablePortHelper;\n+import com.gemstone.gemfire.internal.cache.GemFireCacheImpl;\n+import com.gemstone.gemfire.modules.session.catalina.ClientServerCacheLifecycleListener;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n+import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n+import com.gemstone.gemfire.test.dunit.Host;\n+import com.gemstone.gemfire.test.junit.categories.DistributedTest;\n+import com.gemstone.gemfire.test.junit.categories.UnitTest;\n+\n+@Category(DistributedTest.class)\n+public class Tomcat8SessionsClientServerDUnitTest extends TestSessionsTomcat8Base {\n+\n+  // Set up the session manager we need\n+  @Override\n+  public void postSetUp() throws Exception {\n+    setupServer(new Tomcat8DeltaSessionManager());\n+  }\n+\n+  @Override\n+  public void preTearDown() {\n+    vm0.invoke(() -> {\n+      GemFireCacheImpl.getInstance().getCacheServers().forEach(e -> ((CacheServer)e).stop());\n+    });\n+    server.stopContainer();\n+  }\n+\n+  // Set up the servers we need\n+  public void setupServer(DeltaSessionManager manager) throws Exception {\n+    Host host = Host.getHost(0);\n+    vm0 = host.getVM(1);\n+    String hostName = vm0.getHost().getHostName();\n+    int cacheServerPort = vm0.invoke(() -> {\n+      Properties props = new Properties();\n+      CacheFactory cf = new CacheFactory(props);\n+      Cache cache = cf.create();\n+      CacheServer server = cache.addCacheServer();\n+      server.start();\n+      return server.getPort();\n+    });\n+\n+    port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+\n+    ClientServerCacheLifecycleListener listener = new ClientServerCacheLifecycleListener();\n+    listener.setProperty(MCAST_PORT, \"0\");\n+    listener.setProperty(LOG_LEVEL, \"config\");\n+    server.addLifecycleListener(listener);\n+    sessionManager = manager;\n+    sessionManager.setEnableCommitValve(true);\n+    server.getRootContext().setManager(sessionManager);\n+\n+    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n+    server.startContainer();\n+\n+    PoolFactory pf = PoolManager.createFactory();\n+    pf.addServer(hostName, cacheServerPort);\n+    pf.create(\"Pool Connecting to Cache Server\");\n+\n+    /*\n+     * Can only retrieve the region once the container has started up\n+     * (and the cache has started too).\n+     */\n+    region = sessionManager.getSessionCache().getSessionRegion();\n+    sessionManager.getTheContext().setSessionTimeout(30);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "sha": "ca9cdbe081cf1dbd6262e209830cd7fd46fb9a3f",
                "status": "added"
            },
            {
                "additions": 77,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 0,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "patch": "@@ -0,0 +1,77 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*      http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package com.gemstone.gemfire.modules.session;\n+\n+import static com.gemstone.gemfire.distributed.ConfigurationProperties.*;\n+\n+import com.gemstone.gemfire.internal.AvailablePortHelper;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n+import com.gemstone.gemfire.modules.session.catalina.PeerToPeerCacheLifecycleListener;\n+import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n+import com.gemstone.gemfire.test.junit.categories.DistributedTest;\n+import com.gemstone.gemfire.test.junit.categories.UnitTest;\n+\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.experimental.categories.Category;\n+\n+@Category(DistributedTest.class)\n+public class Tomcat8SessionsDUnitTest extends TestSessionsTomcat8Base {\n+\n+  // Set up the session manager we need\n+  @Override\n+  public void postSetUp() throws Exception {\n+    setupServer(new Tomcat8DeltaSessionManager());\n+  }\n+\n+  @Override\n+  public void preTearDown() throws Exception {\n+    server.stopContainer();\n+  }\n+\n+  public void setupServer(DeltaSessionManager manager) throws Exception {\n+    port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+\n+    PeerToPeerCacheLifecycleListener p2pListener = new PeerToPeerCacheLifecycleListener();\n+    p2pListener.setProperty(MCAST_PORT, \"0\");\n+    p2pListener.setProperty(LOG_LEVEL, \"config\");\n+    server.addLifecycleListener(p2pListener);\n+    sessionManager = manager;\n+    sessionManager.setEnableCommitValve(true);\n+    server.getRootContext().setManager(sessionManager);\n+\n+    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n+    server.startContainer();\n+\n+    /*\n+     * Can only retrieve the region once the container has started up\n+     * (and the cache has started too).\n+     */\n+    region = sessionManager.getSessionCache().getSessionRegion();\n+  }\n+\n+  /**\n+   * Reset some data\n+   */\n+  @Before\n+  public void setup() throws Exception {\n+    sessionManager.getTheContext().setSessionTimeout(30);\n+    region.clear();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "sha": "e573c4e48aee4a1b8e6dff487a07c7b1d711af70",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/e25ba5c0879a4b8ae85116b268a82406857f7cf8/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java?ref=e25ba5c0879a4b8ae85116b268a82406857f7cf8",
                "deletions": 32,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "patch": "@@ -1,32 +0,0 @@\n-/*\n-* Licensed to the Apache Software Foundation (ASF) under one or more\n-* contributor license agreements.  See the NOTICE file distributed with\n-* this work for additional information regarding copyright ownership.\n-* The ASF licenses this file to You under the Apache License, Version 2.0\n-* (the \"License\"); you may not use this file except in compliance with\n-* the License.  You may obtain a copy of the License at\n-*\n-*      http://www.apache.org/licenses/LICENSE-2.0\n-*\n-* Unless required by applicable law or agreed to in writing, software\n-* distributed under the License is distributed on an \"AS IS\" BASIS,\n-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-* See the License for the specific language governing permissions and\n-* limitations under the License.\n-*/\n-package com.gemstone.gemfire.modules.session;\n-\n-import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n-import com.gemstone.gemfire.test.junit.categories.UnitTest;\n-import org.junit.BeforeClass;\n-import org.junit.experimental.categories.Category;\n-\n-@Category(UnitTest.class)\n-public class Tomcat8SessionsJUnitTest extends TestSessionsTomcat8Base {\n-\n-  // Set up the session manager we need\n-  @BeforeClass\n-  public static void setupClass() throws Exception {\n-    setupServer(new Tomcat8DeltaSessionManager());\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/e25ba5c0879a4b8ae85116b268a82406857f7cf8/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "sha": "df65690ee0cb1badb12cf16425aea9732bc07f07",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 3,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "patch": "@@ -90,9 +90,7 @@ public void lifecycleEvent(LifecycleTypeAdapter eventType) {\n         rebalanceCache();\n       }\n     } else if (eventType.equals(LifecycleTypeAdapter.STOP)) {\n-      // Close the cache\n-//      closeCache();\n-      // TODO: Do we need to reset the started flag here?\n+      started.set(false);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "sha": "9704853131a3de61a996abd08249339a1ef32d95",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 1,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "patch": "@@ -52,7 +52,7 @@ protected void createOrRetrieveCache() {\n \n     // If no cache exists, create one\n     String message = null;\n-    if (this.cache == null) {\n+    if (this.cache == null || this.cache.isClosed()) {\n       // enable pool subscription so that default cache can be used by hibernate module\n       this.cache = new ClientCacheFactory(createDistributedSystemProperties()).create();\n       message = \"Created \";",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "sha": "a4bd7a5af6e39d7be19d2a00da5a818534b2f5f8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 1,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "patch": "@@ -55,7 +55,7 @@ protected void createOrRetrieveCache() {\n \n     // If no cache exists, create one\n     String message = null;\n-    if (this.cache == null) {\n+    if (this.cache == null || cache.isClosed()) {\n       this.cache = new CacheFactory(createDistributedSystemProperties()).create();\n       message = \"Created \";\n     } else {",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "sha": "92c5f1fd157df0117a3b70de799ebc3426b27792",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 2,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "patch": "@@ -317,17 +317,18 @@ public void invalidate() {\n   }\n \n   public void processExpired() {\n-    if (((DeltaSessionManager) getManager()).getLogger().isDebugEnabled()) {\n+    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n+    if (manager != null && manager.getLogger() != null && manager.getLogger().isDebugEnabled()) {\n       ((DeltaSessionManager) getManager()).getLogger().debug(this + \": Expired\");\n     }\n+\n     // Set expired (so region.destroy is not called again)\n     setExpired(true);\n \n     // Do expire processing\n     expire();\n \n     // Update statistics\n-    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n     if (manager != null) {\n       manager.getStatistics().incSessionsExpired();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "sha": "754376a16e990c420cdbea7845531a90d941221f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 0,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "patch": "@@ -49,4 +49,5 @@\n   void setOwner(Object manager);\n   void activate();\n \n+  void processExpired();\n }",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "sha": "a2934328f7b0d3441186414bdecb6d78310b31ef",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java?ref=306fda0860218e5a80f3064c55b04396e9e653d1",
                "deletions": 2,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "patch": "@@ -21,6 +21,7 @@\n import com.gemstone.gemfire.cache.Operation;\n import com.gemstone.gemfire.cache.util.CacheListenerAdapter;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSession;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionInterface;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n import com.gemstone.gemfire.modules.util.ContextMapper;\n \n@@ -35,9 +36,9 @@ public void afterDestroy(EntryEvent<String, HttpSession> event) {\n     // A Session expired. If it was destroyed by GemFire expiration, process it.\n     // If it was destroyed via Session.invalidate, ignore it since it has\n     // already been processed.\n-    DeltaSession session = null;\n+    DeltaSessionInterface session = null;\n     if (event.getOperation() == Operation.EXPIRE_DESTROY) {\n-      session = (DeltaSession) event.getOldValue();\n+      session = (DeltaSessionInterface) event.getOldValue();\n     } else {\n       /*\n        * This comes into play when we're dealing with an empty client proxy. We",
                "raw_url": "https://github.com/apache/geode/raw/306fda0860218e5a80f3064c55b04396e9e653d1/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "sha": "4fd1136b8ffee750fe32789102d54ba371248ac6",
                "status": "modified"
            }
        ],
        "message": "GEODE-1675: Fix ClassCastException in ClientServer expiry\n\n* Also fix for NPE if session manager somehow is null in a session\n* Added tests for client/server session management\n* Refactored existing tests so they can share tests with client/server set up",
        "parent": "https://github.com/apache/geode/commit/e25ba5c0879a4b8ae85116b268a82406857f7cf8",
        "patched_files": [
            "AbstractCache.java",
            "DeltaSession8.java",
            "DeltaSession.java",
            "ClientServerCache.java",
            "DeltaSessionInterface.java",
            "PeerToPeerCache.java",
            "SessionExpirationCacheListener.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "Tomcat8SessionsDUnitTest.java",
            "Tomcat8SessionsJUnitTest.java",
            "TestSessionsTomcat8Base.java",
            "Tomcat8SessionsClientServerDUnitTest.java"
        ]
    },
    "geode_364ddef": {
        "bug_id": "geode_364ddef",
        "commit": "https://github.com/apache/geode/commit/364ddeff7f867133060e999db6901be78a35268d",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/364ddeff7f867133060e999db6901be78a35268d/geode-core/src/main/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOp.java?ref=364ddeff7f867133060e999db6901be78a35268d",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOp.java",
                "patch": "@@ -105,7 +105,9 @@ protected Object processResponse(Message msg) throws Exception {\n                     \"GetClientPRMetaDataOpImpl#processResponse: for bucketId : {} locations are {}\",\n                     bucketId, locations);\n               }\n-              advisor.updateBucketServerLocations(bucketId, locations, cms);\n+              if (advisor != null) {\n+                advisor.updateBucketServerLocations(bucketId, locations, cms);\n+              }\n \n               Set<ClientPartitionAdvisor> cpas =\n                   cms.getColocatedClientPartitionAdvisor(regionFullPath);",
                "raw_url": "https://github.com/apache/geode/raw/364ddeff7f867133060e999db6901be78a35268d/geode-core/src/main/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOp.java",
                "sha": "8fcf56627f7cc2e64cd3614a8d811366c7ca4328",
                "status": "modified"
            },
            {
                "additions": 50,
                "blob_url": "https://github.com/apache/geode/blob/364ddeff7f867133060e999db6901be78a35268d/geode-core/src/test/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOpJUnitTest.java",
                "changes": 50,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOpJUnitTest.java?ref=364ddeff7f867133060e999db6901be78a35268d",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOpJUnitTest.java",
                "patch": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.client.internal;\n+\n+import static org.junit.Assert.assertNull;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.doReturn;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.internal.cache.tier.MessageType;\n+import org.apache.geode.internal.cache.tier.sockets.Message;\n+\n+public class GetClientPRMetaDataOpJUnitTest {\n+  @Test\n+  public void processResponseWhenCacheClosedShuouldReturnNull() throws Exception {\n+    Cache cache = mock(Cache.class);\n+    ClientMetadataService cms = new ClientMetadataService(cache);\n+    cms = spy(cms);\n+    doReturn(true).when(cache).isClosed();\n+\n+    Message msg = mock(Message.class);\n+    GetClientPRMetaDataOp.GetClientPRMetaDataOpImpl op =\n+        new GetClientPRMetaDataOp.GetClientPRMetaDataOpImpl(\"testRegion\", cms);\n+    op = spy(op);\n+\n+    when(msg.getMessageType()).thenReturn(MessageType.RESPONSE_CLIENT_PR_METADATA);\n+\n+    assertNull(op.processResponse(msg));\n+    verify(cms, times(1)).setMetadataStable(eq(true));\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/364ddeff7f867133060e999db6901be78a35268d/geode-core/src/test/java/org/apache/geode/cache/client/internal/GetClientPRMetaDataOpJUnitTest.java",
                "sha": "a1208e589d7a3c4230be31428bab6b3c0c4ebd2f",
                "status": "added"
            }
        ],
        "message": "GEODE-6149: when client's cache is closing, its GetClientPRMetaDataOp could end up with NPE (#2952)",
        "parent": "https://github.com/apache/geode/commit/93ed36f9c9248261fdb7817da4e51f49849f876c",
        "patched_files": [
            "GetClientPRMetaDataOp.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GetClientPRMetaDataOpJUnitTest.java"
        ]
    },
    "geode_383bc54": {
        "bug_id": "geode_383bc54",
        "commit": "https://github.com/apache/geode/commit/383bc5430dbf7f06aabeacc8ea639ff5039937cf",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/383bc5430dbf7f06aabeacc8ea639ff5039937cf/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java?ref=383bc5430dbf7f06aabeacc8ea639ff5039937cf",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "patch": "@@ -262,6 +262,7 @@ public void highPriorityMessagesBypassFlowControl() throws Exception {\n \n   @Test\n   public void testMemberWeightIsSerialized() throws Exception {\n+    initMocks(false);\n     BufferDataOutputStream out =\n         new BufferDataOutputStream(500, Version.getCurrentVersion());\n     GMSMember mbr = createAddress(8888);",
                "raw_url": "https://github.com/apache/geode/raw/383bc5430dbf7f06aabeacc8ea639ff5039937cf/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "sha": "b50aa839b7bb2456790a071e2d2fd359b69f1a4a",
                "status": "modified"
            }
        ],
        "message": "fix for NPE in JGroupsMessengerJUnitTest\n\nmocks needed to be initialized in this test",
        "parent": "https://github.com/apache/geode/commit/d853adfee61bbc7d6d93ebd79a575dd93349e3c8",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "JGroupsMessengerJUnitTest.java"
        ]
    },
    "geode_3a3935f": {
        "bug_id": "geode_3a3935f",
        "commit": "https://github.com/apache/geode/commit/3a3935f8d11a3c6b75815781f6cd551584613425",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/main/java/org/apache/geode/management/internal/beans/RegionMBeanBridge.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/beans/RegionMBeanBridge.java?ref=3a3935f8d11a3c6b75815781f6cd551584613425",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/beans/RegionMBeanBridge.java",
                "patch": "@@ -145,6 +145,13 @@ protected RegionMBeanBridge(Region<K, V> region) {\n     this.regAttrs = region.getAttributes();\n \n     this.isStatisticsEnabled = regAttrs.getStatisticsEnabled();\n+    if (isStatisticsEnabled) {\n+      try {\n+        region.getStatistics();\n+      } catch (UnsupportedOperationException e) {\n+        this.isStatisticsEnabled = false;\n+      }\n+    }\n \n     this.regionAttributesData = RegionMBeanCompositeDataFactory.getRegionAttributesData(regAttrs);\n     this.membershipAttributesData =",
                "raw_url": "https://github.com/apache/geode/raw/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/main/java/org/apache/geode/management/internal/beans/RegionMBeanBridge.java",
                "sha": "93da8b42e0c383783e2606f136be72f5ffdc45e9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ShowMetricsCommandIntegrationTest.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ShowMetricsCommandIntegrationTest.java?ref=3a3935f8d11a3c6b75815781f6cd551584613425",
                "deletions": 10,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ShowMetricsCommandIntegrationTest.java",
                "patch": "@@ -45,10 +45,10 @@\n   @ClassRule\n   public static ServerStarterRule server =\n       new ServerStarterRule().withRegion(RegionShortcut.REPLICATE, REGION_NAME)\n-          .withName(MEMBER_NAME).withJMXManager().withEmbeddedLocator().withAutoStart();\n+          .withName(MEMBER_NAME).withJMXManager().withAutoStart();\n \n   @Rule\n-  public GfshCommandRule gfsh = new GfshCommandRule();\n+  public GfshCommandRule gfsh = new GfshCommandRule(server::getJmxPort, PortType.jmxManager);\n \n   @Test\n   public void everyCategoryHasAUseCase() throws Exception {\n@@ -68,6 +68,7 @@ public void everyCategoryHasAUseCase() throws Exception {\n \n   @Test\n   public void commandFailsWhenNotConnected() throws Exception {\n+    gfsh.disconnect();\n     gfsh.executeAndAssertThat(\"show metrics\")\n         .containsOutput(\"was found but is not currently available\");\n   }\n@@ -80,9 +81,7 @@ public void getRegionMetricsShowsExactlyDefaultCategories() throws Exception {\n         ShowMetricsInterceptor.getValidCategoriesAsStrings(true, true, false);\n     // Blank lines are permitted for grouping.\n     expectedCategories.add(\"\");\n-    logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n@@ -97,7 +96,6 @@ public void getSystemRegionMetricsShowsExactlyDefaultCategories() throws Excepti\n     expectedCategories.add(\"\");\n     logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n@@ -112,7 +110,6 @@ public void getMemberMetricsShowsExactlyDefaultCategories() throws Exception {\n     expectedCategories.add(\"\");\n     logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n@@ -127,7 +124,6 @@ public void getMemberWithPortMetricsShowsExactlyDefaultCategories() throws Excep\n     expectedCategories.add(\"\");\n     logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n@@ -142,7 +138,6 @@ public void getSystemMetricsShowsExactlyDefaultCategories() throws Exception {\n     expectedCategories.add(\"\");\n     logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n@@ -152,7 +147,6 @@ public void invalidCategoryGetsReported() throws Exception {\n     String cmd =\n         \"show metrics --categories=\\\"cluster,cache,some_invalid_category,another_invalid_category\\\"\";\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).containsOutput(\"Invalid Categories\")\n         .containsOutput(\"some_invalid_category\").containsOutput(\"another_invalid_category\")\n         .doesNotContainOutput(\"cache\").doesNotContainOutput(\"cluster\");\n@@ -164,8 +158,16 @@ public void categoryOptionAbridgesOutput() throws Exception {\n     List<String> expectedCategories = Arrays.asList(\"cluster\", \"cache\", \"\");\n     logger.info(\"Expecting categories: \" + String.join(\", \", expectedCategories));\n \n-    gfsh.connectAndVerify(server.getEmbeddedLocatorPort(), PortType.locator);\n     gfsh.executeAndAssertThat(cmd).tableHasColumnOnlyWithValues(\"Category\",\n         expectedCategories.toArray(new String[0]));\n   }\n+\n+  @Test\n+  public void getRegionMetricsForPartitionedRegionWithStatistics() throws Exception {\n+    String cmd = \"create region --name=region2 --type=PARTITION --enable-statistics\";\n+    gfsh.executeAndAssertThat(cmd).statusIsSuccess();\n+    String cmd2 = \"show metrics --member=\" + MEMBER_NAME + \" --region=region2\";\n+    gfsh.executeAndAssertThat(cmd2).statusIsSuccess().tableHasRowWithValues(\"Category\", \"Metric\",\n+        \"Value\", \"\", \"missCount\", \"-1\");\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ShowMetricsCommandIntegrationTest.java",
                "sha": "7bbad90a6292124a4f64c78459def0e82c45b281",
                "status": "modified"
            },
            {
                "additions": 49,
                "blob_url": "https://github.com/apache/geode/blob/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/test/java/org/apache/geode/test/junit/assertions/CommandResultAssert.java",
                "changes": 50,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/assertions/CommandResultAssert.java?ref=3a3935f8d11a3c6b75815781f6cd551584613425",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/assertions/CommandResultAssert.java",
                "patch": "@@ -17,14 +17,16 @@\n import static org.assertj.core.api.Assertions.assertThat;\n \n import java.util.Arrays;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n \n import org.assertj.core.api.AbstractAssert;\n import org.assertj.core.api.Assertions;\n import org.json.JSONArray;\n \n import org.apache.geode.management.cli.Result;\n-import org.apache.geode.management.internal.cli.json.GfJsonObject;\n+import org.apache.geode.management.internal.cli.json.GfJsonException;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n \n \n@@ -166,6 +168,52 @@ public CommandResultAssert tableHasColumnWithExactValuesInAnyOrder(String header\n     return this;\n   }\n \n+\n+\n+  public CommandResultAssert tableHasRowWithValues(String... headersThenValues)\n+      throws GfJsonException {\n+    assertThat(headersThenValues.length % 2)\n+        .describedAs(\"You need to pass even number of parameters.\").isEqualTo(0);\n+\n+    int numberOfColumn = headersThenValues.length / 2;\n+\n+    String[] headers = Arrays.copyOfRange(headersThenValues, 0, numberOfColumn);\n+    String[] expectedValues =\n+        Arrays.copyOfRange(headersThenValues, numberOfColumn, headersThenValues.length);\n+\n+    Map<String, List<Object>> allValues = new HashMap<>();\n+    int numberOfRows = -1;\n+    for (String header : headers) {\n+      List<Object> columnValues = actual.getCommandResult().getColumnValues(header);\n+      if (numberOfRows > 0) {\n+        assertThat(columnValues.size()).isEqualTo(numberOfRows);\n+      }\n+      numberOfRows = columnValues.size();\n+      allValues.put(header, columnValues);\n+    }\n+\n+    for (int rowIndex = 0; rowIndex < numberOfRows; rowIndex++) {\n+      Object[] rowValues = new Object[headers.length];\n+      for (int columnIndex = 0; columnIndex < headers.length; columnIndex++) {\n+        rowValues[columnIndex] = allValues.get(headers[columnIndex]).get(rowIndex);\n+      }\n+\n+      // check if entire row is equal, but if not, continue to next row\n+      if (Arrays.deepEquals(expectedValues, rowValues)) {\n+        return this;\n+      }\n+    }\n+\n+    // did not find any matching rows, then this would pass only if we do not pass in any values\n+    assertThat(headersThenValues.length).isEqualTo(0);\n+    return this;\n+  }\n+\n+  public CommandResultAssert tableHasRowCount(String anyColumnHeader, int rowSize) {\n+    assertThat(actual.getCommandResult().getColumnValues(anyColumnHeader)).isEqualTo(rowSize);\n+    return this;\n+  }\n+\n   /**\n    * Verifies that each of the actual values in the column with the given header contains at least\n    * one of the expectedValues.",
                "raw_url": "https://github.com/apache/geode/raw/3a3935f8d11a3c6b75815781f6cd551584613425/geode-core/src/test/java/org/apache/geode/test/junit/assertions/CommandResultAssert.java",
                "sha": "9ec2754dc204359949223ceeab490259ec80fdde",
                "status": "modified"
            }
        ],
        "message": "GEODE-2676: fix NPE with ShowMetricsCommand.",
        "parent": "https://github.com/apache/geode/commit/445b304670894a73cbe66a485539d8732d29a7c8",
        "patched_files": [
            "RegionMBeanBridge.java",
            "CommandResultAssert.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ShowMetricsCommandIntegrationTest.java"
        ]
    },
    "geode_4290946": {
        "bug_id": "geode_4290946",
        "commit": "https://github.com/apache/geode/commit/4290946d9dab98450964bbf498beea2bee650a3f",
        "file": [
            {
                "additions": 413,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionAttributesIntegrationTest.java",
                "changes": 413,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionAttributesIntegrationTest.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionAttributesIntegrationTest.java",
                "patch": "@@ -0,0 +1,413 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.EvictionAction.OVERFLOW_TO_DISK;\n+import static org.apache.geode.cache.EvictionAttributes.createLRUEntryAttributes;\n+import static org.apache.geode.cache.RegionShortcut.LOCAL;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.File;\n+import java.util.Arrays;\n+import java.util.Properties;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.TestName;\n+\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.DiskStore;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.test.junit.rules.ExecutorServiceRule;\n+\n+/**\n+ * Extracted and exploded {@code testDiskRegDWAttrbts} from {@link DiskRegionJUnitTest}.\n+ */\n+public class DiskRegionAttributesIntegrationTest {\n+\n+  private static final long MAX_OPLOG_SIZE_IN_BYTES = 1024 * 1024 * 1024 * 10L;\n+\n+  private InternalCache cache;\n+  private EvictionAttributes evictionAttributes;\n+\n+  private File[] diskDirs;\n+  private int[] diskDirSizes;\n+\n+  private String regionName;\n+  private String diskStoreName;\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  @Rule\n+  public ExecutorServiceRule executorServiceRule = new ExecutorServiceRule();\n+\n+  @Rule\n+  public RestoreSystemProperties restoreSystemProperties = new RestoreSystemProperties();\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public TestName testName = new TestName();\n+\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    String uniqueName = getClass().getSimpleName() + \"_\" + testName.getMethodName();\n+    regionName = uniqueName + \"_region\";\n+    diskStoreName = uniqueName + \"_diskStore\";\n+\n+    Properties config = new Properties();\n+    config.setProperty(MCAST_PORT, \"0\");\n+    config.setProperty(LOCATORS, \"\");\n+\n+    cache = (InternalCache) new CacheFactory(config).create();\n+\n+    diskDirs = new File[4];\n+    diskDirs[0] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"1\");\n+    diskDirs[1] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"2\");\n+    diskDirs[2] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"3\");\n+    diskDirs[3] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"4\");\n+\n+    // set default values of disk dir sizes here\n+    diskDirSizes = new int[4];\n+    diskDirSizes[0] = Integer.MAX_VALUE;\n+    diskDirSizes[1] = Integer.MAX_VALUE;\n+    diskDirSizes[2] = Integer.MAX_VALUE;\n+    diskDirSizes[3] = Integer.MAX_VALUE;\n+\n+    evictionAttributes = createLRUEntryAttributes(1000, OVERFLOW_TO_DISK);\n+\n+    DiskStoreImpl.SET_IGNORE_PREALLOCATE = true;\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (cache != null) {\n+        cache.close();\n+      }\n+    } finally {\n+      DiskStoreImpl.SET_IGNORE_PREALLOCATE = false;\n+    }\n+  }\n+\n+  @Test\n+  public void syncPersistentWithAutoCompact() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void syncPersistent() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void asyncPersistentWithAutoCompact() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void asyncPersistent() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void syncOverflowWithAutoCompact() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void syncOverflow() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void asyncOverflowWithAutoCompact() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+    diskStoreFactory.setQueueSize(10_000);\n+    diskStoreFactory.setTimeInterval(15);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 10_000, 15);\n+  }\n+\n+  @Test\n+  public void asyncOverflowWithEviction() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+    diskStoreFactory.setTimeInterval(15);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, 15);\n+  }\n+\n+  @Test\n+  public void syncPersistentWithOverflowAndAutoCompact() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void syncPersistentWithOverflow() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(true);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, -1);\n+  }\n+\n+  @Test\n+  public void asyncPersistentWithOverflowAndAutoCompactAndBuffer() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+    diskStoreFactory.setQueueSize(10_000);\n+    diskStoreFactory.setTimeInterval(15);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(true, MAX_OPLOG_SIZE_IN_BYTES, 10_000, 15);\n+  }\n+\n+  @Test\n+  public void asyncPersistentWithOverflowAndBuffer() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(false);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+    diskStoreFactory.setTimeInterval(15);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, MAX_OPLOG_SIZE_IN_BYTES);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(false);\n+    regionFactory.setEvictionAttributes(evictionAttributes);\n+\n+    Region region = regionFactory.create(regionName);\n+\n+    assertThat(region.getAttributes().isDiskSynchronous()).isEqualTo(false);\n+    verifyRegionAndDiskStoreAttributes(false, MAX_OPLOG_SIZE_IN_BYTES, 0, 15);\n+  }\n+\n+  private File createDirectory(File parentDirectory, String name) {\n+    File file = new File(parentDirectory, name);\n+    assertThat(file.mkdir()).isTrue();\n+    return file;\n+  }\n+\n+  private void createDiskStoreWithSizeInBytes(String diskStoreName,\n+      DiskStoreFactory diskStoreFactory, long maxOplogSizeInBytes) {\n+    ((DiskStoreFactoryImpl) diskStoreFactory).setMaxOplogSizeInBytes(maxOplogSizeInBytes);\n+    DirectoryHolder.SET_DIRECTORY_SIZE_IN_BYTES_FOR_TESTING_PURPOSES = true;\n+    try {\n+      diskStoreFactory.create(diskStoreName);\n+    } finally {\n+      DirectoryHolder.SET_DIRECTORY_SIZE_IN_BYTES_FOR_TESTING_PURPOSES = false;\n+    }\n+  }\n+\n+  private void verifyRegionAndDiskStoreAttributes(boolean autoCompact, long maxOplogSizeInBytes,\n+      int bytesThreshold, int timeInterval) {\n+    DiskStore diskStore = cache.findDiskStore(diskStoreName);\n+\n+    assertThat(diskStore.getAutoCompact()).isEqualTo(autoCompact);\n+\n+    int expectedDiskDirsCount = diskDirs.length;\n+    int actualDiskDirsCount = diskStore.getDiskDirs().length;\n+    assertThat(actualDiskDirsCount).isEqualTo(expectedDiskDirsCount);\n+\n+    int[] expectedDiskDirSizes = diskDirSizes;\n+    if (expectedDiskDirSizes == null) {\n+      expectedDiskDirSizes = new int[expectedDiskDirsCount];\n+      Arrays.fill(expectedDiskDirSizes, Integer.MAX_VALUE);\n+    }\n+\n+    int[] actualDiskDirSizes = diskStore.getDiskDirSizes();\n+    for (int i = 0; i < expectedDiskDirsCount; i++) {\n+      assertThat(actualDiskDirSizes[i]).isEqualTo(expectedDiskDirSizes[i]);\n+    }\n+\n+    assertThat(diskStore.getDiskUsageWarningPercentage())\n+        .isEqualTo(DiskStoreFactory.DEFAULT_DISK_USAGE_WARNING_PERCENTAGE);\n+    assertThat(diskStore.getDiskUsageCriticalPercentage())\n+        .isEqualTo(DiskStoreFactory.DEFAULT_DISK_USAGE_CRITICAL_PERCENTAGE);\n+    assertThat(diskStore.getMaxOplogSize()).isEqualTo(maxOplogSizeInBytes / (1024 * 1024));\n+    assertThat(diskStore.getQueueSize()).isEqualTo(bytesThreshold);\n+\n+    if (timeInterval != -1) {\n+      assertThat(diskStore.getTimeInterval()).isEqualTo(timeInterval);\n+    } else {\n+      assertThat(diskStore.getTimeInterval()).isEqualTo(DiskStoreFactory.DEFAULT_TIME_INTERVAL);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionAttributesIntegrationTest.java",
                "sha": "8996aacaad92c088e714a94878c8584185460a08",
                "status": "added"
            },
            {
                "additions": 189,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionCompactorCloseIntegrationTest.java",
                "changes": 189,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionCompactorCloseIntegrationTest.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionCompactorCloseIntegrationTest.java",
                "patch": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static java.util.concurrent.TimeUnit.MINUTES;\n+import static org.apache.geode.cache.RegionShortcut.LOCAL;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.test.dunit.Disconnect.disconnectAllFromDS;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.awaitility.Awaitility.await;\n+\n+import java.io.File;\n+import java.util.Arrays;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.TestName;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.DiskAccessException;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+\n+/**\n+ * Extracted {@code testCompactorClose} from {@link DiskRegionJUnitTest}.\n+ */\n+public class DiskRegionCompactorCloseIntegrationTest {\n+\n+  private final CountDownLatch beforeGoingToCompactLatch = new CountDownLatch(1);\n+  private final AtomicBoolean afterStoppingCompactor = new AtomicBoolean();\n+\n+  private final Properties config = new Properties();\n+  private Cache cache;\n+\n+  private File[] diskDirs;\n+  private int[] diskDirSizes;\n+\n+  private String uniqueName;\n+  private String regionName;\n+  private String diskStoreName;\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public TestName testName = new TestName();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    uniqueName = getClass().getSimpleName() + \"_\" + testName.getMethodName();\n+    regionName = uniqueName + \"_region\";\n+    diskStoreName = uniqueName + \"_diskStore\";\n+\n+    config.setProperty(MCAST_PORT, \"0\");\n+    config.setProperty(LOCATORS, \"\");\n+\n+    cache = new CacheFactory(config).create();\n+\n+    diskDirs = new File[4];\n+    diskDirs[0] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"1\");\n+    diskDirs[1] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"2\");\n+    diskDirs[2] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"3\");\n+    diskDirs[3] = createDirectory(temporaryFolder.getRoot(), testName.getMethodName() + \"4\");\n+\n+    diskDirSizes = new int[4];\n+    Arrays.fill(diskDirSizes, Integer.MAX_VALUE);\n+\n+    DiskStoreImpl.SET_IGNORE_PREALLOCATE = true;\n+    LocalRegion.ISSUE_CALLBACKS_TO_CACHE_OBSERVER = true;\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      beforeGoingToCompactLatch.countDown();\n+      cache.close();\n+    } finally {\n+      CacheObserverHolder.setInstance(null);\n+      DiskStoreImpl.SET_IGNORE_PREALLOCATE = false;\n+      LocalRegion.ISSUE_CALLBACKS_TO_CACHE_OBSERVER = false;\n+      disconnectAllFromDS();\n+    }\n+  }\n+\n+  @Test\n+  public void testCompactorClose() {\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setAutoCompact(true);\n+    diskStoreFactory.setCompactionThreshold(100);\n+    diskStoreFactory.setDiskDirsAndSizes(diskDirs, diskDirSizes);\n+\n+    createDiskStoreWithSizeInBytes(diskStoreName, diskStoreFactory, 100);\n+\n+    RegionFactory<Object, Object> regionFactory = cache.createRegionFactory(LOCAL);\n+    regionFactory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+    regionFactory.setDiskStoreName(diskStoreName);\n+    regionFactory.setDiskSynchronous(true);\n+\n+    Region<Object, Object> region = regionFactory.create(regionName);\n+\n+    CacheObserverHolder.setInstance(new CompactorCacheObserver(region));\n+\n+    for (int i = 0; i < 10; ++i) {\n+      region.put(i, new byte[10]);\n+    }\n+\n+    beforeGoingToCompactLatch.countDown();\n+\n+    await().atMost(5, MINUTES).untilAsserted(() -> assertThat(afterStoppingCompactor).isTrue());\n+\n+    assertThat(region.isDestroyed()).isTrue();\n+  }\n+\n+  private File createDirectory(File parentDirectory, String name) {\n+    File file = new File(parentDirectory, name);\n+    assertThat(file.mkdir()).isTrue();\n+    return file;\n+  }\n+\n+  private void createDiskStoreWithSizeInBytes(String diskStoreName,\n+      DiskStoreFactory diskStoreFactory,\n+      long maxOplogSizeInBytes) {\n+    ((DiskStoreFactoryImpl) diskStoreFactory).setMaxOplogSizeInBytes(maxOplogSizeInBytes);\n+    DirectoryHolder.SET_DIRECTORY_SIZE_IN_BYTES_FOR_TESTING_PURPOSES = true;\n+    try {\n+      diskStoreFactory.create(diskStoreName);\n+    } finally {\n+      DirectoryHolder.SET_DIRECTORY_SIZE_IN_BYTES_FOR_TESTING_PURPOSES = false;\n+    }\n+  }\n+\n+  private class CompactorCacheObserver extends CacheObserverAdapter {\n+\n+    private final Region<?, ?> region;\n+\n+    CompactorCacheObserver(Region<?, ?> region) {\n+      this.region = region;\n+    }\n+\n+    @Override\n+    public void beforeGoingToCompact() {\n+      try {\n+        beforeGoingToCompactLatch.await(5, MINUTES);\n+      } catch (Exception e) {\n+        errorCollector.addError(e);\n+      }\n+    }\n+\n+    @Override\n+    public void beforeDeletingCompactedOplog(Oplog compactedOplog) {\n+      // compactor will attempt to destroy the region\n+      throw new DiskAccessException(uniqueName + \"_IGNORE_EXCEPTION\", region);\n+    }\n+\n+    @Override\n+    public void afterStoppingCompactor() {\n+      // compactor destroyed the region and stopped\n+      afterStoppingCompactor.set(true);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionCompactorCloseIntegrationTest.java",
                "sha": "e2af22d4136390f7de31be109c411897bcdf1270",
                "status": "added"
            },
            {
                "additions": 1934,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionJUnitTest.java",
                "changes": 4040,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionJUnitTest.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 2106,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/DiskRegionJUnitTest.java",
                "sha": "af60aca498efb0c3f81d3920a2383310bdff6ec0",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "patch": "@@ -1793,6 +1793,11 @@ public InternalCache getGemFireCache() {\n     return this.cache;\n   }\n \n+  @Override\n+  public InternalCache getInternalCache() {\n+    return cache;\n+  }\n+\n   @Override\n   public RegionSnapshotService getSnapshotService() {\n     return new RegionSnapshotServiceImpl(this);",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "sha": "c313c830ee6c20af0a92c8f8c5276f3b8a5347cc",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/InternalPersistentRegion.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InternalPersistentRegion.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InternalPersistentRegion.java",
                "patch": "@@ -0,0 +1,25 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import org.apache.geode.cache.EntryNotFoundException;\n+import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n+\n+public interface InternalPersistentRegion extends InternalRegion, DiskRecoveryStore {\n+\n+  Object getValueOnDiskOrBuffer(Object key) throws EntryNotFoundException;\n+}",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/InternalPersistentRegion.java",
                "sha": "7989cf0a9724e5aefe31e0ab39ff40839d9f43b3",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "patch": "@@ -410,4 +410,5 @@ default void handleWANEvent(EntryEventImpl event) {}\n \n   MemoryThresholdInfo getAtomicThresholdInfo();\n \n+  InternalCache getInternalCache();\n }",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/InternalRegion.java",
                "sha": "d21d1304663ac141f4ae49156053f3cd757ca82c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java?ref=4290946d9dab98450964bbf498beea2bee650a3f",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "patch": "@@ -185,7 +185,6 @@\n import org.apache.geode.internal.cache.partitioned.RedundancyAlreadyMetException;\n import org.apache.geode.internal.cache.persistence.DefaultDiskDirs;\n import org.apache.geode.internal.cache.persistence.DiskExceptionHandler;\n-import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n import org.apache.geode.internal.cache.persistence.DiskRegionView;\n import org.apache.geode.internal.cache.persistence.PersistentMemberID;\n import org.apache.geode.internal.cache.persistence.query.IndexMap;\n@@ -233,7 +232,7 @@\n  */\n @SuppressWarnings(\"deprecation\")\n public class LocalRegion extends AbstractRegion implements LoaderHelperFactory,\n-    ResourceListener<MemoryEvent>, DiskExceptionHandler, DiskRecoveryStore {\n+    ResourceListener<MemoryEvent>, DiskExceptionHandler, InternalPersistentRegion {\n \n   // package-private to avoid synthetic accessor\n   static final Logger logger = LogService.getLogger();",
                "raw_url": "https://github.com/apache/geode/raw/4290946d9dab98450964bbf498beea2bee650a3f/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "sha": "d6ce8a285268ada3cb26d8d72731aebb8a7ce5f5",
                "status": "modified"
            }
        ],
        "message": "GEODE-4273: overhaul DiskRegionJUnitTest (#2449)\n\n* Remove use of base class\r\n* Extract testCompactorClose to DiskRegionCompactorCloseIntegrationTest\r\n* Extract testDiskRegDWAttrbts to DiskRegionAttributesIntegrationTest\r\n* GEODE-3900: Use TemporaryFolder for all disk dirs and files\r\n* Ensure Cache and DS have proper tearDown\r\n* Use Rules, Awaitility, and AssertJ\r\n* Use CountDownLatch instead of verbose synchronization tricks\r\n* Minimize usage of non-User APIs\r\n* Fix usage of deprecated APIs\r\n* Use proper variable names\r\n* Use MAX_OPLOG_SIZE_IN_BYTES instead of literal value\r\n* Protect AtomicReferences with Awaitility to prevent NPEs",
        "parent": "https://github.com/apache/geode/commit/d9bb24d95bd7d310ae0ce693fe1d84774c2f521c",
        "patched_files": [
            "LocalRegion.java",
            "InternalPersistentRegion.java",
            "AbstractRegion.java",
            "InternalRegion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "DiskRegionAttributesIntegrationTest.java",
            "DiskRegionJUnitTest.java",
            "DiskRegionCompactorCloseIntegrationTest.java",
            "AbstractRegionTest.java"
        ]
    },
    "geode_44643a8": {
        "bug_id": "geode_44643a8",
        "commit": "https://github.com/apache/geode/commit/44643a86a3b2cc254703e6fc460fa09fdf790e8a",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/main/java/org/apache/geode/cache/query/internal/ResultsCollectionPdxDeserializerWrapper.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/query/internal/ResultsCollectionPdxDeserializerWrapper.java?ref=44643a86a3b2cc254703e6fc460fa09fdf790e8a",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/query/internal/ResultsCollectionPdxDeserializerWrapper.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashSet;\n import java.util.Iterator;\n import java.util.List;\n@@ -45,6 +46,9 @@ public ResultsCollectionPdxDeserializerWrapper(SelectResults results, boolean co\n \n   @Override\n   public Iterator iterator() {\n+    if (results == null) {\n+      return new SelectResultsPdxInstanceIterator(Collections.emptyIterator());\n+    }\n     return new SelectResultsPdxInstanceIterator(results.iterator());\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/main/java/org/apache/geode/cache/query/internal/ResultsCollectionPdxDeserializerWrapper.java",
                "sha": "23092519b1bfb424de3155c3d22a19753ae17c53",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/geode/blob/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/test/java/org/apache/geode/cache/query/PdxStringQueryJUnitTest.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/PdxStringQueryJUnitTest.java?ref=44643a86a3b2cc254703e6fc460fa09fdf790e8a",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/PdxStringQueryJUnitTest.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n \n@@ -34,6 +35,8 @@\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.query.internal.QueryObserver;\n+import org.apache.geode.cache.query.internal.ResultsCollectionPdxDeserializerWrapper;\n+import org.apache.geode.cache.query.internal.ResultsSet;\n import org.apache.geode.cache.query.internal.index.CompactRangeIndex;\n import org.apache.geode.cache.query.internal.index.IndexStore.IndexStoreEntry;\n import org.apache.geode.cache.query.internal.index.PrimaryKeyIndex;\n@@ -262,6 +265,17 @@ public void testStringMethods() throws Exception {\n     region.clear();\n   }\n \n+  @Test\n+  public void testPdxResultsCollector() {\n+    SelectResults<Struct> sr1 = new ResultsCollectionPdxDeserializerWrapper();\n+    assertNotNull(sr1.asList());\n+\n+    SelectResults<Struct> sr2 =\n+        new ResultsCollectionPdxDeserializerWrapper(new ResultsSet(), false);\n+    assertNotNull(sr2.asList());\n+\n+  }\n+\n   private void putPdxInstances() throws Exception {\n     PdxInstanceFactory pf = PdxInstanceFactoryImpl.newCreator(\"Portfolio\", false, this.cache);\n     pf.writeInt(\"ID\", 111);",
                "raw_url": "https://github.com/apache/geode/raw/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/test/java/org/apache/geode/cache/query/PdxStringQueryJUnitTest.java",
                "sha": "9c9619c1218abee22420f6340576ae42523ba4d9",
                "status": "modified"
            },
            {
                "additions": 51,
                "blob_url": "https://github.com/apache/geode/blob/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/test/java/org/apache/geode/cache/query/dunit/PdxQueryDUnitTest.java",
                "changes": 51,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/dunit/PdxQueryDUnitTest.java?ref=44643a86a3b2cc254703e6fc460fa09fdf790e8a",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/dunit/PdxQueryDUnitTest.java",
                "patch": "@@ -3555,4 +3555,55 @@ public void run2() throws CacheException {\n     this.closeClient(vm1);\n     this.closeClient(vm0);\n   }\n+\n+  /**\n+   * Test Aggregate queries on Pdx instances\n+   */\n+\n+  @Test\n+  public void testAggregateQueries() {\n+    VM vm0 = VM.getVM(0);\n+    VM vm1 = VM.getVM(1);\n+    VM vm2 = VM.getVM(2);\n+\n+    final int port0 = vm0.invoke(() -> {\n+      configAndStartBridgeServer();\n+      Region region = getRootRegion().getSubregion(regionName);\n+      for (int i = 0; i < 10; i++) {\n+        region.put(\"key-\" + i, new TestObject(i, \"val-\" + i));\n+      }\n+      return getCacheServerPort();\n+    });\n+\n+    final int port1 = vm1.invoke(() -> {\n+      configAndStartBridgeServer();\n+      return getCacheServerPort();\n+    });\n+\n+    final String host0 = NetworkUtils.getServerHostName();\n+\n+    final String poolName = \"testClientServerQueryPool\";\n+    createPool(vm2, poolName, new String[] {host0}, new int[] {port1}, true);\n+\n+    vm2.invoke(() -> {\n+      QueryService queryService = PoolManager.find(poolName).getQueryService();\n+      Query query = queryService.newQuery(\"select SUM(price) from \" + regName + \" where id > 0\");\n+      SelectResults<Object> selectResults = (SelectResults) query.execute();\n+      assertEquals(1, selectResults.size());\n+      assertEquals(45, selectResults.asList().get(0));\n+    });\n+\n+    vm2.invoke(() -> {\n+      QueryService queryService = PoolManager.find(poolName).getQueryService();\n+      Query query = queryService.newQuery(\"select SUM(price) from \" + regName + \" where id > 9\");\n+      SelectResults<Long> selectResults = (SelectResults) query.execute();\n+      assertEquals(0, selectResults.size());\n+      assertEquals(0, selectResults.asList().size());\n+    });\n+\n+    this.closeClient(vm0);\n+    this.closeClient(vm1);\n+    this.closeClient(vm2);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/44643a86a3b2cc254703e6fc460fa09fdf790e8a/geode-core/src/test/java/org/apache/geode/cache/query/dunit/PdxQueryDUnitTest.java",
                "sha": "7f520837aae54b07d6b485fc984c89c09926d7c8",
                "status": "modified"
            }
        ],
        "message": "GEODE-5290: Fixes NPE with ResultsCollectionPdxDeserializerWrapper iterator (#2027)\n\nCo-authored-by: gesterzhou <gzhou@pivotal.io>\r\nCo-authored-by: nabarunnag <nag@cs.wisc.edu>",
        "parent": "https://github.com/apache/geode/commit/f7fb7e3c659f90af7ee809cbe6e426491691cd76",
        "patched_files": [
            "ResultsCollectionPdxDeserializerWrapper.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PdxQueryDUnitTest.java",
            "PdxStringQueryJUnitTest.java"
        ]
    },
    "geode_501bd79": {
        "bug_id": "geode_501bd79",
        "commit": "https://github.com/apache/geode/commit/501bd79a8bc161649df4e3113c27b0093faab45d",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Failure.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Failure.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 6,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Failure.java",
                "patch": "@@ -17,23 +17,23 @@\n import java.util.function.Function;\n \n import org.apache.geode.annotations.Experimental;\n-import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n+import org.apache.geode.internal.protocol.protobuf.ClientProtocol;\n \n @Experimental\n public class Failure<SuccessType> implements Result<SuccessType> {\n-  private final BasicTypes.ErrorResponse errorResponse;\n+  private final ClientProtocol.ErrorResponse errorResponse;\n \n-  public Failure(BasicTypes.ErrorResponse errorResponse) {\n+  public Failure(ClientProtocol.ErrorResponse errorResponse) {\n     this.errorResponse = errorResponse;\n   }\n \n-  public static <T> Failure<T> of(BasicTypes.ErrorResponse errorResponse) {\n+  public static <T> Failure<T> of(ClientProtocol.ErrorResponse errorResponse) {\n     return new Failure<>(errorResponse);\n   }\n \n   @Override\n   public <T> T map(Function<SuccessType, T> successFunction,\n-      Function<BasicTypes.ErrorResponse, T> errorFunction) {\n+      Function<ClientProtocol.ErrorResponse, T> errorFunction) {\n     return errorFunction.apply(errorResponse);\n   }\n \n@@ -43,7 +43,7 @@ public SuccessType getMessage() {\n   }\n \n   @Override\n-  public BasicTypes.ErrorResponse getErrorMessage() {\n+  public ClientProtocol.ErrorResponse getErrorMessage() {\n     return errorResponse;\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Failure.java",
                "sha": "e1595dc48d6fa64466c5a98824252875be482336",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/OperationContext.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/OperationContext.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 4,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/OperationContext.java",
                "patch": "@@ -18,7 +18,6 @@\n import java.util.function.Function;\n \n import org.apache.geode.annotations.Experimental;\n-import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n import org.apache.geode.internal.protocol.protobuf.ClientProtocol;\n import org.apache.geode.protocol.operations.OperationHandler;\n import org.apache.geode.security.ResourcePermission;\n@@ -28,7 +27,7 @@\n   private final OperationHandler<OperationRequest, OperationResponse> operationHandler;\n   private final Function<ClientProtocol.Request, OperationRequest> fromRequest;\n   private final Function<OperationResponse, ClientProtocol.Response.Builder> toResponse;\n-  private final Function<BasicTypes.ErrorResponse, ClientProtocol.Response.Builder> toErrorResponse;\n+  private final Function<ClientProtocol.ErrorResponse, ClientProtocol.Response.Builder> toErrorResponse;\n   private final ResourcePermission accessPermissionRequired;\n \n   public OperationContext(Function<ClientProtocol.Request, OperationRequest> fromRequest,\n@@ -43,7 +42,7 @@ public OperationContext(Function<ClientProtocol.Request, OperationRequest> fromR\n   }\n \n   public static ClientProtocol.Response.Builder makeErrorBuilder(\n-      BasicTypes.ErrorResponse errorResponse) {\n+      ClientProtocol.ErrorResponse errorResponse) {\n     return ClientProtocol.Response.newBuilder().setErrorResponse(errorResponse);\n   }\n \n@@ -59,7 +58,7 @@ public OperationContext(Function<ClientProtocol.Request, OperationRequest> fromR\n     return toResponse;\n   }\n \n-  public Function<BasicTypes.ErrorResponse, ClientProtocol.Response.Builder> getToErrorResponse() {\n+  public Function<ClientProtocol.ErrorResponse, ClientProtocol.Response.Builder> getToErrorResponse() {\n     return toErrorResponse;\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/OperationContext.java",
                "sha": "1b04e54bf77b0852d085d29a0a99e4f98dd77697",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/ProtocolErrorCode.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/ProtocolErrorCode.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 0,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/ProtocolErrorCode.java",
                "patch": "@@ -24,6 +24,7 @@\n   UNAUTHORIZED_REQUEST(1202),\n   LOW_MEMORY(1300),\n   DATA_UNREACHABLE(1301),\n+  OPERATION_TIMEOUT(1302),\n   CONSTRAINT_VIOLATION(2000),\n   BAD_QUERY(2001),\n   REGION_NOT_FOUND(2100),",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/ProtocolErrorCode.java",
                "sha": "e6f6ac1b422e9f817a5b84dfb418dba22083c3af",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Result.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Result.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 3,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Result.java",
                "patch": "@@ -17,14 +17,14 @@\n import java.util.function.Function;\n \n import org.apache.geode.annotations.Experimental;\n-import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n+import org.apache.geode.internal.protocol.protobuf.ClientProtocol;\n \n @Experimental\n public interface Result<SuccessType> {\n   <T> T map(Function<SuccessType, T> successFunction,\n-      Function<BasicTypes.ErrorResponse, T> errorFunction);\n+      Function<ClientProtocol.ErrorResponse, T> errorFunction);\n \n   SuccessType getMessage();\n \n-  BasicTypes.ErrorResponse getErrorMessage();\n+  ClientProtocol.ErrorResponse getErrorMessage();\n }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Result.java",
                "sha": "f0c3b32068bc906d73f0741809913067402d4838",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Success.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Success.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 3,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Success.java",
                "patch": "@@ -17,7 +17,7 @@\n import java.util.function.Function;\n \n import org.apache.geode.annotations.Experimental;\n-import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n+import org.apache.geode.internal.protocol.protobuf.ClientProtocol;\n \n @Experimental\n public class Success<SuccessType> implements Result<SuccessType> {\n@@ -33,7 +33,7 @@ public Success(SuccessType successResponse) {\n \n   @Override\n   public <T> T map(Function<SuccessType, T> successFunction,\n-      Function<BasicTypes.ErrorResponse, T> errorFunction) {\n+      Function<ClientProtocol.ErrorResponse, T> errorFunction) {\n     return successFunction.apply(successResponse);\n   }\n \n@@ -43,7 +43,7 @@ public SuccessType getMessage() {\n   }\n \n   @Override\n-  public BasicTypes.ErrorResponse getErrorMessage() {\n+  public ClientProtocol.ErrorResponse getErrorMessage() {\n     throw new RuntimeException(\"This is a not Failure result\");\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/Success.java",
                "sha": "0d3895bd25ddbb566713b7a80b1fbb917d9b301c",
                "status": "modified"
            },
            {
                "additions": 53,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandler.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandler.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 24,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandler.java",
                "patch": "@@ -14,14 +14,13 @@\n  */\n package org.apache.geode.protocol.protobuf.operations;\n \n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.Set;\n-\n import org.apache.geode.annotations.Experimental;\n+import org.apache.geode.cache.CacheLoaderException;\n+import org.apache.geode.cache.PartitionedRegionStorageException;\n import org.apache.geode.cache.Region;\n-import org.apache.geode.internal.cache.tier.sockets.MessageExecutionContext;\n+import org.apache.geode.cache.TimeoutException;\n import org.apache.geode.internal.cache.tier.sockets.InvalidExecutionContextException;\n+import org.apache.geode.internal.cache.tier.sockets.MessageExecutionContext;\n import org.apache.geode.protocol.operations.OperationHandler;\n import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n import org.apache.geode.protocol.protobuf.Failure;\n@@ -35,6 +34,10 @@\n import org.apache.geode.serialization.exception.UnsupportedEncodingTypeException;\n import org.apache.geode.serialization.registry.exception.CodecNotRegisteredForTypeException;\n \n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n @Experimental\n public class GetAllRequestOperationHandler\n     implements OperationHandler<RegionAPI.GetAllRequest, RegionAPI.GetAllResponse> {\n@@ -50,26 +53,52 @@\n           .makeErrorResponse(ProtocolErrorCode.REGION_NOT_FOUND.codeValue, \"Region not found\"));\n     }\n \n-    try {\n-      Set<Object> keys = new HashSet<>();\n-      for (BasicTypes.EncodedValue key : request.getKeyList()) {\n-        keys.add(ProtobufUtilities.decodeValue(serializationService, key));\n-      }\n-      Map<?, ?> results = region.getAll(keys);\n-      Set<BasicTypes.Entry> entries = new HashSet<>();\n-      for (Map.Entry entry : results.entrySet()) {\n-        entries.add(\n-            ProtobufUtilities.createEntry(serializationService, entry.getKey(), entry.getValue()));\n-      }\n-      return Success.of(RegionAPI.GetAllResponse.newBuilder().addAllEntries(entries).build());\n-    } catch (UnsupportedEncodingTypeException ex) {\n-      return Failure.of(ProtobufResponseUtilities.makeErrorResponse(\n-          ProtocolErrorCode.VALUE_ENCODING_ERROR.codeValue, \"Encoding not supported.\"));\n-    } catch (CodecNotRegisteredForTypeException ex) {\n-      return Failure.of(ProtobufResponseUtilities.makeErrorResponse(\n-          ProtocolErrorCode.VALUE_ENCODING_ERROR.codeValue,\n-          \"Codec error in protobuf deserialization.\"));\n+    Map<Boolean, List<Object>> resultsCollection = request.getKeyList().stream()\n+        .map((key) -> processOneMessage(serializationService, region, key))\n+        .collect(Collectors.partitioningBy(x -> x instanceof BasicTypes.Entry));\n+    RegionAPI.GetAllResponse.Builder responseBuilder = RegionAPI.GetAllResponse.newBuilder();\n+\n+    for (Object entry : resultsCollection.get(true)) {\n+      responseBuilder.addEntries((BasicTypes.Entry) entry);\n+    }\n+\n+    for (Object entry : resultsCollection.get(false)) {\n+      responseBuilder.addFailures((BasicTypes.KeyedError) entry);\n     }\n+\n+    return Success.of(responseBuilder.build());\n   }\n \n+  private Object processOneMessage(SerializationService serializationService, Region region,\n+      BasicTypes.EncodedValue key) {\n+    try {\n+      Object decodedKey = ProtobufUtilities.decodeValue(serializationService, key);\n+      Object value = region.get(decodedKey);\n+      return ProtobufUtilities.createEntry(serializationService, decodedKey, value);\n+    } catch (CodecNotRegisteredForTypeException | UnsupportedEncodingTypeException ex) {\n+      return BasicTypes.KeyedError.newBuilder().setKey(key)\n+          .setError(BasicTypes.Error.newBuilder()\n+              .setErrorCode(ProtocolErrorCode.VALUE_ENCODING_ERROR.codeValue)\n+              .setMessage(\"Encoding not supported.\"))\n+          .build();\n+    } catch (org.apache.geode.distributed.LeaseExpiredException | TimeoutException e) {\n+      return BasicTypes.KeyedError.newBuilder().setKey(key)\n+          .setError(BasicTypes.Error.newBuilder()\n+              .setErrorCode(ProtocolErrorCode.OPERATION_TIMEOUT.codeValue)\n+              .setMessage(\"Operation timed out: \" + e.getMessage()))\n+          .build();\n+    } catch (CacheLoaderException | PartitionedRegionStorageException e) {\n+      return BasicTypes.KeyedError.newBuilder().setKey(key)\n+          .setError(BasicTypes.Error.newBuilder()\n+              .setErrorCode(ProtocolErrorCode.DATA_UNREACHABLE.codeValue)\n+              .setMessage(\"Data unreachable: \" + e.getMessage()))\n+          .build();\n+    } catch (NullPointerException | IllegalArgumentException e) {\n+      return BasicTypes.KeyedError.newBuilder().setKey(key)\n+          .setError(BasicTypes.Error.newBuilder()\n+              .setErrorCode(ProtocolErrorCode.CONSTRAINT_VIOLATION.codeValue)\n+              .setMessage(\"Invalid input: \" + e.getMessage()))\n+          .build();\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandler.java",
                "sha": "4f8ca70a0cc8fd379410e639ef13d7b403da528b",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandler.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandler.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 4,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandler.java",
                "patch": "@@ -61,8 +61,8 @@\n     return Success.of(builder.build());\n   }\n \n-  private BasicTypes.KeyedErrorResponse singlePut(SerializationService serializationService,\n-      Region region, BasicTypes.Entry entry) {\n+  private BasicTypes.KeyedError singlePut(SerializationService serializationService, Region region,\n+      BasicTypes.Entry entry) {\n     try {\n       Object decodedValue = ProtobufUtilities.decodeValue(serializationService, entry.getValue());\n       Object decodedKey = ProtobufUtilities.decodeValue(serializationService, entry.getKey());\n@@ -81,11 +81,11 @@\n     return null;\n   }\n \n-  private BasicTypes.KeyedErrorResponse buildAndLogKeyedError(BasicTypes.Entry entry,\n+  private BasicTypes.KeyedError buildAndLogKeyedError(BasicTypes.Entry entry,\n       ProtocolErrorCode errorCode, String message, Exception ex) {\n     logger.error(message, ex);\n \n-    return BasicTypes.KeyedErrorResponse.newBuilder().setKey(entry.getKey())\n+    return BasicTypes.KeyedError.newBuilder().setKey(entry.getKey())\n         .setError(\n             BasicTypes.Error.newBuilder().setErrorCode(errorCode.codeValue).setMessage(message))\n         .build();",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandler.java",
                "sha": "118f6aa7c1e53a687d152616ceb4afed1f8a7354",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufResponseUtilities.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufResponseUtilities.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 6,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufResponseUtilities.java",
                "patch": "@@ -21,8 +21,9 @@\n import org.apache.geode.annotations.Experimental;\n import org.apache.geode.cache.Region;\n import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n-import org.apache.geode.protocol.protobuf.ProtocolErrorCode;\n+import org.apache.geode.internal.protocol.protobuf.ClientProtocol;\n import org.apache.geode.internal.protocol.protobuf.RegionAPI;\n+import org.apache.geode.protocol.protobuf.ProtocolErrorCode;\n \n \n /**\n@@ -35,15 +36,15 @@\n public abstract class ProtobufResponseUtilities {\n \n   /**\n-   * This creates response object containing a BasicTypes.ErrorResponse, and also logs the passed\n-   * error message and exception (if present) to the provided logger.\n+   * This creates response object containing a ClientProtocol.ErrorResponse, and also logs the\n+   * passed error message and exception (if present) to the provided logger.\n    *\n    * @param errorMessage - description of the error\n    * @param logger - logger to write the error message to\n    * @param ex - exception which should be logged\n    * @return An error response containing the first three parameters.\n    */\n-  public static BasicTypes.ErrorResponse createAndLogErrorResponse(ProtocolErrorCode errorCode,\n+  public static ClientProtocol.ErrorResponse createAndLogErrorResponse(ProtocolErrorCode errorCode,\n       String errorMessage, Logger logger, Exception ex) {\n     if (ex != null) {\n       logger.error(errorMessage, ex);\n@@ -69,8 +70,8 @@\n     return builder.build();\n   }\n \n-  public static BasicTypes.ErrorResponse makeErrorResponse(int errorCode, String message) {\n-    return BasicTypes.ErrorResponse.newBuilder()\n+  public static ClientProtocol.ErrorResponse makeErrorResponse(int errorCode, String message) {\n+    return ClientProtocol.ErrorResponse.newBuilder()\n         .setError(BasicTypes.Error.newBuilder().setErrorCode(errorCode).setMessage(message))\n         .build();\n   }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufResponseUtilities.java",
                "sha": "26e89723b1fed9d9bd07f76f6487b42f13c79d90",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufUtilities.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufUtilities.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 1,
                "filename": "geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufUtilities.java",
                "patch": "@@ -83,7 +83,10 @@\n   }\n \n   /**\n-   * Creates a protobuf key,value pair from unencoded data\n+   * Creates a protobuf (key, value) pair from unencoded data. if the value is null, it will be\n+   * unset in the {@link BasicTypes.Entry}.\n+   *\n+   * The key MUST NOT be null.\n    *\n    * @param serializationService - object which knows how to encode objects for the protobuf\n    *        protocol {@link ProtobufSerializationService}\n@@ -98,6 +101,10 @@\n   public static BasicTypes.Entry createEntry(SerializationService serializationService,\n       Object unencodedKey, Object unencodedValue)\n       throws UnsupportedEncodingTypeException, CodecNotRegisteredForTypeException {\n+    if (unencodedValue == null) {\n+      return BasicTypes.Entry.newBuilder()\n+          .setKey(createEncodedValue(serializationService, unencodedKey)).build();\n+    }\n     return createEntry(createEncodedValue(serializationService, unencodedKey),\n         createEncodedValue(serializationService, unencodedValue));\n   }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/java/org/apache/geode/protocol/protobuf/utilities/ProtobufUtilities.java",
                "sha": "4da87238780115c3ed6f131a13efa44dce2cf57c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/basicTypes.proto",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/proto/basicTypes.proto?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 5,
                "filename": "geode-protobuf/src/main/proto/basicTypes.proto",
                "patch": "@@ -82,11 +82,7 @@ message Error {\n     string message = 2;\n }\n \n-message ErrorResponse {\n-    Error error = 1;\n-}\n-\n-message KeyedErrorResponse {\n+message KeyedError {\n     EncodedValue key = 1;\n     Error error = 2;\n }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/basicTypes.proto",
                "sha": "9bd68ed4b51c306d462722de16bb286727aca5fa",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/clientProtocol.proto",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/proto/clientProtocol.proto?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 0,
                "filename": "geode-protobuf/src/main/proto/clientProtocol.proto",
                "patch": "@@ -83,4 +83,8 @@ message Response {\n message MetaData {\n     int32 numberOfMetadata = 1;\n     map<int32, google.protobuf.Any> metaDataEntries = 2;\n+}\n+\n+message ErrorResponse {\n+    Error error = 1;\n }\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/clientProtocol.proto",
                "sha": "434fdd6391bd0fb4dcc118c49afd0d0bab956d88",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/region_API.proto",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/main/proto/region_API.proto?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 1,
                "filename": "geode-protobuf/src/main/proto/region_API.proto",
                "patch": "@@ -47,7 +47,7 @@ message PutAllRequest {\n }\n \n message PutAllResponse {\n-    repeated KeyedErrorResponse failedKeys = 1;\n+    repeated KeyedError failedKeys = 1;\n }\n \n message GetAllRequest {\n@@ -58,6 +58,7 @@ message GetAllRequest {\n \n message GetAllResponse {\n     repeated Entry entries = 1;\n+    repeated KeyedError failures = 2;\n }\n \n message RemoveRequest {",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/main/proto/region_API.proto",
                "sha": "9792b62e04749395a94c7e1c051967b697b94794",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/RoundTripCacheConnectionJUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/test/java/org/apache/geode/protocol/RoundTripCacheConnectionJUnitTest.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 1,
                "filename": "geode-protobuf/src/test/java/org/apache/geode/protocol/RoundTripCacheConnectionJUnitTest.java",
                "patch": "@@ -397,7 +397,7 @@ private void validatePutAllResponse(Socket socket,\n     assertEquals(expectedFailedKeys.size(), response.getPutAllResponse().getFailedKeysCount());\n \n     Stream<BasicTypes.EncodedValue> failedKeyStream = response.getPutAllResponse()\n-        .getFailedKeysList().stream().map(BasicTypes.KeyedErrorResponse::getKey);\n+        .getFailedKeysList().stream().map(BasicTypes.KeyedError::getKey);\n     assertTrue(failedKeyStream.allMatch(expectedFailedKeys::contains));\n \n   }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/RoundTripCacheConnectionJUnitTest.java",
                "sha": "9819a4daddda86465d2992048052b11b95132288",
                "status": "modified"
            },
            {
                "additions": 76,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandlerJUnitTest.java",
                "changes": 106,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandlerJUnitTest.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 30,
                "filename": "geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandlerJUnitTest.java",
                "patch": "@@ -14,7 +14,12 @@\n  */\n package org.apache.geode.protocol.protobuf.operations;\n \n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.when;\n \n import java.util.HashMap;\n@@ -26,9 +31,10 @@\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n+import org.apache.geode.cache.CacheLoaderException;\n import org.apache.geode.cache.Region;\n-import org.apache.geode.internal.cache.tier.sockets.MessageExecutionContext;\n import org.apache.geode.internal.cache.tier.sockets.InvalidExecutionContextException;\n+import org.apache.geode.internal.cache.tier.sockets.MessageExecutionContext;\n import org.apache.geode.internal.protocol.protobuf.BasicTypes;\n import org.apache.geode.internal.protocol.protobuf.RegionAPI;\n import org.apache.geode.protocol.protobuf.Result;\n@@ -39,7 +45,6 @@\n import org.apache.geode.serialization.exception.UnsupportedEncodingTypeException;\n import org.apache.geode.serialization.registry.exception.CodecAlreadyRegisteredForTypeException;\n import org.apache.geode.serialization.registry.exception.CodecNotRegisteredForTypeException;\n-import org.apache.geode.test.dunit.Assert;\n import org.apache.geode.test.junit.categories.UnitTest;\n \n @Category(UnitTest.class)\n@@ -51,25 +56,21 @@\n   private static final String TEST_KEY3 = \"my key3\";\n   private static final String TEST_VALUE3 = \"my value3\";\n   private static final String TEST_REGION = \"test region\";\n+  private static final String TEST_INVALID_KEY = \"I'm a naughty key!\";\n+  private static final String NO_VALUE_PRESENT_FOR_THIS_KEY = \"no value present for this key\";\n+  private Region regionStub;\n \n   @Before\n   public void setUp() throws Exception {\n     super.setUp();\n \n-    Region regionStub = mock(Region.class);\n-    when(regionStub.getAll(new HashSet<Object>() {\n-      {\n-        add(TEST_KEY1);\n-        add(TEST_KEY2);\n-        add(TEST_KEY3);\n-      }\n-    })).thenReturn(new HashMap() {\n-      {\n-        put(TEST_KEY1, TEST_VALUE1);\n-        put(TEST_KEY2, TEST_VALUE2);\n-        put(TEST_KEY3, TEST_VALUE3);\n-      }\n-    });\n+    regionStub = mock(Region.class);\n+    when(regionStub.get(TEST_KEY1)).thenReturn(TEST_VALUE1);\n+    when(regionStub.get(TEST_KEY2)).thenReturn(TEST_VALUE2);\n+    when(regionStub.get(TEST_KEY3)).thenReturn(TEST_VALUE3);\n+    when(regionStub.get(NO_VALUE_PRESENT_FOR_THIS_KEY)).thenReturn(null);\n+    when(regionStub.get(TEST_INVALID_KEY))\n+        .thenThrow(new CacheLoaderException(\"Let's pretend that didn't work\"));\n \n     when(cacheStub.getRegion(TEST_REGION)).thenReturn(regionStub);\n     operationHandler = new GetAllRequestOperationHandler();\n@@ -80,44 +81,91 @@ public void processReturnsExpectedValuesForValidKeys()\n       throws CodecAlreadyRegisteredForTypeException, UnsupportedEncodingTypeException,\n       CodecNotRegisteredForTypeException, InvalidExecutionContextException {\n     Result<RegionAPI.GetAllResponse> result =\n-        operationHandler.process(serializationServiceStub, generateTestRequest(true),\n+        operationHandler.process(serializationServiceStub, generateTestRequest(true, false),\n             new MessageExecutionContext(cacheStub, new NoOpStreamAuthorizer()));\n \n-    Assert.assertTrue(result instanceof Success);\n+    assertTrue(result instanceof Success);\n \n     RegionAPI.GetAllResponse response = result.getMessage();\n \n-    Assert.assertEquals(3, response.getEntriesCount());\n+    assertEquals(3, response.getEntriesCount());\n \n     List<BasicTypes.Entry> entriesList = response.getEntriesList();\n     Map<String, String> responseEntries = convertEntryListToMap(entriesList);\n \n-    Assert.assertEquals(TEST_VALUE1, responseEntries.get(TEST_KEY1));\n-    Assert.assertEquals(TEST_VALUE2, responseEntries.get(TEST_KEY2));\n-    Assert.assertEquals(TEST_VALUE3, responseEntries.get(TEST_KEY3));\n+    assertEquals(TEST_VALUE1, responseEntries.get(TEST_KEY1));\n+    assertEquals(TEST_VALUE2, responseEntries.get(TEST_KEY2));\n+    assertEquals(TEST_VALUE3, responseEntries.get(TEST_KEY3));\n   }\n \n   @Test\n   public void processReturnsNoEntriesForNoKeysRequested() throws UnsupportedEncodingTypeException,\n       CodecNotRegisteredForTypeException, InvalidExecutionContextException {\n     Result<RegionAPI.GetAllResponse> result =\n-        operationHandler.process(serializationServiceStub, generateTestRequest(false),\n+        operationHandler.process(serializationServiceStub, generateTestRequest(false, false),\n             new MessageExecutionContext(cacheStub, new NoOpStreamAuthorizer()));\n \n-    Assert.assertTrue(result instanceof Success);\n+    assertTrue(result instanceof Success);\n \n     List<BasicTypes.Entry> entriesList = result.getMessage().getEntriesList();\n     Map<String, String> responseEntries = convertEntryListToMap(entriesList);\n-    Assert.assertEquals(0, responseEntries.size());\n+    assertEquals(0, responseEntries.size());\n+  }\n+\n+  @Test\n+  public void singeNullKey() throws Exception {\n+    HashSet<BasicTypes.EncodedValue> testKeys = new HashSet<>();\n+    testKeys.add(ProtobufUtilities.createEncodedValue(serializationServiceStub,\n+        NO_VALUE_PRESENT_FOR_THIS_KEY));\n+    RegionAPI.GetAllRequest getAllRequest =\n+        ProtobufRequestUtilities.createGetAllRequest(TEST_REGION, testKeys);\n+    Result<RegionAPI.GetAllResponse> result = operationHandler.process(serializationServiceStub,\n+        getAllRequest, new MessageExecutionContext(cacheStub, new NoOpStreamAuthorizer()));\n+\n+    assertTrue(result instanceof Success);\n+    RegionAPI.GetAllResponse message = result.getMessage();\n+    assertEquals(1, message.getEntriesCount());\n+    assertFalse(message.getEntries(0).hasValue());\n+    assertEquals(NO_VALUE_PRESENT_FOR_THIS_KEY, message.getEntries(0).getKey().getStringResult());\n+\n+    verify(regionStub, times(1)).get(NO_VALUE_PRESENT_FOR_THIS_KEY);\n+  }\n+\n+  @Test\n+  public void multipleKeysWhereOneThrows() throws UnsupportedEncodingTypeException,\n+      CodecNotRegisteredForTypeException, InvalidExecutionContextException {\n+    Result<RegionAPI.GetAllResponse> result =\n+        operationHandler.process(serializationServiceStub, generateTestRequest(true, true),\n+            new MessageExecutionContext(cacheStub, new NoOpStreamAuthorizer()));\n+\n+    assertTrue(result instanceof Success);\n+\n+    RegionAPI.GetAllResponse response = result.getMessage();\n+\n+    assertEquals(3, response.getEntriesCount());\n+\n+    List<BasicTypes.Entry> entriesList = response.getEntriesList();\n+    Map<String, String> responseEntries = convertEntryListToMap(entriesList);\n+\n+    assertEquals(TEST_VALUE1, responseEntries.get(TEST_KEY1));\n+    assertEquals(TEST_VALUE2, responseEntries.get(TEST_KEY2));\n+    assertEquals(TEST_VALUE3, responseEntries.get(TEST_KEY3));\n+\n+    assertEquals(1, response.getFailuresCount());\n+    assertEquals(TEST_INVALID_KEY, response.getFailures(0).getKey().getStringResult());\n   }\n \n-  private RegionAPI.GetAllRequest generateTestRequest(boolean addKeys)\n+  private RegionAPI.GetAllRequest generateTestRequest(boolean addKeys, boolean useInvalid)\n       throws UnsupportedEncodingTypeException, CodecNotRegisteredForTypeException {\n     HashSet<BasicTypes.EncodedValue> testKeys = new HashSet<>();\n     if (addKeys) {\n       testKeys.add(ProtobufUtilities.createEncodedValue(serializationServiceStub, TEST_KEY1));\n       testKeys.add(ProtobufUtilities.createEncodedValue(serializationServiceStub, TEST_KEY2));\n       testKeys.add(ProtobufUtilities.createEncodedValue(serializationServiceStub, TEST_KEY3));\n+      if (useInvalid) {\n+        testKeys\n+            .add(ProtobufUtilities.createEncodedValue(serializationServiceStub, TEST_INVALID_KEY));\n+      }\n     }\n     return ProtobufRequestUtilities.createGetAllRequest(TEST_REGION, testKeys);\n   }\n@@ -126,12 +174,10 @@ public void processReturnsNoEntriesForNoKeysRequested() throws UnsupportedEncodi\n     Map<String, String> result = new HashMap<>();\n     for (BasicTypes.Entry entry : entriesList) {\n       BasicTypes.EncodedValue encodedKey = entry.getKey();\n-      Assert.assertEquals(BasicTypes.EncodedValue.ValueCase.STRINGRESULT,\n-          encodedKey.getValueCase());\n+      assertEquals(BasicTypes.EncodedValue.ValueCase.STRINGRESULT, encodedKey.getValueCase());\n       String key = encodedKey.getStringResult();\n       BasicTypes.EncodedValue encodedValue = entry.getValue();\n-      Assert.assertEquals(BasicTypes.EncodedValue.ValueCase.STRINGRESULT,\n-          encodedValue.getValueCase());\n+      assertEquals(BasicTypes.EncodedValue.ValueCase.STRINGRESULT, encodedValue.getValueCase());\n       String value = encodedValue.getStringResult();\n       result.put(key, value);\n     }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/GetAllRequestOperationHandlerJUnitTest.java",
                "sha": "75e5d40a9da32595583361df81965cb90264b267",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandlerJUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandlerJUnitTest.java?ref=501bd79a8bc161649df4e3113c27b0093faab45d",
                "deletions": 1,
                "filename": "geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandlerJUnitTest.java",
                "patch": "@@ -100,7 +100,7 @@ public void processWithInvalidEntrySucceedsAndReturnsFailedKey() throws Exceptio\n \n     RegionAPI.PutAllResponse putAllResponse = result.getMessage();\n     assertEquals(1, putAllResponse.getFailedKeysCount());\n-    BasicTypes.KeyedErrorResponse error = putAllResponse.getFailedKeys(0);\n+    BasicTypes.KeyedError error = putAllResponse.getFailedKeys(0);\n     assertEquals(TEST_INVALID_KEY,\n         ProtobufUtilities.decodeValue(serializationServiceStub, error.getKey()));\n   }",
                "raw_url": "https://github.com/apache/geode/raw/501bd79a8bc161649df4e3113c27b0093faab45d/geode-protobuf/src/test/java/org/apache/geode/protocol/protobuf/operations/PutAllRequestOperationHandlerJUnitTest.java",
                "sha": "8acc653b111fa4c3729143e5e948f51d648bad9d",
                "status": "modified"
            }
        ],
        "message": "GEODE-3385: Change GetAllRequest to return list of errors.\n\nAlso:\n* Rename `KeyedErrorResponse` to `KeyedError`.\n* move `ErrorResponse` to `clientProtocol.proto`.\n* Check for null `value` in `ProtobufUtilities.createEntry`.\n  If we find a null, we don't set the value; previously this resulted in\nNPE.\n\nSigned-off-by: Galen O'Sullivan <gosullivan@pivotal.io>",
        "parent": "https://github.com/apache/geode/commit/21c1fb9d88d1fae657d527a13422540f5e8577ce",
        "patched_files": [
            "PutAllRequestOperationHandler.java",
            "ProtocolErrorCode.java",
            "Result.java",
            "Success.java",
            "region_API.java",
            "OperationContext.java",
            "basicTypes.java",
            "Failure.java",
            "ProtobufResponseUtilities.java",
            "clientProtocol.java",
            "ProtobufUtilities.java",
            "GetAllRequestOperationHandler.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PutAllRequestOperationHandlerJUnitTest.java",
            "GetAllRequestOperationHandlerJUnitTest.java",
            "RoundTripCacheConnectionJUnitTest.java"
        ]
    },
    "geode_514b1d3": {
        "bug_id": "geode_514b1d3",
        "commit": "https://github.com/apache/geode/commit/514b1d3f074421041e593a02bbfae831ab320ea8",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/main/java/org/apache/geode/internal/cache/ClusterConfigurationLoader.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ClusterConfigurationLoader.java?ref=514b1d3f074421041e593a02bbfae831ab320ea8",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ClusterConfigurationLoader.java",
                "patch": "@@ -83,7 +83,7 @@\n    */\n   public void deployJarsReceivedFromClusterConfiguration(ConfigurationResponse response)\n       throws IOException, ClassNotFoundException {\n-    logger.info(\"Requesting cluster configuration\");\n+    logger.info(\"deploying jars received from cluster configuration\");\n     if (response == null) {\n       return;\n     }",
                "raw_url": "https://github.com/apache/geode/raw/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/main/java/org/apache/geode/internal/cache/ClusterConfigurationLoader.java",
                "sha": "1a18270afa1e3792d135cc6639b238e415ca5e1d",
                "status": "modified"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/geode/blob/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java?ref=514b1d3f074421041e593a02bbfae831ab320ea8",
                "deletions": 15,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "patch": "@@ -848,16 +848,21 @@ private GemFireCacheImpl(boolean isClient, PoolFactory pf, InternalDistributedSy\n       this.system = system;\n       this.dm = this.system.getDistributionManager();\n \n-      this.configurationResponse = requestSharedConfiguration();\n+      if (!isClient) {\n+        this.configurationResponse = requestSharedConfiguration();\n \n-      // apply the cluster's properties configuration and initialize security using that\n-      // configuration\n-      ccLoader.applyClusterPropertiesConfiguration(this.configurationResponse,\n-          this.system.getConfig());\n+        // apply the cluster's properties configuration and initialize security using that\n+        // configuration\n+        ccLoader.applyClusterPropertiesConfiguration(this.configurationResponse,\n+            this.system.getConfig());\n \n-      this.securityService =\n-          SecurityServiceFactory.create(this.system.getConfig().getSecurityProps(), cacheConfig);\n-      this.system.setSecurityService(this.securityService);\n+        this.securityService =\n+            SecurityServiceFactory.create(this.system.getConfig().getSecurityProps(), cacheConfig);\n+        this.system.setSecurityService(this.securityService);\n+      } else {\n+        // create a no-op security service for client\n+        this.securityService = SecurityServiceFactory.create();\n+      }\n \n       if (!this.isClient && PoolManager.getAll().isEmpty()) {\n         // We only support management on members of a distributed system\n@@ -1034,7 +1039,7 @@ public RestAgent getRestAgent() {\n    * Request the shared configuration from the locator(s) which have the Cluster config service\n    * running\n    */\n-  private ConfigurationResponse requestSharedConfiguration() {\n+  ConfigurationResponse requestSharedConfiguration() {\n     final DistributionConfig config = this.system.getConfig();\n \n     if (!(this.dm instanceof ClusterDistributionManager)) {\n@@ -1216,12 +1221,9 @@ private void initialize() {\n \n     boolean completedCacheXml = false;\n     try {\n-      if (this.configurationResponse == null) {\n-        // Deploy all the jars from the deploy working dir.\n-        ClassPathLoader.getLatest().getJarDeployer().loadPreviouslyDeployedJarsFromDisk();\n+      if (!isClient) {\n+        applyJarAndXmlFromClusterConfig();\n       }\n-      ccLoader.applyClusterXmlConfiguration(this, this.configurationResponse,\n-          this.system.getConfig().getGroups());\n       initializeDeclarativeCache();\n       completedCacheXml = true;\n     } catch (RuntimeException e) {\n@@ -1251,6 +1253,15 @@ private void initialize() {\n     this.isInitialized = true;\n   }\n \n+  void applyJarAndXmlFromClusterConfig() {\n+    if (this.configurationResponse == null) {\n+      // Deploy all the jars from the deploy working dir.\n+      ClassPathLoader.getLatest().getJarDeployer().loadPreviouslyDeployedJarsFromDisk();\n+    }\n+    ccLoader.applyClusterXmlConfiguration(this, this.configurationResponse,\n+        this.system.getConfig().getGroups());\n+  }\n+\n   /**\n    * Initialize any services that provided as extensions to the cache using the service loader\n    * mechanism.\n@@ -2114,7 +2125,7 @@ public ClientMetadataService getClientMetadataService() {\n \n   public void close(String reason, Throwable systemFailureCause, boolean keepAlive,\n       boolean keepDS) {\n-    this.securityService.close();\n+    securityService.close();\n \n     if (isClosed()) {\n       return;",
                "raw_url": "https://github.com/apache/geode/raw/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "sha": "9ec44f1655f87c7fe2318e0feeec9fcf1b367bf7",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/geode/blob/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java?ref=514b1d3f074421041e593a02bbfae831ab320ea8",
                "deletions": 2,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "patch": "@@ -16,8 +16,13 @@\n \n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n-import static org.junit.Assert.*;\n-import static org.mockito.Mockito.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n \n import java.io.NotSerializableException;\n import java.util.Properties;\n@@ -322,4 +327,21 @@ public void testIsMisConfigured() {\n     serverProps.setProperty(\"key\", \"\");\n     assertFalse(GemFireCacheImpl.isMisConfigured(clusterProps, serverProps, \"key\"));\n   }\n+\n+  @Test\n+  public void clientCacheWouldNotRequestClusterConfig() {\n+    // we will need to set the value to true so that we can use a mock cache\n+    boolean oldValue = InternalDistributedSystem.ALLOW_MULTIPLE_SYSTEMS;\n+    InternalDistributedSystem.ALLOW_MULTIPLE_SYSTEMS = true;\n+\n+    cache = mock(GemFireCacheImpl.class);\n+    when(distributedSystem.getCache()).thenReturn(cache);\n+    GemFireCacheImpl.createClient(distributedSystem, null, cacheConfig);\n+\n+    verify(cache, times(0)).requestSharedConfiguration();\n+    verify(cache, times(0)).applyJarAndXmlFromClusterConfig();\n+\n+    // reset it back to the old value\n+    InternalDistributedSystem.ALLOW_MULTIPLE_SYSTEMS = oldValue;\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/514b1d3f074421041e593a02bbfae831ab320ea8/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "sha": "b323bd47a96d2ee438ea152ba55808690c1825f9",
                "status": "modified"
            }
        ],
        "message": "GEODE-5000: do not request/apply cluster config when creating client \u2026 (#1739)\n\n* do not request/apply cluster config when creating client cache.\r\n* give client cache a no-op security service to avoid NPE.",
        "parent": "https://github.com/apache/geode/commit/ced3d005e6a81cd72dd147abb885bb2bb88bfd03",
        "patched_files": [
            "GemFireCacheImpl.java",
            "ClusterConfigurationLoader.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GemFireCacheImplTest.java"
        ]
    },
    "geode_51dd01c": {
        "bug_id": "geode_51dd01c",
        "commit": "https://github.com/apache/geode/commit/51dd01cf309f1fccea9fe41e08fab42ed9759e52",
        "file": [
            {
                "additions": 38,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/execute/ClientServerFunctionExecutionDUnitTest.java",
                "changes": 38,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/execute/ClientServerFunctionExecutionDUnitTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/execute/ClientServerFunctionExecutionDUnitTest.java",
                "patch": "@@ -15,6 +15,7 @@\n package org.apache.geode.internal.cache.execute;\n \n import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertNotNull;\n import static org.junit.Assert.assertNull;\n@@ -37,6 +38,7 @@\n import org.apache.geode.cache.RegionAttributes;\n import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.Scope;\n+import org.apache.geode.cache.client.Pool;\n import org.apache.geode.cache.client.ServerConnectivityException;\n import org.apache.geode.cache.client.ServerOperationException;\n import org.apache.geode.cache.execute.Execution;\n@@ -430,6 +432,42 @@ public void testOnServerExecution_FunctionInvocationTargetException() {\n             Boolean.FALSE));\n   }\n \n+  @Test\n+  public void onRegionShouldThrowExceptionWhenThePoolAssociatedWithTheRegionCanNotBeFound() {\n+    function = new TestFunction(true, TEST_FUNCTION1);\n+    createScenario();\n+    registerFunctionAtServer(function);\n+\n+    server1.invoke(ClientServerFunctionExecutionDUnitTest::createReplicatedRegion);\n+    server2.invoke(ClientServerFunctionExecutionDUnitTest::createReplicatedRegion);\n+    server3.invoke(ClientServerFunctionExecutionDUnitTest::createReplicatedRegion);\n+\n+    client.invoke(() -> {\n+      ClientServerFunctionExecutionDUnitTest\n+          .createProxyRegion(NetworkUtils.getServerHostName(server1.getHost()));\n+      assertThatThrownBy(() -> HijackedFunctionService.onRegion(metaDataRegion).execute(function))\n+          .isInstanceOf(IllegalStateException.class)\n+          .hasMessageMatching(\"Could not find a pool named (.*)\");\n+    });\n+  }\n+\n+  private static class HijackedFunctionService extends FunctionService {\n+    public HijackedFunctionService(FunctionExecutionService functionExecutionService) {\n+      super(functionExecutionService);\n+    }\n+\n+    public static Execution onRegion(Region region) {\n+      return new HijackedInternalFunctionServiceImpl().onRegion(region);\n+    }\n+  }\n+\n+  private static class HijackedInternalFunctionServiceImpl\n+      extends InternalFunctionExecutionServiceImpl {\n+    @Override\n+    protected Pool findPool(String poolName) {\n+      return null;\n+    }\n+  }\n \n   private void createScenario() {\n     LogWriterUtils.getLogWriter()",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/execute/ClientServerFunctionExecutionDUnitTest.java",
                "sha": "d76a63dc37c5376cccb424607390efbb5f3795d4",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/cache/PoolManagerIntegrationTest.java",
                "changes": 88,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/cache/PoolManagerIntegrationTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 27,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/cache/PoolManagerIntegrationTest.java",
                "patch": "@@ -14,10 +14,12 @@\n  */\n package org.apache.geode.cache;\n \n+import static org.apache.geode.cache.client.ClientRegionShortcut.PROXY;\n import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertNotNull;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n \n import java.util.Properties;\n \n@@ -26,21 +28,23 @@\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n+import org.apache.geode.cache.client.ClientCache;\n+import org.apache.geode.cache.client.ClientCacheFactory;\n import org.apache.geode.cache.client.Pool;\n import org.apache.geode.cache.client.PoolFactory;\n import org.apache.geode.cache.client.PoolManager;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.internal.cache.PoolFactoryImpl;\n+import org.apache.geode.internal.cache.PoolManagerImpl;\n import org.apache.geode.test.junit.categories.ClientServerTest;\n \n /**\n  * Tests PoolManager\n  *\n  * @since GemFire 5.7\n  */\n-@Category({ClientServerTest.class})\n-public class PoolManagerJUnitTest {\n-\n+@Category(ClientServerTest.class)\n+public class PoolManagerIntegrationTest {\n   private DistributedSystem ds;\n \n   @Before\n@@ -49,7 +53,7 @@ public void setUp() {\n     props.setProperty(MCAST_PORT, \"0\");\n     props.setProperty(LOCATORS, \"\");\n     ds = DistributedSystem.connect(props);\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n   }\n \n   @After\n@@ -60,29 +64,31 @@ public void tearDown() {\n \n   @Test\n   public void testCreateFactory() {\n-    assertNotNull(PoolManager.createFactory());\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.createFactory()).isNotNull();\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n   }\n \n   @Test\n   public void testGetMap() {\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n     {\n       PoolFactory cpf = PoolManager.createFactory();\n       ((PoolFactoryImpl) cpf).setStartDisabled(true);\n       cpf.addLocator(\"localhost\", 12345).create(\"mypool\");\n     }\n-    assertEquals(1, PoolManager.getAll().size());\n+\n+    assertThat(PoolManager.getAll().size()).isEqualTo(1);\n     {\n       PoolFactory cpf = PoolManager.createFactory();\n       ((PoolFactoryImpl) cpf).setStartDisabled(true);\n       cpf.addLocator(\"localhost\", 12345).create(\"mypool2\");\n     }\n-    assertEquals(2, PoolManager.getAll().size());\n-    assertNotNull(PoolManager.getAll().get(\"mypool\"));\n-    assertNotNull(PoolManager.getAll().get(\"mypool2\"));\n-    assertEquals(\"mypool\", (PoolManager.getAll().get(\"mypool\")).getName());\n-    assertEquals(\"mypool2\", (PoolManager.getAll().get(\"mypool2\")).getName());\n+\n+    assertThat(PoolManager.getAll().size()).isEqualTo(2);\n+    assertThat(PoolManager.getAll().get(\"mypool\")).isNotNull();\n+    assertThat(PoolManager.getAll().get(\"mypool2\")).isNotNull();\n+    assertThat((PoolManager.getAll().get(\"mypool\")).getName()).isEqualTo(\"mypool\");\n+    assertThat((PoolManager.getAll().get(\"mypool2\")).getName()).isEqualTo(\"mypool2\");\n   }\n \n   @Test\n@@ -92,9 +98,9 @@ public void testFind() {\n       ((PoolFactoryImpl) cpf).setStartDisabled(true);\n       cpf.addLocator(\"localhost\", 12345).create(\"mypool\");\n     }\n-    assertNotNull(PoolManager.find(\"mypool\"));\n-    assertEquals(\"mypool\", (PoolManager.find(\"mypool\")).getName());\n-    assertEquals(null, PoolManager.find(\"bogus\"));\n+    assertThat(PoolManager.find(\"mypool\")).isNotNull();\n+    assertThat((PoolManager.find(\"mypool\")).getName()).isEqualTo(\"mypool\");\n+    assertThat(PoolManager.find(\"bogus\")).isNull();\n   }\n \n   @Test\n@@ -103,34 +109,62 @@ public void testRegionFind() {\n     ((PoolFactoryImpl) cpf).setStartDisabled(true);\n     Pool pool = cpf.addLocator(\"localhost\", 12345).create(\"mypool\");\n     Cache cache = CacheFactory.create(ds);\n-    AttributesFactory fact = new AttributesFactory();\n+    AttributesFactory<Object, Object> fact = new AttributesFactory<>();\n     fact.setPoolName(pool.getName());\n     Region region = cache.createRegion(\"myRegion\", fact.create());\n-    assertEquals(pool, PoolManager.find(region));\n+    assertThat(PoolManager.find(region)).isEqualTo(pool);\n   }\n \n   @Test\n   public void testClose() {\n     PoolManager.close();\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n     {\n       PoolFactory cpf = PoolManager.createFactory();\n       ((PoolFactoryImpl) cpf).setStartDisabled(true);\n       cpf.addLocator(\"localhost\", 12345).create(\"mypool\");\n     }\n-    assertEquals(1, PoolManager.getAll().size());\n+\n+    assertThat(PoolManager.getAll().size()).isEqualTo(1);\n     PoolManager.close();\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n     {\n       PoolFactory cpf = PoolManager.createFactory();\n       ((PoolFactoryImpl) cpf).setStartDisabled(true);\n       cpf.addLocator(\"localhost\", 12345).create(\"mypool\");\n     }\n-    assertEquals(1, PoolManager.getAll().size());\n+\n+    assertThat(PoolManager.getAll().size()).isEqualTo(1);\n     PoolManager.find(\"mypool\").destroy();\n-    assertEquals(null, PoolManager.find(\"mypool\"));\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.find(\"mypool\")).isNull();\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n     PoolManager.close();\n-    assertEquals(0, PoolManager.getAll().size());\n+    assertThat(PoolManager.getAll().size()).isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void unregisterShouldThrowExceptionWhenThePoolHasRegionsStillAssociated() {\n+    PoolManager.createFactory().addLocator(\"localhost\", 12345).create(\"poolOne\");\n+    ClientCache clientCache = new ClientCacheFactory().create();\n+    assertThat(\n+        clientCache.createClientRegionFactory(PROXY).setPoolName(\"poolOne\").create(\"regionOne\"))\n+            .isNotNull();\n+    assertThatThrownBy(() -> PoolManagerImpl.getPMI().unregister(PoolManager.find(\"poolOne\")))\n+        .isInstanceOf(IllegalStateException.class)\n+        .hasMessage(\"Pool could not be destroyed because it is still in use by 1 regions\");\n+  }\n+\n+  @Test\n+  public void unregisterShouldCompleteSuccessfullyWhenThePoolDoesNotHaveRegionsAssociated() {\n+    PoolManager.createFactory().addLocator(\"localhost\", 12345).create(\"poolOne\");\n+    ClientCache clientCache = new ClientCacheFactory().create();\n+    assertThat(\n+        clientCache.createClientRegionFactory(PROXY).setPoolName(\"poolOne\").create(\"regionOne\"))\n+            .isNotNull();\n+\n+    Pool poolOne = PoolManager.find(\"poolOne\");\n+    clientCache.getRegion(\"regionOne\").localDestroyRegion();\n+    assertThatCode(() -> PoolManagerImpl.getPMI().unregister(poolOne)).doesNotThrowAnyException();\n+    assertThat(PoolManager.find(\"poolOne\")).isNull();\n   }\n }",
                "previous_filename": "geode-core/src/integrationTest/java/org/apache/geode/cache/PoolManagerJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/cache/PoolManagerIntegrationTest.java",
                "sha": "d63ee3edf2e4128a2dc9a3baaec0b8e198bb5016",
                "status": "renamed"
            },
            {
                "additions": 155,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/cache/client/ClientRegionFactoryJUnitTest.java",
                "changes": 343,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/cache/client/ClientRegionFactoryJUnitTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 188,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/cache/client/ClientRegionFactoryJUnitTest.java",
                "patch": "@@ -25,10 +25,9 @@\n import static org.apache.geode.cache.client.ClientRegionShortcut.PROXY;\n import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertNotNull;\n-import static org.junit.Assert.assertTrue;\n-import static org.junit.Assert.fail;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n \n import java.net.InetAddress;\n import java.util.Arrays;\n@@ -67,26 +66,17 @@\n  *\n  * @since GemFire 6.5\n  */\n-@Category({ClientServerTest.class})\n+@Category(ClientServerTest.class)\n public class ClientRegionFactoryJUnitTest {\n \n   @Rule\n   public TestName testName = new TestName();\n \n-  private static final String key = \"key\";\n-  private static final Integer val = new Integer(1);\n-  private final String r1Name = \"r1\";\n-  private final String sr1Name = \"sr1\";\n-  private final String r2Name = \"r2\";\n-  private final String r3Name = \"r3\";\n-\n-  private Cache cache;\n-  private DistributedSystem distSys;\n-\n   private Region r1;\n-  private Region r2;\n-  private Region r3;\n   private Region sr1;\n+  private Cache cache;\n+  private DistributedSystem distSys;\n+  private final String r1Name = \"r1\";\n \n   @After\n   public void tearDown() throws Exception {\n@@ -95,324 +85,321 @@ public void tearDown() throws Exception {\n       if (r1 != null) {\n         this.cleanUpRegion(r1);\n       }\n-      if (r2 != null) {\n-        this.cleanUpRegion(r2);\n-      }\n-      if (r3 != null) {\n-        this.cleanUpRegion(r3);\n-      }\n       if (sr1 != null) {\n         this.cleanUpRegion(sr1);\n       }\n+\n       ids.disconnect();\n     }\n     this.distSys = null;\n     this.cache = null;\n   }\n \n   @Test\n-  public void testLOCAL() throws Exception {\n+  public void testLOCAL() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n   }\n \n   @Test\n-  public void testLOCAL_HEAP_LRU() throws Exception {\n+  public void testLOCAL_HEAP_LRU() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_HEAP_LRU);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n-    assertEquals(EvictionAttributes.createLRUHeapAttributes(), ra.getEvictionAttributes());\n-    assertEquals(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE,\n-        c.getResourceManager().getEvictionHeapPercentage(), 0);\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n+    assertThat(ra.getEvictionAttributes()).isEqualTo(EvictionAttributes.createLRUHeapAttributes());\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage())\n+        .isEqualTo(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE);\n   }\n \n   @Test\n-  public void testLOCAL_OVERFLOW() throws Exception {\n+  public void testLOCAL_OVERFLOW() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_OVERFLOW);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n-    assertEquals(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK),\n-        ra.getEvictionAttributes());\n-    assertEquals(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE,\n-        c.getResourceManager().getEvictionHeapPercentage(), 0);\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n+    assertThat(ra.getEvictionAttributes()).isEqualTo(\n+        EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage())\n+        .isEqualTo(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE);\n   }\n \n   @Test\n-  public void testLOCAL_PERSISTENT() throws Exception {\n+  public void testLOCAL_PERSISTENT() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_PERSISTENT);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.PERSISTENT_REPLICATE, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.PERSISTENT_REPLICATE);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n   }\n \n   @Test\n-  public void testLOCAL_PERSISTENT_OVERFLOW() throws Exception {\n+  public void testLOCAL_PERSISTENT_OVERFLOW() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_PERSISTENT_OVERFLOW);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.PERSISTENT_REPLICATE, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n-    assertEquals(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK),\n-        ra.getEvictionAttributes());\n-    assertEquals(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE,\n-        c.getResourceManager().getEvictionHeapPercentage(), 0);\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.PERSISTENT_REPLICATE);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n+    assertThat(ra.getEvictionAttributes()).isEqualTo(\n+        EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage())\n+        .isEqualTo(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE);\n   }\n \n   @Test\n-  public void testPROXY() throws Exception {\n+  public void testPROXY() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(PROXY);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.EMPTY, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(\"DEFAULT\", ra.getPoolName());\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.EMPTY);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isEqualTo(\"DEFAULT\");\n   }\n \n   @Test\n-  public void testCACHING_PROXY() throws Exception {\n+  public void testCACHING_PROXY() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(\"DEFAULT\", ra.getPoolName());\n-    assertEquals(0, (int) c.getResourceManager().getEvictionHeapPercentage());\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isEqualTo(\"DEFAULT\");\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage()).isEqualTo(0);\n   }\n \n   @Test\n-  public void testCACHING_PROXY_LRU() throws Exception {\n+  public void testCACHING_PROXY_LRU() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY_HEAP_LRU);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(\"DEFAULT\", ra.getPoolName());\n-    assertEquals(EvictionAttributes.createLRUHeapAttributes(), ra.getEvictionAttributes());\n-    assertEquals(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE,\n-        c.getResourceManager().getEvictionHeapPercentage(), 0);\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isEqualTo(\"DEFAULT\");\n+    assertThat(ra.getEvictionAttributes())\n+        .isEqualTo(EvictionAttributes.createLRUHeapAttributes());\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage())\n+        .isEqualTo(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE);\n   }\n \n   @Test\n-  public void testCACHING_PROXY_OVERFLOW() throws Exception {\n+  public void testCACHING_PROXY_OVERFLOW() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY_OVERFLOW);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(\"DEFAULT\", ra.getPoolName());\n-    assertEquals(EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK),\n-        ra.getEvictionAttributes());\n-    assertEquals(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE,\n-        c.getResourceManager().getEvictionHeapPercentage(), 0);\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isEqualTo(\"DEFAULT\");\n+    assertThat(ra.getEvictionAttributes()).isEqualTo(\n+        EvictionAttributes.createLRUHeapAttributes(null, EvictionAction.OVERFLOW_TO_DISK));\n+    assertThat(c.getResourceManager().getEvictionHeapPercentage())\n+        .isEqualTo(LocalRegion.DEFAULT_HEAPLRU_EVICTION_HEAP_PERCENTAGE);\n   }\n \n   @Test\n-  public void testAddCacheListener() throws Exception {\n+  public void testAddCacheListener() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(PROXY);\n-    CacheListener cl = new MyCacheListener();\n+    ClientRegionFactory<Object, Object> factory = c.createClientRegionFactory(PROXY);\n+    CacheListener<Object, Object> cl = new MyCacheListener();\n     r1 = factory.addCacheListener(cl).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(cl, ra.getCacheListener());\n+    assertThat(ra.getCacheListeners()[0]).isEqualTo(cl);\n   }\n \n   @Test\n-  public void testInitCacheListener() throws Exception {\n+  public void testInitCacheListener() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(PROXY);\n-    CacheListener cl1 = new MyCacheListener();\n-    CacheListener cl2 = new MyCacheListener();\n+    ClientRegionFactory<Object, Object> factory = c.createClientRegionFactory(PROXY);\n+    CacheListener<Object, Object> cl1 = new MyCacheListener();\n+    CacheListener<Object, Object> cl2 = new MyCacheListener();\n     r1 = factory.initCacheListeners(new CacheListener[] {cl1, cl2}).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(true, Arrays.equals(new CacheListener[] {cl1, cl2}, ra.getCacheListeners()));\n+    assertThat(Arrays.equals(new CacheListener[] {cl1, cl2}, ra.getCacheListeners())).isTrue();\n   }\n \n   @Test\n-  public void testSetEvictionAttributes() throws Exception {\n+  public void testSetEvictionAttributes() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(77))\n         .create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(EvictionAttributes.createLRUEntryAttributes(77), ra.getEvictionAttributes());\n+    assertThat(ra.getEvictionAttributes())\n+        .isEqualTo(EvictionAttributes.createLRUEntryAttributes(77));\n   }\n \n   @Test\n-  public void testSetEntryIdleTimeout() throws Exception {\n+  public void testSetEntryIdleTimeout() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     ExpirationAttributes ea = new ExpirationAttributes(7);\n     r1 = factory.setEntryIdleTimeout(ea).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ea, ra.getEntryIdleTimeout());\n+    assertThat(ra.getEntryIdleTimeout()).isEqualTo(ea);\n   }\n \n   @Test\n-  public void testSetCustomEntryIdleTimeout() throws Exception {\n+  public void testSetCustomEntryIdleTimeout() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n+    ClientRegionFactory<Object, Object> factory = c.createClientRegionFactory(CACHING_PROXY);\n     MyCustomExpiry ce = new MyCustomExpiry();\n     r1 = factory.setCustomEntryIdleTimeout(ce).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ce, ra.getCustomEntryIdleTimeout());\n+    assertThat(ra.getCustomEntryIdleTimeout()).isEqualTo(ce);\n   }\n \n   @Test\n-  public void testSetEntryTimeToLive() throws Exception {\n+  public void testSetEntryTimeToLive() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     ExpirationAttributes ea = new ExpirationAttributes(7);\n     r1 = factory.setEntryTimeToLive(ea).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ea, ra.getEntryTimeToLive());\n+    assertThat(ra.getEntryTimeToLive()).isEqualTo(ea);\n   }\n \n   @Test\n-  public void testSetCustomEntryTimeToLive() throws Exception {\n+  public void testSetCustomEntryTimeToLive() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n+    ClientRegionFactory<Object, Object> factory = c.createClientRegionFactory(CACHING_PROXY);\n     MyCustomExpiry ce = new MyCustomExpiry();\n     r1 = factory.setCustomEntryTimeToLive(ce).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ce, ra.getCustomEntryTimeToLive());\n+    assertThat(ra.getCustomEntryTimeToLive()).isEqualTo(ce);\n   }\n \n   @Test\n-  public void testSetRegionIdleTimeout() throws Exception {\n+  public void testSetRegionIdleTimeout() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     ExpirationAttributes ea = new ExpirationAttributes(7);\n     r1 = factory.setRegionIdleTimeout(ea).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ea, ra.getRegionIdleTimeout());\n+    assertThat(ra.getRegionIdleTimeout()).isEqualTo(ea);\n   }\n \n   @Test\n-  public void testSetRegionTimeToLive() throws Exception {\n+  public void testSetRegionTimeToLive() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     ExpirationAttributes ea = new ExpirationAttributes(7);\n     r1 = factory.setRegionTimeToLive(ea).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(ea, ra.getRegionTimeToLive());\n+    assertThat(ra.getRegionTimeToLive()).isEqualTo(ea);\n   }\n \n   @Test\n-  public void testSetKeyConstraint() throws Exception {\n+  public void testSetKeyConstraint() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n+    ClientRegionFactory<String, String> factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setKeyConstraint(String.class).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(String.class, ra.getKeyConstraint());\n+    assertThat(ra.getKeyConstraint()).isEqualTo(String.class);\n   }\n \n   @Test\n-  public void testSetValueConstraint() throws Exception {\n+  public void testSetValueConstraint() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n+    ClientRegionFactory<String, String> factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setValueConstraint(String.class).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(String.class, ra.getValueConstraint());\n+    assertThat(ra.getValueConstraint()).isEqualTo(String.class);\n   }\n \n   @Test\n-  public void testSetInitialCapacity() throws Exception {\n+  public void testSetInitialCapacity() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setInitialCapacity(777).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(777, ra.getInitialCapacity());\n+    assertThat(ra.getInitialCapacity()).isEqualTo(777);\n   }\n \n   @Test\n-  public void testSetLoadFactor() throws Exception {\n+  public void testSetLoadFactor() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setLoadFactor(77.7f).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(77.7f, ra.getLoadFactor(), 0);\n+    assertThat(ra.getLoadFactor()).isEqualTo(77.7f);\n   }\n \n   @Test\n-  public void testSetConcurrencyLevel() throws Exception {\n+  public void testSetConcurrencyLevel() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setConcurrencyLevel(7).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(7, ra.getConcurrencyLevel());\n+    assertThat(ra.getConcurrencyLevel()).isEqualTo(7);\n   }\n \n   @Test\n-  public void testSetDiskStoreName() throws Exception {\n+  public void testSetDiskStoreName() {\n     ClientCache c = new ClientCacheFactory().create();\n     c.createDiskStoreFactory().create(\"ds\");\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_PERSISTENT);\n     r1 = factory.setDiskStoreName(\"ds\").create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(\"ds\", ra.getDiskStoreName());\n+    assertThat(ra.getDiskStoreName()).isEqualTo(\"ds\");\n   }\n \n   @Test\n-  public void testSetDiskSynchronous() throws Exception {\n+  public void testSetDiskSynchronous() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL_PERSISTENT);\n     r1 = factory.setDiskSynchronous(true).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(true, ra.isDiskSynchronous());\n+    assertThat(ra.isDiskSynchronous()).isTrue();\n   }\n \n   @Test\n-  public void testSetStatisticsEnabled() throws Exception {\n+  public void testSetStatisticsEnabled() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setStatisticsEnabled(true).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(true, ra.getStatisticsEnabled());\n+    assertThat(ra.getStatisticsEnabled()).isTrue();\n   }\n \n   @Test\n-  public void testSetCloningEnabled() throws Exception {\n+  public void testSetCloningEnabled() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(CACHING_PROXY);\n     r1 = factory.setCloningEnabled(true).create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(true, ra.getCloningEnabled());\n+    assertThat(ra.getCloningEnabled()).isTrue();\n   }\n \n   @Test\n-  public void testSetPoolName() throws Exception {\n+  public void testSetPoolName() {\n     ClientCache c = new ClientCacheFactory().create();\n     ClientRegionFactory factory = c.createClientRegionFactory(PROXY);\n     r1 = factory.setPoolName(\"DEFAULT\").create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(\"DEFAULT\", ra.getPoolName());\n+    assertThat(ra.getPoolName()).isEqualTo(\"DEFAULT\");\n   }\n \n   @Test\n   public void testMultiUserRootRegions() throws Exception {\n-    DistributedSystem ds = DistributedSystem.connect(createGemFireProperties());\n+    DistributedSystem.connect(createGemFireProperties());\n     PoolManager.createFactory().addServer(InetAddress.getLocalHost().getHostName(), 7777)\n         .setMultiuserAuthentication(true).create(\"muPool\");\n     PoolManager.createFactory().addServer(InetAddress.getLocalHost().getHostName(), 6666)\n@@ -421,74 +408,76 @@ public void testMultiUserRootRegions() throws Exception {\n     cc.createClientRegionFactory(PROXY).setPoolName(\"muPool\").create(\"p\");\n     cc.createClientRegionFactory(CACHING_PROXY).setPoolName(\"suPool\").create(\"cp\");\n     cc.createClientRegionFactory(LOCAL).create(\"l\");\n-    assertEquals(3, cc.rootRegions().size());\n+    assertThat(cc.rootRegions().size()).isEqualTo(3);\n \n     {\n       Properties muProps = new Properties();\n       muProps.setProperty(\"user\", \"foo\");\n       RegionService rs = cc.createAuthenticatedView(muProps, \"muPool\");\n-      assertNotNull(rs.getRegion(\"p\"));\n-      try {\n-        rs.getRegion(\"cp\");\n-        fail(\"expected IllegalStateException\");\n-      } catch (IllegalStateException expected) {\n-      }\n-      try {\n-        rs.getRegion(\"l\");\n-        fail(\"expected IllegalStateException\");\n-      } catch (IllegalStateException expected) {\n-      }\n-      assertEquals(1, rs.rootRegions().size());\n-      assertEquals(true, rs.getRegion(\"p\") instanceof ProxyRegion);\n-      assertEquals(true, rs.rootRegions().iterator().next() instanceof ProxyRegion);\n+      assertThat(rs.getRegion(\"p\")).isNotNull();\n+      assertThatThrownBy(() -> rs.getRegion(\"cp\")).isInstanceOf(IllegalStateException.class);\n+      assertThatThrownBy(() -> rs.getRegion(\"l\")).isInstanceOf(IllegalStateException.class);\n+      assertThat(rs.rootRegions().size()).isEqualTo(1);\n+      assertThat(rs.getRegion(\"p\")).isInstanceOf(ProxyRegion.class);\n+      assertThat(rs.rootRegions().iterator().next()).isInstanceOf(ProxyRegion.class);\n     }\n   }\n \n   /**\n    * Make sure getLocalQueryService works.\n    */\n   @Test\n-  public void testBug42294() throws Exception {\n+  public void testBug42294() {\n     ClientCache c = new ClientCacheFactory().create();\n     QueryService qs = c.getLocalQueryService();\n     ClientRegionFactory factory = c.createClientRegionFactory(LOCAL);\n     r1 = factory.create(\"localRegion\");\n     Query q = qs.newQuery(\"SELECT * from /localRegion\");\n-    q.execute();\n+    assertThatCode(q::execute).doesNotThrowAnyException();\n   }\n \n   @Test\n-  public void testSubregionCreate() throws Exception {\n+  public void testSubregionCreate() {\n     ClientCache c = new ClientCacheFactory().create();\n-    ClientRegionFactory factory = c.createClientRegionFactory(LOCAL);\n+    ClientRegionFactory<Object, Object> factory = c.createClientRegionFactory(LOCAL);\n     r1 = factory.create(this.r1Name);\n     RegionAttributes ra = r1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, ra.getScope());\n-    assertEquals(null, ra.getPoolName());\n+    assertThat(ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(ra.getPoolName()).isNull();\n \n+    String sr1Name = \"sr1\";\n     sr1 = factory.createSubregion(r1, sr1Name);\n     RegionAttributes sr1ra = sr1.getAttributes();\n-    assertEquals(DataPolicy.NORMAL, sr1ra.getDataPolicy());\n-    assertEquals(Scope.LOCAL, sr1ra.getScope());\n-    assertEquals(null, sr1ra.getPoolName());\n-\n-    try {\n-      factory.createSubregion(r1, sr1Name);\n-      fail(\"Expected RegionExistsException\");\n-    } catch (RegionExistsException expected) {\n-    }\n+    assertThat(sr1ra.getDataPolicy()).isEqualTo(DataPolicy.NORMAL);\n+    assertThat(sr1ra.getScope()).isEqualTo(Scope.LOCAL);\n+    assertThat(sr1ra.getPoolName()).isNull();\n+    assertThatThrownBy(() -> factory.createSubregion(r1, sr1Name))\n+        .isInstanceOf(RegionExistsException.class);\n+\n     cleanUpRegion(sr1);\n     cleanUpRegion(r1);\n-    try {\n-      factory.createSubregion(r1, sr1Name);\n-      fail(\"Expected RegionDestroyedException\");\n-    } catch (RegionDestroyedException expected) {\n-    }\n+    assertThatThrownBy(() -> factory.createSubregion(r1, sr1Name))\n+        .isInstanceOf(RegionDestroyedException.class);\n   }\n \n-  private String getName() {\n-    return getClass().getSimpleName() + \"_\" + this.testName.getMethodName();\n+  @Test\n+  public void setPoolNameShouldThrowExceptionWhenPoolDoesNotExist() throws Exception {\n+    DistributedSystem.connect(createGemFireProperties());\n+    PoolManager.createFactory().addServer(InetAddress.getLocalHost().getHostName(), 7777)\n+        .create(\"poolOne\");\n+    PoolManager.createFactory().addServer(InetAddress.getLocalHost().getHostName(), 6666)\n+        .create(\"poolTwo\");\n+\n+    ClientCache cc = new ClientCacheFactory().create();\n+    assertThat(cc.createClientRegionFactory(PROXY).setPoolName(\"poolOne\")\n+        .create(\"regionOne\")).isNotNull();\n+    assertThat(cc.createClientRegionFactory(CACHING_PROXY).setPoolName(\"poolTwo\")\n+        .create(\"regionTwo\")).isNotNull();\n+    assertThatThrownBy(() -> cc.createClientRegionFactory(CACHING_PROXY)\n+        .setPoolName(\"nonExistingPool\").create(\"regionThree\"))\n+            .isInstanceOf(IllegalStateException.class)\n+            .hasMessage(\"The connection pool nonExistingPool has not been created\");\n   }\n \n   private Properties createGemFireProperties() {\n@@ -507,32 +496,10 @@ private void cleanUpRegion(Region r) {\n     }\n   }\n \n-  private void assertBasicRegionFunctionality(Region r, String name) {\n-    assertEquals(r.getName(), name);\n-    r.put(key, val);\n-    assertEquals(r.getEntry(key).getValue(), val);\n-  }\n-\n-  private static void assertRegionAttributes(RegionAttributes ra1, RegionAttributes ra2) {\n-    assertEquals(ra1.getScope(), ra2.getScope());\n-    assertEquals(ra1.getKeyConstraint(), ra2.getKeyConstraint());\n-    assertEquals(ra1.getValueConstraint(), ra2.getValueConstraint());\n-    assertEquals(ra1.getCacheListener(), ra2.getCacheListener());\n-    assertEquals(ra1.getCacheWriter(), ra2.getCacheWriter());\n-    assertEquals(ra1.getCacheLoader(), ra2.getCacheLoader());\n-    assertEquals(ra1.getStatisticsEnabled(), ra2.getStatisticsEnabled());\n-    assertEquals(ra1.getConcurrencyLevel(), ra2.getConcurrencyLevel());\n-    assertEquals(ra1.getInitialCapacity(), ra2.getInitialCapacity());\n-    assertTrue(ra1.getLoadFactor() == ra2.getLoadFactor());\n-    assertEquals(ra1.getEarlyAck(), ra2.getEarlyAck());\n-    assertEquals(ra1.isDiskSynchronous(), ra2.isDiskSynchronous());\n-    assertEquals(ra1.getDiskStoreName(), ra2.getDiskStoreName());\n-  }\n-\n-  public static class MyCacheListener extends CacheListenerAdapter {\n+  public static class MyCacheListener extends CacheListenerAdapter<Object, Object> {\n   }\n \n-  public static class MyCustomExpiry implements CustomExpiry {\n+  public static class MyCustomExpiry implements CustomExpiry<Object, Object> {\n     @Override\n     public ExpirationAttributes getExpiry(Region.Entry entry) {\n       return null;",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/cache/client/ClientRegionFactoryJUnitTest.java",
                "sha": "dde0a4cf676a1a8e814a975e598b9daca2bb9521",
                "status": "modified"
            },
            {
                "additions": 52,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.java",
                "changes": 88,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 36,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.java",
                "patch": "@@ -15,11 +15,9 @@\n package org.apache.geode.internal.cache.xmlcache;\n \n import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertNotNull;\n-import static org.junit.Assert.assertNull;\n-import static org.junit.Assert.assertSame;\n-import static org.junit.Assert.assertTrue;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n \n import java.lang.reflect.Field;\n import java.lang.reflect.InvocationTargetException;\n@@ -33,7 +31,6 @@\n import org.junit.Test;\n import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n import org.xml.sax.Attributes;\n-import org.xml.sax.SAXException;\n \n import org.apache.geode.cache.client.ClientCache;\n import org.apache.geode.cache.client.ClientCacheFactory;\n@@ -71,28 +68,26 @@ public void tearDown() throws Exception {\n   @Test\n   public void testGetDelegate() {\n     final TestCacheXmlParser cacheXmlParser = new TestCacheXmlParser();\n-\n-    assertTrue(\"delegates should be empty.\", cacheXmlParser.getDelegates().isEmpty());\n+    assertThat(cacheXmlParser.getDelegates()).as(\"delegates should be empty.\").isEmpty();\n \n     final MockXmlParser delegate = (MockXmlParser) cacheXmlParser.getDelegate(NAMESPACE_URI);\n-\n-    assertNotNull(\"Delegate should be found in classpath.\", delegate);\n-\n-    assertSame(\"Should have same stack as cacheXmlParser.\", cacheXmlParser.stack, delegate.stack);\n-    assertSame(\"Should have same stack as cacheXmlParser.\", cacheXmlParser.documentLocator,\n-        delegate.documentLocator);\n-\n-    assertEquals(\"Should be exactly 1 delegate.\", 1, cacheXmlParser.getDelegates().size());\n-    assertNotNull(\"There should be an entry in delegates cache.\",\n-        cacheXmlParser.getDelegates().get(NAMESPACE_URI));\n-    assertSame(\"Cached delegate should match the one from get.\", delegate,\n-        cacheXmlParser.getDelegates().get(NAMESPACE_URI));\n+    assertThat(delegate).as(\"Delegate should be found in classpath.\").isNotNull();\n+    assertThat(cacheXmlParser.stack).as(\"Should have same stack as cacheXmlParser.\")\n+        .isSameAs(delegate.stack);\n+    assertThat(cacheXmlParser.documentLocator).as(\"Should have same stack as cacheXmlParser.\")\n+        .isSameAs(delegate.documentLocator);\n+    assertThat(cacheXmlParser.getDelegates().size()).as(\"Should be exactly 1 delegate.\")\n+        .isEqualTo(1);\n+    assertThat(cacheXmlParser.getDelegates().get(NAMESPACE_URI))\n+        .as(\"There should be an entry in delegates cache.\").isNotNull();\n+    assertThat(cacheXmlParser.getDelegates().get(NAMESPACE_URI))\n+        .as(\"Cached delegate should match the one from get.\").isSameAs(delegate);\n \n     final MockXmlParser delegate2 = (MockXmlParser) cacheXmlParser.getDelegate(NAMESPACE_URI);\n-    assertSame(\"Delegate should be the same between gets.\", delegate, delegate2);\n-    assertEquals(\"Should still be exactly 1 delegate.\", 1, cacheXmlParser.getDelegates().size());\n-\n-    assertNull(cacheXmlParser.getDelegate(\"--nothing-should-use-this-namespace--\"));\n+    assertThat(delegate2).as(\"Delegate should be the same between gets.\").isSameAs(delegate);\n+    assertThat(cacheXmlParser.getDelegates().size()).as(\"Should still be exactly 1 delegate.\")\n+        .isEqualTo(1);\n+    assertThat(cacheXmlParser.getDelegate(\"--nothing-should-use-this-namespace--\")).isNull();\n   }\n \n   /**\n@@ -102,15 +97,14 @@ public void testGetDelegate() {\n    */\n   @Test\n   public void testCacheXmlParserWithSimplePool() {\n-    assertNotNull(\"Did not find simple config.xml file\", getClass()\n-        .getResourceAsStream(\"CacheXmlParserJUnitTest.testSimpleClientCacheXml.cache.xml\"));\n-\n     Properties nonDefault = new Properties();\n     nonDefault.setProperty(MCAST_PORT, \"0\"); // loner\n \n-    ClientCache cache = new ClientCacheFactory(nonDefault).set(\"cache-xml-file\",\n-        \"xmlcache/CacheXmlParserJUnitTest.testSimpleClientCacheXml.cache.xml\").create();\n-    cache.close();\n+    assertThatCode(() -> {\n+      ClientCache cache = new ClientCacheFactory(nonDefault).set(\"cache-xml-file\",\n+          \"xmlcache/CacheXmlParserJUnitTest.testSimpleClientCacheXml.cache.xml\").create();\n+      cache.close();\n+    }).doesNotThrowAnyException();\n   }\n \n   /**\n@@ -127,6 +121,30 @@ public void testCacheXmlParserWithSimplePoolXerces() {\n     testCacheXmlParserWithSimplePool();\n   }\n \n+  @Test\n+  public void cacheXmlParserShouldCorrectlyHandleWithMultiplePools() {\n+    Properties nonDefault = new Properties();\n+    nonDefault.setProperty(MCAST_PORT, \"0\"); // loner\n+\n+    ClientCache cache = new ClientCacheFactory(nonDefault).set(\"cache-xml-file\",\n+        \"xmlcache/CacheXmlParserJUnitTest.testMultiplePools.cache.xml\").create();\n+\n+    assertThat(cache.getRegion(\"regionOne\").getAttributes().getPoolName()).isEqualTo(\"poolOne\");\n+    assertThat(cache.getRegion(\"regionTwo\").getAttributes().getPoolName()).isEqualTo(\"poolTwo\");\n+    cache.close();\n+  }\n+\n+  @Test\n+  public void cacheXmlParserShouldShouldThrowExceptionWhenPoolDoesNotExist() {\n+    Properties nonDefault = new Properties();\n+    nonDefault.setProperty(MCAST_PORT, \"0\"); // loner\n+\n+    assertThatThrownBy(() -> new ClientCacheFactory(nonDefault).set(\"cache-xml-file\",\n+        \"xmlcache/CacheXmlParserJUnitTest.testRegionWithNonExistingPool.cache.xml\").create())\n+            .isInstanceOf(IllegalStateException.class)\n+            .hasMessage(\"The connection pool nonExistingPool has not been created\");\n+  }\n+\n   /**\n    * Test that {@link CacheXmlParser} falls back to DTD parsing when locale language is not English.\n    *\n@@ -167,7 +185,6 @@ public void testDTDFallbackWithNonEnglishLocalXerces() {\n    * @since GemFire 8.1\n    */\n   private static class TestCacheXmlParser extends CacheXmlParser {\n-\n     static Field delegatesField;\n     static Method getDelegateMethod;\n \n@@ -188,7 +205,7 @@ public void testDTDFallbackWithNonEnglishLocalXerces() {\n      * @since GemFire 8.1\n      */\n     @SuppressWarnings(\"unchecked\")\n-    public HashMap<String, XmlParser> getDelegates() {\n+    HashMap<String, XmlParser> getDelegates() {\n       try {\n         return (HashMap<String, XmlParser>) delegatesField.get(this);\n       } catch (IllegalArgumentException | IllegalAccessException e) {\n@@ -201,7 +218,7 @@ public void testDTDFallbackWithNonEnglishLocalXerces() {\n      *\n      * @since GemFire 8.1\n      */\n-    public XmlParser getDelegate(final String namespaceUri) {\n+    XmlParser getDelegate(final String namespaceUri) {\n       try {\n         return (XmlParser) getDelegateMethod.invoke(this, namespaceUri);\n       } catch (IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {\n@@ -218,13 +235,12 @@ public String getNamespaceUri() {\n     }\n \n     @Override\n-    public void startElement(String uri, String localName, String qName, Attributes atts)\n-        throws SAXException {\n+    public void startElement(String uri, String localName, String qName, Attributes atts) {\n       throw new UnsupportedOperationException();\n     }\n \n     @Override\n-    public void endElement(String uri, String localName, String qName) throws SAXException {\n+    public void endElement(String uri, String localName, String qName) {\n       throw new UnsupportedOperationException();\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.java",
                "sha": "3276e832d8f131d528ab65e2efbcadbf2f7498af",
                "status": "modified"
            },
            {
                "additions": 37,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testMultiplePools.cache.xml",
                "changes": 37,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testMultiplePools.cache.xml?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testMultiplePools.cache.xml",
                "patch": "@@ -0,0 +1,37 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+  ~ agreements. See the NOTICE file distributed with this work for additional information regarding\n+  ~ copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+  ~ \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+  ~ copy of the License at\n+  ~\n+  ~ http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software distributed under the License\n+  ~ is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+  ~ or implied. See the License for the specific language governing permissions and limitations under\n+  ~ the License.\n+  -->\n+<client-cache\n+    xmlns=\"http://geode.apache.org/schema/cache\"\n+    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+    xsi:schemaLocation=\"http://geode.apache.org/schema/cache http://geode.apache.org/schema/cache/cache-1.0.xsd\"\n+    version=\"1.0\">\n+\n+\t<pool name=\"poolOne\" subscription-enabled=\"true\">\n+\t\t<server host=\"127.0.0.1\" port=\"11211\"/>\n+\t</pool>\n+\n+\t<pool name=\"poolTwo\" subscription-enabled=\"true\">\n+\t\t<server host=\"127.0.0.1\" port=\"11222\"/>\n+\t</pool>\n+\n+\t<region name=\"regionOne\" refid=\"PROXY\">\n+\t\t<region-attributes pool-name=\"poolOne\"/>\n+\t</region>\n+\n+\t<region name=\"regionTwo\" refid=\"PROXY\">\n+\t\t<region-attributes pool-name=\"poolTwo\"/>\n+\t</region>\n+</client-cache>",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testMultiplePools.cache.xml",
                "sha": "656f57288a00a242719eaf8b706f89fd761d9cfa",
                "status": "added"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testRegionWithNonExistingPool.cache.xml",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testRegionWithNonExistingPool.cache.xml?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testRegionWithNonExistingPool.cache.xml",
                "patch": "@@ -0,0 +1,29 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+  ~ agreements. See the NOTICE file distributed with this work for additional information regarding\n+  ~ copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+  ~ \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+  ~ copy of the License at\n+  ~\n+  ~ http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software distributed under the License\n+  ~ is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+  ~ or implied. See the License for the specific language governing permissions and limitations under\n+  ~ the License.\n+  -->\n+<client-cache\n+    xmlns=\"http://geode.apache.org/schema/cache\"\n+    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+    xsi:schemaLocation=\"http://geode.apache.org/schema/cache http://geode.apache.org/schema/cache/cache-1.0.xsd\"\n+    version=\"1.0\">\n+\n+\t<pool name=\"poolOne\" subscription-enabled=\"true\">\n+\t\t<server host=\"127.0.0.1\" port=\"11211\"/>\n+\t</pool>\n+\n+\t<region name=\"region\" refid=\"PROXY\">\n+\t\t<region-attributes pool-name=\"nonExistingPool\"/>\n+\t</region>\n+</client-cache>",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/integrationTest/resources/org/apache/geode/internal/cache/xmlcache/CacheXmlParserJUnitTest.testRegionWithNonExistingPool.cache.xml",
                "sha": "07e82e5a752432a01a9906e235c68a4960e42c6a",
                "status": "added"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/main/java/org/apache/geode/internal/cache/PoolManagerImpl.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/PoolManagerImpl.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/PoolManagerImpl.java",
                "patch": "@@ -166,6 +166,13 @@ public void register(Pool pool) {\n    * @return true if pool unregistered from cache; false if someone else already did it\n    */\n   public boolean unregister(Pool pool) {\n+    // Continue only if the pool is not currently being used by any region and/or service.\n+    int attachCount = ((PoolImpl) pool).getAttachCount();\n+    if (attachCount > 0) {\n+      throw new IllegalStateException(String.format(\n+          \"Pool could not be destroyed because it is still in use by %s regions\", attachCount));\n+    }\n+\n     synchronized (poolLock) {\n       Map<String, Pool> copy = new HashMap<>(pools);\n       String name = pool.getName();",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/main/java/org/apache/geode/internal/cache/PoolManagerImpl.java",
                "sha": "429480349e4a3134cd666a2a8f3afdb50c456e89",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/main/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceImpl.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceImpl.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 10,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceImpl.java",
                "patch": "@@ -106,24 +106,32 @@ public Execution onMember(String... groups) {\n     return onMember(getDistributedSystem(), groups);\n   }\n \n+  protected Pool findPool(String poolName) {\n+    return PoolManager.find(poolName);\n+  }\n+\n   @Override\n   public Execution onRegion(Region region) {\n     if (region == null) {\n-      throw new FunctionException(\n-          String.format(\"%s passed is null\", \"Region instance \"));\n+      throw new FunctionException(\"Region instance passed is null\");\n     }\n \n     ProxyCache proxyCache = null;\n     String poolName = region.getAttributes().getPoolName();\n     if (poolName != null) {\n-      Pool pool = PoolManager.find(poolName);\n-      if (pool.getMultiuserAuthentication()) {\n-        if (region instanceof ProxyRegion) {\n-          ProxyRegion proxyRegion = (ProxyRegion) region;\n-          region = proxyRegion.getRealRegion();\n-          proxyCache = proxyRegion.getAuthenticatedCache();\n-        } else {\n-          throw new UnsupportedOperationException();\n+      Pool pool = findPool(poolName);\n+\n+      if (pool == null) {\n+        throw new IllegalStateException(String.format(\"Could not find a pool named %s.\", poolName));\n+      } else {\n+        if (pool.getMultiuserAuthentication()) {\n+          if (region instanceof ProxyRegion) {\n+            ProxyRegion proxyRegion = (ProxyRegion) region;\n+            region = proxyRegion.getRealRegion();\n+            proxyCache = proxyRegion.getAuthenticatedCache();\n+          } else {\n+            throw new UnsupportedOperationException();\n+          }\n         }\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/main/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceImpl.java",
                "sha": "3416c93b5187cb8437973cc2f0fcb97b8ddce19d",
                "status": "modified"
            },
            {
                "additions": 64,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/test/java/org/apache/geode/internal/cache/PoolManagerTest.java",
                "changes": 64,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/PoolManagerTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/PoolManagerTest.java",
                "patch": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.when;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.client.internal.PoolImpl;\n+\n+public class PoolManagerTest {\n+  private PoolImpl pool;\n+  private PoolManagerImpl poolManager;\n+\n+  @Before\n+  public void setUp() {\n+    pool = mock(PoolImpl.class);\n+    poolManager = spy(new PoolManagerImpl(true));\n+\n+    assertThat(poolManager.getMap()).isEmpty();\n+  }\n+\n+  @Test\n+  public void unregisterShouldThrowExceptionWhenPoolHasRegionsStillAssociated() {\n+    when(pool.getAttachCount()).thenReturn(2);\n+\n+    assertThatThrownBy(() -> poolManager.unregister(pool)).isInstanceOf(IllegalStateException.class)\n+        .hasMessage(\"Pool could not be destroyed because it is still in use by 2 regions\");\n+  }\n+\n+  @Test\n+  public void unregisterShouldReturnFalseWhenThePoolIsNotPartOfTheManagedPools() {\n+    when(pool.getAttachCount()).thenReturn(0);\n+\n+    assertThat(poolManager.unregister(pool)).isFalse();\n+  }\n+\n+  @Test\n+  public void unregisterShouldReturnTrueWhenThePoolIsSuccessfullyRemovedFromTheManagedPools() {\n+    when(pool.getAttachCount()).thenReturn(0);\n+    poolManager.register(pool);\n+    assertThat(poolManager.getMap()).isNotEmpty();\n+\n+    assertThat(poolManager.unregister(pool)).isTrue();\n+    assertThat(poolManager.getMap()).isEmpty();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/test/java/org/apache/geode/internal/cache/PoolManagerTest.java",
                "sha": "2925c73ffb6b4fc9234132a743e34a7658c08b61",
                "status": "added"
            },
            {
                "additions": 101,
                "blob_url": "https://github.com/apache/geode/blob/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/test/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceTest.java",
                "changes": 101,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceTest.java?ref=51dd01cf309f1fccea9fe41e08fab42ed9759e52",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceTest.java",
                "patch": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache.execute;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.when;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionAttributes;\n+import org.apache.geode.cache.client.Pool;\n+import org.apache.geode.cache.execute.FunctionException;\n+import org.apache.geode.internal.cache.LocalRegion;\n+import org.apache.geode.internal.cache.PartitionedRegion;\n+\n+public class InternalFunctionExecutionServiceTest {\n+  private InternalFunctionExecutionServiceImpl functionExecutionService;\n+\n+  @Before\n+  public void setUp() {\n+    functionExecutionService = spy(new InternalFunctionExecutionServiceImpl());\n+  }\n+\n+  @Test\n+  public void onRegionShouldThrowExceptionWhenRegionIsNull() {\n+    assertThatThrownBy(() -> functionExecutionService.onRegion(null))\n+        .isInstanceOf(FunctionException.class)\n+        .hasMessage(\"Region instance passed is null\");\n+  }\n+\n+  @Test\n+  public void onRegionShouldThrowExceptionWhenThePoolAssociatedWithTheRegionCanNotBeFound() {\n+    when(functionExecutionService.findPool(any())).thenReturn(null);\n+\n+    Region mockRegion = mock(Region.class);\n+    RegionAttributes mockAttributes = mock(RegionAttributes.class);\n+    when(mockAttributes.getPoolName()).thenReturn(\"testPool\");\n+    when(mockRegion.getAttributes()).thenReturn(mockAttributes);\n+\n+\n+    assertThatThrownBy(() -> functionExecutionService.onRegion(mockRegion))\n+        .isInstanceOf(IllegalStateException.class)\n+        .hasMessage(\"Could not find a pool named testPool.\");\n+  }\n+\n+  @Test\n+  public void onRegionShouldThrowExceptionWhenMultiUserAuthenticationIsSetForNonProxyRegions() {\n+    Pool mockPool = mock(Pool.class);\n+    when(mockPool.getMultiuserAuthentication()).thenReturn(true);\n+    when(functionExecutionService.findPool(any())).thenReturn(mockPool);\n+\n+    Region mockRegion = mock(Region.class);\n+    RegionAttributes mockAttributes = mock(RegionAttributes.class);\n+    when(mockAttributes.getPoolName()).thenReturn(\"testPool\");\n+    when(mockRegion.getAttributes()).thenReturn(mockAttributes);\n+\n+    assertThatThrownBy(() -> functionExecutionService.onRegion(mockRegion))\n+        .isInstanceOf(UnsupportedOperationException.class);\n+  }\n+\n+  @Test\n+  public void onRegionShouldReturnClientExecutorImplementationForClientRegions() {\n+    LocalRegion mockRegion = mock(LocalRegion.class);\n+    when(mockRegion.hasServerProxy()).thenReturn(true);\n+    RegionAttributes mockAttributes = mock(RegionAttributes.class);\n+    when(mockAttributes.getPoolName()).thenReturn(null);\n+    when(mockRegion.getAttributes()).thenReturn(mockAttributes);\n+\n+    assertThat(functionExecutionService.onRegion(mockRegion))\n+        .isInstanceOf(ServerRegionFunctionExecutor.class);\n+  }\n+\n+  @Test\n+  public void onRegionShouldReturnPartitionExecutorImplementationForPartitionedRegions() {\n+    PartitionedRegion mockRegion = mock(PartitionedRegion.class);\n+    RegionAttributes mockAttributes = mock(RegionAttributes.class);\n+    when(mockAttributes.getPoolName()).thenReturn(null);\n+    when(mockRegion.getAttributes()).thenReturn(mockAttributes);\n+\n+    assertThat(functionExecutionService.onRegion(mockRegion))\n+        .isInstanceOf(PartitionedRegionFunctionExecutor.class);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/51dd01cf309f1fccea9fe41e08fab42ed9759e52/geode-core/src/test/java/org/apache/geode/internal/cache/execute/InternalFunctionExecutionServiceTest.java",
                "sha": "eec2b6df0031c58d5963082e572a103140bfa0a7",
                "status": "added"
            }
        ],
        "message": "GEODE-6759: Prevent Deleting Pool Still in Use and Fix NPE in Function Execution (#3569)\n\n* GEODE-6759: Avoid Deleting Pools Still in Use\r\n\r\n- Fixed minor warnings.\r\n- Added unit and integration tests.\r\n- Replaced the usage of `junit.Assert` by `assertj`.\r\n- PoolManagerImpl now checks whether the pool is being used or not\r\n  before unregistering it.\r\n- InternalFunctionExecutionServiceImpl now throws a meaningful\r\n  exception if the pool can not be found instead of NPE.",
        "parent": "https://github.com/apache/geode/commit/8342938cce4dee733a45529fe95402f46cedc119",
        "patched_files": [
            "InternalFunctionExecutionService.java",
            "PoolManager.java",
            "PoolManagerImpl.java",
            "InternalFunctionExecutionServiceImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ClientRegionFactoryJUnitTest.java",
            "PoolManagerIntegrationTest.java",
            "CacheXmlParserJUnitTest.java",
            "InternalFunctionExecutionServiceTest.java",
            "PoolManagerTest.java",
            "ClientServerFunctionExecutionDUnitTest.java"
        ]
    },
    "geode_5503de0": {
        "bug_id": "geode_5503de0",
        "commit": "https://github.com/apache/geode/commit/5503de078aa0d45961dc143569651276948ff587",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/5503de078aa0d45961dc143569651276948ff587/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java?ref=5503de078aa0d45961dc143569651276948ff587",
                "deletions": 1,
                "filename": "geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "patch": "@@ -1502,7 +1502,8 @@ public boolean isDistributed() {\n      Boolean value = isTXDistributed.get();\n     // This can be null if not set in setDistributed().\n     if (value == null) {\n-      return InternalDistributedSystem.getAnyInstance().getOriginalConfig().getDistributedTransactions();\n+      InternalDistributedSystem ids = (InternalDistributedSystem) cache.getDistributedSystem();\n+      return ids.getOriginalConfig().getDistributedTransactions();\n     } else {\n       return value.booleanValue();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/5503de078aa0d45961dc143569651276948ff587/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "sha": "7c270fe89144fef61507f5e4d3932ef61c5a5012",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/5503de078aa0d45961dc143569651276948ff587/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java?ref=5503de078aa0d45961dc143569651276948ff587",
                "deletions": 0,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "patch": "@@ -331,4 +331,11 @@ public void testSuspendTimeout() throws Exception {\n     assertNull(region.get(\"key\"));\n     System.setProperty(\"gemfire.suspendedTxTimeout\", \"\");\n   }\n+\n+  @Test\n+  public void testIsDistributedDoesNotThrowNPE() {\n+    TXManagerImpl txMgr = (TXManagerImpl) cache.getCacheTransactionManager();\n+    cache.getDistributedSystem().disconnect();\n+    assertFalse(txMgr.isDistributed());\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/5503de078aa0d45961dc143569651276948ff587/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "sha": "0467f4fde5c888294dbf197974c62676f3378b37",
                "status": "modified"
            }
        ],
        "message": "GEODE-1099: NPE thrown from TXManagerImpl.isDistributed()\n\nUse the existing reference to InternalDistributedSystem so as to prevent a NPE.\nIf the member is indeed being disconnected, a CacheClosed exception is thrown\nwhile trying to send the message.",
        "parent": "https://github.com/apache/geode/commit/e22cd9532946322c0a0829b755ab184cd08977fb",
        "patched_files": [
            "TXManagerImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "TXManagerImplJUnitTest.java"
        ]
    },
    "geode_5dfce1b": {
        "bug_id": "geode_5dfce1b",
        "commit": "https://github.com/apache/geode/commit/5dfce1bd6fe625042abf243dec60098a9394ef27",
        "file": [
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/geode/blob/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/NetView.java",
                "changes": 50,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/NetView.java?ref=5dfce1bd6fe625042abf243dec60098a9394ef27",
                "deletions": 17,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/NetView.java",
                "patch": "@@ -14,21 +14,29 @@\n  */\n package org.apache.geode.distributed.internal.membership;\n \n-import java.io.DataInput;\n-import java.io.DataOutput;\n-import java.io.IOException;\n-import java.util.stream.*;\n-import java.util.*;\n-import java.util.concurrent.ConcurrentHashMap;\n-\n-import org.apache.logging.log4j.Logger;\n-\n import org.apache.geode.DataSerializer;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.internal.DistributionManager;\n import org.apache.geode.internal.DataSerializableFixedID;\n import org.apache.geode.internal.InternalDataSerializer;\n import org.apache.geode.internal.Version;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n \n /**\n  * The NetView class represents a membership view. Note that this class is not synchronized, so take\n@@ -41,7 +49,7 @@\n   private int viewId;\n   private List<InternalDistributedMember> members;\n   // TODO this should be a List\n-  private Map<InternalDistributedMember, Object> publicKeys = new ConcurrentHashMap<>();\n+  private final Map<InternalDistributedMember, Object> publicKeys = new ConcurrentHashMap<>();\n   private int[] failureDetectionPorts = new int[10];\n   private Set<InternalDistributedMember> shutdownMembers;\n   private Set<InternalDistributedMember> crashedMembers;\n@@ -113,7 +121,7 @@ public NetView(NetView other, int viewId) {\n         other.failureDetectionPorts.length);\n     this.shutdownMembers = new HashSet<>(other.shutdownMembers);\n     this.crashedMembers = new HashSet<>(other.crashedMembers);\n-    this.publicKeys = new HashMap<>(other.publicKeys);\n+    this.publicKeys.putAll(other.publicKeys);\n   }\n \n   public NetView(InternalDistributedMember creator, int viewId,\n@@ -146,14 +154,19 @@ public Object getPublicKey(InternalDistributedMember mbr) {\n   }\n \n   public void setPublicKey(InternalDistributedMember mbr, Object key) {\n-    publicKeys.put(mbr, key);\n+    if (mbr != null && key != null) {\n+      publicKeys.put(mbr, key);\n+    }\n   }\n \n   public void setPublicKeys(NetView otherView) {\n-    this.publicKeys.putAll(otherView.publicKeys);\n+    if (otherView.publicKeys != null) {\n+      this.publicKeys.putAll(otherView.publicKeys);\n+    }\n   }\n \n \n+\n   public int[] getFailureDetectionPorts() {\n     return this.failureDetectionPorts;\n   }\n@@ -558,10 +571,10 @@ public synchronized boolean equals(Object other) {\n     if (other == this) {\n       return true;\n     }\n-    if (!(other instanceof NetView)) {\n-      return false;\n+    if (other instanceof NetView) {\n+      return this.members.equals(((NetView) other).getMembers());\n     }\n-    return this.members.equals(((NetView) other).getMembers());\n+    return false;\n   }\n \n   @Override\n@@ -591,7 +604,10 @@ public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n     shutdownMembers = InternalDataSerializer.readHashSet(in);\n     crashedMembers = InternalDataSerializer.readHashSet(in);\n     failureDetectionPorts = DataSerializer.readIntArray(in);\n-    publicKeys = DataSerializer.readHashMap(in);\n+    Map pubkeys = DataSerializer.readHashMap(in);\n+    if (pubkeys != null) {\n+      publicKeys.putAll(pubkeys);\n+    }\n   }\n \n   /** this will deserialize as an ArrayList */",
                "raw_url": "https://github.com/apache/geode/raw/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/NetView.java",
                "sha": "26b03276b0abbf6210a5602a8c551abe38edc261",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/NetViewJUnitTest.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/NetViewJUnitTest.java?ref=5dfce1bd6fe625042abf243dec60098a9394ef27",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/NetViewJUnitTest.java",
                "patch": "@@ -193,6 +193,22 @@ public void testAddLotsOfMembers() throws Exception {\n     assertEquals(100, view.getNewMembers(copy).size());\n   }\n \n+  @Test\n+  public void testNullPublicKeysNotRetained() throws Exception {\n+    NetView view = new NetView(members.get(0), 2, new ArrayList<>(members));\n+    setFailureDetectionPorts(view);\n+\n+    NetView newView = new NetView(view, 3);\n+    for (InternalDistributedMember member : view.getMembers()) {\n+      view.setPublicKey(member, null);\n+    }\n+    newView.setPublicKeys(view);\n+    for (InternalDistributedMember member : view.getMembers()) {\n+      assertNull(newView.getPublicKey(member));\n+      assertNull(view.getPublicKey(member));\n+    }\n+  }\n+\n   /**\n    * Test that failed weight calculations are correctly performed. See bug #47342\n    */",
                "raw_url": "https://github.com/apache/geode/raw/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/NetViewJUnitTest.java",
                "sha": "fef77de73df4918e7d960205da18a698958fc0d5",
                "status": "modified"
            },
            {
                "additions": 532,
                "blob_url": "https://github.com/apache/geode/blob/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/test/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "changes": 1064,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt?ref=5dfce1bd6fe625042abf243dec60098a9394ef27",
                "deletions": 532,
                "filename": "geode-core/src/test/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "raw_url": "https://github.com/apache/geode/raw/5dfce1bd6fe625042abf243dec60098a9394ef27/geode-core/src/test/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "sha": "d56ba6afe9575bf15ea5e620894a264edb69f841",
                "status": "modified"
            }
        ],
        "message": "GEODE-2215 NPE in ViewCreator thread setting public keys into a NetView\n\nNetView creates a ConcurrentHashmap to hold the public keys when it's\nconstructed but it had some methods that were replacing it with a\nHashmap.  I made the field final and also added checks to avoid putting\na null key or value into the map.",
        "parent": "https://github.com/apache/geode/commit/f68c41600151b18bd096d7d1e77d6a5fcecce9d5",
        "patched_files": [
            "NetView.java",
            "sanctionedDataSerializables.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "NetViewJUnitTest.java"
        ]
    },
    "geode_5ec5dd1": {
        "bug_id": "geode_5ec5dd1",
        "commit": "https://github.com/apache/geode/commit/5ec5dd182ac8f523ee83518b4d727a5527203f5a",
        "file": [
            {
                "additions": 53,
                "blob_url": "https://github.com/apache/geode/blob/5ec5dd182ac8f523ee83518b4d727a5527203f5a/geode-core/src/main/java/org/apache/geode/management/internal/SystemManagementService.java",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/SystemManagementService.java?ref=5ec5dd182ac8f523ee83518b4d727a5527203f5a",
                "deletions": 30,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/SystemManagementService.java",
                "patch": "@@ -25,6 +25,8 @@\n import java.util.Set;\n import java.util.concurrent.CopyOnWriteArrayList;\n import java.util.concurrent.ExecutorService;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n import java.util.function.Supplier;\n \n import javax.management.Notification;\n@@ -39,6 +41,7 @@\n import org.apache.geode.cache.execute.FunctionService;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.ResourceEvent;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n@@ -113,6 +116,7 @@\n   private final StatisticsClock statisticsClock;\n   private final FederatingManagerFactory federatingManagerFactory;\n \n+\n   /**\n    * whether the service is closed or not if cache is closed automatically this service will be\n    * closed\n@@ -133,15 +137,33 @@\n    * Managing node.\n    */\n   private ManagementMembershipListener listener;\n+  private final Function<SystemManagementService, LocalManager> localManagerFactory;\n \n   static BaseManagementService newSystemManagementService(\n       InternalCacheForClientAccess cache) {\n-    return new SystemManagementService(cache).init();\n+    return newSystemManagementService(cache, NotificationHub::new,\n+        SystemManagementService::createLocalManager,\n+        createFederatingManagerFactory(), ManagementAgent::new);\n   }\n \n-  private SystemManagementService(InternalCacheForClientAccess cache) {\n+  @VisibleForTesting\n+  static BaseManagementService newSystemManagementService(InternalCacheForClientAccess cache,\n+      Function<ManagementResourceRepo, NotificationHub> notificationHubFactory,\n+      Function<SystemManagementService, LocalManager> localManagerFactory,\n+      FederatingManagerFactory federatingManagerFactory,\n+      BiFunction<DistributionConfig, InternalCacheForClientAccess, ManagementAgent> managementAgentFactory) {\n+    return new SystemManagementService(cache, notificationHubFactory, localManagerFactory,\n+        federatingManagerFactory, managementAgentFactory).init();\n+  }\n+\n+  private SystemManagementService(InternalCacheForClientAccess cache,\n+      Function<ManagementResourceRepo, NotificationHub> notificationHubFactory,\n+      Function<SystemManagementService, LocalManager> localManagerFactory,\n+      FederatingManagerFactory federatingManagerFactory,\n+      BiFunction<DistributionConfig, InternalCacheForClientAccess, ManagementAgent> managementAgentFactory) {\n     this.cache = cache;\n     system = cache.getInternalDistributedSystem();\n+    this.localManagerFactory = localManagerFactory;\n \n     if (!system.isConnected()) {\n       throw new DistributedSystemDisconnectedException(\n@@ -152,18 +174,18 @@ private SystemManagementService(InternalCacheForClientAccess cache) {\n     statisticsClock = cache.getStatisticsClock();\n     jmxAdapter = new MBeanJMXAdapter(system.getDistributedMember());\n     repo = new ManagementResourceRepo();\n-    notificationHub = new NotificationHub(repo);\n+    notificationHub = notificationHubFactory.apply(repo);\n \n     if (system.getConfig().getJmxManager()) {\n-      agent = new ManagementAgent(system.getConfig(), cache);\n+      agent = managementAgentFactory.apply(system.getConfig(), cache);\n     } else {\n       agent = null;\n     }\n \n     FunctionService.registerFunction(new ManagementFunction(notificationHub));\n \n     proxyListeners = new CopyOnWriteArrayList<>();\n-    federatingManagerFactory = createFederatingManagerFactory();\n+    this.federatingManagerFactory = federatingManagerFactory;\n   }\n \n   @Override\n@@ -341,34 +363,28 @@ public void startManager() {\n             \"Manager is already running\");\n       }\n \n-      boolean needsToBeStarted = false;\n       if (!isManagerCreated()) {\n         createManager();\n-        needsToBeStarted = true;\n-      } else if (!federatingManager.isRunning()) {\n-        needsToBeStarted = true;\n       }\n \n-      if (needsToBeStarted) {\n-        boolean started = false;\n-        try {\n-          system.handleResourceEvent(ResourceEvent.MANAGER_START, null);\n-          federatingManager.startManager();\n-          if (agent != null) {\n-            agent.startAgent();\n-          }\n-          cache.getJmxManagerAdvisor().broadcastChange();\n-          started = true;\n-        } catch (RuntimeException | Error e) {\n-          logger.error(\"Jmx manager could not be started because {}\", e.getMessage(), e);\n-          throw e;\n-        } finally {\n-          if (!started) {\n-            if (federatingManager != null) {\n-              federatingManager.stopManager();\n-            }\n-            system.handleResourceEvent(ResourceEvent.MANAGER_STOP, null);\n+      boolean started = false;\n+      try {\n+        system.handleResourceEvent(ResourceEvent.MANAGER_START, null);\n+        federatingManager.startManager();\n+        if (agent != null) {\n+          agent.startAgent();\n+        }\n+        cache.getJmxManagerAdvisor().broadcastChange();\n+        started = true;\n+      } catch (RuntimeException | Error e) {\n+        logger.error(\"Jmx manager could not be started because {}\", e.getMessage(), e);\n+        throw e;\n+      } finally {\n+        if (!started) {\n+          if (federatingManager != null) {\n+            federatingManager.stopManager();\n           }\n+          system.handleResourceEvent(ResourceEvent.MANAGER_STOP, null);\n         }\n       }\n     }\n@@ -672,8 +688,7 @@ private void verifyManagementService() {\n    */\n   private SystemManagementService init() {\n     try {\n-      localManager =\n-          new LocalManager(repo, system, this, cache, statisticsFactory, statisticsClock);\n+      localManager = localManagerFactory.apply(this);\n       listener = new ManagementMembershipListener(this);\n \n       localManager.startManager();\n@@ -690,6 +705,14 @@ private SystemManagementService init() {\n     }\n   }\n \n+  private static LocalManager createLocalManager(SystemManagementService service) {\n+    return service.newLocalManager();\n+  }\n+\n+  private LocalManager newLocalManager() {\n+    return new LocalManager(repo, system, this, cache, statisticsFactory, statisticsClock);\n+  }\n+\n   private static FederatingManagerFactory createFederatingManagerFactory() {\n     try {\n       String federatingManagerFactoryName =",
                "raw_url": "https://github.com/apache/geode/raw/5ec5dd182ac8f523ee83518b4d727a5527203f5a/geode-core/src/main/java/org/apache/geode/management/internal/SystemManagementService.java",
                "sha": "2e9403e4add9e85dfd36ba34c837fc5cd188dc3d",
                "status": "modified"
            },
            {
                "additions": 218,
                "blob_url": "https://github.com/apache/geode/blob/5ec5dd182ac8f523ee83518b4d727a5527203f5a/geode-core/src/test/java/org/apache/geode/management/internal/SystemManagementServiceTest.java",
                "changes": 218,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/SystemManagementServiceTest.java?ref=5ec5dd182ac8f523ee83518b4d727a5527203f5a",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/SystemManagementServiceTest.java",
                "patch": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.management.internal;\n+\n+import static org.apache.geode.distributed.internal.ResourceEvent.MANAGER_START;\n+import static org.apache.geode.distributed.internal.ResourceEvent.MANAGER_STOP;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.clearInvocations;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.quality.Strictness.LENIENT;\n+\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.distributed.internal.DistributionManager;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.cache.InternalCacheForClientAccess;\n+import org.apache.geode.management.AlreadyRunningException;\n+import org.apache.geode.management.ManagementException;\n+\n+public class SystemManagementServiceTest {\n+\n+  @Rule\n+  public MockitoRule rule = MockitoJUnit.rule().strictness(LENIENT);\n+\n+  @Mock\n+  private FederatingManagerFactory federatingManagerFactory;\n+  @Mock\n+  private InternalCacheForClientAccess cache;\n+  @Mock\n+  private DistributionConfig config;\n+  @Mock\n+  private FederatingManager federatingManager;\n+  @Mock\n+  private JmxManagerAdvisor jmxManagerAdvisor;\n+  @Mock\n+  private Function<SystemManagementService, LocalManager> localManagerFactory;\n+  @Mock\n+  private ManagementAgent managementAgent;\n+  @Mock\n+  private BiFunction<DistributionConfig, InternalCacheForClientAccess, ManagementAgent> managementAgentFactory;\n+  @Mock\n+  private Function<ManagementResourceRepo, NotificationHub> notificationHubFactory;\n+  @Mock\n+  private InternalDistributedSystem system;\n+\n+  @Before\n+  public void setup() {\n+    when(config.getJmxManager()).thenReturn(true);\n+\n+    when(system.isConnected()).thenReturn(true);\n+    when(system.getConfig()).thenReturn(config);\n+    when(system.getDistributionManager()).thenReturn(mock(DistributionManager.class));\n+\n+    when(cache.getInternalDistributedSystem()).thenReturn(system);\n+    when(cache.getJmxManagerAdvisor()).thenReturn(jmxManagerAdvisor);\n+\n+    when(federatingManagerFactory\n+        .create(any(), any(), any(), any(), any(), any(), any(), any(), any()))\n+            .thenReturn(federatingManager);\n+\n+    when(managementAgentFactory.apply(any(), any())).thenReturn(managementAgent);\n+    when(notificationHubFactory.apply(any())).thenReturn(mock(NotificationHub.class));\n+    when(localManagerFactory.apply(any())).thenReturn(mock(LocalManager.class));\n+  }\n+\n+  @Test\n+  public void startManager_throws_ifIfNotWillingToBeJmxManager() {\n+    when(config.getJmxManager()).thenReturn(false);\n+\n+    BaseManagementService service = systemManagementService();\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(ManagementException.class);\n+  }\n+\n+  @Test\n+  public void startManager_throws_ifSystemIsNotConnected() {\n+    // Must be connected to construct the service\n+    when(system.isConnected()).thenReturn(true);\n+\n+    BaseManagementService service = systemManagementService();\n+\n+    when(system.isConnected()).thenReturn(false);\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(ManagementException.class);\n+  }\n+\n+  @Test\n+  public void startManager_throws_ifServiceIsClosed() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.close();\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(ManagementException.class);\n+  }\n+\n+  @Test\n+  public void startManager_throws_ifExistingFederatingManagerIsAlreadyRunning() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.startManager();\n+\n+    when(federatingManager.isRunning()).thenReturn(true);\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(AlreadyRunningException.class);\n+  }\n+\n+  @Test\n+  public void startManager_startsExistingFederatingManager_ifNotAlreadyStarted() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.startManager();\n+\n+    clearInvocations(federatingManager);\n+    clearInvocations(federatingManagerFactory);\n+\n+    when(federatingManager.isRunning()).thenReturn(false);\n+\n+    service.startManager();\n+\n+    verify(federatingManager).startManager();\n+\n+    // Verify that the service did not create a second federating manager\n+    verifyNoMoreInteractions(federatingManagerFactory);\n+  }\n+\n+  @Test\n+  public void startManager_startsNewFederatingManager_ifNoExistingFederatingManager() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.startManager();\n+\n+    verify(federatingManagerFactory)\n+        .create(any(), any(), any(), any(), any(), any(), any(), any(), any());\n+    verify(federatingManager).startManager();\n+  }\n+\n+  @Test\n+  public void startManager_reportsManagerStarted() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.startManager();\n+\n+    verify(system).handleResourceEvent(eq(MANAGER_START), any());\n+  }\n+\n+  @Test\n+  public void startManager_broadcastsJmxManagerChange() {\n+    BaseManagementService service = systemManagementService();\n+\n+    service.startManager();\n+\n+    verify(jmxManagerAdvisor, atLeastOnce()).broadcastChange();\n+  }\n+\n+  @Test\n+  public void startManager_stopsFederatingManager_ifRuntimeExceptionAfterStarting() {\n+    BaseManagementService service = systemManagementService();\n+\n+    // Called after starting federating manager\n+    doThrow(new RuntimeException(\"thrown for testing\")).when(managementAgent).startAgent();\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(RuntimeException.class);\n+\n+    verify(federatingManager).stopManager();\n+  }\n+\n+  @Test\n+  public void startManager_reportsManagerStopped_ifRuntimeExceptionAfterStarting() {\n+    BaseManagementService service = systemManagementService();\n+\n+    // Called after starting federating manager\n+    doThrow(new RuntimeException(\"thrown for testing\")).when(managementAgent).startAgent();\n+\n+    assertThatThrownBy(service::startManager)\n+        .isInstanceOf(RuntimeException.class);\n+\n+    verify(system).handleResourceEvent(eq(MANAGER_STOP), any());\n+  }\n+\n+  private BaseManagementService systemManagementService() {\n+    return SystemManagementService.newSystemManagementService(cache, notificationHubFactory,\n+        localManagerFactory, federatingManagerFactory, managementAgentFactory);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/5ec5dd182ac8f523ee83518b4d727a5527203f5a/geode-core/src/test/java/org/apache/geode/management/internal/SystemManagementServiceTest.java",
                "sha": "627a5b4c7db67a9de909b47580870556cb5c7ffd",
                "status": "added"
            }
        ],
        "message": "GEODE-7592: Simplify startManager() precondition checks (#4510)\n\nCo-authored-by: Dale Emery <demery@pivotal.io>\r\nCo-authored-by: Joris Melchior <joris.melchior@gmail.com>\r\n\r\n* LGTM complained about a possible NPE in startManager(). There was no\r\npossibility of an NPE, but precondition-checking code was overly\r\ncomplex, and difficult for LGTM and humans to analyze.\r\n\r\n* Adding the tests required injecting several dependencies.",
        "parent": "https://github.com/apache/geode/commit/fa7463bdaf918afe70cf3fe0a824a4c4f9937a6c",
        "patched_files": [
            "SystemManagementService.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "SystemManagementServiceTest.java"
        ]
    },
    "geode_5eca360": {
        "bug_id": "geode_5eca360",
        "commit": "https://github.com/apache/geode/commit/5eca360b9fc7e637457d60a65091f1a036135a06",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/5eca360b9fc7e637457d60a65091f1a036135a06/geode-core/src/main/java/org/apache/geode/management/internal/cli/shell/unsafe/GfshSignalHandler.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/shell/unsafe/GfshSignalHandler.java?ref=5eca360b9fc7e637457d60a65091f1a036135a06",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/shell/unsafe/GfshSignalHandler.java",
                "patch": "@@ -67,9 +67,10 @@ protected void handleDefault(final sun.misc.Signal sig, final ConsoleReader cons\n     final Signal signal = Signal.valueOfName(sig.getName());\n     switch (signal) {\n       case SIGINT:\n-        String prompt = consoleReader.getPrompt();\n-        consoleReader.resetPromptLine(prompt, \"\", -1);\n-\n+        if (consoleReader != null) {\n+          String prompt = consoleReader.getPrompt();\n+          consoleReader.resetPromptLine(prompt, \"\", -1);\n+        }\n         break;\n       default:\n         final SignalHandler handler = getOriginalSignalHandler(signal);",
                "raw_url": "https://github.com/apache/geode/raw/5eca360b9fc7e637457d60a65091f1a036135a06/geode-core/src/main/java/org/apache/geode/management/internal/cli/shell/unsafe/GfshSignalHandler.java",
                "sha": "d95c976d076d8dca0009459825ed56ce85e787c1",
                "status": "modified"
            }
        ],
        "message": "GEODE-6112: Improve robustness for SIGINT handling\n\n- A NPE was being thrown when trying to Ctrl-C a process running `gfsh start\n  locator`. i.e. a non-interactive gfsh session.",
        "parent": "https://github.com/apache/geode/commit/9529403261ec19ecb7e03b27799c33f621fc0452",
        "patched_files": [
            "GfshSignalHandler.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GfshSignalHandlerTest.java"
        ]
    },
    "geode_635d311": {
        "bug_id": "geode_635d311",
        "commit": "https://github.com/apache/geode/commit/635d3118177f6cae6b0497097e64bdb7a9aee800",
        "file": [
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/BUILDING.md",
                "changes": 68,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/BUILDING.md?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 51,
                "filename": "BUILDING.md",
                "patch": "@@ -1,64 +1,30 @@\n # Building this Release from Source\n \n-Build instructions differ slightly for Unix and Windows platforms.\n All platforms require a Java installation, with JDK 1.8 or more recent version.\n \n-## Build from Source on Unix\n+Set the JAVA\\_HOME environment variable.  For example:\n \n-1. Set the JAVA\\_HOME environment variable.  For example:\n+| Platform | Command |\n+| :---: | --- |\n+|  Unix    | ``export JAVA_HOME=/usr/java/jdk1.8.0_121``            |\n+|  OSX     | ``export JAVA_HOME=`/usr/libexec/java_home -v 1.8``    |\n+|  Windows | ``set JAVA_HOME=\"C:\\Program Files\\Java\\jdk1.8.0_121\"`` |\n \n-    ```     \n-    JAVA_HOME=/usr/java/jdk1.8.0_60\n-    export JAVA_HOME\n-    ```\n-2. Download the project source from the Releases page at [Apache Geode] (http://geode.apache.org), and unpack the source code.\n-3. Within the directory containing the unpacked source code, build without the tests:\n-    \n-    ```\n-    $ ./gradlew build -Dskip.tests=true\n-    ```\n-Or, build with the tests:\n-   \n-    ```\n-    $ ./gradlew build\n-    ```\n-The built binaries will be in `geode-assembly/build/distributions/`,\n-or the `gfsh` script can be found in \n-`geode-assembly/build/install/apache-geode/bin/`.\n-4. Verify the installation by invoking `gfsh` to print version information and exit:\n-   \n-    ```\n-    $ gfsh version\n-    v1.1.0\n-    ```\n+Download the project source from the Releases page at [Apache Geode]\n+(http://geode.apache.org/releases/), and unpack the source code.\n \n-## Build from Source on Windows\n+Within the directory containing the unpacked source code, run the gradle build:\n \n-1. Set the JAVA\\_HOME environment variable.  For example:\n+    $ ./gradlew build\n \n-    ```\n-    $ set JAVA_HOME=\"C:\\Program Files\\Java\\jdk1.8.0_60\"\n-    ```\n-2. Install Gradle, version 2.12 or a more recent version.\n-3. Download the project source from the Releases page at [Apache Geode] (http://geode.apache.org), and unpack the source code.\n-4. Within the folder containing the unpacked source code, build without the tests:\n+Once the build completes, the project files will be installed at\n+`geode-assembly/build/install/apache-geode`. The distribution archives will be\n+created in `geode-assembly/build/distributions/`.\n \n-    ```\n-    $ gradle build -Dskip.test=true\n-    ```\n-Or, build with the tests:\n+Verify the installation by invoking the `gfsh` shell command to print version\n+information:\n \n-    ```\n-    $ gradle build\n-    ```\n-The built binaries will be in `geode-assembly\\build\\distributions\\`,\n-or the `gfsh.bat` script can be found in \n-`geode-assembly\\build\\install\\apache-geode\\bin\\`.\n-4. Verify the installation by invoking `gfsh` to print version information and exit:\n-   \n-    ```\n-    $ gfsh.bat version\n+    $ ./geode-assembly/build/install/apache-geode/bin/gfsh version\n     v1.1.0\n-    ```\n-\n \n+Note: on Windows invoke the `gfsh.bat` script to print the version string.",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/BUILDING.md",
                "sha": "308ef8a9e5c3d75376335036baeb1c75a67bf740",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/LICENSE",
                "changes": 140,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/LICENSE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 139,
                "filename": "LICENSE",
                "patch": "@@ -274,35 +274,6 @@ WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\n IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n \n----------------------------------------------------------------------------\n-The JSON License (http://www.json.org/license.html)\n----------------------------------------------------------------------------\n-\n-Apache Geode bundles the following file under the JSON license:\n-\n-  - JSON (http://www.json.org), Copyright (c) 2002 JSON.org\n-\n-Permission is hereby granted, free of charge, to any person obtaining a\n-copy of this software and associated documentation files (the \"Software\"),\n-to deal in the Software without restriction, including without limitation\n-the rights to use, copy, modify, merge, publish, distribute, sublicense,\n-and/or sell copies of the Software, and to permit persons to whom the\n-Software is furnished to do so, subject to the following conditions:\n-\n-The above copyright notice and this permission notice shall be included in\n-all copies or substantial portions of the Software.\n-\n-The Software shall be used for Good, not Evil.\n-\n-THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n-FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n-DEALINGS IN THE SOFTWARE.\n-\n-\n ---------------------------------------------------------------------------\n The MIT License (http://opensource.org/licenses/mit-license.html)\n ---------------------------------------------------------------------------\n@@ -311,21 +282,9 @@ Apache Geode bundles the following files under the MIT license:\n \n   - Backbone.js v0.9.2 (http://backbonejs.org), Copyright (c) 2010-2012\n     Jeremy Ashkenas, DocumentCloud Inc.\n-  - Bootflat v1.0.1 (http://bootflat.github.io/), Copyright (c) 2014\n-    bootflat\n-  - Font Awesome v4.0.3 (code files) (http://fontawesome.io), Copyright (c)\n-    Dave Gandy\n-  - Handlebars v1.0.0 (http://handlebarsjs.com), Copyright (c) 2011, Yehuda\n-    Katz\n-  - HeadJS v0.96 (http://headjs.com/), Copyright (c) 2013 Tero Piirainen\n-    (tipiirai)\n-  - HTML5 Shiv v3.6.2pre (https://github.com/aFarkas/html5shiv), Copyright\n-    (c) 2014 Alexander Farkas (aFarkas)\n-  - iCheck v0.8 (http://icheck.fronteed.com/), Copyright (c) 2013 Damir\n-    Foy, http://damirfoy.com\n   - JavaScript InfoVis Toolkit v2.0.1 (http://philogb.github.io/jit/), \n     Copyright (c) 2011 Sencha Inc.\n-  - jQuery JavaScript Library v1.7.2, v1.8.0 (https://jquery.com), Copyright (c)\n+  - jQuery JavaScript Library v1.7.2 (https://jquery.com), Copyright (c)\n     jQuery Foundation and other contributors, http://jquery.org\n   - jQuery BBQ v1.2.1 (http://benalman.com/projects/jquery-bbq-plugin/),\n     Copyright (c) 2010, \"Cowboy\" Ben Alman\n@@ -354,8 +313,6 @@ Apache Geode bundles the following files under the MIT license:\n     Proietti, <http://mad4milk.net/>\n   - Normalize.css v2.1.0 (https://necolas.github.io/normalize.css/),\n     Copyright (c) Nicolas Gallagher and Jonathan Neal\n-  - Respond.js v1.1.0 (https://github.com/scottjehl/Respond), Copyright (c)\n-    2012 Scott Jehl\n   - Sizzle.js (http://sizzlejs.com/), Copyright (c) 2011, The Dojo Foundation\n   - Split.js (https://github.com/nathancahill/Split.js), Copyright (c)\n     2015 Nathan Cahill\n@@ -453,98 +410,3 @@ domain:\n     (http://gee.cs.oswego.edu/dl/concurrency-interest).\n   - Reset CSS (http://meyerweb.com/eric/tools/css/reset/)\n   - tooltip.js v1.2.6 (https://github.com/jquerytools/jquerytools)\n-\n-\n----------------------------------------------------------------------------\n-SIL Open Font License (https://opensource.org/licenses/OFL-1.1)\n----------------------------------------------------------------------------\n-\n-Apache Geode bundles the following files under the SIL OFL 1.1 license:\n-\n-  - Font Awesome (font files) (http://fontawesome.io) Copyright (c) Dave\n-    Gandy\n-\n-Version 1.1 - 26 February 2007\n-\n-PREAMBLE\n-The goals of the Open Font License (OFL) are to stimulate worldwide\n-development of collaborative font projects, to support the font creation\n-efforts of academic and linguistic communities, and to provide a free and\n-open framework in which fonts may be shared and improved in partnership\n-with others.\n-\n-The OFL allows the licensed fonts to be used, studied, modified and\n-redistributed freely as long as they are not sold by themselves. The\n-fonts, including any derivative works, can be bundled, embedded,\n-redistributed and/or sold with any software provided that any reserved\n-names are not used by derivative works. The fonts and derivatives,\n-however, cannot be released under any other type of license. The\n-requirement for fonts to remain under this license does not apply\n-to any document created using the fonts or their derivatives.\n-\n-DEFINITIONS\n-\"Font Software\" refers to the set of files released by the Copyright\n-Holder(s) under this license and clearly marked as such. This may\n-include source files, build scripts and documentation.\n-\n-\"Reserved Font Name\" refers to any names specified as such after the\n-copyright statement(s).\n-\n-\"Original Version\" refers to the collection of Font Software components as\n-distributed by the Copyright Holder(s).\n-\n-\"Modified Version\" refers to any derivative made by adding to, deleting,\n-or substituting \u2014 in part or in whole \u2014 any of the components of the\n-Original Version, by changing formats or by porting the Font Software to a\n-new environment.\n-\n-\"Author\" refers to any designer, engineer, programmer, technical\n-writer or other person who contributed to the Font Software.\n-\n-PERMISSION & CONDITIONS\n-Permission is hereby granted, free of charge, to any person obtaining\n-a copy of the Font Software, to use, study, copy, merge, embed, modify,\n-redistribute, and sell modified and unmodified copies of the Font\n-Software, subject to the following conditions:\n-\n-1) Neither the Font Software nor any of its individual components,\n-in Original or Modified Versions, may be sold by itself.\n-\n-2) Original or Modified Versions of the Font Software may be bundled,\n-redistributed and/or sold with any software, provided that each copy\n-contains the above copyright notice and this license. These can be\n-included either as stand-alone text files, human-readable headers or\n-in the appropriate machine-readable metadata fields within text or\n-binary files as long as those fields can be easily viewed by the user.\n-\n-3) No Modified Version of the Font Software may use the Reserved Font\n-Name(s) unless explicit written permission is granted by the corresponding\n-Copyright Holder. This restriction only applies to the primary font name as\n-presented to the users.\n-\n-4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font\n-Software shall not be used to promote, endorse or advertise any\n-Modified Version, except to acknowledge the contribution(s) of the\n-Copyright Holder(s) and the Author(s) or with their explicit written\n-permission.\n-\n-5) The Font Software, modified or unmodified, in part or in whole,\n-must be distributed entirely under this license, and must not be\n-distributed under any other license. The requirement for fonts to\n-remain under this license does not apply to any document created\n-using the Font Software.\n-\n-TERMINATION\n-This license becomes null and void if any of the above conditions are\n-not met.\n-\n-DISCLAIMER\n-THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n-EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF\n-MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT\n-OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE\n-COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n-INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL\n-DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n-FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM\n-OTHER DEALINGS IN THE FONT SOFTWARE.",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/LICENSE",
                "sha": "e5f1557cfb909a1798e67405b3fa560ec81d1fad",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/NOTICE",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/NOTICE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "NOTICE",
                "patch": "@@ -18,6 +18,4 @@ Copyright 2016 AddThis\n    Copyright 2014 The Apache Software Foundation\n \n This product includes software developed by the MX4J\n-project (http://mx4j.sourceforge.net).\n-\n-This project includes software licensed under the JSON license.\n+project (http://mx4j.sourceforge.net).\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/NOTICE",
                "sha": "d27ae96d519ce41ec4a3a907ed358af4c118ab74",
                "status": "modified"
            },
            {
                "additions": 127,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/README.md",
                "changes": 162,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/README.md?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 35,
                "filename": "README.md",
                "patch": "@@ -1,102 +1,195 @@\n [<img src=\"https://geode.apache.org/img/apache_geode_logo.png\" align=\"center\"/>](http://geode.apache.org)\n \n-[![Build Status](https://travis-ci.org/apache/geode.svg?branch=develop)](https://travis-ci.org/apache/geode) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0) [![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.apache.geode/geode-core/badge.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.geode%22)\n+[![Build Status](https://travis-ci.org/apache/geode.svg?branch=develop)](https://travis-ci.org/apache/geode) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0) [![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.apache.geode/geode-core/badge.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.geode%22) [![homebrew](https://img.shields.io/homebrew/v/apache-geode.svg)](http://brewformulas.org/ApacheGeode) [![Docker Pulls](https://img.shields.io/docker/pulls/apachegeode/geode.svg)](https://hub.docker.com/r/apachegeode/geode/)\n+\n \n ## Contents\n-1. [Overview](#overview)  \n+1. [Overview](#overview)\n+2. [How to Get Apache Geode](#obtaining)\n 2. [Main Concepts and Components](#concepts)\n 3. [Location of Directions for Building from Source](#building)\n 4. [Geode in 5 minutes](#started)\n 5. [Application Development](#development)\n 6. [Documentation](http://geode.apache.org/docs/)\n 7. [Wiki](https://cwiki.apache.org/confluence/display/GEODE/Index)\n-                                                                                                                       \n \n-## <a name=\"overview\"></a>Overview\n-[Apache Geode](http://geode.apache.org/) is a data management platform that provides real-time, consistent access to data-intensive applications throughout widely distributed cloud architectures.\n \n-Apache Geode pools memory, CPU, network resources, and optionally local disk across multiple processes to manage application objects and behavior. It uses dynamic replication and data partitioning techniques to implement high availability, improved performance, scalability, and fault tolerance. In addition to being a distributed data container, Apache Geode is an in-memory data management system that provides reliable asynchronous event notifications and guaranteed message delivery.\n+## <a name=\"overview\"></a>Overview\n \n-Apache Geode is a mature, robust technology originally developed by GemStone Systems in Beaverton, Oregon. Commercially available as GemFire\u2122, the technology was first deployed in the financial sector as the transactional, low-latency data engine used in Wall Street trading platforms.  Today Apache Geode is used by over 600 enterprise customers for high-scale business applications that must meet low latency and 24x7 availability requirements. An example deployment includes [China National Railways](http://pivotal.io/big-data/case-study/scaling-online-sales-for-the-largest-railway-in-the-world-china-railway-corporation) that uses Geode to run railway ticketing for the entire country of China with a 10 node cluster that manages 2 terabytes of \"hot data\" in memory, and 10 backup nodes for high availability and elastic scale.\n+[Apache Geode](http://geode.apache.org/) is\n+a data management platform that provides real-time, consistent access to\n+data-intensive applications throughout widely distributed cloud architectures.\n+\n+Apache Geode pools memory, CPU, network resources, and optionally local disk\n+across multiple processes to manage application objects and behavior. It uses\n+dynamic replication and data partitioning techniques to implement high\n+availability, improved performance, scalability, and fault tolerance. In\n+addition to being a distributed data container, Apache Geode is an in-memory\n+data management system that provides reliable asynchronous event notifications\n+and guaranteed message delivery.\n+\n+Apache Geode is a mature, robust technology originally developed by GemStone\n+Systems. Commercially available as GemFire\u2122, it was first deployed in the\n+financial sector as the transactional, low-latency data engine used in Wall\n+Street trading platforms.  Today Apache Geode technology is used by hundreds of\n+enterprise customers for high-scale business applications that must meet low\n+latency and 24x7 availability requirements.\n+\n+## <a name=\"obtaining\"></a>How to Get Apache Geode\n+\n+You can download Apache Geode from the\n+[website](http://geode.apache.org/releases/), run a Docker\n+[image](https://hub.docker.com/r/apachegeode/geode/), or install with\n+[homebrew](http://brewformulas.org/ApacheGeode) on OSX. Application developers\n+can load dependencies from [Maven\n+Central](https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.geode%22).\n+\n+Maven\n+```\n+<dependencies>\n+    <dependency>\n+        <groupId>org.apache.geode</groupId>\n+        <artifactId>geode-core</artifactId>\n+        <version>$VERSION</version>\n+    </dependency>\n+</dependencies>\n+```\n+\n+Gradle\n+```\n+dependencies {\n+  compile \"org.apache.geode:geode-core:$VERSION\"\n+}\n+```\n \n ## <a name=\"concepts\"></a>Main Concepts and Components\n \n-_Caches_ are an abstraction that describe a node in an Apache Geode distributed system.\n+_Caches_ are an abstraction that describe a node in an Apache Geode distributed\n+system.\n \n-Within each cache, you define data _regions_. Data regions are analogous to tables in a relational database and manage data in a distributed fashion as name/value pairs. A _replicated_ region stores identical copies of the data on each cache member of a distributed system. A _partitioned_ region spreads the data among cache members. After the system is configured, client applications can access the distributed data in regions without knowledge of the underlying system architecture. You can define listeners to receive notifications when data has changed, and you can define expiration criteria to delete obsolete data in a region.\n+Within each cache, you define data _regions_. Data regions are analogous to\n+tables in a relational database and manage data in a distributed fashion as\n+name/value pairs. A _replicated_ region stores identical copies of the data on\n+each cache member of a distributed system. A _partitioned_ region spreads the\n+data among cache members. After the system is configured, client applications\n+can access the distributed data in regions without knowledge of the underlying\n+system architecture. You can define listeners to receive notifications when\n+data has changed, and you can define expiration criteria to delete obsolete\n+data in a region.\n \n-_Locators_ provide clients with both discovery and server load balancing services. Clients are configured with locator information, and the locators maintain a dynamic list of member servers. The locators provide clients with connection information to a server. \n+_Locators_ provide clients with both discovery and server load balancing\n+services. Clients are configured with locator information, and the locators\n+maintain a dynamic list of member servers. The locators provide clients with\n+connection information to a server.\n \n Apache Geode includes the following features:\n \n-* Combines redundancy, replication, and a \"shared nothing\" persistence architecture to deliver fail-safe reliability and performance.\n-* Horizontally scalable to thousands of cache members, with multiple cache topologies to meet different enterprise needs. The cache can be distributed across multiple computers.\n+* Combines redundancy, replication, and a \"shared nothing\" persistence\n+  architecture to deliver fail-safe reliability and performance.\n+* Horizontally scalable to thousands of cache members, with multiple cache\n+  topologies to meet different enterprise needs. The cache can be\n+  distributed across multiple computers.\n * Asynchronous and synchronous cache update propagation.\n-* Delta propagation distributes only the difference between old and new versions of an object (delta) instead of the entire object, resulting in significant distribution cost savings.\n-* Reliable asynchronous event notifications and guaranteed message delivery through optimized, low latency distribution layer.\n-* Applications run 4 to 40 times faster with no additional hardware.\n-* Data awareness and real-time business intelligence. If data changes as you retrieve it, you see the changes immediately.\n-* Integration with Spring Framework to speed and simplify the development of scalable, transactional enterprise applications.\n+* Delta propagation distributes only the difference between old and new\n+  versions of an object (delta) instead of the entire object, resulting in\n+  significant distribution cost savings.\n+* Reliable asynchronous event notifications and guaranteed message delivery\n+  through optimized, low latency distribution layer.\n+* Data awareness and real-time business intelligence. If data changes as\n+  you retrieve it, you see the changes immediately.\n+* Integration with Spring Framework to speed and simplify the development\n+  of scalable, transactional enterprise applications.\n * JTA compliant transaction support.\n-* Cluster-wide configurations that can be persisted and exported to other clusters.\n+* Cluster-wide configurations that can be persisted and exported to other\n+  clusters.\n * Remote cluster management through HTTP.\n * REST APIs for REST-enabled application development.\n-* Rolling upgrades may be possible, but they will be subject to any limitations imposed by new features.\n+* Rolling upgrades may be possible, but they will be subject to any\n+  limitations imposed by new features.\n \n ## <a name=\"building\"></a>Building this Release from Source\n \n-Directions to build Apache Geode from source are in the source distribution, file `BUILDING.md`.\n+See [BUILDING.md](https://github.com/apache/geode/blob/develop/BUILDING.md) for\n+instructions on how to build the project.\n \n ## <a name=\"started\"></a>Geode in 5 minutes\n \n-With a JDK version 1.8 or a more recent version installed,\n+Geode requires installation of JDK version 1.8.  After installing Apache Geode,\n start a locator and server:\n \n     $ gfsh\n-    gfsh> start locator --name=locator\n-    gfsh> start server --name=server\n+    gfsh> start locator\n+    gfsh> start server\n \n Create a region:\n \n-    gfsh> create region --name=region --type=REPLICATE\n+    gfsh> create region --name=hello --type=REPLICATE\n+\n+Write a client application (this example uses a [Gradle](https://gradle.org)\n+build script):\n+\n+_build.gradle_\n \n-Write a client application:\n+    apply plugin: 'java'\n+    apply plugin: 'application'\n \n-_HelloWorld.java_\n+    mainClassName = 'HelloWorld'\n+\n+    repositories { mavenCentral() }\n+    dependencies {\n+      compile 'org.apache.geode:geode-core:1.1.0'\n+      runtime 'org.slf4j:slf4j-log4j12:1.7.24'\n+    }\n+\n+_src/main/java/HelloWorld.java_\n \n     import java.util.Map;\n     import org.apache.geode.cache.Region;\n     import org.apache.geode.cache.client.*;\n-    \n+\n     public class HelloWorld {\n       public static void main(String[] args) throws Exception {\n         ClientCache cache = new ClientCacheFactory()\n           .addPoolLocator(\"localhost\", 10334)\n           .create();\n         Region<String, String> region = cache\n           .<String, String>createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)\n-          .create(\"region\");\n-    \n+          .create(\"hello\");\n+\n         region.put(\"1\", \"Hello\");\n         region.put(\"2\", \"World\");\n-    \n+\n         for (Map.Entry<String, String>  entry : region.entrySet()) {\n           System.out.format(\"key = %s, value = %s\\n\", entry.getKey(), entry.getValue());\n         }\n         cache.close();\n       }\n     }\n \n-Compile and run `HelloWorld.java`.  The classpath should include `geode-dependencies.jar`.\n+Build and run the `HelloWorld` example:\n+\n+    $ gradle run\n+\n+The application will connect to the running cluster, create a local cache, put\n+some data in the cache, and print the cached data to the console:\n \n-    javac -cp /some/path/geode/geode-assembly/build/install/apache-geode/lib/geode-dependencies.jar HelloWorld.java\n-    java -cp .:/some/path/geode/geode-assembly/build/install/apache-geode/lib/geode-dependencies.jar HelloWorld\n+    key = 1, value = Hello\n+    key = 2, value = World\n+\n+Finally, shutdown the Geode server and locator:\n+\n+    $ gfsh> shutdown --include-locators=true\n+\n+For more information see the [Geode\n+Examples](https://github.com/apache/geode-examples) repository or the\n+[documentation](http://geode.apache.org/docs/).\n \n ## <a name=\"development\"></a>Application Development\n \n Apache Geode applications can be written in these client technologies:\n \n-* Java [client](http://geode.apache.org/docs/guide/topologies_and_comm/cs_configuration/chapter_overview.html) or [peer](http://geode.apache.org/docs/guide/topologies_and_comm/p2p_configuration/chapter_overview.html)\n+* Java [client](http://geode.apache.org/docs/guide/topologies_and_comm/cs_configuration/chapter_overview.html)\n+  or [peer](http://geode.apache.org/docs/guide/topologies_and_comm/p2p_configuration/chapter_overview.html)\n * [REST](http://geode.apache.org/docs/guide/rest_apps/chapter_overview.html)\n * [Memcached](https://cwiki.apache.org/confluence/display/GEODE/Moving+from+memcached+to+gemcached)\n * [Redis](https://cwiki.apache.org/confluence/display/GEODE/Geode+Redis+Adapter)\n@@ -106,4 +199,3 @@ The following libraries are available external to the Apache Geode project:\n * [Spring Data GemFire](http://projects.spring.io/spring-data-gemfire/)\n * [Spring Cache](http://docs.spring.io/spring/docs/current/spring-framework-reference/html/cache.html)\n * [Python](https://github.com/gemfire/py-gemfire-rest)\n-",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/README.md",
                "sha": "0909364cf0d857b57e79e0bb103cd333576c7e01",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/installer/InstallerJUnitTest.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/installer/InstallerJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 10,
                "filename": "extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/installer/InstallerJUnitTest.java",
                "patch": "@@ -14,22 +14,21 @@\n  */\n package org.apache.geode.modules.session.installer;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.ByteArrayOutputStream;\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.InputStream;\n-\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n+import static org.junit.Assert.assertEquals;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.commons.io.IOUtils;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n import org.junit.rules.TemporaryFolder;\n \n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+\n @Category(IntegrationTest.class)\n public class InstallerJUnitTest {\n \n@@ -43,7 +42,7 @@ public void installIntoWebXML() throws Exception {\n \n   private void testTransformation(final String name) throws Exception {\n     File webXmlFile = temporaryFolder.newFile();\n-    FileUtil.copy(getClass().getResource(name), webXmlFile);\n+    FileUtils.copyFile(new File(getClass().getResource(name).getFile()), webXmlFile);\n     final String[] args = {\"-t\", \"peer-to-peer\", \"-w\", webXmlFile.getAbsolutePath()};\n \n     ByteArrayOutputStream output = new ByteArrayOutputStream();",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/extensions/geode-modules-session/src/test/java/org/apache/geode/modules/session/installer/InstallerJUnitTest.java",
                "sha": "aa3e0d22d7aaf155b7e9cc7f45e3359a1db530d2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/build.gradle",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/build.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-assembly/build.gradle",
                "patch": "@@ -168,7 +168,6 @@ def cp = {\n         it.contains('spring-core') ||\n         it.contains('spring-shell') ||\n         it.contains('snappy') ||\n-        it.contains('hbase') ||\n         it.contains('jgroups') ||\n         it.contains('netty') ||\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/build.gradle",
                "sha": "1c95927f19888b15e771b3cbbc92f120787868c4",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/main/dist/LICENSE",
                "changes": 137,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/main/dist/LICENSE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 137,
                "filename": "geode-assembly/src/main/dist/LICENSE",
                "patch": "@@ -595,52 +595,12 @@ Federal Courts of the Northern District of California and the state courts\n of the State of California, with venue lying in Santa Clara County,\n California.\n \n-\n----------------------------------------------------------------------------\n-The JSON License (http://www.json.org/license.html)\n----------------------------------------------------------------------------\n-\n-Apache Geode bundles the following file under the JSON license:\n-\n-  - JSON (http://www.json.org), Copyright (c) 2002 JSON.org\n-\n-Permission is hereby granted, free of charge, to any person obtaining a\n-copy of this software and associated documentation files (the \"Software\"),\n-to deal in the Software without restriction, including without limitation\n-the rights to use, copy, modify, merge, publish, distribute, sublicense,\n-and/or sell copies of the Software, and to permit persons to whom the\n-Software is furnished to do so, subject to the following conditions:\n-\n-The above copyright notice and this permission notice shall be included in\n-all copies or substantial portions of the Software.\n-\n-The Software shall be used for Good, not Evil.\n-\n-THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n-FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n-DEALINGS IN THE SOFTWARE.\n-\n-\n ---------------------------------------------------------------------------\n The MIT License (http://opensource.org/licenses/mit-license.html)\n ---------------------------------------------------------------------------\n \n Apache Geode bundles the following files under the MIT license:\n \n-  - Bootflat v1.0.1 (http://bootflat.github.io/), Copyright (c) 2014\n-    bootflat\n-  - Font Awesome v4.0.3 (code files) (http://fontawesome.io), Copyright (c)\n-    Dave Gandy\n-  - HeadJS v0.96 (http://headjs.com/), Copyright (c) 2013 Tero Piirainen\n-    (tipiirai)\n-  - HTML5 Shiv v3.6.2pre (https://github.com/aFarkas/html5shiv), Copyright\n-    (c) 2014 Alexander Farkas (aFarkas)\n-  - iCheck v0.8 (http://icheck.fronteed.com/), Copyright (c) 2013 Damir\n-    Foy, http://damirfoy.com\n   - JavaScript InfoVis Toolkit v2.0.1 (http://philogb.github.io/jit/),\n     Copyright (c) 2011 Sencha Inc.\n   - JOpt Simple (http://pholser.github.io/jopt-simple/), Copyright (c)\n@@ -670,8 +630,6 @@ Apache Geode bundles the following files under the MIT license:\n     Proietti, <http://mad4milk.net/>\n   - Normalize.css v2.1.0 (https://necolas.github.io/normalize.css/),\n     Copyright (c) Nicolas Gallagher and Jonathan Neal\n-  - Respond.js v1.1.0 (https://github.com/scottjehl/Respond), Copyright (c)\n-    2012 Scott Jehl\n   - SLF4J API v1.7.21 (http://www.slf4j.org), Copyright (c) 2004-2013 QOS.ch\n   - sizzle.js (http://sizzlejs.com/), Copyright (c) 2011, The Dojo Foundation\n   - Split.js (https://github.com/nathancahill/Split.js), Copyright (c)\n@@ -767,98 +725,3 @@ domain:\n   - CompactConcurrentHashSet2, derived from JSR-166 ConcurrentHashMap v1.43\n     (http://gee.cs.oswego.edu/dl/concurrency-interest).\n   - tooltip.js v1.2.6 (https://github.com/jquerytools/jquerytools)\n-\n-\n----------------------------------------------------------------------------\n-SIL Open Font License (https://opensource.org/licenses/OFL-1.1)\n----------------------------------------------------------------------------\n-\n-Apache Geode bundles the following files under the SIL OFL 1.1 license:\n-\n-  - Font Awesome (font files) (http://fontawesome.io) Copyright (c) Dave\n-    Gandy\n-\n-Version 1.1 - 26 February 2007\n-\n-PREAMBLE\n-The goals of the Open Font License (OFL) are to stimulate worldwide\n-development of collaborative font projects, to support the font creation\n-efforts of academic and linguistic communities, and to provide a free and\n-open framework in which fonts may be shared and improved in partnership\n-with others.\n-\n-The OFL allows the licensed fonts to be used, studied, modified and\n-redistributed freely as long as they are not sold by themselves. The\n-fonts, including any derivative works, can be bundled, embedded,\n-redistributed and/or sold with any software provided that any reserved\n-names are not used by derivative works. The fonts and derivatives,\n-however, cannot be released under any other type of license. The\n-requirement for fonts to remain under this license does not apply\n-to any document created using the fonts or their derivatives.\n-\n-DEFINITIONS\n-\"Font Software\" refers to the set of files released by the Copyright\n-Holder(s) under this license and clearly marked as such. This may\n-include source files, build scripts and documentation.\n-\n-\"Reserved Font Name\" refers to any names specified as such after the\n-copyright statement(s).\n-\n-\"Original Version\" refers to the collection of Font Software components as\n-distributed by the Copyright Holder(s).\n-\n-\"Modified Version\" refers to any derivative made by adding to, deleting,\n-or substituting \u2014 in part or in whole \u2014 any of the components of the\n-Original Version, by changing formats or by porting the Font Software to a\n-new environment.\n-\n-\"Author\" refers to any designer, engineer, programmer, technical\n-writer or other person who contributed to the Font Software.\n-\n-PERMISSION & CONDITIONS\n-Permission is hereby granted, free of charge, to any person obtaining\n-a copy of the Font Software, to use, study, copy, merge, embed, modify,\n-redistribute, and sell modified and unmodified copies of the Font\n-Software, subject to the following conditions:\n-\n-1) Neither the Font Software nor any of its individual components,\n-in Original or Modified Versions, may be sold by itself.\n-\n-2) Original or Modified Versions of the Font Software may be bundled,\n-redistributed and/or sold with any software, provided that each copy\n-contains the above copyright notice and this license. These can be\n-included either as stand-alone text files, human-readable headers or\n-in the appropriate machine-readable metadata fields within text or\n-binary files as long as those fields can be easily viewed by the user.\n-\n-3) No Modified Version of the Font Software may use the Reserved Font\n-Name(s) unless explicit written permission is granted by the corresponding\n-Copyright Holder. This restriction only applies to the primary font name as\n-presented to the users.\n-\n-4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font\n-Software shall not be used to promote, endorse or advertise any\n-Modified Version, except to acknowledge the contribution(s) of the\n-Copyright Holder(s) and the Author(s) or with their explicit written\n-permission.\n-\n-5) The Font Software, modified or unmodified, in part or in whole,\n-must be distributed entirely under this license, and must not be\n-distributed under any other license. The requirement for fonts to\n-remain under this license does not apply to any document created\n-using the Font Software.\n-\n-TERMINATION\n-This license becomes null and void if any of the above conditions are\n-not met.\n-\n-DISCLAIMER\n-THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n-EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF\n-MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT\n-OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE\n-COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n-INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL\n-DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n-FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM\n-OTHER DEALINGS IN THE FONT SOFTWARE.",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/main/dist/LICENSE",
                "sha": "2f2de9530a2d907a864dbf1bb33e2c3a6d58279b",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/main/dist/NOTICE",
                "changes": 145,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/main/dist/NOTICE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 135,
                "filename": "geode-assembly/src/main/dist/NOTICE",
                "patch": "@@ -20,15 +20,13 @@ Copyright 2016 AddThis\n This product includes software developed by the MX4J\n project (http://mx4j.sourceforge.net).\n \n-This project includes software licensed under the JSON license.\n-\n Java ClassMate library was originally written by Tatu Saloranta (tatu.saloranta@iki.fi)\n \n   Other developers who have contributed code are:\n   \n   * Brian Langel\n \n-Jackson Core 2.8.2\n+Jackson Core 2.8.6\n \n   # Jackson JSON processor\n \n@@ -64,14 +62,7 @@ Apache Lucene\n    - Apache Jakarta Regexp\n    - Apache Commons\n    - Apache Xerces\n-  \n-  ICU4J, (under analysis/icu) is licensed under an MIT styles license\n-  and Copyright (c) 1995-2008 International Business Machines Corporation and others\n-  \n-  Some data files (under analysis/icu/src/data) are derived from Unicode data such\n-  as the Unicode Character Database. See http://unicode.org/copyright.html for more\n-  details.\n-  \n+ \n   Brics Automaton (under core/src/java/org/apache/lucene/util/automaton) is \n   BSD-licensed, created by Anders M\u00f8ller. See http://www.brics.dk/automaton/\n   \n@@ -87,13 +78,6 @@ Apache Lucene\n   The Google Code Prettify is Apache License 2.0.\n   See http://code.google.com/p/google-code-prettify/\n   \n-  JUnit (junit-4.10) is licensed under the Common Public License v. 1.0\n-  See http://junit.sourceforge.net/cpl-v10.html\n-  \n-  This product includes code (JaspellTernarySearchTrie) from Java Spelling Checkin\n-  g Package (jaspell): http://jaspell.sourceforge.net/\n-  License: The BSD License (http://www.opensource.org/licenses/bsd-license.php)\n-  \n   The snowball stemmers in\n     analysis/common/src/java/net/sf/snowball\n   were developed by Martin Porter and Richard Boulton.\n@@ -132,120 +116,11 @@ Apache Lucene\n   analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLightStemmer.java\n   analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemmer.java\n   \n-  The Stempel analyzer (stempel) includes BSD-licensed software developed \n-  by the Egothor project http://egothor.sf.net/, created by Leo Galambos, Martin Kvapil,\n-  and Edmond Nolan.\n-  \n-  The Polish analyzer (stempel) comes with a default\n-  stopword list that is BSD-licensed created by the Carrot2 project. The file resides\n-  in stempel/src/resources/org/apache/lucene/analysis/pl/stopwords.txt.\n-  See http://project.carrot2.org/license.html.\n-  \n-  The SmartChineseAnalyzer source code (smartcn) was\n-  provided by Xiaoping Gao and copyright 2009 by www.imdict.net.\n-  \n-  WordBreakTestUnicode_*.java (under modules/analysis/common/src/test/) \n-  is derived from Unicode data such as the Unicode Character Database. \n-  See http://unicode.org/copyright.html for more details.\n-  \n-  The Morfologik analyzer (morfologik) includes BSD-licensed software\n-  developed by Dawid Weiss and Marcin Mi\u0142kowski (http://morfologik.blogspot.com/).\n-  \n-  Morfologik uses data from Polish ispell/myspell dictionary\n-  (http://www.sjp.pl/slownik/en/) licenced on the terms of (inter alia)\n-  LGPL and Creative Commons ShareAlike.\n-  \n-  Morfologic includes data from BSD-licensed dictionary of Polish (SGJP)\n-  (http://sgjp.pl/morfeusz/)\n-  \n-  Servlet-api.jar and javax.servlet-*.jar are under the CDDL license, the original\n-  source code for this can be found at http://www.eclipse.org/jetty/downloads.php\n-  \n-  ===========================================================================\n-  Kuromoji Japanese Morphological Analyzer - Apache Lucene Integration\n-  ===========================================================================\n-  \n-  This software includes a binary and/or source version of data from\n-  \n-    mecab-ipadic-2.7.0-20070801\n-  \n-  which can be obtained from\n-  \n-    http://atilika.com/releases/mecab-ipadic/mecab-ipadic-2.7.0-20070801.tar.gz\n-  \n-  or\n-  \n-    http://jaist.dl.sourceforge.net/project/mecab/mecab-ipadic/2.7.0-20070801/mecab-ipadic-2.7.0-20070801.tar.gz\n-  \n-  ===========================================================================\n-  mecab-ipadic-2.7.0-20070801 Notice\n-  ===========================================================================\n-  \n-  Nara Institute of Science and Technology (NAIST),\n-  the copyright holders, disclaims all warranties with regard to this\n-  software, including all implied warranties of merchantability and\n-  fitness, in no event shall NAIST be liable for\n-  any special, indirect or consequential damages or any damages\n-  whatsoever resulting from loss of use, data or profits, whether in an\n-  action of contract, negligence or other tortuous action, arising out\n-  of or in connection with the use or performance of this software.\n-  \n-  A large portion of the dictionary entries\n-  originate from ICOT Free Software.  The following conditions for ICOT\n-  Free Software applies to the current dictionary as well.\n-  \n-  Each User may also freely distribute the Program, whether in its\n-  original form or modified, to any third party or parties, PROVIDED\n-  that the provisions of Section 3 (\"NO WARRANTY\") will ALWAYS appear\n-  on, or be attached to, the Program, which is distributed substantially\n-  in the same form as set out herein and that such intended\n-  distribution, if actually made, will neither violate or otherwise\n-  contravene any of the laws and regulations of the countries having\n-  jurisdiction over the User or the intended distribution itself.\n-  \n-  NO WARRANTY\n-  \n-  The program was produced on an experimental basis in the course of the\n-  research and development conducted during the project and is provided\n-  to users as so produced on an experimental basis.  Accordingly, the\n-  program is provided without any warranty whatsoever, whether express,\n-  implied, statutory or otherwise.  The term \"warranty\" used herein\n-  includes, but is not limited to, any warranty of the quality,\n-  performance, merchantability and fitness for a particular purpose of\n-  the program and the nonexistence of any infringement or violation of\n-  any right of any third party.\n-  \n-  Each user of the program will agree and understand, and be deemed to\n-  have agreed and understood, that there is no warranty whatsoever for\n-  the program and, accordingly, the entire risk arising from or\n-  otherwise connected with the program is assumed by the user.\n-  \n-  Therefore, neither ICOT, the copyright holder, or any other\n-  organization that participated in or was otherwise related to the\n-  development of the program and their respective officials, directors,\n-  officers and other employees shall be held liable for any and all\n-  damages, including, without limitation, general, special, incidental\n-  and consequential damages, arising out of or otherwise in connection\n-  with the use or inability to use the program or any product, material\n-  or result produced or otherwise obtained by using the program,\n-  regardless of whether they have been advised of, or otherwise had\n-  knowledge of, the possibility of such damages at any time during the\n-  project or thereafter.  Each user will be deemed to have agreed to the\n-  foregoing by his or her commencement of use of the program.  The term\n-  \"use\" as used herein includes, but is not limited to, the use,\n-  modification, copying and distribution of the program and the\n-  production of secondary products from the program.\n-  \n-  In the case where the program, whether in its original form or\n-  modified, was distributed or delivered to or received by a user from\n-  any person, organization or entity other than ICOT, unless it makes or\n-  grants independently of ICOT any specific warranty to the user in\n-  writing, such person, organization or entity, will also be exempted\n-  from and not be held liable to the user for any such damages as noted\n-  above as far as the program is concerned.\n+Servlet-api.jar and javax.servlet-*.jar are under the CDDL license, the original\n+source code for this can be found at http://www.eclipse.org/jetty/downloads.php\n \n-Spring Framework 4.3.2.RELEASE\n-Copyright (c) 2002-2015 Pivotal, Inc.\n+Spring Framework 4.3.6.RELEASE\n+Copyright (c) 2002-2017 Pivotal, Inc.\n \n   This product is licensed to you under the Apache License, Version 2.0\n   (the \"License\"). You may not use this product except in compliance with\n@@ -256,8 +131,8 @@ Copyright (c) 2002-2015 Pivotal, Inc.\n   these subcomponents is subject to the terms and conditions of the\n   subcomponent's license, as noted in the license.txt file.\n \n-Spring Hateoas 0.21.0\n-Copyright (c) [2012-2014] Pivotal Software, Inc.\n+Spring Hateoas 0.23.0.RELEASE\n+Copyright (c) [2012-2017] Pivotal Software, Inc.\n \n   This product is licensed to you under the Apache License, Version 2.0 (the \"License\").  \n   You may not use this product except in compliance with the License.  \n@@ -267,12 +142,12 @@ Copyright (c) [2012-2014] Pivotal Software, Inc.\n   code for the these subcomponents is subject to the terms and\n   conditions of the subcomponent's license, as noted in the LICENSE file.\n \n-Spring LDAP Core 2.1.0\n+Spring LDAP Core 2.3.1.RELEASE\n \n    This product includes software developed by the Spring LDAP\n    Project (http://www.springframework.org/ldap).\n \n-Spring Shell 1.2.0\n+Spring Shell 1.2.0.RELEASE\n \n    This product includes software developed by the Spring Framework\n    Project (http://www.springframework.org).",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/main/dist/NOTICE",
                "sha": "0985dc2954b2459b45791ed5d0cb294991cf0127",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/java/org/apache/geode/BundledJarsJUnitTest.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/test/java/org/apache/geode/BundledJarsJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 14,
                "filename": "geode-assembly/src/test/java/org/apache/geode/BundledJarsJUnitTest.java",
                "patch": "@@ -14,29 +14,28 @@\n  */\n package org.apache.geode;\n \n-import static org.junit.Assert.*;\n+import static org.junit.Assert.assertTrue;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.apache.geode.test.junit.categories.RestAPITest;\n+import org.apache.geode.util.test.TestUtil;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n \n import java.io.File;\n import java.io.IOException;\n import java.nio.file.Files;\n import java.nio.file.Paths;\n-import java.util.List;\n+import java.util.Collection;\n import java.util.Set;\n import java.util.TreeMap;\n import java.util.TreeSet;\n import java.util.jar.JarFile;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n-import org.apache.geode.test.junit.categories.RestAPITest;\n-import org.junit.Before;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n-import org.apache.geode.util.test.TestUtil;\n-\n @Category({IntegrationTest.class, RestAPITest.class})\n public class BundledJarsJUnitTest {\n \n@@ -93,11 +92,11 @@ public void verifyBundledJarsHaveNotChanged() throws IOException {\n         \"Please set the GEODE_HOME environment variable to the product installation directory.\",\n         geodeHomeDirectory.isDirectory());\n \n-    List<File> jars = FileUtil.findAll(geodeHomeDirectory, \".*\\\\.jar\");\n+    Collection<File> jars = FileUtils.listFiles(geodeHomeDirectory, new String[] {\"jar\"}, true);\n     TreeMap<String, String> sortedJars = new TreeMap<String, String>();\n-    jars.stream().forEach(jar -> sortedJars.put(jar.getName(), jar.getPath()));\n+    jars.forEach(jar -> sortedJars.put(jar.getName(), jar.getPath()));\n \n-    List<File> wars = FileUtil.findAll(geodeHomeDirectory, \".*\\\\.war\");\n+    Collection<File> wars = FileUtils.listFiles(geodeHomeDirectory, new String[] {\"war\"}, true);\n     TreeSet<File> sortedWars = new TreeSet<File>(wars);\n     sortedWars.stream().flatMap(BundledJarsJUnitTest::extractJarNames)\n         .forEach(jar -> sortedJars.put(jar.getName(), jar.getPath()));",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/java/org/apache/geode/BundledJarsJUnitTest.java",
                "sha": "3f0e2c07a82e1a7e19716ca8bcf9f5adbc9bf38e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/java/org/apache/geode/management/internal/configuration/ClusterConfigurationServiceEndToEndDUnitTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/test/java/org/apache/geode/management/internal/configuration/ClusterConfigurationServiceEndToEndDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 8,
                "filename": "geode-assembly/src/test/java/org/apache/geode/management/internal/configuration/ClusterConfigurationServiceEndToEndDUnitTest.java",
                "patch": "@@ -27,8 +27,6 @@\n import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n import static org.apache.geode.distributed.ConfigurationProperties.NAME;\n import static org.apache.geode.internal.AvailablePortHelper.getRandomAvailableTCPPorts;\n-import static org.apache.geode.internal.FileUtil.delete;\n-import static org.apache.geode.internal.FileUtil.deleteMatching;\n import static org.apache.geode.internal.lang.StringUtils.isBlank;\n import static org.apache.geode.management.internal.cli.CliUtil.getAllNormalMembers;\n import static org.apache.geode.test.dunit.Assert.assertEquals;\n@@ -48,7 +46,6 @@\n import org.apache.geode.distributed.Locator;\n import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.internal.ClassBuilder;\n-import org.apache.geode.internal.JarDeployer;\n import org.apache.geode.internal.admin.remote.ShutdownAllRequest;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.management.cli.Result.Status;\n@@ -323,11 +320,6 @@ private void createAndDeployJar(final String jarName) throws IOException {\n     jarFileNames.add(jarName);\n   }\n \n-  private void deleteSavedJarFiles() throws IOException {\n-    deleteMatching(new File(\".\"), \"^\" + JarDeployer.JAR_PREFIX + \"Deploy1.*#\\\\d++$\");\n-    delete(new File(\"Deploy1.jar\"));\n-  }\n-\n   private Object[] setup() throws IOException {\n     final int[] ports = getRandomAvailableTCPPorts(3);\n     final int locator1Port = ports[0];",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/java/org/apache/geode/management/internal/configuration/ClusterConfigurationServiceEndToEndDUnitTest.java",
                "sha": "0103cf6d8d6f088b4bd3ffc30f8e52b977a82621",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/resources/expected_jars.txt",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/test/resources/expected_jars.txt?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-assembly/src/test/resources/expected_jars.txt",
                "patch": "@@ -36,7 +36,6 @@ jgroups\n jline\n jna\n jopt-simple\n-json4s-ast\n log4j-api\n log4j-core\n log4j-jcl",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-assembly/src/test/resources/expected_jars.txt",
                "sha": "b7d1dc22fd7995e6f7786984994ce62e1064bed3",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/build.gradle",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/build.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/build.gradle",
                "patch": "@@ -107,7 +107,11 @@ dependencies {\n   } \n \n   compile 'org.apache.shiro:shiro-core:' + project.'shiro.version'\n- \n+  // This is only added since shiro is using an old version of beanutils and we want\n+  // to use a standard version. Once shiro deps are updated, remove this explicit dependency\n+  // in favor of a transitive dependency on beanutils.\n+  compile 'commons-beanutils:commons-beanutils:' + project.'commons-beanutils.version'\n+  \n   compile project(':geode-common')\n   compile project(':geode-json')\n   \n@@ -118,6 +122,7 @@ dependencies {\n \n   // Test Dependencies\n   // External\n+  testCompile 'com.google.guava:guava:' + project.'guava.version'\n   testCompile 'com.jayway.jsonpath:json-path-assert:' + project.'json-path-assert.version'\n   testCompile 'org.apache.bcel:bcel:' + project.'bcel.version'\n   testRuntime 'org.apache.derby:derby:' + project.'derby.version'",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/build.gradle",
                "sha": "757599a9d76844dec17e545d1b4d19b32c22afef",
                "status": "modified"
            },
            {
                "additions": 69,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/DataSerializer.java",
                "changes": 69,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/DataSerializer.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/DataSerializer.java",
                "patch": "@@ -33,6 +33,7 @@\n import java.util.Hashtable;\n import java.util.IdentityHashMap;\n import java.util.LinkedHashSet;\n+import java.util.LinkedHashMap;\n import java.util.LinkedList;\n import java.util.Map;\n import java.util.Properties;\n@@ -2667,6 +2668,74 @@ public static void writeTreeMap(TreeMap<?, ?> map, DataOutput out) throws IOExce\n     }\n   }\n \n+\n+  /**\n+   * Writes a <code>LinkedHashMap</code> to a <code>DataOutput</code>. Note that even though\n+   * <code>map</code> may be an instance of a subclass of <code>LinkedHashMap</code>,\n+   * <code>readLinkedHashMap</code> will always return an instance of <code>LinkedHashMap</code>,\n+   * <B>not</B> an instance of the subclass. To preserve the class type of <code>map</code>,\n+   * {@link #writeObject(Object, DataOutput)} should be used for data serialization. This method\n+   * will serialize a <code>null</code> map and not throw a <code>NullPointerException</code>.\n+   *\n+   * @throws IOException A problem occurs while writing to <code>out</code>\n+   * @see #readLinkedHashMap\n+   */\n+  public static void writeLinkedHashMap(Map<?, ?> map, DataOutput out) throws IOException {\n+\n+    InternalDataSerializer.checkOut(out);\n+\n+    int size;\n+    if (map == null) {\n+      size = -1;\n+    } else {\n+      size = map.size();\n+    }\n+    InternalDataSerializer.writeArrayLength(size, out);\n+    if (logger.isTraceEnabled(LogMarker.SERIALIZER)) {\n+      logger.trace(LogMarker.SERIALIZER, \"Writing LinkedHashMap with {} elements: {}\", size, map);\n+    }\n+    if (size > 0) {\n+      for (Map.Entry<?, ?> entry : map.entrySet()) {\n+        writeObject(entry.getKey(), out);\n+        writeObject(entry.getValue(), out);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Reads a <code>LinkedHashMap</code> from a <code>DataInput</code>.\n+   *\n+   * @throws IOException A problem occurs while reading from <code>in</code>\n+   * @throws ClassNotFoundException The class of one of the <Code>HashMap</code>'s elements cannot\n+   *         be found.\n+   * @see #writeLinkedHashMap\n+   */\n+  public static <K, V> LinkedHashMap<K, V> readLinkedHashMap(DataInput in)\n+      throws IOException, ClassNotFoundException {\n+\n+    InternalDataSerializer.checkIn(in);\n+\n+    int size = InternalDataSerializer.readArrayLength(in);\n+    if (size == -1) {\n+      return null;\n+    } else {\n+      LinkedHashMap<K, V> map = new LinkedHashMap<>(size);\n+      for (int i = 0; i < size; i++) {\n+        K key = DataSerializer.<K>readObject(in);\n+        V value = DataSerializer.<V>readObject(in);\n+        map.put(key, value);\n+      }\n+\n+      if (logger.isTraceEnabled(LogMarker.SERIALIZER)) {\n+        logger.trace(LogMarker.SERIALIZER, \"Read LinkedHashMap with {} elements: {}\", size, map);\n+      }\n+\n+      return map;\n+    }\n+  }\n+\n+\n+\n   /**\n    * Writes a <code>TreeSet</code> to a <code>DataOutput</code>. Note that even though\n    * <code>set</code> may be an instance of a subclass of <code>TreeSet</code>,",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/DataSerializer.java",
                "sha": "627661a8ebbf5f8ffc6a5d2edff6c08f99a4035e",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/cache/Operation.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/Operation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/Operation.java",
                "patch": "@@ -49,6 +49,7 @@\n   private static final byte OP_TYPE_CLEAR = OpType.CLEAR;\n   private static final byte OP_TYPE_MARKER = OpType.MARKER;\n   private static final byte OP_TYPE_UPDATE_VERSION = OpType.UPDATE_ENTRY_VERSION;\n+  private static final byte OP_TYPE_GET_FOR_REGISTER_INTEREST = OpType.GET_FOR_REGISTER_INTEREST;\n \n   private static final int OP_DETAILS_NONE = 0;\n   private static final int OP_DETAILS_SEARCH = 1;\n@@ -531,6 +532,14 @@\n       false, // isRegion\n       OP_TYPE_DESTROY, OP_DETAILS_REMOVEALL);\n \n+  /**\n+   * A 'get for register interest' operation.\n+   */\n+  public static final Operation GET_FOR_REGISTER_INTEREST =\n+      new Operation(\"GET_FOR_REGISTER_INTEREST\", false, // isLocal\n+          false, // isRegion\n+          OP_TYPE_GET_FOR_REGISTER_INTEREST, OP_DETAILS_NONE);\n+\n   /** The name of this mirror type. */\n   private final transient String name;\n \n@@ -635,6 +644,13 @@ public boolean isGetEntry() {\n     return this.opType == OP_TYPE_GET_ENTRY;\n   }\n \n+  /**\n+   * Returns true if this operation is a get for register interest.\n+   */\n+  public boolean isGetForRegisterInterest() {\n+    return this.opType == OP_TYPE_GET_FOR_REGISTER_INTEREST;\n+  }\n+\n   /**\n    * Returns true if the operation invalidated an entry.\n    */",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/cache/Operation.java",
                "sha": "d835b6cfa0b95bcc67226f04586962edd554b71c",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/cache/asyncqueue/internal/AsyncEventQueueImpl.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/asyncqueue/internal/AsyncEventQueueImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/asyncqueue/internal/AsyncEventQueueImpl.java",
                "patch": "@@ -25,6 +25,7 @@\n import org.apache.geode.cache.wan.GatewayEventSubstitutionFilter;\n import org.apache.geode.cache.wan.GatewaySender;\n import org.apache.geode.cache.wan.GatewaySender.OrderPolicy;\n+import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.RegionQueue;\n import org.apache.geode.internal.cache.wan.AbstractGatewaySender;\n import org.apache.geode.internal.cache.wan.AbstractGatewaySenderEventProcessor;\n@@ -191,8 +192,16 @@ public boolean isMetaQueue() {\n     return ((AbstractGatewaySender) sender).getIsMetaQueue();\n   }\n \n+  public void stop() {\n+    if (this.sender.isRunning()) {\n+      this.sender.stop();\n+    }\n+  }\n+\n   public void destroy() {\n+    GemFireCacheImpl gfci = (GemFireCacheImpl) ((AbstractGatewaySender) this.sender).getCache();\n     this.sender.destroy();\n+    gfci.removeAsyncEventQueue(this);\n   }\n \n   public boolean isBucketSorted() {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/cache/asyncqueue/internal/AsyncEventQueueImpl.java",
                "sha": "a44b9e4824b3166899ff7826fb6108bded9d8f7e",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/Locator.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "patch": "@@ -391,7 +391,10 @@ public String asString() {\n       }\n     }\n     StringBuilder locatorString = new StringBuilder(String.valueOf(ba));\n-    locatorString.append('[').append(this.getPort()).append(']');\n+    Integer port = getPort();\n+    if (port != null && port.intValue() > 0) {\n+      locatorString.append('[').append(this.getPort()).append(']');\n+    }\n     return locatorString.toString();\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "sha": "87cd243749f59215527c83e68e9855ddf2889967",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/DistributionAdvisor.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/DistributionAdvisor.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/DistributionAdvisor.java",
                "patch": "@@ -1294,6 +1294,28 @@ protected void profileRemoved(Profile profile) {}\n     }\n   }\n \n+  /**\n+   * This method calls filter->include on every profile until include returns true.\n+   * \n+   * @return false if all filter->include calls returns false; otherwise true.\n+   **/\n+  protected boolean satisfiesFilter(Filter f) {\n+    initializationGate();\n+    if (disabled) {\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"Intelligent Messaging Disabled\");\n+      }\n+      return !getDefaultDistributionMembers().isEmpty();\n+    }\n+    Profile[] locProfiles = this.profiles; // grab current profiles\n+    for (Profile p : locProfiles) {\n+      if (f.include(p)) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n   /**\n    * A visitor interface for all the available profiles used by\n    * {@link DistributionAdvisor#accept(ProfileVisitor, Object)}. Unlike the {@link Filter} class",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/DistributionAdvisor.java",
                "sha": "1d3dc860b20cffb1a08383f2c0428c5326a6c01b",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "patch": "@@ -135,12 +135,6 @@ protected void init() {\n     this.manager.init(this);\n     this.joinLeave.init(this);\n     this.healthMon.init(this);\n-    InternalLocator l = (InternalLocator) org.apache.geode.distributed.Locator.getLocator();\n-    if (l != null && l.getLocatorHandler() != null) {\n-      if (l.getLocatorHandler().setMembershipManager((MembershipManager) this.manager)) {\n-        this.locator = (Locator) l.getLocatorHandler();\n-      }\n-    }\n   }\n \n   protected void start() {\n@@ -176,6 +170,12 @@ protected void start() {\n     this.joinLeave.started();\n     this.healthMon.started();\n     this.manager.started();\n+    InternalLocator l = (InternalLocator) org.apache.geode.distributed.Locator.getLocator();\n+    if (l != null && l.getLocatorHandler() != null) {\n+      if (l.getLocatorHandler().setMembershipManager((MembershipManager) this.manager)) {\n+        this.locator = (Locator) l.getLocatorHandler();\n+      }\n+    }\n     logger.debug(\"All membership services have been started\");\n     try {\n       this.manager.joinDistributedSystem();",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "sha": "1404b3b6f2a44aeaf3c76b99dad8a428b1b5d1f7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/FindCoordinatorResponse.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/FindCoordinatorResponse.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/FindCoordinatorResponse.java",
                "patch": "@@ -128,7 +128,7 @@ public String toString() {\n       return \"FindCoordinatorResponse(coordinator=\" + coordinator + \")\";\n     } else {\n       return \"FindCoordinatorResponse(coordinator=\" + coordinator + \", fromView=\" + fromView\n-          + \", viewId=\" + (view == null ? \"nul\" : view.getViewId()) + \", registrants=\"\n+          + \", viewId=\" + (view == null ? \"null\" : view.getViewId()) + \", registrants=\"\n           + (registrants == null ? 0 : registrants.size()) + \", senderId=\" + senderId\n           + \", network partition detection enabled=\" + this.networkPartitionDetectionEnabled\n           + \", locators preferred as coordinators=\" + this.usePreferredCoordinators + \")\";",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/FindCoordinatorResponse.java",
                "sha": "edfaf625e6c652f46d9323c1116791f1c69fda59",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 11,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "patch": "@@ -112,9 +112,11 @@ public GMSLocator(InetAddress bindAddress, File stateFile, String locatorString,\n   @Override\n   public synchronized boolean setMembershipManager(MembershipManager mgr) {\n     if (services == null || services.isStopped()) {\n-      logger.info(\"Peer locator is connecting to local membership services\");\n       services = ((GMSMembershipManager) mgr).getServices();\n       localAddress = services.getMessenger().getMemberID();\n+      assert localAddress != null : \"member address should have been established\";\n+      logger.info(\"Peer locator is connecting to local membership services with ID {}\",\n+          localAddress);\n       services.setLocator(this);\n       NetView newView = services.getJoinLeave().getView();\n       if (newView != null) {\n@@ -142,7 +144,7 @@ private synchronized void findServices() {\n     }\n     if (services == null) {\n       try {\n-        wait(2000);\n+        wait(10000);\n       } catch (InterruptedException e) {\n       }\n     }\n@@ -177,12 +179,14 @@ public Object processRequest(Object request) throws IOException {\n       }\n     } else if (request instanceof FindCoordinatorRequest) {\n       findServices();\n+\n       FindCoordinatorRequest findRequest = (FindCoordinatorRequest) request;\n       if (!findRequest.getDHAlgo().equals(securityUDPDHAlgo)) {\n         return new FindCoordinatorResponse(\n             \"Rejecting findCoordinatorRequest, as member not configured same udp security(\"\n                 + findRequest.getDHAlgo() + \" )as locator (\" + securityUDPDHAlgo + \")\");\n       }\n+\n       if (services != null) {\n         services.getMessenger().setPublicKey(findRequest.getMyPublicKey(),\n             findRequest.getMemberID());\n@@ -193,14 +197,22 @@ public Object processRequest(Object request) throws IOException {\n           registerMbrVsPK.put(new InternalDistributedMemberWrapper(findRequest.getMemberID()),\n               findRequest.getMyPublicKey());\n         }\n+        logger.debug(\"Rejecting a request to find the coordinator - membership services are\"\n+            + \" still initializing\");\n+        return null;\n       }\n+\n       if (findRequest.getMemberID() != null) {\n         InternalDistributedMember coord = null;\n \n         // at this level we want to return the coordinator known to membership services,\n         // which may be more up-to-date than the one known by the membership manager\n         if (view == null) {\n           findServices();\n+          if (services == null) {\n+            // we must know this process's identity in order to respond\n+            return null;\n+          }\n         }\n \n         boolean fromView = false;\n@@ -237,9 +249,7 @@ public Object processRequest(Object request) throws IOException {\n           }\n           synchronized (registrants) {\n             registrants.add(findRequest.getMemberID());\n-            if (services != null) {\n-              coord = services.getJoinLeave().getMemberID();\n-            }\n+            coord = services.getJoinLeave().getMemberID();\n             for (InternalDistributedMember mbr : registrants) {\n               if (mbr != coord && (coord == null || mbr.compareTo(coord) < 0)) {\n                 if (!rejections.contains(mbr) && (mbr.getNetMember().preferredForCoordinator()\n@@ -258,12 +268,7 @@ public Object processRequest(Object request) throws IOException {\n             coordPk = (byte[]) view.getPublicKey(coord);\n           }\n           if (coordPk == null) {\n-            if (services != null) {\n-              coordPk = services.getMessenger().getPublicKey(coord);\n-            } else {\n-              // coordPk = GMSEncrypt.getRegisteredPublicKey(coord);\n-              coordPk = registerMbrVsPK.get(new InternalDistributedMemberWrapper(coord));\n-            }\n+            coordPk = services.getMessenger().getPublicKey(coord);\n           }\n           response = new FindCoordinatorResponse(coord, localAddress, fromView, view,\n               new HashSet<InternalDistributedMember>(registrants),",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "sha": "e3635f2d93aae212cbff2f2058b6dc728a04776a",
                "status": "modified"
            },
            {
                "additions": 90,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "changes": 183,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 93,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "patch": "@@ -128,7 +128,7 @@ protected Boolean initialValue() {\n \n   /**\n    * Trick class to make the startup synch more visible in stack traces\n-   * \n+   *\n    * @see GMSMembershipManager#startupLock\n    */\n   static class EventProcessingLock {\n@@ -143,7 +143,7 @@ public EventProcessingLock() {}\n     /**\n      * indicates whether the event is a departure, a surprise connect (i.e., before the view message\n      * arrived), a view, or a regular message\n-     * \n+     *\n      * @see #SURPRISE_CONNECT\n      * @see #VIEW\n      * @see #MESSAGE\n@@ -181,7 +181,7 @@ public String toString() {\n \n     /**\n      * Create a surprise connect event\n-     * \n+     *\n      * @param member the member connecting\n      */\n     StartupEvent(final InternalDistributedMember member) {\n@@ -191,7 +191,7 @@ public String toString() {\n \n     /**\n      * Indicate if this is a surprise connect event\n-     * \n+     *\n      * @return true if this is a connect event\n      */\n     boolean isSurpriseConnect() {\n@@ -200,7 +200,7 @@ boolean isSurpriseConnect() {\n \n     /**\n      * Create a view event\n-     * \n+     *\n      * @param v the new view\n      */\n     StartupEvent(NetView v) {\n@@ -210,7 +210,7 @@ boolean isSurpriseConnect() {\n \n     /**\n      * Indicate if this is a view event\n-     * \n+     *\n      * @return true if this is a view event\n      */\n     boolean isGmsView() {\n@@ -219,7 +219,7 @@ boolean isGmsView() {\n \n     /**\n      * Create a message event\n-     * \n+     *\n      * @param d the message\n      */\n     StartupEvent(DistributionMessage d) {\n@@ -229,7 +229,7 @@ boolean isGmsView() {\n \n     /**\n      * Indicate if this is a message event\n-     * \n+     *\n      * @return true if this is a message event\n      */\n     boolean isDistributionMessage() {\n@@ -248,14 +248,14 @@ boolean isDistributionMessage() {\n \n   /**\n    * This is the latest view (ordered list of DistributedMembers) that has been installed\n-   * \n+   *\n    * All accesses to this object are protected via {@link #latestViewLock}\n    */\n   private NetView latestView = new NetView();\n \n   /**\n    * This is the lock for protecting access to latestView\n-   * \n+   *\n    * @see #latestView\n    */\n   private final ReadWriteLock latestViewLock = new ReentrantReadWriteLock();\n@@ -290,11 +290,11 @@ boolean isDistributionMessage() {\n    * Members of the distributed system that we believe have shut down. Keys are instances of\n    * {@link InternalDistributedMember}, values are Longs indicating the time this member was\n    * shunned.\n-   * \n+   *\n    * Members are removed after {@link #SHUNNED_SUNSET} seconds have passed.\n-   * \n+   *\n    * Accesses to this list needs to be under the read or write lock of {@link #latestViewLock}\n-   * \n+   *\n    * @see System#currentTimeMillis()\n    */\n   // protected final Set shunnedMembers = Collections.synchronizedSet(new HashSet());\n@@ -310,7 +310,7 @@ boolean isDistributionMessage() {\n    * per bug 39552, keep a list of members that have been shunned and for which a message is\n    * printed. Contents of this list are cleared at the same time they are removed from\n    * {@link #shunnedMembers}.\n-   * \n+   *\n    * Accesses to this list needs to be under the read or write lock of {@link #latestViewLock}\n    */\n   private final HashSet<DistributedMember> shunnedAndWarnedMembers = new HashSet<>();\n@@ -326,7 +326,7 @@ boolean isDistributionMessage() {\n    * arrived, the member is removed from membership and member-left notification is performed.\n    * <p>\n    * > Accesses to this list needs to be under the read or write lock of {@link #latestViewLock}\n-   * \n+   *\n    * @see System#currentTimeMillis()\n    */\n   private final Map<InternalDistributedMember, Long> surpriseMembers = new ConcurrentHashMap<>();\n@@ -344,7 +344,7 @@ boolean isDistributionMessage() {\n \n   /**\n    * Length of time, in seconds, that a member is retained in the zombie set\n-   * \n+   *\n    * @see #shunnedMembers\n    */\n   static private final int SHUNNED_SUNSET = Integer\n@@ -368,7 +368,7 @@ boolean isDistributionMessage() {\n   /**\n    * A list of messages received during channel startup that couldn't be processed yet. Additions or\n    * removals of this list must be synchronized via {@link #startupLock}.\n-   * \n+   *\n    * @since GemFire 5.0\n    */\n   private final LinkedList<StartupEvent> startupMessages = new LinkedList<>();\n@@ -381,18 +381,18 @@ boolean isDistributionMessage() {\n   /**\n    * Insert our own MessageReceiver between us and the direct channel, in order to correctly filter\n    * membership events.\n-   * \n-   * \n+   *\n+   *\n    */\n   class MyDCReceiver implements DirectChannelListener {\n \n     final DirectChannelListener upCall;\n \n     /**\n      * Don't provide events until the caller has told us we are ready.\n-     * \n+     *\n      * Synchronization provided via GroupMembershipService.class.\n-     * \n+     *\n      * Note that in practice we only need to delay accepting the first client; we don't need to put\n      * this check before every call...\n      *\n@@ -509,7 +509,7 @@ protected void processView(long newViewId, NetView newView) {\n           continue; // no additions processed after shutdown begins\n         } else {\n           boolean wasShunned = endShun(m); // bug #45158 - no longer shun a process that is now in\n-                                           // view\n+          // view\n           if (wasShunned && logger.isDebugEnabled()) {\n             logger.debug(\"No longer shunning {} as it is in the current membership view\", m);\n           }\n@@ -608,17 +608,20 @@ protected void processView(long newViewId, NetView newView) {\n       }\n       try {\n         listener.viewInstalled(latestView);\n-        startCleanupTimer();\n       } catch (DistributedSystemDisconnectedException se) {\n       }\n     } finally {\n       latestViewWriteLock.unlock();\n     }\n   }\n \n+  public boolean isCleanupTimerStarted() {\n+    return this.cleanupTimer != null;\n+  }\n+\n   /**\n    * the timer used to perform periodic tasks\n-   * \n+   *\n    * Concurrency: protected by {@link #latestViewLock} ReentrantReadWriteLock\n    */\n   private SystemTimer cleanupTimer;\n@@ -637,7 +640,7 @@ public boolean isMulticastAllowed() {\n \n   /**\n    * Joins the distributed system\n-   * \n+   *\n    * @throws GemFireConfigException - configuration error\n    * @throws SystemConnectException - problem joining\n    */\n@@ -767,7 +770,9 @@ public void joinDistributedSystem() {\n   }\n \n   @Override\n-  public void started() {}\n+  public void started() {\n+    startCleanupTimer();\n+  }\n \n \n   /** this is invoked by JoinLeave when there is a loss of quorum in the membership system */\n@@ -843,7 +848,7 @@ private void removeWithViewLock(InternalDistributedMember dm, boolean crashed, S\n \n   /**\n    * Process a surprise connect event, or place it on the startup queue.\n-   * \n+   *\n    * @param member the member\n    */\n   protected void handleOrDeferSurpriseConnect(InternalDistributedMember member) {\n@@ -875,7 +880,7 @@ public void startupMessageFailed(DistributedMember mbr, String failureMessage) {\n    * <p>\n    * Must be called with {@link #latestViewLock} held. Waits until there is a stable view. If the\n    * member has already been added, simply returns; else adds the member.\n-   * \n+   *\n    * @param dm the member joining\n    */\n   public boolean addSurpriseMember(DistributedMember dm) {\n@@ -942,12 +947,6 @@ public void run() {\n         surpriseMembers.remove(member);\n       } else {\n \n-        // Now that we're sure the member is new, add them.\n-        // make sure the surprise-member cleanup task is running\n-        if (this.cleanupTimer == null) {\n-          startCleanupTimer();\n-        } // cleanupTimer == null\n-\n         // Ensure that the member is accounted for in the view\n         // Conjure up a new view including the new member. This is necessary\n         // because we are about to tell the listener about a new member, so\n@@ -978,48 +977,46 @@ public void run() {\n \n   /** starts periodic task to perform cleanup chores such as expire surprise members */\n   private void startCleanupTimer() {\n+    if (this.listener == null || listener.getDM() == null) {\n+      return;\n+    }\n+    DistributedSystem ds = this.listener.getDM().getSystem();\n+    this.cleanupTimer = new SystemTimer(ds, true);\n+    SystemTimer.SystemTimerTask st = new SystemTimer.SystemTimerTask() {\n+      @Override\n+      public void run2() {\n+        cleanUpSurpriseMembers();\n+      }\n+    };\n+    this.cleanupTimer.scheduleAtFixedRate(st, surpriseMemberTimeout, surpriseMemberTimeout / 3);\n+  }\n+\n+  // invoked from the cleanupTimer task\n+  private void cleanUpSurpriseMembers() {\n     latestViewWriteLock.lock();\n     try {\n-      if (this.cleanupTimer != null) {\n-        return;\n+      long oldestAllowed = System.currentTimeMillis() - surpriseMemberTimeout;\n+      for (Iterator it = surpriseMembers.entrySet().iterator(); it.hasNext();) {\n+        Map.Entry entry = (Map.Entry) it.next();\n+        Long birthtime = (Long) entry.getValue();\n+        if (birthtime.longValue() < oldestAllowed) {\n+          it.remove();\n+          InternalDistributedMember m = (InternalDistributedMember) entry.getKey();\n+          logger.info(LocalizedMessage.create(\n+              LocalizedStrings.GroupMembershipService_MEMBERSHIP_EXPIRING_MEMBERSHIP_OF_SURPRISE_MEMBER_0,\n+              m));\n+          removeWithViewLock(m, true,\n+              \"not seen in membership view in \" + surpriseMemberTimeout + \"ms\");\n+        }\n       }\n-      DistributedSystem ds = InternalDistributedSystem.getAnyInstance();\n-      if (ds != null && ds.isConnected()) {\n-        this.cleanupTimer = new SystemTimer(ds, true);\n-        SystemTimer.SystemTimerTask st = new SystemTimer.SystemTimerTask() {\n-          @Override\n-          public void run2() {\n-            latestViewWriteLock.lock();\n-            try {\n-              long oldestAllowed = System.currentTimeMillis() - surpriseMemberTimeout;\n-              for (Iterator it = surpriseMembers.entrySet().iterator(); it.hasNext();) {\n-                Map.Entry entry = (Map.Entry) it.next();\n-                Long birthtime = (Long) entry.getValue();\n-                if (birthtime.longValue() < oldestAllowed) {\n-                  it.remove();\n-                  InternalDistributedMember m = (InternalDistributedMember) entry.getKey();\n-                  logger.info(LocalizedMessage.create(\n-                      LocalizedStrings.GroupMembershipService_MEMBERSHIP_EXPIRING_MEMBERSHIP_OF_SURPRISE_MEMBER_0,\n-                      m));\n-                  removeWithViewLock(m, true,\n-                      \"not seen in membership view in \" + surpriseMemberTimeout + \"ms\");\n-                }\n-              }\n-            } finally {\n-              latestViewWriteLock.unlock();\n-            }\n-          }\n-        };\n-        this.cleanupTimer.scheduleAtFixedRate(st, surpriseMemberTimeout, surpriseMemberTimeout / 3);\n-      } // ds != null && ds.isConnected()\n     } finally {\n       latestViewWriteLock.unlock();\n     }\n   }\n \n   /**\n    * Dispatch the distribution message, or place it on the startup queue.\n-   * \n+   *\n    * @param msg the message to process\n    */\n   protected void handleOrDeferMessage(DistributionMessage msg) {\n@@ -1068,7 +1065,7 @@ public void processMessage(DistributionMessage msg) {\n    * <p>\n    * It is possible to receive messages not consistent with our view. We handle this here, and\n    * generate an uplevel event if necessary\n-   * \n+   *\n    * @param msg the message\n    */\n   private void dispatchMessage(DistributionMessage msg) {\n@@ -1103,7 +1100,7 @@ private void dispatchMessage(DistributionMessage msg) {\n     }\n \n     if (shunned) { // bug #41538 - shun notification must be outside synchronization to avoid\n-                   // hanging\n+      // hanging\n       warnShun(m);\n       if (logger.isTraceEnabled(LogMarker.DISTRIBUTION_VIEWS)) {\n         logger.trace(LogMarker.DISTRIBUTION_VIEWS,\n@@ -1118,7 +1115,7 @@ private void dispatchMessage(DistributionMessage msg) {\n \n   /**\n    * Process a new view object, or place on the startup queue\n-   * \n+   *\n    * @param viewArg the new view\n    */\n   protected void handleOrDeferViewEvent(NetView viewArg) {\n@@ -1159,7 +1156,7 @@ public void memberSuspected(InternalDistributedMember initiator,\n \n   /**\n    * Process a new view object, or place on the startup queue\n-   * \n+   *\n    * @param suspectInfo the suspectee and suspector\n    */\n   protected void handleOrDeferSuspect(SuspectMember suspectInfo) {\n@@ -1196,7 +1193,7 @@ private void processSurpriseConnect(InternalDistributedMember member) {\n \n   /**\n    * Dispatch routine for processing a single startup event\n-   * \n+   *\n    * @param o the startup event to handle\n    */\n   private void processStartupEvent(StartupEvent o) {\n@@ -1350,7 +1347,7 @@ public NetView getView() {\n    * <p>\n    * If no members have partition detection enabled, there will be no lead member and this method\n    * will return null.\n-   * \n+   *\n    * @return the lead member associated with the latest view\n    */\n   public DistributedMember getLeadMember() {\n@@ -1368,7 +1365,7 @@ private boolean isJoining() {\n \n   /**\n    * test hook\n-   * \n+   *\n    * @return the current membership view coordinator\n    */\n   public DistributedMember getCoordinator() {\n@@ -1415,7 +1412,7 @@ public void postConnect() {}\n \n   /**\n    * Ensure that the critical classes from components get loaded.\n-   * \n+   *\n    * @see SystemFailure#loadEmergencyClasses()\n    */\n   public static void loadEmergencyClasses() {\n@@ -1430,7 +1427,7 @@ public static void loadEmergencyClasses() {\n   /**\n    * Close the receiver, avoiding all potential deadlocks and eschewing any attempts at being\n    * graceful.\n-   * \n+   *\n    * @see SystemFailure#emergencyClose()\n    */\n   public void emergencyClose() {\n@@ -1652,7 +1649,7 @@ public boolean verifyMember(DistributedMember mbr, String reason) {\n \n   /**\n    * Perform the grossness associated with sending a message over a DirectChannel\n-   * \n+   *\n    * @param destinations the list of destinations\n    * @param content the message\n    * @param theStats the statistics object to update\n@@ -1716,18 +1713,18 @@ public boolean verifyMember(DistributedMember mbr, String reason) {\n         return null;\n \n       List<InternalDistributedMember> members = (List<InternalDistributedMember>) ex.getMembers(); // We\n-                                                                                                   // need\n-                                                                                                   // to\n-                                                                                                   // return\n-                                                                                                   // this\n-                                                                                                   // list\n-                                                                                                   // of\n-                                                                                                   // failures\n+      // need\n+      // to\n+      // return\n+      // this\n+      // list\n+      // of\n+      // failures\n \n       // SANITY CHECK: If we fail to send a message to an existing member\n       // of the view, we have a serious error (bug36202).\n       NetView view = services.getJoinLeave().getView(); // grab a recent view, excluding shunned\n-                                                        // members\n+      // members\n \n       // Iterate through members and causes in tandem :-(\n       Iterator it_mem = members.iterator();\n@@ -1866,7 +1863,7 @@ public void releaseQuorumChecker(QuorumChecker checker) {\n     }\n \n     boolean sendViaMessenger = isForceUDPCommunications(); // enable when bug #46438 is fixed: ||\n-                                                           // msg.sendViaUDP();\n+    // msg.sendViaUDP();\n \n     if (useMcast || tcpDisabled || sendViaMessenger) {\n       checkAddressesForUUIDs(destinations);\n@@ -1933,7 +1930,7 @@ public boolean shutdownInProgress() {\n \n   /**\n    * Clean up and create consistent new view with member removed. No uplevel events are generated.\n-   * \n+   *\n    * Must be called with the {@link #latestViewLock} held.\n    */\n   private void destroyMember(final InternalDistributedMember member, final String reason) {\n@@ -1996,12 +1993,12 @@ public void run() {\n \n   /**\n    * Indicate whether the given member is in the zombie list (dead or dying)\n-   * \n+   *\n    * @param m the member in question\n-   * \n+   *\n    *        This also checks the time the given member was shunned, and has the side effect of\n    *        removing the member from the list if it was shunned too far in the past.\n-   * \n+   *\n    *        Concurrency: protected by {@link #latestViewLock} ReentrantReadWriteLock\n    *\n    * @return true if the given member is a zombie\n@@ -2049,9 +2046,9 @@ private boolean isNew(final InternalDistributedMember m) {\n    * during view processing.\n    * <p>\n    * Like isShunned, this method holds the view lock while executing\n-   * \n+   *\n    * Concurrency: protected by {@link #latestViewLock} ReentrantReadWriteLock\n-   * \n+   *\n    * @param m the member in question\n    * @return true if the given member is a surprise member\n    */\n@@ -2072,7 +2069,7 @@ public boolean isSurpriseMember(DistributedMember m) {\n   /**\n    * for testing we need to be able to inject surprise members into the view to ensure that\n    * sunsetting works properly\n-   * \n+   *\n    * @param m the member ID to add\n    * @param birthTime the millisecond clock time that the member was first seen\n    */\n@@ -2106,7 +2103,7 @@ private boolean endShun(DistributedMember m) {\n    * really old.\n    * <p>\n    * Must be called with {@link #latestViewLock} held and the view stable.\n-   * \n+   *\n    * @param m the member to add\n    */\n   private void addShunnedMember(InternalDistributedMember m) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "sha": "0180ddb98f3e67d14a29129a9a9f81237123e1ab",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/DSFIDFactory.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/DSFIDFactory.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/DSFIDFactory.java",
                "patch": "@@ -251,7 +251,6 @@\n import org.apache.geode.internal.cache.RemoteRemoveAllMessage;\n import org.apache.geode.internal.cache.RoleEventImpl;\n import org.apache.geode.internal.cache.SearchLoadAndWriteProcessor;\n-import org.apache.geode.internal.cache.SendQueueOperation.SendQueueMessage;\n import org.apache.geode.internal.cache.ServerPingMessage;\n import org.apache.geode.internal.cache.StateFlushOperation.StateMarkerMessage;\n import org.apache.geode.internal.cache.StateFlushOperation.StateStabilizationMessage;\n@@ -667,7 +666,6 @@ private static void registerDSFIDTypes() {\n     registerDSFID(CLEAR_REGION_MESSAGE, ClearRegionMessage.class);\n     registerDSFID(TOMBSTONE_MESSAGE, TombstoneMessage.class);\n     registerDSFID(INVALIDATE_REGION_MESSAGE, InvalidateRegionMessage.class);\n-    registerDSFID(SEND_QUEUE_MESSAGE, SendQueueMessage.class);\n     registerDSFID(STATE_MARKER_MESSAGE, StateMarkerMessage.class);\n     registerDSFID(STATE_STABILIZATION_MESSAGE, StateStabilizationMessage.class);\n     registerDSFID(STATE_STABILIZED_MESSAGE, StateStabilizedMessage.class);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/DSFIDFactory.java",
                "sha": "c02dc474fe5a20802be2604728b9579b0c27ee08",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/DataSerializableFixedID.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/DataSerializableFixedID.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/DataSerializableFixedID.java",
                "patch": "@@ -160,7 +160,6 @@\n   public static final byte PUT_ALL_MESSAGE = -84;\n   public static final byte CLEAR_REGION_MESSAGE = -83;\n   public static final byte INVALIDATE_REGION_MESSAGE = -82;\n-  public static final byte SEND_QUEUE_MESSAGE = -81;\n   public static final byte STATE_MARKER_MESSAGE = -80;\n   public static final byte STATE_STABILIZATION_MESSAGE = -79;\n   public static final byte STATE_STABILIZED_MESSAGE = -78;\n@@ -809,8 +808,9 @@\n   public static final short LUCENE_ENTRY_SCORE = 2174;\n   public static final short LUCENE_TOP_ENTRIES = 2175;\n   public static final short LUCENE_TOP_ENTRIES_COLLECTOR = 2176;\n-\n   public static final short WAIT_UNTIL_FLUSHED_FUNCTION_CONTEXT = 2177;\n+  public static final short DESTROY_LUCENE_INDEX_MESSAGE = 2178;\n+  public static final short LUCENE_PAGE_RESULTS = 2179;\n \n   // NOTE, codes > 65535 will take 4 bytes to serialize\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/DataSerializableFixedID.java",
                "sha": "63a95a5890c8c358c5c00eaa6ae78deda0d1675f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/FileUtil.java",
                "changes": 328,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/FileUtil.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 328,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/FileUtil.java",
                "patch": "@@ -1,328 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal;\n-\n-import org.apache.geode.distributed.internal.DistributionConfig;\n-\n-import java.io.*;\n-import java.net.URL;\n-import java.nio.channels.FileChannel;\n-import java.nio.file.Files;\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-/**\n- * This class contains static methods for manipulating files and directories, such as recursively\n- * copying or deleting files.\n- * \n- * TODO A lot of this functionality is probably duplicating apache commons io, maybe we should\n- * switch to that.\n- * \n- * \n- */\n-public class FileUtil {\n-  public static final long MAX_TRANSFER_SIZE =\n-      Long.getLong(DistributionConfig.GEMFIRE_PREFIX + \"FileUtil.MAX_TRANSFER_SIZE\", 1024 * 1024)\n-          .longValue();\n-  public static final boolean USE_NIO =\n-      !Boolean.getBoolean(DistributionConfig.GEMFIRE_PREFIX + \"FileUtil.USE_OLD_IO\");\n-  public static final String extSeparator = \".\";\n-\n-  /**\n-   * Copy a file from the source file to the destination file. If the source is a directory, it will\n-   * be copied recursively.\n-   * \n-   * Note that unlike unix cp, if the destination is directory, the source *contents* will be copied\n-   * to the destination *contents*, not as a subdirectory of dest.\n-   * \n-   * @param source the source file or directory\n-   * @param dest the destination file or directory.\n-   * @throws IOException\n-   */\n-  public static void copy(File source, File dest) throws IOException {\n-    if (source.isDirectory()) {\n-      dest.mkdir();\n-      for (File child : listFiles(source)) {\n-        copy(child, new File(dest, child.getName()));\n-      }\n-    } else {\n-      if (source.exists()) {\n-        long lm = source.lastModified();\n-        if (dest.isDirectory()) {\n-          dest = new File(dest, source.getName());\n-        }\n-        FileOutputStream fos = new FileOutputStream(dest);\n-        try {\n-          FileInputStream fis = new FileInputStream(source);\n-          try {\n-            if (USE_NIO) {\n-              nioCopy(fos, fis);\n-            } else {\n-              oioCopy(source, fos, fis);\n-            }\n-          } finally {\n-            fis.close();\n-          }\n-        } finally {\n-          fos.close();\n-        }\n-        dest.setExecutable(source.canExecute(), true);\n-        dest.setLastModified(lm);\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Basically just like {@link File#listFiles()} but instead of returning null returns an empty\n-   * array. This fixes bug 43729\n-   */\n-  public static File[] listFiles(File dir) {\n-    File[] result = dir.listFiles();\n-    if (result == null) {\n-      result = new File[0];\n-    }\n-    return result;\n-  }\n-\n-  /**\n-   * Basically just like {@link File#listFiles(FilenameFilter)} but instead of returning null\n-   * returns an empty array. This fixes bug 43729\n-   */\n-  public static File[] listFiles(File dir, FilenameFilter filter) {\n-    File[] result = dir.listFiles(filter);\n-    if (result == null) {\n-      result = new File[0];\n-    }\n-    return result;\n-  }\n-\n-  /**\n-   * Copy a single file using NIO.\n-   * \n-   * @throws IOException\n-   */\n-  private static void nioCopy(FileOutputStream fos, FileInputStream fis) throws IOException {\n-    FileChannel outChannel = fos.getChannel();\n-    FileChannel inChannel = fis.getChannel();\n-    long length = inChannel.size();\n-    long offset = 0;\n-    while (true) {\n-      long remaining = length - offset;\n-\n-      long toTransfer = remaining < MAX_TRANSFER_SIZE ? remaining : MAX_TRANSFER_SIZE;\n-      long transferredBytes = inChannel.transferTo(offset, toTransfer, outChannel);\n-      offset += transferredBytes;\n-      length = inChannel.size();\n-      if (offset >= length) {\n-        break;\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Copy a single file using the java.io.\n-   * \n-   * @throws IOException\n-   */\n-  private static void oioCopy(File source, FileOutputStream fos, FileInputStream fis)\n-      throws IOException {\n-    int size = (int) (source.length() < MAX_TRANSFER_SIZE ? source.length() : MAX_TRANSFER_SIZE);\n-    byte[] buffer = new byte[size];\n-    int read;\n-    while ((read = fis.read(buffer)) > 0) {\n-      fos.write(buffer, 0, read);\n-    }\n-\n-  }\n-\n-  /**\n-   * Recursively delete a file or directory.\n-   * \n-   * @throws IOException if the file or directory couldn't be deleted. Unlike File.delete, which\n-   *         just returns false.\n-   */\n-  public static void delete(File file) throws IOException {\n-    if (!file.exists())\n-      return;\n-\n-    if (file.isDirectory()) {\n-      for (File child : listFiles(file)) {\n-        delete(child);\n-      }\n-    }\n-\n-    Files.delete(file.toPath());\n-  }\n-\n-  /**\n-   * Recursively delete a file or directory. A description of any files or directories that can not\n-   * be deleted will be added to failures if failures is non-null. This method tries to delete as\n-   * much as possible.\n-   */\n-  public static void delete(File file, StringBuilder failures) {\n-    if (!file.exists())\n-      return;\n-\n-    if (file.isDirectory()) {\n-      for (File child : listFiles(file)) {\n-        delete(child, failures);\n-      }\n-    }\n-\n-    try {\n-      Files.delete(file.toPath());\n-    } catch (IOException e) {\n-      if (failures != null) {\n-        failures.append(\"Could not delete \").append(file).append(\" due to \").append(e.getMessage())\n-            .append('\\n');\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Find the file whose name matches the given regular expression. The regex is matched against the\n-   * absolute path of the file.\n-   * \n-   * This could probably use a lot of optimization!\n-   */\n-  public static File find(File baseFile, String regex) {\n-    if (baseFile.getAbsolutePath().matches(regex)) {\n-      return baseFile;\n-    }\n-    if (baseFile.exists() && baseFile.isDirectory()) {\n-      for (File child : listFiles(baseFile)) {\n-        File foundFile = find(child, regex);\n-        if (foundFile != null) {\n-          return foundFile;\n-        }\n-      }\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Find a files in a given base directory that match a the given regex. The regex is matched\n-   * against the full path of the file.\n-   */\n-  public static List<File> findAll(File baseFile, String regex) {\n-    ArrayList<File> found = new ArrayList<File>();\n-    findAll(baseFile, regex, found);\n-    return found;\n-  }\n-\n-  /**\n-   * Destroys all files that match the given regex that are in the given directory. If a destroy\n-   * fails it is ignored and an attempt is made to destroy any other files that match.\n-   */\n-  public static void deleteMatching(File baseFile, String regex) {\n-    if (baseFile.exists() && baseFile.isDirectory()) {\n-      for (File child : listFiles(baseFile)) {\n-        if (child.getName().matches(regex)) {\n-          try {\n-            delete(child);\n-          } catch (IOException ignore) {\n-          }\n-        }\n-      }\n-    }\n-  }\n-\n-  /** Implementation of findAll. */\n-  private static void findAll(File baseFile, String regex, List<File> found) {\n-    if (baseFile.getAbsolutePath().matches(regex)) {\n-      found.add(baseFile);\n-    }\n-    if (baseFile.exists() && baseFile.isDirectory()) {\n-      for (File child : listFiles(baseFile)) {\n-        findAll(child, regex, found);\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Convert a file into a relative path from a given parent. This is useful if you want to write\n-   * out the file name into that parent directory.\n-   * \n-   * @param parent The parent directory.\n-   * @param file The file we want to covert to a relative file.\n-   * @return A file, such that new File(parent, returnValue) == file. Note that if file does not\n-   *         have the parent in it's path, an the absolute version if the file is returned.\n-   */\n-  public static File removeParent(File parent, File file) {\n-    String absolutePath = file.getAbsolutePath();\n-    String parentAbsolutePath = parent.getAbsolutePath();\n-    String newPath = absolutePath.replace(parentAbsolutePath + \"/\", \"\");\n-    return new File(newPath);\n-  }\n-\n-  /**\n-   * Copy a URL to a file.\n-   * \n-   * @throws IOException\n-   */\n-  public static void copy(URL url, File file) throws IOException {\n-    InputStream is = url.openStream();\n-    try {\n-      OutputStream os = new FileOutputStream(file);\n-      try {\n-        byte[] buffer = new byte[8192];\n-        int read;\n-        while ((read = is.read(buffer)) > 0) {\n-          os.write(buffer, 0, read);\n-        }\n-      } finally {\n-        os.close();\n-      }\n-    } finally {\n-      is.close();\n-    }\n-\n-  }\n-\n-  /**\n-   * A safer version of File.mkdirs, which works around a race in the 1.5 JDK where two VMs creating\n-   * the same directory chain at the same time could end up in one VM failing to create a\n-   * subdirectory.\n-   * \n-   * @param file\n-   */\n-  public static boolean mkdirs(File file) {\n-    final File parentFile = file.getAbsoluteFile().getParentFile();\n-    if (!parentFile.exists()) {\n-      mkdirs(parentFile);\n-    }\n-    // As long as someone successfully created the parent file\n-    // go ahead and create the child directory.\n-    if (parentFile.exists()) {\n-      return file.mkdir();\n-    } else {\n-      return false;\n-    }\n-  }\n-\n-  /**\n-   * Returns the file name with the extension stripped off (if it has one).\n-   * \n-   * @param fileName the file name\n-   * @return the file name with the extension stripped off (if it had one)\n-   */\n-  public static String stripOffExtension(final String fileName) {\n-    if (fileName.contains(extSeparator)) {\n-      // strip off the extension and right-most \".\"\n-      return fileName.substring(0, fileName.lastIndexOf(extSeparator));\n-    }\n-    return fileName;\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/FileUtil.java",
                "sha": "2d729303a27179876e2f8a96c0542d796f426e16",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "patch": "@@ -1719,15 +1719,13 @@ protected void checkForLimitedOrNoAccess() {}\n    * Makes sure that the data was distributed to every required role. If it was not it either queues\n    * the data for later delivery or it throws an exception.\n    *\n-   * @param data the data that needs to be reliably distributed\n    * @param successfulRecipients the successful recipients\n    * @throws RoleException if a required role was not sent the message and the LossAction is either\n    *         NO_ACCESS or LIMITED_ACCESS.\n    * @since GemFire 5.0\n    *\n    */\n-  protected void handleReliableDistribution(ReliableDistributionData data,\n-      Set successfulRecipients) {\n+  protected void handleReliableDistribution(Set successfulRecipients) {\n     // do nothing by default\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegion.java",
                "sha": "7dffee264b3ef1cdf27781648d0d412612deb254",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "patch": "@@ -332,9 +332,9 @@ protected void notifyClientsOfTombstoneGC(Map<VersionSource, Long> regionGCVersi\n       // have the filter profile ferret out all of the clients that have interest\n       // in this region\n       FilterProfile fp = getFilterProfile();\n+      // fix for bug #46309 - don't send null/empty key set to clients\n       if ((removedKeys != null && !removedKeys.isEmpty()) // bug #51877 - NPE in clients\n-          && (routing != null || fp != null)) { // fix for bug #46309 - don't send null/empty key\n-                                                // set to clients\n+          && (routing != null || (fp != null && fp.hasInterest()))) {\n         RegionEventImpl regionEvent = new RegionEventImpl(getPartitionedRegion(),\n             Operation.REGION_DESTROY, null, true, getMyId());\n         FilterInfo clientRouting = routing;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "sha": "d92ddabdeda3b98344c36a1ff65e28f12212b869",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyOperation.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DestroyOperation.java",
                "patch": "@@ -198,12 +198,6 @@ public EventID getEventID() {\n       return this.eventId;\n     }\n \n-    @Override\n-    public List getOperations() {\n-      return Collections.singletonList(new QueuedOperation(getOperation(), this.key, null, null,\n-          DistributedCacheOperation.DESERIALIZATION_POLICY_NONE, this.callbackArg));\n-    }\n-\n     @Override\n     public ConflationKey getConflationKey() {\n       if (!super.regionAllowsConflation || getProcessorId() != 0) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyOperation.java",
                "sha": "5132ec0b4b5dffb330b5e1c2c424b43726202c0f",
                "status": "modified"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DiskInitFile.java",
                "changes": 60,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DiskInitFile.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 31,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DiskInitFile.java",
                "patch": "@@ -20,35 +20,7 @@\n import it.unimi.dsi.fastutil.longs.LongIterator;\n import it.unimi.dsi.fastutil.longs.LongOpenHashSet;\n import it.unimi.dsi.fastutil.objects.ObjectIterator;\n-\n-import java.io.BufferedInputStream;\n-import java.io.ByteArrayInputStream;\n-import java.io.DataInput;\n-import java.io.DataInputStream;\n-import java.io.DataOutput;\n-import java.io.EOFException;\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.IOException;\n-import java.io.PrintStream;\n-import java.io.RandomAccessFile;\n-import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.EnumSet;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.LinkedHashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-\n-import org.apache.logging.log4j.Logger;\n-\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.CancelCriterion;\n import org.apache.geode.CancelException;\n import org.apache.geode.DataSerializer;\n@@ -59,7 +31,6 @@\n import org.apache.geode.cache.RegionAttributes;\n import org.apache.geode.cache.RegionDestroyedException;\n import org.apache.geode.compression.Compressor;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.HeapDataOutputStream;\n import org.apache.geode.internal.InternalDataSerializer;\n import org.apache.geode.internal.InternalInstantiator;\n@@ -80,6 +51,33 @@\n import org.apache.geode.internal.i18n.LocalizedStrings;\n import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.logging.log4j.LogMarker;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedInputStream;\n+import java.io.ByteArrayInputStream;\n+import java.io.DataInput;\n+import java.io.DataInputStream;\n+import java.io.DataOutput;\n+import java.io.EOFException;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.RandomAccessFile;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n \n /**\n  * Does all the IF file work for a DiskStoreImpl.\n@@ -1506,7 +1504,7 @@ private void compact() {\n   public void copyTo(File targetDir) throws IOException {\n     lock.lock(false);\n     try {\n-      FileUtil.copy(this.ifFile, targetDir);\n+      FileUtils.copyFileToDirectory(this.ifFile, targetDir);\n     } finally {\n       lock.unlock();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DiskInitFile.java",
                "sha": "f6bf17f24ed2621731078d15bf59f1fd0326e3a9",
                "status": "modified"
            },
            {
                "additions": 97,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DiskStoreImpl.java",
                "changes": 192,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DiskStoreImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 95,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DiskStoreImpl.java",
                "patch": "@@ -14,25 +14,47 @@\n  */\n package org.apache.geode.internal.cache;\n \n+import static org.apache.geode.distributed.ConfigurationProperties.CACHE_XML_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongOpenHashSet;\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.CancelCriterion;\n import org.apache.geode.CancelException;\n import org.apache.geode.StatisticsFactory;\n import org.apache.geode.SystemFailure;\n-import org.apache.geode.cache.*;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheClosedException;\n+import org.apache.geode.cache.DiskAccessException;\n+import org.apache.geode.cache.DiskStore;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.RegionDestroyedException;\n import org.apache.geode.cache.persistence.PersistentID;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.i18n.StringId;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.DiskEntry.Helper.ValueWrapper;\n import org.apache.geode.internal.cache.DiskEntry.RecoveredEntry;\n import org.apache.geode.internal.cache.ExportDiskRegion.ExportWriter;\n import org.apache.geode.internal.cache.lru.LRUAlgorithm;\n import org.apache.geode.internal.cache.lru.LRUStatistics;\n-import org.apache.geode.internal.cache.persistence.*;\n+import org.apache.geode.internal.cache.persistence.BackupInspector;\n+import org.apache.geode.internal.cache.persistence.BackupManager;\n+import org.apache.geode.internal.cache.persistence.BytesAndBits;\n+import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n+import org.apache.geode.internal.cache.persistence.DiskRegionView;\n+import org.apache.geode.internal.cache.persistence.DiskStoreFilter;\n+import org.apache.geode.internal.cache.persistence.DiskStoreID;\n+import org.apache.geode.internal.cache.persistence.OplogType;\n+import org.apache.geode.internal.cache.persistence.PRPersistentConfig;\n+import org.apache.geode.internal.cache.persistence.PersistentMemberID;\n+import org.apache.geode.internal.cache.persistence.PersistentMemberPattern;\n+import org.apache.geode.internal.cache.persistence.RestoreScript;\n import org.apache.geode.internal.cache.snapshot.GFSnapshot;\n import org.apache.geode.internal.cache.snapshot.GFSnapshot.SnapshotWriter;\n import org.apache.geode.internal.cache.snapshot.SnapshotPacket.SnapshotRecord;\n@@ -50,17 +72,41 @@\n import org.apache.geode.pdx.internal.PdxField;\n import org.apache.geode.pdx.internal.PdxType;\n import org.apache.geode.pdx.internal.PeerTypeRegistration;\n-import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n-import it.unimi.dsi.fastutil.longs.LongOpenHashSet;\n import org.apache.logging.log4j.Logger;\n \n-import java.io.*;\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.FilenameFilter;\n+import java.io.IOException;\n+import java.io.PrintStream;\n import java.net.InetAddress;\n import java.nio.channels.ClosedByInterruptException;\n import java.nio.channels.FileChannel;\n import java.nio.channels.FileLock;\n-import java.util.*;\n-import java.util.concurrent.*;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.RejectedExecutionException;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.concurrent.atomic.AtomicLong;\n import java.util.concurrent.atomic.AtomicReference;\n@@ -70,8 +116,6 @@\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-\n /**\n  * Represents a (disk-based) persistent store for region data. Used for both persistent recoverable\n  * regions and overflow-only regions.\n@@ -86,15 +130,15 @@\n   private static final String BACKUP_DIR_PREFIX = \"dir\";\n   public static final boolean KRF_DEBUG = Boolean.getBoolean(\"disk.KRF_DEBUG\");\n \n-  public static final int MAX_OPEN_INACTIVE_OPLOGS = Integer\n-      .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPEN_INACTIVE_OPLOGS\", 7).intValue();\n+  public static final int MAX_OPEN_INACTIVE_OPLOGS =\n+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPEN_INACTIVE_OPLOGS\", 7);\n \n   /*\n    * If less than 20MB (default - configurable through this property) of the available space is left\n    * for logging and other misc stuff then it is better to bail out.\n    */\n-  public static final int MIN_DISK_SPACE_FOR_LOGS = Integer\n-      .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MIN_DISK_SPACE_FOR_LOGS\", 20).intValue();\n+  public static final int MIN_DISK_SPACE_FOR_LOGS =\n+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MIN_DISK_SPACE_FOR_LOGS\", 20);\n \n   /** Represents an invalid id of a key/value on disk */\n   public static final long INVALID_ID = 0L; // must be zero\n@@ -158,17 +202,15 @@ public static boolean getBoolean(String sysProp, boolean def) {\n    * other regions waiting for a compactor thread from the pool. Ignored if set to <= 0. Made non\n    * static so tests can set it.\n    */\n-  private final int MAX_OPLOGS_PER_COMPACTION = Integer\n-      .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPLOGS_PER_COMPACTION\", Integer\n-          .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPLOGS_PER_ROLL\", 1).intValue())\n-      .intValue();\n+  private final int MAX_OPLOGS_PER_COMPACTION = Integer.getInteger(\n+      DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPLOGS_PER_COMPACTION\",\n+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_OPLOGS_PER_ROLL\", 1).intValue());\n   /**\n    *\n    */\n-  public static final int MAX_CONCURRENT_COMPACTIONS = Integer\n-      .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_CONCURRENT_COMPACTIONS\", Integer\n-          .getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_CONCURRENT_ROLLS\", 1).intValue())\n-      .intValue();\n+  public static final int MAX_CONCURRENT_COMPACTIONS = Integer.getInteger(\n+      DistributionConfig.GEMFIRE_PREFIX + \"MAX_CONCURRENT_COMPACTIONS\",\n+      Integer.getInteger(DistributionConfig.GEMFIRE_PREFIX + \"MAX_CONCURRENT_ROLLS\", 1).intValue());\n \n   /**\n    * This system property indicates that maximum number of delayed write tasks that can be pending\n@@ -1441,8 +1483,8 @@ private void unsetPendingAsync(AsyncDiskEntry ade) {\n   private volatile boolean flusherThreadTerminated;\n \n   private void startAsyncFlusher() {\n-    final String thName = LocalizedStrings.DiskRegion_ASYNCHRONOUS_DISK_WRITER_0\n-        .toLocalizedString(new Object[] {getName()});\n+    final String thName =\n+        LocalizedStrings.DiskRegion_ASYNCHRONOUS_DISK_WRITER_0.toLocalizedString(getName());\n     this.flusherThread = new Thread(\n         LoggingThreadGroup.createThreadGroup(\n             LocalizedStrings.DiskRegion_DISK_WRITERS.toLocalizedString(), logger),\n@@ -1802,7 +1844,7 @@ private void createLockFile(String name) throws DiskAccessException {\n         f.deleteOnExit();\n         dae = null;\n         break;\n-      } catch (IOException ex) {\n+      } catch (IOException | IllegalStateException ex) {\n         if (fs != null) {\n           try {\n             fs.close();\n@@ -1811,16 +1853,6 @@ private void createLockFile(String name) throws DiskAccessException {\n         }\n         dae = new DiskAccessException(\n             LocalizedStrings.Oplog_COULD_NOT_LOCK_0.toLocalizedString(f.getPath()), ex, this);\n-      } catch (IllegalStateException ex2) {\n-        // OverlappingFileLockExtension needs to be caught here see bug 41290\n-        if (fs != null) {\n-          try {\n-            fs.close();\n-          } catch (IOException ignore) {\n-          }\n-        }\n-        dae = new DiskAccessException(\n-            LocalizedStrings.Oplog_COULD_NOT_LOCK_0.toLocalizedString(f.getPath()), ex2, this);\n       }\n       cnt++;\n       try {\n@@ -1945,17 +1977,7 @@ private void loadFiles(boolean needsOplogs) {\n       {\n         FilenameFilter overflowFileFilter =\n             new DiskStoreFilter(OplogType.OVERFLOW, true, partialFileName);\n-        for (DirectoryHolder dh : this.directories) {\n-          File dir = dh.getDir();\n-          // delete all overflow files\n-          File[] files = FileUtil.listFiles(dir, overflowFileFilter);\n-          for (File file : files) {\n-            boolean deleted = file.delete();\n-            if (!deleted && file.exists() && logger.isDebugEnabled()) {\n-              logger.debug(\"Could not delete file {}\", file);\n-            }\n-          }\n-        }\n+        deleteFiles(overflowFileFilter);\n       }\n \n       persistentOplogs.createOplogs(needsOplogs, persistentBackupFiles);\n@@ -1991,8 +2013,8 @@ private void loadFiles(boolean needsOplogs) {\n   private void statsClose() {\n     this.stats.close();\n     if (this.directories != null) {\n-      for (int i = 0; i < this.directories.length; i++) {\n-        this.directories[i].close();\n+      for (final DirectoryHolder directory : this.directories) {\n+        directory.close();\n       }\n     }\n   }\n@@ -2137,9 +2159,7 @@ private void clearAsyncQueue(LocalRegion region, boolean needsWriteLock,\n     try {\n       // Now while holding the write lock remove any elements from the queue\n       // for this region.\n-      Iterator<Object> it = this.asyncQueue.iterator();\n-      while (it.hasNext()) {\n-        Object o = it.next();\n+      for (final Object o : this.asyncQueue) {\n         if (o instanceof AsyncDiskEntry) {\n           AsyncDiskEntry ade = (AsyncDiskEntry) o;\n           if (shouldClear(region, rvv, ade)) {\n@@ -2531,8 +2551,7 @@ void beginDestroyRegion(LocalRegion region, DiskRegion dr) {\n \n   int incBackgroundTasks() {\n     getCache().getCachePerfStats().incDiskTasksWaiting();\n-    int v = this.backgroundTasks.incrementAndGet();\n-    return v;\n+    return this.backgroundTasks.incrementAndGet();\n   }\n \n   void decBackgroundTasks() {\n@@ -2636,13 +2655,14 @@ private void destroyAllOplogs() {\n   }\n \n   private void deleteFiles(FilenameFilter overflowFileFilter) {\n-    for (int i = 0; i < this.directories.length; i++) {\n-      File dir = this.directories[i].getDir();\n-      File[] files = FileUtil.listFiles(dir, overflowFileFilter);\n-      for (File file : files) {\n-        boolean deleted = file.delete();\n-        if (!deleted && file.exists() && logger.isDebugEnabled()) {\n-          logger.debug(\"Could not delete file {}\", file);\n+    for (final DirectoryHolder directory : this.directories) {\n+      File[] files = directory.getDir().listFiles(overflowFileFilter);\n+      if (files != null) {\n+        for (File file : files) {\n+          boolean deleted = file.delete();\n+          if (!deleted && file.exists() && logger.isDebugEnabled()) {\n+            logger.debug(\"Could not delete file {}\", file);\n+          }\n         }\n       }\n     }\n@@ -2738,8 +2758,8 @@ public String getBackupDirName() {\n \n     // Find all of the member's diskstore oplogs in the member's baseline\n     // diskstore directory structure (*.crf,*.krf,*.drf)\n-    List<File> baselineOplogFiles = FileUtil.findAll(baselineDir, \".*\\\\.[kdc]rf$\");\n-\n+    Collection<File> baselineOplogFiles =\n+        FileUtils.listFiles(baselineDir, new String[] {\"krf\", \"drf\", \"crf\"}, true);\n     // Our list of oplogs to copy (those not already in the baseline)\n     List<Oplog> oplogList = new LinkedList<Oplog>();\n \n@@ -2858,11 +2878,7 @@ private void stopCompactor() {\n      * @return true if compaction done; false if it was not\n      */\n     private synchronized boolean scheduleIfNeeded(CompactableOplog[] opLogs) {\n-      if (!this.scheduled) {\n-        return schedule(opLogs);\n-      } else {\n-        return false;\n-      }\n+      return !this.scheduled && schedule(opLogs);\n     }\n \n     /**\n@@ -2873,8 +2889,8 @@ private synchronized boolean schedule(CompactableOplog[] opLogs) {\n       if (!this.compactorEnabled)\n         return false;\n       if (opLogs != null) {\n-        for (int i = 0; i < opLogs.length; i++) {\n-          opLogs[i].prepareForCompact();\n+        for (final CompactableOplog opLog : opLogs) {\n+          opLog.prepareForCompact();\n         }\n         this.scheduled = true;\n         this.scheduledOplogs = opLogs;\n@@ -2922,10 +2938,7 @@ private boolean isClosing() {\n         return true;\n       }\n       CancelCriterion stopper = getCache().getCancelCriterion();\n-      if (stopper.isCancelInProgress()) {\n-        return true;\n-      }\n-      return false;\n+      return stopper.isCancelInProgress();\n     }\n \n     /**\n@@ -2953,7 +2966,7 @@ public void run() {\n           String tName = \"OplogCompactor \" + getName() + \" for oplog \" + oplogs[0].toString();\n           Thread.currentThread().setName(tName);\n \n-          StringBuffer buffer = new StringBuffer();\n+          StringBuilder buffer = new StringBuilder();\n           for (int j = 0; j < oplogs.length; ++j) {\n             buffer.append(oplogs[j].toString());\n             if (j + 1 < oplogs.length) {\n@@ -3239,9 +3252,8 @@ public PersistentMemberID generatePersistentID(DiskRegionView dr) {\n \n     // NOTE - do NOT use DM.cacheTimeMillis here. See bug #49920\n     long timestamp = System.currentTimeMillis();\n-    PersistentMemberID id = new PersistentMemberID(getDiskStoreID(), memberId.getInetAddress(),\n+    return new PersistentMemberID(getDiskStoreID(), memberId.getInetAddress(),\n         firstDir.getAbsolutePath(), memberId.getName(), timestamp, (short) 0);\n-    return id;\n   }\n \n   public PersistentID getPersistentID() {\n@@ -3534,12 +3546,12 @@ public AsyncDiskEntry(LocalRegion region, VersionTag tag) {\n     public String toString() {\n       StringBuilder sb = new StringBuilder();\n       sb.append(\"dr=\").append(region.getDiskRegion().getId());\n-      sb.append(\" versionOnly=\" + this.versionOnly);\n+      sb.append(\" versionOnly=\").append(this.versionOnly);\n       if (this.versionOnly) {\n-        sb.append(\" versionTag=\" + this.tag);\n+        sb.append(\" versionTag=\").append(this.tag);\n       }\n       if (de != null) {\n-        sb.append(\" key=\" + de.getKey());\n+        sb.append(\" key=\").append(de.getKey());\n       } else {\n         sb.append(\" <END CLEAR>\");\n       }\n@@ -3698,18 +3710,8 @@ private void dumpPdxTypes(PrintStream printStream) {\n           enums.add((EnumInfo) i);\n         }\n       }\n-      Collections.sort(types, new Comparator<PdxType>() {\n-        @Override\n-        public int compare(PdxType o1, PdxType o2) {\n-          return o1.getClassName().compareTo(o2.getClassName());\n-        }\n-      });\n-      Collections.sort(enums, new Comparator<EnumInfo>() {\n-        @Override\n-        public int compare(EnumInfo o1, EnumInfo o2) {\n-          return o1.compareTo(o2);\n-        }\n-      });\n+      types.sort(Comparator.comparing(PdxType::getClassName));\n+      enums.sort(EnumInfo::compareTo);\n \n       printStream.println(\"PDX Types:\");\n       for (PdxType type : types) {\n@@ -4132,7 +4134,7 @@ public void startBackup(File targetDir, BackupInspector baselineInspector,\n         }\n \n         // Get an appropriate lock object for each set of oplogs.\n-        Object childLock = childOplog == null ? new Object() : childOplog.lock;;\n+        Object childLock = childOplog.lock;;\n \n         // TODO - We really should move this lock into the disk store, but\n         // until then we need to do this magic to make sure we're actually\n@@ -4152,7 +4154,7 @@ public void startBackup(File targetDir, BackupInspector baselineInspector,\n           // Create the directories for this disk store\n           for (int i = 0; i < directories.length; i++) {\n             File dir = getBackupDir(targetDir, i);\n-            if (!FileUtil.mkdirs(dir)) {\n+            if (!dir.mkdirs()) {\n               throw new IOException(\"Could not create directory \" + dir);\n             }\n             restoreScript.addFile(directories[i].getDir(), dir);\n@@ -4364,7 +4366,7 @@ public static void dumpInfo(PrintStream printStream, String dsName, File[] dsDir\n     try {\n       DiskStoreImpl dsi = createForOffline(dsName, dsDirs, false);\n       dsi.dumpInfo(printStream, regName);\n-      if (listPdxTypes != null && listPdxTypes.booleanValue()) {\n+      if (listPdxTypes != null && listPdxTypes) {\n         dsi.dumpPdxTypes(printStream);\n       }\n     } finally {\n@@ -4554,7 +4556,7 @@ private static boolean isBackgroundTaskThread() {\n     boolean result = false;\n     Boolean tmp = backgroundTaskThread.get();\n     if (tmp != null) {\n-      result = tmp.booleanValue();\n+      result = tmp;\n     }\n     return result;\n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DiskStoreImpl.java",
                "sha": "cce810070be109b81c01bc5c0023d84c9eabe203",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedCacheOperation.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedCacheOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 24,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DistributedCacheOperation.java",
                "patch": "@@ -365,13 +365,7 @@ public void distribute() {\n         if (!reliableOp || region.isNoDistributionOk()) {\n           // nothing needs be done in this case\n         } else {\n-          // create the message so it can be passed to\n-          // handleReliableDistribution\n-          // for queuing\n-          CacheOperationMessage msg = createMessage();\n-          initMessage(msg, null);\n-          msg.setRecipients(recipients); // it is going to no one\n-          region.handleReliableDistribution(msg, Collections.EMPTY_SET);\n+          region.handleReliableDistribution(Collections.EMPTY_SET);\n         }\n \n         /** compute local client routing before waiting for an ack only for a bucket */\n@@ -625,7 +619,7 @@ public void distribute() {\n           if (departedMembers != null) {\n             successfulRecips.removeAll(departedMembers);\n           }\n-          region.handleReliableDistribution(msg, successfulRecips);\n+          region.handleReliableDistribution(successfulRecips);\n         }\n       }\n \n@@ -864,7 +858,7 @@ public static void setBeforePutOutgoing(Runnable beforePutOutgoing) {\n   }\n \n   public static abstract class CacheOperationMessage extends SerialDistributionMessage\n-      implements MessageWithReply, DirectReplyMessage, ReliableDistributionData, OldValueImporter {\n+      implements MessageWithReply, DirectReplyMessage, OldValueImporter {\n \n     protected final static short POSSIBLE_DUPLICATE_MASK = POS_DUP;\n     protected final static short OLD_VALUE_MASK = DistributionMessage.UNRESERVED_FLAGS_START;\n@@ -1482,21 +1476,6 @@ public final boolean supportsDirectAck() {\n       return this.directAck;\n     }\n \n-    // ////////////////////////////////////////////////////////////////////\n-    // ReliableDistributionData methods\n-    // ////////////////////////////////////////////////////////////////////\n-\n-    public int getOperationCount() {\n-      return 1;\n-    }\n-\n-    public List getOperations() {\n-      byte noDeserialize = DistributedCacheOperation.DESERIALIZATION_POLICY_NONE;\n-      QueuedOperation qOp =\n-          new QueuedOperation(getOperation(), null, null, null, noDeserialize, this.callbackArg);\n-      return Collections.singletonList(qOp);\n-    }\n-\n     public void setSendDelta(boolean sendDelta) {\n       this.sendDelta = sendDelta;\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedCacheOperation.java",
                "sha": "bded899f3254c5a9d5e53762959f2d948c0a60bf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedPutAllOperation.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedPutAllOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 27,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DistributedPutAllOperation.java",
                "patch": "@@ -1261,11 +1261,6 @@ protected short computeCompressedShort(short s) {\n       return s;\n     }\n \n-    @Override\n-    public int getOperationCount() {\n-      return this.putAllDataSize;\n-    }\n-\n     public ClientProxyMembershipID getContext() {\n       return this.context;\n     }\n@@ -1274,27 +1269,5 @@ public ClientProxyMembershipID getContext() {\n       return this.putAllData;\n     }\n \n-    @Override\n-    public List getOperations() {\n-      QueuedOperation[] ops = new QueuedOperation[getOperationCount()];\n-      for (int i = 0; i < ops.length; i++) {\n-        PutAllEntryData entry = this.putAllData[i];\n-        byte[] valueBytes = null;\n-        Object valueObj = null;\n-        Object v = entry.getValue();\n-        byte deserializationPolicy;\n-        if (v instanceof CachedDeserializable) {\n-          deserializationPolicy = DESERIALIZATION_POLICY_LAZY;\n-          valueBytes = ((CachedDeserializable) v).getSerializedValue();\n-        } else {\n-          deserializationPolicy = DESERIALIZATION_POLICY_NONE;\n-          valueBytes = (byte[]) v;\n-        }\n-\n-        ops[i] = new QueuedOperation(entry.getOp(), entry.getKey(), valueBytes, valueObj,\n-            deserializationPolicy, this.callbackArg);\n-      }\n-      return Arrays.asList(ops);\n-    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedPutAllOperation.java",
                "sha": "61542c4e2bfef494ea8854bb683cec967372e973",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRegion.java",
                "changes": 100,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRegion.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 76,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRegion.java",
                "patch": "@@ -109,13 +109,6 @@\n    */\n   private final boolean requiresReliabilityCheck;\n \n-  /**\n-   * Provides a queue for reliable message delivery\n-   * \n-   * @since GemFire 5.0\n-   */\n-  protected final ReliableMessageQueue rmq;\n-\n   /**\n    * Latch that is opened after initialization waits for required roles up to the\n    * <a href=\"DistributedSystem#member-timeout\">member-timeout </a>.\n@@ -183,18 +176,6 @@ protected DistributedRegion(String regionName, RegionAttributes attrs, LocalRegi\n \n     this.requiresReliabilityCheck = setRequiresReliabilityCheck;\n \n-    {\n-      ReliableMessageQueue tmp = null;\n-      if (this.requiresReliabilityCheck) {\n-        // if\n-        // (attrs.getMembershipAttributes().getLossAction().isAllAccessWithQueuing())\n-        // {\n-        // tmp = cache.getReliableMessageQueueFactory().create(this);\n-        // }\n-      }\n-      this.rmq = tmp;\n-    }\n-\n     if (internalRegionArgs.isUsedForPartitionedRegionBucket()) {\n       this.persistenceAdvisor = internalRegionArgs.getPersistenceAdvisor();\n     } else if (this.allowsPersistence()) {\n@@ -567,14 +548,12 @@ protected void checkForLimitedOrNoAccess() {\n   }\n \n   @Override\n-  protected void handleReliableDistribution(ReliableDistributionData data,\n-      Set successfulRecipients) {\n-    handleReliableDistribution(data, successfulRecipients, Collections.EMPTY_SET,\n-        Collections.EMPTY_SET);\n+  protected void handleReliableDistribution(Set successfulRecipients) {\n+    handleReliableDistribution(successfulRecipients, Collections.EMPTY_SET, Collections.EMPTY_SET);\n   }\n \n-  protected void handleReliableDistribution(ReliableDistributionData data, Set successfulRecipients,\n-      Set otherRecipients1, Set otherRecipients2) {\n+  protected void handleReliableDistribution(Set successfulRecipients, Set otherRecipients1,\n+      Set otherRecipients2) {\n     if (this.requiresReliabilityCheck) {\n       MembershipAttributes ra = getMembershipAttributes();\n       Set recipients = successfulRecipients;\n@@ -2140,19 +2119,6 @@ public final DistributionConfig getDistributionConfig() {\n     return getSystem().getDistributionManager().getConfig();\n   }\n \n-  /**\n-   * Sends a list of queued messages to members playing a specified role\n-   * \n-   * @param list List of QueuedOperation instances to send. Any messages sent will be removed from\n-   *        this list\n-   * @param role the role that a recipient must be playing\n-   * @return true if at least one message made it to at least one guy playing the role\n-   */\n-  boolean sendQueue(List list, Role role) {\n-    SendQueueOperation op = new SendQueueOperation(getDistributionManager(), this, list, role);\n-    return op.distribute();\n-  }\n-\n   /*\n    * @see SearchLoadAndWriteProcessor#initialize(LocalRegion, Object, Object)\n    */\n@@ -2336,17 +2302,27 @@ protected Object findObjectInSystem(KeyInfo keyInfo, boolean isCreate, TXStateIn\n         if (requestingClient != null) {\n           event.setContext(requestingClient);\n         }\n-        SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();\n-        try {\n-          processor.initialize(this, key, aCallbackArgument);\n-          // processor fills in event\n-          processor.doSearchAndLoad(event, txState, localValue);\n-          if (clientEvent != null && clientEvent.getVersionTag() == null) {\n-            clientEvent.setVersionTag(event.getVersionTag());\n+        // If this event is because of a register interest call, don't invoke the CacheLoader\n+        boolean getForRegisterInterest = clientEvent != null && clientEvent.getOperation() != null\n+            && clientEvent.getOperation().isGetForRegisterInterest();\n+        if (!getForRegisterInterest) {\n+          SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();\n+          try {\n+            processor.initialize(this, key, aCallbackArgument);\n+            // processor fills in event\n+            processor.doSearchAndLoad(event, txState, localValue);\n+            if (clientEvent != null && clientEvent.getVersionTag() == null) {\n+              clientEvent.setVersionTag(event.getVersionTag());\n+            }\n+            lastModified = processor.getLastModified();\n+          } finally {\n+            processor.release();\n+          }\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"DistributedRegion.findObjectInSystem skipping loader for region=\"\n+                + getFullPath() + \"; key=\" + key);\n           }\n-          lastModified = processor.getLastModified();\n-        } finally {\n-          processor.release();\n         }\n       }\n       if (event.hasNewValue() && !isMemoryThresholdReachedForLoad()) {\n@@ -2521,10 +2497,6 @@ protected void distributedRegionCleanup(RegionEventImpl event) {\n             this.getFullPath()), ex);\n       }\n     }\n-    if (this.rmq != null) {\n-      this.rmq.close();\n-    }\n-\n     // Fix for #48066 - make sure that region operations are completely\n     // distributed to peers before destroying the region.\n     long timeout = 1000L * getCache().getDistributedSystem().getConfig().getAckWaitThreshold();\n@@ -2628,9 +2600,6 @@ protected void postDestroyRegion(boolean destroyDiskRegion, RegionEventImpl even\n       logger.warn(\"postDestroyRegion: encountered cancellation\", e);\n     }\n \n-    if (this.rmq != null && destroyDiskRegion) {\n-      this.rmq.destroy();\n-    }\n   }\n \n   @Override\n@@ -3601,27 +3570,6 @@ public synchronized void memberJoined(InternalDistributedMember id) {\n             newlyAcquiredRoles = new HashSet(missingRequiredRoles);\n             newlyAcquiredRoles.retainAll(roles); // find the intersection\n             if (!newlyAcquiredRoles.isEmpty()) {\n-              if (DistributedRegion.this.rmq != null) {\n-                Iterator it = newlyAcquiredRoles.iterator();\n-                final DM dm = getDistributionManager();\n-                while (it.hasNext()) {\n-                  getCache().getCancelCriterion().checkCancelInProgress(null);\n-                  final Role role = (Role) it.next();\n-                  try {\n-                    // do this in the waiting pool to make it async\n-                    // @todo darrel/klund: add a single serial executor for\n-                    // queue flush\n-                    dm.getWaitingThreadPool().execute(new Runnable() {\n-                      public void run() {\n-                        DistributedRegion.this.rmq.roleReady(role);\n-                      }\n-                    });\n-                    break;\n-                  } catch (RejectedExecutionException ex) {\n-                    throw ex;\n-                  }\n-                } // while\n-              }\n               missingRequiredRoles.removeAll(newlyAcquiredRoles);\n               if (this.members == null && missingRequiredRoles.isEmpty()) {\n                 isMissingRequiredRoles = false;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRegion.java",
                "sha": "b9cdfd75c19f3425dacc8f99c1bc399248230b71",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRemoveAllOperation.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRemoveAllOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 15,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRemoveAllOperation.java",
                "patch": "@@ -1042,11 +1042,6 @@ protected short computeCompressedShort(short s) {\n       return s;\n     }\n \n-    @Override\n-    public int getOperationCount() {\n-      return this.removeAllDataSize;\n-    }\n-\n     public ClientProxyMembershipID getContext() {\n       return this.context;\n     }\n@@ -1055,15 +1050,5 @@ public ClientProxyMembershipID getContext() {\n       return this.removeAllData;\n     }\n \n-    @Override\n-    public List getOperations() {\n-      QueuedOperation[] ops = new QueuedOperation[getOperationCount()];\n-      for (int i = 0; i < ops.length; i++) {\n-        RemoveAllEntryData entry = this.removeAllData[i];\n-        ops[i] = new QueuedOperation(entry.getOp(), entry.getKey(), null, null, (byte) 0,\n-            this.callbackArg);\n-      }\n-      return Arrays.asList(ops);\n-    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/DistributedRemoveAllOperation.java",
                "sha": "0c13b59085878bcdf17cb78346221e65230dbc4e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 27,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "patch": "@@ -878,8 +878,6 @@ private GemFireCacheImpl(boolean isClient, PoolFactory pf, DistributedSystem sys\n \n       this.cqService = CqServiceProvider.create(this);\n \n-      this.rmqFactory = new ReliableMessageQueueFactoryImpl();\n-\n       // Create the CacheStatistics\n       this.cachePerfStats = new CachePerfStats(system);\n       CachePerfStats.enableClockStats = this.system.getConfig().getEnableTimeStatistics();\n@@ -2326,17 +2324,6 @@ public void close(String reason, Throwable systemFailureCause, boolean keepalive\n \n           PoolManager.close(keepalive);\n \n-          if (isDebugEnabled) {\n-            logger.debug(\"{}: closing reliable message queue...\", this);\n-          }\n-          try {\n-            getReliableMessageQueueFactory().close(true);\n-          } catch (CancelException e) {\n-            if (isDebugEnabled) {\n-              logger.debug(\"Ignored cancellation while closing reliable message queue\", e);\n-            }\n-          }\n-\n           if (isDebugEnabled) {\n             logger.debug(\"{}: notifying admins of close...\", this);\n           }\n@@ -4497,22 +4484,8 @@ public void readyForEvents() {\n     PoolManagerImpl.readyForEvents(this.system, false);\n   }\n \n-  /**\n-   * This cache's reliable message queue factory. Should always have an instance of it.\n-   */\n-  private final ReliableMessageQueueFactory rmqFactory;\n-\n   private List<File> backupFiles = Collections.emptyList();\n \n-  /**\n-   * Returns this cache's ReliableMessageQueueFactory.\n-   *\n-   * @since GemFire 5.0\n-   */\n-  public ReliableMessageQueueFactory getReliableMessageQueueFactory() {\n-    return this.rmqFactory;\n-  }\n-\n   public InternalResourceManager getResourceManager() {\n     return getResourceManager(true);\n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "sha": "66f1a4a59c91bfb59fa40ef3b50a5f4463631e65",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidateOperation.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidateOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 8,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InvalidateOperation.java",
                "patch": "@@ -145,14 +145,6 @@ public EventID getEventID() {\n       return this.eventId;\n     }\n \n-    @Override\n-    public List getOperations() {\n-      byte deserializationPolicy = DistributedCacheOperation.DESERIALIZATION_POLICY_NONE;\n-      QueuedOperation qOp = new QueuedOperation(getOperation(), this.key, null, null,\n-          deserializationPolicy, this.callbackArg);\n-      return Collections.singletonList(qOp);\n-    }\n-\n     @Override\n     public ConflationKey getConflationKey() {\n       if (!super.regionAllowsConflation || getProcessorId() != 0) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidateOperation.java",
                "sha": "eceb1947a3598b5832502c2278604e14ca07311c",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/OpType.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/OpType.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/OpType.java",
                "patch": "@@ -49,6 +49,8 @@ private OpType() {}\n \n   public static final byte UPDATE_ENTRY_VERSION = 11;\n \n+  public static final byte GET_FOR_REGISTER_INTEREST = 12;\n+\n   public static final byte CLEAR = 16;\n \n   public static final byte MARKER = 32;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/OpType.java",
                "sha": "ff36a570b714bfb5b4340cda5ea5aae86428c281",
                "status": "modified"
            },
            {
                "additions": 64,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/Oplog.java",
                "changes": 82,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/Oplog.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 18,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/Oplog.java",
                "patch": "@@ -14,14 +14,34 @@\n  */\n package org.apache.geode.internal.cache;\n \n+import it.unimi.dsi.fastutil.ints.Int2ObjectMap;\n+import it.unimi.dsi.fastutil.ints.Int2ObjectOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectOpenHashMap;\n+import it.unimi.dsi.fastutil.objects.ObjectIterator;\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.CancelException;\n import org.apache.geode.DataSerializer;\n import org.apache.geode.SerializationException;\n-import org.apache.geode.cache.*;\n+import org.apache.geode.cache.CacheClosedException;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.DiskAccessException;\n+import org.apache.geode.cache.EntryDestroyedException;\n+import org.apache.geode.cache.EntryEvent;\n+import org.apache.geode.cache.EntryNotFoundException;\n+import org.apache.geode.cache.RegionDestroyedException;\n+import org.apache.geode.cache.TimeoutException;\n+import org.apache.geode.cache.UnsupportedVersionException;\n import org.apache.geode.distributed.OplogCancelledException;\n import org.apache.geode.distributed.internal.DM;\n import org.apache.geode.distributed.internal.DistributionConfig;\n-import org.apache.geode.internal.*;\n+import org.apache.geode.internal.Assert;\n+import org.apache.geode.internal.ByteArrayDataInput;\n+import org.apache.geode.internal.HeapDataOutputStream;\n+import org.apache.geode.internal.InternalDataSerializer;\n+import org.apache.geode.internal.InternalStatisticsDisabledException;\n+import org.apache.geode.internal.Sendable;\n+import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.DiskEntry.Helper.Flushable;\n import org.apache.geode.internal.cache.DiskEntry.Helper.ValueWrapper;\n import org.apache.geode.internal.cache.DiskInitFile.DiskRegionFlag;\n@@ -30,8 +50,19 @@\n import org.apache.geode.internal.cache.DistributedRegion.DiskPosition;\n import org.apache.geode.internal.cache.lru.EnableLRU;\n import org.apache.geode.internal.cache.lru.NewLRUClockHand;\n-import org.apache.geode.internal.cache.persistence.*;\n-import org.apache.geode.internal.cache.versions.*;\n+import org.apache.geode.internal.cache.persistence.BytesAndBits;\n+import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n+import org.apache.geode.internal.cache.persistence.DiskRegionView;\n+import org.apache.geode.internal.cache.persistence.DiskStoreID;\n+import org.apache.geode.internal.cache.persistence.UninterruptibleFileChannel;\n+import org.apache.geode.internal.cache.persistence.UninterruptibleRandomAccessFile;\n+import org.apache.geode.internal.cache.versions.CompactVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionHolder;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.internal.cache.versions.VersionStamp;\n+import org.apache.geode.internal.cache.versions.VersionTag;\n import org.apache.geode.internal.i18n.LocalizedStrings;\n import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.logging.log4j.LocalizedMessage;\n@@ -47,20 +78,35 @@\n import org.apache.geode.internal.util.IOUtils;\n import org.apache.geode.internal.util.TransformUtils;\n import org.apache.geode.pdx.internal.PdxWriterImpl;\n-\n-import it.unimi.dsi.fastutil.ints.Int2ObjectMap;\n-import it.unimi.dsi.fastutil.ints.Int2ObjectOpenHashMap;\n-import it.unimi.dsi.fastutil.longs.Long2ObjectMap;\n-import it.unimi.dsi.fastutil.longs.Long2ObjectOpenHashMap;\n-import it.unimi.dsi.fastutil.objects.ObjectIterator;\n-\n import org.apache.logging.log4j.Logger;\n \n-import java.io.*;\n+import java.io.BufferedInputStream;\n+import java.io.BufferedOutputStream;\n+import java.io.DataInput;\n+import java.io.DataInputStream;\n+import java.io.DataOutput;\n+import java.io.DataOutputStream;\n+import java.io.EOFException;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.InterruptedIOException;\n+import java.io.SyncFailedException;\n import java.nio.ByteBuffer;\n import java.nio.channels.ClosedChannelException;\n-import java.util.*;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n import java.util.Map.Entry;\n+import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.atomic.AtomicBoolean;\n@@ -1176,7 +1222,7 @@ File getOplogFile() throws SyncFailedException, IOException {\n    * @return a map of baslineline oplog files to copy. May be empty if total current set for this\n    *         oplog does not match the baseline.\n    */\n-  Map<File, File> mapBaseline(List<File> baselineOplogFiles) {\n+  Map<File, File> mapBaseline(Collection<File> baselineOplogFiles) {\n     // Map of baseline oplog file name to oplog file\n     Map<String, File> baselineOplogMap =\n         TransformUtils.transformAndMap(baselineOplogFiles, TransformUtils.fileNameTransformer);\n@@ -5759,13 +5805,13 @@ public void deleteDRFFileOnly() {\n \n   public void copyTo(File targetDir) throws IOException {\n     if (this.crf.f != null) { // fixes bug 43951\n-      FileUtil.copy(this.crf.f, targetDir);\n+      FileUtils.copyFileToDirectory(this.crf.f, targetDir);\n     }\n-    FileUtil.copy(this.drf.f, targetDir);\n+    FileUtils.copyFileToDirectory(this.drf.f, targetDir);\n \n     // this krf existence check fixes 45089\n     if (getParent().getDiskInitFile().hasKrf(this.oplogId)) {\n-      FileUtil.copy(this.getKrfFile(), targetDir);\n+      FileUtils.copyFileToDirectory(this.getKrfFile(), targetDir);\n     }\n   }\n \n@@ -5788,7 +5834,7 @@ private void deleteFile(final OplogFile olf) {\n         return;\n       if (!olf.f.exists())\n         return;\n-      assert olf.RAFClosed == true;\n+      assert olf.RAFClosed;\n       if (!olf.RAFClosed || olf.raf != null) {\n         try {\n           olf.raf.close();",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/Oplog.java",
                "sha": "f5aec51a09e671bc7d4ca33d4de8f0f683ef4d73",
                "status": "modified"
            },
            {
                "additions": 19,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/PersistentOplogSet.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/PersistentOplogSet.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 21,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/PersistentOplogSet.java",
                "patch": "@@ -15,6 +15,20 @@\n package org.apache.geode.internal.cache;\n \n import it.unimi.dsi.fastutil.longs.LongOpenHashSet;\n+import org.apache.geode.cache.DiskAccessException;\n+import org.apache.geode.internal.cache.DiskEntry.Helper.ValueWrapper;\n+import org.apache.geode.internal.cache.DiskStoreImpl.OplogEntryIdSet;\n+import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n+import org.apache.geode.internal.cache.persistence.DiskRegionView;\n+import org.apache.geode.internal.cache.persistence.DiskStoreFilter;\n+import org.apache.geode.internal.cache.persistence.OplogType;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.i18n.LocalizedStrings;\n+import org.apache.geode.internal.logging.LogService;\n+import org.apache.geode.internal.logging.log4j.LocalizedMessage;\n+import org.apache.geode.internal.logging.log4j.LogMarker;\n+import org.apache.geode.internal.sequencelog.EntryLogger;\n+import org.apache.logging.log4j.Logger;\n \n import java.io.File;\n import java.io.FilenameFilter;\n@@ -32,23 +46,6 @@\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.concurrent.atomic.AtomicLong;\n \n-import org.apache.logging.log4j.Logger;\n-\n-import org.apache.geode.cache.DiskAccessException;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.internal.cache.DiskEntry.Helper.ValueWrapper;\n-import org.apache.geode.internal.cache.DiskStoreImpl.OplogEntryIdSet;\n-import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n-import org.apache.geode.internal.cache.persistence.DiskRegionView;\n-import org.apache.geode.internal.cache.persistence.DiskStoreFilter;\n-import org.apache.geode.internal.cache.persistence.OplogType;\n-import org.apache.geode.internal.cache.versions.RegionVersionVector;\n-import org.apache.geode.internal.i18n.LocalizedStrings;\n-import org.apache.geode.internal.logging.LogService;\n-import org.apache.geode.internal.logging.log4j.LocalizedMessage;\n-import org.apache.geode.internal.logging.log4j.LogMarker;\n-import org.apache.geode.internal.sequencelog.EntryLogger;\n-\n public class PersistentOplogSet implements OplogSet {\n   private static final Logger logger = LogService.getLogger();\n \n@@ -212,10 +209,11 @@ public void forceRoll(DiskRegion dr) {\n     Map<File, DirectoryHolder> backupFiles = new HashMap<File, DirectoryHolder>();\n     FilenameFilter backupFileFilter = getFileNameFilter(partialFileName);\n     for (DirectoryHolder dh : parent.directories) {\n-      File dir = dh.getDir();\n-      File[] backupList = FileUtil.listFiles(dir, backupFileFilter);\n-      for (File f : backupList) {\n-        backupFiles.put(f, dh);\n+      File[] backupList = dh.getDir().listFiles(backupFileFilter);\n+      if (backupList != null) {\n+        for (File f : backupList) {\n+          backupFiles.put(f, dh);\n+        }\n       }\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/PersistentOplogSet.java",
                "sha": "036c74070ec01f68da382dc33a836e25635c61f7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableDistributionData.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableDistributionData.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 41,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ReliableDistributionData.java",
                "patch": "@@ -1,41 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal.cache;\n-\n-import java.util.*;\n-\n-/**\n- * Represents one or more distributed operations that can be reliably distributed. This interface\n- * allows the data to be queued and checked for reliable distribution.\n- * \n- * @since GemFire 5.0\n- */\n-public interface ReliableDistributionData {\n-  // /**\n-  // * Returns a set of the recipients that this data was sent to successfully.\n-  // * @param processor the reply processor used for responses to this data.\n-  // */\n-  // public Set getSuccessfulRecipients(ReliableReplyProcessor21 processor);\n-  /**\n-   * Returns the number of logical operations this data contains.\n-   */\n-  public int getOperationCount();\n-\n-  /**\n-   * Returns a list of QueuedOperation instances one for each logical operation done by this data\n-   * instance.\n-   */\n-  public List getOperations();\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableDistributionData.java",
                "sha": "5c635eeff35cc2697f0657476a1dc46c871f7c4d",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueue.java",
                "changes": 69,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueue.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 69,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueue.java",
                "patch": "@@ -1,69 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal.cache;\n-\n-import org.apache.geode.distributed.Role;\n-\n-import java.util.Set;\n-\n-/**\n- * A reliable message queue is used by a DistributedRegion to queue up distributed operations for\n- * required roles that are not present at the time the operation is done. Instances of this\n- * interface can be obtained from {@link ReliableMessageQueueFactory} which can be obtained from\n- * {@link GemFireCacheImpl#getReliableMessageQueueFactory}.\n- * \n- * @since GemFire 5.0\n- */\n-public interface ReliableMessageQueue {\n-  /**\n-   * Returns the region this queue belongs to.\n-   */\n-  public DistributedRegion getRegion();\n-\n-  /**\n-   * Adds a message to the queue to be sent to the list of roles.\n-   * \n-   * @param data the actual data that describes the operation to enqueue\n-   * @param roles the roles that need to receive this message.\n-   */\n-  public void add(ReliableDistributionData data, Set roles);\n-\n-  /**\n-   * Gets the roles that this queue currently has messages for.\n-   * \n-   * @return a set of {link Role}s that currently have queued messages. <code>null</code> is\n-   *         returned if no messages are queued.\n-   */\n-  public Set getQueuingRoles();\n-\n-  /**\n-   * Attempts to send any messages that have been added for the given role to all members that are\n-   * currently playing that role.\n-   * \n-   * @param role the role whose queued messages should be sent\n-   * @return true if send was successful; false if it was not and the messages are still queued.\n-   */\n-  public boolean roleReady(Role role);\n-\n-  /**\n-   * Removes all the data in this queue causing it to never be sent.\n-   */\n-  public void destroy();\n-\n-  /**\n-   * Closes this queue. This frees up any memory used by the queue but its persistent data remains.\n-   */\n-  public void close();\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueue.java",
                "sha": "55c1039f28fcd9ef4c1503999492952d0b0b428f",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactory.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactory.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 41,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactory.java",
                "patch": "@@ -1,41 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal.cache;\n-\n-/**\n- * Represents a factory for instances of {@link ReliableMessageQueue}. The Cache will have an\n- * instance of the factory that can be obtained from\n- * {@link GemFireCacheImpl#getReliableMessageQueueFactory}.\n- * \n- * @since GemFire 5.0\n- */\n-public interface ReliableMessageQueueFactory {\n-  /**\n-   * Creates an instance of {@link ReliableMessageQueue} given the region that the queue will be on.\n-   * \n-   * @param region the distributed region that the created queue will service.\n-   * @return the created queue\n-   */\n-  public ReliableMessageQueue create(DistributedRegion region);\n-\n-  /**\n-   * Cleanly shutdown this factory flushing any persistent data to disk.\n-   * \n-   * @param force true if close should always work\n-   * @throws IllegalStateException if <code>force</code> is false and the factory is still in use.\n-   *         The factory is in use as long as a queue it produced remains unclosed.\n-   */\n-  public void close(boolean force);\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactory.java",
                "sha": "39da937503c3dda897fdb2b55b8a4df3db3827af",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactoryImpl.java",
                "changes": 246,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactoryImpl.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 246,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactoryImpl.java",
                "patch": "@@ -1,246 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal.cache;\n-\n-import org.apache.geode.distributed.Role;\n-import org.apache.geode.internal.i18n.LocalizedStrings;\n-\n-import java.util.*;\n-\n-/**\n- * Implementation of {@link ReliableMessageQueueFactory}\n- * \n- * @since GemFire 5.0\n- */\n-public class ReliableMessageQueueFactoryImpl implements ReliableMessageQueueFactory {\n-  private boolean closed;\n-\n-  /**\n-   * Create a factory given its persistence attributes.\n-   */\n-  public ReliableMessageQueueFactoryImpl() {\n-    this.closed = false;\n-  }\n-\n-  /**\n-   * Contains all the unclosed queues that have been created by this factory.\n-   */\n-  private final ArrayList queues = new ArrayList();\n-\n-  public ReliableMessageQueue create(DistributedRegion region) {\n-    if (this.closed) {\n-      throw new IllegalStateException(\n-          LocalizedStrings.ReliableMessageQueueFactoryImpl_RELIABLE_MESSAGE_QUEUE_IS_CLOSED\n-              .toLocalizedString());\n-    }\n-    synchronized (this.queues) {\n-      Queue q = new Queue(region);\n-      this.queues.add(q);\n-      return q;\n-    }\n-  }\n-\n-  public void close(boolean force) {\n-    // @todo darrel: nyi\n-    if (!force) {\n-      synchronized (this.queues) {\n-        if (!this.queues.isEmpty()) {\n-          throw new IllegalStateException(\n-              LocalizedStrings.ReliableMessageQueueFactoryImpl_REGIONS_WITH_MESSAGE_QUEUING_ALREADY_EXIST\n-                  .toLocalizedString());\n-        }\n-      }\n-    }\n-    this.closed = true;\n-  }\n-\n-  /**\n-   * Maps DistributedRegion keys to QueuedRegionData values\n-   */\n-  private final IdentityHashMap regionMap = new IdentityHashMap(128);\n-\n-  /**\n-   * Adds data in the specified region to be sent to the specified roles\n-   */\n-  protected void add(DistributedRegion r, ReliableDistributionData data, Set roles) {\n-    QueuedRegionData qrd = null;\n-    synchronized (this.regionMap) {\n-      qrd = (QueuedRegionData) this.regionMap.get(r);\n-    }\n-    qrd.add(r, data, roles);\n-    r.getCachePerfStats().incReliableQueuedOps(data.getOperationCount() * roles.size());\n-  }\n-\n-  public Set getQueuingRoles(DistributedRegion r) {\n-    QueuedRegionData qrd = null;\n-    synchronized (this.regionMap) {\n-      qrd = (QueuedRegionData) this.regionMap.get(r);\n-    }\n-    return qrd.getQueuingRoles(r);\n-  }\n-\n-  protected boolean roleReady(DistributedRegion r, Role role) {\n-    QueuedRegionData qrd = null;\n-    synchronized (this.regionMap) {\n-      qrd = (QueuedRegionData) this.regionMap.get(r);\n-    }\n-    return qrd.roleReady(r, role);\n-  }\n-\n-  /**\n-   * Initializes data queuing for the given region\n-   */\n-  protected void init(DistributedRegion r) {\n-    QueuedRegionData qrd = new QueuedRegionData();\n-    synchronized (this.regionMap) {\n-      Object old = this.regionMap.put(r, qrd);\n-      if (old != null) {\n-        throw new IllegalStateException(\n-            LocalizedStrings.ReliableMessageQueueFactoryImpl_UNEXPECTED_QUEUEDREGIONDATA_0_FOR_REGION_1\n-                .toLocalizedString(new Object[] {old, r}));\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Removes any data queued for the given region\n-   */\n-  protected void destroy(DistributedRegion r) {\n-    QueuedRegionData qrd = null;\n-    synchronized (this.regionMap) {\n-      qrd = (QueuedRegionData) this.regionMap.remove(r);\n-    }\n-    if (qrd != null) {\n-      qrd.destroy(r);\n-    }\n-  }\n-\n-  /**\n-   * Removes a previously created queue from this factory.\n-   */\n-  protected void removeQueue(Queue q) {\n-    synchronized (this.queues) {\n-      this.queues.remove(q);\n-    }\n-  }\n-\n-  /**\n-   * Implements ReliableMessageQueue.\n-   * \n-   * @since GemFire 5.0\n-   */\n-  public class Queue implements ReliableMessageQueue {\n-    private final DistributedRegion r;\n-\n-    Queue(DistributedRegion r) {\n-      this.r = r;\n-      init(this.r);\n-    }\n-\n-    public DistributedRegion getRegion() {\n-      return this.r;\n-    }\n-\n-    public void add(ReliableDistributionData data, Set roles) {\n-      ReliableMessageQueueFactoryImpl.this.add(this.r, data, roles);\n-    }\n-\n-    public Set getQueuingRoles() {\n-      return ReliableMessageQueueFactoryImpl.this.getQueuingRoles(this.r);\n-    }\n-\n-    public boolean roleReady(Role role) {\n-      return ReliableMessageQueueFactoryImpl.this.roleReady(this.r, role);\n-    }\n-\n-    public void destroy() {\n-      ReliableMessageQueueFactoryImpl.this.destroy(this.r);\n-    }\n-\n-    public void close() {\n-      removeQueue(this);\n-    }\n-  }\n-  /**\n-   * Used to organize all the queued data for a region.\n-   */\n-  static protected class QueuedRegionData {\n-    /**\n-     * Maps Role keys to lists of ReliableDistributionData\n-     */\n-    private final HashMap roleMap = new HashMap();\n-\n-    /**\n-     * Adds data in the specified region to be sent to the specified roles\n-     */\n-    protected void add(DistributedRegion r, ReliableDistributionData data, Set roles) {\n-      synchronized (this) {\n-        Iterator it = roles.iterator();\n-        while (it.hasNext()) {\n-          Role role = (Role) it.next();\n-          List l = (List) this.roleMap.get(role);\n-          if (l == null) {\n-            l = new ArrayList();\n-            this.roleMap.put(role, l);\n-          }\n-          l.addAll(data.getOperations());\n-        }\n-      }\n-    }\n-\n-    protected Set getQueuingRoles(DistributedRegion r) {\n-      Set result = null;\n-      synchronized (this) {\n-        Iterator it = this.roleMap.entrySet().iterator();\n-        while (it.hasNext()) {\n-          Map.Entry me = (Map.Entry) it.next();\n-          List l = (List) me.getValue();\n-          if (l != null && !l.isEmpty()) {\n-            // found a role with a non-empty list of operations so add to result\n-            if (result == null) {\n-              result = new HashSet();\n-            }\n-            result.add(me.getKey());\n-          }\n-        }\n-      }\n-      return result;\n-    }\n-\n-    protected boolean roleReady(DistributedRegion r, Role role) {\n-      List l = null;\n-      synchronized (this) {\n-        l = (List) this.roleMap.get(role);\n-      }\n-      if (l != null) {\n-        // @todo darrel: do this in a background thread\n-        while (!l.isEmpty()) {\n-          if (!r.sendQueue(l, role)) {\n-            // Couldn't send the last message so stop and return false\n-            return false;\n-          }\n-        }\n-      }\n-      return true;\n-    }\n-\n-    /**\n-     * Blows away all the data in this object.\n-     */\n-    public void destroy(DistributedRegion r) {\n-      // @todo darrel: nothing needs doing until we use disk\n-    }\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/ReliableMessageQueueFactoryImpl.java",
                "sha": "282a0e1f6f6e98e760857d8ea14505020f8c4c15",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/SendQueueOperation.java",
                "changes": 190,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/SendQueueOperation.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 190,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/SendQueueOperation.java",
                "patch": "@@ -1,190 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-\n-package org.apache.geode.internal.cache;\n-\n-import java.util.*;\n-import java.io.*;\n-import org.apache.geode.*;\n-import org.apache.geode.cache.*;\n-import org.apache.geode.distributed.*;\n-import org.apache.geode.distributed.internal.*;\n-\n-\n-/**\n- * Sends a chunk of queued messages to everyone currently playing a role.\n- *\n- * @since GemFire 5.0\n- *\n- */\n-public class SendQueueOperation {\n-  // private ReplyProcessor21 processor = null;\n-  private DM dm;\n-  private DistributedRegion r;\n-  private List l;\n-  private Role role;\n-\n-  SendQueueOperation(DM dm, DistributedRegion r, List l, Role role) {\n-    this.dm = dm;\n-    this.r = r;\n-    this.l = l;\n-    this.role = role;\n-  }\n-\n-  /**\n-   * Returns true if distribution successful. Also modifies message list by removing messages sent\n-   * to the required role.\n-   */\n-  boolean distribute() {\n-    CacheDistributionAdvisor advisor = this.r.getCacheDistributionAdvisor();\n-    Set recipients = advisor.adviseCacheOpRole(this.role);\n-    if (recipients.isEmpty()) {\n-      return false;\n-    }\n-    ReplyProcessor21 processor = new ReplyProcessor21(this.dm, recipients);\n-    // @todo darrel: make this a reliable one\n-    SendQueueMessage msg = new SendQueueMessage();\n-    msg.setRecipients(recipients);\n-    msg.setRegionPath(this.r.getFullPath());\n-    msg.setProcessorId(processor.getProcessorId());\n-    msg.setOperations(this.l);\n-    dm.putOutgoing(msg);\n-    try {\n-      processor.waitForReplies();\n-    } catch (InterruptedException ex) {\n-      Thread.currentThread().interrupt();\n-      // It's OK to keep going, no significant work below.\n-    } catch (ReplyException ex) {\n-      ex.handleAsUnexpected();\n-    }\n-    if (msg.getSuccessfulRecipients().isEmpty()) {\n-      return false;\n-    }\n-    // @todo darrel: now remove sent items from the list\n-    this.r.getCachePerfStats().incReliableQueuedOps(-l.size());\n-    this.l.clear();\n-    return true;\n-  }\n-\n-  /**\n-   * A batch of queued messages. Once they are processed on the other side an ack is sent.\n-   */\n-  public static final class SendQueueMessage extends SerialDistributionMessage\n-      implements MessageWithReply {\n-    private int processorId;\n-    private String regionPath;\n-    /**\n-     * List of QueuedOperation instances\n-     */\n-    private List ops;\n-\n-    @Override\n-    public int getProcessorId() {\n-      return this.processorId;\n-    }\n-\n-    public void setProcessorId(int id) {\n-      this.processorId = id;\n-    }\n-\n-    public String getRegionPath() {\n-      return this.regionPath;\n-    }\n-\n-    public void setRegionPath(String rp) {\n-      this.regionPath = rp;\n-    }\n-\n-    public void setOperations(List l) {\n-      this.ops = l;\n-    }\n-\n-    @Override\n-    protected void process(DistributionManager dm) {\n-      ReplyException rex = null;\n-      boolean ignored = false;\n-      try {\n-        GemFireCacheImpl gfc = (GemFireCacheImpl) CacheFactory.getInstance(dm.getSystem());\n-        final LocalRegion lclRgn = gfc.getRegionByPathForProcessing(this.regionPath);\n-        if (lclRgn != null) {\n-          lclRgn.waitOnInitialization();\n-          final long lastMod = gfc.cacheTimeMillis();\n-          Iterator it = this.ops.iterator();\n-          while (it.hasNext()) {\n-            QueuedOperation op = (QueuedOperation) it.next();\n-            op.process(lclRgn, getSender(), lastMod);\n-          }\n-        } else {\n-          ignored = true;\n-        }\n-      } catch (RegionDestroyedException e) {\n-        ignored = true;\n-      } catch (CancelException e) {\n-        ignored = true;\n-      } finally {\n-        ReplyMessage.send(getSender(), this.processorId, rex, dm, ignored, false, false);\n-      }\n-    }\n-\n-    public int getDSFID() {\n-      return SEND_QUEUE_MESSAGE;\n-    }\n-\n-    @Override\n-    public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n-      super.fromData(in);\n-      this.regionPath = DataSerializer.readString(in);\n-      this.processorId = in.readInt();\n-      {\n-        int opCount = in.readInt();\n-        QueuedOperation[] ops = new QueuedOperation[opCount];\n-        for (int i = 0; i < opCount; i++) {\n-          ops[i] = QueuedOperation.createFromData(in);\n-        }\n-        this.ops = Arrays.asList(ops);\n-      }\n-    }\n-\n-    @Override\n-    public void toData(DataOutput out) throws IOException {\n-      super.toData(out);\n-      DataSerializer.writeString(this.regionPath, out);\n-      out.writeInt(this.processorId);\n-      {\n-        int opCount = this.ops.size();\n-        out.writeInt(opCount);\n-        for (int i = 0; i < opCount; i++) {\n-          QueuedOperation op = (QueuedOperation) this.ops.get(i);\n-          op.toData(out);\n-        }\n-      }\n-    }\n-\n-    @Override\n-    public String toString() {\n-      StringBuffer buff = new StringBuffer();\n-      buff.append(getClass().getName());\n-      buff.append(\"(region path='\"); // make sure this is the first one\n-      buff.append(this.regionPath);\n-      buff.append(\"'\");\n-      buff.append(\"; processorId=\");\n-      buff.append(this.processorId);\n-      buff.append(\"; queuedOps=\");\n-      buff.append(this.ops.size());\n-      buff.append(\")\");\n-      return buff.toString();\n-    }\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/main/java/org/apache/geode/internal/cache/SendQueueOperation.java",
                "sha": "a72dee97457d40c4b87ce6983cbbd12eed1c3828",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/TXCommitMessage.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/TXCommitMessage.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 40,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/TXCommitMessage.java",
                "patch": "@@ -526,19 +526,7 @@ private void checkDistributionReliability(Map distMap, CommitReplyProcessor proc\n       successfulRecipients.removeAll(regionDestroyedMembers);\n \n       try {\n-        ReliableDistributionData rdd = new ReliableDistributionData() {\n-          // public Set getSuccessfulRecipients(ReliableReplyProcessor21 processor) {\n-          // return successfulRecipients;\n-          // }\n-          public int getOperationCount() {\n-            return rc.getOperationCount();\n-          }\n-\n-          public List getOperations() {\n-            return rc.getOperations();\n-          }\n-        };\n-        rc.r.handleReliableDistribution(rdd, successfulRecipients);\n+        rc.r.handleReliableDistribution(successfulRecipients);\n       } catch (RegionDistributionException e) {\n         if (regionDistributionExceptions == Collections.EMPTY_SET) {\n           regionDistributionExceptions = new HashSet();\n@@ -1408,19 +1396,6 @@ boolean isEmpty() {\n       return this.opKeys == null;\n     }\n \n-    /**\n-     * Returns the number of operations this region commit will do\n-     * \n-     * @since GemFire 5.0\n-     */\n-    int getOperationCount() {\n-      int result = 0;\n-      if (!isEmpty()) {\n-        result = this.opKeys.size();\n-      }\n-      return result;\n-    }\n-\n     boolean needsAck() {\n       return this.r.getScope().isDistributedAck();\n     }\n@@ -1481,20 +1456,6 @@ public String toString() {\n       return result.toString();\n     }\n \n-    /**\n-     * Returns a list of QueuedOperation instances for reliable distribution\n-     * \n-     * @since GemFire 5.0\n-     */\n-    List getOperations() {\n-      QueuedOperation[] ops = new QueuedOperation[getOperationCount()];\n-      for (int i = 0; i < ops.length; i++) {\n-        TXEntryState es = (TXEntryState) this.opEntries.get(i);\n-        ops[i] = es.toFarSideQueuedOp(this.opKeys.get(i));\n-      }\n-      return Arrays.asList(ops);\n-    }\n-\n     private void basicToData(DataOutput out) throws IOException {\n       if (this.r != null) {\n         DataSerializer.writeString(this.r.getFullPath(), out);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/TXCommitMessage.java",
                "sha": "7c2a3e3722213e3a75276a8559c81ec8832f6cd0",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/TombstoneService.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/TombstoneService.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/TombstoneService.java",
                "patch": "@@ -550,7 +550,7 @@ private void expireBatch() {\n             DistributedRegion tr = (DistributedRegion) t.region;\n             boolean tombstoneWasStillInRegionMap =\n                 tr.getRegionMap().removeTombstone(t.entry, t, false, true);\n-            if (tombstoneWasStillInRegionMap && tr.isUsedForPartitionedRegionBucket()) {\n+            if (tombstoneWasStillInRegionMap && hasToTrackKeysForClients(tr)) {\n               Set<Object> keys = reapedKeys.get(tr);\n               if (keys.isEmpty()) {\n                 keys = new HashSet<Object>();\n@@ -589,6 +589,15 @@ public void run() {\n       } // sync on deltaGIILock\n     }\n \n+    /**\n+     * Returns true if keys needs to be tracked for clients registering interests on PR.\n+     */\n+    private boolean hasToTrackKeysForClients(DistributedRegion r) {\n+      return r.isUsedForPartitionedRegionBucket()\n+          && ((r.getFilterProfile() != null && r.getFilterProfile().hasInterest())\n+              || r.getPartitionedRegion().getRegionAdvisor().hasPRServerWithInterest());\n+    }\n+\n     @Override\n     protected void checkExpiredTombstoneGC() {\n       if (shouldCallExpireBatch()) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/TombstoneService.java",
                "sha": "0df27c88f2523edd012ba0ea0472c5a3d4ce6976",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateEntryVersionOperation.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateEntryVersionOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/UpdateEntryVersionOperation.java",
                "patch": "@@ -103,12 +103,6 @@ protected InternalCacheEvent createEvent(DistributedRegion rgn) throws EntryNotF\n       return ev;\n     }\n \n-    @Override\n-    public List getOperations() {\n-      return Collections.singletonList(new QueuedOperation(getOperation(), this.key, null, null,\n-          DistributedCacheOperation.DESERIALIZATION_POLICY_NONE, this.callbackArg));\n-    }\n-\n     @Override\n     protected void appendFields(StringBuilder buff) {\n       super.appendFields(buff);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateEntryVersionOperation.java",
                "sha": "f82f0ce5d92420f27ba8c260069221ee6605254c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateOperation.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/UpdateOperation.java",
                "patch": "@@ -445,19 +445,6 @@ private void setDeltaFlag(DistributedRegion region) {\n       }\n     }\n \n-    @Override\n-    public List getOperations() {\n-      byte[] valueBytes = null;\n-      Object valueObj = null;\n-      if (this.newValueObj != null) {\n-        valueBytes = EntryEventImpl.serialize(this.newValueObj);\n-      } else {\n-        valueBytes = this.newValue;\n-      }\n-      return Collections.singletonList(new QueuedOperation(getOperation(), this.key, valueBytes,\n-          valueObj, this.deserializationPolicy, this.callbackArg));\n-    }\n-\n     public boolean hasBridgeContext() {\n       if (this.event != null) {\n         return this.event.getContext() != null;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/UpdateOperation.java",
                "sha": "1afae86d4822bfbdb345c8fa2fb946b20d2b1c8c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/PRTombstoneMessage.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/PRTombstoneMessage.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/PRTombstoneMessage.java",
                "patch": "@@ -68,7 +68,7 @@ public PRTombstoneMessage() {}\n \n   public static void send(BucketRegion r, final Set<Object> keys, EventID eventID) {\n     Set<InternalDistributedMember> recipients =\n-        r.getPartitionedRegion().getRegionAdvisor().adviseAllPRNodes();\n+        r.getPartitionedRegion().getRegionAdvisor().adviseAllServersWithInterest();\n     recipients.removeAll(r.getDistributionAdvisor().adviseReplicates());\n     if (recipients.size() == 0) {\n       return;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/PRTombstoneMessage.java",
                "sha": "0e6b707f1e1b5a7e1eab3203bca6d8e019cd7ec2",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/RegionAdvisor.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/RegionAdvisor.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/RegionAdvisor.java",
                "patch": "@@ -1004,6 +1004,28 @@ public boolean include(Profile profile) {\n     });\n   }\n \n+  public Set adviseAllServersWithInterest() {\n+    return adviseFilter(new Filter() {\n+      public boolean include(Profile profile) {\n+        CacheProfile prof = (CacheProfile) profile;\n+        return prof.hasCacheServer && prof.filterProfile != null\n+            && prof.filterProfile.hasInterest();\n+      }\n+    });\n+  }\n+\n+  private static final Filter prServerWithInterestFilter = new Filter() {\n+    public boolean include(Profile profile) {\n+      CacheProfile prof = (CacheProfile) profile;\n+      return prof.isPartitioned && prof.hasCacheServer && prof.filterProfile != null\n+          && prof.filterProfile.hasInterest();\n+    }\n+  };\n+\n+  public boolean hasPRServerWithInterest() {\n+    return satisfiesFilter(prServerWithInterestFilter);\n+  }\n+\n   /**\n    * return the set of all members who must receive operation notifications\n    * ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/RegionAdvisor.java",
                "sha": "8f4c65c11fcbc5f4c26f55bc02353cb75a4494c5",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/BackupManager.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/BackupManager.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 21,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/persistence/BackupManager.java",
                "patch": "@@ -14,14 +14,14 @@\n  */\n package org.apache.geode.internal.cache.persistence;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.InternalGemFireError;\n import org.apache.geode.cache.persistence.PersistentID;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.distributed.internal.DM;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.MembershipListener;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.JarClassLoader;\n import org.apache.geode.internal.JarDeployer;\n import org.apache.geode.internal.cache.DiskStoreImpl;\n@@ -30,10 +30,18 @@\n \n import java.io.File;\n import java.io.FileOutputStream;\n+import java.io.FilenameFilter;\n import java.io.IOException;\n import java.net.URL;\n-import java.util.*;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Set;\n import java.util.concurrent.CountDownLatch;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n /**\n  * This class manages the state an logic to backup a single cache.\n@@ -108,20 +116,19 @@ private File findBaselineForThisMember(File baselineParentDir) {\n      * Find the first matching DiskStoreId directory for this member.\n      */\n     for (DiskStoreImpl diskStore : cache.listDiskStoresIncludingRegionOwned()) {\n-      baselineDir = FileUtil.find(baselineParentDir, \".*\" + diskStore.getBackupDirName() + \"$\");\n-      if (null != baselineDir) {\n-        break;\n-      }\n-    }\n+      File[] matchingFiles = baselineParentDir.listFiles(new FilenameFilter() {\n+        Pattern pattern = Pattern.compile(\".*\" + diskStore.getBackupDirName() + \"$\");\n \n-    /*\n-     * We found it? Good. Set this member's baseline to the backed up disk store's member dir (two\n-     * levels up).\n-     */\n-    if (null != baselineDir) {\n-      baselineDir = baselineDir.getParentFile().getParentFile();\n+        public boolean accept(File dir, String name) {\n+          Matcher m = pattern.matcher(name);\n+          return m.find();\n+        }\n+      });\n+      // We found it? Good. Set this member's baseline to the backed up disk store's member dir (two\n+      // levels up).\n+      if (null != matchingFiles && matchingFiles.length > 0)\n+        baselineDir = matchingFiles[0].getParentFile().getParentFile();\n     }\n-\n     return baselineDir;\n   }\n \n@@ -233,19 +240,19 @@ public void abort() {\n \n   private void backupConfigFiles(RestoreScript restoreScript, File backupDir) throws IOException {\n     File configBackupDir = new File(backupDir, CONFIG);\n-    FileUtil.mkdirs(configBackupDir);\n+    configBackupDir.mkdirs();\n     URL url = cache.getCacheXmlURL();\n     if (url != null) {\n       File cacheXMLBackup =\n           new File(configBackupDir, DistributionConfig.DEFAULT_CACHE_XML_FILE.getName());\n-      FileUtil.copy(url, cacheXMLBackup);\n+      FileUtils.copyFile(new File(cache.getCacheXmlURL().getFile()), cacheXMLBackup);\n     }\n \n-    URL propertyURL = DistributedSystem.getPropertyFileURL();\n+    URL propertyURL = DistributedSystem.getPropertiesFileURL();\n     if (propertyURL != null) {\n       File propertyBackup =\n           new File(configBackupDir, DistributionConfig.GEMFIRE_PREFIX + \"properties\");\n-      FileUtil.copy(propertyURL, propertyBackup);\n+      FileUtils.copyFile(new File(DistributedSystem.getPropertiesFile()), propertyBackup);\n     }\n \n     // TODO sbawaska: should the gfsecurity.properties file be backed up?\n@@ -261,7 +268,11 @@ private void backupUserFiles(RestoreScript restoreScript, File backupDir) throws\n       if (original.exists()) {\n         original = original.getAbsoluteFile();\n         File dest = new File(userBackupDir, original.getName());\n-        FileUtil.copy(original, dest);\n+        if (original.isDirectory()) {\n+          FileUtils.copyDirectory(original, dest);\n+        } else {\n+          FileUtils.copyFile(original, dest);\n+        }\n         restoreScript.addExistenceTest(original);\n         restoreScript.addFile(original, dest);\n       }\n@@ -296,7 +307,11 @@ private void backupDeployedJars(RestoreScript restoreScript, File backupDir) thr\n         for (JarClassLoader loader : jarList) {\n           File source = new File(loader.getFileCanonicalPath());\n           File dest = new File(userBackupDir, source.getName());\n-          FileUtil.copy(source, dest);\n+          if (source.isDirectory()) {\n+            FileUtils.copyDirectory(source, dest);\n+          } else {\n+            FileUtils.copyFile(source, dest);\n+          }\n           restoreScript.addFile(source, dest);\n         }\n       }\n@@ -325,7 +340,7 @@ private void createBackupDir(File backupDir) throws IOException {\n       throw new IOException(\"Backup directory \" + backupDir.getAbsolutePath() + \" already exists.\");\n     }\n \n-    if (!FileUtil.mkdirs(backupDir)) {\n+    if (!backupDir.mkdirs()) {\n       throw new IOException(\"Could not create directory: \" + backupDir);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/BackupManager.java",
                "sha": "d052551d85e5b01b16255160f76795e829a14429",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/RestoreScript.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/RestoreScript.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/persistence/RestoreScript.java",
                "patch": "@@ -23,8 +23,6 @@\n import java.util.List;\n import java.util.Map;\n \n-import org.apache.geode.internal.FileUtil;\n-\n /**\n  * This class is used to automatically generate a restore script for a backup. It keeps a list of\n  * files that were backed up, and a list of files that we should test for to avoid overriding when\n@@ -100,7 +98,7 @@ private void generateScript(File outputDir, File outputFile, ScriptGenerator osG\n       for (Map.Entry<File, File> entry : backedUpFiles.entrySet()) {\n         File backup = entry.getKey();\n         boolean backupHasFiles = backup.isDirectory() && backup.list().length != 0;\n-        backup = FileUtil.removeParent(outputDir, backup);\n+        backup = outputDir.toPath().relativize(backup.toPath()).toFile();\n         File original = entry.getValue();\n         if (original.isDirectory()) {\n           osGenerator.writeCopyDirectoryContents(writer, backup, original, backupHasFiles);\n@@ -136,7 +134,7 @@ private void generateScript(File outputDir, File outputFile, ScriptGenerator osG\n   private boolean isWindows() {\n     String os = System.getProperty(\"os.name\");\n     if (os != null) {\n-      if (os.indexOf(\"Windows\") != -1) {\n+      if (os.contains(\"Windows\")) {\n         return true;\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/persistence/RestoreScript.java",
                "sha": "3076e04dc06537e276d711734fe09455370f5165",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/BaseCommand.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/BaseCommand.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/BaseCommand.java",
                "patch": "@@ -1074,7 +1074,7 @@ private static void handleKVSingleton(LocalRegion region, Object entryKey,\n \n     if (region != null) {\n       if (region.containsKey(entryKey) || region.containsTombstone(entryKey)) {\n-        VersionTagHolder versionHolder = new VersionTagHolder();\n+        VersionTagHolder versionHolder = createVersionTagHolder();\n         ClientProxyMembershipID id = servConn == null ? null : servConn.getProxyID();\n         // From Get70.getValueAndIsObject()\n         Object data = region.get(entryKey, null, true, true, true, id, versionHolder, true);\n@@ -1161,7 +1161,7 @@ private static void handleKVAllKeys(LocalRegion region, String regex, boolean se\n       }\n \n       for (Object key : region.keySet(true)) {\n-        VersionTagHolder versionHolder = new VersionTagHolder();\n+        VersionTagHolder versionHolder = createVersionTagHolder();\n         if (keyPattern != null) {\n           if (!(key instanceof String)) {\n             // key is not a String, cannot apply regex to this entry\n@@ -1263,12 +1263,10 @@ private static void updateValues(VersionedObjectList values, Object key, Object\n   public static void appendNewRegisterInterestResponseChunkFromLocal(LocalRegion region,\n       VersionedObjectList values, Object riKeys, Set keySet, ServerConnection servConn)\n       throws IOException {\n-    Object key = null;\n-    VersionTagHolder versionHolder = null;\n     ClientProxyMembershipID requestingClient = servConn == null ? null : servConn.getProxyID();\n     for (Iterator it = keySet.iterator(); it.hasNext();) {\n-      key = it.next();\n-      versionHolder = new VersionTagHolder();\n+      Object key = it.next();\n+      VersionTagHolder versionHolder = createVersionTagHolder();\n \n       Object value = region.get(key, null, true, true, true, requestingClient, versionHolder, true);\n \n@@ -1454,7 +1452,7 @@ private static void handleKVList(final LocalRegion region, final List keyList,\n       for (Iterator it = keyList.iterator(); it.hasNext();) {\n         Object key = it.next();\n         if (region.containsKey(key) || region.containsTombstone(key)) {\n-          VersionTagHolder versionHolder = new VersionTagHolder();\n+          VersionTagHolder versionHolder = createVersionTagHolder();\n \n           ClientProxyMembershipID id = servConn == null ? null : servConn.getProxyID();\n           data = region.get(key, null, true, true, true, id, versionHolder, true);\n@@ -1475,6 +1473,12 @@ private static void handleKVList(final LocalRegion region, final List keyList,\n     sendNewRegisterInterestResponseChunk(region, keyList, values, true, servConn);\n   }\n \n+  private static VersionTagHolder createVersionTagHolder() {\n+    VersionTagHolder versionHolder = new VersionTagHolder();\n+    versionHolder.setOperation(Operation.GET_FOR_REGISTER_INTEREST);\n+    return versionHolder;\n+  }\n+\n   /**\n    * Append an interest response\n    *",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/BaseCommand.java",
                "sha": "d217672b7b9f0affbd262740143152d8e900967e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/wan/serial/BatchDestroyOperation.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/wan/serial/BatchDestroyOperation.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/wan/serial/BatchDestroyOperation.java",
                "patch": "@@ -37,7 +37,6 @@\n import org.apache.geode.internal.cache.EntryEventImpl;\n import org.apache.geode.internal.cache.EventID;\n import org.apache.geode.internal.cache.InternalCacheEvent;\n-import org.apache.geode.internal.cache.QueuedOperation;\n import org.apache.geode.internal.cache.RegionQueue;\n import org.apache.geode.internal.i18n.LocalizedStrings;\n import org.apache.geode.internal.logging.LogService;\n@@ -209,12 +208,6 @@ public void toData(DataOutput out) throws IOException {\n       DataSerializer.writeLong(this.event.getTailKey(), out);\n     }\n \n-    @Override\n-    public List getOperations() {\n-      return Collections.singletonList(new QueuedOperation(getOperation(), this.key, null, null,\n-          DistributedCacheOperation.DESERIALIZATION_POLICY_NONE, this.callbackArg));\n-    }\n-\n     @Override\n     public ConflationKey getConflationKey() {\n       if (!super.regionAllowsConflation || getProcessorId() != 0) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/cache/wan/serial/BatchDestroyOperation.java",
                "sha": "a368b60afb0f1bbcf73e550fd1257266d24f9515",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/i18n/LocalizedStrings.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/i18n/LocalizedStrings.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/i18n/LocalizedStrings.java",
                "patch": "@@ -3604,12 +3604,6 @@\n   public static final StringId RegisterInterest_CACHECLIENTPROXY_FOR_THIS_CLIENT_IS_NO_LONGER_ON_THE_SERVER_SO_REGISTERINTEREST_OPERATION_IS_UNSUCCESSFUL =\n       new StringId(3176,\n           \"CacheClientProxy for this client is no longer on the server , so registerInterest operation is unsuccessful\");\n-  public static final StringId ReliableMessageQueueFactoryImpl_REGIONS_WITH_MESSAGE_QUEUING_ALREADY_EXIST =\n-      new StringId(3177, \"Regions with message queuing already exist\");\n-  public static final StringId ReliableMessageQueueFactoryImpl_RELIABLE_MESSAGE_QUEUE_IS_CLOSED =\n-      new StringId(3178, \"reliable message queue is closed\");\n-  public static final StringId ReliableMessageQueueFactoryImpl_UNEXPECTED_QUEUEDREGIONDATA_0_FOR_REGION_1 =\n-      new StringId(3179, \"unexpected QueuedRegionData  {0}  for region  {1}\");\n   public static final StringId RemoteBridgeServer_A_REMOTE_BRIDGESERVER_CANNOT_BE_STARTED =\n       new StringId(3180, \"A remote BridgeServer cannot be started.\");\n   public static final StringId RemoteBridgeServer_A_REMOTE_BRIDGESERVER_CANNOT_BE_STOPPED =\n@@ -7674,6 +7668,10 @@\n       new StringId(6650,\n           \"Caught the following exception attempting waitUntilFlushed and will return:\");\n \n+  public static final StringId LuceneService_INDEX_0_NOT_FOUND_IN_REGION_1 =\n+      new StringId(6651, \"Lucene index {0} was not found in region {1}.\");\n+  public static final StringId LuceneService_DESTROYED_INDEX_0_FROM_REGION_1 =\n+      new StringId(6652, \"Destroyed Lucene index {0} from region {1}.\");\n   /** Testing strings, messageId 90000-99999 **/\n \n   /**",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/i18n/LocalizedStrings.java",
                "sha": "47ae0c51058cc9693b2aa8e4bbb15a79d5315f93",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 20,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "patch": "@@ -15,11 +15,9 @@\n package org.apache.geode.internal.io;\n \n import org.apache.geode.i18n.LogWriterI18n;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.i18n.LocalizedStrings;\n \n import java.io.File;\n-import java.io.FilenameFilter;\n import java.util.Arrays;\n import java.util.Comparator;\n import java.util.regex.Pattern;\n@@ -42,7 +40,7 @@ public int calcNextChildId(final File file, final int mainId) {\n     File dir = getParentFile(file.getAbsoluteFile());\n     int endIdx1 = file.getName().indexOf('-');\n     int endIdx2 = file.getName().lastIndexOf('.');\n-    String baseName = file.getName();\n+    String baseName;\n     if (endIdx1 != -1) {\n       baseName = file.getName().substring(0, endIdx1);\n     } else {\n@@ -206,7 +204,11 @@ public File getParentFile(final File file) {\n     return tmp;\n   }\n \n-  private Pattern getFilePattern(String name) {\n+  Pattern getFilePattern(String name) {\n+    if (name == null || \"\".equals(name.trim())) {\n+      throw new IllegalArgumentException(\"Name must not be empty\");\n+    }\n+\n     int extIdx = name.lastIndexOf('.');\n     String ext = \"\";\n     if (extIdx != -1) {\n@@ -218,26 +220,13 @@ private Pattern getFilePattern(String name) {\n   }\n \n   private File[] findChildren(final File dir, final Pattern pattern) {\n-    return FileUtil.listFiles(dir, new FilenameFilter() {\n-      @Override\n-      public boolean accept(File dir, String name) {\n-        return pattern.matcher(name).matches();\n-      }\n-    });\n+    return dir.listFiles((dir1, name) -> pattern.matcher(name).matches());\n   }\n \n   private File[] findChildrenExcept(final File dir, final Pattern pattern, final File exception) {\n     final String exceptionName = (exception == null) ? null : exception.getName();\n-    return FileUtil.listFiles(dir, new FilenameFilter() {\n-      @Override\n-      public boolean accept(File dir, String name) {\n-        if (name.equals(exceptionName)) {\n-          return false;\n-        } else {\n-          return pattern.matcher(name).matches();\n-        }\n-      }\n-    });\n+    return dir\n+        .listFiles((dir1, name) -> !name.equals(exceptionName) && pattern.matcher(name).matches());\n   }\n \n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "sha": "f814aebb8717c3a53c72d4cdf55b81d72e0fbed5",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/logging/MergeLogFiles.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/logging/MergeLogFiles.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 14,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/logging/MergeLogFiles.java",
                "patch": "@@ -14,6 +14,10 @@\n  */\n package org.apache.geode.internal.logging;\n \n+import org.apache.geode.SystemFailure;\n+import org.apache.geode.internal.Assert;\n+import org.apache.geode.internal.i18n.LocalizedStrings;\n+\n import java.io.BufferedReader;\n import java.io.File;\n import java.io.FileInputStream;\n@@ -37,11 +41,6 @@\n import java.util.regex.Pattern;\n import java.util.zip.GZIPInputStream;\n \n-import org.apache.geode.SystemFailure;\n-import org.apache.geode.internal.Assert;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.internal.i18n.LocalizedStrings;\n-\n /**\n  * This program merges entries from multiple GemFire log files (those written using a\n  * {@link org.apache.geode.i18n.LogWriterI18n} together, sorting them by their timestamp. Note that\n@@ -188,17 +187,19 @@ private static void usage(String s) {\n    * @param dirName directory to search\n    * @return all of the .log files found (Files)\n    */\n-  static ArrayList getLogFiles(String dirName) {\n-    ArrayList result = new ArrayList();\n+  static ArrayList<File> getLogFiles(String dirName) {\n+    ArrayList<File> result = new ArrayList<>();\n \n     File dir = new File(dirName);\n-    File names[] = FileUtil.listFiles(dir);\n-    for (int i = 0; i < names.length; i++) {\n-      String n = names[i].getAbsolutePath();\n-      if (n.endsWith(\".log\") || n.endsWith(\".log.gz\")) {\n-        result.add(names[i]);\n-      }\n-    } // for\n+    File names[] = dir.listFiles();\n+    if (names != null) {\n+      for (final File name : names) {\n+        String n = name.getAbsolutePath();\n+        if (n.endsWith(\".log\") || n.endsWith(\".log.gz\")) {\n+          result.add(name);\n+        }\n+      } // for\n+    }\n     return result;\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/logging/MergeLogFiles.java",
                "sha": "27f2116356581fe19394fd8d675fd3c9d8b51c11",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/process/ProcessUtils.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/process/ProcessUtils.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/process/ProcessUtils.java",
                "patch": "@@ -145,7 +145,7 @@ private static InternalProcessUtils initializeInternalProcessUtils() {\n     } catch (LinkageError e) {\n       // fall through\n     } catch (PidUnavailableException e) {\n-      // fall through TODO:KIRK log warning??\n+      // fall through (log warning??)\n     } catch (UnsupportedOperationException e) {\n       // fall through\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/process/ProcessUtils.java",
                "sha": "f15489f757bee3bdc806f90e2ef84b0111c35a93",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveHandler.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveHandler.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveHandler.java",
                "patch": "@@ -446,7 +446,7 @@ private void changeArchiveFile(File newFile, boolean resetHandler, long nanosTim\n    * @return the modified archive file name to use; it is modified by applying mainArchiveId and\n    *         archiveId to the name for supporting file rolling\n    */\n-  private File getRollingArchiveName(File archive, boolean archiveClosed) {\n+  File getRollingArchiveName(File archive, boolean archiveClosed) {\n     if (mainArchiveId != -1) {\n       // leave mainArchiveId as is. Bump archiveId.\n     } else {\n@@ -538,7 +538,7 @@ private File getRollingArchiveName(File archive, boolean archiveClosed) {\n     return result;\n   }\n \n-  private void initMainArchiveId(File archive) {\n+  void initMainArchiveId(File archive) {\n     if (mainArchiveId != -1) {\n       // already initialized\n       return;\n@@ -598,7 +598,7 @@ private void initMainArchiveId(File archive) {\n    * @return the modified archive file name to use; it is modified by applying the next main id if\n    *         any files in the dir already have a main id in the file name\n    */\n-  private File getRenameArchiveName(File archive) {\n+  File getRenameArchiveName(File archive) {\n     File dir = archive.getAbsoluteFile().getParentFile();\n     int previousMainId = this.rollingFileHandler.calcNextMainId(dir, false);\n     if (previousMainId == 0) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveHandler.java",
                "sha": "03b0f898ad30b6b088108fa0187b0a5a750ed6dc",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveReader.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveReader.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveReader.java",
                "patch": "@@ -3230,8 +3230,8 @@ private void readResourceInstanceCreateToken(boolean initialize) throws IOExcept\n       }\n       ResourceType type = resourceTypeTable[resourceTypeId];\n       if (type == null) {\n-        throw new IllegalStateException(\n-            \"ResourceType is missing for resourceTypeId \" + resourceTypeId);\n+        throw new IllegalStateException(\"ResourceType is missing for resourceTypeId \"\n+            + resourceTypeId + \", resourceName \" + name);\n       }\n       boolean loadInstance = loadInstance(name, id, resourceTypeTable[resourceTypeId]);\n       resourceInstTable[resourceInstId] = new ResourceInst(this, resourceInstId, name, id,",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/internal/statistics/StatArchiveReader.java",
                "sha": "65e4370eb08a3a5c5c86933e577b46627e044817",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/CliUtil.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/CliUtil.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/CliUtil.java",
                "patch": "@@ -440,11 +440,6 @@ public static DeflaterInflaterData compressBytes(byte[] input) {\n \n       compressedDataLength = compresser.deflate(buffer);\n       totalCompressedDataLength += compressedDataLength;\n-      // System.out.println(compressedDataLength);\n-      // System.out.println(\"uc: b \"+buffer.length);\n-      // System.out.println(\"uc: r \"+result.length);\n-      // System.out.println(\"uc: nr \"+newResult.length);\n-      // System.out.println();\n       System.arraycopy(buffer, 0, newResult, result.length, buffer.length);\n       result = newResult;\n     } while (compressedDataLength != 0);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/CliUtil.java",
                "sha": "8cd098d9719774c49efcf28d1d5ecdcd345687fc",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/json/GfJsonObject.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/json/GfJsonObject.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 36,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/json/GfJsonObject.java",
                "patch": "@@ -49,22 +49,6 @@ public GfJsonObject(Object bean, boolean checkCyclicDep) {\n       this.jsonObject = (JSONObject) bean;\n     } else {\n       this.jsonObject = new JSONObject(bean);\n-      // If we want to print out the values of the primitive arrays and report back\n-      // Class klass = bean.getClass();\n-      // if(klass.isArray() && klass.getComponentType().isPrimitive()){\n-      // String str = \"\";\n-      // int length = Array.getLength(bean);\n-      // for (int i = 0; i < length; i++) {\n-      // if(i==0)\n-      // str += (Array.get(bean, i));\n-      // else\n-      // str +=(\",\"+Array.get(bean, i));\n-      // }\n-      // try {\n-      // this.jsonObject.put(\"Value\", str);\n-      // } catch (JSONException ignore) {\n-      // }\n-      // }\n     }\n     if (checkCyclicDep) {\n       JSONObject.cyclicDepChkEnabled.set(false);\n@@ -88,10 +72,6 @@ public GfJsonObject(Object bean) {\n     }\n   }\n \n-  public GfJsonObject(Object bean, String[] paramNames) {\n-    this.jsonObject = new JSONObject(bean, paramNames);\n-  }\n-\n   /**\n    * \n    * @param source A string beginning with { (left brace) and ending with } (right brace).\n@@ -253,22 +233,6 @@ public GfJsonObject putAsJSONObject(String key, Object value) throws GfJsonExcep\n     return this;\n   }\n \n-  /**\n-   * \n-   * @param key\n-   * @param value\n-   * @return this GfJsonObject\n-   * @throws GfJsonException if the key is a duplicate\n-   */\n-  public GfJsonObject putOnce(String key, Object value) throws GfJsonException {\n-    try {\n-      jsonObject.putOnce(key, value);\n-    } catch (JSONException e) {\n-      throw new GfJsonException(e.getMessage());\n-    }\n-    return this;\n-  }\n-\n   /**\n    * \n    * @param key",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/json/GfJsonObject.java",
                "sha": "66e9f799a0c1233686f88261bcce95da1b0959c6",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/parser/ParserUtils.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/parser/ParserUtils.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/parser/ParserUtils.java",
                "patch": "@@ -93,7 +93,7 @@\n \n       // Remove quotes from the beginning and end of split strings\n       for (int i = 0; i < split.length; i++) {\n-        if ((split[i].endsWith(\"\\\"\") && split[i].endsWith(\"\\\"\"))\n+        if ((split[i].startsWith(\"\\\"\") && split[i].endsWith(\"\\\"\"))\n             || (split[i].startsWith(\"\\'\") && split[i].endsWith(\"\\'\"))) {\n           split[i] = split[i].substring(1, split[i].length() - 1);\n         }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/parser/ParserUtils.java",
                "sha": "80f12867b7c0144ef9cb5aa5d5e7cc4f5c36b9f1",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/AbstractResultData.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/AbstractResultData.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 35,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/result/AbstractResultData.java",
                "patch": "@@ -20,7 +20,10 @@\n import java.io.FileOutputStream;\n import java.io.FileWriter;\n import java.io.IOException;\n+import java.io.UnsupportedEncodingException;\n+import java.nio.charset.Charset;\n import java.text.MessageFormat;\n+import java.util.Base64;\n import java.util.zip.DataFormatException;\n \n import org.apache.geode.management.cli.Result.Status;\n@@ -151,26 +154,10 @@ public ResultData addAsFile(String fileName, byte[] data, int fileType, String m\n     if (addTimeStampToName) {\n       fileName = addTimeStampBeforeLastDot(fileName);\n     }\n-    return addAsFile(fileName.getBytes(), bytes, fileType, message);\n+    return addAsFile(fileName, bytes, fileType, message);\n   }\n \n-  public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-      boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-    byte[][] filesToBytes = CliUtil.filesToBytes(new String[] {filePath});\n-\n-    byte[] bytes = filesToBytes[0];\n-    if (addTimeStampToName) {\n-      String fileName = new String(filesToBytes[0]);\n-      fileName = addTimeStampBeforeLastDot(fileName);\n-      bytes = fileName.getBytes();\n-    }\n-    return addAsFile(bytes, filesToBytes[1], fileType, message);\n-  }\n-\n-  private ResultData addAsFile(byte[] fileName, byte[] data, int fileType, String message) {\n-    // System.out.println(\"fileType :: \"+fileType);\n-    // System.out.println(\"FILE_TYPE_BINARY :: \"+FILE_TYPE_BINARY);\n-    // System.out.println(\"FILE_TYPE_TEXT :: \"+FILE_TYPE_TEXT);\n+  private ResultData addAsFile(String fileName, byte[] data, int fileType, String message) {\n     if (fileType != FILE_TYPE_BINARY && fileType != FILE_TYPE_TEXT) {\n       throw new IllegalArgumentException(\"Unsupported file type is specified.\");\n     }\n@@ -186,14 +173,13 @@ private ResultData addAsFile(byte[] fileName, byte[] data, int fileType, String\n \n       sectionData.put(FILE_NAME_FIELD, fileName);\n       sectionData.put(FILE_TYPE_FIELD, fileType);\n-      sectionData.put(FILE_MESSAGE, message.getBytes());\n-      sectionData.putAsJSONObject(FILE_DATA_FIELD, CliUtil.compressBytes(data));\n-      // System.out.println(data);\n-      // sectionData.put(FILE_DATA_FIELD, Base64.encodeBytes(data, Base64.GZIP));\n+      sectionData.put(FILE_MESSAGE, message);\n+      DeflaterInflaterData deflaterInflaterData = CliUtil.compressBytes(data);\n+      sectionData.put(FILE_DATA_FIELD,\n+          Base64.getEncoder().encodeToString(deflaterInflaterData.getData()));\n+      sectionData.put(DATA_LENGTH_FIELD, deflaterInflaterData.getDataLength());\n     } catch (GfJsonException e) {\n       throw new ResultDataException(e.getMessage());\n-      // } catch (IOException e) {\n-      // e.printStackTrace();\n     }\n     return this;\n   }\n@@ -223,29 +209,30 @@ public static void readFileDataAndDump(GfJsonArray byteDataArray, String directo\n \n       // build file name\n       byte[] fileNameBytes = null;\n+      String fileName = null;\n       GfJsonArray fileNameJsonBytes = object.getJSONArray(FILE_NAME_FIELD);\n       if (fileNameJsonBytes != null) { // if in gfsh\n         fileNameBytes = GfJsonArray.toByteArray(fileNameJsonBytes);\n+        fileName = new String(fileNameBytes);\n       } else { // if on member\n-        fileNameBytes = (byte[]) object.get(FILE_NAME_FIELD);\n+        fileName = (String) object.get(FILE_NAME_FIELD);\n       }\n-      String fileName = new String(fileNameBytes);\n \n       // build file message\n       byte[] fileMessageBytes = null;\n+      String fileMessage = null;\n       GfJsonArray fileMessageJsonBytes = object.getJSONArray(FILE_MESSAGE);\n       if (fileMessageJsonBytes != null) { // if in gfsh\n         fileMessageBytes = GfJsonArray.toByteArray(fileMessageJsonBytes);\n+        fileMessage = new String(fileMessageBytes);\n       } else { // if on member\n-        fileMessageBytes = (byte[]) object.get(FILE_MESSAGE);\n+        fileMessage = (String) object.get(FILE_MESSAGE);\n       }\n-      String fileMessage = new String(fileMessageBytes);\n \n-      GfJsonObject fileDataBytes = object.getJSONObject(FILE_DATA_FIELD);\n-      byte[] byteArray = GfJsonArray.toByteArray(fileDataBytes.getJSONArray(DATA_FIELD));\n-      int dataLength = fileDataBytes.getInt(DATA_LENGTH_FIELD);\n-      DeflaterInflaterData uncompressBytes = CliUtil.uncompressBytes(byteArray, dataLength);\n-      byte[] uncompressed = uncompressBytes.getData();\n+      String fileDataString = (String) object.get(FILE_DATA_FIELD);\n+      int fileDataLength = (int) object.get(DATA_LENGTH_FIELD);\n+      byte[] byteArray = Base64.getDecoder().decode(fileDataString);\n+      byte[] uncompressBytes = CliUtil.uncompressBytes(byteArray, fileDataLength).getData();\n \n       boolean isGfshVM = CliUtil.isGfshVM();\n       File fileToDumpData = new File(fileName);\n@@ -299,13 +286,13 @@ public static void readFileDataAndDump(GfJsonArray byteDataArray, String directo\n       if (fileType == FILE_TYPE_TEXT) {\n         FileWriter fw = new FileWriter(fileToDumpData);\n         BufferedWriter bw = new BufferedWriter(fw);\n-        bw.write(new String(uncompressed));\n+        bw.write(new String(uncompressBytes));\n         bw.flush();\n         fw.flush();\n         fw.close();\n       } else if (fileType == FILE_TYPE_BINARY) {\n         FileOutputStream fos = new FileOutputStream(fileToDumpData);\n-        fos.write(uncompressed);\n+        fos.write(uncompressBytes);\n         fos.flush();\n         fos.close();\n       }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/AbstractResultData.java",
                "sha": "f453ec67ce3e1b227314666c802bbae9f5b64d53",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/ResultBuilder.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/ResultBuilder.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 30,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/result/ResultBuilder.java",
                "patch": "@@ -300,12 +300,6 @@ public ResultData addAsFile(String fileName, String fileContents, String message\n           throw new UnsupportedOperationException(\"This is read only result data\");\n         }\n \n-        @Override\n-        public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-            boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-          throw new UnsupportedOperationException(\"This is read only result data\");\n-        }\n-\n         @Override\n         public TabularResultData accumulate(String accumulateFor, Object value) {\n           throw new UnsupportedOperationException(\"This is read only result data\");\n@@ -325,12 +319,6 @@ public ResultData addAsFile(String fileName, String fileContents, String message\n           throw new UnsupportedOperationException(\"This is read only result data\");\n         }\n \n-        @Override\n-        public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-            boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-          throw new UnsupportedOperationException(\"This is read only result data\");\n-        }\n-\n         @Override\n         public ErrorResultData addLine(String line) {\n           throw new UnsupportedOperationException(\"This is read only result data\");\n@@ -350,12 +338,6 @@ public ResultData addAsFile(String fileName, String fileContents, String message\n           throw new UnsupportedOperationException(\"This is read only result data\");\n         }\n \n-        @Override\n-        public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-            boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-          throw new UnsupportedOperationException(\"This is read only result data\");\n-        }\n-\n         @Override\n         public ErrorResultData addLine(String line) {\n           throw new UnsupportedOperationException(\"This is read only result data\");\n@@ -380,12 +362,6 @@ public ResultData addAsFile(String fileName, String fileContents, String message\n           throw new UnsupportedOperationException(\"This is read only result data\");\n         }\n \n-        @Override\n-        public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-            boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-          throw new UnsupportedOperationException(\"This is read only result data\");\n-        }\n-\n         @Override\n         public SectionResultData addSection() {\n           throw new UnsupportedOperationException(\"This is read only result data\");\n@@ -415,12 +391,6 @@ public ResultData addAsFile(String fileName, String fileContents, String message\n           throw new UnsupportedOperationException(\"This is read only result data\");\n         }\n \n-        @Override\n-        public ResultData addByteDataFromFileFile(String filePath, int fileType, String message,\n-            boolean addTimeStampToName) throws FileNotFoundException, IOException {\n-          throw new UnsupportedOperationException(\"This is read only result data\");\n-        }\n-\n         @Override\n         public ObjectResultData<CliJsonSerializable> addCollection(\n             Collection<CliJsonSerializable> infoBeans) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/result/ResultBuilder.java",
                "sha": "9bd2bf98c24e0a21e530f0dfbe6726163c689592",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/util/JsonUtil.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/util/JsonUtil.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/util/JsonUtil.java",
                "patch": "@@ -385,7 +385,7 @@ public static Object getPrimitiveOrWrapperValue(Class<?> klass, Object value)\n       return value;\n     } else if (klass.isAssignableFrom(Long.class) || klass.isAssignableFrom(long.class)) {\n       return value;\n-    } else if (klass.isAssignableFrom(Float.class) || klass.isAssignableFrom(Float.class)) {\n+    } else if (klass.isAssignableFrom(Float.class) || klass.isAssignableFrom(float.class)) {\n       return value;\n     } else if (klass.isAssignableFrom(Double.class) || klass.isAssignableFrom(double.class)) {\n       return value;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/main/java/org/apache/geode/management/internal/cli/util/JsonUtil.java",
                "sha": "166b375720c5f2aceb160bb00958357c74204abd",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/client/ClientCacheFactoryJUnitTest.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/client/ClientCacheFactoryJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/client/ClientCacheFactoryJUnitTest.java",
                "patch": "@@ -15,6 +15,15 @@\n \n package org.apache.geode.cache.client;\n \n+import static org.apache.geode.distributed.ConfigurationProperties.CACHE_XML_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+import static org.junit.runners.MethodSorters.NAME_ASCENDING;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.DataSerializer;\n import org.apache.geode.cache.RegionService;\n import org.apache.geode.cache.client.internal.ProxyCache;\n@@ -24,7 +33,6 @@\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.distributed.internal.membership.gms.GMSMember;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.HeapDataOutputStream;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.VersionedDataInputStream;\n@@ -50,11 +58,6 @@\n import java.util.Collections;\n import java.util.Properties;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.fail;\n-import static org.junit.runners.MethodSorters.NAME_ASCENDING;\n-\n /**\n  * Unit test for the ClientCacheFactory class\n  * \n@@ -125,7 +128,7 @@ public void test001FindDefaultFromXML() throws Exception {\n     this.tmpFile.deleteOnExit();\n     URL url = ClientCacheFactoryJUnitTest.class\n         .getResource(\"ClientCacheFactoryJUnitTest_single_pool.xml\");;\n-    FileUtil.copy(url, this.tmpFile);\n+    FileUtils.copyFile(new File(url.getFile()), this.tmpFile);\n     this.cc = new ClientCacheFactory().set(CACHE_XML_FILE, this.tmpFile.getAbsolutePath()).create();\n     GemFireCacheImpl gfc = (GemFireCacheImpl) this.cc;\n     assertEquals(true, gfc.isClient());",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/client/ClientCacheFactoryJUnitTest.java",
                "sha": "c633a47ac4ea8b839f855326c5165f53d67c1e3d",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/BaseLineAndCompareQueryPerfJUnitTest.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/BaseLineAndCompareQueryPerfJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/BaseLineAndCompareQueryPerfJUnitTest.java",
                "patch": "@@ -29,15 +29,18 @@\n import java.util.*;\n import java.io.*;\n \n+import org.apache.geode.test.junit.categories.PerformanceTest;\n import org.junit.After;\n import org.junit.Before;\n+import org.junit.Ignore;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n /**\n  * This test is to baseline and compare the performance figures for index usage benchmarks.\n  */\n-@Category(IntegrationTest.class)\n+@Category(PerformanceTest.class)\n+@Ignore(\"Performance tests should not be run as part of precheckin\")\n public class BaseLineAndCompareQueryPerfJUnitTest {\n \n   /** Creates a new instance of BaseLineAndCompareQueryPerfJUnitTest */",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/BaseLineAndCompareQueryPerfJUnitTest.java",
                "sha": "a46e1c40f69e93220e81f2ee81634dc4db553a1e",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/QueryTestUtils.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/QueryTestUtils.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 15,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/QueryTestUtils.java",
                "patch": "@@ -14,15 +14,9 @@\n  */\n package org.apache.geode.cache.query;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.io.Serializable;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.Properties;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.LogWriter;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n@@ -38,6 +32,13 @@\n import org.apache.geode.test.dunit.SerializableRunnable;\n import org.apache.geode.test.dunit.VM;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+\n /**\n  * Utility class for testing supported queries\n  */\n@@ -1763,12 +1764,11 @@ public void run2() {\n     Object[] result = new Object[qarr.length];\n     String query = null;\n     int j = 0;\n-    for (int i = 0; i < qarr.length; i++) {\n-      query = queries.get(qarr[i]);\n-      if (query.indexOf(\"distinct\") == -1)\n-        query = query.replaceFirst(\"select\", \"select distinct\");\n-      else if (query.indexOf(\"DISTINCT\") == -1)\n+    for (final String aQarr : qarr) {\n+      query = queries.get(aQarr);\n+      if (!query.toLowerCase().contains(\"distinct\")) {\n         query = query.replaceFirst(\"select\", \"select distinct\");\n+      }\n \n       // hydra.getLogWriter().info(\"\\nExecuting query: \" + query);\n       try {\n@@ -1799,7 +1799,7 @@ public static void createCacheInVM(VM vm, Properties props) {\n \n   public static void closeCacheInVM(VM vm) {\n     vm.invoke(() -> {\n-      getInstance().cache.close();\n+      cache.close();\n     });\n   }\n \n@@ -1822,7 +1822,7 @@ public static void populateRegion(VM vm, String regionName, Map<?, ?> entries) {\n \n   public static File createTestRootDiskStore(String testName) throws IOException {\n     File diskDir = new File(testName).getAbsoluteFile();\n-    org.apache.geode.internal.FileUtil.delete(diskDir);\n+    FileUtils.deleteDirectory(diskDir);\n     diskDir.mkdir();\n     diskDir.deleteOnExit();\n     return diskDir;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/QueryTestUtils.java",
                "sha": "f53faed95a4cd539ecfd8ff863dcd5dee7b479cc",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/dunit/QueryIndexUsingXMLDUnitTest.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/dunit/QueryIndexUsingXMLDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 15,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/dunit/QueryIndexUsingXMLDUnitTest.java",
                "patch": "@@ -14,18 +14,9 @@\n  */\n package org.apache.geode.cache.query.dunit;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.Properties;\n-\n-import org.junit.Ignore;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n+import static org.junit.Assert.fail;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.LogWriter;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheExistsException;\n@@ -44,7 +35,6 @@\n import org.apache.geode.cache30.CacheSerializableRunnable;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.LocalRegion;\n import org.apache.geode.internal.cache.PartitionedRegion;\n@@ -62,6 +52,15 @@\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n import org.apache.geode.util.test.TestUtil;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Properties;\n \n @Category(DistributedTest.class)\n public class QueryIndexUsingXMLDUnitTest extends JUnit4CacheTestCase {\n@@ -70,7 +69,7 @@\n \n   static private final int WAIT_DEFAULT = (60 * 1000);\n \n-  public static final long MAX_TIME = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();\n+  public static final long MAX_TIME = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT);\n \n   final String name = \"PartionedPortfolios\";\n   final String repRegName = \"Portfolios\";\n@@ -120,7 +119,9 @@ public final void postTearDownCacheTestCase() throws Exception {\n     // avoid creating a new cache just to get the diskstore name\n     Invoke.invokeInEveryVM(resetTestHook());\n     disconnectFromDS();\n-    FileUtil.delete(new File(GemFireCacheImpl.DEFAULT_DS_NAME).getAbsoluteFile());\n+    File deleteMe = new File(GemFireCacheImpl.DEFAULT_DS_NAME).getAbsoluteFile();\n+    if (deleteMe.exists())\n+      FileUtils.forceDelete(deleteMe);\n   }\n \n   /**\n@@ -882,7 +883,7 @@ public void run2() {\n         // remove the disk store.\n         File diskDir = new File(diskStoreName).getAbsoluteFile();\n         try {\n-          org.apache.geode.internal.FileUtil.delete(diskDir);\n+          FileUtils.deleteDirectory(diskDir);\n         } catch (Exception ex) {\n           fail(\"Failed to delete the disDir\");\n         }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/dunit/QueryIndexUsingXMLDUnitTest.java",
                "sha": "9bd20a663e9edcb7227c6e4b531d8a0ade959a80",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/dunit/SelectStarQueryDUnitTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/dunit/SelectStarQueryDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/dunit/SelectStarQueryDUnitTest.java",
                "patch": "@@ -1381,7 +1381,7 @@ public Object call() throws Exception {\n                         + obj.getClass());\n                   }\n                 }\n-              } else if (rs instanceof PortfolioPdx || rs instanceof PortfolioPdx) {\n+              } else if (rs instanceof PortfolioPdx) {\n               } else {\n                 fail(\"Result objects for remote client query: \" + queries[i]\n                     + \" should be instance of PortfolioPdx and not \" + rs.getClass());\n@@ -1441,7 +1441,7 @@ public Object call() throws Exception {\n                         + obj.getClass());\n                   }\n                 }\n-              } else if (rs instanceof PortfolioPdx || rs instanceof PortfolioPdx) {\n+              } else if (rs instanceof PortfolioPdx) {\n               } else {\n                 fail(\"Result objects for remote client query: \" + queries[i]\n                     + \" should be instance of PortfolioPdx and not \" + rs.getClass());",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/dunit/SelectStarQueryDUnitTest.java",
                "sha": "c6502588bc94b829e428561d160f92b0a2a84a4b",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/functional/IndexCreationJUnitTest.java",
                "changes": 51,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache/query/functional/IndexCreationJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 23,
                "filename": "geode-core/src/test/java/org/apache/geode/cache/query/functional/IndexCreationJUnitTest.java",
                "patch": "@@ -24,23 +24,17 @@\n  */\n package org.apache.geode.cache.query.functional;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Properties;\n-import java.util.Set;\n-\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Ignore;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n+import static org.apache.geode.distributed.ConfigurationProperties.CACHE_XML_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_TIME_STATISTICS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.NAME;\n+import static org.apache.geode.distributed.ConfigurationProperties.STATISTIC_SAMPLING_ENABLED;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheFactory;\n@@ -55,7 +49,6 @@\n import org.apache.geode.cache.query.QueryInvalidException;\n import org.apache.geode.cache.query.QueryService;\n import org.apache.geode.cache.query.SelectResults;\n-import org.apache.geode.cache.query.Utils;\n import org.apache.geode.cache.query.data.ComparableWrapper;\n import org.apache.geode.cache.query.data.Portfolio;\n import org.apache.geode.cache.query.internal.DefaultQueryService;\n@@ -71,9 +64,21 @@\n import org.apache.geode.cache.query.types.StructType;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.LocalRegion;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Properties;\n+import java.util.Set;\n \n @Category(IntegrationTest.class)\n public class IndexCreationJUnitTest {\n@@ -815,7 +820,7 @@ public void testIndexCreationFromXML() throws Exception {\n           .execute();\n       assertEquals(\"OQL index results did not match\", 1, results.size());\n       ds.disconnect();\n-      FileUtil.delete(file);\n+      FileUtils.deleteDirectory(file);\n     }\n   }\n \n@@ -845,7 +850,7 @@ public void testIndexCreationFromXMLForLocalScope() throws Exception {\n         .newQuery(\"<trace>SELECT * FROM \" + localRegion.getFullPath() + \" Where ID > 0\").execute();\n     assertEquals(\"OQL index results did not match\", 99, results.size());\n     ds.disconnect();\n-    FileUtil.delete(file);\n+    FileUtils.deleteDirectory(file);\n   }\n \n   @Test\n@@ -876,7 +881,7 @@ public void testIndexCreationFromXMLForDiskLocalScope() throws Exception {\n         .execute();\n     assertEquals(\"OQL index results did not match\", 50, results.size());\n     ds.disconnect();\n-    FileUtil.delete(file);\n+    FileUtils.deleteDirectory(file);\n   }\n \n   @Test\n@@ -954,7 +959,7 @@ public void testIndexInitializationForOverFlowRegions() throws Exception {\n           .execute();\n       assertEquals(\"OQL index results did not match\", 1, results.size());\n       ds.disconnect();\n-      FileUtil.delete(file);\n+      FileUtils.deleteDirectory(file);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache/query/functional/IndexCreationJUnitTest.java",
                "sha": "620ab17032fdd740556001e670bba2e93b477e37",
                "status": "modified"
            },
            {
                "additions": 59,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache30/ClientServerCCEDUnitTest.java",
                "changes": 59,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache30/ClientServerCCEDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/cache30/ClientServerCCEDUnitTest.java",
                "patch": "@@ -260,6 +260,65 @@ public void testTombstoneMessageSentToReplicatesAreNotProcessedInLine() {\n     }\n   }\n \n+  @Test\n+  public void testTombstoneGcMessagesAreOnlySentToPRNodesWithInterestRegistration() {\n+    Host host = Host.getHost(0);\n+    VM vm0 = host.getVM(0);\n+    VM vm1 = host.getVM(1);\n+    VM vm2 = host.getVM(2);\n+    VM vm3 = host.getVM(3);\n+\n+    final String name = \"Region\";\n+\n+    createServerRegion(vm0, name, false);\n+    // Create all the buckets on this vm.\n+    createEntries(vm0);\n+\n+    createServerRegion(vm1, name, false);\n+\n+    int port = createServerRegion(vm2, name, false);\n+\n+    // Create client and register interest on one server.\n+    createClientRegion(vm3, name, port, true, ClientRegionShortcut.CACHING_PROXY);\n+\n+    try {\n+      vm1.invoke(() -> {\n+        DistributionMessageObserver.setInstance(new PRTombstoneMessageObserver());\n+      });\n+      vm2.invoke(() -> {\n+        DistributionMessageObserver.setInstance(new PRTombstoneMessageObserver());\n+      });\n+\n+      destroyEntries(vm0);\n+      forceGC(vm0);\n+\n+      // vm2 should receive tombstone GC messages\n+      vm2.invoke(() -> {\n+        PRTombstoneMessageObserver mo =\n+            (PRTombstoneMessageObserver) DistributionMessageObserver.getInstance();\n+        // Should receive tombstone message for each bucket.\n+        Awaitility.await().atMost(60, TimeUnit.SECONDS).until(() -> {\n+          return mo.prTsMessageProcessed >= 2;\n+        });\n+        assertEquals(\"Tombstone GC message is expected.\", 2, mo.prTsMessageProcessed);\n+      });\n+\n+      // Since there is no interest registered, vm1 should not receive any tombstone GC messages\n+      vm1.invoke(() -> {\n+        PRTombstoneMessageObserver mo =\n+            (PRTombstoneMessageObserver) DistributionMessageObserver.getInstance();\n+        assertEquals(\"Tombstone GC message is not expected.\", 0, mo.prTsMessageProcessed);\n+      });\n+    } finally {\n+      vm1.invoke(() -> {\n+        DistributionMessageObserver.setInstance(null);\n+      });\n+      vm2.invoke(() -> {\n+        DistributionMessageObserver.setInstance(null);\n+      });\n+    }\n+  }\n+\n   private class PRTombstoneMessageObserver extends DistributionMessageObserver {\n     public int tsMessageProcessed = 0;\n     public int prTsMessageProcessed = 0;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/cache30/ClientServerCCEDUnitTest.java",
                "sha": "b4224e0dcba91ee75cf1abf185f6fc9fbe22390f",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/AbstractLauncherIntegrationTestCase.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/AbstractLauncherIntegrationTestCase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/AbstractLauncherIntegrationTestCase.java",
                "patch": "@@ -14,9 +14,11 @@\n  */\n package org.apache.geode.distributed;\n \n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertTrue;\n+\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.lang.StringUtils;\n import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.process.PidUnavailableException;\n@@ -31,16 +33,18 @@\n import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n import org.junit.rules.TestName;\n \n-import java.io.*;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n import java.net.ServerSocket;\n+import java.nio.file.Files;\n import java.util.List;\n import java.util.Properties;\n import java.util.concurrent.Callable;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertTrue;\n-\n /**\n  * @since GemFire 8.0\n  */\n@@ -105,7 +109,7 @@ public Boolean call() throws Exception {\n           return true;\n         }\n         try {\n-          FileUtil.delete(file);\n+          Files.delete(file.toPath());\n         } catch (IOException e) {\n         }\n         return !file.exists();",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/AbstractLauncherIntegrationTestCase.java",
                "sha": "09fa09eaedb905952c84fc65d7be6225f3faa9cf",
                "status": "modified"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "patch": "@@ -43,6 +43,8 @@\n import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n \n+import org.apache.geode.distributed.internal.membership.gms.Services;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n import org.awaitility.Awaitility;\n import org.apache.geode.ForcedDisconnectException;\n import org.apache.geode.GemFireConfigException;\n@@ -101,7 +103,7 @@\n  * \n  * @since GemFire 4.0\n  */\n-@Category({DistributedTest.class, MembershipTest.class})\n+@Category({DistributedTest.class, MembershipTest.class, FlakyTest.class}) // Flaky: GEODE-2542\n public class LocatorDUnitTest extends JUnit4DistributedTestCase {\n \n   static volatile InternalDistributedSystem system = null;\n@@ -408,10 +410,28 @@ public void testStartTwoLocatorsWithMultiKeystoreSSL() throws Exception {\n   }\n \n   private void startVerifyAndStopLocator(VM loc1, VM loc2, int port1, int port2,\n-      Properties properties) {\n+      Properties properties) throws Exception {\n     try {\n-      loc2.invoke(\"startLocator2\", () -> startLocatorWithPortAndProperties(port2, properties));\n-      loc1.invoke(\"startLocator1\", () -> startLocatorWithPortAndProperties(port1, properties));\n+      getBlackboard().initBlackboard();\n+      AsyncInvocation<Boolean> async1 = loc1.invokeAsync(\"startLocator1\", () -> {\n+        getBlackboard().signalGate(\"locator1\");\n+        getBlackboard().waitForGate(\"go\", 10, TimeUnit.SECONDS);\n+        return startLocatorWithPortAndProperties(port1, properties);\n+      });\n+\n+      AsyncInvocation<Boolean> async2 = loc2.invokeAsync(\"startLocator2\", () -> {\n+        getBlackboard().signalGate(\"locator2\");\n+        getBlackboard().waitForGate(\"go\", 10, TimeUnit.SECONDS);\n+        return startLocatorWithPortAndProperties(port2, properties);\n+      });\n+\n+      getBlackboard().waitForGate(\"locator1\", 10, TimeUnit.SECONDS);\n+      getBlackboard().waitForGate(\"locator2\", 10, TimeUnit.SECONDS);\n+      getBlackboard().signalGate(\"go\");\n+\n+      async1.await();\n+      async2.await();\n+\n     } finally {\n       try {\n         // verify that they found each other",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/LocatorDUnitTest.java",
                "sha": "37e8b5c8333d6745c402f97034e3162b06a8cbad",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/LocatorUDPSecurityDUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/LocatorUDPSecurityDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/LocatorUDPSecurityDUnitTest.java",
                "patch": "@@ -35,7 +35,7 @@\n \n import java.util.Properties;\n \n-@Category({DistributedTest.class, MembershipTest.class})\n+@Category({DistributedTest.class, MembershipTest.class, FlakyTest.class}) // Flaky: GEODE-2542\n public class LocatorUDPSecurityDUnitTest extends LocatorDUnitTest {\n \n   public LocatorUDPSecurityDUnitTest() {}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/LocatorUDPSecurityDUnitTest.java",
                "sha": "9d49d30abfb8acccd8a5547ba0ee3c7bcf9e7970",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/internal/DistributionManagerDUnitTest.java",
                "changes": 78,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/DistributionManagerDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 48,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/DistributionManagerDUnitTest.java",
                "patch": "@@ -17,6 +17,7 @@\n import static org.apache.geode.distributed.ConfigurationProperties.*;\n import static org.apache.geode.test.dunit.Assert.*;\n \n+import org.apache.geode.test.dunit.rules.DistributedRestoreSystemProperties;\n import org.awaitility.Awaitility;\n \n import java.net.InetAddress;\n@@ -28,6 +29,7 @@\n import org.apache.logging.log4j.Logger;\n import org.junit.Assert;\n import org.junit.Ignore;\n+import org.junit.Rule;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n@@ -74,6 +76,10 @@\n \n   public static DistributedSystem ds;\n \n+  @Rule\n+  public DistributedRestoreSystemProperties restoreSystemProperties =\n+      new DistributedRestoreSystemProperties();\n+\n   /**\n    * Clears the exceptionInThread flag in the given distribution manager.\n    */\n@@ -137,18 +143,14 @@ public void testConnectAfterBeingShunned() {\n     InternalDistributedMember idm = mgr.getLocalMember();\n     // TODO GMS needs to have a system property allowing the bind-port to be set\n     System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"jg-bind-port\", \"\" + idm.getPort());\n-    try {\n-      sys.disconnect();\n-      sys = getSystem();\n-      mgr = MembershipManagerHelper.getMembershipManager(sys);\n-      sys.disconnect();\n-      InternalDistributedMember idm2 = mgr.getLocalMember();\n-      org.apache.geode.test.dunit.LogWriterUtils.getLogWriter()\n-          .info(\"original ID=\" + idm + \" and after connecting=\" + idm2);\n-      assertTrue(\"should not have used a different udp port\", idm.getPort() == idm2.getPort());\n-    } finally {\n-      System.getProperties().remove(DistributionConfig.GEMFIRE_PREFIX + \"jg-bind-port\");\n-    }\n+    sys.disconnect();\n+    sys = getSystem();\n+    mgr = MembershipManagerHelper.getMembershipManager(sys);\n+    sys.disconnect();\n+    InternalDistributedMember idm2 = mgr.getLocalMember();\n+    org.apache.geode.test.dunit.LogWriterUtils.getLogWriter()\n+        .info(\"original ID=\" + idm + \" and after connecting=\" + idm2);\n+    assertTrue(\"should not have used a different udp port\", idm.getPort() == idm2.getPort());\n   }\n \n   /**\n@@ -158,11 +160,12 @@ public void testConnectAfterBeingShunned() {\n    * should be gone and force more view processing to have it scrubbed from the set.\n    **/\n   @Test\n-  public void testSurpriseMemberHandling() {\n-    VM vm0 = Host.getHost(0).getVM(0);\n+  public void testSurpriseMemberHandling() throws Exception {\n \n+    System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"surprise-member-timeout\", \"3000\");\n     InternalDistributedSystem sys = getSystem();\n     MembershipManager mgr = MembershipManagerHelper.getMembershipManager(sys);\n+    assertTrue(((GMSMembershipManager) mgr).isCleanupTimerStarted());\n \n     try {\n       InternalDistributedMember mbr =\n@@ -180,19 +183,13 @@ public void testSurpriseMemberHandling() {\n           .info(\"current membership view is \" + mgr.getView());\n       org.apache.geode.test.dunit.LogWriterUtils.getLogWriter()\n           .info(\"created ID \" + mbr + \" with view ID \" + mbr.getVmViewId());\n-      sys.getLogWriter()\n-          .info(\"<ExpectedException action=add>attempt to add old member</ExpectedException>\");\n-      sys.getLogWriter()\n-          .info(\"<ExpectedException action=add>Removing shunned GemFire node</ExpectedException>\");\n-      try {\n-        boolean accepted = mgr.addSurpriseMember(mbr);\n-        Assert.assertTrue(\"member with old ID was not rejected (bug #44566)\", !accepted);\n-      } finally {\n-        sys.getLogWriter()\n-            .info(\"<ExpectedException action=remove>attempt to add old member</ExpectedException>\");\n-        sys.getLogWriter().info(\n-            \"<ExpectedException action=remove>Removing shunned GemFire node</ExpectedException>\");\n-      }\n+\n+      IgnoredException.addIgnoredException(\"attempt to add old member\");\n+      IgnoredException.addIgnoredException(\"Removing shunned GemFire node\");\n+\n+      boolean accepted = mgr.addSurpriseMember(mbr);\n+      Assert.assertTrue(\"member with old ID was not rejected (bug #44566)\", !accepted);\n+\n       mbr.setVmViewId(oldViewId);\n \n       // now forcibly add it as a surprise member and show that it is reaped\n@@ -203,28 +200,13 @@ public void testSurpriseMemberHandling() {\n       MembershipManagerHelper.addSurpriseMember(sys, mbr, birthTime);\n       assertTrue(\"Member was not a surprise member\", mgr.isSurpriseMember(mbr));\n \n-      // force a real view change\n-      SerializableRunnable connectDisconnect = new SerializableRunnable() {\n-        public void run() {\n-          getSystem().disconnect();\n-        }\n-      };\n-      vm0.invoke(connectDisconnect);\n-\n-      if (birthTime < (System.currentTimeMillis() - timeout)) {\n-        return; // machine is too busy and we didn't get enough CPU to perform more assertions\n-      }\n-      assertTrue(\"Member was incorrectly removed from surprise member set\",\n-          mgr.isSurpriseMember(mbr));\n-\n-      try {\n-        Thread.sleep(gracePeriod);\n-      } catch (InterruptedException e) {\n-        fail(\"test was interrupted\", e);\n-      }\n+      // if (birthTime < (System.currentTimeMillis() - timeout)) {\n+      // return; // machine is too busy and we didn't get enough CPU to perform more assertions\n+      // }\n \n-      vm0.invoke(connectDisconnect);\n-      assertTrue(\"Member was not removed from surprise member set\", !mgr.isSurpriseMember(mbr));\n+      Awaitility.await(\"waiting for member to be removed\")\n+          .atMost((timeout / 3) + gracePeriod, TimeUnit.MILLISECONDS)\n+          .until(() -> !mgr.isSurpriseMember(mbr));\n \n     } finally {\n       if (sys != null && sys.isConnected()) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/distributed/internal/DistributionManagerDUnitTest.java",
                "sha": "24d8a8a364b6536e98e7a016a8e9d57461e0a3d4",
                "status": "modified"
            },
            {
                "additions": 48,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/DataSerializableJUnitTest.java",
                "changes": 64,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/DataSerializableJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 16,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/DataSerializableJUnitTest.java",
                "patch": "@@ -32,22 +32,7 @@\n import java.net.InetAddress;\n import java.nio.ByteBuffer;\n import java.sql.Timestamp;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.Date;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Hashtable;\n-import java.util.IdentityHashMap;\n-import java.util.LinkedHashSet;\n-import java.util.LinkedList;\n-import java.util.Properties;\n-import java.util.Random;\n-import java.util.Stack;\n-import java.util.TreeMap;\n-import java.util.TreeSet;\n-import java.util.UUID;\n-import java.util.Vector;\n+import java.util.*;\n import java.util.concurrent.TimeUnit;\n \n import org.junit.Before;\n@@ -1579,6 +1564,53 @@ public void testHashtableObject() throws Exception {\n     assertEquals(map, map2);\n   }\n \n+  /**\n+   * Tests data serializing an {@link java.util.LinkedHashMap}\n+   */\n+  @Test\n+  public void testLinkedHashMap() throws Exception {\n+    Random random = getRandom();\n+    LinkedHashMap map = new LinkedHashMap();\n+    int size = random.nextInt(50);\n+    for (int i = 0; i < size; i++) {\n+      Object key = new Long(random.nextLong());\n+      Object value = String.valueOf(random.nextLong());\n+      map.put(key, value);\n+    }\n+\n+    DataOutputStream out = getDataOutput();\n+    DataSerializer.writeLinkedHashMap(map, out);\n+    out.flush();\n+\n+    DataInput in = getDataInput();\n+    LinkedHashMap map2 = DataSerializer.readLinkedHashMap(in);\n+    assertEquals(map, map2);\n+  }\n+\n+  /**\n+   * Tests data serializing an {@link LinkedHashMap} using {@link DataSerializer#writeObject}.\n+   */\n+  @Test\n+  public void testLinkedHashMapObject() throws Exception {\n+    Random random = getRandom();\n+    LinkedHashMap map = new LinkedHashMap();\n+    int size = random.nextInt(50);\n+    for (int i = 0; i < size; i++) {\n+      Object key = new Long(random.nextLong());\n+      Object value = String.valueOf(random.nextLong());\n+      map.put(key, value);\n+    }\n+\n+    DataOutputStream out = getDataOutput();\n+    DataSerializer.writeObject(map, out);\n+    out.flush();\n+\n+    DataInput in = getDataInput();\n+    LinkedHashMap map2 = (LinkedHashMap) DataSerializer.readObject(in);\n+    assertEquals(map, map2);\n+  }\n+\n+\n   /**\n    * Tests data serializing an {@link IdentityHashMap}\n    */",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/DataSerializableJUnitTest.java",
                "sha": "0c5d561f42f7eb88154a3f36bc30c3e9d795115c",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/FileUtilJUnitTest.java",
                "changes": 101,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/FileUtilJUnitTest.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 101,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/FileUtilJUnitTest.java",
                "patch": "@@ -1,101 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal;\n-\n-import static org.junit.Assert.*;\n-\n-import java.io.DataInput;\n-import java.io.DataInputStream;\n-import java.io.DataOutput;\n-import java.io.DataOutputStream;\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.FileOutputStream;\n-import java.io.IOException;\n-\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n-\n-@Category(IntegrationTest.class)\n-public class FileUtilJUnitTest {\n-\n-  @Test\n-  public void testCopyFile() throws IOException {\n-    File source = File.createTempFile(\"FileUtilJUnitTest\", null);\n-    File dest = File.createTempFile(\"FileUtilJUnitTest\", null);\n-    try {\n-      FileOutputStream fos = new FileOutputStream(source);\n-      DataOutput daos = new DataOutputStream(fos);\n-      try {\n-        for (long i = 0; i < FileUtil.MAX_TRANSFER_SIZE * 2.5 / 8; i++) {\n-          daos.writeLong(i);\n-        }\n-      } finally {\n-        fos.close();\n-      }\n-      FileUtil.copy(source, dest);\n-\n-      FileInputStream fis = new FileInputStream(dest);\n-      DataInput dis = new DataInputStream(fis);\n-      try {\n-        for (long i = 0; i < FileUtil.MAX_TRANSFER_SIZE * 2.5 / 8; i++) {\n-          assertEquals(i, dis.readLong());\n-        }\n-        assertEquals(-1, fis.read());\n-      } finally {\n-        fis.close();\n-      }\n-    } finally {\n-      source.delete();\n-      dest.delete();\n-    }\n-  }\n-\n-  @Test\n-  public void testStripOffExtension() {\n-    String fileName = \"filename\";\n-    assertEquals(\"filename\", FileUtil.stripOffExtension(fileName));\n-    fileName = \"filename.txt\";\n-    assertEquals(\"filename\", FileUtil.stripOffExtension(fileName));\n-    fileName = \"filename.txt.txt\";\n-    assertEquals(\"filename.txt\", FileUtil.stripOffExtension(fileName));\n-    fileName = \"filename.txt.log\";\n-    assertEquals(\"filename.txt\", FileUtil.stripOffExtension(fileName));\n-    fileName = \"/dir/dir/dir/dir/filename.txt.log\";\n-    assertEquals(\"/dir/dir/dir/dir/filename.txt\", FileUtil.stripOffExtension(fileName));\n-  }\n-\n-  @Test\n-  public void testDeleteFile() throws IOException {\n-    File file = File.createTempFile(\"FileUtilJUnitTest\", null);\n-    assertTrue(file.exists());\n-    FileUtil.delete(file);\n-    assertFalse(file.exists());\n-  }\n-\n-  @Test\n-  public void testDeleteDir() throws IOException {\n-    File dir = new File(\"testDirName\");\n-    dir.mkdir();\n-    File file = File.createTempFile(\"testFile\", null, dir);\n-    assertTrue(dir.exists());\n-    assertTrue(file.exists());\n-    FileUtil.delete(dir);\n-    assertFalse(file.exists());\n-    assertFalse(dir.exists());\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/FileUtilJUnitTest.java",
                "sha": "942059e110487f3f886ef5749134190768a87eac",
                "status": "removed"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/JarDeployerDUnitTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/JarDeployerDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 16,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/JarDeployerDUnitTest.java",
                "patch": "@@ -42,10 +42,12 @@\n import java.io.OutputStream;\n import java.io.RandomAccessFile;\n import java.nio.channels.FileLock;\n+import java.nio.file.Files;\n import java.util.List;\n import java.util.Properties;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.atomic.AtomicReference;\n+import java.util.regex.Pattern;\n \n /**\n  * Unit tests for the JarDeployer class\n@@ -515,9 +517,7 @@ public void run() {\n   }\n \n   FileLock acquireSharedLock(final File file) throws IOException {\n-    @SuppressWarnings(\"resource\")\n-    FileLock fileLock = new FileInputStream(file).getChannel().lock(0, 1, true);\n-    return fileLock;\n+    return new FileInputStream(file).getChannel().lock(0, 1, true);\n   }\n \n   void releaseLock(final FileLock fileLock, final File lockFile) throws IOException {\n@@ -544,32 +544,28 @@ protected boolean doesFileMatchBytes(final File file, final byte[] bytes) throws\n     }\n \n     // Open the file then loop comparing each byte\n-    InputStream inStream = new FileInputStream(file);\n     int index = 0;\n-    try {\n+    try (InputStream inStream = new FileInputStream(file)) {\n       for (; index < bytes.length; index++) {\n         if (((byte) inStream.read()) != bytes[index])\n           break;\n       }\n-    } finally {\n-      inStream.close();\n     }\n \n     // If we didn't get to the end then something was different\n-    if (index < bytes.length)\n-      return false;\n-\n-    return true;\n+    return index >= bytes.length;\n   }\n \n   private void deleteSavedJarFiles() throws IOException {\n-    FileUtil.deleteMatching(new File(\".\"),\n-        \"^\" + JarDeployer.JAR_PREFIX + \"JarDeployerDUnit.*#\\\\d++$\");\n-    FileUtil.delete(new File(\"JarDeployerDUnit\"));\n+    Pattern pattern = Pattern.compile(\"^\" + JarDeployer.JAR_PREFIX + \"JarDeployerDUnit.*#\\\\d++$\");\n+    File[] files = new File(\".\").listFiles((dir1, name) -> pattern.matcher(name).matches());\n+    if (files != null) {\n+      for (File file : files) {\n+        Files.delete(file.toPath());\n+      }\n+    }\n   }\n \n-\n-\n   void writeJarBytesToFile(File jarFile, byte[] jarBytes) throws IOException {\n     final OutputStream outStream = new FileOutputStream(jarFile);\n     outStream.write(jarBytes);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/JarDeployerDUnitTest.java",
                "sha": "a365899c46bb7f28ce75118e45137a243493cbd0",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/JarDeployerIntegrationTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/JarDeployerIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/JarDeployerIntegrationTest.java",
                "patch": "@@ -107,7 +107,7 @@ public void testDeployNoUpdateWhenNoChange() throws Exception {\n   @Test\n   public void testDeployToInvalidDirectory() throws IOException, ClassNotFoundException {\n     final File alternateDir = new File(temporaryFolder.getRoot(), \"JarDeployerDUnit\");\n-    FileUtil.delete(alternateDir);\n+    alternateDir.delete();\n \n     final JarDeployer jarDeployer = new JarDeployer(alternateDir);\n     final CyclicBarrier barrier = new CyclicBarrier(2);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/JarDeployerIntegrationTest.java",
                "sha": "71daeccc42e7944f01ce50d94fc3c4afc5c9b121",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/JavaExec.java",
                "changes": 71,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/JavaExec.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 71,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/JavaExec.java",
                "patch": "@@ -1,71 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal;\n-\n-import java.io.*;\n-import java.util.*;\n-\n-/**\n- * Used to exec a java main class in its own vm\n- *\n- *\n- */\n-public class JavaExec {\n-  /**\n-   * Creates a java process that executes the given main class and waits for the process to\n-   * terminate.\n-   * \n-   * @return a {@link ProcessOutputReader} that can be used to get the exit code and stdout+stderr\n-   *         of the terminated process.\n-   */\n-  public static ProcessOutputReader fg(Class main) throws IOException {\n-    return fg(main, null, null);\n-  }\n-\n-  /**\n-   * Creates a java process that executes the given main class and waits for the process to\n-   * terminate.\n-   * \n-   * @return a {@link ProcessOutputReader} that can be used to get the exit code and stdout+stderr\n-   *         of the terminated process.\n-   */\n-  public static ProcessOutputReader fg(Class main, String[] vmArgs, String[] mainArgs)\n-      throws IOException {\n-    File javabindir = new File(System.getProperty(\"java.home\"), \"bin\");\n-    File javaexe = new File(javabindir, \"java\");\n-\n-    int bits = Integer.getInteger(\"sun.arch.data.model\", 0).intValue();\n-    String vmKindArg = (bits == 64) ? \"-d64\" : null;\n-\n-    ArrayList argList = new ArrayList();\n-    argList.add(javaexe.getPath());\n-    if (vmKindArg != null) {\n-      argList.add(vmKindArg);\n-    }\n-    // argList.add(\"-Dgemfire.systemDirectory=\" +\n-    // GemFireConnectionFactory.getDefaultSystemDirectory());\n-    argList.add(\"-Djava.class.path=\" + System.getProperty(\"java.class.path\"));\n-    argList.add(\"-Djava.library.path=\" + System.getProperty(\"java.library.path\"));\n-    if (vmArgs != null) {\n-      argList.addAll(Arrays.asList(vmArgs));\n-    }\n-    argList.add(main.getName());\n-    if (mainArgs != null) {\n-      argList.addAll(Arrays.asList(mainArgs));\n-    }\n-    String[] cmd = (String[]) argList.toArray(new String[argList.size()]);\n-    return new ProcessOutputReader(Runtime.getRuntime().exec(cmd));\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/JavaExec.java",
                "sha": "7803d5dd967a9888333390036af215b802c42640",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/LongBuffer.java",
                "changes": 96,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/LongBuffer.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 96,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/LongBuffer.java",
                "patch": "@@ -1,96 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal;\n-\n-public class LongBuffer {\n-\n-  private long data[]; // the array implementing the buffer\n-  public int length; // number of valid elements in the buffer,\n-  // data[0.. this.length-1 ] are the valid elements\n-\n-  /** construct a new instance of the specified capacity */\n-  LongBuffer(int size) {\n-    data = new long[size];\n-    length = 0;\n-  }\n-\n-  /** construct a new instance, installing the argument as the data array */\n-  LongBuffer(long[] someIds) {\n-    data = someIds;\n-    length = someIds.length;\n-  }\n-\n-  /** change the capacity to the specified size, without loosing elements */\n-  private void changeSize(int newSize) {\n-    if (newSize >= length) { // only change size if we won't loose data\n-      long[] oldData = data;\n-      int oldLength = length;\n-      data = new long[newSize];\n-      length = 0;\n-      add(oldData, oldLength);\n-    }\n-  }\n-\n-\n-  public synchronized void add(long id) {\n-    if (length >= data.length) {\n-      // if buffer is large, don't double to reduce out-of-mem problems\n-      if (length > 10000)\n-        changeSize(length + 2000);\n-      else\n-        changeSize(length * 2);\n-    }\n-    data[length++] = id;\n-  }\n-\n-  /** add argIds[0..argLength] , growing as required */\n-  public synchronized void add(long[] argIds, int argLength) {\n-    if (length + argLength > data.length) {\n-      long[] oldData = data;\n-      data = new long[argLength + length];\n-      System.arraycopy(oldData, 0, data, 0, oldData.length);\n-    }\n-    System.arraycopy(argIds, 0, data, length, argLength);\n-    length += argLength;\n-  }\n-\n-  /** add all of argIds, growing as required */\n-  public synchronized void add(long[] argIds) {\n-    add(argIds, argIds.length);\n-  }\n-\n-  /** add all elements in the argument, growing as required */\n-  public synchronized void add(LongBuffer argBuf) {\n-    add(argBuf.data, argBuf.length);\n-  }\n-\n-  public synchronized long get(int index) {\n-    if (index >= length)\n-      throw new IndexOutOfBoundsException(\" index \" + index + \" length \" + length);\n-    return data[index];\n-  }\n-\n-  public synchronized long getAndStore(int index, int newValue) {\n-    if (index >= length)\n-      throw new IndexOutOfBoundsException(\" index \" + index + \" length \" + length);\n-    long result = data[index];\n-    data[index] = newValue;\n-    return result;\n-  }\n-\n-  public synchronized void clear() {\n-    length = 0;\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-core/src/test/java/org/apache/geode/internal/LongBuffer.java",
                "sha": "addd5ea121aeaccfbfdc89c04e7a433869483150",
                "status": "removed"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldDUnitTest.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldDUnitTest.java",
                "patch": "@@ -14,18 +14,12 @@\n  */\n package org.apache.geode.internal;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.List;\n-import java.util.Properties;\n-import java.util.concurrent.CopyOnWriteArrayList;\n-\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_CLUSTER_CONFIGURATION;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.START_LOCATOR;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n \n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheFactory;\n@@ -46,6 +40,16 @@\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CopyOnWriteArrayList;\n \n @Category(DistributedTest.class)\n public class PdxDeleteFieldDUnitTest extends JUnit4CacheTestCase {\n@@ -186,7 +190,7 @@ public Object call() throws Exception {\n   public void preTearDownCacheTestCase() throws Exception {\n     for (String path : this.filesToBeDeleted) {\n       try {\n-        FileUtil.delete(new File(path));\n+        Files.delete(new File(path).toPath());\n       } catch (IOException e) {\n         LogWriterUtils.getLogWriter().error(\"Unable to delete file\", e);\n       }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldDUnitTest.java",
                "sha": "435655da9dd977bcf2591a9d1444888050494b03",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldJUnitTest.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 9,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldJUnitTest.java",
                "patch": "@@ -14,13 +14,32 @@\n  */\n package org.apache.geode.internal;\n \n-import org.apache.geode.cache.*;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertSame;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.query.internal.DefaultQuery;\n import org.apache.geode.internal.cache.DiskStoreImpl;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.util.BlobHelper;\n-import org.apache.geode.pdx.*;\n-import org.apache.geode.pdx.internal.*;\n+import org.apache.geode.pdx.PdxInstance;\n+import org.apache.geode.pdx.PdxInstanceFactory;\n+import org.apache.geode.pdx.PdxReader;\n+import org.apache.geode.pdx.PdxSerializable;\n+import org.apache.geode.pdx.PdxWriter;\n+import org.apache.geode.pdx.internal.PdxField;\n+import org.apache.geode.pdx.internal.PdxInstanceImpl;\n+import org.apache.geode.pdx.internal.PdxType;\n+import org.apache.geode.pdx.internal.PdxUnreadData;\n+import org.apache.geode.pdx.internal.TypeRegistry;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n@@ -29,11 +48,6 @@\n import java.util.Collection;\n import java.util.Properties;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n-import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertSame;\n-\n @Category(IntegrationTest.class)\n public class PdxDeleteFieldJUnitTest {\n \n@@ -96,7 +110,7 @@ public void testPdxDeleteField() throws Exception {\n         }\n       }\n     } finally {\n-      FileUtil.delete(f);\n+      FileUtils.deleteDirectory(f);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxDeleteFieldJUnitTest.java",
                "sha": "affa7e3f2eba2d53922732c93a5d850818b555fa",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxRenameDUnitTest.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/PdxRenameDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/PdxRenameDUnitTest.java",
                "patch": "@@ -14,18 +14,12 @@\n  */\n package org.apache.geode.internal;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.List;\n-import java.util.Properties;\n-import java.util.concurrent.CopyOnWriteArrayList;\n-\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_CLUSTER_CONFIGURATION;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.START_LOCATOR;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n \n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheFactory;\n@@ -47,6 +41,16 @@\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CopyOnWriteArrayList;\n \n @Category(DistributedTest.class)\n public class PdxRenameDUnitTest extends JUnit4CacheTestCase {\n@@ -195,7 +199,7 @@ public Object call() throws Exception {\n   public void preTearDownCacheTestCase() throws Exception {\n     for (String path : this.filesToBeDeleted) {\n       try {\n-        FileUtil.delete(new File(path));\n+        Files.delete(new File(path).toPath());\n       } catch (IOException e) {\n         LogWriterUtils.getLogWriter().error(\"Unable to delete file\", e);\n       }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxRenameDUnitTest.java",
                "sha": "b05285a8fe24a8ec7acc47384f10d9ef5eda0195",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxRenameJUnitTest.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/PdxRenameJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/PdxRenameJUnitTest.java",
                "patch": "@@ -14,7 +14,17 @@\n  */\n package org.apache.geode.internal;\n \n-import org.apache.geode.cache.*;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.internal.cache.DiskStoreImpl;\n import org.apache.geode.pdx.PdxReader;\n import org.apache.geode.pdx.PdxSerializable;\n@@ -30,10 +40,6 @@\n import java.util.Properties;\n import java.util.regex.Pattern;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n-import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-\n @Category(IntegrationTest.class)\n public class PdxRenameJUnitTest {\n   @Test\n@@ -67,7 +73,7 @@ public void testGetPdxTypes() throws Exception {\n         }\n       }\n     } finally {\n-      FileUtil.delete(f);\n+      FileUtils.deleteDirectory(f);\n     }\n   }\n \n@@ -118,7 +124,7 @@ public void testPdxRename() throws Exception {\n         }\n       }\n     } finally {\n-      FileUtil.delete(f);\n+      FileUtils.deleteDirectory(f);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/PdxRenameJUnitTest.java",
                "sha": "561e8df176d6361dd0f719fd53fe1befd3091581",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/BackupDUnitTest.java",
                "changes": 113,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/BackupDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 52,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/BackupDUnitTest.java",
                "patch": "@@ -14,33 +14,13 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import org.junit.experimental.categories.Category;\n-import org.junit.Test;\n-\n-import static org.junit.Assert.*;\n-\n-import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n-import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n-import org.apache.geode.test.junit.categories.DistributedTest;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n \n-import java.io.BufferedReader;\n-import java.io.File;\n-import java.io.FileNotFoundException;\n-import java.io.FileReader;\n-import java.io.IOException;\n-import java.io.PrintStream;\n-import java.io.Serializable;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Set;\n-import java.util.TreeSet;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicReference;\n-\n-import org.apache.geode.GemFireIOException;\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.admin.BackupStatus;\n-import org.apache.geode.admin.internal.FinishBackupRequest;\n import org.apache.geode.admin.internal.PrepareBackupRequest;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.DataPolicy;\n@@ -58,7 +38,6 @@\n import org.apache.geode.distributed.internal.DistributionMessage;\n import org.apache.geode.distributed.internal.DistributionMessageObserver;\n import org.apache.geode.distributed.internal.ReplyMessage;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.admin.remote.AdminFailureResponse;\n import org.apache.geode.internal.cache.partitioned.PersistentPartitionedRegionTestBase;\n import org.apache.geode.test.dunit.Assert;\n@@ -71,6 +50,26 @@\n import org.apache.geode.test.dunit.SerializableCallable;\n import org.apache.geode.test.dunit.SerializableRunnable;\n import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.Serializable;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.regex.Pattern;\n \n @Category(DistributedTest.class)\n public class BackupDUnitTest extends PersistentPartitionedRegionTestBase {\n@@ -80,7 +79,7 @@\n   @Override\n   public final void preTearDownCacheTestCase() throws Exception {\n     StringBuilder failures = new StringBuilder();\n-    FileUtil.delete(getBackupDir(), failures);\n+    delete(getBackupDir(), failures);\n     if (failures.length() > 0) {\n       LogWriterUtils.getLogWriter().error(failures.toString());\n     }\n@@ -108,9 +107,9 @@ public void testBackupPR() throws Throwable {\n     assertEquals(2, status.getBackedUpDiskStores().size());\n     assertEquals(Collections.emptySet(), status.getOfflineDiskStores());\n \n-\n-    List<File> mytexts = FileUtil.findAll(getBackupDir(), \".*my.txt.*\");\n-    assertEquals(2, mytexts.size());\n+    Pattern pattern = Pattern.compile(\".*my.txt.*\");\n+    Collection<File> files = FileUtils.listFiles(getBackupDir(), new String[] {\"txt\"}, true);\n+    assertEquals(4, files.size());\n     deleteOldUserUserFile(vm0);\n     deleteOldUserUserFile(vm1);\n     validateBackupComplete();\n@@ -153,8 +152,6 @@ public void run() {\n \n   /**\n    * Test of bug 42419\n-   * \n-   * @throws Throwable\n    */\n   @Test\n   public void testBackupFromMemberWithDiskStore() throws Throwable {\n@@ -177,7 +174,6 @@ public void testBackupFromMemberWithDiskStore() throws Throwable {\n     }\n     assertEquals(Collections.emptySet(), status.getOfflineDiskStores());\n \n-\n     validateBackupComplete();\n \n     closeCache(vm0);\n@@ -218,8 +214,6 @@ public void run() {\n \n   /**\n    * Test for bug 42419\n-   * \n-   * @throws Throwable\n    */\n   @Test\n   public void testBackupWhileBucketIsCreated() throws Throwable {\n@@ -228,7 +222,6 @@ public void testBackupWhileBucketIsCreated() throws Throwable {\n     VM vm1 = host.getVM(1);\n     final VM vm2 = host.getVM(2);\n \n-\n     LogWriterUtils.getLogWriter().info(\"Creating region in VM0\");\n     createPersistentRegion(vm0);\n \n@@ -239,7 +232,6 @@ public void testBackupWhileBucketIsCreated() throws Throwable {\n     LogWriterUtils.getLogWriter().info(\"Creating region in VM1\");\n     createPersistentRegion(vm1);\n \n-\n     final AtomicReference<BackupStatus> statusRef = new AtomicReference<BackupStatus>();\n     Thread thread1 = new Thread() {\n       public void run() {\n@@ -259,12 +251,10 @@ public void run() {\n     thread1.join();\n     thread2.join();\n \n-\n     BackupStatus status = statusRef.get();\n     assertEquals(2, status.getBackedUpDiskStores().size());\n     assertEquals(Collections.emptySet(), status.getOfflineDiskStores());\n \n-\n     validateBackupComplete();\n \n     createData(vm0, 0, 5, \"C\", \"region1\");\n@@ -416,7 +406,6 @@ public void beforeProcessMessage(DistributionManager dm, DistributionMessage mes\n    * Test for bug 42420. Invoke a backup when a bucket is in the middle of being moved.\n    * \n    * @param observer - a message observer that triggers at the backup at the correct time.\n-   * @throws Throwable\n    */\n   public void backupWhileBucketIsMoved(final DistributionMessageObserver observer)\n       throws Throwable {\n@@ -467,7 +456,6 @@ public void run() {\n         }\n       });\n \n-\n       validateBackupComplete();\n \n       createData(vm0, 0, 5, \"C\", \"region1\");\n@@ -510,8 +498,6 @@ public void run() {\n \n   /**\n    * Make sure we don't report members without persistent data as backed up.\n-   * \n-   * @throws Throwable\n    */\n   @Test\n   public void testBackupOverflow() throws Throwable {\n@@ -533,7 +519,6 @@ public void testBackupOverflow() throws Throwable {\n     assertEquals(2, status.getBackedUpDiskStores().values().iterator().next().size());\n     assertEquals(Collections.emptySet(), status.getOfflineDiskStores());\n \n-\n     validateBackupComplete();\n \n   }\n@@ -558,14 +543,11 @@ public void testBackupPRWithOfflineMembers() throws Throwable {\n \n     closeCache(vm2);\n \n-\n     BackupStatus status = backup(vm3);\n     assertEquals(2, status.getBackedUpDiskStores().size());\n     assertEquals(2, status.getOfflineDiskStores().size());\n   }\n \n-\n-\n   // TODO\n   // Test default disk store.\n   // Test backing up and recovering while a bucket move is in progress.\n@@ -574,8 +556,10 @@ public void testBackupPRWithOfflineMembers() throws Throwable {\n \n   private void validateBackupComplete() {\n     File backupDir = getBackupDir();\n-    File incompleteBackup = FileUtil.find(backupDir, \".*INCOMPLETE.*\");\n-    assertNull(incompleteBackup);\n+    Pattern pattern = Pattern.compile(\".*INCOMPLETE.*\");\n+    File[] files = backupDir.listFiles((dir1, name) -> pattern.matcher(name).matches());\n+    assertNotNull(files);\n+    assertTrue(files.length == 0);\n   }\n \n   protected void createPersistentRegion(VM vm) throws Throwable {\n@@ -594,7 +578,7 @@ private void deleteOldUserUserFile(final VM vm) {\n       public void run() {\n         final int pid = vm.getPid();\n         try {\n-          FileUtil.delete(new File(\"userbackup_\" + pid));\n+          FileUtils.deleteDirectory(new File(\"userbackup_\" + pid));\n         } catch (IOException e) {\n           fail(e.getMessage());\n         }\n@@ -674,7 +658,6 @@ public void run() {\n         dsf.setMaxOplogSize(1);\n         DiskStore ds = dsf.create(getUniqueName());\n \n-\n         RegionFactory rf = new RegionFactory();\n         rf.setDiskStoreName(ds.getName());\n         rf.setDiskSynchronous(true);\n@@ -704,7 +687,6 @@ public void run() {\n         dsf.setMaxOplogSize(1);\n         DiskStore ds = dsf.create(getUniqueName());\n \n-\n         RegionFactory rf = new RegionFactory();\n         rf.setDiskStoreName(ds.getName());\n         rf.setDiskSynchronous(true);\n@@ -802,4 +784,31 @@ protected DataPolicy getDataPolicy() {\n \n   }\n \n+  /**\n+   * Recursively delete a file or directory. A description of any files or directories that can not\n+   * be deleted will be added to failures if failures is non-null. This method tries to delete as\n+   * much as possible.\n+   */\n+  public static void delete(File file, StringBuilder failures) {\n+    if (!file.exists())\n+      return;\n+\n+    if (file.isDirectory()) {\n+      File[] fileList = file.listFiles();\n+      if (fileList != null) {\n+        for (File child : fileList) {\n+          delete(child, failures);\n+        }\n+      }\n+    }\n+\n+    try {\n+      Files.delete(file.toPath());\n+    } catch (IOException e) {\n+      if (failures != null) {\n+        failures.append(\"Could not delete \").append(file).append(\" due to \").append(e.getMessage())\n+            .append('\\n');\n+      }\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/BackupDUnitTest.java",
                "sha": "f2cee7126d497fe374c63e44806300c3a6345e11",
                "status": "modified"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/BackupJUnitTest.java",
                "changes": 58,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/BackupJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 14,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/BackupJUnitTest.java",
                "patch": "@@ -14,9 +14,28 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import org.apache.geode.cache.*;\n+import static junit.framework.TestCase.assertNotNull;\n+import static org.apache.geode.distributed.ConfigurationProperties.CACHE_XML_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.filefilter.DirectoryFileFilter;\n+import org.apache.commons.io.filefilter.RegexFileFilter;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.DiskStore;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.DiskWriteAttributesFactory;\n+import org.apache.geode.cache.EvictionAction;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.distributed.DistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.persistence.BackupManager;\n import org.apache.geode.internal.cache.persistence.RestoreScript;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n@@ -25,13 +44,19 @@\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n-import java.io.*;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n import java.net.URISyntaxException;\n import java.net.URL;\n-import java.util.*;\n-\n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Properties;\n+import java.util.Random;\n \n /**\n  *\n@@ -92,15 +117,15 @@ private void createCache() throws IOException {\n   @After\n   public void tearDown() throws Exception {\n     cache.close();\n-    FileUtil.delete(backupDir);\n-    FileUtil.delete(diskDirs[0]);\n-    FileUtil.delete(diskDirs[1]);\n+    FileUtils.deleteDirectory(backupDir);\n+    FileUtils.deleteDirectory(diskDirs[0]);\n+    FileUtils.deleteDirectory(diskDirs[1]);\n   }\n \n   private void destroyDiskDirs() throws IOException {\n-    FileUtil.delete(diskDirs[0]);\n+    FileUtils.deleteDirectory(diskDirs[0]);\n     diskDirs[0].mkdir();\n-    FileUtil.delete(diskDirs[1]);\n+    FileUtils.deleteDirectory(diskDirs[1]);\n     diskDirs[1].mkdir();\n   }\n \n@@ -300,7 +325,10 @@ public void testBackupCacheXml() throws Exception {\n     BackupManager backup = cache.startBackup(cache.getDistributedSystem().getDistributedMember());\n     backup.prepareBackup();\n     backup.finishBackup(backupDir, null, false);\n-    File cacheXmlBackup = FileUtil.find(backupDir, \".*config.cache.xml\");\n+    Collection<File> fileCollection = FileUtils.listFiles(backupDir,\n+        new RegexFileFilter(\"cache.xml\"), DirectoryFileFilter.DIRECTORY);\n+    assertEquals(1, fileCollection.size());\n+    File cacheXmlBackup = fileCollection.iterator().next();\n     assertTrue(cacheXmlBackup.exists());\n     byte[] expectedBytes = getBytes(cacheXmlFile);\n     byte[] backupBytes = getBytes(cacheXmlBackup);\n@@ -345,7 +373,9 @@ private void validateEntriesExist(Region region, int start, int end) {\n   }\n \n   private void restoreBackup(boolean expectFailure) throws IOException, InterruptedException {\n-    List<File> restoreScripts = FileUtil.findAll(backupDir, \".*restore.*\");\n+    Collection<File> restoreScripts = FileUtils.listFiles(backupDir,\n+        new RegexFileFilter(\".*restore.*\"), DirectoryFileFilter.DIRECTORY);\n+    assertNotNull(restoreScripts);\n     assertEquals(\"Restore scripts \" + restoreScripts, 1, restoreScripts.size());\n     for (File script : restoreScripts) {\n       execute(script, expectFailure);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/BackupJUnitTest.java",
                "sha": "6d047732544aa9099cdd486b42007c2257a961f6",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "patch": "@@ -42,6 +42,8 @@\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.apache.geode.test.junit.categories.FlakyTest;\n+\n import org.apache.logging.log4j.Logger;\n import org.assertj.core.api.JUnitSoftAssertions;\n import org.junit.Ignore;\n@@ -107,6 +109,7 @@ public void testPutWithClearSameVM() throws InterruptedException {\n     performTestAndCheckResults(putOperationsTest);\n   }\n \n+  @Category(FlakyTest.class) // GEODE-2275\n   @Test\n   public void testPutWithClearDifferentVM() throws InterruptedException {\n     getVMs();",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "sha": "1b97cc4226aea8481b4ef2099e6f91483a50fd26",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionAsyncRecoveryJUnitTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionAsyncRecoveryJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionAsyncRecoveryJUnitTest.java",
                "patch": "@@ -14,7 +14,18 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import static org.junit.Assert.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.test.junit.categories.FlakyTest;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n \n import java.io.File;\n import java.io.IOException;\n@@ -23,15 +34,6 @@\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.TimeUnit;\n \n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n-import org.apache.geode.cache.DataPolicy;\n-import org.apache.geode.cache.Region;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.junit.categories.FlakyTest;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n-\n @Category(IntegrationTest.class)\n public class DiskRegionAsyncRecoveryJUnitTest extends DiskRegionTestingBase {\n \n@@ -492,15 +494,15 @@ private void backupDisk() throws IOException {\n     File tmpDir = new File(dirs[0].getParent(), \"backupDir\");\n     tmpDir.mkdirs();\n     for (File file : dirs) {\n-      FileUtil.copy(file, new File(tmpDir, file.getName()));\n+      FileUtils.copyDirectory(file, new File(tmpDir, file.getName()));\n     }\n   }\n \n   private void restoreDisk() throws IOException {\n     File tmpDir = new File(dirs[0].getParent(), \"backupDir\");\n     for (File file : dirs) {\n-      FileUtil.delete(file);\n-      FileUtil.copy(new File(tmpDir, file.getName()), file);\n+      FileUtils.deleteDirectory(file);\n+      FileUtils.copyDirectory(new File(tmpDir, file.getName()), file);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionAsyncRecoveryJUnitTest.java",
                "sha": "44036c030ba51ae4d6f6e2ca9d4ab90f7e89a646",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionTestingBase.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionTestingBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 15,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionTestingBase.java",
                "patch": "@@ -17,19 +17,15 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.Properties;\n-\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.rules.TestName;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_TIME_STATISTICS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.STATISTIC_ARCHIVE_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.STATISTIC_SAMPLING_ENABLED;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n \n import org.apache.geode.LogWriter;\n import org.apache.geode.cache.Cache;\n@@ -40,9 +36,19 @@\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionDestroyedException;\n import org.apache.geode.distributed.DistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.LocalRegion.NonTXEntry;\n import org.apache.geode.internal.cache.versions.VersionTag;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.rules.TestName;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Properties;\n \n /**\n  * All disk region unit tests extend this base class , common method to be used in all tests are\n@@ -204,7 +210,7 @@ protected static void deleteFiles() {\n         while (cnt < 3) {\n           try {\n             cnt++;\n-            FileUtil.delete(files[j]);\n+            Files.delete(files[j].toPath());\n             break;\n           } catch (IOException e) {\n             ioe = e;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/DiskRegionTestingBase.java",
                "sha": "5333726e30d30a56f08fff513e70b14817a75115",
                "status": "modified"
            },
            {
                "additions": 98,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/IncrementalBackupDUnitTest.java",
                "changes": 167,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/IncrementalBackupDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 69,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/IncrementalBackupDUnitTest.java",
                "patch": "@@ -14,24 +14,15 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.BufferedReader;\n-import java.io.File;\n-import java.io.FileFilter;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.filefilter.DirectoryFileFilter;\n+import org.apache.commons.io.filefilter.RegexFileFilter;\n import org.apache.geode.admin.AdminDistributedSystem;\n import org.apache.geode.admin.AdminDistributedSystemFactory;\n import org.apache.geode.admin.AdminException;\n@@ -47,7 +38,6 @@\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.internal.ClassBuilder;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.JarClassLoader;\n import org.apache.geode.internal.JarDeployer;\n import org.apache.geode.internal.cache.persistence.BackupManager;\n@@ -62,6 +52,22 @@\n import org.apache.geode.test.dunit.WaitCriterion;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileFilter;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.nio.file.Files;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.regex.Pattern;\n \n /**\n  * Tests for the incremental backup feature.\n@@ -105,7 +111,7 @@ public void run() {\n   };\n \n   protected RegionFactory<Integer, String> getRegionFactory(Cache cache) {\n-    return cache.<Integer, String>createRegionFactory(RegionShortcut.PARTITION_PERSISTENT);\n+    return cache.createRegionFactory(RegionShortcut.PARTITION_PERSISTENT);\n   }\n \n   /**\n@@ -376,7 +382,7 @@ public Object call() {\n       }\n     });\n \n-    final Set<PersistentID> missingMembers = new HashSet<PersistentID>();\n+    final Set<PersistentID> missingMembers = new HashSet<>();\n     Wait.waitForCriterion(new WaitCriterion() {\n       @Override\n       public boolean done() {\n@@ -415,7 +421,7 @@ private void waitForBackup(VM vm) {\n       public void run() {\n         Collection<DiskStoreImpl> backupInProgress =\n             ((GemFireCacheImpl) getCache()).listDiskStores();\n-        List<DiskStoreImpl> backupCompleteList = new LinkedList<DiskStoreImpl>();\n+        List<DiskStoreImpl> backupCompleteList = new LinkedList<>();\n \n         while (backupCompleteList.size() < backupInProgress.size()) {\n           for (DiskStoreImpl diskStore : backupInProgress) {\n@@ -497,7 +503,7 @@ private File getBackupDirForMember(final File rootDir, final String memberId) {\n     File[] memberDirs = dateDirs[0].listFiles(new FileFilter() {\n       @Override\n       public boolean accept(File file) {\n-        return (file.isDirectory() && (file.getName().indexOf(memberId) != -1));\n+        return (file.isDirectory() && (file.getName().contains(memberId)));\n       }\n     });\n \n@@ -578,9 +584,7 @@ public void run() {\n       }\n     }).start();\n \n-    int result = process.waitFor();\n-\n-    return result;\n+    return process.waitFor();\n   }\n \n   /**\n@@ -593,15 +597,17 @@ private void performRestore(File memberDir, File backupDir) throws Exception {\n      * The restore script will not restore if there is an if file in the copy to directory. Remove\n      * these files first.\n      */\n-    List<File> ifFiles = FileUtil.findAll(memberDir, \".*\\\\.if$\");\n+    Collection<File> ifFiles = FileUtils.listFiles(memberDir, new RegexFileFilter(\".*\\\\.if$\"),\n+        DirectoryFileFilter.DIRECTORY);\n     for (File file : ifFiles) {\n       file.delete();\n     }\n \n     /*\n      * Remove all operation logs.\n      */\n-    List<File> oplogs = FileUtil.findAll(memberDir, OPLOG_REGEX);\n+    Collection<File> oplogs = FileUtils.listFiles(memberDir, new RegexFileFilter(OPLOG_REGEX),\n+        DirectoryFileFilter.DIRECTORY);\n     for (File file : oplogs) {\n       file.delete();\n     }\n@@ -688,9 +694,9 @@ public final void postSetUp() throws Exception {\n    */\n   @Override\n   public final void preTearDownCacheTestCase() throws Exception {\n-    FileUtil.delete(getIncremental2Dir());\n-    FileUtil.delete(getIncrementalDir());\n-    FileUtil.delete(getBaselineDir());\n+    FileUtils.deleteDirectory(getIncremental2Dir());\n+    FileUtils.deleteDirectory(getIncrementalDir());\n+    FileUtils.deleteDirectory(getBaselineDir());\n   }\n \n   /**\n@@ -709,19 +715,21 @@ public void testIncrementalBackup() throws Exception {\n     assertNotNull(memberDir);\n \n     // Find all of the member's oplogs in the disk directory (*.crf,*.krf,*.drf)\n-    List<File> memberOplogFiles = FileUtil.findAll(memberDir, OPLOG_REGEX);\n+    Collection<File> memberOplogFiles = FileUtils.listFiles(memberDir,\n+        new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberOplogFiles.isEmpty());\n \n     // Perform a full backup and wait for it to finish\n     assertBackupStatus(performBaseline());\n     waitForBackup(Host.getHost(0).getVM(1));\n \n     // Find all of the member's oplogs in the baseline (*.crf,*.krf,*.drf)\n-    List<File> memberBaselineOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getBaselineDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberBaselineOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getBaselineDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberBaselineOplogs.isEmpty());\n \n-    List<String> memberBaselineOplogNames = new LinkedList<String>();\n+    List<String> memberBaselineOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberBaselineOplogs, memberBaselineOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -731,11 +739,12 @@ public void testIncrementalBackup() throws Exception {\n     waitForBackup(Host.getHost(0).getVM(1));\n \n     // Find all of the member's oplogs in the incremental (*.crf,*.krf,*.drf)\n-    List<File> memberIncrementalOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getIncrementalDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberIncrementalOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getIncrementalDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberIncrementalOplogs.isEmpty());\n \n-    List<String> memberIncrementalOplogNames = new LinkedList<String>();\n+    List<String> memberIncrementalOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberIncrementalOplogs, memberIncrementalOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -755,11 +764,12 @@ public void testIncrementalBackup() throws Exception {\n     assertBackupStatus(performIncremental2());\n     waitForBackup(Host.getHost(0).getVM(1));\n \n-    List<File> memberIncremental2Oplogs =\n-        FileUtil.findAll(getBackupDirForMember(getIncremental2Dir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberIncremental2Oplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getIncremental2Dir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberIncremental2Oplogs.isEmpty());\n \n-    List<String> memberIncremental2OplogNames = new LinkedList<String>();\n+    List<String> memberIncremental2OplogNames = new LinkedList<>();\n     TransformUtils.transform(memberIncremental2Oplogs, memberIncremental2OplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -792,9 +802,10 @@ public void testIncrementalBackup() throws Exception {\n     /*\n      * Collect all of the restored operation logs.\n      */\n-    List<File> restoredOplogs = FileUtil.findAll(new File(id.getDirectory()), OPLOG_REGEX);\n+    Collection<File> restoredOplogs = FileUtils.listFiles(new File(id.getDirectory()),\n+        new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(restoredOplogs.isEmpty());\n-    List<String> restoredOplogNames = new LinkedList<String>();\n+    List<String> restoredOplogNames = new LinkedList<>();\n     TransformUtils.transform(restoredOplogs, restoredOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -854,8 +865,9 @@ public void testMissingMemberInBaseline() throws Exception {\n \n     // Find all of the member's oplogs in the missing member's diskstore directory structure\n     // (*.crf,*.krf,*.drf)\n-    List<File> missingMemberOplogFiles =\n-        FileUtil.findAll(new File(missingMember.getDirectory()), OPLOG_REGEX);\n+    Collection<File> missingMemberOplogFiles =\n+        FileUtils.listFiles(new File(missingMember.getDirectory()),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(missingMemberOplogFiles.isEmpty());\n \n     /*\n@@ -866,7 +878,7 @@ public void testMissingMemberInBaseline() throws Exception {\n     /*\n      * After reconnecting make sure the other members agree that the missing member is back online.\n      */\n-    final Set<PersistentID> missingMembers = new HashSet<PersistentID>();\n+    final Set<PersistentID> missingMembers = new HashSet<>();\n     Wait.waitForCriterion(new WaitCriterion() {\n       @Override\n       public boolean done() {\n@@ -897,16 +909,17 @@ public String description() {\n \n     // Get list of backed up oplog files in the incremental backup for the missing member\n     File incrementalMemberDir = getBackupDirForMember(getIncrementalDir(), memberId);\n-    List<File> backupOplogFiles = FileUtil.findAll(incrementalMemberDir, OPLOG_REGEX);\n+    Collection<File> backupOplogFiles = FileUtils.listFiles(incrementalMemberDir,\n+        new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(backupOplogFiles.isEmpty());\n \n     // Transform missing member oplogs to just their file names.\n-    List<String> missingMemberOplogNames = new LinkedList<String>();\n+    List<String> missingMemberOplogNames = new LinkedList<>();\n     TransformUtils.transform(missingMemberOplogFiles, missingMemberOplogNames,\n         TransformUtils.fileNameTransformer);\n \n     // Transform missing member's incremental backup oplogs to just their file names.\n-    List<String> backupOplogNames = new LinkedList<String>();\n+    List<String> backupOplogNames = new LinkedList<>();\n     TransformUtils.transform(backupOplogFiles, backupOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -932,11 +945,12 @@ public void testIncompleteInBaseline() throws Exception {\n     /*\n      * Find all of the member's oplogs in the baseline (*.crf,*.krf,*.drf)\n      */\n-    List<File> memberBaselineOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getBaselineDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberBaselineOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getBaselineDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberBaselineOplogs.isEmpty());\n \n-    List<String> memberBaselineOplogNames = new LinkedList<String>();\n+    List<String> memberBaselineOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberBaselineOplogs, memberBaselineOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -952,11 +966,12 @@ public void testIncompleteInBaseline() throws Exception {\n     /*\n      * Find all of the member's oplogs in the incremental (*.crf,*.krf,*.drf)\n      */\n-    List<File> memberIncrementalOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getIncrementalDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberIncrementalOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getIncrementalDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberIncrementalOplogs.isEmpty());\n \n-    List<String> memberIncrementalOplogNames = new LinkedList<String>();\n+    List<String> memberIncrementalOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberIncrementalOplogs, memberIncrementalOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -984,11 +999,12 @@ public void testMissingBaseline() throws Exception {\n     /*\n      * Find all of the member's oplogs in the baseline (*.crf,*.krf,*.drf)\n      */\n-    List<File> memberBaselineOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getBaselineDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberBaselineOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getBaselineDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberBaselineOplogs.isEmpty());\n \n-    List<String> memberBaselineOplogNames = new LinkedList<String>();\n+    List<String> memberBaselineOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberBaselineOplogs, memberBaselineOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -1021,17 +1037,18 @@ public Object call() {\n      * Do an incremental after deleting the baseline. It should discover that the baseline is gone\n      * and backup all of the operation logs that are in the baseline.\n      */\n-    FileUtil.delete(getBaselineDir());\n+    FileUtils.deleteDirectory(getBaselineDir());\n     Host.getHost(0).getVM(1).invoke(callable);\n \n     /*\n      * Find all of the member's oplogs in the incremental (*.crf,*.krf,*.drf)\n      */\n-    List<File> memberIncrementalOplogs =\n-        FileUtil.findAll(getBackupDirForMember(getIncrementalDir(), memberId), OPLOG_REGEX);\n+    Collection<File> memberIncrementalOplogs =\n+        FileUtils.listFiles(getBackupDirForMember(getIncrementalDir(), memberId),\n+            new RegexFileFilter(OPLOG_REGEX), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberIncrementalOplogs.isEmpty());\n \n-    List<String> memberIncrementalOplogNames = new LinkedList<String>();\n+    List<String> memberIncrementalOplogNames = new LinkedList<>();\n     TransformUtils.transform(memberIncrementalOplogs, memberIncrementalOplogNames,\n         TransformUtils.fileNameTransformer);\n \n@@ -1078,8 +1095,9 @@ public Object call() throws Exception {\n     /*\n      * Make sure the user deployed jar is part of the backup.\n      */\n-    List<File> memberDeployedJarFiles =\n-        FileUtil.findAll(getBackupDirForMember(getBaselineDir(), getMemberId(vm0)), jarNameRegex);\n+    Collection<File> memberDeployedJarFiles =\n+        FileUtils.listFiles(getBackupDirForMember(getBaselineDir(), getMemberId(vm0)),\n+            new RegexFileFilter(jarNameRegex), DirectoryFileFilter.DIRECTORY);\n     assertFalse(memberDeployedJarFiles.isEmpty());\n \n     // Shut down our member so we can perform a restore\n@@ -1103,21 +1121,23 @@ public Object call() throws Exception {\n     /*\n      * Cleanup \"dummy\" jar from file system.\n      */\n-    FileUtil.deleteMatching(new File(vmDir), \"^\" + JarDeployer.JAR_PREFIX + jarName + \".*#\\\\d++$\");\n+    Pattern pattern = Pattern.compile(\"^\" + JarDeployer.JAR_PREFIX + jarName + \".*#\\\\d++$\");\n+    deleteMatching(new File(\".\"), pattern);\n \n     // Execute the restore\n     performRestore(new File(id.getDirectory()), backupDir);\n \n     /*\n      * Make sure the user deployed jar is part of the restore.\n      */\n-    List<File> restoredJars = FileUtil.findAll(new File(vmDir), jarNameRegex);\n+    Collection<File> restoredJars = FileUtils.listFiles(new File(vmDir),\n+        new RegexFileFilter(jarNameRegex), DirectoryFileFilter.DIRECTORY);\n     assertFalse(restoredJars.isEmpty());\n-    List<String> restoredJarNames = new LinkedList<String>();\n+    List<String> restoredJarNames = new LinkedList<>();\n     TransformUtils.transform(memberDeployedJarFiles, restoredJarNames,\n         TransformUtils.fileNameTransformer);\n     for (String name : restoredJarNames) {\n-      assertTrue(name.indexOf(jarName) != -1);\n+      assertTrue(name.contains(jarName));\n     }\n \n     // Restart the member\n@@ -1142,6 +1162,15 @@ public Object call() throws Exception {\n     /*\n      * Cleanup \"dummy\" jar from file system.\n      */\n-    FileUtil.deleteMatching(new File(vmDir), \"^\" + JarDeployer.JAR_PREFIX + jarName + \".*#\\\\d++$\");\n+    pattern = Pattern.compile(\"^\" + JarDeployer.JAR_PREFIX + jarName + \".*#\\\\d++$\");\n+    deleteMatching(new File(vmDir), pattern);\n+  }\n+\n+  private void deleteMatching(File dir, final Pattern pattern) throws IOException {\n+    Collection<File> files =\n+        FileUtils.listFiles(dir, new RegexFileFilter(pattern), DirectoryFileFilter.DIRECTORY);\n+    for (File file : files) {\n+      Files.delete(file.toPath());\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/IncrementalBackupDUnitTest.java",
                "sha": "0cc003ebd15628ea62a67a36c1ac595fe0a02693",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/OplogRVVJUnitTest.java",
                "changes": 42,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/OplogRVVJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 19,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/OplogRVVJUnitTest.java",
                "patch": "@@ -14,13 +14,17 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import java.io.File;\n-import java.net.UnknownHostException;\n-import java.util.Collections;\n-import java.util.EnumSet;\n-import java.util.HashMap;\n-import java.util.Map;\n+import static org.junit.Assert.assertEquals;\n \n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.StatisticsFactory;\n+import org.apache.geode.i18n.LogWriterI18n;\n+import org.apache.geode.internal.cache.DiskInitFile.DiskRegionFlag;\n+import org.apache.geode.internal.cache.DiskStoreImpl.OplogEntryIdSet;\n+import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n+import org.apache.geode.internal.cache.persistence.DiskStoreID;\n+import org.apache.geode.internal.cache.versions.DiskRegionVersionVector;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n import org.jmock.Expectations;\n import org.jmock.Mockery;\n import org.jmock.lib.legacy.ClassImposteriser;\n@@ -31,15 +35,13 @@\n import org.junit.experimental.categories.Category;\n import org.junit.rules.TemporaryFolder;\n \n-import org.apache.geode.StatisticsFactory;\n-import org.apache.geode.i18n.LogWriterI18n;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.internal.cache.DiskInitFile.DiskRegionFlag;\n-import org.apache.geode.internal.cache.DiskStoreImpl.OplogEntryIdSet;\n-import org.apache.geode.internal.cache.persistence.DiskRecoveryStore;\n-import org.apache.geode.internal.cache.persistence.DiskStoreID;\n-import org.apache.geode.internal.cache.versions.DiskRegionVersionVector;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n+import java.io.File;\n+import java.net.UnknownHostException;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.HashMap;\n+import java.util.Map;\n \n @Category(IntegrationTest.class)\n public class OplogRVVJUnitTest {\n@@ -174,10 +176,12 @@ public void testRecoverRVV() throws UnknownHostException {\n     });\n \n     oplog = new Oplog(1, oplogSet);\n-    File drfFile = FileUtil.find(testDirectory, \".*.drf\");\n-    File crfFile = FileUtil.find(testDirectory, \".*.crf\");\n-    oplog.addRecoveredFile(drfFile, dirHolder);\n-    oplog.addRecoveredFile(crfFile, dirHolder);\n+    Collection<File> drfFiles = FileUtils.listFiles(testDirectory, new String[] {\"drf\"}, true);\n+    assertEquals(1, drfFiles.size());\n+    Collection<File> crfFiles = FileUtils.listFiles(testDirectory, new String[] {\"crf\"}, true);\n+    assertEquals(1, crfFiles.size());\n+    oplog.addRecoveredFile(drfFiles.iterator().next(), dirHolder);\n+    oplog.addRecoveredFile(crfFiles.iterator().next(), dirHolder);\n     OplogEntryIdSet deletedIds = new OplogEntryIdSet();\n     oplog.recoverDrf(deletedIds, false, true);\n     oplog.recoverCrf(deletedIds, true, true, false, Collections.singleton(oplog), true);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/OplogRVVJUnitTest.java",
                "sha": "65833c402da8f8e4b43e0e071cb8fb2581571c58",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionStatsJUnitTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionStatsJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionStatsJUnitTest.java",
                "patch": "@@ -22,17 +22,7 @@\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n \n-import java.io.File;\n-import java.io.IOException;\n-import java.util.Iterator;\n-import java.util.Random;\n-import java.util.Set;\n-\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n-\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.LogWriter;\n import org.apache.geode.Statistics;\n import org.apache.geode.cache.AttributesFactory;\n@@ -43,8 +33,17 @@\n import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.PartitionedRegionStorageException;\n import org.apache.geode.cache.RegionExistsException;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.Random;\n+import java.util.Set;\n \n /**\n  *  \n@@ -62,7 +61,7 @@ public void setUp() {\n   @After\n   public void tearDown() throws IOException {\n     PartitionedRegionTestHelper.closeCache();\n-    FileUtil.delete(DISK_DIR);\n+    FileUtils.deleteDirectory(DISK_DIR);\n   }\n \n   private PartitionedRegion createPR(String name, int lmax, int redundancy) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionStatsJUnitTest.java",
                "sha": "e433771a14ee41b69859f230290c23e287047fcb",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/PersistentPartitionedRegionJUnitTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/PersistentPartitionedRegionJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/PersistentPartitionedRegionJUnitTest.java",
                "patch": "@@ -14,9 +14,24 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import org.apache.geode.cache.*;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.EntryNotFoundException;\n+import org.apache.geode.cache.EvictionAction;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.ExpirationAction;\n+import org.apache.geode.cache.ExpirationAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.util.ObjectSizer;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n import org.junit.After;\n import org.junit.Before;\n@@ -27,10 +42,6 @@\n import java.util.Properties;\n import java.util.concurrent.CountDownLatch;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.fail;\n-\n @Category(IntegrationTest.class)\n public class PersistentPartitionedRegionJUnitTest {\n \n@@ -48,7 +59,7 @@ public void tearDown() throws Exception {\n     if (cache != null && !cache.isClosed()) {\n       cache.close();\n     }\n-    FileUtil.delete(dir);\n+    FileUtils.deleteDirectory(dir);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/PersistentPartitionedRegionJUnitTest.java",
                "sha": "bfdf1c025ed5ae06c69b2e3840e0fde34af23f09",
                "status": "modified"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentColocatedPartitionedRegionDUnitTest.java",
                "changes": 55,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentColocatedPartitionedRegionDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 29,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentColocatedPartitionedRegionDUnitTest.java",
                "patch": "@@ -14,39 +14,19 @@\n  */\n package org.apache.geode.internal.cache.partitioned;\n \n-import org.junit.experimental.categories.Category;\n-import org.mockito.ArgumentCaptor;\n-import org.apache.logging.log4j.Level;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.core.Appender;\n-import org.apache.logging.log4j.core.LogEvent;\n-import org.apache.logging.log4j.core.Logger;\n-import org.junit.Test;\n-\n-import static org.junit.Assert.*;\n-\n import static org.awaitility.Awaitility.await;\n-\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n import static org.mockito.Mockito.atLeastOnce;\n import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.verifyNoMoreInteractions;\n import static org.mockito.Mockito.when;\n-import static org.mockito.Mockito.times;\n-\n-import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n-import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n-import org.apache.geode.test.junit.categories.DistributedTest;\n-\n-import java.io.IOException;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Set;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicBoolean;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.admin.internal.AdminDistributedSystemImpl;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n@@ -64,7 +44,6 @@\n import org.apache.geode.distributed.internal.DistributionMessage;\n import org.apache.geode.distributed.internal.DistributionMessageObserver;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.ColocationLogger;\n import org.apache.geode.internal.cache.InitialImageOperation.RequestImageMessage;\n import org.apache.geode.internal.cache.PartitionedRegion;\n@@ -73,16 +52,34 @@\n import org.apache.geode.internal.cache.control.InternalResourceManager.ResourceObserver;\n import org.apache.geode.test.dunit.Assert;\n import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.IgnoredException;\n import org.apache.geode.test.dunit.LogWriterUtils;\n import org.apache.geode.test.dunit.RMIException;\n-import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.SerializableCallable;\n import org.apache.geode.test.dunit.SerializableRunnable;\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.Wait;\n import org.apache.geode.test.dunit.WaitCriterion;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n import org.apache.geode.test.junit.categories.FlakyTest;\n+import org.apache.logging.log4j.Level;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.core.Appender;\n+import org.apache.logging.log4j.core.LogEvent;\n+import org.apache.logging.log4j.core.Logger;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.mockito.ArgumentCaptor;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n \n @Category(DistributedTest.class)\n public class PersistentColocatedPartitionedRegionDUnitTest\n@@ -105,7 +102,7 @@ public PersistentColocatedPartitionedRegionDUnitTest() {\n \n   @Override\n   public final void preTearDownCacheTestCase() throws Exception {\n-    FileUtil.delete(getBackupDir());\n+    FileUtils.deleteDirectory(getBackupDir());\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentColocatedPartitionedRegionDUnitTest.java",
                "sha": "8748df6bdc33584952476f9e936a62bb39cbdb79",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentPartitionedRegionTestBase.java",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentPartitionedRegionTestBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 15,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentPartitionedRegionTestBase.java",
                "patch": "@@ -14,20 +14,11 @@\n  */\n package org.apache.geode.internal.cache.partitioned;\n \n-import static org.apache.geode.test.dunit.Assert.*;\n-\n-import java.io.BufferedReader;\n-import java.io.File;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.InputStreamReader;\n-import java.net.InetAddress;\n-import java.util.List;\n-import java.util.Set;\n-import java.util.TreeSet;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n \n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.filefilter.DirectoryFileFilter;\n+import org.apache.commons.io.filefilter.RegexFileFilter;\n import org.apache.geode.admin.AdminDistributedSystem;\n import org.apache.geode.admin.AdminDistributedSystemFactory;\n import org.apache.geode.admin.AdminException;\n@@ -45,7 +36,6 @@\n import org.apache.geode.cache.partition.PartitionRegionInfo;\n import org.apache.geode.cache.persistence.PersistentID;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.DiskRegion;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.PartitionedRegion;\n@@ -65,6 +55,18 @@\n import org.apache.geode.test.dunit.WaitCriterion;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n \n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.net.InetAddress;\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n public abstract class PersistentPartitionedRegionTestBase extends JUnit4CacheTestCase {\n \n   public static String PR_REGION_NAME = \"region\";\n@@ -774,7 +776,8 @@ public Object call() {\n   }\n \n   protected void restoreBackup(int expectedNumScripts) throws IOException, InterruptedException {\n-    List<File> restoreScripts = FileUtil.findAll(getBackupDir(), \".*restore.*\");\n+    Collection<File> restoreScripts = FileUtils.listFiles(getBackupDir(),\n+        new RegexFileFilter(\".*restore.*\"), DirectoryFileFilter.DIRECTORY);\n     assertEquals(\"Restore scripts \" + restoreScripts, expectedNumScripts, restoreScripts.size());\n     for (File script : restoreScripts) {\n       execute(script);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/PersistentPartitionedRegionTestBase.java",
                "sha": "ccdd38df1732f4d1b4a574533aa7e0d2c04fafba",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/fixed/FixedPartitioningTestBase.java",
                "changes": 40,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/fixed/FixedPartitioningTestBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 18,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/fixed/FixedPartitioningTestBase.java",
                "patch": "@@ -14,23 +14,15 @@\n  */\n package org.apache.geode.internal.cache.partitioned.fixed;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.text.ParseException;\n-import java.text.SimpleDateFormat;\n-import java.util.Date;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Locale;\n-import java.util.Properties;\n-import java.util.Set;\n-\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.commons.lang.StringUtils;\n-import org.junit.experimental.categories.Category;\n-\n import org.apache.geode.SystemFailure;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n@@ -48,7 +40,6 @@\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.FixedPartitionAttributesImpl;\n import org.apache.geode.internal.cache.HARegion;\n import org.apache.geode.internal.cache.PartitionRegionConfig;\n@@ -70,6 +61,19 @@\n import org.apache.geode.test.dunit.WaitCriterion;\n import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Properties;\n+import java.util.Set;\n \n /**\n  * This is the base class to do operations\n@@ -1285,7 +1289,7 @@ protected synchronized static void remoteTearDown() {\n   }\n \n   public static void cleanDiskDirs() throws IOException {\n-    FileUtil.delete(getDiskDir());\n+    FileUtils.deleteDirectory(getDiskDir());\n   }\n \n   public static void closeCache() {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/fixed/FixedPartitioningTestBase.java",
                "sha": "5d4096e17fc36c12768bb6f8d5871ad594959441",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/BackupInspectorJUnitTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/BackupInspectorJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 9,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/persistence/BackupInspectorJUnitTest.java",
                "patch": "@@ -14,22 +14,22 @@\n  */\n package org.apache.geode.internal.cache.persistence;\n \n-import static org.junit.Assert.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n \n-import java.io.File;\n-import java.io.IOException;\n-import java.io.PrintWriter;\n-import java.util.Set;\n-\n-import org.junit.After;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n import org.junit.rules.TemporaryFolder;\n \n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.util.Set;\n \n /**\n  * TODO: fails when running integrationTest from gradle command-line on Windows 7",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/BackupInspectorJUnitTest.java",
                "sha": "5fd35852c122e739746aca31375cde447fe399fd",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/PersistentReplicatedTestBase.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/PersistentReplicatedTestBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/persistence/PersistentReplicatedTestBase.java",
                "patch": "@@ -14,21 +14,16 @@\n  */\n package org.apache.geode.internal.cache.persistence;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.util.Map;\n-import java.util.Set;\n+import static org.junit.Assert.fail;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.DataPolicy;\n import org.apache.geode.cache.DiskStore;\n import org.apache.geode.cache.DiskStoreFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.Scope;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.test.dunit.AsyncInvocation;\n import org.apache.geode.test.dunit.Invoke;\n@@ -38,6 +33,11 @@\n import org.apache.geode.test.dunit.WaitCriterion;\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Set;\n+\n public abstract class PersistentReplicatedTestBase extends JUnit4CacheTestCase {\n \n   protected static final int MAX_WAIT = 30 * 1000;\n@@ -51,7 +51,7 @@ public final void postSetUp() throws Exception {\n         new Object[] {getUniqueName()});\n     setRegionName(getUniqueName());\n     diskDir = new File(\"diskDir-\" + getName()).getAbsoluteFile();\n-    org.apache.geode.internal.FileUtil.delete(diskDir);\n+    FileUtils.deleteDirectory(diskDir);\n     diskDir.mkdir();\n     diskDir.deleteOnExit();\n   }\n@@ -62,7 +62,7 @@ public static void setRegionName(String testName) {\n \n   @Override\n   public final void postTearDownCacheTestCase() throws Exception {\n-    org.apache.geode.internal.FileUtil.delete(diskDir);\n+    FileUtils.deleteDirectory(diskDir);\n     postTearDownPersistentReplicatedTestBase();\n   }\n \n@@ -216,16 +216,16 @@ protected File getDiskDirForVM(final VM vm) {\n   protected void backupDir(VM vm) throws IOException {\n     File dirForVM = getDiskDirForVM(vm);\n     File backFile = new File(dirForVM.getParent(), dirForVM.getName() + \".bk\");\n-    FileUtil.copy(dirForVM, backFile);\n+    FileUtils.copyDirectory(dirForVM, backFile);\n   }\n \n   protected void restoreBackup(VM vm) throws IOException {\n     File dirForVM = getDiskDirForVM(vm);\n     File backFile = new File(dirForVM.getParent(), dirForVM.getName() + \".bk\");\n     if (!backFile.renameTo(dirForVM)) {\n-      FileUtil.delete(dirForVM);\n-      FileUtil.copy(backFile, dirForVM);\n-      FileUtil.delete(backFile);\n+      FileUtils.deleteDirectory(dirForVM);\n+      FileUtils.copyDirectory(backFile, dirForVM);\n+      FileUtils.deleteDirectory(backFile);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/persistence/PersistentReplicatedTestBase.java",
                "sha": "4c827423df33915e9e085c7a1465f475f75675d2",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgrade2DUnitTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgrade2DUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgrade2DUnitTest.java",
                "patch": "@@ -19,6 +19,7 @@\n import static org.apache.geode.test.dunit.Assert.assertTrue;\n import static org.apache.geode.test.dunit.Assert.fail;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.DataPolicy;\n@@ -48,7 +49,6 @@\n import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.internal.AvailablePortHelper;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.DiskInitFile;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n@@ -149,7 +149,7 @@ private void deleteVMFiles() throws Exception {\n     File pwd = new File(\".\");\n     for (File entry : pwd.listFiles()) {\n       try {\n-        FileUtil.delete(entry);\n+        FileUtils.deleteDirectory(entry);\n       } catch (Exception e) {\n         System.out.println(\"Could not delete \" + entry + \": \" + e.getMessage());\n       }\n@@ -1527,7 +1527,7 @@ public void run2() {\n \n   public void deleteDiskStores() throws Exception {\n     try {\n-      FileUtil.delete(new File(diskDir).getAbsoluteFile());\n+      FileUtils.deleteDirectory(new File(diskDir).getAbsoluteFile());\n     } catch (IOException e) {\n       throw new Error(\"Error deleting files\", e);\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgrade2DUnitTest.java",
                "sha": "54c6d94e4f27c66875776f218205494448f4abb9",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgradeDUnitTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgradeDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgradeDUnitTest.java",
                "patch": "@@ -14,11 +14,11 @@\n  */\n package org.apache.geode.internal.cache.rollingupgrade;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache30.CacheSerializableRunnable;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.internal.AvailablePortHelper;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.Version;\n import org.apache.geode.test.dunit.DistributedTestUtils;\n import org.apache.geode.test.dunit.Host;\n@@ -28,7 +28,6 @@\n import org.apache.geode.test.dunit.NetworkUtils;\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n-import org.apache.geode.test.dunit.standalone.DUnitLauncher;\n import org.apache.geode.test.dunit.standalone.VersionManager;\n import org.apache.geode.test.junit.categories.BackwardCompatibilityTest;\n import org.apache.geode.test.junit.categories.DistributedTest;\n@@ -98,7 +97,7 @@ private void deleteVMFiles() throws Exception {\n     File pwd = new File(\".\");\n     for (File entry : pwd.listFiles()) {\n       try {\n-        FileUtil.delete(entry);\n+        FileUtils.deleteDirectory(entry);\n       } catch (Exception e) {\n         System.out.println(\"Could not delete \" + entry + \": \" + e.getMessage());\n       }\n@@ -688,7 +687,7 @@ public void run2() {\n \n   public void deleteDiskStores() throws Exception {\n     try {\n-      FileUtil.delete(new File(diskDir).getAbsoluteFile());\n+      FileUtils.deleteDirectory(new File(diskDir).getAbsoluteFile());\n     } catch (IOException e) {\n       throw new Error(\"Error deleting files\", e);\n     }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/rollingupgrade/RollingUpgradeDUnitTest.java",
                "sha": "0940ea6661c55849cb9dc168327f6abca8c4292d",
                "status": "modified"
            },
            {
                "additions": 99,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/InterestListDUnitTest.java",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/InterestListDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/InterestListDUnitTest.java",
                "patch": "@@ -479,6 +479,80 @@ private void runRegisterInterestWithCacheLoaderTest(boolean addReplicatedRegion)\n     vm1.invoke(() -> InterestListDUnitTest.confirmNoCacheListenerInvalidates());\n   }\n \n+  @Test\n+  public void testRegisterInterestSingleKeyWithDestroyOnReplicatedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    keysToDestroy.add(\"0\");\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(true, keysToDestroy, keysToDestroy);\n+  }\n+\n+  @Test\n+  public void testRegisterInterestSingleKeyWithDestroyOnPartitionedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    keysToDestroy.add(\"0\");\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(false, keysToDestroy, keysToDestroy);\n+  }\n+\n+  @Test\n+  public void testRegisterInterestListOfKeysWithDestroyOnReplicatedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    for (int i = 0; i < 5; i++) {\n+      keysToDestroy.add(String.valueOf(i));\n+    }\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(true, keysToDestroy, keysToDestroy);\n+  }\n+\n+  @Test\n+  public void testRegisterInterestListOfKeysWithDestroyOnPartitionedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    for (int i = 0; i < 5; i++) {\n+      keysToDestroy.add(String.valueOf(i));\n+    }\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(false, keysToDestroy, keysToDestroy);\n+  }\n+\n+  @Test\n+  public void testRegisterInterestAllKeysWithDestroyOnReplicatedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    keysToDestroy.add(\"0\");\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(true, keysToDestroy, \"ALL_KEYS\");\n+  }\n+\n+  @Test\n+  public void testRegisterInterestAllKeysWithDestroyOnPartitionedRegionWithCacheLoader() {\n+    List keysToDestroy = new ArrayList();\n+    keysToDestroy.add(\"0\");\n+    runRegisterInterestWithDestroyAndCacheLoaderTest(false, keysToDestroy, \"ALL_KEYS\");\n+  }\n+\n+  private void runRegisterInterestWithDestroyAndCacheLoaderTest(boolean addReplicatedRegion,\n+      List keysToDestroy, Object keyToRegister) {\n+    // The server was already started with a replicated region. Bounce it if necessary\n+    int port1 = PORT1;\n+    if (!addReplicatedRegion) {\n+      vm0.invoke(() -> closeCache());\n+      port1 =\n+          ((Integer) vm0.invoke(() -> InterestListDUnitTest.createServerCache(addReplicatedRegion)))\n+              .intValue();\n+    }\n+    final int port = port1;\n+\n+    // Add a cache loader to the region\n+    vm0.invoke(() -> addCacheLoader());\n+\n+    // Create client cache\n+    vm1.invoke(() -> createClientCache(NetworkUtils.getServerHostName(vm0.getHost()), port));\n+\n+    // Destroy appropriate key(s)\n+    vm1.invoke(() -> destroyKeys(keysToDestroy));\n+\n+    // Register interest in appropriate keys(s)\n+    vm1.invoke(() -> registerKey(keyToRegister));\n+\n+    // Verify CacheLoader was not invoked\n+    vm0.invoke(() -> verifyNoCacheLoaderLoads());\n+  }\n+\n   private void createCache(Properties props) throws Exception {\n     DistributedSystem ds = getSystem(props);\n     cache = CacheFactory.create(ds);\n@@ -905,6 +979,20 @@ private static void putAgain(String vm) {\n     }\n   }\n \n+  private static void destroyKeys(List keys) {\n+    Region r = cache.getRegion(REGION_NAME);\n+    for (Object key : keys) {\n+      r.destroy(key);\n+    }\n+  }\n+\n+  private static void verifyNoCacheLoaderLoads() throws Exception {\n+    Region region = cache.getRegion(REGION_NAME);\n+    ReturnKeyCacheLoader cacheLoader =\n+        (ReturnKeyCacheLoader) region.getAttributes().getCacheLoader();\n+    assertEquals(0/* expected */, cacheLoader.getLoads()/* actual */);\n+  }\n+\n   private static void validateEntriesK1andK2(final String vm) {\n     WaitCriterion ev = new WaitCriterion() {\n       @Override\n@@ -1076,14 +1164,25 @@ public boolean hasReceivedAllCreateEvents() {\n \n   private static class ReturnKeyCacheLoader implements CacheLoader {\n \n+    private AtomicInteger loads = new AtomicInteger();\n+\n     @Override\n     public void close() {\n       // Do nothing\n     }\n \n     @Override\n     public Object load(LoaderHelper helper) throws CacheLoaderException {\n+      incrementLoads();\n       return helper.getKey();\n     }\n+\n+    private void incrementLoads() {\n+      this.loads.incrementAndGet();\n+    }\n+\n+    private int getLoads() {\n+      return this.loads.get();\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/InterestListDUnitTest.java",
                "sha": "d8164f1b3eb6a0be55e4022298a3860cc654426c",
                "status": "modified"
            },
            {
                "additions": 96,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandlerIntegrationTest.java",
                "changes": 96,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandlerIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandlerIntegrationTest.java",
                "patch": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ * \n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.io;\n+\n+import static org.assertj.core.api.Assertions.*;\n+\n+import java.util.regex.Pattern;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+\n+@Category(IntegrationTest.class)\n+public class MainWithChildrenRollingFileHandlerIntegrationTest {\n+\n+  private String name;\n+  private MainWithChildrenRollingFileHandler handler;\n+\n+  @Rule\n+  public TestName testName = new TestName();\n+\n+  @Before\n+  public void before() throws Exception {\n+    this.name = this.testName.getMethodName();\n+    this.handler = new MainWithChildrenRollingFileHandler();\n+  }\n+\n+  @Test\n+  public void getFilePattern_matchesFilesWithBothIds() throws Exception {\n+    Pattern pattern = this.handler.getFilePattern(this.name);\n+\n+    assertThat(pattern).isNotNull();\n+    assertThat(pattern.matcher(this.name).matches()).isFalse();\n+    assertThat(pattern.matcher(this.name + \"-01-01\").matches()).isTrue();\n+    assertThat(pattern.matcher(this.name + \"-01-02\").matches()).isTrue();\n+    assertThat(pattern.matcher(this.name + \"-02-01\").matches()).isTrue();\n+    assertThat(pattern.matcher(this.name + \"-01\").matches()).isFalse();\n+    assertThat(pattern.matcher(this.name + \"0101\").matches()).isFalse();\n+    assertThat(pattern.matcher(this.name + \"--\").matches()).isFalse();\n+\n+    // TODO: revisit these to determine if behavior should change\n+    assertThat(pattern.matcher(this.name + \"-01-01-01\").matches()).isFalse();\n+    assertThat(pattern.matcher(this.name + \".01-01-01\").matches()).isFalse();\n+  }\n+\n+  @Test\n+  public void getFilePattern_withNumbers_matchesFiles() throws Exception {\n+    this.name = \"a1s2d3f4_cache1_statistics\";\n+    Pattern pattern = this.handler.getFilePattern(this.name);\n+\n+    assertThat(pattern).isNotNull();\n+    assertThat(pattern.matcher(this.name + \"-01-41\").matches()).isTrue();\n+  }\n+\n+  @Test\n+  public void getFilePattern_withHyphens_matchesFiles() throws Exception {\n+    this.name = \"a1s2d3f4_cache1-statistics\";\n+    Pattern pattern = this.handler.getFilePattern(this.name);\n+\n+    assertThat(pattern).isNotNull();\n+    assertThat(pattern.matcher(this.name + \"-01-41\").matches()).isTrue();\n+  }\n+\n+  @Test\n+  public void getFilePattern_empty_throwsIllegalArgumentException() throws Exception {\n+    this.name = \"\";\n+\n+    assertThatThrownBy(() -> this.handler.getFilePattern(this.name))\n+        .isInstanceOf(IllegalArgumentException.class);\n+  }\n+\n+  @Test\n+  public void getFilePattern_null_throwsIllegalArgumentException() throws Exception {\n+    this.name = null;\n+\n+    assertThatThrownBy(() -> this.handler.getFilePattern(this.name))\n+        .isInstanceOf(IllegalArgumentException.class);\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandlerIntegrationTest.java",
                "sha": "5ea77c4119b7551d0f2fd8283f5ce6108b3295a1",
                "status": "added"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/Log4J2PerformanceTest.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/Log4J2PerformanceTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 14,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/logging/log4j/Log4J2PerformanceTest.java",
                "patch": "@@ -14,16 +14,13 @@\n  */\n package org.apache.geode.internal.logging.log4j;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.FileNotFoundException;\n-import java.io.FileOutputStream;\n-import java.io.IOException;\n-import java.io.PrintWriter;\n-import java.net.URL;\n+import static org.junit.Assert.assertTrue;\n \n import org.apache.commons.io.FileUtils;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.internal.logging.LoggingPerformanceTestCase;\n+import org.apache.geode.internal.util.IOUtils;\n+import org.apache.geode.test.junit.categories.PerformanceTest;\n import org.apache.logging.log4j.Level;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n@@ -32,11 +29,12 @@\n import org.junit.Ignore;\n import org.junit.experimental.categories.Category;\n \n-import org.apache.geode.distributed.internal.DistributionConfig;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.internal.logging.LoggingPerformanceTestCase;\n-import org.apache.geode.internal.util.IOUtils;\n-import org.apache.geode.test.junit.categories.PerformanceTest;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.net.URL;\n \n @Category(PerformanceTest.class)\n @Ignore(\"Tests have no assertions\")\n@@ -101,7 +99,8 @@ protected Logger createLogger() throws IOException {\n \n     this.logFile = new File(this.configDirectory, DistributionConfig.GEMFIRE_PREFIX + \"log\");\n     final String logFilePath = IOUtils.tryGetCanonicalPathElseGetAbsolutePath(logFile);\n-    final String logFileName = FileUtil.stripOffExtension(logFilePath);\n+    final String logFileName =\n+        logFilePath.substring(0, logFilePath.lastIndexOf(File.separatorChar));\n     setPropertySubstitutionValues(logFileName, DEFAULT_LOG_FILE_SIZE_LIMIT,\n         DEFAULT_LOG_FILE_COUNT_LIMIT);\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/Log4J2PerformanceTest.java",
                "sha": "24cb6d84f7392cc9f7016697941cb4f6b3f812d1",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/LogWriterLoggerPerformanceTest.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/LogWriterLoggerPerformanceTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 14,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/logging/log4j/LogWriterLoggerPerformanceTest.java",
                "patch": "@@ -14,28 +14,26 @@\n  */\n package org.apache.geode.internal.logging.log4j;\n \n-import static org.junit.Assert.*;\n-\n-import java.io.File;\n-import java.io.FileNotFoundException;\n-import java.io.FileOutputStream;\n-import java.io.IOException;\n-import java.io.PrintWriter;\n-import java.net.URL;\n+import static org.junit.Assert.assertTrue;\n \n import org.apache.commons.io.FileUtils;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.internal.logging.LoggingPerformanceTestCase;\n+import org.apache.geode.internal.util.IOUtils;\n+import org.apache.geode.test.junit.categories.PerformanceTest;\n import org.apache.logging.log4j.Level;\n import org.apache.logging.log4j.Logger;\n import org.apache.logging.log4j.core.config.ConfigurationFactory;\n import org.junit.After;\n import org.junit.Ignore;\n import org.junit.experimental.categories.Category;\n \n-import org.apache.geode.distributed.internal.DistributionConfig;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.internal.logging.LoggingPerformanceTestCase;\n-import org.apache.geode.internal.util.IOUtils;\n-import org.apache.geode.test.junit.categories.PerformanceTest;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.net.URL;\n \n @Category(PerformanceTest.class)\n @Ignore(\"Tests have no assertions\")\n@@ -100,7 +98,8 @@ protected Logger createLogger() throws IOException {\n \n     this.logFile = new File(this.configDirectory, DistributionConfig.GEMFIRE_PREFIX + \"log\");\n     final String logFilePath = IOUtils.tryGetCanonicalPathElseGetAbsolutePath(logFile);\n-    final String logFileName = FileUtil.stripOffExtension(logFilePath);\n+    final String logFileName =\n+        logFilePath.substring(0, logFilePath.lastIndexOf(File.separatorChar));\n     setPropertySubstitutionValues(logFileName, DEFAULT_LOG_FILE_SIZE_LIMIT,\n         DEFAULT_LOG_FILE_COUNT_LIMIT);\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/LogWriterLoggerPerformanceTest.java",
                "sha": "31bdd95bacf77207b693b35ca6c0c380d16b85a1",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/net/SSLSocketIntegrationTest.java",
                "changes": 49,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/net/SSLSocketIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 24,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/net/SSLSocketIntegrationTest.java",
                "patch": "@@ -14,13 +14,31 @@\n  */\n package org.apache.geode.internal.net;\n \n-import static org.awaitility.Awaitility.*;\n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.apache.geode.internal.security.SecurableCommunicationChannel.*;\n-import static org.assertj.core.api.Assertions.*;\n-\n+import static org.apache.geode.distributed.ConfigurationProperties.CLUSTER_SSL_CIPHERS;\n+import static org.apache.geode.distributed.ConfigurationProperties.CLUSTER_SSL_ENABLED;\n+import static org.apache.geode.distributed.ConfigurationProperties.CLUSTER_SSL_PROTOCOLS;\n+import static org.apache.geode.distributed.ConfigurationProperties.CLUSTER_SSL_REQUIRE_AUTHENTICATION;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.internal.security.SecurableCommunicationChannel.CLUSTER;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.awaitility.Awaitility.await;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.distributed.internal.DistributionConfigImpl;\n+import org.apache.geode.internal.security.SecurableCommunicationChannel;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.apache.geode.test.junit.categories.MembershipTest;\n import org.awaitility.Awaitility;\n-import com.sun.tools.hat.internal.model.StackTrace;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.TestName;\n \n import java.io.File;\n import java.io.IOException;\n@@ -37,23 +55,6 @@\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicReference;\n \n-import org.apache.geode.internal.security.SecurableCommunicationChannel;\n-import org.apache.geode.test.junit.categories.MembershipTest;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n-import org.junit.experimental.categories.Category;\n-import org.junit.rules.ErrorCollector;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.TestName;\n-\n-import org.apache.geode.distributed.internal.DistributionConfig;\n-import org.apache.geode.distributed.internal.DistributionConfigImpl;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.junit.categories.IntegrationTest;\n-\n /**\n  * Integration tests for SocketCreatorFactory with SSL.\n  * <p>\n@@ -226,7 +227,7 @@ public File copyKeystoreResourceToFile(final String name) throws IOException {\n     assertThat(resource).isNotNull();\n \n     File file = this.temporaryFolder.newFile(name.replaceFirst(\".*/\", \"\"));\n-    FileUtil.copy(resource, file);\n+    FileUtils.copyFile(new File(resource.getFile()), file);\n     return file;\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/net/SSLSocketIntegrationTest.java",
                "sha": "a9bcab12c40b1d738ca1ba9c4fb36dc69f63ecda",
                "status": "modified"
            },
            {
                "additions": 235,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/DiskSpaceLimitIntegrationTest.java",
                "changes": 245,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/statistics/DiskSpaceLimitIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 10,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/statistics/DiskSpaceLimitIntegrationTest.java",
                "patch": "@@ -14,8 +14,10 @@\n  */\n package org.apache.geode.internal.statistics;\n \n+import static java.lang.String.valueOf;\n import static java.util.concurrent.TimeUnit.MINUTES;\n-import static org.apache.commons.io.FileUtils.moveFileToDirectory;\n+import static org.apache.commons.io.FileUtils.*;\n+import static org.apache.commons.lang.StringUtils.leftPad;\n import static org.assertj.core.api.Assertions.assertThat;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n@@ -37,9 +39,14 @@\n \n import java.io.File;\n import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n import java.util.concurrent.TimeoutException;\n \n @Category(IntegrationTest.class)\n+@SuppressWarnings(\"unused\")\n public class DiskSpaceLimitIntegrationTest {\n \n   private static final long FILE_SIZE_LIMIT = 256;\n@@ -48,16 +55,23 @@\n   private File dir;\n   private File dirOfDeletedFiles;\n \n+  private String name;\n+\n   private String archiveFileName;\n \n   private LocalStatisticsFactory factory;\n   private StatisticDescriptor[] statisticDescriptors;\n   private StatisticsType statisticsType;\n   private Statistics statistics;\n \n+  private RollingFileHandler testRollingFileHandler;\n+  private MainWithChildrenRollingFileHandler mainWithChildrenRollingFileHandler;\n+\n   private SampleCollector sampleCollector;\n   private StatArchiveHandlerConfig config;\n \n+  private long initTimeStamp;\n+\n   private NanoTimer timer = new NanoTimer();\n   private long nanosTimeStamp;\n \n@@ -69,10 +83,10 @@\n   @Before\n   public void setUp() throws Exception {\n     this.dir = this.temporaryFolder.getRoot();\n-    this.dirOfDeletedFiles = this.temporaryFolder.newFolder(\"deleted\");\n \n-    this.archiveFileName =\n-        new File(this.dir, this.testName.getMethodName() + \".gfs\").getAbsolutePath();\n+    this.name = this.testName.getMethodName();\n+\n+    this.archiveFileName = new File(this.dir, this.name + \".gfs\").getAbsolutePath();\n \n     this.factory = new LocalStatisticsFactory(null);\n     this.statisticDescriptors = new StatisticDescriptor[] {\n@@ -93,11 +107,12 @@ public void setUp() throws Exception {\n         .thenReturn(this.temporaryFolder.getRoot().getAbsolutePath());\n     when(this.config.getProductDescription()).thenReturn(this.testName.getMethodName());\n \n-    RollingFileHandler rollingFileHandler = new TestableRollingFileHandler();\n+    this.testRollingFileHandler = new TestableRollingFileHandler();\n+    this.mainWithChildrenRollingFileHandler = new MainWithChildrenRollingFileHandler();\n \n     this.sampleCollector = new SampleCollector(sampler);\n-    this.sampleCollector.initialize(this.config, NanoTimer.getTime(), rollingFileHandler);\n \n+    this.initTimeStamp = NanoTimer.getTime();\n     this.timer.reset();\n     this.nanosTimeStamp = this.timer.getLastResetTime() - getNanoRate();\n   }\n@@ -109,6 +124,9 @@ public void tearDown() throws Exception {\n \n   @Test\n   public void zeroKeepsAllFiles() throws Exception {\n+    this.dirOfDeletedFiles = this.temporaryFolder.newFolder(\"deleted\");\n+    this.sampleCollector.initialize(this.config, this.initTimeStamp, this.testRollingFileHandler);\n+\n     when(this.config.getArchiveDiskSpaceLimit()).thenReturn(0L);\n     sampleUntilFileExists(archiveFile(1));\n     sampleUntilFileExists(archiveFile(2));\n@@ -118,6 +136,9 @@ public void zeroKeepsAllFiles() throws Exception {\n \n   @Test\n   public void aboveZeroDeletesOldestFile() throws Exception {\n+    this.dirOfDeletedFiles = this.temporaryFolder.newFolder(\"deleted\");\n+    this.sampleCollector.initialize(this.config, this.initTimeStamp, this.testRollingFileHandler);\n+\n     when(this.config.getArchiveDiskSpaceLimit()).thenReturn(DISK_SPACE_LIMIT);\n     sampleUntilFileExists(archiveFile(1));\n     sampleUntilFileExists(archiveFile(2));\n@@ -138,6 +159,118 @@ public void aboveZeroDeletesOldestFile() throws Exception {\n     assertThat(everExisted(archiveFile(1))).isTrue();\n   }\n \n+  @Test\n+  public void aboveZeroDeletesPreviousFiles() throws Exception {\n+    assertThat(numberOfFiles(this.dir)).as(\"Unexpected files: \" + listFiles(this.dir)).isEqualTo(0);\n+\n+    int oldMainId = 1;\n+    int newMainId = 2;\n+\n+    int numberOfPreviousFiles = 100;\n+    int numberOfLines = 100;\n+    createPreviousFiles(oldMainId, numberOfPreviousFiles, numberOfLines);\n+    assertThat(numberOfFiles(this.dir)).as(\"Missing files: \" + listFiles(this.dir))\n+        .isEqualTo(numberOfPreviousFiles);\n+\n+    for (int childId = 1; childId <= numberOfPreviousFiles; childId++) {\n+      assertThat(archiveFile(oldMainId, childId)).exists();\n+    }\n+\n+    // current archive file does not exist yet\n+    assertThat(archiveFile()).doesNotExist();\n+\n+    // rolling files for mainId 2 do not exist yet\n+    assertThat(markerFile(newMainId)).doesNotExist();\n+    assertThat(archiveFile(newMainId, 1)).doesNotExist();\n+\n+    when(this.config.getArchiveDiskSpaceLimit())\n+        .thenReturn(sizeOfDirectory(this.dir) / numberOfPreviousFiles);\n+\n+    this.sampleCollector.initialize(this.config, this.initTimeStamp,\n+        this.mainWithChildrenRollingFileHandler);\n+\n+    assertThat(archiveFile()).exists().hasParent(this.dir);\n+    assertThat(markerFile(newMainId)).exists().hasParent(this.dir).hasBinaryContent(new byte[0]);\n+\n+    assertThat(archiveFile(newMainId, 1)).doesNotExist();\n+\n+    sampleNumberOfTimes(1);\n+\n+    sampleUntilFileExists(archiveFile(newMainId, 1));\n+    assertThat(archiveFile(newMainId, 1)).exists();\n+\n+    // this might be a brittle assertion... ok to delete if following for-block-assertion passes\n+    assertThat(numberOfFiles(this.dir)).as(\"Unexpected files: \" + listFiles(this.dir)).isEqualTo(2);\n+\n+    for (int childId = 1; childId <= numberOfPreviousFiles; childId++) {\n+      assertThat(archiveFile(oldMainId, childId)).doesNotExist();\n+    }\n+  }\n+\n+  @Test\n+  public void aboveZeroDeletesPreviousFiles_nameWithHyphen() throws Exception {\n+    this.name = \"psin8p724_cache1-statistics\";\n+    this.archiveFileName = new File(this.dir, this.name + \".gfs\").getAbsolutePath();\n+    when(this.config.getArchiveFileName()).thenReturn(new File(this.archiveFileName));\n+\n+    assertThat(numberOfFiles(this.dir)).as(\"Unexpected files: \" + listFiles(this.dir)).isEqualTo(0);\n+\n+    int oldMainId = 1;\n+    int newMainId = 2;\n+\n+    int numberOfPreviousFiles = 100;\n+    int numberOfLines = 100;\n+    createPreviousFiles(oldMainId, numberOfPreviousFiles, numberOfLines);\n+    assertThat(numberOfFiles(this.dir)).as(\"Missing files: \" + listFiles(this.dir))\n+        .isEqualTo(numberOfPreviousFiles);\n+\n+    for (int childId = 1; childId <= numberOfPreviousFiles; childId++) {\n+      assertThat(archiveFile(oldMainId, childId)).exists();\n+    }\n+\n+    // current archive file does not exist yet\n+    assertThat(archiveFile()).doesNotExist();\n+\n+    // rolling files for mainId 2 do not exist yet\n+    assertThat(markerFile(newMainId)).doesNotExist();\n+    assertThat(archiveFile(newMainId, 1)).doesNotExist();\n+\n+    when(this.config.getArchiveDiskSpaceLimit())\n+        .thenReturn(sizeOfDirectory(this.dir) / numberOfPreviousFiles);\n+\n+    this.sampleCollector.initialize(this.config, this.initTimeStamp,\n+        this.mainWithChildrenRollingFileHandler);\n+\n+    assertThat(archiveFile()).exists().hasParent(this.dir);\n+    assertThat(markerFile(newMainId)).exists().hasParent(this.dir).hasBinaryContent(new byte[0]);\n+\n+    assertThat(archiveFile(newMainId, 1)).doesNotExist();\n+\n+    sampleNumberOfTimes(1);\n+\n+    sampleUntilFileExists(archiveFile(newMainId, 1));\n+    assertThat(archiveFile(newMainId, 1)).exists();\n+\n+    // this might be a brittle assertion... ok to delete if following for-block-assertion passes\n+    assertThat(numberOfFiles(this.dir)).as(\"Unexpected files: \" + listFiles(this.dir)).isEqualTo(2);\n+\n+    for (int childId = 1; childId <= numberOfPreviousFiles; childId++) {\n+      assertThat(archiveFile(oldMainId, childId)).doesNotExist();\n+    }\n+  }\n+\n+  private void sampleNumberOfTimes(final int value) throws InterruptedException {\n+    long minutes = 1;\n+    long timeout = System.nanoTime() + MINUTES.toNanos(minutes);\n+    int count = 0;\n+    do {\n+      sample(advanceNanosTimeStamp());\n+      count++;\n+      Thread.sleep(10);\n+    } while (count < value && System.nanoTime() < timeout);\n+    System.out.println(\"Sampled \" + count + \" times.\");\n+  }\n+\n   private void sampleUntilFileExists(final File file)\n       throws InterruptedException, TimeoutException {\n     long minutes = 1;\n@@ -203,9 +336,102 @@ private long getSampleRate() {\n     return 1000; // 1 second\n   }\n \n-  private File archiveFile(final int child) {\n-    return new File(this.dir,\n-        this.testName.getMethodName() + \"-01-\" + String.format(\"%02d\", child) + \".gfs\");\n+  private File archiveFile() {\n+    return archiveFile(archiveName());\n+  }\n+\n+  private String archiveName() {\n+    return this.name;\n+  }\n+\n+  private File archiveFile(final String name) {\n+    return new File(this.dir, name + \".gfs\");\n+  }\n+\n+  private File archiveFile(final int childId) {\n+    return archiveFile(1, childId);\n+  }\n+\n+  private File archiveFile(final int mainId, final int childId) {\n+    return archiveFile(archiveName(), mainId, childId);\n+  }\n+\n+  private File archiveFile(final String name, final int mainId, final int childId) {\n+    return new File(this.dir, archiveName(name, mainId, childId) + \".gfs\");\n+  }\n+\n+  private String archiveName(final int mainId, final int childId) {\n+    return archiveName(archiveName(), mainId, childId);\n+  }\n+\n+  private String archiveName(final String name, final int mainId, final int childId) {\n+    return name + \"-\" + formatId(mainId) + \"-\" + formatId(childId);\n+  }\n+\n+  private File markerFile(final int mainId) {\n+    return markerFile(archiveName(), mainId);\n+  }\n+\n+  private File markerFile(final String name, final int mainId) {\n+    return new File(this.dir, markerName(name, mainId));\n+  }\n+\n+  private String markerName(final int mainId) {\n+    return markerName(archiveName(), mainId);\n+  }\n+\n+  private String markerName(final String name, final int mainId) {\n+    return archiveName(name, mainId, 0) + \".marker\";\n+  }\n+\n+  private String formatId(final int id) {\n+    return String.format(\"%02d\", id);\n+  }\n+\n+  private List<File> listFiles(final File dir) {\n+    return Arrays.asList(dir.listFiles());\n+  }\n+\n+  private int numberOfFiles(final File dir) {\n+    return dir.listFiles().length;\n+  }\n+\n+  private void createPreviousFiles(final int mainId, final int fileCount, final int lineCount)\n+      throws IOException {\n+    createPreviousFiles(this.name, mainId, fileCount, lineCount);\n+  }\n+\n+  private void createPreviousFiles(final String name, final int mainId, final int fileCount,\n+      final int lineCount) throws IOException {\n+    int childId = 1;\n+    List<String> lines = lines(lineCount);\n+    for (int i = 0; i < fileCount; i++) {\n+      File file = createFile(name, mainId, childId);\n+      writeFile(file, lines);\n+      childId++;\n+    }\n+  }\n+\n+  private File createFile(final String name, final int mainId, final int childId) {\n+    File file = new File(this.dir, name + \"-\" + leftPad(valueOf(mainId), 2, \"0\") + \"-\"\n+        + leftPad(valueOf(childId), 2, \"0\") + \".gfs\");\n+    return file;\n+  }\n+\n+  private void writeFile(final File file, final List<String> lines) throws IOException {\n+    PrintWriter writer = new PrintWriter(file, \"UTF-8\");\n+    for (String line : lines) {\n+      writer.println(line);\n+    }\n+    writer.close();\n+  }\n+\n+  private List<String> lines(final int lineCount) {\n+    List<String> lines = new ArrayList<>();\n+    for (int i = 0; i < lineCount; i++) {\n+      lines.add(this.testName.getMethodName());\n+    }\n+    return lines;\n   }\n \n   /**\n@@ -222,5 +448,4 @@ protected boolean delete(final File file) {\n       }\n     }\n   }\n-\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/DiskSpaceLimitIntegrationTest.java",
                "sha": "5d94fa0ba32aabc0f0bfc396d99d0b5ef9572360",
                "status": "modified"
            },
            {
                "additions": 243,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveHandlerIntegrationTest.java",
                "changes": 243,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveHandlerIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveHandlerIntegrationTest.java",
                "patch": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.statistics;\n+\n+import static org.assertj.core.api.Assertions.*;\n+import static org.mockito.Mockito.mock;\n+\n+import java.io.File;\n+import java.io.IOException;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.internal.io.MainWithChildrenRollingFileHandler;\n+import org.apache.geode.internal.io.RollingFileHandler;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+\n+/**\n+ * Tests behavior that interacts with file system.\n+ */\n+@Category(IntegrationTest.class)\n+@RunWith(JUnitParamsRunner.class)\n+public class StatArchiveHandlerIntegrationTest {\n+\n+  private File dir;\n+  private String ext;\n+  private String name;\n+  private File archive;\n+\n+  private StatArchiveHandlerConfig mockConfig;\n+  private SampleCollector mockCollector;\n+  private RollingFileHandler rollingFileHandler;\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public TestName testName = new TestName();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    this.dir = this.temporaryFolder.getRoot();\n+\n+    this.ext = \".gfs\";\n+    this.name = this.testName.getMethodName();\n+    this.archive = new File(this.dir, this.name + this.ext);\n+\n+    this.mockConfig = mock(StatArchiveHandlerConfig.class);\n+    this.mockCollector = mock(SampleCollector.class);\n+    this.rollingFileHandler = new MainWithChildrenRollingFileHandler();\n+  }\n+\n+  @Test\n+  @Parameters({\"false,false,false\", \"false,false,true\", \"false,true,false\", \"false,true,true\",\n+      \"true,false,false\", \"true,false,true\", \"true,true,false\", \"true,true,true\"})\n+  public void getRollingArchiveName_withEmptyDir_createsFirstIds(final boolean archiveExists,\n+      final boolean archiveClosed, final boolean initMainId) throws Exception {\n+    if (archiveExists) {\n+      this.archive.createNewFile();\n+    }\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    if (initMainId) {\n+      handler.initMainArchiveId(this.archive);\n+    }\n+\n+    File file = handler.getRollingArchiveName(this.archive, archiveClosed);\n+\n+    assertThat(file).hasParent(this.dir).hasName(this.name + formatIds(1, 1) + this.ext);\n+  }\n+\n+  @Test\n+  @Parameters({\"1,1,false,false\", \"1,1,false,true\", \"1,1,true,false\", \"1,1,true,true\",\n+      \"1,10,false,false\", \"1,10,false,true\", \"1,10,true,false\", \"1,10,true,true\",\n+      \"10,1,false,false\", \"10,1,false,true\", \"10,1,true,false\", \"10,1,true,true\",\n+      \"10,10,false,false\", \"10,10,false,true\", \"10,10,true,false\", \"10,10,true,true\"})\n+  public void getRollingArchiveName_withOldArchives_rollsChildId(final int mainCount,\n+      final int childCount, final boolean archiveExists, final boolean archiveClosed)\n+      throws Exception {\n+    createEmptyArchiveFiles(this.dir, this.name, this.ext, mainCount, childCount);\n+    if (archiveExists) {\n+      this.archive.createNewFile();\n+    }\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+\n+    File file = handler.getRollingArchiveName(this.archive, archiveClosed);\n+\n+    assertThat(file).hasParent(this.dir)\n+        .hasName(this.name + formatIds(mainCount, childCount + 1) + this.ext);\n+  }\n+\n+  @Test\n+  public void initMainArchiveId_withEmptyDir_createsMainId_createsFirstMarker() throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+\n+    handler.initMainArchiveId(this.archive);\n+\n+    assertThat(new File(this.dir, this.name + formatIds(1, 0) + \".marker\")).exists();\n+  }\n+\n+  @Test\n+  @Parameters({\"1,1\", \"1,10\", \"10,1\", \"10,10\"})\n+  public void initMainArchiveId_withOldArchives_rollsMainId_rollsMarker(final int mainCount,\n+      final int childCount) throws Exception {\n+    createEmptyArchiveFiles(this.dir, this.name, this.ext, mainCount, childCount);\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+\n+    handler.initMainArchiveId(this.archive);\n+\n+    assertThat(new File(this.dir, this.name + formatIds(mainCount + 1, 0) + \".marker\")).exists();\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withEmptyDir_createsFirstIds() throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).isNotNull().isEqualTo(new File(this.dir, this.name + \"-01-01\" + this.ext));\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withExtraneousIds_withEmptyDir_appendsIds() throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    this.archive = new File(this.dir, this.name + \"-01-01\" + this.ext);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).hasParent(this.dir).hasName(this.name + \"-01-01-01-01\" + this.ext);\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withExtraneousDots_withEmptyDir_appendsIds() throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    this.archive = new File(this.dir, this.name + \".test.test\" + this.ext);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).hasParent(this.dir).hasName(this.name + \".test.test-01-01\" + this.ext);\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withExtraneousUnderscores_withEptyDir_appendsIds()\n+      throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    this.archive = new File(this.dir, this.name + \"_test_test\" + this.ext);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).hasParent(this.dir).hasName(this.name + \"_test_test-01-01\" + this.ext);\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withExtraneousHyphens_withEmptyDir_appendsIds()\n+      throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    this.archive = new File(this.dir, this.name + \"-test-test\" + this.ext);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).hasParent(this.dir).hasName(this.name + \"-test-test-01-01\" + this.ext);\n+  }\n+\n+  @Test\n+  @Parameters({\"1,1\", \"1,10\", \"10,1\", \"10,10\"})\n+  public void getRenameArchiveName_withOldArchives_rollsMainId(final int mainCount,\n+      final int childCount) throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    createEmptyArchiveFiles(this.dir, this.name, this.ext, mainCount, childCount);\n+\n+    File renamed = handler.getRenameArchiveName(this.archive);\n+\n+    assertThat(renamed).doesNotExist().hasParent(this.dir)\n+        .hasName(this.name + formatIds(mainCount + 1, 1) + this.ext);\n+  }\n+\n+  @Test\n+  public void getRenameArchiveName_withNullArchive_throwsNullPointerException() throws Exception {\n+    StatArchiveHandler handler =\n+        new StatArchiveHandler(this.mockConfig, this.mockCollector, this.rollingFileHandler);\n+    File archive = null;\n+\n+    assertThatThrownBy(() -> handler.getRenameArchiveName(archive))\n+        .isInstanceOf(NullPointerException.class);\n+  }\n+\n+  /**\n+   * Returns mainId and childId formatted like \"-01-01\"\n+   */\n+  private String formatIds(final int mainId, final int childId) {\n+    return \"-\" + formatId(mainId) + \"-\" + formatId(childId);\n+  }\n+\n+  /**\n+   * Returns id formatted like \"01\"\n+   */\n+  private String formatId(final int id) {\n+    return String.format(\"%02d\", id);\n+  }\n+\n+  /**\n+   * Creates empty archive files like dir/name-mainId-childId.ext. Returns greatest mainId.\n+   */\n+  private int createEmptyArchiveFiles(final File dir, final String name, final String ext,\n+      final int mainCount, final int childCount) throws IOException {\n+    int mainId = 1;\n+    for (; mainId <= mainCount; mainId++) {\n+      for (int childId = 1; childId <= childCount; childId++) {\n+        File existing = new File(dir, name + formatIds(mainId, childId) + ext);\n+        existing.createNewFile();\n+      }\n+    }\n+    return mainId - 1;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveHandlerIntegrationTest.java",
                "sha": "ca5993ca3a569edd86a7d4a80f7505ba71ab0a50",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveWithMissingResourceTypeRegressionTest.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveWithMissingResourceTypeRegressionTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveWithMissingResourceTypeRegressionTest.java",
                "patch": "@@ -59,7 +59,8 @@ public void tearDown() throws Exception {\n   public void throwsIllegalStateExceptionWithMessage() throws Exception {\n     assertThatThrownBy(() -> new StatArchiveReader(new File[] {this.archiveFile}, null, true))\n         .isExactlyInstanceOf(IllegalStateException.class) // was NullPointerException\n-        .hasMessage(\"ResourceType is missing for resourceTypeId 0\"); // was null\n+        .hasMessageStartingWith(\"ResourceType is missing for resourceTypeId 0\")\n+        .hasMessageContaining(\"resourceName statistics1\");\n   }\n \n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/internal/statistics/StatArchiveWithMissingResourceTypeRegressionTest.java",
                "sha": "7a265d6b60e0161d42e817bc8dfebccca85f2a2c",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/CreateAlterDestroyRegionCommandsDUnitTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/CreateAlterDestroyRegionCommandsDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/CreateAlterDestroyRegionCommandsDUnitTest.java",
                "patch": "@@ -14,7 +14,6 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n-import static org.awaitility.Awaitility.waitAtMost;\n import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_CLUSTER_CONFIGURATION;\n import static org.apache.geode.distributed.ConfigurationProperties.GROUPS;\n import static org.apache.geode.distributed.ConfigurationProperties.HTTP_SERVICE_PORT;\n@@ -34,7 +33,9 @@\n import static org.apache.geode.test.dunit.Assert.assertTrue;\n import static org.apache.geode.test.dunit.Assert.fail;\n import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n+import static org.awaitility.Awaitility.waitAtMost;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.PartitionAttributes;\n import org.apache.geode.cache.PartitionAttributesFactory;\n@@ -54,7 +55,6 @@\n import org.apache.geode.internal.AvailablePort;\n import org.apache.geode.internal.AvailablePortHelper;\n import org.apache.geode.internal.ClassBuilder;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.PartitionedRegion;\n import org.apache.geode.internal.cache.RegionEntryContext;\n@@ -1364,7 +1364,7 @@ protected final void preTearDownCliCommandTestBase() throws Exception {\n     for (String path : this.filesToBeDeleted) {\n       try {\n         final File fileToDelete = new File(path);\n-        FileUtil.delete(fileToDelete);\n+        FileUtils.forceDelete(fileToDelete);\n         if (path.endsWith(\".jar\")) {\n           executeCommand(\"undeploy --jar=\" + fileToDelete.getName());\n         }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/CreateAlterDestroyRegionCommandsDUnitTest.java",
                "sha": "5f885e136e09541a6d095516fc7cb7db88f659aa",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsDUnitTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsDUnitTest.java",
                "patch": "@@ -36,6 +36,7 @@\n import static org.junit.Assert.assertNull;\n import static org.junit.Assert.assertTrue;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.DataPolicy;\n@@ -53,11 +54,10 @@\n import org.apache.geode.compression.SnappyCompressor;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n import org.apache.geode.distributed.Locator;\n-import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.distributed.internal.ClusterConfigurationService;\n+import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.internal.AvailablePort;\n import org.apache.geode.internal.AvailablePortHelper;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.cache.DiskStoreImpl;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.PartitionedRegion;\n@@ -257,7 +257,7 @@ public String description() {\n       vm.invoke(new SerializableRunnable() {\n         public void run() {\n           try {\n-            FileUtil.delete((new File(diskStoreName + vm.getPid())));\n+            FileUtils.deleteDirectory((new File(diskStoreName + vm.getPid())));\n           } catch (IOException iex) {\n             // There's nothing else we can do\n           }\n@@ -498,7 +498,7 @@ public String description() {\n       vm.invoke(new SerializableRunnable() {\n         public void run() {\n           try {\n-            FileUtil.delete((new File(diskStoreName + vm.getPid())));\n+            FileUtils.deleteDirectory((new File(diskStoreName + vm.getPid())));\n           } catch (IOException iex) {\n             // There's nothing else we can do\n           }\n@@ -1475,7 +1475,7 @@ protected final void preTearDownCliCommandTestBase() throws Exception {\n \n   private void deleteFiles() throws IOException {\n     for (String path : this.filesToBeDeleted) {\n-      FileUtil.delete(new File(path));\n+      FileUtils.deleteDirectory(new File(path));\n     }\n \n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsDUnitTest.java",
                "sha": "5b07f282b83d1539df6a7ea7bf19888436738723",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart1DUnitTest.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart1DUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 10,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart1DUnitTest.java",
                "patch": "@@ -14,19 +14,15 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n-import static org.apache.geode.test.dunit.Assert.*;\n-import static org.apache.geode.test.dunit.LogWriterUtils.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.text.SimpleDateFormat;\n-import java.util.Date;\n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n+import static org.apache.geode.test.dunit.Assert.fail;\n+import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.logging.LogWriterImpl;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n@@ -38,6 +34,11 @@\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n /**\n  * Dunit class for testing gemfire function commands : export logs\n  */\n@@ -100,7 +101,7 @@ public void testExportLogs() throws IOException {\n     } else {\n       fail(\"testExportLogs failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"./testExportLogs\" + dir));\n+    FileUtils.deleteDirectory(new File(\"./testExportLogs\" + dir));\n   }\n \n   @Category(FlakyTest.class) // GEODE-1477 (http)\n@@ -132,6 +133,6 @@ public void testExportLogsForMerge() throws IOException {\n     } else {\n       fail(\"testExportLogsForMerge failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"./testExportLogsForMerge\" + dir));\n+    FileUtils.deleteDirectory(new File(\"./testExportLogsForMerge\" + dir));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart1DUnitTest.java",
                "sha": "cb9a8c6f74ba2a7b9799ad049a4ebe2861b9087b",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart2DUnitTest.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart2DUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 11,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart2DUnitTest.java",
                "patch": "@@ -14,30 +14,30 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n-import static org.apache.geode.test.dunit.Assert.*;\n-import static org.apache.geode.test.dunit.LogWriterUtils.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.text.SimpleDateFormat;\n-import java.util.Date;\n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n+import static org.apache.geode.test.dunit.Assert.fail;\n+import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.logging.LogWriterImpl;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.SerializableRunnable;\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.junit.categories.DistributedTest;\n-\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n /**\n  * Dunit class for testing gemfire function commands : export logs\n  */\n@@ -101,7 +101,7 @@ public void testExportLogsForLogLevel() throws IOException {\n     } else {\n       fail(\"testExportLogsForLogLevel failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForLogLevel\" + dir));\n+    FileUtils.deleteDirectory(new File(\"testExportLogsForLogLevel\" + dir));\n   }\n \n   @Test\n@@ -136,6 +136,6 @@ public void testExportLogsForLogLevelWithUPTOLOGLEVEL() throws IOException {\n     } else {\n       fail(\"testExportLogsForLogLevelWithUPTOLOGLEVEL failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForLogLevelWithUPTOLOGLEVEL\" + dir));\n+    FileUtils.deleteDirectory(new File(\"testExportLogsForLogLevelWithUPTOLOGLEVEL\" + dir));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart2DUnitTest.java",
                "sha": "2b2e524c5369950073099c3509c8f30e768607f6",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart3DUnitTest.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart3DUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 8,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart3DUnitTest.java",
                "patch": "@@ -14,11 +14,17 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n+import static org.apache.geode.distributed.ConfigurationProperties.GROUPS;\n+import static org.apache.geode.distributed.ConfigurationProperties.NAME;\n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n+import static org.apache.geode.test.dunit.Assert.fail;\n+import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.logging.LogWriterImpl;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n@@ -36,11 +42,6 @@\n import java.util.Date;\n import java.util.Properties;\n \n-import static org.apache.geode.test.dunit.Assert.assertEquals;\n-import static org.apache.geode.test.dunit.Assert.fail;\n-import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-\n /**\n  * Dunit class for testing gemfire function commands : export logs\n  */\n@@ -115,7 +116,7 @@ public void testExportLogsForGroup() throws IOException {\n     } else {\n       fail(\"testExportLogsForGroup failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForGroup\" + dir));\n+    FileUtils.deleteQuietly(new File(\"testExportLogsForGroup\" + dir));\n   }\n \n   @Test\n@@ -150,6 +151,6 @@ public void testExportLogsForMember() throws IOException {\n     } else {\n       fail(\"testExportLogsForMember failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForMember\" + dir));\n+    FileUtils.deleteQuietly(new File(\"testExportLogsForMember\" + dir));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart3DUnitTest.java",
                "sha": "efef2c4abf70deeaef81285f13997542490234e3",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart4DUnitTest.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart4DUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 10,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart4DUnitTest.java",
                "patch": "@@ -14,19 +14,15 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n-import static org.apache.geode.test.dunit.Assert.*;\n-import static org.apache.geode.test.dunit.LogWriterUtils.*;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.text.SimpleDateFormat;\n-import java.util.Date;\n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n+import static org.apache.geode.test.dunit.Assert.fail;\n+import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.logging.LogWriterImpl;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n@@ -38,6 +34,11 @@\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n /**\n  * Dunit class for testing gemfire function commands : export logs\n  */\n@@ -100,7 +101,7 @@ public void testExportLogsForTimeRange1() throws IOException {\n     } else {\n       fail(\"testExportLogsForTimeRange1 failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForTimeRange1\" + dir));\n+    FileUtils.deleteQuietly(new File(\"testExportLogsForTimeRange1\" + dir));\n   }\n \n   @Category(FlakyTest.class) // GEODE-1500 (http)\n@@ -132,6 +133,6 @@ public void testExportLogsForTimeRangeForOnlyStartTime() throws IOException {\n     } else {\n       fail(\"testExportLogsForTimeRangeForOnlyStartTime failed as did not get CommandResult\");\n     }\n-    FileUtil.delete(new File(\"testExportLogsForTimeRangeForOnlyStartTime\" + dir));\n+    FileUtils.deleteQuietly(new File(\"testExportLogsForTimeRangeForOnlyStartTime\" + dir));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/MiscellaneousCommandsExportLogsPart4DUnitTest.java",
                "sha": "9d64bd9ed3fec910c2b5dd4e8be50d3368c63893",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/QueueCommandsDUnitTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/QueueCommandsDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/QueueCommandsDUnitTest.java",
                "patch": "@@ -34,15 +34,15 @@\n import static org.apache.geode.test.dunit.LogWriterUtils.getLogWriter;\n import static org.apache.geode.test.dunit.Wait.waitForCriterion;\n \n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.asyncqueue.AsyncEventQueue;\n import org.apache.geode.distributed.Locator;\n-import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.distributed.internal.ClusterConfigurationService;\n+import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.internal.AvailablePort;\n import org.apache.geode.internal.AvailablePortHelper;\n import org.apache.geode.internal.ClassBuilder;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.i18n.CliStrings;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n@@ -62,6 +62,7 @@\n import java.io.OutputStream;\n import java.net.InetAddress;\n import java.net.UnknownHostException;\n+import java.nio.file.Files;\n import java.util.List;\n import java.util.Properties;\n import java.util.concurrent.CopyOnWriteArrayList;\n@@ -418,7 +419,10 @@ protected final void preTearDownCliCommandTestBase() throws Exception {\n     for (String path : this.filesToBeDeleted) {\n       try {\n         final File fileToDelete = new File(path);\n-        FileUtil.delete(fileToDelete);\n+        if (fileToDelete.isDirectory())\n+          FileUtils.deleteDirectory(fileToDelete);\n+        else\n+          Files.delete(fileToDelete.toPath());\n         if (path.endsWith(\".jar\")) {\n           executeCommand(\"undeploy --jar=\" + fileToDelete.getName());\n         }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/QueueCommandsDUnitTest.java",
                "sha": "42a0624546742491e0c8c4d8c406ae8e567c1f85",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/UserCommandsDUnitTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/UserCommandsDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/UserCommandsDUnitTest.java",
                "patch": "@@ -14,10 +14,12 @@\n  */\n package org.apache.geode.management.internal.cli.commands;\n \n+import static org.apache.geode.test.dunit.Assert.assertEquals;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.distributed.ConfigurationProperties;\n import org.apache.geode.internal.ClassBuilder;\n import org.apache.geode.internal.ClassPathLoader;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.management.cli.Result;\n import org.apache.geode.management.internal.cli.CommandManager;\n import org.apache.geode.management.internal.cli.result.CommandResult;\n@@ -32,8 +34,6 @@\n import java.io.IOException;\n import java.util.Properties;\n \n-import static org.apache.geode.test.dunit.Assert.assertEquals;\n-\n /**\n  * Unit tests for configuring user commands.\n  *\n@@ -58,9 +58,9 @@ public final void postSetUpCliCommandTestBase() throws Exception {\n   @Override\n   public final void postTearDownCacheTestCase() throws Exception {\n     if (this.deleteJarDirectory) {\n-      FileUtil.delete(this.jarDirectory);\n+      FileUtils.deleteDirectory(this.jarDirectory);\n     } else {\n-      FileUtil.delete(this.jarFile);\n+      FileUtils.forceDelete(this.jarFile);\n     }\n \n     System.clearProperty(CommandManager.USER_CMD_PACKAGES_PROPERTY);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/UserCommandsDUnitTest.java",
                "sha": "24f5cdb549fbc172e12f965044681e83f11b5829",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/pdx/PdxAttributesJUnitTest.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/pdx/PdxAttributesJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/pdx/PdxAttributesJUnitTest.java",
                "patch": "@@ -14,13 +14,21 @@\n  */\n package org.apache.geode.pdx;\n \n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+\n+import org.apache.commons.io.FileUtils;\n import org.apache.geode.DataSerializer;\n import org.apache.geode.ToDataException;\n-import org.apache.geode.cache.*;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.client.PoolManager;\n import org.apache.geode.distributed.ConfigurationProperties;\n import org.apache.geode.internal.AvailablePortHelper;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.HeapDataOutputStream;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n@@ -42,9 +50,6 @@\n import java.util.Iterator;\n import java.util.Map;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n-import static org.junit.Assert.assertEquals;\n-\n /**\n  *\n  */\n@@ -66,7 +71,7 @@ public void tearDown() throws Exception {\n     if (instance != null) {\n       instance.close();\n     }\n-    FileUtil.delete(diskDir);\n+    FileUtils.deleteDirectory(diskDir);\n     File[] defaultStoreFiles = new File(\".\").listFiles(new FilenameFilter() {\n \n       public boolean accept(File dir, String name) {\n@@ -75,7 +80,7 @@ public boolean accept(File dir, String name) {\n     });\n \n     for (File file : defaultStoreFiles) {\n-      FileUtil.delete(file);\n+      FileUtils.forceDelete(file);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/pdx/PdxAttributesJUnitTest.java",
                "sha": "ef15cd5017203d5a3dcd660eb27eab5dd4e78b38",
                "status": "modified"
            },
            {
                "additions": 44,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/pdx/PdxSerializableJUnitTest.java",
                "changes": 72,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/pdx/PdxSerializableJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 28,
                "filename": "geode-core/src/test/java/org/apache/geode/pdx/PdxSerializableJUnitTest.java",
                "patch": "@@ -14,31 +14,12 @@\n  */\n package org.apache.geode.pdx;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n-import static org.junit.Assert.*;\n-\n-import java.io.ByteArrayInputStream;\n-import java.io.ByteArrayOutputStream;\n-import java.io.DataInput;\n-import java.io.DataInputStream;\n-import java.io.File;\n-import java.io.IOException;\n-import java.io.NotSerializableException;\n-import java.io.OutputStreamWriter;\n-import java.io.PrintWriter;\n-import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Date;\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import org.apache.geode.test.junit.categories.SerializationTest;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Test;\n-import org.junit.experimental.categories.Category;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n \n import org.apache.geode.CopyHelper;\n import org.apache.geode.DataSerializable;\n@@ -51,7 +32,6 @@\n import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.query.internal.DefaultQuery;\n import org.apache.geode.internal.DSCODE;\n-import org.apache.geode.internal.FileUtil;\n import org.apache.geode.internal.HeapDataOutputStream;\n import org.apache.geode.internal.PdxSerializerObject;\n import org.apache.geode.internal.SystemAdmin;\n@@ -66,6 +46,30 @@\n import org.apache.geode.pdx.internal.PeerTypeRegistration;\n import org.apache.geode.pdx.internal.TypeRegistry;\n import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.apache.geode.test.junit.categories.SerializationTest;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataInput;\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.NotSerializableException;\n+import java.io.OutputStreamWriter;\n+import java.io.PrintWriter;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n \n @Category({IntegrationTest.class, SerializationTest.class})\n public class PdxSerializableJUnitTest {\n@@ -188,7 +192,13 @@ public void testPdxPersistentKeys() throws Exception {\n       try {\n         this.c.close();\n       } finally {\n-        FileUtil.deleteMatching(new File(\".\"), \"BACKUP(DEFAULT|pdxDS|r2DS).*\");\n+        Pattern pattern = Pattern.compile(\"BACKUP(DEFAULT|pdxDS|r2DS).*\");\n+        File[] files = new File(\".\").listFiles((dir1, name) -> pattern.matcher(name).matches());\n+        if (files != null) {\n+          for (File file : files) {\n+            Files.delete(file.toPath());\n+          }\n+        }\n       }\n     }\n   }\n@@ -265,7 +275,13 @@ public void testPdxPersistentKeysDefDS() throws Exception {\n       try {\n         this.c.close();\n       } finally {\n-        FileUtil.deleteMatching(new File(\".\"), \"BACKUP(DEFAULT|r2DS).*\");\n+        Pattern pattern = Pattern.compile(\"BACKUP(DEFAULT|r2DS).*\");\n+        File[] files = new File(\".\").listFiles((dir1, name) -> pattern.matcher(name).matches());\n+        if (files != null) {\n+          for (File file : files) {\n+            Files.delete(file.toPath());\n+          }\n+        }\n       }\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/pdx/PdxSerializableJUnitTest.java",
                "sha": "d1502cd7ecefc0c191bbffe75a55f6d3ed73a884",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/test/dunit/standalone/ProcessManager.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/standalone/ProcessManager.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 9,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/standalone/ProcessManager.java",
                "patch": "@@ -14,7 +14,13 @@\n  */\n package org.apache.geode.test.dunit.standalone;\n \n-import static org.apache.geode.distributed.ConfigurationProperties.*;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_NETWORK_PARTITION_DETECTION;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.distributed.internal.InternalLocator;\n+import org.apache.geode.test.dunit.VM;\n \n import java.io.BufferedReader;\n import java.io.File;\n@@ -24,6 +30,7 @@\n import java.io.PrintStream;\n import java.lang.management.ManagementFactory;\n import java.lang.management.RuntimeMXBean;\n+import java.nio.file.Files;\n import java.rmi.AccessException;\n import java.rmi.NotBoundException;\n import java.rmi.RemoteException;\n@@ -33,13 +40,6 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-import org.apache.commons.io.FileUtils;\n-\n-import org.apache.geode.distributed.internal.DistributionConfig;\n-import org.apache.geode.distributed.internal.InternalLocator;\n-import org.apache.geode.internal.FileUtil;\n-import org.apache.geode.test.dunit.VM;\n-\n /**\n  *\n  */\n@@ -76,7 +76,7 @@ public synchronized void launchVM(String version, int vmNum, boolean bouncedVM)\n       workingDir.mkdirs();\n     } else if (!bouncedVM || DUnitLauncher.MAKE_NEW_WORKING_DIRS) {\n       try {\n-        FileUtil.delete(workingDir);\n+        Files.delete(workingDir.toPath());\n       } catch (IOException e) {\n         // This delete is occasionally failing on some platforms, maybe due to a lingering\n         // process. Allow the process to be launched anyway.",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/test/dunit/standalone/ProcessManager.java",
                "sha": "4e0e82fd21f08958fc0334da63541e837438c61a",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/util/test/TestUtil.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/util/test/TestUtil.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/util/test/TestUtil.java",
                "patch": "@@ -14,14 +14,14 @@\n  */\n package org.apache.geode.util.test;\n \n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.lang.SystemUtils;\n+\n import java.io.File;\n import java.io.IOException;\n import java.net.URISyntaxException;\n import java.net.URL;\n \n-import org.apache.commons.lang.SystemUtils;\n-import org.apache.geode.internal.FileUtil;\n-\n public class TestUtil {\n \n   /**\n@@ -46,7 +46,7 @@ public static String getResourcePath(Class<?> clazz, String name) {\n         String filename = name.replaceFirst(\".*/\", \"\");\n         File tmpFile = File.createTempFile(filename, null);\n         tmpFile.deleteOnExit();\n-        FileUtil.copy(resource, tmpFile);\n+        FileUtils.copyFile(new File(resource.getFile()), tmpFile);\n         return compatibleWithWindows(tmpFile.getAbsolutePath());\n       }\n       return compatibleWithWindows(path);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-core/src/test/java/org/apache/geode/util/test/TestUtil.java",
                "sha": "92fd2c54db53813fedd4b2070aceed840558aff4",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/build.gradle",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/build.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-json/build.gradle",
                "patch": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+dependencies {\n+    testCompile project(':geode-junit')\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/build.gradle",
                "sha": "722244a0ad449b69bd52c96db47be403953678c4",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/CDL.java",
                "changes": 272,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/CDL.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 272,
                "filename": "geode-json/src/main/java/org/json/CDL.java",
                "patch": "@@ -1,272 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-/**\n- * This provides static methods to convert comma delimited text into a JSONArray, and to covert a\n- * JSONArray into comma delimited text. Comma delimited text is a very popular format for data\n- * interchange. It is understood by most database, spreadsheet, and organizer programs.\n- * <p>\n- * Each row of text represents a row in a table or a data record. Each row ends with a NEWLINE\n- * character. Each row contains one or more values. Values are separated by commas. A value can\n- * contain any character except for comma, unless is is wrapped in single quotes or double quotes.\n- * <p>\n- * The first row usually contains the names of the columns.\n- * <p>\n- * A comma delimited list can be converted into a JSONArray of JSONObjects. The names for the\n- * elements in the JSONObjects can be taken from the names in the first row.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class CDL {\n-\n-  /**\n-   * Get the next value. The value can be wrapped in quotes. The value can be empty.\n-   * \n-   * @param x A JSONTokener of the source text.\n-   * @return The value string, or null if empty.\n-   * @throws JSONException if the quoted string is badly formed.\n-   */\n-  private static String getValue(JSONTokener x) throws JSONException {\n-    char c;\n-    char q;\n-    StringBuffer sb;\n-    do {\n-      c = x.next();\n-    } while (c == ' ' || c == '\\t');\n-    switch (c) {\n-      case 0:\n-        return null;\n-      case '\"':\n-      case '\\'':\n-        q = c;\n-        sb = new StringBuffer();\n-        for (;;) {\n-          c = x.next();\n-          if (c == q) {\n-            break;\n-          }\n-          if (c == 0 || c == '\\n' || c == '\\r') {\n-            throw x.syntaxError(\"Missing close quote '\" + q + \"'.\");\n-          }\n-          sb.append(c);\n-        }\n-        return sb.toString();\n-      case ',':\n-        x.back();\n-        return \"\";\n-      default:\n-        x.back();\n-        return x.nextTo(',');\n-    }\n-  }\n-\n-  /**\n-   * Produce a JSONArray of strings from a row of comma delimited values.\n-   * \n-   * @param x A JSONTokener of the source text.\n-   * @return A JSONArray of strings.\n-   * @throws JSONException\n-   */\n-  public static JSONArray rowToJSONArray(JSONTokener x) throws JSONException {\n-    JSONArray ja = new JSONArray();\n-    for (;;) {\n-      String value = getValue(x);\n-      char c = x.next();\n-      if (value == null || (ja.length() == 0 && value.length() == 0 && c != ',')) {\n-        return null;\n-      }\n-      ja.put(value);\n-      for (;;) {\n-        if (c == ',') {\n-          break;\n-        }\n-        if (c != ' ') {\n-          if (c == '\\n' || c == '\\r' || c == 0) {\n-            return ja;\n-          }\n-          throw x.syntaxError(\"Bad character '\" + c + \"' (\" + (int) c + \").\");\n-        }\n-        c = x.next();\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Produce a JSONObject from a row of comma delimited text, using a parallel JSONArray of strings\n-   * to provides the names of the elements.\n-   * \n-   * @param names A JSONArray of names. This is commonly obtained from the first row of a comma\n-   *        delimited text file using the rowToJSONArray method.\n-   * @param x A JSONTokener of the source text.\n-   * @return A JSONObject combining the names and values.\n-   * @throws JSONException\n-   */\n-  public static JSONObject rowToJSONObject(JSONArray names, JSONTokener x) throws JSONException {\n-    JSONArray ja = rowToJSONArray(x);\n-    return ja != null ? ja.toJSONObject(names) : null;\n-  }\n-\n-  /**\n-   * Produce a comma delimited text row from a JSONArray. Values containing the comma character will\n-   * be quoted. Troublesome characters may be removed.\n-   * \n-   * @param ja A JSONArray of strings.\n-   * @return A string ending in NEWLINE.\n-   */\n-  public static String rowToString(JSONArray ja) {\n-    StringBuffer sb = new StringBuffer();\n-    for (int i = 0; i < ja.length(); i += 1) {\n-      if (i > 0) {\n-        sb.append(',');\n-      }\n-      Object object = ja.opt(i);\n-      if (object != null) {\n-        String string = object.toString();\n-        if (string.length() > 0 && (string.indexOf(',') >= 0 || string.indexOf('\\n') >= 0\n-            || string.indexOf('\\r') >= 0 || string.indexOf(0) >= 0 || string.charAt(0) == '\"')) {\n-          sb.append('\"');\n-          int length = string.length();\n-          for (int j = 0; j < length; j += 1) {\n-            char c = string.charAt(j);\n-            if (c >= ' ' && c != '\"') {\n-              sb.append(c);\n-            }\n-          }\n-          sb.append('\"');\n-        } else {\n-          sb.append(string);\n-        }\n-      }\n-    }\n-    sb.append('\\n');\n-    return sb.toString();\n-  }\n-\n-  /**\n-   * Produce a JSONArray of JSONObjects from a comma delimited text string, using the first row as a\n-   * source of names.\n-   * \n-   * @param string The comma delimited text.\n-   * @return A JSONArray of JSONObjects.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(String string) throws JSONException {\n-    return toJSONArray(new JSONTokener(string));\n-  }\n-\n-  /**\n-   * Produce a JSONArray of JSONObjects from a comma delimited text string, using the first row as a\n-   * source of names.\n-   * \n-   * @param x The JSONTokener containing the comma delimited text.\n-   * @return A JSONArray of JSONObjects.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(JSONTokener x) throws JSONException {\n-    return toJSONArray(rowToJSONArray(x), x);\n-  }\n-\n-  /**\n-   * Produce a JSONArray of JSONObjects from a comma delimited text string using a supplied\n-   * JSONArray as the source of element names.\n-   * \n-   * @param names A JSONArray of strings.\n-   * @param string The comma delimited text.\n-   * @return A JSONArray of JSONObjects.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(JSONArray names, String string) throws JSONException {\n-    return toJSONArray(names, new JSONTokener(string));\n-  }\n-\n-  /**\n-   * Produce a JSONArray of JSONObjects from a comma delimited text string using a supplied\n-   * JSONArray as the source of element names.\n-   * \n-   * @param names A JSONArray of strings.\n-   * @param x A JSONTokener of the source text.\n-   * @return A JSONArray of JSONObjects.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(JSONArray names, JSONTokener x) throws JSONException {\n-    if (names == null || names.length() == 0) {\n-      return null;\n-    }\n-    JSONArray ja = new JSONArray();\n-    for (;;) {\n-      JSONObject jo = rowToJSONObject(names, x);\n-      if (jo == null) {\n-        break;\n-      }\n-      ja.put(jo);\n-    }\n-    if (ja.length() == 0) {\n-      return null;\n-    }\n-    return ja;\n-  }\n-\n-\n-  /**\n-   * Produce a comma delimited text from a JSONArray of JSONObjects. The first row will be a list of\n-   * names obtained by inspecting the first JSONObject.\n-   * \n-   * @param ja A JSONArray of JSONObjects.\n-   * @return A comma delimited text.\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONArray ja) throws JSONException {\n-    JSONObject jo = ja.optJSONObject(0);\n-    if (jo != null) {\n-      JSONArray names = jo.names();\n-      if (names != null) {\n-        return rowToString(names) + toString(names, ja);\n-      }\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Produce a comma delimited text from a JSONArray of JSONObjects using a provided list of names.\n-   * The list of names is not included in the output.\n-   * \n-   * @param names A JSONArray of strings.\n-   * @param ja A JSONArray of JSONObjects.\n-   * @return A comma delimited text.\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONArray names, JSONArray ja) throws JSONException {\n-    if (names == null || names.length() == 0) {\n-      return null;\n-    }\n-    StringBuffer sb = new StringBuffer();\n-    for (int i = 0; i < ja.length(); i += 1) {\n-      JSONObject jo = ja.optJSONObject(i);\n-      if (jo != null) {\n-        sb.append(rowToString(jo.toJSONArray(names)));\n-      }\n-    }\n-    return sb.toString();\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/CDL.java",
                "sha": "d78935bd7cd5555e697378d35c5a4b24ec2a80b1",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/Cookie.java",
                "changes": 162,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/Cookie.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 162,
                "filename": "geode-json/src/main/java/org/json/Cookie.java",
                "patch": "@@ -1,162 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-/**\n- * Convert a web browser cookie specification to a JSONObject and back. JSON and Cookies are both\n- * notations for name/value pairs.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class Cookie {\n-\n-  /**\n-   * Produce a copy of a string in which the characters '+', '%', '=', ';' and control characters\n-   * are replaced with \"%hh\". This is a gentle form of URL encoding, attempting to cause as little\n-   * distortion to the string as possible. The characters '=' and ';' are meta characters in\n-   * cookies. By convention, they are escaped using the URL-encoding. This is only a convention, not\n-   * a standard. Often, cookies are expected to have encoded values. We encode '=' and ';' because\n-   * we must. We encode '%' and '+' because they are meta characters in URL encoding.\n-   * \n-   * @param string The source string.\n-   * @return The escaped result.\n-   */\n-  public static String escape(String string) {\n-    char c;\n-    String s = string.trim();\n-    StringBuffer sb = new StringBuffer();\n-    int length = s.length();\n-    for (int i = 0; i < length; i += 1) {\n-      c = s.charAt(i);\n-      if (c < ' ' || c == '+' || c == '%' || c == '=' || c == ';') {\n-        sb.append('%');\n-        sb.append(Character.forDigit((char) ((c >>> 4) & 0x0f), 16));\n-        sb.append(Character.forDigit((char) (c & 0x0f), 16));\n-      } else {\n-        sb.append(c);\n-      }\n-    }\n-    return sb.toString();\n-  }\n-\n-\n-  /**\n-   * Convert a cookie specification string into a JSONObject. The string will contain a name value\n-   * pair separated by '='. The name and the value will be unescaped, possibly converting '+' and\n-   * '%' sequences. The cookie properties may follow, separated by ';', also represented as\n-   * name=value (except the secure property, which does not have a value). The name will be stored\n-   * under the key \"name\", and the value will be stored under the key \"value\". This method does not\n-   * do checking or validation of the parameters. It only converts the cookie string into a\n-   * JSONObject.\n-   * \n-   * @param string The cookie specification string.\n-   * @return A JSONObject containing \"name\", \"value\", and possibly other members.\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(String string) throws JSONException {\n-    String name;\n-    JSONObject jo = new JSONObject();\n-    Object value;\n-    JSONTokener x = new JSONTokener(string);\n-    jo.put(\"name\", x.nextTo('='));\n-    x.next('=');\n-    jo.put(\"value\", x.nextTo(';'));\n-    x.next();\n-    while (x.more()) {\n-      name = unescape(x.nextTo(\"=;\"));\n-      if (x.next() != '=') {\n-        if (name.equals(\"secure\")) {\n-          value = Boolean.TRUE;\n-        } else {\n-          throw x.syntaxError(\"Missing '=' in cookie parameter.\");\n-        }\n-      } else {\n-        value = unescape(x.nextTo(';'));\n-        x.next();\n-      }\n-      jo.put(name, value);\n-    }\n-    return jo;\n-  }\n-\n-\n-  /**\n-   * Convert a JSONObject into a cookie specification string. The JSONObject must contain \"name\" and\n-   * \"value\" members. If the JSONObject contains \"expires\", \"domain\", \"path\", or \"secure\" members,\n-   * they will be appended to the cookie specification string. All other members are ignored.\n-   * \n-   * @param jo A JSONObject\n-   * @return A cookie specification string\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONObject jo) throws JSONException {\n-    StringBuffer sb = new StringBuffer();\n-\n-    sb.append(escape(jo.getString(\"name\")));\n-    sb.append(\"=\");\n-    sb.append(escape(jo.getString(\"value\")));\n-    if (jo.has(\"expires\")) {\n-      sb.append(\";expires=\");\n-      sb.append(jo.getString(\"expires\"));\n-    }\n-    if (jo.has(\"domain\")) {\n-      sb.append(\";domain=\");\n-      sb.append(escape(jo.getString(\"domain\")));\n-    }\n-    if (jo.has(\"path\")) {\n-      sb.append(\";path=\");\n-      sb.append(escape(jo.getString(\"path\")));\n-    }\n-    if (jo.optBoolean(\"secure\")) {\n-      sb.append(\";secure\");\n-    }\n-    return sb.toString();\n-  }\n-\n-  /**\n-   * Convert <code>%</code><i>hh</i> sequences to single characters, and convert plus to space.\n-   * \n-   * @param string A string that may contain <code>+</code>&nbsp;<small>(plus)</small> and\n-   *        <code>%</code><i>hh</i> sequences.\n-   * @return The unescaped string.\n-   */\n-  public static String unescape(String string) {\n-    int length = string.length();\n-    StringBuffer sb = new StringBuffer();\n-    for (int i = 0; i < length; ++i) {\n-      char c = string.charAt(i);\n-      if (c == '+') {\n-        c = ' ';\n-      } else if (c == '%' && i + 2 < length) {\n-        int d = JSONTokener.dehexchar(string.charAt(i + 1));\n-        int e = JSONTokener.dehexchar(string.charAt(i + 2));\n-        if (d >= 0 && e >= 0) {\n-          c = (char) (d * 16 + e);\n-          i += 2;\n-        }\n-      }\n-      sb.append(c);\n-    }\n-    return sb.toString();\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/Cookie.java",
                "sha": "21f88d8bd810aac5d08fd954c4d79151b2dd8da5",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/CookieList.java",
                "changes": 87,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/CookieList.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 87,
                "filename": "geode-json/src/main/java/org/json/CookieList.java",
                "patch": "@@ -1,87 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-import java.util.Iterator;\n-\n-/**\n- * Convert a web browser cookie list string to a JSONObject and back.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class CookieList {\n-\n-  /**\n-   * Convert a cookie list into a JSONObject. A cookie list is a sequence of name/value pairs. The\n-   * names are separated from the values by '='. The pairs are separated by ';'. The names and the\n-   * values will be unescaped, possibly converting '+' and '%' sequences.\n-   *\n-   * To add a cookie to a cooklist, cookielistJSONObject.put(cookieJSONObject.getString(\"name\"),\n-   * cookieJSONObject.getString(\"value\"));\n-   * \n-   * @param string A cookie list string\n-   * @return A JSONObject\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(String string) throws JSONException {\n-    JSONObject jo = new JSONObject();\n-    JSONTokener x = new JSONTokener(string);\n-    while (x.more()) {\n-      String name = Cookie.unescape(x.nextTo('='));\n-      x.next('=');\n-      jo.put(name, Cookie.unescape(x.nextTo(';')));\n-      x.next();\n-    }\n-    return jo;\n-  }\n-\n-\n-  /**\n-   * Convert a JSONObject into a cookie list. A cookie list is a sequence of name/value pairs. The\n-   * names are separated from the values by '='. The pairs are separated by ';'. The characters '%',\n-   * '+', '=', and ';' in the names and values are replaced by \"%hh\".\n-   * \n-   * @param jo A JSONObject\n-   * @return A cookie list string\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONObject jo) throws JSONException {\n-    boolean b = false;\n-    Iterator keys = jo.keys();\n-    String string;\n-    StringBuffer sb = new StringBuffer();\n-    while (keys.hasNext()) {\n-      string = keys.next().toString();\n-      if (!jo.isNull(string)) {\n-        if (b) {\n-          sb.append(';');\n-        }\n-        sb.append(Cookie.escape(string));\n-        sb.append(\"=\");\n-        sb.append(Cookie.escape(jo.getString(string)));\n-        b = true;\n-      }\n-    }\n-    return sb.toString();\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/CookieList.java",
                "sha": "35e1a97f4dd48c6e99829406100fc6f6f99769e8",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/HTTP.java",
                "changes": 185,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/HTTP.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 185,
                "filename": "geode-json/src/main/java/org/json/HTTP.java",
                "patch": "@@ -1,185 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-import java.util.Iterator;\n-\n-/**\n- * Convert an HTTP header to a JSONObject and back.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class HTTP {\n-\n-  /** Carriage return/line feed. */\n-  public static final String CRLF = \"\\r\\n\";\n-\n-  /**\n-   * Convert an HTTP header string into a JSONObject. It can be a request header or a response\n-   * header. A request header will contain\n-   * \n-   * <pre>\n-   * {\n-   *    Method: \"POST\" (for example),\n-   *    \"Request-URI\": \"/\" (for example),\n-   *    \"HTTP-Version\": \"HTTP/1.1\" (for example)\n-   * }\n-   * </pre>\n-   * \n-   * A response header will contain\n-   * \n-   * <pre>\n-   * {\n-   *    \"HTTP-Version\": \"HTTP/1.1\" (for example),\n-   *    \"Status-Code\": \"200\" (for example),\n-   *    \"Reason-Phrase\": \"OK\" (for example)\n-   * }\n-   * </pre>\n-   * \n-   * In addition, the other parameters in the header will be captured, using the HTTP field names as\n-   * JSON names, so that\n-   * \n-   * <pre>\n-   *    Date: Sun, 26 May 2002 18:06:04 GMT\n-   *    Cookie: Q=q2=PPEAsg--; B=677gi6ouf29bn&b=2&f=s\n-   *    Cache-Control: no-cache\n-   * </pre>\n-   * \n-   * become\n-   * \n-   * <pre>\n-   * {...\n-   *    Date: \"Sun, 26 May 2002 18:06:04 GMT\",\n-   *    Cookie: \"Q=q2=PPEAsg--; B=677gi6ouf29bn&b=2&f=s\",\n-   *    \"Cache-Control\": \"no-cache\",\n-   * ...}\n-   * </pre>\n-   * \n-   * It does no further checking or conversion. It does not parse dates. It does not do '%'\n-   * transforms on URLs.\n-   * \n-   * @param string An HTTP header string.\n-   * @return A JSONObject containing the elements and attributes of the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(String string) throws JSONException {\n-    JSONObject jo = new JSONObject();\n-    HTTPTokener x = new HTTPTokener(string);\n-    String token;\n-\n-    token = x.nextToken();\n-    if (token.toUpperCase().startsWith(\"HTTP\")) {\n-\n-      // Response\n-\n-      jo.put(\"HTTP-Version\", token);\n-      jo.put(\"Status-Code\", x.nextToken());\n-      jo.put(\"Reason-Phrase\", x.nextTo('\\0'));\n-      x.next();\n-\n-    } else {\n-\n-      // Request\n-\n-      jo.put(\"Method\", token);\n-      jo.put(\"Request-URI\", x.nextToken());\n-      jo.put(\"HTTP-Version\", x.nextToken());\n-    }\n-\n-    // Fields\n-\n-    while (x.more()) {\n-      String name = x.nextTo(':');\n-      x.next(':');\n-      jo.put(name, x.nextTo('\\0'));\n-      x.next();\n-    }\n-    return jo;\n-  }\n-\n-\n-  /**\n-   * Convert a JSONObject into an HTTP header. A request header must contain\n-   * \n-   * <pre>\n-   * {\n-   *    Method: \"POST\" (for example),\n-   *    \"Request-URI\": \"/\" (for example),\n-   *    \"HTTP-Version\": \"HTTP/1.1\" (for example)\n-   * }\n-   * </pre>\n-   * \n-   * A response header must contain\n-   * \n-   * <pre>\n-   * {\n-   *    \"HTTP-Version\": \"HTTP/1.1\" (for example),\n-   *    \"Status-Code\": \"200\" (for example),\n-   *    \"Reason-Phrase\": \"OK\" (for example)\n-   * }\n-   * </pre>\n-   * \n-   * Any other members of the JSONObject will be output as HTTP fields. The result will end with two\n-   * CRLF pairs.\n-   * \n-   * @param jo A JSONObject\n-   * @return An HTTP header string.\n-   * @throws JSONException if the object does not contain enough information.\n-   */\n-  public static String toString(JSONObject jo) throws JSONException {\n-    Iterator keys = jo.keys();\n-    String string;\n-    StringBuffer sb = new StringBuffer();\n-    if (jo.has(\"Status-Code\") && jo.has(\"Reason-Phrase\")) {\n-      sb.append(jo.getString(\"HTTP-Version\"));\n-      sb.append(' ');\n-      sb.append(jo.getString(\"Status-Code\"));\n-      sb.append(' ');\n-      sb.append(jo.getString(\"Reason-Phrase\"));\n-    } else if (jo.has(\"Method\") && jo.has(\"Request-URI\")) {\n-      sb.append(jo.getString(\"Method\"));\n-      sb.append(' ');\n-      sb.append('\"');\n-      sb.append(jo.getString(\"Request-URI\"));\n-      sb.append('\"');\n-      sb.append(' ');\n-      sb.append(jo.getString(\"HTTP-Version\"));\n-    } else {\n-      throw new JSONException(\"Not enough material for an HTTP header.\");\n-    }\n-    sb.append(CRLF);\n-    while (keys.hasNext()) {\n-      string = keys.next().toString();\n-      if (!\"HTTP-Version\".equals(string) && !\"Status-Code\".equals(string)\n-          && !\"Reason-Phrase\".equals(string) && !\"Method\".equals(string)\n-          && !\"Request-URI\".equals(string) && !jo.isNull(string)) {\n-        sb.append(string);\n-        sb.append(\": \");\n-        sb.append(jo.getString(string));\n-        sb.append(CRLF);\n-      }\n-    }\n-    sb.append(CRLF);\n-    return sb.toString();\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/HTTP.java",
                "sha": "1e815aabeb1fa68d27c092e9586d7934b9d5830b",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/HTTPTokener.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/HTTPTokener.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 77,
                "filename": "geode-json/src/main/java/org/json/HTTPTokener.java",
                "patch": "@@ -1,77 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-/**\n- * The HTTPTokener extends the JSONTokener to provide additional methods for the parsing of HTTP\n- * headers.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class HTTPTokener extends JSONTokener {\n-\n-  /**\n-   * Construct an HTTPTokener from a string.\n-   * \n-   * @param string A source string.\n-   */\n-  public HTTPTokener(String string) {\n-    super(string);\n-  }\n-\n-\n-  /**\n-   * Get the next token or string. This is used in parsing HTTP headers.\n-   * \n-   * @throws JSONException\n-   * @return A String.\n-   */\n-  public String nextToken() throws JSONException {\n-    char c;\n-    char q;\n-    StringBuffer sb = new StringBuffer();\n-    do {\n-      c = next();\n-    } while (Character.isWhitespace(c));\n-    if (c == '\"' || c == '\\'') {\n-      q = c;\n-      for (;;) {\n-        c = next();\n-        if (c < ' ') {\n-          throw syntaxError(\"Unterminated string.\");\n-        }\n-        if (c == q) {\n-          return sb.toString();\n-        }\n-        sb.append(c);\n-      }\n-    }\n-    for (;;) {\n-      if (c == 0 || Character.isWhitespace(c)) {\n-        return sb.toString();\n-      }\n-      sb.append(c);\n-      c = next();\n-    }\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/HTTPTokener.java",
                "sha": "72c9b8878903efc6c206c70e569c043a80c0a34c",
                "status": "removed"
            },
            {
                "additions": 112,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSON.java",
                "changes": 112,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSON.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-json/src/main/java/org/json/JSON.java",
                "patch": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.json;\n+\n+class JSON {\n+  /**\n+   * Returns the input if it is a JSON-permissible value; throws otherwise.\n+   */\n+  static double checkDouble(double d) throws JSONException {\n+    if (Double.isInfinite(d) || Double.isNaN(d)) {\n+      throw new JSONException(\"Forbidden numeric value: \" + d);\n+    }\n+    return d;\n+  }\n+\n+  static Boolean toBoolean(Object value) {\n+    if (value instanceof Boolean) {\n+      return (Boolean) value;\n+    } else if (value instanceof String) {\n+      String stringValue = (String) value;\n+      if (\"true\".equalsIgnoreCase(stringValue)) {\n+        return true;\n+      } else if (\"false\".equalsIgnoreCase(stringValue)) {\n+        return false;\n+      }\n+    }\n+    return null;\n+  }\n+\n+  static Double toDouble(Object value) {\n+    if (value instanceof Double) {\n+      return (Double) value;\n+    } else if (value instanceof Number) {\n+      return ((Number) value).doubleValue();\n+    } else if (value instanceof String) {\n+      try {\n+        return Double.valueOf((String) value);\n+      } catch (NumberFormatException ignored) {\n+      }\n+    }\n+    return null;\n+  }\n+\n+  static Integer toInteger(Object value) {\n+    if (value instanceof Integer) {\n+      return (Integer) value;\n+    } else if (value instanceof Number) {\n+      return ((Number) value).intValue();\n+    } else if (value instanceof String) {\n+      try {\n+        return (int) Double.parseDouble((String) value);\n+      } catch (NumberFormatException ignored) {\n+      }\n+    }\n+    return null;\n+  }\n+\n+  static Long toLong(Object value) {\n+    if (value instanceof Long) {\n+      return (Long) value;\n+    } else if (value instanceof Number) {\n+      return ((Number) value).longValue();\n+    } else if (value instanceof String) {\n+      try {\n+        return (long) Double.parseDouble((String) value);\n+      } catch (NumberFormatException ignored) {\n+      }\n+    }\n+    return null;\n+  }\n+\n+  static String toString(Object value) {\n+    if (value instanceof String) {\n+      return (String) value;\n+    } else if (value != null) {\n+      return String.valueOf(value);\n+    }\n+    return null;\n+  }\n+\n+  public static JSONException typeMismatch(Object indexOrName, Object actual, String requiredType)\n+      throws JSONException {\n+    if (actual == null) {\n+      throw new JSONException(\"Value at \" + indexOrName + \" is null.\");\n+    } else {\n+      throw new JSONException(\"Value \" + actual + \" at \" + indexOrName + \" of type \"\n+          + actual.getClass().getName() + \" cannot be converted to \" + requiredType);\n+    }\n+  }\n+\n+  public static JSONException typeMismatch(Object actual, String requiredType)\n+      throws JSONException {\n+    if (actual == null) {\n+      throw new JSONException(\"Value is null.\");\n+    } else {\n+      throw new JSONException(\"Value \" + actual + \" of type \" + actual.getClass().getName()\n+          + \" cannot be converted to \" + requiredType);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSON.java",
                "sha": "7105cab08d7b4bf808a79f184d853676b4289b4b",
                "status": "added"
            },
            {
                "additions": 508,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONArray.java",
                "changes": 1137,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONArray.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 629,
                "filename": "geode-json/src/main/java/org/json/JSONArray.java",
                "patch": "@@ -1,868 +1,747 @@\n-package org.json;\n-\n /*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n  */\n \n-import java.io.IOException;\n-import java.io.StringWriter;\n-import java.io.Writer;\n+package org.json;\n+\n import java.lang.reflect.Array;\n import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.Iterator;\n-import java.util.Map;\n+import java.util.List;\n+\n+// Note: this class was written without inspecting the non-free org.json sourcecode.\n \n /**\n- * A JSONArray is an ordered sequence of values. Its external text form is a string wrapped in\n- * square brackets with commas separating the values. The internal form is an object having\n- * <code>get</code> and <code>opt</code> methods for accessing the values by index, and\n- * <code>put</code> methods for adding or replacing values. The values can be any of these types:\n- * <code>Boolean</code>, <code>JSONArray</code>, <code>JSONObject</code>, <code>Number</code>,\n- * <code>String</code>, or the <code>JSONObject.NULL object</code>.\n- * <p>\n- * The constructor can convert a JSON text into a Java object. The <code>toString</code> method\n- * converts to JSON text.\n- * <p>\n- * A <code>get</code> method returns a value if one can be found, and throws an exception if one\n- * cannot be found. An <code>opt</code> method returns a default value instead of throwing an\n- * exception, and so is useful for obtaining optional values.\n- * <p>\n- * The generic <code>get()</code> and <code>opt()</code> methods return an object which you can cast\n- * or query for type. There are also typed <code>get</code> and <code>opt</code> methods that do\n- * type checking and type coercion for you.\n- * <p>\n- * The texts produced by the <code>toString</code> methods strictly conform to JSON syntax rules.\n- * The constructors are more forgiving in the texts they will accept:\n- * <ul>\n- * <li>An extra <code>,</code>&nbsp;<small>(comma)</small> may appear just before the closing\n- * bracket.</li>\n- * <li>The <code>null</code> value will be inserted when there is <code>,</code>\n- * &nbsp;<small>(comma)</small> elision.</li>\n- * <li>Strings may be quoted with <code>'</code>&nbsp;<small>(single quote)</small>.</li>\n- * <li>Strings do not need to be quoted at all if they do not begin with a quote or single quote,\n- * and if they do not contain leading or trailing spaces, and if they do not contain any of these\n- * characters: <code>{ } [ ] / \\ : , = ; #</code> and if they do not look like numbers and if they\n- * are not the reserved words <code>true</code>, <code>false</code>, or <code>null</code>.</li>\n- * <li>Values can be separated by <code>;</code> <small>(semicolon)</small> as well as by\n- * <code>,</code> <small>(comma)</small>.</li>\n- * </ul>\n+ * A dense indexed sequence of values. Values may be any mix of {@link JSONObject JSONObjects},\n+ * other {@link JSONArray JSONArrays}, Strings, Booleans, Integers, Longs, Doubles, {@code null} or\n+ * {@link JSONObject#NULL}. Values may not be {@link Double#isNaN() NaNs},\n+ * {@link Double#isInfinite() infinities}, or of any type not listed here.\n+ *\n+ * {@code JSONArray} has the same type coercion behavior and optional/mandatory accessors as\n+ * {@link JSONObject}. See that class' documentation for details.\n  *\n- * @author JSON.org\n- * @version 2012-04-20\n+ * <strong>Warning:</strong> this class represents null in two incompatible ways: the standard Java\n+ * {@code null} reference, and the sentinel value {@link JSONObject#NULL}. In particular,\n+ * {@code get} fails if the requested index holds the null reference, but succeeds if it holds\n+ * {@code JSONObject.NULL}.\n+ *\n+ * Instances of this class are not thread safe. Although this class is non-final, it was not\n+ * designed for inheritance and should not be subclassed. In particular, self-use by overridable\n+ * methods is not specified. See <i>Effective Java</i> Item 17, \"Design and Document or inheritance\n+ * or else prohibit it\" for further information.\n  */\n public class JSONArray {\n \n+  private final List<Object> values;\n \n   /**\n-   * The arrayList where the JSONArray's properties are kept.\n-   */\n-  private final ArrayList myArrayList;\n-\n-\n-  /**\n-   * Construct an empty JSONArray.\n+   * Creates a {@code JSONArray} with no values.\n    */\n   public JSONArray() {\n-    this.myArrayList = new ArrayList();\n+    values = new ArrayList<Object>();\n   }\n \n   /**\n-   * Construct a JSONArray from a JSONTokener.\n-   * \n-   * @param x A JSONTokener\n-   * @throws JSONException If there is a syntax error.\n+   * Creates a new {@code JSONArray} by copying all values from the given collection.\n+   *\n+   * @param copyFrom a collection whose values are of supported types. Unsupported values are not\n+   *        permitted and will yield an array in an inconsistent state.\n    */\n-  public JSONArray(JSONTokener x) throws JSONException {\n+  /* Accept a raw type for API compatibility */\n+  public JSONArray(Collection<?> copyFrom) {\n     this();\n-    if (x.nextClean() != '[') {\n-      throw x.syntaxError(\"A JSONArray text must start with '['\");\n-    }\n-    if (x.nextClean() != ']') {\n-      x.back();\n-      for (;;) {\n-        if (x.nextClean() == ',') {\n-          x.back();\n-          this.myArrayList.add(JSONObject.NULL);\n-        } else {\n-          x.back();\n-          this.myArrayList.add(x.nextValue());\n-        }\n-        switch (x.nextClean()) {\n-          case ';':\n-          case ',':\n-            if (x.nextClean() == ']') {\n-              return;\n-            }\n-            x.back();\n-            break;\n-          case ']':\n-            return;\n-          default:\n-            throw x.syntaxError(\"Expected a ',' or ']'\");\n-        }\n+    if (copyFrom != null) {\n+      for (Object aCopyFrom : copyFrom) {\n+        put(JSONObject.wrap(aCopyFrom));\n       }\n     }\n   }\n \n-\n   /**\n-   * Construct a JSONArray from a source JSON text.\n-   * \n-   * @param source A string that begins with <code>[</code>&nbsp;<small>(left bracket)</small> and\n-   *        ends with <code>]</code>&nbsp;<small>(right bracket)</small>.\n-   * @throws JSONException If there is a syntax error.\n-   */\n-  public JSONArray(String source) throws JSONException {\n-    this(new JSONTokener(source));\n+   * Creates a new {@code JSONArray} with values from the next array in the tokener.\n+   *\n+   * @param readFrom a tokener whose nextValue() method will yield a {@code JSONArray}.\n+   * @throws JSONException if the parse fails or doesn't yield a {@code JSONArray}.\n+   */\n+  public JSONArray(JSONTokener readFrom) throws JSONException {\n+    /*\n+     * Getting the parser to populate this could get tricky. Instead, just parse to temporary\n+     * JSONArray and then steal the data from that.\n+     */\n+    Object object = readFrom.nextValue();\n+    if (object instanceof JSONArray) {\n+      values = ((JSONArray) object).values;\n+    } else {\n+      throw JSON.typeMismatch(object, \"JSONArray\");\n+    }\n   }\n \n-\n   /**\n-   * Construct a JSONArray from a Collection.\n-   * \n-   * @param collection A Collection.\n-   */\n-  public JSONArray(Collection collection) {\n-    this.myArrayList = new ArrayList();\n-    if (collection != null) {\n-      Iterator iter = collection.iterator();\n-      while (iter.hasNext()) {\n-        this.myArrayList.add(JSONObject.wrap(iter.next()));\n-      }\n-    }\n+   * Creates a new {@code JSONArray} with values from the JSON string.\n+   *\n+   * @param json a JSON-encoded string containing an array.\n+   * @throws JSONException if the parse fails or doesn't yield a {@code\n+   *                       JSONArray}.\n+   */\n+  public JSONArray(String json) throws JSONException {\n+    this(new JSONTokener(json));\n   }\n \n-\n   /**\n-   * Construct a JSONArray from an array\n-   * \n-   * @throws JSONException If not an array.\n+   * Creates a new {@code JSONArray} with values from the given primitive array.\n+   *\n+   * @param array The values to use.\n+   * @throws JSONException if any of the values are non-finite double values (i.e. NaN or infinite)\n    */\n   public JSONArray(Object array) throws JSONException {\n-    this();\n-    if (array.getClass().isArray()) {\n-      int length = Array.getLength(array);\n-      for (int i = 0; i < length; i += 1) {\n-        this.put(JSONObject.wrap(Array.get(array, i)));\n-      }\n-    } else {\n-      throw new JSONException(\"JSONArray initial value should be a string or collection or array.\");\n+    if (!array.getClass().isArray()) {\n+      throw new JSONException(\"Not a primitive array: \" + array.getClass());\n+    }\n+    final int length = Array.getLength(array);\n+    values = new ArrayList<Object>(length);\n+    for (int i = 0; i < length; ++i) {\n+      put(JSONObject.wrap(Array.get(array, i)));\n     }\n   }\n \n-\n   /**\n-   * Get the object value associated with an index.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @return An object value.\n-   * @throws JSONException If there is no value for the index.\n+   * @return Returns the number of values in this array.\n    */\n-  public Object get(int index) throws JSONException {\n-    Object object = this.opt(index);\n-    if (object == null) {\n-      throw new JSONException(\"JSONArray[\" + index + \"] not found.\");\n-    }\n-    return object;\n+  public int length() {\n+    return values.size();\n   }\n \n-\n   /**\n-   * Get the boolean value associated with an index. The string values \"true\" and \"false\" are\n-   * converted to boolean.\n+   * Appends {@code value} to the end of this array.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The truth.\n-   * @throws JSONException If there is no value for the index or if the value is not convertible to\n-   *         boolean.\n+   * @param value The value to append.\n+   * @return this array.\n    */\n-  public boolean getBoolean(int index) throws JSONException {\n-    Object object = this.get(index);\n-    if (object.equals(Boolean.FALSE)\n-        || (object instanceof String && ((String) object).equalsIgnoreCase(\"false\"))) {\n-      return false;\n-    } else if (object.equals(Boolean.TRUE)\n-        || (object instanceof String && ((String) object).equalsIgnoreCase(\"true\"))) {\n-      return true;\n-    }\n-    throw new JSONException(\"JSONArray[\" + index + \"] is not a boolean.\");\n+  public JSONArray put(boolean value) {\n+    values.add(value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the double value associated with an index.\n+   * Appends {@code value} to the end of this array.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n-   * @throws JSONException If the key is not found or if the value cannot be converted to a number.\n+   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this array.\n+   * @throws JSONException If the value is unacceptable.\n    */\n-  public double getDouble(int index) throws JSONException {\n-    Object object = this.get(index);\n-    try {\n-      return object instanceof Number ? ((Number) object).doubleValue()\n-          : Double.parseDouble((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONArray[\" + index + \"] is not a number.\");\n-    }\n+  public JSONArray put(double value) throws JSONException {\n+    values.add(JSON.checkDouble(value));\n+    return this;\n   }\n \n-\n   /**\n-   * Get the int value associated with an index.\n+   * Appends {@code value} to the end of this array.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n-   * @throws JSONException If the key is not found or if the value is not a number.\n+   * @param value The value to append.\n+   * @return this array.\n    */\n-  public int getInt(int index) throws JSONException {\n-    Object object = this.get(index);\n-    try {\n-      return object instanceof Number ? ((Number) object).intValue()\n-          : Integer.parseInt((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONArray[\" + index + \"] is not a number.\");\n-    }\n+  public JSONArray put(int value) {\n+    values.add(value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the JSONArray associated with an index.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @return A JSONArray value.\n-   * @throws JSONException If there is no value for the index. or if the value is not a JSONArray\n+   * Appends {@code value} to the end of this array.\n+   *\n+   * @param value The value to append.\n+   * @return this array.\n    */\n-  public JSONArray getJSONArray(int index) throws JSONException {\n-    Object object = this.get(index);\n-    if (object instanceof JSONArray) {\n-      return (JSONArray) object;\n-    }\n-    throw new JSONException(\"JSONArray[\" + index + \"] is not a JSONArray.\");\n+  public JSONArray put(long value) {\n+    values.add(value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the JSONObject associated with an index.\n-   * \n-   * @param index subscript\n-   * @return A JSONObject value.\n-   * @throws JSONException If there is no value for the index or if the value is not a JSONObject\n+   * Appends {@code value} wrapped by {@link JSONArray} to the end of this array.\n+   *\n+   * @param value any collection.\n+   * @return this array.\n    */\n-  public JSONObject getJSONObject(int index) throws JSONException {\n-    Object object = this.get(index);\n-    if (object instanceof JSONObject) {\n-      return (JSONObject) object;\n+  public JSONArray put(Collection<?> value) {\n+    if (value == null) {\n+      return put((Object) null);\n     }\n-    throw new JSONException(\"JSONArray[\" + index + \"] is not a JSONObject.\");\n+    values.add(new JSONArray(value));\n+    return this;\n   }\n \n-\n   /**\n-   * Get the long value associated with an index.\n+   * Appends {@code value} to the end of this array.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n-   * @throws JSONException If the key is not found or if the value cannot be converted to a number.\n+   * @param value a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double,\n+   *        {@link JSONObject#NULL}, or {@code null}. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}. Unsupported values are not permitted and will\n+   *        cause the array to be in an inconsistent state.\n+   * @return this array.\n    */\n-  public long getLong(int index) throws JSONException {\n-    Object object = this.get(index);\n-    try {\n-      return object instanceof Number ? ((Number) object).longValue()\n-          : Long.parseLong((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONArray[\" + index + \"] is not a number.\");\n-    }\n+  public JSONArray put(Object value) {\n+    values.add(value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the string associated with an index.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @return A string value.\n-   * @throws JSONException If there is no string value for the index.\n+   * Same as {@link #put}, with added validity checks.\n+   *\n+   * @param value The value to append.\n    */\n-  public String getString(int index) throws JSONException {\n-    Object object = this.get(index);\n-    if (object instanceof String) {\n-      return (String) object;\n+  void checkedPut(Object value) throws JSONException {\n+    if (value instanceof Number) {\n+      JSON.checkDouble(((Number) value).doubleValue());\n     }\n-    throw new JSONException(\"JSONArray[\" + index + \"] not a string.\");\n-  }\n \n+    put(value);\n+  }\n \n   /**\n-   * Determine if the value is null.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @return true if the value at the index is null, or if there is no value.\n+   * Sets the value at {@code index} to {@code value}, null padding this array to the required\n+   * length if necessary. If a value already exists at {@code\n+   * index}, it will be replaced.\n+   *\n+   * @param index Where to put the value.\n+   * @param value The value to set.\n+   * @return this array.\n+   * @throws JSONException This should never happen.\n    */\n-  public boolean isNull(int index) {\n-    return JSONObject.NULL.equals(this.opt(index));\n+  public JSONArray put(int index, boolean value) throws JSONException {\n+    return put(index, (Boolean) value);\n   }\n \n-\n   /**\n-   * Make a string from the contents of this JSONArray. The <code>separator</code> string is\n-   * inserted between each element. Warning: This method assumes that the data structure is\n-   * acyclical.\n-   * \n-   * @param separator A string that will be inserted between the elements.\n-   * @return a string.\n-   * @throws JSONException If the array contains an invalid number.\n+   * Sets the value at {@code index} to {@code value}, null padding this array to the required\n+   * length if necessary. If a value already exists at {@code\n+   * index}, it will be replaced.\n+   *\n+   * @param index Where to put the value.\n+   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this array.\n+   * @throws JSONException If the value is not a finite value.\n    */\n-  public String join(String separator) throws JSONException {\n-    int len = this.length();\n-    StringBuffer sb = new StringBuffer();\n-\n-    for (int i = 0; i < len; i += 1) {\n-      if (i > 0) {\n-        sb.append(separator);\n-      }\n-      sb.append(JSONObject.valueToString(this.myArrayList.get(i)));\n-    }\n-    return sb.toString();\n+  public JSONArray put(int index, double value) throws JSONException {\n+    return put(index, (Double) value);\n   }\n \n-\n   /**\n-   * Get the number of elements in the JSONArray, included nulls.\n+   * Sets the value at {@code index} to {@code value}, null padding this array to the required\n+   * length if necessary. If a value already exists at {@code\n+   * index}, it will be replaced.\n    *\n-   * @return The length (or size).\n+   * @param index Where to put the value.\n+   * @param value The value to set.\n+   * @return this array.\n+   * @throws JSONException Should never actually happen.\n    */\n-  public int length() {\n-    return this.myArrayList.size();\n+  public JSONArray put(int index, int value) throws JSONException {\n+    return put(index, (Integer) value);\n   }\n \n-\n   /**\n-   * Get the optional object value associated with an index.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @return An object value, or null if there is no object at that index.\n+   * Sets the value at {@code index} to {@code value}, null padding this array to the required\n+   * length if necessary. If a value already exists at {@code\n+   * index}, it will be replaced.\n+   *\n+   * @param index Where to put the value.\n+   * @param value The value to set.\n+   * @return this array.\n+   * @throws JSONException Should never actually happen.\n    */\n-  public Object opt(int index) {\n-    return (index < 0 || index >= this.length()) ? null : this.myArrayList.get(index);\n+  public JSONArray put(int index, long value) throws JSONException {\n+    return put(index, (Long) value);\n   }\n \n-\n   /**\n-   * Get the optional boolean value associated with an index. It returns false if there is no value\n-   * at that index, or if the value is not Boolean.TRUE or the String \"true\".\n+   * Sets the value at {@code index} to {@code value} wrapped into {@link JSONArray}, null padding\n+   * this array to the required length if necessary. If a value already exists at {@code index}, it\n+   * will be replaced.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The truth.\n-   */\n-  public boolean optBoolean(int index) {\n-    return this.optBoolean(index, false);\n+   * @param index Where to put the value.\n+   * @param value The value to set.\n+   * @return this array.\n+   * @throws JSONException Should never actually happen.\n+   */\n+  public JSONArray put(int index, Collection<?> value) throws JSONException {\n+    if (value == null) {\n+      return put(index, (Object) null);\n+    }\n+    return put(index, new JSONArray(value));\n   }\n \n-\n   /**\n-   * Get the optional boolean value associated with an index. It returns the defaultValue if there\n-   * is no value at that index or if it is not a Boolean or the String \"true\" or \"false\" (case\n-   * insensitive).\n+   * Sets the value at {@code index} to {@code value}, null padding this array to the required\n+   * length if necessary. If a value already exists at {@code\n+   * index}, it will be replaced.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @param defaultValue A boolean default.\n-   * @return The truth.\n+   * @param index Where to put the value.\n+   * @param value a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double,\n+   *        {@link JSONObject#NULL}, or {@code null}. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this array.\n+   * @throws JSONException If the value cannot be represented as a finite double value.\n    */\n-  public boolean optBoolean(int index, boolean defaultValue) {\n-    try {\n-      return this.getBoolean(index);\n-    } catch (Exception e) {\n-      return defaultValue;\n+  public JSONArray put(int index, Object value) throws JSONException {\n+    if (value instanceof Number) {\n+      // deviate from the original by checking all Numbers, not just floats & doubles\n+      JSON.checkDouble(((Number) value).doubleValue());\n+    }\n+    while (values.size() <= index) {\n+      values.add(null);\n     }\n+    values.set(index, value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the optional double value associated with an index. NaN is returned if there is no value\n-   * for the index, or if the value is not a number and cannot be converted to a number.\n+   * Returns true if this array has no value at {@code index}, or if its value is the {@code null}\n+   * reference or {@link JSONObject#NULL}.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n+   * @param index Which value to check.\n+   * @return true if the value is null.\n    */\n-  public double optDouble(int index) {\n-    return this.optDouble(index, Double.NaN);\n+  public boolean isNull(int index) {\n+    Object value = opt(index);\n+    return value == null || value == JSONObject.NULL;\n   }\n \n-\n   /**\n-   * Get the optional double value associated with an index. The defaultValue is returned if there\n-   * is no value for the index, or if the value is not a number and cannot be converted to a number.\n+   * Returns the value at {@code index}.\n    *\n-   * @param index subscript\n-   * @param defaultValue The default value.\n-   * @return The value.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if this array has no value at {@code index}, or if that value is the\n+   *         {@code null} reference. This method returns normally if the value is\n+   *         {@code JSONObject#NULL}.\n    */\n-  public double optDouble(int index, double defaultValue) {\n+  public Object get(int index) throws JSONException {\n     try {\n-      return this.getDouble(index);\n-    } catch (Exception e) {\n-      return defaultValue;\n+      Object value = values.get(index);\n+      if (value == null) {\n+        throw new JSONException(\"Value at \" + index + \" is null.\");\n+      }\n+      return value;\n+    } catch (IndexOutOfBoundsException e) {\n+      throw new JSONException(\"Index \" + index + \" out of range [0..\" + values.size() + \")\");\n     }\n   }\n \n-\n   /**\n-   * Get the optional int value associated with an index. Zero is returned if there is no value for\n-   * the index, or if the value is not a number and cannot be converted to a number.\n+   * Returns the value at {@code index}, or null if the array has no value at {@code index}.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public int optInt(int index) {\n-    return this.optInt(index, 0);\n+  public Object opt(int index) {\n+    if (index < 0 || index >= values.size()) {\n+      return null;\n+    }\n+    return values.get(index);\n   }\n \n-\n   /**\n-   * Get the optional int value associated with an index. The defaultValue is returned if there is\n-   * no value for the index, or if the value is not a number and cannot be converted to a number.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @param defaultValue The default value.\n-   * @return The value.\n+   * Removes and returns the value at {@code index}, or null if the array has no value at\n+   * {@code index}.\n+   *\n+   * @param index Which value to remove.\n+   * @return The value previously at the specified location.\n    */\n-  public int optInt(int index, int defaultValue) {\n-    try {\n-      return this.getInt(index);\n-    } catch (Exception e) {\n-      return defaultValue;\n+  public Object remove(int index) {\n+    if (index < 0 || index >= values.size()) {\n+      return null;\n     }\n+    return values.remove(index);\n   }\n \n-\n   /**\n-   * Get the optional JSONArray associated with an index.\n-   * \n-   * @param index subscript\n-   * @return A JSONArray value, or null if the index has no value, or if the value is not a\n-   *         JSONArray.\n+   * Returns the value at {@code index} if it exists and is a boolean or can be coerced to a\n+   * boolean.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value at {@code index} doesn't exist or cannot be coerced to a\n+   *         boolean.\n    */\n-  public JSONArray optJSONArray(int index) {\n-    Object o = this.opt(index);\n-    return o instanceof JSONArray ? (JSONArray) o : null;\n+  public boolean getBoolean(int index) throws JSONException {\n+    Object object = get(index);\n+    Boolean result = JSON.toBoolean(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(index, object, \"boolean\");\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Get the optional JSONObject associated with an index. Null is returned if the key is not found,\n-   * or null if the index has no value, or if the value is not a JSONObject.\n+   * Returns the value at {@code index} if it exists and is a boolean or can be coerced to a\n+   * boolean. Returns false otherwise.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return A JSONObject value.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONObject optJSONObject(int index) {\n-    Object o = this.opt(index);\n-    return o instanceof JSONObject ? (JSONObject) o : null;\n+  public boolean optBoolean(int index) {\n+    return optBoolean(index, false);\n   }\n \n-\n   /**\n-   * Get the optional long value associated with an index. Zero is returned if there is no value for\n-   * the index, or if the value is not a number and cannot be converted to a number.\n+   * Returns the value at {@code index} if it exists and is a boolean or can be coerced to a\n+   * boolean. Returns {@code fallback} otherwise.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return The value.\n+   * @param index Which value to get.\n+   * @param fallback the fallback value to return if no value exists.\n+   * @return the value at the specified location or the fallback value.\n    */\n-  public long optLong(int index) {\n-    return this.optLong(index, 0);\n+  public boolean optBoolean(int index, boolean fallback) {\n+    Object object = opt(index);\n+    Boolean result = JSON.toBoolean(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Get the optional long value associated with an index. The defaultValue is returned if there is\n-   * no value for the index, or if the value is not a number and cannot be converted to a number.\n-   * \n-   * @param index The index must be between 0 and length() - 1.\n-   * @param defaultValue The default value.\n-   * @return The value.\n+   * Returns the value at {@code index} if it exists and is a double or can be coerced to a double.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value at {@code index} doesn't exist or cannot be coerced to a\n+   *         double.\n    */\n-  public long optLong(int index, long defaultValue) {\n-    try {\n-      return this.getLong(index);\n-    } catch (Exception e) {\n-      return defaultValue;\n+  public double getDouble(int index) throws JSONException {\n+    Object object = get(index);\n+    Double result = JSON.toDouble(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(index, object, \"double\");\n     }\n+    return result;\n   }\n \n-\n   /**\n-   * Get the optional string value associated with an index. It returns an empty string if there is\n-   * no value at that index. If the value is not a string and is not null, then it is coverted to a\n-   * string.\n+   * Returns the value at {@code index} if it exists and is a double or can be coerced to a double.\n+   * Returns {@code NaN} otherwise.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @return A String value.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public String optString(int index) {\n-    return this.optString(index, \"\");\n+  public double optDouble(int index) {\n+    return optDouble(index, Double.NaN);\n   }\n \n-\n   /**\n-   * Get the optional string associated with an index. The defaultValue is returned if the key is\n-   * not found.\n+   * Returns the value at {@code index} if it exists and is a double or can be coerced to a double.\n+   * Returns {@code fallback} otherwise.\n    *\n-   * @param index The index must be between 0 and length() - 1.\n-   * @param defaultValue The default value.\n-   * @return A String value.\n+   * @param index Which value to get.\n+   * @param fallback The fallback value to use if no value is at the specified location.\n+   * @return the value at the specified location or the fallback value.\n    */\n-  public String optString(int index, String defaultValue) {\n-    Object object = this.opt(index);\n-    return JSONObject.NULL.equals(object) ? defaultValue : object.toString();\n+  public double optDouble(int index, double fallback) {\n+    Object object = opt(index);\n+    Double result = JSON.toDouble(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Append a boolean value. This increases the array's length by one.\n+   * Returns the value at {@code index} if it exists and is an int or can be coerced to an int.\n    *\n-   * @param value A boolean value.\n-   * @return this.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value at {@code index} doesn't exist or cannot be coerced to a\n+   *         int.\n    */\n-  public JSONArray put(boolean value) {\n-    this.put(value ? Boolean.TRUE : Boolean.FALSE);\n-    return this;\n+  public int getInt(int index) throws JSONException {\n+    Object object = get(index);\n+    Integer result = JSON.toInteger(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(index, object, \"int\");\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Put a value in the JSONArray, where the value will be a JSONArray which is produced from a\n-   * Collection.\n-   * \n-   * @param value A Collection value.\n-   * @return this.\n+   * Returns the value at {@code index} if it exists and is an int or can be coerced to an int.\n+   * Returns 0 otherwise.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONArray put(Collection value) {\n-    this.put(new JSONArray(value));\n-    return this;\n+  public int optInt(int index) {\n+    return optInt(index, 0);\n   }\n \n-\n   /**\n-   * Append a double value. This increases the array's length by one.\n+   * Returns the value at {@code index} if it exists and is an int or can be coerced to an int.\n+   * Returns {@code fallback} otherwise.\n    *\n-   * @param value A double value.\n-   * @throws JSONException if the value is not finite.\n-   * @return this.\n+   * @param index Which value to get.\n+   * @param fallback The fallback value to use if no value is at the specified location.\n+   * @return the value at the specified location or the fallback value.\n    */\n-  public JSONArray put(double value) throws JSONException {\n-    Double d = new Double(value);\n-    JSONObject.testValidity(d);\n-    this.put(d);\n-    return this;\n+  public int optInt(int index, int fallback) {\n+    Object object = opt(index);\n+    Integer result = JSON.toInteger(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Append an int value. This increases the array's length by one.\n+   * Returns the value at {@code index} if it exists and is a long or can be coerced to a long.\n    *\n-   * @param value An int value.\n-   * @return this.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value at {@code index} doesn't exist or cannot be coerced to a\n+   *         long.\n    */\n-  public JSONArray put(int value) {\n-    this.put(new Integer(value));\n-    return this;\n+  public long getLong(int index) throws JSONException {\n+    Object object = get(index);\n+    Long result = JSON.toLong(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(index, object, \"long\");\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Append an long value. This increases the array's length by one.\n+   * Returns the value at {@code index} if it exists and is a long or can be coerced to a long.\n+   * Returns 0 otherwise.\n    *\n-   * @param value A long value.\n-   * @return this.\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONArray put(long value) {\n-    this.put(new Long(value));\n-    return this;\n+  public long optLong(int index) {\n+    return optLong(index, 0L);\n   }\n \n-\n   /**\n-   * Put a value in the JSONArray, where the value will be a JSONObject which is produced from a\n-   * Map.\n-   * \n-   * @param value A Map value.\n-   * @return this.\n+   * Returns the value at {@code index} if it exists and is a long or can be coerced to a long.\n+   * Returns {@code fallback} otherwise.\n+   *\n+   * @param index Which value to get.\n+   * @param fallback The fallback value to use if no value is at the specified location.\n+   * @return the value at the specified location or the fallback value.\n    */\n-  public JSONArray put(Map value) {\n-    this.put(new JSONObject(value));\n-    return this;\n+  public long optLong(int index, long fallback) {\n+    Object object = opt(index);\n+    Long result = JSON.toLong(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Append an object value. This increases the array's length by one.\n-   * \n-   * @param value An object value. The value should be a Boolean, Double, Integer, JSONArray,\n-   *        JSONObject, Long, or String, or the JSONObject.NULL object.\n-   * @return this.\n+   * Returns the value at {@code index} if it exists, coercing it if necessary.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if no such value exists.\n    */\n-  public JSONArray put(Object value) {\n-    this.myArrayList.add(value);\n-    return this;\n+  public String getString(int index) throws JSONException {\n+    Object object = get(index);\n+    String result = JSON.toString(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(index, object, \"String\");\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Put or replace a boolean value in the JSONArray. If the index is greater than the length of the\n-   * JSONArray, then null elements will be added as necessary to pad it out.\n-   * \n-   * @param index The subscript.\n-   * @param value A boolean value.\n-   * @return this.\n-   * @throws JSONException If the index is negative.\n+   * Returns the value at {@code index} if it exists, coercing it if necessary. Returns the empty\n+   * string if no such value exists.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONArray put(int index, boolean value) throws JSONException {\n-    this.put(index, value ? Boolean.TRUE : Boolean.FALSE);\n-    return this;\n+  public String optString(int index) {\n+    return optString(index, \"\");\n   }\n \n-\n   /**\n-   * Put a value in the JSONArray, where the value will be a JSONArray which is produced from a\n-   * Collection.\n-   * \n-   * @param index The subscript.\n-   * @param value A Collection value.\n-   * @return this.\n-   * @throws JSONException If the index is negative or if the value is not finite.\n+   * Returns the value at {@code index} if it exists, coercing it if necessary. Returns\n+   * {@code fallback} if no such value exists.\n+   *\n+   * @param index Which value to get.\n+   * @param fallback The fallback value to use if no value is at the specified location.\n+   * @return the value at the specified location or the fallback value.\n    */\n-  public JSONArray put(int index, Collection value) throws JSONException {\n-    this.put(index, new JSONArray(value));\n-    return this;\n+  public String optString(int index, String fallback) {\n+    Object object = opt(index);\n+    String result = JSON.toString(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Put or replace a double value. If the index is greater than the length of the JSONArray, then\n-   * null elements will be added as necessary to pad it out.\n-   * \n-   * @param index The subscript.\n-   * @param value A double value.\n-   * @return this.\n-   * @throws JSONException If the index is negative or if the value is not finite.\n+   * Returns the value at {@code index} if it exists and is a {@code\n+   * JSONArray}.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value doesn't exist or is not a {@code\n+   *                       JSONArray}.\n    */\n-  public JSONArray put(int index, double value) throws JSONException {\n-    this.put(index, new Double(value));\n-    return this;\n+  public JSONArray getJSONArray(int index) throws JSONException {\n+    Object object = get(index);\n+    if (object instanceof JSONArray) {\n+      return (JSONArray) object;\n+    } else {\n+      throw JSON.typeMismatch(index, object, \"JSONArray\");\n+    }\n   }\n \n-\n   /**\n-   * Put or replace an int value. If the index is greater than the length of the JSONArray, then\n-   * null elements will be added as necessary to pad it out.\n-   * \n-   * @param index The subscript.\n-   * @param value An int value.\n-   * @return this.\n-   * @throws JSONException If the index is negative.\n+   * Returns the value at {@code index} if it exists and is a {@code\n+   * JSONArray}. Returns null otherwise.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONArray put(int index, int value) throws JSONException {\n-    this.put(index, new Integer(value));\n-    return this;\n+  public JSONArray optJSONArray(int index) {\n+    Object object = opt(index);\n+    return object instanceof JSONArray ? (JSONArray) object : null;\n   }\n \n-\n   /**\n-   * Put or replace a long value. If the index is greater than the length of the JSONArray, then\n-   * null elements will be added as necessary to pad it out.\n-   * \n-   * @param index The subscript.\n-   * @param value A long value.\n-   * @return this.\n-   * @throws JSONException If the index is negative.\n+   * Returns the value at {@code index} if it exists and is a {@code\n+   * JSONObject}.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n+   * @throws JSONException if the value doesn't exist or is not a {@code\n+   *                       JSONObject}.\n    */\n-  public JSONArray put(int index, long value) throws JSONException {\n-    this.put(index, new Long(value));\n-    return this;\n+  public JSONObject getJSONObject(int index) throws JSONException {\n+    Object object = get(index);\n+    if (object instanceof JSONObject) {\n+      return (JSONObject) object;\n+    } else {\n+      throw JSON.typeMismatch(index, object, \"JSONObject\");\n+    }\n   }\n \n-\n   /**\n-   * Put a value in the JSONArray, where the value will be a JSONObject that is produced from a Map.\n-   * \n-   * @param index The subscript.\n-   * @param value The Map value.\n-   * @return this.\n-   * @throws JSONException If the index is negative or if the the value is an invalid number.\n+   * Returns the value at {@code index} if it exists and is a {@code\n+   * JSONObject}. Returns null otherwise.\n+   *\n+   * @param index Which value to get.\n+   * @return the value at the specified location.\n    */\n-  public JSONArray put(int index, Map value) throws JSONException {\n-    this.put(index, new JSONObject(value));\n-    return this;\n+  public JSONObject optJSONObject(int index) {\n+    Object object = opt(index);\n+    return object instanceof JSONObject ? (JSONObject) object : null;\n   }\n \n-\n   /**\n-   * Put or replace an object value in the JSONArray. If the index is greater than the length of the\n-   * JSONArray, then null elements will be added as necessary to pad it out.\n-   * \n-   * @param index The subscript.\n-   * @param value The value to put into the array. The value should be a Boolean, Double, Integer,\n-   *        JSONArray, JSONObject, Long, or String, or the JSONObject.NULL object.\n-   * @return this.\n-   * @throws JSONException If the index is negative or if the the value is an invalid number.\n+   * Returns a new object whose values are the values in this array, and whose names are the values\n+   * in {@code names}. Names and values are paired up by index from 0 through to the shorter array's\n+   * length. Names that are not strings will be coerced to strings. This method returns null if\n+   * either array is empty.\n+   *\n+   * @param names The names to apply to the returned values.\n+   * @return the newly constructed object.\n+   * @throws JSONException Should not be possible.\n    */\n-  public JSONArray put(int index, Object value) throws JSONException {\n-    JSONObject.testValidity(value);\n-    if (index < 0) {\n-      throw new JSONException(\"JSONArray[\" + index + \"] not found.\");\n+  public JSONObject toJSONObject(JSONArray names) throws JSONException {\n+    JSONObject result = new JSONObject();\n+    int length = Math.min(names.length(), values.size());\n+    if (length == 0) {\n+      return null;\n     }\n-    if (index < this.length()) {\n-      this.myArrayList.set(index, value);\n-    } else {\n-      while (index != this.length()) {\n-        this.put(JSONObject.NULL);\n-      }\n-      this.put(value);\n+    for (int i = 0; i < length; i++) {\n+      String name = JSON.toString(names.opt(i));\n+      result.put(name, opt(i));\n     }\n-    return this;\n+    return result;\n   }\n \n-\n   /**\n-   * Remove an index and close the hole.\n+   * Returns a new string by alternating this array's values with {@code\n+   * separator}. This array's string values are quoted and have their special characters escaped.\n+   * For example, the array containing the strings '12\" pizza', 'taco' and 'soda' joined on '+'\n+   * returns this:\n    * \n-   * @param index The index of the element to be removed.\n-   * @return The value that was associated with the index, or null if there was no value.\n-   */\n-  public Object remove(int index) {\n-    Object o = this.opt(index);\n-    this.myArrayList.remove(index);\n-    return o;\n-  }\n-\n-\n-  /**\n-   * Produce a JSONObject by combining a JSONArray of names with the values of this JSONArray.\n-   * \n-   * @param names A JSONArray containing a list of key strings. These will be paired with the\n-   *        values.\n-   * @return A JSONObject, or null if there are no names or if this JSONArray has no values.\n-   * @throws JSONException If any of the names are null.\n+   * <pre>\n+   * \"12\\\" pizza\" + \"taco\" + \"soda\"\n+   * </pre>\n+   *\n+   * @param separator The string used to separate the returned values.\n+   * @return the conjoined values.\n+   * @throws JSONException Only if there is a coding error.\n    */\n-  public JSONObject toJSONObject(JSONArray names) throws JSONException {\n-    if (names == null || names.length() == 0 || this.length() == 0) {\n-      return null;\n-    }\n-    JSONObject jo = new JSONObject();\n-    for (int i = 0; i < names.length(); i += 1) {\n-      jo.put(names.getString(i), this.opt(i));\n+  public String join(String separator) throws JSONException {\n+    JSONStringer stringer = new JSONStringer();\n+    stringer.open(JSONStringer.Scope.NULL, \"\");\n+    for (int i = 0, size = values.size(); i < size; i++) {\n+      if (i > 0) {\n+        stringer.out.append(separator);\n+      }\n+      stringer.value(values.get(i));\n     }\n-    return jo;\n+    stringer.close(JSONStringer.Scope.NULL, JSONStringer.Scope.NULL, \"\");\n+    return stringer.out.toString();\n   }\n \n-\n   /**\n-   * Make a JSON text of this JSONArray. For compactness, no unnecessary whitespace is added. If it\n-   * is not possible to produce a syntactically correct JSON text then null will be returned\n-   * instead. This could occur if the array contains an invalid number.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n+   * Encodes this array as a compact JSON string, such as:\n+   * \n+   * <pre>\n+   * [94043,90210]\n+   * </pre>\n    *\n-   * @return a printable, displayable, transmittable representation of the array.\n+   * @return The string form of this array.\n    */\n+  @Override\n   public String toString() {\n     try {\n-      return '[' + this.join(\",\") + ']';\n-    } catch (Exception e) {\n+      JSONStringer stringer = new JSONStringer();\n+      writeTo(stringer);\n+      return stringer.toString();\n+    } catch (JSONException e) {\n       return null;\n     }\n   }\n \n-\n   /**\n-   * Make a prettyprinted JSON text of this JSONArray. Warning: This method assumes that the data\n-   * structure is acyclical.\n+   * Encodes this array as a human readable JSON string for debugging, such as:\n    * \n-   * @param indentFactor The number of spaces to add to each level of indentation.\n-   * @return a printable, displayable, transmittable representation of the object, beginning with\n-   *         <code>[</code>&nbsp;<small>(left bracket)</small> and ending with\n-   *         <code>]</code>&nbsp;<small>(right bracket)</small>.\n-   * @throws JSONException\n-   */\n-  public String toString(int indentFactor) throws JSONException {\n-    StringWriter sw = new StringWriter();\n-    synchronized (sw.getBuffer()) {\n-      return this.write(sw, indentFactor, 0).toString();\n-    }\n-  }\n-\n-  /**\n-   * Write the contents of the JSONArray as JSON text to a writer. For compactness, no whitespace is\n-   * added.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n+   * <pre>\n+   * [\n+   *     94043,\n+   *     90210\n+   * ]\n+   * </pre>\n    *\n-   * @return The writer.\n-   * @throws JSONException\n+   * @param indentSpaces the number of spaces to indent for each level of nesting.\n+   * @return The string form of this array.\n+   * @throws JSONException Only if there is a coding error.\n    */\n-  public Writer write(Writer writer) throws JSONException {\n-    return this.write(writer, 0, 0);\n+  public String toString(int indentSpaces) throws JSONException {\n+    JSONStringer stringer = new JSONStringer(indentSpaces);\n+    writeTo(stringer);\n+    return stringer.toString();\n   }\n \n-  /**\n-   * Write the contents of the JSONArray as JSON text to a writer. For compactness, no whitespace is\n-   * added.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n-   *\n-   * @param indentFactor The number of spaces to add to each level of indentation.\n-   * @param indent The indention of the top level.\n-   * @return The writer.\n-   * @throws JSONException\n-   */\n-  Writer write(Writer writer, int indentFactor, int indent) throws JSONException {\n-    try {\n-      boolean commanate = false;\n-      int length = this.length();\n-      writer.write('[');\n-\n-      if (length == 1) {\n-        JSONObject.writeValue(writer, this.myArrayList.get(0), indentFactor, indent);\n-      } else if (length != 0) {\n-        final int newindent = indent + indentFactor;\n-\n-        for (int i = 0; i < length; i += 1) {\n-          if (commanate) {\n-            writer.write(',');\n-          }\n-          if (indentFactor > 0) {\n-            writer.write('\\n');\n-          }\n-          JSONObject.indent(writer, newindent);\n-          JSONObject.writeValue(writer, this.myArrayList.get(i), indentFactor, newindent);\n-          commanate = true;\n-        }\n-        if (indentFactor > 0) {\n-          writer.write('\\n');\n-        }\n-        JSONObject.indent(writer, indent);\n-      }\n-      writer.write(']');\n-      return writer;\n-    } catch (IOException e) {\n-      throw new JSONException(e);\n+  void writeTo(JSONStringer stringer) throws JSONException {\n+    stringer.array();\n+    for (Object value : values) {\n+      stringer.value(value);\n     }\n+    stringer.endArray();\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    return o instanceof JSONArray && ((JSONArray) o).values.equals(values);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    // diverge from the original, which doesn't implement hashCode\n+    return values.hashCode();\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONArray.java",
                "sha": "c9611393c3a264f3444142398f83ddd33a6de8af",
                "status": "modified"
            },
            {
                "additions": 45,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONException.java",
                "changes": 62,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONException.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 17,
                "filename": "geode-json/src/main/java/org/json/JSONException.java",
                "patch": "@@ -1,30 +1,58 @@\n+/*\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n package org.json;\n \n+// Note: this class was written without inspecting the non-free org.json sourcecode.\n+\n /**\n- * The JSONException is thrown by the JSON.org classes when things are amiss.\n+ * Thrown to indicate a problem with the JSON API. Such problems include:\n+ * <ul>\n+ * <li>Attempts to parse or construct malformed documents\n+ * <li>Use of null as a name\n+ * <li>Use of numeric types not available to JSON, such as {@link Double#isNaN() NaNs} or\n+ * {@link Double#isInfinite() infinities}.\n+ * <li>Lookups using an out of range index or nonexistent name\n+ * <li>Type mismatches on lookups\n+ * </ul>\n+ *\n+ * <p>\n+ * Although this is a checked exception, it is rarely recoverable. Most callers should simply wrap\n+ * this exception in an unchecked exception and rethrow:\n  * \n- * @author JSON.org\n- * @version 2010-12-24\n+ * <pre>\n+ *   public JSONArray toJSONObject() {\n+ *     try {\n+ *         JSONObject result = new JSONObject();\n+ *         ...\n+ *     } catch (JSONException e) {\n+ *         throw new RuntimeException(e);\n+ *     }\n+ * }\n+ * </pre>\n  */\n-public class JSONException extends Exception {\n-  private static final long serialVersionUID = 0;\n-  private Throwable cause;\n+public class JSONException extends RuntimeException {\n \n-  /**\n-   * Constructs a JSONException with an explanatory message.\n-   * \n-   * @param message Detail about the reason for the exception.\n-   */\n-  public JSONException(String message) {\n-    super(message);\n+  public JSONException(String s) {\n+    super(s);\n   }\n \n   public JSONException(Throwable cause) {\n-    super(cause.getMessage());\n-    this.cause = cause;\n+    super(cause);\n   }\n \n-  public Throwable getCause() {\n-    return this.cause;\n+  public JSONException(String message, Throwable cause) {\n+    super(message, cause);\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONException.java",
                "sha": "83fb4b89781401ab3e9d7a34828d5125f68ad2c2",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/JSONML.java",
                "changes": 454,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONML.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 454,
                "filename": "geode-json/src/main/java/org/json/JSONML.java",
                "patch": "@@ -1,454 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2008 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-import java.util.Iterator;\n-\n-\n-/**\n- * This provides static methods to convert an XML text into a JSONArray or JSONObject, and to covert\n- * a JSONArray or JSONObject into an XML text using the JsonML transform.\n- * \n- * @author JSON.org\n- * @version 2012-03-28\n- */\n-public class JSONML {\n-\n-  /**\n-   * Parse XML values and store them in a JSONArray.\n-   * \n-   * @param x The XMLTokener containing the source string.\n-   * @param arrayForm true if array form, false if object form.\n-   * @param ja The JSONArray that is containing the current tag or null if we are at the outermost\n-   *        level.\n-   * @return A JSONArray if the value is the outermost tag, otherwise null.\n-   * @throws JSONException\n-   */\n-  private static Object parse(XMLTokener x, boolean arrayForm, JSONArray ja) throws JSONException {\n-    String attribute;\n-    char c;\n-    String closeTag = null;\n-    int i;\n-    JSONArray newja = null;\n-    JSONObject newjo = null;\n-    Object token;\n-    String tagName = null;\n-\n-    // Test for and skip past these forms:\n-    // <!-- ... -->\n-    // <![ ... ]]>\n-    // <! ... >\n-    // <? ... ?>\n-\n-    while (true) {\n-      if (!x.more()) {\n-        throw x.syntaxError(\"Bad XML\");\n-      }\n-      token = x.nextContent();\n-      if (token == XML.LT) {\n-        token = x.nextToken();\n-        if (token instanceof Character) {\n-          if (token == XML.SLASH) {\n-\n-            // Close tag </\n-\n-            token = x.nextToken();\n-            if (!(token instanceof String)) {\n-              throw new JSONException(\"Expected a closing name instead of '\" + token + \"'.\");\n-            }\n-            if (x.nextToken() != XML.GT) {\n-              throw x.syntaxError(\"Misshaped close tag\");\n-            }\n-            return token;\n-          } else if (token == XML.BANG) {\n-\n-            // <!\n-\n-            c = x.next();\n-            if (c == '-') {\n-              if (x.next() == '-') {\n-                x.skipPast(\"-->\");\n-              } else {\n-                x.back();\n-              }\n-            } else if (c == '[') {\n-              token = x.nextToken();\n-              if (token.equals(\"CDATA\") && x.next() == '[') {\n-                if (ja != null) {\n-                  ja.put(x.nextCDATA());\n-                }\n-              } else {\n-                throw x.syntaxError(\"Expected 'CDATA['\");\n-              }\n-            } else {\n-              i = 1;\n-              do {\n-                token = x.nextMeta();\n-                if (token == null) {\n-                  throw x.syntaxError(\"Missing '>' after '<!'.\");\n-                } else if (token == XML.LT) {\n-                  i += 1;\n-                } else if (token == XML.GT) {\n-                  i -= 1;\n-                }\n-              } while (i > 0);\n-            }\n-          } else if (token == XML.QUEST) {\n-\n-            // <?\n-\n-            x.skipPast(\"?>\");\n-          } else {\n-            throw x.syntaxError(\"Misshaped tag\");\n-          }\n-\n-          // Open tag <\n-\n-        } else {\n-          if (!(token instanceof String)) {\n-            throw x.syntaxError(\"Bad tagName '\" + token + \"'.\");\n-          }\n-          tagName = (String) token;\n-          newja = new JSONArray();\n-          newjo = new JSONObject();\n-          if (arrayForm) {\n-            newja.put(tagName);\n-            if (ja != null) {\n-              ja.put(newja);\n-            }\n-          } else {\n-            newjo.put(\"tagName\", tagName);\n-            if (ja != null) {\n-              ja.put(newjo);\n-            }\n-          }\n-          token = null;\n-          for (;;) {\n-            if (token == null) {\n-              token = x.nextToken();\n-            }\n-            if (token == null) {\n-              throw x.syntaxError(\"Misshaped tag\");\n-            }\n-            if (!(token instanceof String)) {\n-              break;\n-            }\n-\n-            // attribute = value\n-\n-            attribute = (String) token;\n-            if (!arrayForm && (\"tagName\".equals(attribute) || \"childNode\".equals(attribute))) {\n-              throw x.syntaxError(\"Reserved attribute.\");\n-            }\n-            token = x.nextToken();\n-            if (token == XML.EQ) {\n-              token = x.nextToken();\n-              if (!(token instanceof String)) {\n-                throw x.syntaxError(\"Missing value\");\n-              }\n-              newjo.accumulate(attribute, XML.stringToValue((String) token));\n-              token = null;\n-            } else {\n-              newjo.accumulate(attribute, \"\");\n-            }\n-          }\n-          if (arrayForm && newjo.length() > 0) {\n-            newja.put(newjo);\n-          }\n-\n-          // Empty tag <.../>\n-\n-          if (token == XML.SLASH) {\n-            if (x.nextToken() != XML.GT) {\n-              throw x.syntaxError(\"Misshaped tag\");\n-            }\n-            if (ja == null) {\n-              if (arrayForm) {\n-                return newja;\n-              } else {\n-                return newjo;\n-              }\n-            }\n-\n-            // Content, between <...> and </...>\n-\n-          } else {\n-            if (token != XML.GT) {\n-              throw x.syntaxError(\"Misshaped tag\");\n-            }\n-            closeTag = (String) parse(x, arrayForm, newja);\n-            if (closeTag != null) {\n-              if (!closeTag.equals(tagName)) {\n-                throw x.syntaxError(\"Mismatched '\" + tagName + \"' and '\" + closeTag + \"'\");\n-              }\n-              tagName = null;\n-              if (!arrayForm && newja.length() > 0) {\n-                newjo.put(\"childNodes\", newja);\n-              }\n-              if (ja == null) {\n-                if (arrayForm) {\n-                  return newja;\n-                } else {\n-                  return newjo;\n-                }\n-              }\n-            }\n-          }\n-        }\n-      } else {\n-        if (ja != null) {\n-          ja.put(token instanceof String ? XML.stringToValue((String) token) : token);\n-        }\n-      }\n-    }\n-  }\n-\n-\n-  /**\n-   * Convert a well-formed (but not necessarily valid) XML string into a JSONArray using the JsonML\n-   * transform. Each XML tag is represented as a JSONArray in which the first element is the tag\n-   * name. If the tag has attributes, then the second element will be JSONObject containing the\n-   * name/value pairs. If the tag contains children, then strings and JSONArrays will represent the\n-   * child tags. Comments, prologs, DTDs, and <code>&lt;[ [ ]]></code> are ignored.\n-   * \n-   * @param string The source string.\n-   * @return A JSONArray containing the structured data from the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(String string) throws JSONException {\n-    return toJSONArray(new XMLTokener(string));\n-  }\n-\n-\n-  /**\n-   * Convert a well-formed (but not necessarily valid) XML string into a JSONArray using the JsonML\n-   * transform. Each XML tag is represented as a JSONArray in which the first element is the tag\n-   * name. If the tag has attributes, then the second element will be JSONObject containing the\n-   * name/value pairs. If the tag contains children, then strings and JSONArrays will represent the\n-   * child content and tags. Comments, prologs, DTDs, and <code>&lt;[ [ ]]></code> are ignored.\n-   * \n-   * @param x An XMLTokener.\n-   * @return A JSONArray containing the structured data from the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONArray toJSONArray(XMLTokener x) throws JSONException {\n-    return (JSONArray) parse(x, true, null);\n-  }\n-\n-\n-  /**\n-   * Convert a well-formed (but not necessarily valid) XML string into a JSONObject using the JsonML\n-   * transform. Each XML tag is represented as a JSONObject with a \"tagName\" property. If the tag\n-   * has attributes, then the attributes will be in the JSONObject as properties. If the tag\n-   * contains children, the object will have a \"childNodes\" property which will be an array of\n-   * strings and JsonML JSONObjects.\n-   * \n-   * Comments, prologs, DTDs, and <code>&lt;[ [ ]]></code> are ignored.\n-   * \n-   * @param x An XMLTokener of the XML source text.\n-   * @return A JSONObject containing the structured data from the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(XMLTokener x) throws JSONException {\n-    return (JSONObject) parse(x, false, null);\n-  }\n-\n-\n-  /**\n-   * Convert a well-formed (but not necessarily valid) XML string into a JSONObject using the JsonML\n-   * transform. Each XML tag is represented as a JSONObject with a \"tagName\" property. If the tag\n-   * has attributes, then the attributes will be in the JSONObject as properties. If the tag\n-   * contains children, the object will have a \"childNodes\" property which will be an array of\n-   * strings and JsonML JSONObjects.\n-   * \n-   * Comments, prologs, DTDs, and <code>&lt;[ [ ]]></code> are ignored.\n-   * \n-   * @param string The XML source text.\n-   * @return A JSONObject containing the structured data from the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(String string) throws JSONException {\n-    return toJSONObject(new XMLTokener(string));\n-  }\n-\n-\n-  /**\n-   * Reverse the JSONML transformation, making an XML text from a JSONArray.\n-   * \n-   * @param ja A JSONArray.\n-   * @return An XML string.\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONArray ja) throws JSONException {\n-    int i;\n-    JSONObject jo;\n-    String key;\n-    Iterator keys;\n-    int length;\n-    Object object;\n-    StringBuffer sb = new StringBuffer();\n-    String tagName;\n-    String value;\n-\n-    // Emit <tagName\n-\n-    tagName = ja.getString(0);\n-    XML.noSpace(tagName);\n-    tagName = XML.escape(tagName);\n-    sb.append('<');\n-    sb.append(tagName);\n-\n-    object = ja.opt(1);\n-    if (object instanceof JSONObject) {\n-      i = 2;\n-      jo = (JSONObject) object;\n-\n-      // Emit the attributes\n-\n-      keys = jo.keys();\n-      while (keys.hasNext()) {\n-        key = keys.next().toString();\n-        XML.noSpace(key);\n-        value = jo.optString(key);\n-        if (value != null) {\n-          sb.append(' ');\n-          sb.append(XML.escape(key));\n-          sb.append('=');\n-          sb.append('\"');\n-          sb.append(XML.escape(value));\n-          sb.append('\"');\n-        }\n-      }\n-    } else {\n-      i = 1;\n-    }\n-\n-    // Emit content in body\n-\n-    length = ja.length();\n-    if (i >= length) {\n-      sb.append('/');\n-      sb.append('>');\n-    } else {\n-      sb.append('>');\n-      do {\n-        object = ja.get(i);\n-        i += 1;\n-        if (object != null) {\n-          if (object instanceof String) {\n-            sb.append(XML.escape(object.toString()));\n-          } else if (object instanceof JSONObject) {\n-            sb.append(toString((JSONObject) object));\n-          } else if (object instanceof JSONArray) {\n-            sb.append(toString((JSONArray) object));\n-          }\n-        }\n-      } while (i < length);\n-      sb.append('<');\n-      sb.append('/');\n-      sb.append(tagName);\n-      sb.append('>');\n-    }\n-    return sb.toString();\n-  }\n-\n-  /**\n-   * Reverse the JSONML transformation, making an XML text from a JSONObject. The JSONObject must\n-   * contain a \"tagName\" property. If it has children, then it must have a \"childNodes\" property\n-   * containing an array of objects. The other properties are attributes with string values.\n-   * \n-   * @param jo A JSONObject.\n-   * @return An XML string.\n-   * @throws JSONException\n-   */\n-  public static String toString(JSONObject jo) throws JSONException {\n-    StringBuffer sb = new StringBuffer();\n-    int i;\n-    JSONArray ja;\n-    String key;\n-    Iterator keys;\n-    int length;\n-    Object object;\n-    String tagName;\n-    String value;\n-\n-    // Emit <tagName\n-\n-    tagName = jo.optString(\"tagName\");\n-    if (tagName == null) {\n-      return XML.escape(jo.toString());\n-    }\n-    XML.noSpace(tagName);\n-    tagName = XML.escape(tagName);\n-    sb.append('<');\n-    sb.append(tagName);\n-\n-    // Emit the attributes\n-\n-    keys = jo.keys();\n-    while (keys.hasNext()) {\n-      key = keys.next().toString();\n-      if (!\"tagName\".equals(key) && !\"childNodes\".equals(key)) {\n-        XML.noSpace(key);\n-        value = jo.optString(key);\n-        if (value != null) {\n-          sb.append(' ');\n-          sb.append(XML.escape(key));\n-          sb.append('=');\n-          sb.append('\"');\n-          sb.append(XML.escape(value));\n-          sb.append('\"');\n-        }\n-      }\n-    }\n-\n-    // Emit content in body\n-\n-    ja = jo.optJSONArray(\"childNodes\");\n-    if (ja == null) {\n-      sb.append('/');\n-      sb.append('>');\n-    } else {\n-      sb.append('>');\n-      length = ja.length();\n-      for (i = 0; i < length; i += 1) {\n-        object = ja.get(i);\n-        if (object != null) {\n-          if (object instanceof String) {\n-            sb.append(XML.escape(object.toString()));\n-          } else if (object instanceof JSONObject) {\n-            sb.append(toString((JSONObject) object));\n-          } else if (object instanceof JSONArray) {\n-            sb.append(toString((JSONArray) object));\n-          } else {\n-            sb.append(object.toString());\n-          }\n-        }\n-      }\n-      sb.append('<');\n-      sb.append('/');\n-      sb.append(tagName);\n-      sb.append('>');\n-    }\n-    return sb.toString();\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/JSONML.java",
                "sha": "b535614f8e9b44981e872797fb8cd7a7307bbb84",
                "status": "removed"
            },
            {
                "additions": 696,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONObject.java",
                "changes": 1915,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONObject.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 1219,
                "filename": "geode-json/src/main/java/org/json/JSONObject.java",
                "patch": "@@ -1,1525 +1,1002 @@\n-package org.json;\n-\n /*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n  */\n \n-import java.io.IOException;\n-import java.io.StringWriter;\n-import java.io.Writer;\n-import java.lang.reflect.Field;\n+package org.json;\n+\n import java.lang.reflect.Method;\n import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.Enumeration;\n import java.util.Iterator;\n import java.util.LinkedHashMap;\n-import java.util.Locale;\n import java.util.Map;\n-import java.util.ResourceBundle;\n import java.util.Set;\n+import java.util.TreeMap;\n+\n+// Note: this class was written without inspecting the non-free org.json sourcecode.\n \n /**\n- * A JSONObject is an unordered collection of name/value pairs. Its external form is a string\n- * wrapped in curly braces with colons between the names and values, and commas between the values\n- * and names. The internal form is an object having <code>get</code> and <code>opt</code> methods\n- * for accessing the values by name, and <code>put</code> methods for adding or replacing values by\n- * name. The values can be any of these types: <code>Boolean</code>, <code>JSONArray</code>,\n- * <code>JSONObject</code>, <code>Number</code>, <code>String</code>, or the\n- * <code>JSONObject.NULL</code> object. A JSONObject constructor can be used to convert an external\n- * form JSON text into an internal form whose values can be retrieved with the <code>get</code> and\n- * <code>opt</code> methods, or to convert values into a JSON text using the <code>put</code> and\n- * <code>toString</code> methods. A <code>get</code> method returns a value if one can be found, and\n- * throws an exception if one cannot be found. An <code>opt</code> method returns a default value\n- * instead of throwing an exception, and so is useful for obtaining optional values.\n- * <p>\n- * The generic <code>get()</code> and <code>opt()</code> methods return an object, which you can\n- * cast or query for type. There are also typed <code>get</code> and <code>opt</code> methods that\n- * do type checking and type coercion for you. The opt methods differ from the get methods in that\n- * they do not throw. Instead, they return a specified value, such as null.\n- * <p>\n- * The <code>put</code> methods add or replace values in an object. For example,\n+ * A modifiable set of name/value mappings. Names are unique, non-null strings. Values may be any\n+ * mix of {@link JSONObject JSONObjects}, {@link JSONArray JSONArrays}, Strings, Booleans, Integers,\n+ * Longs, Doubles or {@link #NULL}. Values may not be {@code null}, {@link Double#isNaN() NaNs},\n+ * {@link Double#isInfinite() infinities}, or of any type not listed here.\n  *\n- * <pre>\n- * myString = new JSONObject().put(&quot;JSON&quot;, &quot;Hello, World!&quot;).toString();\n- * </pre>\n+ * <p>\n+ * This class can coerce values to another type when requested.\n+ * <ul>\n+ * <li>When the requested type is a boolean, strings will be coerced using a case-insensitive\n+ * comparison to \"true\" and \"false\".\n+ * <li>When the requested type is a double, other {@link Number} types will be coerced using\n+ * {@link Number#doubleValue() doubleValue}. Strings that can be coerced using\n+ * {@link Double#valueOf(String)} will be.\n+ * <li>When the requested type is an int, other {@link Number} types will be coerced using\n+ * {@link Number#intValue() intValue}. Strings that can be coerced using\n+ * {@link Double#valueOf(String)} will be, and then cast to int.\n+ * <li><a name=\"lossy\">When the requested type is a long, other {@link Number} types will be coerced\n+ * using {@link Number#longValue() longValue}. Strings that can be coerced using\n+ * {@link Double#valueOf(String)} will be, and then cast to long. This two-step conversion is lossy\n+ * for very large values. For example, the string \"9223372036854775806\" yields the long\n+ * 9223372036854775807.</a>\n+ * <li>When the requested type is a String, other non-null values will be coerced using\n+ * {@link String#valueOf(Object)}. Although null cannot be coerced, the sentinel value\n+ * {@link JSONObject#NULL} is coerced to the string \"null\".\n+ * </ul>\n  *\n- * produces the string <code>{\"JSON\": \"Hello, World\"}</code>.\n  * <p>\n- * The texts produced by the <code>toString</code> methods strictly conform to the JSON syntax\n- * rules. The constructors are more forgiving in the texts they will accept:\n+ * This class can look up both mandatory and optional values:\n  * <ul>\n- * <li>An extra <code>,</code>&nbsp;<small>(comma)</small> may appear just before the closing\n- * brace.</li>\n- * <li>Strings may be quoted with <code>'</code>&nbsp;<small>(single quote)</small>.</li>\n- * <li>Strings do not need to be quoted at all if they do not begin with a quote or single quote,\n- * and if they do not contain leading or trailing spaces, and if they do not contain any of these\n- * characters: <code>{ } [ ] / \\ : , = ; #</code> and if they do not look like numbers and if they\n- * are not the reserved words <code>true</code>, <code>false</code>, or <code>null</code>.</li>\n- * <li>Keys can be followed by <code>=</code> or <code>=></code> as well as by <code>:</code>.</li>\n- * <li>Values can be followed by <code>;</code> <small>(semicolon)</small> as well as by\n- * <code>,</code> <small>(comma)</small>.</li>\n+ * <li>Use <code>get<i>Type</i>()</code> to retrieve a mandatory value. This fails with a\n+ * {@code JSONException} if the requested name has no value or if the value cannot be coerced to the\n+ * requested type.\n+ * <li>Use <code>opt<i>Type</i>()</code> to retrieve an optional value. This returns a system- or\n+ * user-supplied default if the requested name has no value or if the value cannot be coerced to the\n+ * requested type.\n  * </ul>\n  *\n- * @author JSON.org\n- * @version 2012-05-29\n+ * <p>\n+ * <strong>Warning:</strong> this class represents null in two incompatible ways: the standard Java\n+ * {@code null} reference, and the sentinel value {@link JSONObject#NULL}. In particular, calling\n+ * {@code put(name, null)} removes the named entry from the object but\n+ * {@code put(name, JSONObject.NULL)} stores an entry whose value is {@code JSONObject.NULL}.\n+ *\n+ * <p>\n+ * Instances of this class are not thread safe. Although this class is nonfinal, it was not designed\n+ * for inheritance and should not be subclassed. In particular, self-use by overrideable methods is\n+ * not specified. See <i>Effective Java</i> Item 17, \"Design and Document or inheritance or else\n+ * prohibit it\" for further information.\n  */\n public class JSONObject {\n+\n+  private static final Double NEGATIVE_ZERO = -0d;\n+\n+  public static ThreadLocal<Set> cyclicDependencySet = new ThreadLocal();\n+  public static ThreadLocal<Boolean> cyclicDepChkEnabled = new ThreadLocal();\n+\n   /**\n-   * JSONObject.NULL is equivalent to the value that JavaScript calls null, whilst Java's null is\n-   * equivalent to the value that JavaScript calls undefined.\n+   * A sentinel value used to explicitly define a name with no value. Unlike {@code null}, names\n+   * with this value:\n+   * <ul>\n+   * <li>show up in the {@link #names} array\n+   * <li>show up in the {@link #keys} iterator\n+   * <li>return {@code true} for {@link #has(String)}\n+   * <li>do not throw on {@link #get(String)}\n+   * <li>are included in the encoded JSON string.\n+   * </ul>\n+   *\n+   * <p>\n+   * This value violates the general contract of {@link Object#equals} by returning true when\n+   * compared to {@code null}. Its {@link #toString} method returns \"null\".\n    */\n-  private static final class Null {\n-\n-    /**\n-     * There is only intended to be a single instance of the NULL object, so the clone method\n-     * returns itself.\n-     * \n-     * @return NULL.\n-     */\n-    protected final Object clone() {\n-      return this;\n+  public static final Object NULL = new Object() {\n+    @SuppressWarnings(\"EqualsWhichDoesntCheckParameterClass\")\n+    @Override\n+    public boolean equals(Object o) {\n+      return o == this || o == null; // API specifies this broken equals implementation\n     }\n \n-    /**\n-     * A Null object is equal to the null value and to itself.\n-     * \n-     * @param object An object to test for nullness.\n-     * @return true if the object parameter is the JSONObject.NULL object or null.\n-     */\n-    public boolean equals(Object object) {\n-      return object == null || object == this;\n+    // at least make the broken equals(null) consistent with Objects.hashCode(null).\n+    @Override\n+    public int hashCode() {\n+      return 0;\n     }\n \n-    /**\n-     * Get the \"null\" string value.\n-     * \n-     * @return The string \"null\".\n-     */\n+    @Override\n     public String toString() {\n       return \"null\";\n     }\n-  }\n-\n-\n-  /**\n-   * The map where the JSONObject's properties are kept.\n-   */\n-  private final Map map;\n+  };\n \n+  private final LinkedHashMap<String, Object> nameValuePairs;\n \n   /**\n-   * It is sometimes more convenient and less ambiguous to have a <code>NULL</code> object than to\n-   * use Java's <code>null</code> value. <code>JSONObject.NULL.equals(null)</code> returns\n-   * <code>true</code>. <code>JSONObject.NULL.toString()</code> returns <code>\"null\"</code>.\n-   */\n-  public static final Object NULL = new Null();\n-\n-\n-  public static ThreadLocal<Set> cyclicDependencySet = new ThreadLocal();\n-  public static ThreadLocal<Boolean> cyclicDepChkEnabled = new ThreadLocal();\n-\n-\n-  /**\n-   * Construct an empty JSONObject.\n+   * Creates a {@code JSONObject} with no name/value mappings.\n    */\n   public JSONObject() {\n-    this.map = new LinkedHashMap();\n+    nameValuePairs = new LinkedHashMap<String, Object>();\n   }\n \n-\n   /**\n-   * Construct a JSONObject from a subset of another JSONObject. An array of strings is used to\n-   * identify the keys that should be copied. Missing keys are ignored.\n+   * Creates a new {@code JSONObject} by copying all name/value mappings from the given map.\n    * \n-   * @param jo A JSONObject.\n-   * @param names An array of strings.\n+   * @param copyFrom a map whose keys are of type {@link String} and whose values are of supported\n+   *        types.\n+   * @throws NullPointerException if any of the map's keys are null.\n    */\n-  public JSONObject(JSONObject jo, String[] names) {\n+  /* (accept a raw type for API compatibility) */\n+  public JSONObject(Map copyFrom) {\n     this();\n-    for (int i = 0; i < names.length; i += 1) {\n-      try {\n-        this.putOnce(names[i], jo.opt(names[i]));\n-      } catch (Exception ignore) {\n+    Map<?, ?> contentsTyped = (Map<?, ?>) copyFrom;\n+    for (Map.Entry<?, ?> entry : contentsTyped.entrySet()) {\n+      /*\n+       * Deviate from the original by checking that keys are non-null and of the proper type. (We\n+       * still defer validating the values).\n+       */\n+      String key = (String) entry.getKey();\n+      if (key == null) {\n+        throw new NullPointerException(\"key == null\");\n       }\n+      nameValuePairs.put(key, wrap(entry.getValue()));\n     }\n   }\n \n-\n   /**\n-   * Construct a JSONObject from a JSONTokener.\n+   * Creates a new {@code JSONObject} with name/value mappings from the next object in the tokener.\n    * \n-   * @param x A JSONTokener object containing the source string.\n-   * @throws JSONException If there is a syntax error in the source string or a duplicated key.\n-   */\n-  public JSONObject(JSONTokener x) throws JSONException {\n-    this();\n-    char c;\n-    String key;\n-\n-    if (x.nextClean() != '{') {\n-      throw x.syntaxError(\"A JSONObject text must begin with '{'\");\n-    }\n-    for (;;) {\n-      c = x.nextClean();\n-      switch (c) {\n-        case 0:\n-          throw x.syntaxError(\"A JSONObject text must end with '}'\");\n-        case '}':\n-          return;\n-        default:\n-          x.back();\n-          key = x.nextValue().toString();\n-      }\n-\n-      // The key is followed by ':'. We will also tolerate '=' or '=>'.\n-\n-      c = x.nextClean();\n-      if (c == '=') {\n-        if (x.next() != '>') {\n-          x.back();\n-        }\n-      } else if (c != ':') {\n-        throw x.syntaxError(\"Expected a ':' after a key\");\n-      }\n-      this.putOnce(key, x.nextValue());\n-\n-      // Pairs are separated by ','. We will also tolerate ';'.\n-\n-      switch (x.nextClean()) {\n-        case ';':\n-        case ',':\n-          if (x.nextClean() == '}') {\n-            return;\n-          }\n-          x.back();\n-          break;\n-        case '}':\n-          return;\n-        default:\n-          throw x.syntaxError(\"Expected a ',' or '}'\");\n-      }\n-    }\n-  }\n-\n-\n-  /**\n-   * Construct a JSONObject from a Map.\n-   *\n-   * @param map A map object that can be used to initialize the contents of the JSONObject.\n+   * @param readFrom a tokener whose nextValue() method will yield a {@code JSONObject}.\n+   * @throws JSONException if the parse fails or doesn't yield a {@code JSONObject}.\n    */\n-  public JSONObject(Map map) {\n-    this.map = new LinkedHashMap();\n-    if (map != null) {\n-      Iterator i = map.entrySet().iterator();\n-      while (i.hasNext()) {\n-        Map.Entry e = (Map.Entry) i.next();\n-        Object value = e.getValue();\n-        if (value != null) {\n-          this.map.put(e.getKey(), wrap(value));\n-        }\n-      }\n+  public JSONObject(JSONTokener readFrom) throws JSONException {\n+    /*\n+     * Getting the parser to populate this could get tricky. Instead, just parse to temporary\n+     * JSONObject and then steal the data from that.\n+     */\n+    Object object = readFrom.nextValue();\n+    if (object instanceof JSONObject) {\n+      this.nameValuePairs = ((JSONObject) object).nameValuePairs;\n+    } else {\n+      throw JSON.typeMismatch(object, \"JSONObject\");\n     }\n   }\n \n-\n   /**\n-   * Construct a JSONObject from an Object using bean getters. It reflects on all of the public\n-   * methods of the object. For each of the methods with no parameters and a name starting with\n-   * <code>\"get\"</code> or <code>\"is\"</code> followed by an uppercase letter, the method is invoked,\n-   * and a key and the value returned from the getter method are put into the new JSONObject.\n-   *\n-   * The key is formed by removing the <code>\"get\"</code> or <code>\"is\"</code> prefix. If the second\n-   * remaining character is not upper case, then the first character is converted to lower case.\n-   *\n-   * For example, if an object has a method named <code>\"getName\"</code>, and if the result of\n-   * calling <code>object.getName()</code> is <code>\"Larry Fine\"</code>, then the JSONObject will\n-   * contain <code>\"name\": \"Larry Fine\"</code>.\n-   *\n-   * @param bean An object that has getter methods that should be used to make a JSONObject.\n+   * Creates a new {@code JSONObject} with name/value mappings from the JSON string.\n+   * \n+   * @param json a JSON-encoded string containing an object.\n+   * @throws JSONException if the parse fails or doesn't yield a {@code JSONObject}.\n    */\n-  public JSONObject(Object bean) {\n-    this();\n-    this.populateMap(bean);\n+  public JSONObject(String json) throws JSONException {\n+    this(new JSONTokener(json));\n   }\n \n-\n   /**\n-   * Construct a JSONObject from an Object, using reflection to find the public members. The\n-   * resulting JSONObject's keys will be the strings from the names array, and the values will be\n-   * the field values associated with those keys in the object. If a key is not found or not\n-   * visible, then it will not be copied into the new JSONObject.\n+   * Creates a new {@code JSONObject} by copying mappings for the listed names from the given\n+   * object. Names that aren't present in {@code copyFrom} will be skipped.\n    * \n-   * @param object An object that has fields that should be used to make a JSONObject.\n-   * @param names An array of strings, the names of the fields to be obtained from the object.\n+   * @param copyFrom The source object.\n+   * @param names The names of the fields to copy.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n    */\n-  public JSONObject(Object object, String names[]) {\n+  public JSONObject(JSONObject copyFrom, String[] names) throws JSONException {\n     this();\n-    Class c = object.getClass();\n-    for (int i = 0; i < names.length; i += 1) {\n-      String name = names[i];\n-      try {\n-        this.putOpt(name, c.getField(name).get(object));\n-      } catch (Exception ignore) {\n+    for (String name : names) {\n+      Object value = copyFrom.opt(name);\n+      if (value != null) {\n+        nameValuePairs.put(name, value);\n       }\n     }\n   }\n \n-\n   /**\n-   * Construct a JSONObject from a source JSON text string. This is the most commonly used\n-   * JSONObject constructor.\n+   * Creates a json object from a bean\n    * \n-   * @param source A string beginning with <code>{</code>&nbsp;<small>(left brace)</small> and\n-   *        ending with <code>}</code>&nbsp;<small>(right brace)</small>.\n-   * @exception JSONException If there is a syntax error in the source string or a duplicated key.\n+   * @param bean the bean to create the json object from\n+   * @throws JSONException If there is an exception while reading the bean\n    */\n-  public JSONObject(String source) throws JSONException {\n-    this(new JSONTokener(source));\n+  public JSONObject(Object bean) throws JSONException {\n+    this(propertiesAsMap(bean));\n   }\n \n+  // This is custom properties mapping specific for GEODE\n+  private static Map<String, Object> propertiesAsMap(Object bean) {\n+    Map<String, Object> props = new TreeMap();\n+    Class klass = bean.getClass();\n \n-  /**\n-   * Construct a JSONObject from a ResourceBundle.\n-   * \n-   * @param baseName The ResourceBundle base name.\n-   * @param locale The Locale to load the ResourceBundle for.\n-   * @throws JSONException If any JSONExceptions are detected.\n-   */\n-  public JSONObject(String baseName, Locale locale) throws JSONException {\n-    this();\n-    ResourceBundle bundle =\n-        ResourceBundle.getBundle(baseName, locale, Thread.currentThread().getContextClassLoader());\n-\n-    // Iterate through the keys in the bundle.\n-\n-    Enumeration keys = bundle.getKeys();\n-    while (keys.hasMoreElements()) {\n-      Object key = keys.nextElement();\n-      if (key instanceof String) {\n-\n-        // Go through the path, ensuring that there is a nested JSONObject for each\n-        // segment except the last. Add the value using the last segment's name into\n-        // the deepest nested JSONObject.\n-\n-        String[] path = ((String) key).split(\"\\\\.\");\n-        int last = path.length - 1;\n-        JSONObject target = this;\n-        for (int i = 0; i < last; i += 1) {\n-          String segment = path[i];\n-          JSONObject nextTarget = target.optJSONObject(segment);\n-          if (nextTarget == null) {\n-            nextTarget = new JSONObject();\n-            target.put(segment, nextTarget);\n+    // If klass is a System class then set includeSuperClass to false.\n+\n+    boolean includeSuperClass = klass.getClassLoader() != null;\n+\n+    Method[] methods = includeSuperClass ? klass.getMethods() : klass.getDeclaredMethods();\n+    for (int i = 0; i < methods.length; i += 1) {\n+      try {\n+        Method method = methods[i];\n+        if (Modifier.isPublic(method.getModifiers()) && !Modifier.isStatic(method.getModifiers())) {\n+          String name = method.getName();\n+          String key = \"\";\n+          if (name.startsWith(\"get\")) {\n+            if (\"getClass\".equals(name) || \"getDeclaringClass\".equals(name)) {\n+              key = \"\";\n+            } else {\n+              key = name.substring(3);\n+            }\n+          } else if (name.startsWith(\"is\")) {\n+            key = name.substring(2);\n+          }\n+          if (key.length() > 0 && Character.isUpperCase(key.charAt(0))\n+              && method.getParameterTypes().length == 0) {\n+            if (key.length() == 1) {\n+              key = key.toLowerCase();\n+            } else if (!Character.isUpperCase(key.charAt(1))) {\n+              key = key.substring(0, 1).toLowerCase() + key.substring(1);\n+            }\n+            Object result = method.invoke(bean, (Object[]) null);\n+            if (result != null) {\n+              props.put(key, wrap(result));\n+            } else if (!method.getReturnType().isArray()) {\n+              props.put(key, JSONObject.NULL);\n+            }\n           }\n-          target = nextTarget;\n         }\n-        target.put(path[last], bundle.getString((String) key));\n+      } catch (Exception ignore) {\n       }\n     }\n+    props.put(\"type-class\", klass.getCanonicalName());\n+    return props;\n   }\n \n-\n-  /**\n-   * Accumulate values under a key. It is similar to the put method except that if there is already\n-   * an object stored under the key then a JSONArray is stored under the key to hold all of the\n-   * accumulated values. If there is already a JSONArray, then the new value is appended to it. In\n-   * contrast, the put method replaces the previous value.\n-   *\n-   * If only one value is accumulated that is not a JSONArray, then the result will be the same as\n-   * using put. But if multiple values are accumulated, then the result will be like append.\n-   * \n-   * @param key A key string.\n-   * @param value An object to be accumulated under the key.\n-   * @return this.\n-   * @throws JSONException If the value is an invalid number or if the key is null.\n-   */\n-  public JSONObject accumulate(String key, Object value) throws JSONException {\n-    testValidity(value);\n-    Object object = this.opt(key);\n-    if (object == null) {\n-      this.put(key, value instanceof JSONArray ? new JSONArray().put(value) : value);\n-    } else if (object instanceof JSONArray) {\n-      ((JSONArray) object).put(value);\n-    } else {\n-      this.put(key, new JSONArray().put(object).put(value));\n+  public static String[] getNames(JSONObject x) {\n+    Set<String> names = x.keySet();\n+    String[] r = new String[names.size()];\n+    int i = 0;\n+    for (String name : names) {\n+      r[i++] = name;\n     }\n-    return this;\n+    return r;\n   }\n \n-\n   /**\n-   * Append values to the array under a key. If the key does not exist in the JSONObject, then the\n-   * key is put in the JSONObject with its value being a JSONArray containing the value parameter.\n-   * If the key was already associated with a JSONArray, then the value parameter is appended to it.\n+   * Returns the number of name/value mappings in this object.\n    * \n-   * @param key A key string.\n-   * @param value An object to be accumulated under the key.\n-   * @return this.\n-   * @throws JSONException If the key is null or if the current value associated with the key is not\n-   *         a JSONArray.\n+   * @return the length of this.\n    */\n-  public JSONObject append(String key, Object value) throws JSONException {\n-    testValidity(value);\n-    Object object = this.opt(key);\n-    if (object == null) {\n-      this.put(key, new JSONArray().put(value));\n-    } else if (object instanceof JSONArray) {\n-      this.put(key, ((JSONArray) object).put(value));\n-    } else {\n-      throw new JSONException(\"JSONObject[\" + key + \"] is not a JSONArray.\");\n-    }\n-    return this;\n+  public int length() {\n+    return nameValuePairs.size();\n   }\n \n-\n   /**\n-   * Produce a string from a double. The string \"null\" will be returned if the number is not finite.\n+   * Maps {@code name} to {@code value}, clobbering any existing name/value mapping with the same\n+   * name.\n    * \n-   * @param d A double.\n-   * @return A String.\n+   * @param name The name of the value to insert.\n+   * @param value The value to insert.\n+   * @return this object.\n+   * @throws JSONException Should not be possible.\n    */\n-  public static String doubleToString(double d) {\n-    if (Double.isInfinite(d) || Double.isNaN(d)) {\n-      return \"null\";\n-    }\n-\n-    // Shave off trailing zeros and decimal point, if possible.\n-\n-    String string = Double.toString(d);\n-    if (string.indexOf('.') > 0 && string.indexOf('e') < 0 && string.indexOf('E') < 0) {\n-      while (string.endsWith(\"0\")) {\n-        string = string.substring(0, string.length() - 1);\n-      }\n-      if (string.endsWith(\".\")) {\n-        string = string.substring(0, string.length() - 1);\n-      }\n-    }\n-    return string;\n+  public JSONObject put(String name, boolean value) throws JSONException {\n+    nameValuePairs.put(checkName(name), value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the value object associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return The object associated with the key.\n-   * @throws JSONException if the key is not found.\n-   */\n-  public Object get(String key) throws JSONException {\n-    if (key == null) {\n-      throw new JSONException(\"Null key.\");\n-    }\n-    Object object = this.opt(key);\n-    if (object == null) {\n-      throw new JSONException(\"JSONObject[\" + quote(key) + \"] not found.\");\n-    }\n-    return object;\n+   * Maps {@code name} to {@code value}, clobbering any existing name/value mapping with the same\n+   * name.\n+   * \n+   * @param name The name for the new value.\n+   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this object.\n+   * @throws JSONException if value is NaN or infinite.\n+   */\n+  public JSONObject put(String name, double value) throws JSONException {\n+    nameValuePairs.put(checkName(name), JSON.checkDouble(value));\n+    return this;\n   }\n \n-\n   /**\n-   * Get the boolean value associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return The truth.\n-   * @throws JSONException if the value is not a Boolean or the String \"true\" or \"false\".\n+   * Maps {@code name} to {@code value}, clobbering any existing name/value mapping with the same\n+   * name.\n+   * \n+   * @param name The name for the new value.\n+   * @param value The new value.\n+   * @return this object.\n+   * @throws JSONException Should not be possible.\n    */\n-  public boolean getBoolean(String key) throws JSONException {\n-    Object object = this.get(key);\n-    if (object.equals(Boolean.FALSE)\n-        || (object instanceof String && ((String) object).equalsIgnoreCase(\"false\"))) {\n-      return false;\n-    } else if (object.equals(Boolean.TRUE)\n-        || (object instanceof String && ((String) object).equalsIgnoreCase(\"true\"))) {\n-      return true;\n-    }\n-    throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not a Boolean.\");\n+  public JSONObject put(String name, int value) throws JSONException {\n+    nameValuePairs.put(checkName(name), value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the double value associated with a key.\n+   * Maps {@code name} to {@code value}, clobbering any existing name/value mapping with the same\n+   * name.\n    * \n-   * @param key A key string.\n-   * @return The numeric value.\n-   * @throws JSONException if the key is not found or if the value is not a Number object and cannot\n-   *         be converted to a number.\n+   * @param name The name of the new value.\n+   * @param value The new value to insert.\n+   * @return this object.\n+   * @throws JSONException Should not be possible.\n    */\n-  public double getDouble(String key) throws JSONException {\n-    Object object = this.get(key);\n-    try {\n-      return object instanceof Number ? ((Number) object).doubleValue()\n-          : Double.parseDouble((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not a number.\");\n-    }\n+  public JSONObject put(String name, long value) throws JSONException {\n+    nameValuePairs.put(checkName(name), value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the int value associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return The integer value.\n-   * @throws JSONException if the key is not found or if the value cannot be converted to an\n-   *         integer.\n-   */\n-  public int getInt(String key) throws JSONException {\n-    Object object = this.get(key);\n-    try {\n-      return object instanceof Number ? ((Number) object).intValue()\n-          : Integer.parseInt((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not an int.\");\n+   * Maps {@code name} to {@code value}, clobbering any existing name/value mapping with the same\n+   * name. If the value is {@code null}, any existing mapping for {@code name} is removed.\n+   * \n+   * @param name The name of the new value.\n+   * @param value a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double,\n+   *        {@link #NULL}, or {@code null}. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this object.\n+   * @throws JSONException if the value is an invalid double (infinite or NaN).\n+   */\n+  public JSONObject put(String name, Object value) throws JSONException {\n+    if (value == null) {\n+      nameValuePairs.remove(name);\n+      return this;\n     }\n-  }\n-\n-\n-  /**\n-   * Get the JSONArray value associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return A JSONArray which is the value.\n-   * @throws JSONException if the key is not found or if the value is not a JSONArray.\n-   */\n-  public JSONArray getJSONArray(String key) throws JSONException {\n-    Object object = this.get(key);\n-    if (object instanceof JSONArray) {\n-      return (JSONArray) object;\n+    if (value instanceof Number) {\n+      // deviate from the original by checking all Numbers, not just floats & doubles\n+      JSON.checkDouble(((Number) value).doubleValue());\n     }\n-    throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not a JSONArray.\");\n+    nameValuePairs.put(checkName(name), value);\n+    return this;\n   }\n \n-\n   /**\n-   * Get the JSONObject value associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return A JSONObject which is the value.\n-   * @throws JSONException if the key is not found or if the value is not a JSONObject.\n+   * Equivalent to {@code put(name, value)} when both parameters are non-null; does nothing\n+   * otherwise.\n+   * \n+   * @param name The name of the value to insert.\n+   * @param value The value to insert.\n+   * @return this object.\n+   * @throws JSONException if the value is an invalid double (infinite or NaN).\n    */\n-  public JSONObject getJSONObject(String key) throws JSONException {\n-    Object object = this.get(key);\n-    if (object instanceof JSONObject) {\n-      return (JSONObject) object;\n+  public JSONObject putOpt(String name, Object value) throws JSONException {\n+    if (name == null || value == null) {\n+      return this;\n     }\n-    throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not a JSONObject.\");\n+    return put(name, value);\n   }\n \n-\n   /**\n-   * Get the long value associated with a key.\n+   * Appends {@code value} to the array already mapped to {@code name}. If this object has no\n+   * mapping for {@code name}, this inserts a new mapping. If the mapping exists but its value is\n+   * not an array, the existing and new values are inserted in order into a new array which is\n+   * itself mapped to {@code name}. In aggregate, this allows values to be added to a mapping one at\n+   * a time.\n    *\n-   * @param key A key string.\n-   * @return The long value.\n-   * @throws JSONException if the key is not found or if the value cannot be converted to a long.\n-   */\n-  public long getLong(String key) throws JSONException {\n-    Object object = this.get(key);\n-    try {\n-      return object instanceof Number ? ((Number) object).longValue()\n-          : Long.parseLong((String) object);\n-    } catch (Exception e) {\n-      throw new JSONException(\"JSONObject[\" + quote(key) + \"] is not a long.\");\n+   * Note that {@code append(String, Object)} provides better semantics. In particular, the mapping\n+   * for {@code name} will <b>always</b> be a {@link JSONArray}. Using {@code accumulate} will\n+   * result in either a {@link JSONArray} or a mapping whose type is the type of {@code value}\n+   * depending on the number of calls to it.\n+   * \n+   * @param name The name of the field to change.\n+   * @param value a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double,\n+   *        {@link #NULL} or null. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this object after mutation.\n+   * @throws JSONException If the object being added is an invalid number.\n+   */\n+  // TODO: Change {@code append) to {@link #append} when append is\n+  // unhidden.\n+  public JSONObject accumulate(String name, Object value) throws JSONException {\n+    Object current = nameValuePairs.get(checkName(name));\n+    if (current == null) {\n+      return put(name, value);\n+    }\n+\n+    if (current instanceof JSONArray) {\n+      JSONArray array = (JSONArray) current;\n+      array.checkedPut(value);\n+    } else {\n+      JSONArray array = new JSONArray();\n+      array.checkedPut(current);\n+      array.checkedPut(value);\n+      nameValuePairs.put(name, array);\n     }\n+    return this;\n   }\n \n-\n   /**\n-   * Get an array of field names from a JSONObject.\n-   *\n-   * @return An array of field names, or null if there are no names.\n-   */\n-  public static String[] getNames(JSONObject jo) {\n-    int length = jo.length();\n-    if (length == 0) {\n-      return null;\n-    }\n-    Iterator iterator = jo.keys();\n-    String[] names = new String[length];\n-    int i = 0;\n-    while (iterator.hasNext()) {\n-      names[i] = (String) iterator.next();\n-      i += 1;\n+   * Appends values to the array mapped to {@code name}. A new {@link JSONArray} mapping for\n+   * {@code name} will be inserted if no mapping exists. If the existing mapping for {@code name} is\n+   * not a {@link JSONArray}, a {@link JSONException} will be thrown.\n+   * \n+   * @param name The name of the array to which the value should be appended.\n+   * @param value The value to append.\n+   * @return this object.\n+   * @throws JSONException if {@code name} is {@code null} or if the mapping for {@code name} is\n+   *         non-null and is not a {@link JSONArray}.\n+   */\n+  public JSONObject append(String name, Object value) throws JSONException {\n+    Object current = nameValuePairs.get(checkName(name));\n+\n+    final JSONArray array;\n+    if (current instanceof JSONArray) {\n+      array = (JSONArray) current;\n+    } else if (current == null) {\n+      JSONArray newArray = new JSONArray();\n+      nameValuePairs.put(name, newArray);\n+      array = newArray;\n+    } else {\n+      throw new JSONException(\"Key \" + name + \" is not a JSONArray\");\n     }\n-    return names;\n-  }\n \n+    array.checkedPut(value);\n \n-  /**\n-   * Get an array of field names from an Object.\n-   *\n-   * @return An array of field names, or null if there are no names.\n-   */\n-  public static String[] getNames(Object object) {\n-    if (object == null) {\n-      return null;\n-    }\n-    Class klass = object.getClass();\n-    Field[] fields = klass.getFields();\n-    int length = fields.length;\n-    if (length == 0) {\n-      return null;\n-    }\n-    String[] names = new String[length];\n-    for (int i = 0; i < length; i += 1) {\n-      names[i] = fields[i].getName();\n-    }\n-    return names;\n+    return this;\n   }\n \n-\n-  /**\n-   * Get the string associated with a key.\n-   *\n-   * @param key A key string.\n-   * @return A string which is the value.\n-   * @throws JSONException if there is no string value for the key.\n-   */\n-  public String getString(String key) throws JSONException {\n-    Object object = this.get(key);\n-    if (object instanceof String) {\n-      return (String) object;\n+  String checkName(String name) throws JSONException {\n+    if (name == null) {\n+      throw new JSONException(\"Names must be non-null\");\n     }\n-    throw new JSONException(\"JSONObject[\" + quote(key) + \"] not a string.\");\n+    return name;\n   }\n \n-\n   /**\n-   * Determine if the JSONObject contains a specific key.\n+   * Removes the named mapping if it exists; does nothing otherwise.\n    * \n-   * @param key A key string.\n-   * @return true if the key exists in the JSONObject.\n+   * @param name The name of the mapping to remove.\n+   * @return the value previously mapped by {@code name}, or null if there was no such mapping.\n    */\n-  public boolean has(String key) {\n-    return this.map.containsKey(key);\n+  public Object remove(String name) {\n+    return nameValuePairs.remove(name);\n   }\n \n-\n   /**\n-   * Increment a property of a JSONObject. If there is no such property, create one with a value of\n-   * 1. If there is such a property, and if it is an Integer, Long, Double, or Float, then add one\n-   * to it.\n+   * Returns true if this object has no mapping for {@code name} or if it has a mapping whose value\n+   * is {@link #NULL}.\n    * \n-   * @param key A key string.\n-   * @return this.\n-   * @throws JSONException If there is already a property with this name that is not an Integer,\n-   *         Long, Double, or Float.\n+   * @param name The name of the value to check on.\n+   * @return true if the field doesn't exist or is null.\n    */\n-  public JSONObject increment(String key) throws JSONException {\n-    Object value = this.opt(key);\n-    if (value == null) {\n-      this.put(key, 1);\n-    } else if (value instanceof Integer) {\n-      this.put(key, ((Integer) value).intValue() + 1);\n-    } else if (value instanceof Long) {\n-      this.put(key, ((Long) value).longValue() + 1);\n-    } else if (value instanceof Double) {\n-      this.put(key, ((Double) value).doubleValue() + 1);\n-    } else if (value instanceof Float) {\n-      this.put(key, ((Float) value).floatValue() + 1);\n-    } else {\n-      throw new JSONException(\"Unable to increment [\" + quote(key) + \"].\");\n-    }\n-    return this;\n+  public boolean isNull(String name) {\n+    Object value = nameValuePairs.get(name);\n+    return value == null || value == NULL;\n   }\n \n-\n   /**\n-   * Determine if the value associated with the key is null or if there is no value.\n+   * Returns true if this object has a mapping for {@code name}. The mapping may be {@link #NULL}.\n    * \n-   * @param key A key string.\n-   * @return true if there is no value associated with the key or if the value is the\n-   *         JSONObject.NULL object.\n+   * @param name The name of the value to check on.\n+   * @return true if this object has a field named {@code name}\n    */\n-  public boolean isNull(String key) {\n-    return JSONObject.NULL.equals(this.opt(key));\n+  public boolean has(String name) {\n+    return nameValuePairs.containsKey(name);\n   }\n \n-\n   /**\n-   * Get an enumeration of the keys of the JSONObject.\n-   *\n-   * @return An iterator of the keys.\n-   */\n-  public Iterator keys() {\n-    return this.map.keySet().iterator();\n-  }\n-\n-\n-  /**\n-   * Get the number of keys stored in the JSONObject.\n-   *\n-   * @return The number of keys in the JSONObject.\n+   * Returns the value mapped by {@code name}, or throws if no such mapping exists.\n+   * \n+   * @param name The name of the value to get.\n+   * @return The value.\n+   * @throws JSONException if no such mapping exists.\n    */\n-  public int length() {\n-    return this.map.size();\n+  public Object get(String name) throws JSONException {\n+    Object result = nameValuePairs.get(name);\n+    if (result == null) {\n+      throw new JSONException(\"No value for \" + name);\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Produce a JSONArray containing the names of the elements of this JSONObject.\n+   * Returns the value mapped by {@code name}, or null if no such mapping exists.\n    * \n-   * @return A JSONArray containing the key strings, or null if the JSONObject is empty.\n+   * @param name The name of the value to get.\n+   * @return The value.\n    */\n-  public JSONArray names() {\n-    JSONArray ja = new JSONArray();\n-    Iterator keys = this.keys();\n-    while (keys.hasNext()) {\n-      ja.put(keys.next());\n-    }\n-    return ja.length() == 0 ? null : ja;\n+  public Object opt(String name) {\n+    return nameValuePairs.get(name);\n   }\n \n   /**\n-   * Produce a string from a Number.\n+   * Returns the value mapped by {@code name} if it exists and is a boolean or can be coerced to a\n+   * boolean, or throws otherwise.\n    * \n-   * @param number A Number\n-   * @return A String.\n-   * @throws JSONException If n is a non-finite number.\n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n+   * @throws JSONException if the mapping doesn't exist or cannot be coerced to a boolean.\n    */\n-  public static String numberToString(Number number) throws JSONException {\n-    if (number == null) {\n-      throw new JSONException(\"Null pointer\");\n-    }\n-    testValidity(number);\n-\n-    // Shave off trailing zeros and decimal point, if possible.\n-\n-    String string = number.toString();\n-    if (string.indexOf('.') > 0 && string.indexOf('e') < 0 && string.indexOf('E') < 0) {\n-      while (string.endsWith(\"0\")) {\n-        string = string.substring(0, string.length() - 1);\n-      }\n-      if (string.endsWith(\".\")) {\n-        string = string.substring(0, string.length() - 1);\n-      }\n+  public boolean getBoolean(String name) throws JSONException {\n+    Object object = get(name);\n+    Boolean result = JSON.toBoolean(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(name, object, \"boolean\");\n     }\n-    return string;\n+    return result;\n   }\n \n-\n   /**\n-   * Get an optional value associated with a key.\n+   * Returns the value mapped by {@code name} if it exists and is a boolean or can be coerced to a\n+   * boolean, or false otherwise.\n    * \n-   * @param key A key string.\n-   * @return An object which is the value, or null if there is no value.\n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n    */\n-  public Object opt(String key) {\n-    return key == null ? null : this.map.get(key);\n+  public boolean optBoolean(String name) {\n+    return optBoolean(name, false);\n   }\n \n-\n   /**\n-   * Get an optional boolean associated with a key. It returns false if there is no such key, or if\n-   * the value is not Boolean.TRUE or the String \"true\".\n-   *\n-   * @param key A key string.\n-   * @return The truth.\n+   * Returns the value mapped by {@code name} if it exists and is a boolean or can be coerced to a\n+   * boolean, or {@code fallback} otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @param fallback The value to return if the field isn't there.\n+   * @return The selected value or the fallback.\n    */\n-  public boolean optBoolean(String key) {\n-    return this.optBoolean(key, false);\n+  public boolean optBoolean(String name, boolean fallback) {\n+    Object object = opt(name);\n+    Boolean result = JSON.toBoolean(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Get an optional boolean associated with a key. It returns the defaultValue if there is no such\n-   * key, or if it is not a Boolean or the String \"true\" or \"false\" (case insensitive).\n-   *\n-   * @param key A key string.\n-   * @param defaultValue The default.\n-   * @return The truth.\n+   * Returns the value mapped by {@code name} if it exists and is a double or can be coerced to a\n+   * double, or throws otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n+   * @throws JSONException if the mapping doesn't exist or cannot be coerced to a double.\n    */\n-  public boolean optBoolean(String key, boolean defaultValue) {\n-    try {\n-      return this.getBoolean(key);\n-    } catch (Exception e) {\n-      return defaultValue;\n+  public double getDouble(String name) throws JSONException {\n+    Object object = get(name);\n+    Double result = JSON.toDouble(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(name, object, \"double\");\n     }\n+    return result;\n   }\n \n-\n   /**\n-   * Get an optional double associated with a key, or NaN if there is no such key or if its value is\n-   * not a number. If the value is a string, an attempt will be made to evaluate it as a number.\n-   *\n-   * @param key A string which is the key.\n-   * @return An object which is the value.\n-   */\n-  public double optDouble(String key) {\n-    return this.optDouble(key, Double.NaN);\n-  }\n-\n-\n-  /**\n-   * Get an optional double associated with a key, or the defaultValue if there is no such key or if\n-   * its value is not a number. If the value is a string, an attempt will be made to evaluate it as\n-   * a number.\n-   *\n-   * @param key A key string.\n-   * @param defaultValue The default.\n-   * @return An object which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is a double or can be coerced to a\n+   * double, or {@code NaN} otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n    */\n-  public double optDouble(String key, double defaultValue) {\n-    try {\n-      return this.getDouble(key);\n-    } catch (Exception e) {\n-      return defaultValue;\n-    }\n+  public double optDouble(String name) {\n+    return optDouble(name, Double.NaN);\n   }\n \n-\n   /**\n-   * Get an optional int value associated with a key, or zero if there is no such key or if the\n-   * value is not a number. If the value is a string, an attempt will be made to evaluate it as a\n-   * number.\n-   *\n-   * @param key A key string.\n-   * @return An object which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is a double or can be coerced to a\n+   * double, or {@code fallback} otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @param fallback The value to return if the field isn't there.\n+   * @return The selected value or the fallback.\n    */\n-  public int optInt(String key) {\n-    return this.optInt(key, 0);\n+  public double optDouble(String name, double fallback) {\n+    Object object = opt(name);\n+    Double result = JSON.toDouble(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Get an optional int value associated with a key, or the default if there is no such key or if\n-   * the value is not a number. If the value is a string, an attempt will be made to evaluate it as\n-   * a number.\n-   *\n-   * @param key A key string.\n-   * @param defaultValue The default.\n-   * @return An object which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is an int or can be coerced to an\n+   * int, or throws otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n+   * @throws JSONException if the mapping doesn't exist or cannot be coerced to an int.\n    */\n-  public int optInt(String key, int defaultValue) {\n-    try {\n-      return this.getInt(key);\n-    } catch (Exception e) {\n-      return defaultValue;\n+  public int getInt(String name) throws JSONException {\n+    Object object = get(name);\n+    Integer result = JSON.toInteger(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(name, object, \"int\");\n     }\n+    return result;\n   }\n \n-\n   /**\n-   * Get an optional JSONArray associated with a key. It returns null if there is no such key, or if\n-   * its value is not a JSONArray.\n-   *\n-   * @param key A key string.\n-   * @return A JSONArray which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is an int or can be coerced to an\n+   * int, or 0 otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The selected value if it exists.\n    */\n-  public JSONArray optJSONArray(String key) {\n-    Object o = this.opt(key);\n-    return o instanceof JSONArray ? (JSONArray) o : null;\n+  public int optInt(String name) {\n+    return optInt(name, 0);\n   }\n \n-\n   /**\n-   * Get an optional JSONObject associated with a key. It returns null if there is no such key, or\n-   * if its value is not a JSONObject.\n-   *\n-   * @param key A key string.\n-   * @return A JSONObject which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is an int or can be coerced to an\n+   * int, or {@code fallback} otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @param fallback The value to return if the field isn't there.\n+   * @return The selected value or the fallback.\n    */\n-  public JSONObject optJSONObject(String key) {\n-    Object object = this.opt(key);\n-    return object instanceof JSONObject ? (JSONObject) object : null;\n+  public int optInt(String name, int fallback) {\n+    Object object = opt(name);\n+    Integer result = JSON.toInteger(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Get an optional long value associated with a key, or zero if there is no such key or if the\n-   * value is not a number. If the value is a string, an attempt will be made to evaluate it as a\n-   * number.\n+   * Returns the value mapped by {@code name} if it exists and is a long or can be coerced to a\n+   * long, or throws otherwise. Note that JSON represents numbers as doubles,\n    *\n-   * @param key A key string.\n-   * @return An object which is the value.\n+   * so this is <a href=\"#lossy\">lossy</a>; use strings to transfer numbers via JSON without loss.\n+   * \n+   * @param name The name of the field that we want.\n+   * @return The value of the field.\n+   * @throws JSONException if the mapping doesn't exist or cannot be coerced to a long.\n    */\n-  public long optLong(String key) {\n-    return this.optLong(key, 0);\n+  public long getLong(String name) throws JSONException {\n+    Object object = get(name);\n+    Long result = JSON.toLong(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(name, object, \"long\");\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Get an optional long value associated with a key, or the default if there is no such key or if\n-   * the value is not a number. If the value is a string, an attempt will be made to evaluate it as\n-   * a number.\n-   *\n-   * @param key A key string.\n-   * @param defaultValue The default.\n-   * @return An object which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is a long or can be coerced to a\n+   * long, or 0 otherwise. Note that JSON represents numbers as doubles, so this is\n+   * <a href=\"#lossy\">lossy</a>; use strings to transfer numbers via JSON.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The selected value.\n    */\n-  public long optLong(String key, long defaultValue) {\n-    try {\n-      return this.getLong(key);\n-    } catch (Exception e) {\n-      return defaultValue;\n-    }\n+  public long optLong(String name) {\n+    return optLong(name, 0L);\n   }\n \n-\n   /**\n-   * Get an optional string associated with a key. It returns an empty string if there is no such\n-   * key. If the value is not a string and is not null, then it is converted to a string.\n-   *\n-   * @param key A key string.\n-   * @return A string which is the value.\n+   * Returns the value mapped by {@code name} if it exists and is a long or can be coerced to a\n+   * long, or {@code fallback} otherwise. Note that JSON represents numbers as doubles, so this is\n+   * <a href=\"#lossy\">lossy</a>; use strings to transfer numbers via JSON.\n+   * \n+   * @param name The name of the field we want.\n+   * @param fallback The value to return if the field isn't there.\n+   * @return The selected value or the fallback.\n    */\n-  public String optString(String key) {\n-    return this.optString(key, \"\");\n+  public long optLong(String name, long fallback) {\n+    Object object = opt(name);\n+    Long result = JSON.toLong(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Get an optional string associated with a key. It returns the defaultValue if there is no such\n-   * key.\n-   *\n-   * @param key A key string.\n-   * @param defaultValue The default.\n-   * @return A string which is the value.\n+   * Returns the value mapped by {@code name} if it exists, coercing it if necessary, or throws if\n+   * no such mapping exists.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The value of the field.\n+   * @throws JSONException if no such mapping exists.\n    */\n-  public String optString(String key, String defaultValue) {\n-    Object object = this.opt(key);\n-    return NULL.equals(object) ? defaultValue : object.toString();\n-  }\n-\n-\n-  private void populateMap(Object bean) {\n-    Class klass = bean.getClass();\n-\n-    // If klass is a System class then set includeSuperClass to false.\n-\n-    boolean includeSuperClass = klass.getClassLoader() != null;\n-\n-    Method[] methods = includeSuperClass ? klass.getMethods() : klass.getDeclaredMethods();\n-    for (int i = 0; i < methods.length; i += 1) {\n-      try {\n-        Method method = methods[i];\n-        if (Modifier.isPublic(method.getModifiers()) && !Modifier.isStatic(method.getModifiers())) {\n-          String name = method.getName();\n-          String key = \"\";\n-          if (name.startsWith(\"get\")) {\n-            if (\"getClass\".equals(name) || \"getDeclaringClass\".equals(name)) {\n-              key = \"\";\n-            } else {\n-              key = name.substring(3);\n-            }\n-          } else if (name.startsWith(\"is\")) {\n-            key = name.substring(2);\n-          }\n-          if (key.length() > 0 && Character.isUpperCase(key.charAt(0))\n-              && method.getParameterTypes().length == 0) {\n-            if (key.length() == 1) {\n-              key = key.toLowerCase();\n-            } else if (!Character.isUpperCase(key.charAt(1))) {\n-              key = key.substring(0, 1).toLowerCase() + key.substring(1);\n-            }\n-            Object result = method.invoke(bean, (Object[]) null);\n-            if (result != null) {\n-              this.map.put(key, wrap(result));\n-            } else if (!method.getReturnType().isArray()) {\n-              this.map.put(key, JSONObject.NULL);\n-            }\n-          }\n-        }\n-      } catch (Exception ignore) {\n-      }\n+  public String getString(String name) throws JSONException {\n+    Object object = get(name);\n+    String result = JSON.toString(object);\n+    if (result == null) {\n+      throw JSON.typeMismatch(name, object, \"String\");\n     }\n-    this.map.put(\"type-class\", klass.getCanonicalName());\n+    return result;\n   }\n \n-\n   /**\n-   * Put a key/boolean pair in the JSONObject.\n-   *\n-   * @param key A key string.\n-   * @param value A boolean which is the value.\n-   * @return this.\n-   * @throws JSONException If the key is null.\n+   * Returns the value mapped by {@code name} if it exists, coercing it if necessary, or the empty\n+   * string if no such mapping exists.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The value of the field.\n    */\n-  public JSONObject put(String key, boolean value) throws JSONException {\n-    this.put(key, value ? Boolean.TRUE : Boolean.FALSE);\n-    return this;\n+  public String optString(String name) {\n+    return optString(name, \"\");\n   }\n \n-\n   /**\n-   * Put a key/value pair in the JSONObject, where the value will be a JSONArray which is produced\n-   * from a Collection.\n+   * Returns the value mapped by {@code name} if it exists, coercing it if necessary, or\n+   * {@code fallback} if no such mapping exists.\n    * \n-   * @param key A key string.\n-   * @param value A Collection value.\n-   * @return this.\n-   * @throws JSONException\n+   * @param name The name of the field that we want.\n+   * @param fallback The value to return if the field doesn't exist.\n+   * @return The value of the field or fallback.\n    */\n-  public JSONObject put(String key, Collection value) throws JSONException {\n-    this.put(key, new JSONArray(value));\n-    return this;\n+  public String optString(String name, String fallback) {\n+    Object object = opt(name);\n+    String result = JSON.toString(object);\n+    return result != null ? result : fallback;\n   }\n \n-\n   /**\n-   * Put a key/double pair in the JSONObject.\n-   *\n-   * @param key A key string.\n-   * @param value A double which is the value.\n-   * @return this.\n-   * @throws JSONException If the key is null or if the number is invalid.\n+   * Returns the value mapped by {@code name} if it exists and is a {@code\n+   * JSONArray}, or throws otherwise.\n+   * \n+   * @param name The field we want to get.\n+   * @return The value of the field (if it is a JSONArray.\n+   * @throws JSONException if the mapping doesn't exist or is not a {@code JSONArray}.\n    */\n-  public JSONObject put(String key, double value) throws JSONException {\n-    this.put(key, new Double(value));\n-    return this;\n+  public JSONArray getJSONArray(String name) throws JSONException {\n+    Object object = get(name);\n+    if (object instanceof JSONArray) {\n+      return (JSONArray) object;\n+    } else {\n+      throw JSON.typeMismatch(name, object, \"JSONArray\");\n+    }\n   }\n \n-\n   /**\n-   * Put a key/int pair in the JSONObject.\n-   *\n-   * @param key A key string.\n-   * @param value An int which is the value.\n-   * @return this.\n-   * @throws JSONException If the key is null.\n+   * Returns the value mapped by {@code name} if it exists and is a {@code\n+   * JSONArray}, or null otherwise.\n+   * \n+   * @param name The name of the field we want.\n+   * @return The value of the specified field (assuming it is a JSNOArray\n    */\n-  public JSONObject put(String key, int value) throws JSONException {\n-    this.put(key, new Integer(value));\n-    return this;\n+  public JSONArray optJSONArray(String name) {\n+    Object object = opt(name);\n+    return object instanceof JSONArray ? (JSONArray) object : null;\n   }\n \n-\n   /**\n-   * Put a key/long pair in the JSONObject.\n-   *\n-   * @param key A key string.\n-   * @param value A long which is the value.\n-   * @return this.\n-   * @throws JSONException If the key is null.\n+   * Returns the value mapped by {@code name} if it exists and is a {@code\n+   * JSONObject}, or throws otherwise.\n+   * \n+   * @param name The name of the field that we want.\n+   * @return a specified field value (if it is a JSONObject)\n+   * @throws JSONException if the mapping doesn't exist or is not a {@code JSONObject}.\n    */\n-  public JSONObject put(String key, long value) throws JSONException {\n-    this.put(key, new Long(value));\n-    return this;\n+  public JSONObject getJSONObject(String name) throws JSONException {\n+    Object object = get(name);\n+    if (object instanceof JSONObject) {\n+      return (JSONObject) object;\n+    } else {\n+      throw JSON.typeMismatch(name, object, \"JSONObject\");\n+    }\n   }\n \n-\n   /**\n-   * Put a key/value pair in the JSONObject, where the value will be a JSONObject which is produced\n-   * from a Map.\n+   * Returns the value mapped by {@code name} if it exists and is a {@code\n+   * JSONObject}, or null otherwise.\n    * \n-   * @param key A key string.\n-   * @param value A Map value.\n-   * @return this.\n-   * @throws JSONException\n+   * @param name The name of the value we want.\n+   * @return The specified value.\n    */\n-  public JSONObject put(String key, Map value) throws JSONException {\n-    this.put(key, new JSONObject(value));\n-    return this;\n+  public JSONObject optJSONObject(String name) {\n+    Object object = opt(name);\n+    return object instanceof JSONObject ? (JSONObject) object : null;\n   }\n \n-\n   /**\n-   * Put a key/value pair in the JSONObject. If the value is null, then the key will be removed from\n-   * the JSONObject if it is present.\n+   * Returns an array with the values corresponding to {@code names}. The array contains null for\n+   * names that aren't mapped. This method returns null if {@code names} is either null or empty.\n    * \n-   * @param key A key string.\n-   * @param value An object which is the value. It should be of one of these types: Boolean, Double,\n-   *        Integer, JSONArray, JSONObject, Long, String, or the JSONObject.NULL object.\n-   * @return this.\n-   * @throws JSONException If the value is non-finite number or if the key is null.\n+   * @param names The names of the fields that we want the values for.\n+   * @return The selected values.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n    */\n-  public JSONObject put(String key, Object value) throws JSONException {\n-    if (key == null) {\n-      throw new JSONException(\"Null key.\");\n+  public JSONArray toJSONArray(JSONArray names) throws JSONException {\n+    JSONArray result = new JSONArray();\n+    if (names == null) {\n+      return null;\n     }\n-    if (value != null) {\n-      testValidity(value);\n-      this.map.put(key, value);\n-    } else {\n-      this.remove(key);\n+    int length = names.length();\n+    if (length == 0) {\n+      return null;\n     }\n-    return this;\n+    for (int i = 0; i < length; i++) {\n+      String name = JSON.toString(names.opt(i));\n+      result.put(opt(name));\n+    }\n+    return result;\n   }\n \n-\n   /**\n-   * Put a key/value pair in the JSONObject, but only if the key and the value are both non-null,\n-   * and only if there is not already a member with that name.\n+   * Returns an iterator of the {@code String} names in this object. The returned iterator supports\n+   * {@link Iterator#remove() remove}, which will remove the corresponding mapping from this object.\n+   * If this object is modified after the iterator is returned, the iterator's behavior is\n+   * undefined. The order of the keys is undefined.\n    * \n-   * @param key\n-   * @param value\n-   * @return his.\n-   * @throws JSONException if the key is a duplicate\n+   * @return an iterator over the keys.\n    */\n-  public JSONObject putOnce(String key, Object value) throws JSONException {\n-    if (key != null && value != null) {\n-      if (this.opt(key) != null) {\n-        throw new JSONException(\"Duplicate key \\\"\" + key + \"\\\"\");\n-      }\n-      this.put(key, value);\n-    }\n-    return this;\n+  public Iterator<String> keys() {\n+    return nameValuePairs.keySet().iterator();\n   }\n \n-\n   /**\n-   * Put a key/value pair in the JSONObject, but only if the key and the value are both non-null.\n+   * Returns the set of {@code String} names in this object. The returned set is a view of the keys\n+   * in this object. {@link Set#remove(Object)} will remove the corresponding mapping from this\n+   * object and set iterator behaviour is undefined if this object is modified after it is returned.\n+   *\n+   * See {@link #keys()}.\n    * \n-   * @param key A key string.\n-   * @param value An object which is the value. It should be of one of these types: Boolean, Double,\n-   *        Integer, JSONArray, JSONObject, Long, String, or the JSONObject.NULL object.\n-   * @return this.\n-   * @throws JSONException If the value is a non-finite number.\n+   * @return The names in this object.\n    */\n-  public JSONObject putOpt(String key, Object value) throws JSONException {\n-    if (key != null && value != null) {\n-      this.put(key, value);\n-    }\n-    return this;\n+  public Set<String> keySet() {\n+    return nameValuePairs.keySet();\n   }\n \n-\n   /**\n-   * Produce a string in double quotes with backslash sequences in all the right places. A backslash\n-   * will be inserted within </, producing <\\/, allowing JSON text to be delivered in HTML. In JSON\n-   * text, a string cannot contain a control character or an unescaped quote or backslash.\n+   * Returns an array containing the string names in this object. This method returns null if this\n+   * object contains no mappings.\n    * \n-   * @param string A String\n-   * @return A String correctly formatted for insertion in a JSON text.\n+   * @return the names.\n    */\n-  public static String quote(String string) {\n-    StringWriter sw = new StringWriter();\n-    synchronized (sw.getBuffer()) {\n-      try {\n-        return quote(string, sw).toString();\n-      } catch (IOException ignored) {\n-        // will never happen - we are writing to a string writer\n-        return \"\";\n-      }\n-    }\n-  }\n-\n-  public static Writer quote(String string, Writer w) throws IOException {\n-    if (string == null || string.length() == 0) {\n-      w.write(\"\\\"\\\"\");\n-      return w;\n-    }\n-\n-    char b;\n-    char c = 0;\n-    String hhhh;\n-    int i;\n-    int len = string.length();\n-\n-    w.write('\"');\n-    for (i = 0; i < len; i += 1) {\n-      b = c;\n-      c = string.charAt(i);\n-      switch (c) {\n-        case '\\\\':\n-        case '\"':\n-          w.write('\\\\');\n-          w.write(c);\n-          break;\n-        case '/':\n-          if (b == '<') {\n-            w.write('\\\\');\n-          }\n-          w.write(c);\n-          break;\n-        case '\\b':\n-          w.write(\"\\\\b\");\n-          break;\n-        case '\\t':\n-          w.write(\"\\\\t\");\n-          break;\n-        case '\\n':\n-          w.write(\"\\\\n\");\n-          break;\n-        case '\\f':\n-          w.write(\"\\\\f\");\n-          break;\n-        case '\\r':\n-          w.write(\"\\\\r\");\n-          break;\n-        default:\n-          if (c < ' ' || (c >= '\\u0080' && c < '\\u00a0') || (c >= '\\u2000' && c < '\\u2100')) {\n-            hhhh = \"000\" + Integer.toHexString(c);\n-            w.write(\"\\\\u\" + hhhh.substring(hhhh.length() - 4));\n-          } else {\n-            w.write(c);\n-          }\n-      }\n-    }\n-    w.write('\"');\n-    return w;\n+  public JSONArray names() {\n+    return nameValuePairs.isEmpty() ? null\n+        : new JSONArray(new ArrayList<String>(nameValuePairs.keySet()));\n   }\n \n   /**\n-   * Remove a name and its value, if present.\n+   * Encodes this object as a compact JSON string, such as:\n    * \n-   * @param key The name to be removed.\n-   * @return The value that was associated with the name, or null if there was no value.\n+   * <pre>\n+   * {\"query\":\"Pizza\",\"locations\":[94043,90210]}\n+   * </pre>\n    */\n-  public Object remove(String key) {\n-    return this.map.remove(key);\n+  @Override\n+  public String toString() {\n+    try {\n+      JSONStringer stringer = new JSONStringer();\n+      writeTo(stringer);\n+      return stringer.toString();\n+    } catch (JSONException e) {\n+      return null;\n+    }\n   }\n \n   /**\n-   * Try to convert a string into a number, boolean, or null. If the string can't be converted,\n-   * return the string.\n+   * Encodes this object as a human readable JSON string for debugging, such as:\n+   * \n+   * <pre>\n+   * {\n+   *     \"query\": \"Pizza\",\n+   *     \"locations\": [\n+   *         94043,\n+   *         90210\n+   *     ]\n+   * }\n+   * </pre>\n    * \n-   * @param string A String.\n-   * @return A simple JSON value.\n+   * @param indentSpaces the number of spaces to indent for each level of nesting.\n+   * @return The string containing the pretty form of this.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n    */\n-  public static Object stringToValue(String string) {\n-    Double d;\n-    if (string.equals(\"\")) {\n-      return string;\n-    }\n-    if (string.equalsIgnoreCase(\"true\")) {\n-      return Boolean.TRUE;\n-    }\n-    if (string.equalsIgnoreCase(\"false\")) {\n-      return Boolean.FALSE;\n-    }\n-    if (string.equalsIgnoreCase(\"null\")) {\n-      return JSONObject.NULL;\n-    }\n-\n-    /*\n-     * If it might be a number, try converting it. If a number cannot be produced, then the value\n-     * will just be a string. Note that the plus and implied string conventions are non-standard. A\n-     * JSON parser may accept non-JSON forms as long as it accepts all correct JSON forms.\n-     */\n+  public String toString(int indentSpaces) throws JSONException {\n+    JSONStringer stringer = new JSONStringer(indentSpaces);\n+    writeTo(stringer);\n+    return stringer.toString();\n+  }\n \n-    char b = string.charAt(0);\n-    if ((b >= '0' && b <= '9') || b == '.' || b == '-' || b == '+') {\n-      try {\n-        if (string.indexOf('.') > -1 || string.indexOf('e') > -1 || string.indexOf('E') > -1) {\n-          d = Double.valueOf(string);\n-          if (!d.isInfinite() && !d.isNaN()) {\n-            return d;\n-          }\n-        } else {\n-          Long myLong = new Long(string);\n-          if (myLong.longValue() == myLong.intValue()) {\n-            return new Integer(myLong.intValue());\n-          } else {\n-            return myLong;\n-          }\n-        }\n-      } catch (Exception ignore) {\n-      }\n+  void writeTo(JSONStringer stringer) throws JSONException {\n+    stringer.object();\n+    for (Map.Entry<String, Object> entry : nameValuePairs.entrySet()) {\n+      stringer.key(entry.getKey()).value(entry.getValue());\n     }\n-    return string;\n+    stringer.endObject();\n   }\n \n-\n   /**\n-   * Throw an exception if the object is a NaN or infinite number.\n+   * Encodes the number as a JSON string.\n    * \n-   * @param o The object to test.\n-   * @throws JSONException If o is a non-finite number.\n+   * @param number a finite value. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return The encoded number in string form.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n    */\n-  public static void testValidity(Object o) throws JSONException {\n-    if (o != null) {\n-      if (o instanceof Double) {\n-        if (((Double) o).isInfinite() || ((Double) o).isNaN()) {\n-          throw new JSONException(\"JSON does not allow non-finite numbers.\");\n-        }\n-      } else if (o instanceof Float) {\n-        if (((Float) o).isInfinite() || ((Float) o).isNaN()) {\n-          throw new JSONException(\"JSON does not allow non-finite numbers.\");\n-        }\n-      }\n+  public static String numberToString(Number number) throws JSONException {\n+    if (number == null) {\n+      throw new JSONException(\"Number must be non-null\");\n     }\n-  }\n \n+    double doubleValue = number.doubleValue();\n+    JSON.checkDouble(doubleValue);\n \n-  /**\n-   * Produce a JSONArray containing the values of the members of this JSONObject.\n-   * \n-   * @param names A JSONArray containing a list of key strings. This determines the sequence of the\n-   *        values in the result.\n-   * @return A JSONArray of values.\n-   * @throws JSONException If any of the values are non-finite numbers.\n-   */\n-  public JSONArray toJSONArray(JSONArray names) throws JSONException {\n-    if (names == null || names.length() == 0) {\n-      return null;\n-    }\n-    JSONArray ja = new JSONArray();\n-    for (int i = 0; i < names.length(); i += 1) {\n-      ja.put(this.opt(names.getString(i)));\n+    // the original returns \"-0\" instead of \"-0.0\" for negative zero\n+    if (number.equals(NEGATIVE_ZERO)) {\n+      return \"-0\";\n     }\n-    return ja;\n-  }\n \n-  /**\n-   * Make a JSON text of this JSONObject. For compactness, no whitespace is added. If this would not\n-   * result in a syntactically correct JSON text, then null will be returned instead.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n-   *\n-   * @return a printable, displayable, portable, transmittable representation of the object,\n-   *         beginning with <code>{</code>&nbsp;<small>(left brace)</small> and ending with\n-   *         <code>}</code>&nbsp;<small>(right brace)</small>.\n-   */\n-  public String toString() {\n-    try {\n-      return this.toString(0);\n-    } catch (Exception e) {\n-      return null;\n+    long longValue = number.longValue();\n+    if (doubleValue == (double) longValue) {\n+      return Long.toString(longValue);\n     }\n-  }\n \n+    return number.toString();\n+  }\n \n   /**\n-   * Make a prettyprinted JSON text of this JSONObject.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n+   * Encodes {@code data} as a JSON string. This applies quotes and any necessary character\n+   * escaping.\n    * \n-   * @param indentFactor The number of spaces to add to each level of indentation.\n-   * @return a printable, displayable, portable, transmittable representation of the object,\n-   *         beginning with <code>{</code>&nbsp;<small>(left brace)</small> and ending with\n-   *         <code>}</code>&nbsp;<small>(right brace)</small>.\n-   * @throws JSONException If the object contains an invalid number.\n+   * @param data the string to encode. Null will be interpreted as an empty string.\n+   * @return the quoted string.\n    */\n-  public String toString(int indentFactor) throws JSONException {\n-    StringWriter w = new StringWriter();\n-    synchronized (w.getBuffer()) {\n-      return this.write(w, indentFactor, 0).toString();\n+  public static String quote(String data) {\n+    if (data == null) {\n+      return \"\\\"\\\"\";\n+    }\n+    try {\n+      JSONStringer stringer = new JSONStringer();\n+      stringer.open(JSONStringer.Scope.NULL, \"\");\n+      stringer.value(data);\n+      stringer.close(JSONStringer.Scope.NULL, JSONStringer.Scope.NULL, \"\");\n+      return stringer.toString();\n+    } catch (JSONException e) {\n+      throw new AssertionError();\n     }\n   }\n \n   /**\n-   * Make a JSON text of an Object value. If the object has an value.toJSONString() method, then\n-   * that method will be used to produce the JSON text. The method is required to produce a strictly\n-   * conforming text. If the object does not contain a toJSONString method (which is the most common\n-   * case), then a text will be produced by other means. If the value is an array or Collection,\n-   * then a JSONArray will be made from it and its toJSONString method will be called. If the value\n-   * is a MAP, then a JSONObject will be made from it and its toJSONString method will be called.\n-   * Otherwise, the value's toString method will be called, and the result will be quoted.\n+   * Wraps the given object if necessary.\n    *\n    * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n+   * If the object is null or , returns {@link #NULL}. If the object is a {@code JSONArray} or\n+   * {@code JSONObject}, no wrapping is necessary. If the object is {@code NULL}, no wrapping is\n+   * necessary. If the object is an array or {@code Collection}, returns an equivalent {@code\n+   * JSONArray}. If the object is a {@code Map}, returns an equivalent {@code JSONObject}. If the\n+   * object is a primitive wrapper type or {@code String}, returns the object. If the object is from\n+   * a {@code java} package, returns the result of {@code toString}. If the object is some other\n+   * kind of object then it is assumed to be a bean and is converted to a JSONObject. If wrapping\n+   * fails, returns null.\n    * \n-   * @param value The value to be serialized.\n-   * @return a printable, displayable, transmittable representation of the object, beginning with\n-   *         <code>{</code>&nbsp;<small>(left brace)</small> and ending with\n-   *         <code>}</code>&nbsp;<small>(right brace)</small>.\n-   * @throws JSONException If the value is or contains an invalid number.\n+   * @param o The object to wrap.\n+   * @return The wrapped (if necessary) form of the object {$code o}\n    */\n-  public static String valueToString(Object value) throws JSONException {\n-    if (value == null || value.equals(null)) {\n-      return \"null\";\n-    }\n-    if (value instanceof JSONString) {\n-      Object object;\n-      try {\n-        object = ((JSONString) value).toJSONString();\n-      } catch (Exception e) {\n-        throw new JSONException(e);\n-      }\n-      if (object instanceof String) {\n-        return (String) object;\n-      }\n-      throw new JSONException(\"Bad value from toJSONString: \" + object);\n-    }\n-    if (value instanceof Number) {\n-      return numberToString((Number) value);\n+  public static Object wrap(Object o) {\n+    if (o == null) {\n+      return NULL;\n     }\n-    if (value instanceof Boolean || value instanceof JSONObject || value instanceof JSONArray) {\n-      return value.toString();\n+    if (o instanceof JSONArray || o instanceof JSONObject) {\n+      return o;\n     }\n-    if (value instanceof Map) {\n-      return new JSONObject((Map) value).toString();\n+    if (o.equals(NULL)) {\n+      return o;\n     }\n-    if (value instanceof Collection) {\n-      return new JSONArray((Collection) value).toString();\n-    }\n-    if (value.getClass().isArray()) {\n-      return new JSONArray(value).toString();\n-    }\n-    return quote(value.toString());\n-  }\n-\n-  /**\n-   * Wrap an object, if necessary. If the object is null, return the NULL object. If it is an array\n-   * or collection, wrap it in a JSONArray. If it is a map, wrap it in a JSONObject. If it is a\n-   * standard property (Double, String, et al) then it is already wrapped. Otherwise, if it comes\n-   * from one of the java packages, turn it into a string. And if it doesn't, try to wrap it in a\n-   * JSONObject. If the wrapping fails, then null is returned.\n-   *\n-   * @param object The object to wrap\n-   * @return The wrapped value\n-   */\n-  public static Object wrap(Object object) {\n     try {\n-      if (object == null) {\n-        return NULL;\n+      if (o instanceof Collection) {\n+        return new JSONArray((Collection) o);\n+      } else if (o.getClass().isArray()) {\n+        return new JSONArray(o);\n       }\n-      if (object instanceof JSONObject || object instanceof JSONArray || NULL.equals(object)\n-          || object instanceof JSONString || object instanceof Byte || object instanceof Character\n-          || object instanceof Short || object instanceof Integer || object instanceof Long\n-          || object instanceof Boolean || object instanceof Float || object instanceof Double\n-          || object instanceof String) {\n-        return object;\n+      if (o instanceof Map) {\n+        return new JSONObject((Map) o);\n       }\n-\n-      if (object instanceof Collection) {\n-        return new JSONArray((Collection) object);\n+      if (o instanceof Boolean || o instanceof Byte || o instanceof Character || o instanceof Double\n+          || o instanceof Float || o instanceof Integer || o instanceof Long || o instanceof Short\n+          || o instanceof String) {\n+        return o;\n       }\n-      if (object.getClass().isArray()) {\n-        return new JSONArray(object);\n-      }\n-      if (object instanceof Map) {\n-        return new JSONObject((Map) object);\n-      }\n-      Package objectPackage = object.getClass().getPackage();\n+      // GEODE-2142: Added check to ignore GemFireCacheImpl\n+      Package objectPackage = o.getClass().getPackage();\n       String objectPackageName = objectPackage != null ? objectPackage.getName() : \"\";\n       if (objectPackageName.startsWith(\"java.\") || objectPackageName.startsWith(\"javax.\")\n-          || object.getClass().getClassLoader() == null\n-          || object.getClass().getName().contains(\"GemFireCacheImpl\")) {\n-        return object.toString();\n+          || o instanceof Enum<?> || o.getClass().getClassLoader() == null\n+          || o.getClass().getName().contains(\"GemFireCacheImpl\")) {\n+        return o.toString();\n       }\n-\n+      // GEODE-2142: Added the cyclicalDepCheck\n       if (cyclicDepChkEnabled.get() != null && cyclicDependencySet.get() != null) {\n-        if (cyclicDepChkEnabled.get() && cyclicDependencySet.get().contains(object)) {\n+        if (cyclicDepChkEnabled.get() && cyclicDependencySet.get().contains(o)) {\n           // break cyclic reference\n-          return object.getClass().getCanonicalName();\n+          return o.getClass().getCanonicalName();\n         } else {\n-          cyclicDependencySet.get().add(object);\n-          return new JSONObject(object);\n-        }\n-      } else\n-        return new JSONObject(object);\n-\n-    } catch (Exception exception) {\n-      return null;\n-    }\n-  }\n-\n-\n-  /**\n-   * Write the contents of the JSONObject as JSON text to a writer. For compactness, no whitespace\n-   * is added.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n-   *\n-   * @return The writer.\n-   * @throws JSONException\n-   */\n-  public Writer write(Writer writer) throws JSONException {\n-    return this.write(writer, 0, 0);\n-  }\n-\n-\n-  static final Writer writeValue(Writer writer, Object value, int indentFactor, int indent)\n-      throws JSONException, IOException {\n-    if (value == null || value.equals(null)) {\n-      writer.write(\"null\");\n-    } else if (value instanceof JSONObject) {\n-      ((JSONObject) value).write(writer, indentFactor, indent);\n-    } else if (value instanceof JSONArray) {\n-      ((JSONArray) value).write(writer, indentFactor, indent);\n-    } else if (value instanceof Map) {\n-      new JSONObject((Map) value).write(writer, indentFactor, indent);\n-    } else if (value instanceof Collection) {\n-      new JSONArray((Collection) value).write(writer, indentFactor, indent);\n-    } else if (value.getClass().isArray()) {\n-      new JSONArray(value).write(writer, indentFactor, indent);\n-    } else if (value instanceof Number) {\n-      writer.write(numberToString((Number) value));\n-    } else if (value instanceof Boolean) {\n-      writer.write(value.toString());\n-    } else if (value instanceof JSONString) {\n-      Object o;\n-      try {\n-        o = ((JSONString) value).toJSONString();\n-      } catch (Exception e) {\n-        throw new JSONException(e);\n-      }\n-      writer.write(o != null ? o.toString() : quote(value.toString()));\n-    } else {\n-      quote(value.toString(), writer);\n-    }\n-    return writer;\n-  }\n-\n-  static final void indent(Writer writer, int indent) throws IOException {\n-    for (int i = 0; i < indent; i += 1) {\n-      writer.write(' ');\n-    }\n-  }\n-\n-  /**\n-   * Write the contents of the JSONObject as JSON text to a writer. For compactness, no whitespace\n-   * is added.\n-   * <p>\n-   * Warning: This method assumes that the data structure is acyclical.\n-   *\n-   * @return The writer.\n-   * @throws JSONException\n-   */\n-  Writer write(Writer writer, int indentFactor, int indent) throws JSONException {\n-    try {\n-      boolean commanate = false;\n-      final int length = this.length();\n-      Iterator keys = this.keys();\n-      writer.write('{');\n-\n-      if (length == 1) {\n-        Object key = keys.next();\n-        writer.write(quote(key.toString()));\n-        writer.write(':');\n-        if (indentFactor > 0) {\n-          writer.write(' ');\n-        }\n-        writeValue(writer, this.map.get(key), indentFactor, indent);\n-      } else if (length != 0) {\n-        final int newindent = indent + indentFactor;\n-        while (keys.hasNext()) {\n-          Object key = keys.next();\n-          if (commanate) {\n-            writer.write(',');\n-          }\n-          if (indentFactor > 0) {\n-            writer.write('\\n');\n-          }\n-          indent(writer, newindent);\n-          writer.write(quote(key.toString()));\n-          writer.write(':');\n-          if (indentFactor > 0) {\n-            writer.write(' ');\n-          }\n-          writeValue(writer, this.map.get(key), indentFactor, newindent);\n-          commanate = true;\n-        }\n-        if (indentFactor > 0) {\n-          writer.write('\\n');\n+          cyclicDependencySet.get().add(o);\n+          return new JSONObject(o);\n         }\n-        indent(writer, indent);\n+      } else {\n+        return new JSONObject(o);\n       }\n-      writer.write('}');\n-      return writer;\n-    } catch (IOException exception) {\n-      throw new JSONException(exception);\n+    } catch (Exception ignored) {\n     }\n+    return null;\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONObject.java",
                "sha": "07a024cd6448cd7993a630bb2f43e998193efdf0",
                "status": "modified"
            },
            {
                "additions": 438,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONStringer.java",
                "changes": 492,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONStringer.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 54,
                "filename": "geode-json/src/main/java/org/json/JSONStringer.java",
                "patch": "@@ -1,75 +1,459 @@\n-package org.json;\n-\n /*\n- * Copyright (c) 2006 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n  */\n \n-import java.io.StringWriter;\n+package org.json;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+// Note: this class was written without inspecting the non-free org.json sourcecode.\n \n /**\n- * JSONStringer provides a quick and convenient way of producing JSON text. The texts produced\n- * strictly conform to JSON syntax rules. No whitespace is added, so the results are ready for\n- * transmission or storage. Each instance of JSONStringer can produce one JSON text.\n- * <p>\n- * A JSONStringer instance provides a <code>value</code> method for appending values to the text,\n- * and a <code>key</code> method for adding keys before values in objects. There are\n- * <code>array</code> and <code>endArray</code> methods that make and bound array values, and\n- * <code>object</code> and <code>endObject</code> methods which make and bound object values. All of\n- * these methods return the JSONWriter instance, permitting cascade style. For example,\n- * \n- * <pre>\n- * myString = new JSONStringer().object().key(\"JSON\").value(\"Hello, World!\").endObject().toString();\n- * </pre>\n- * \n- * which produces the string\n+ * Implements {@link JSONObject#toString} and {@link JSONArray#toString}. Most application\n+ * developers should use those methods directly and disregard this API. For example:\n  * \n  * <pre>\n- * {\"JSON\":\"Hello, World!\"}\n+ * JSONObject object = ...\n+ * String json = object.toString();\n  * </pre>\n+ *\n  * <p>\n- * The first method called must be <code>array</code> or <code>object</code>. There are no methods\n- * for adding commas or colons. JSONStringer adds them for you. Objects and arrays can be nested up\n- * to 20 levels deep.\n+ * Stringers only encode well-formed JSON strings. In particular:\n+ * <ul>\n+ * <li>The stringer must have exactly one top-level array or object.\n+ * <li>Lexical scopes must be balanced: every call to {@link #array} must have a matching call to\n+ * {@link #endArray} and every call to {@link #object} must have a matching call to\n+ * {@link #endObject}.\n+ * <li>Arrays may not contain keys (property names).\n+ * <li>Objects must alternate keys (property names) and values.\n+ * <li>Values are inserted with either literal {@link #value(Object) value} calls, or by nesting\n+ * arrays or objects.\n+ * </ul>\n+ * Calls that would result in a malformed JSON string will fail with a {@link JSONException}.\n+ *\n  * <p>\n- * This can sometimes be easier than using a JSONObject to build a string.\n- * \n- * @author JSON.org\n- * @version 2008-09-18\n+ * This class provides no facility for pretty-printing (ie. indenting) output. To encode indented\n+ * output, use {@link JSONObject#toString(int)} or {@link JSONArray#toString(int)}.\n+ *\n+ * <p>\n+ * Some implementations of the API support at most 20 levels of nesting. Attempts to create more\n+ * than 20 levels of nesting may fail with a {@link JSONException}.\n+ *\n+ * <p>\n+ * Each stringer may be used to encode a single top level value. Instances of this class are not\n+ * thread safe. Although this class is nonfinal, it was not designed for inheritance and should not\n+ * be subclassed. In particular, self-use by overrideable methods is not specified. See <i>Effective\n+ * Java</i> Item 17, \"Design and Document or inheritance or else prohibit it\" for further\n+ * information.\n  */\n-public class JSONStringer extends JSONWriter {\n+public class JSONStringer {\n+\n+  /**\n+   * The output data, containing at most one top-level array or object.\n+   */\n+  final StringBuilder out = new StringBuilder();\n+\n+  /**\n+   * Lexical scoping elements within this stringer, necessary to insert the appropriate separator\n+   * characters (ie. commas and colons) and to detect nesting errors.\n+   */\n+  enum Scope {\n+\n+    /**\n+     * An array with no elements requires no separators or newlines before it is closed.\n+     */\n+    EMPTY_ARRAY,\n+\n+    /**\n+     * A array with at least one value requires a comma and newline before the next element.\n+     */\n+    NONEMPTY_ARRAY,\n+\n+    /**\n+     * An object with no keys or values requires no separators or newlines before it is closed.\n+     */\n+    EMPTY_OBJECT,\n+\n+    /**\n+     * An object whose most recent element is a key. The next element must be a value.\n+     */\n+    DANGLING_KEY,\n+\n+    /**\n+     * An object with at least one name/value pair requires a comma and newline before the next\n+     * element.\n+     */\n+    NONEMPTY_OBJECT,\n+\n+    /**\n+     * A special bracketless array needed by JSONStringer.join() and JSONObject.quote() only. Not\n+     * used for JSON encoding.\n+     */\n+    NULL,\n+  }\n+\n   /**\n-   * Make a fresh JSONStringer. It can be used to build one JSON text.\n+   * Unlike the original implementation, this stack isn't limited to 20 levels of nesting.\n    */\n+  private final List<Scope> stack = new ArrayList<Scope>();\n+\n+  /**\n+   * A string containing a full set of spaces for a single level of indentation, or null for no\n+   * pretty printing.\n+   */\n+  private final String indent;\n+\n   public JSONStringer() {\n-    super(new StringWriter());\n+    indent = null;\n+  }\n+\n+  JSONStringer(int indentSpaces) {\n+    char[] indentChars = new char[indentSpaces];\n+    Arrays.fill(indentChars, ' ');\n+    indent = new String(indentChars);\n+  }\n+\n+  /**\n+   * Begins encoding a new array. Each call to this method must be paired with a call to\n+   * {@link #endArray}.\n+   *\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer array() throws JSONException {\n+    return open(Scope.EMPTY_ARRAY, \"[\");\n+  }\n+\n+  /**\n+   * Ends encoding the current array.\n+   *\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer endArray() throws JSONException {\n+    return close(Scope.EMPTY_ARRAY, Scope.NONEMPTY_ARRAY, \"]\");\n+  }\n+\n+  /**\n+   * Begins encoding a new object. Each call to this method must be paired with a call to\n+   * {@link #endObject}.\n+   *\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer object() throws JSONException {\n+    return open(Scope.EMPTY_OBJECT, \"{\");\n+  }\n+\n+  /**\n+   * Ends encoding the current object.\n+   *\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer endObject() throws JSONException {\n+    return close(Scope.EMPTY_OBJECT, Scope.NONEMPTY_OBJECT, \"}\");\n+  }\n+\n+  /**\n+   * Enters a new scope by appending any necessary whitespace and the given bracket.\n+   */\n+  JSONStringer open(Scope empty, String openBracket) throws JSONException {\n+    if (stack.isEmpty() && out.length() > 0) {\n+      throw new JSONException(\"Nesting problem: multiple top-level roots\");\n+    }\n+    beforeValue();\n+    stack.add(empty);\n+    out.append(openBracket);\n+    return this;\n+  }\n+\n+  /**\n+   * Closes the current scope by appending any necessary whitespace and the given bracket.\n+   */\n+  JSONStringer close(Scope empty, Scope nonempty, String closeBracket) throws JSONException {\n+    Scope context = peek();\n+    if (context != nonempty && context != empty) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+\n+    stack.remove(stack.size() - 1);\n+    if (context == nonempty) {\n+      newline();\n+    }\n+    out.append(closeBracket);\n+    return this;\n+  }\n+\n+  /**\n+   * Returns the value on the top of the stack.\n+   */\n+  private Scope peek() throws JSONException {\n+    if (stack.isEmpty()) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+    return stack.get(stack.size() - 1);\n+  }\n+\n+  /**\n+   * Replace the value on the top of the stack with the given value.\n+   */\n+  private void replaceTop(Scope topOfStack) {\n+    stack.set(stack.size() - 1, topOfStack);\n+  }\n+\n+  /**\n+   * Encodes {@code value}.\n+   *\n+   * @param value a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double or\n+   *        null. May not be {@link Double#isNaN() NaNs} or {@link Double#isInfinite() infinities}.\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer value(Object value) throws JSONException {\n+    if (stack.isEmpty()) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+\n+    if (value instanceof JSONArray) {\n+      ((JSONArray) value).writeTo(this);\n+      return this;\n+\n+    } else if (value instanceof JSONObject) {\n+      ((JSONObject) value).writeTo(this);\n+      return this;\n+    }\n+\n+    beforeValue();\n+\n+    if (value instanceof JSONString) {\n+      out.append(((JSONString) value).toJSONString());\n+      return this;\n+    }\n+\n+    if (value == null || value instanceof Boolean || value == JSONObject.NULL) {\n+      out.append(value);\n+\n+    } else if (value instanceof Number) {\n+      out.append(JSONObject.numberToString((Number) value));\n+\n+    } else {\n+      // Hack to make it possible that the value is not surrounded by quotes. (Used for JavaScript\n+      // function calls)\n+      // Example: { \"name\": \"testkey\", \"value\": window.myfunction() }\n+      if (value.getClass().getSimpleName().contains(\"JSONFunction\")) {\n+        // note that no escaping of quotes (or anything else) is done in this case.\n+        // that is fine because the only way to get to this point is to\n+        // explicitly put a special kind of object into the JSON data structure.\n+        out.append(value);\n+      } else {\n+        string(value.toString());\n+      }\n+    }\n+\n+    return this;\n+  }\n+\n+  /**\n+   * Encodes {@code value} to this stringer.\n+   *\n+   * @param value The value to encode.\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer value(boolean value) throws JSONException {\n+    if (stack.isEmpty()) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+    beforeValue();\n+    out.append(value);\n+    return this;\n+  }\n+\n+  /**\n+   * Encodes {@code value} to this stringer.\n+   *\n+   * @param value a finite value. May not be {@link Double#isNaN() NaNs} or\n+   *        {@link Double#isInfinite() infinities}.\n+   * @return this stringer.\n+   * @throws JSONException On internal errors. Shouldn't happen.\n+   */\n+  public JSONStringer value(double value) throws JSONException {\n+    if (stack.isEmpty()) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+    beforeValue();\n+    out.append(JSONObject.numberToString(value));\n+    return this;\n+  }\n+\n+  /**\n+   * Encodes {@code value} to this stringer.\n+   *\n+   * @param value The value to encode.\n+   * @return this stringer.\n+   * @throws JSONException If we have an internal error. Shouldn't happen.\n+   */\n+  public JSONStringer value(long value) throws JSONException {\n+    if (stack.isEmpty()) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+    beforeValue();\n+    out.append(value);\n+    return this;\n+  }\n+\n+  private void string(String value) {\n+    out.append(\"\\\"\");\n+    char currentChar = 0;\n+\n+    for (int i = 0, length = value.length(); i < length; i++) {\n+      char previousChar = currentChar;\n+      currentChar = value.charAt(i);\n+\n+      /*\n+       * From RFC 4627, \"All Unicode characters may be placed within the quotation marks except for\n+       * the characters that must be escaped: quotation mark, reverse solidus, and the control\n+       * characters (U+0000 through U+001F).\"\n+       */\n+      switch (currentChar) {\n+        case '\"':\n+        case '\\\\':\n+          out.append('\\\\').append(currentChar);\n+          break;\n+\n+        case '/':\n+          // it makes life easier for HTML embedding of javascript if we escape </ sequences\n+          if (previousChar == '<') {\n+            out.append('\\\\');\n+          }\n+          out.append(currentChar);\n+          break;\n+\n+        case '\\t':\n+          out.append(\"\\\\t\");\n+          break;\n+\n+        case '\\b':\n+          out.append(\"\\\\b\");\n+          break;\n+\n+        case '\\n':\n+          out.append(\"\\\\n\");\n+          break;\n+\n+        case '\\r':\n+          out.append(\"\\\\r\");\n+          break;\n+\n+        case '\\f':\n+          out.append(\"\\\\f\");\n+          break;\n+\n+        default:\n+          if (currentChar <= 0x1F) {\n+            out.append(String.format(\"\\\\u%04x\", (int) currentChar));\n+          } else {\n+            out.append(currentChar);\n+          }\n+          break;\n+      }\n+\n+    }\n+    out.append(\"\\\"\");\n+  }\n+\n+  private void newline() {\n+    if (indent == null) {\n+      return;\n+    }\n+\n+    out.append(\"\\n\");\n+    for (int i = 0; i < stack.size(); i++) {\n+      out.append(indent);\n+    }\n+  }\n+\n+  /**\n+   * Encodes the key (property name) to this stringer.\n+   *\n+   * @param name the name of the forthcoming value. May not be null.\n+   * @return this stringer.\n+   * @throws JSONException on internal errors, shouldn't happen.\n+   */\n+  public JSONStringer key(String name) throws JSONException {\n+    if (name == null) {\n+      throw new JSONException(\"Names must be non-null\");\n+    }\n+    beforeKey();\n+    string(name);\n+    return this;\n+  }\n+\n+  /**\n+   * Inserts any necessary separators and whitespace before a name. Also adjusts the stack to expect\n+   * the key's value.\n+   */\n+  private void beforeKey() throws JSONException {\n+    Scope context = peek();\n+    if (context == Scope.NONEMPTY_OBJECT) { // first in object\n+      out.append(',');\n+    } else if (context != Scope.EMPTY_OBJECT) { // not in an object!\n+      throw new JSONException(\"Nesting problem\");\n+    }\n+    newline();\n+    replaceTop(Scope.DANGLING_KEY);\n+  }\n+\n+  /**\n+   * Inserts any necessary separators and whitespace before a literal value, inline array, or inline\n+   * object. Also adjusts the stack to expect either a closing bracket or another element.\n+   */\n+  private void beforeValue() throws JSONException {\n+    if (stack.isEmpty()) {\n+      return;\n+    }\n+\n+    Scope context = peek();\n+    if (context == Scope.EMPTY_ARRAY) { // first in array\n+      replaceTop(Scope.NONEMPTY_ARRAY);\n+      newline();\n+    } else if (context == Scope.NONEMPTY_ARRAY) { // another in array\n+      out.append(',');\n+      newline();\n+    } else if (context == Scope.DANGLING_KEY) { // value for key\n+      out.append(indent == null ? \":\" : \": \");\n+      replaceTop(Scope.NONEMPTY_OBJECT);\n+    } else if (context != Scope.NULL) {\n+      throw new JSONException(\"Nesting problem\");\n+    }\n   }\n \n   /**\n-   * Return the JSON text. This method is used to obtain the product of the JSONStringer instance.\n-   * It will return <code>null</code> if there was a problem in the construction of the JSON text\n-   * (such as the calls to <code>array</code> were not properly balanced with calls to\n-   * <code>endArray</code>).\n-   * \n-   * @return The JSON text.\n+   * Returns the encoded JSON string.\n+   *\n+   * <p>\n+   * If invoked with unterminated arrays or unclosed objects, this method's return value is\n+   * undefined.\n+   *\n+   * <p>\n+   * <strong>Warning:</strong> although it contradicts the general contract of\n+   * {@link Object#toString}, this method returns null if the stringer contains no data.\n    */\n+  @Override\n   public String toString() {\n-    return this.mode == 'd' ? this.writer.toString() : null;\n+    return out.length() == 0 ? null : out.toString();\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONStringer.java",
                "sha": "43224a56394694d6602cc6a131586738fc731d2a",
                "status": "modified"
            },
            {
                "additions": 527,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONTokener.java",
                "changes": 852,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONTokener.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 325,
                "filename": "geode-json/src/main/java/org/json/JSONTokener.java",
                "patch": "@@ -1,437 +1,639 @@\n+/*\n+ * Copyright (C) 2010 The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n+ * in compliance with the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n package org.json;\n \n-import java.io.BufferedReader;\n+// Note: this class was written without inspecting the non-free org.json sourcecode.\n+\n import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.InputStreamReader;\n import java.io.Reader;\n-import java.io.StringReader;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n \n /**\n- * A JSONTokener takes a source string and extracts characters and tokens from it. It is used by the\n- * JSONObject and JSONArray constructors to parse JSON source strings.\n+ * Parses a JSON (<a href=\"http://www.ietf.org/rfc/rfc4627.txt\">RFC 4627</a>) encoded string into\n+ * the corresponding object. Most clients of this class will use only need the\n+ * {@link #JSONTokener(String) constructor} and {@link #nextValue} method. Example usage:\n  * \n- * @author JSON.org\n- * @version 2012-02-16\n+ * <pre>\n+ * String json = \"{\" + \"  \\\"query\\\": \\\"Pizza\\\", \" + \"  \\\"locations\\\": [ 94043, 90210 ] \" + \"}\";\n+ *\n+ * JSONObject object = (JSONObject) new JSONTokener(json).nextValue();\n+ * String query = object.getString(\"query\");\n+ * JSONArray locations = object.getJSONArray(\"locations\");\n+ * </pre>\n+ *\n+ * <p>\n+ * For best interoperability and performance use JSON that complies with RFC 4627, such as that\n+ * generated by {@link JSONStringer}. For legacy reasons this parser is lenient, so a successful\n+ * parse does not indicate that the input string was valid JSON. All of the following syntax errors\n+ * will be ignored:\n+ * <ul>\n+ * <li>End of line comments starting with {@code //} or {@code #} and ending with a newline\n+ * character.\n+ * <li>C-style comments starting with {@code /*} and ending with {@code *}{@code /}. Such comments\n+ * may not be nested.\n+ * <li>Strings that are unquoted or {@code 'single quoted'}.\n+ * <li>Hexadecimal integers prefixed with {@code 0x} or {@code 0X}.\n+ * <li>Octal integers prefixed with {@code 0}.\n+ * <li>Array elements separated by {@code ;}.\n+ * <li>Unnecessary array separators. These are interpreted as if null was the omitted value.\n+ * <li>Key-value pairs separated by {@code =} or {@code =>}.\n+ * <li>Key-value pairs separated by {@code ;}.\n+ * </ul>\n+ *\n+ * <p>\n+ * Each tokener may be used to parse a single JSON string. Instances of this class are not thread\n+ * safe. Although this class is nonfinal, it was not designed for inheritance and should not be\n+ * subclassed. In particular, self-use by overrideable methods is not specified. See <i>Effective\n+ * Java</i> Item 17, \"Design and Document or inheritance or else prohibit it\" for further\n+ * information.\n  */\n public class JSONTokener {\n \n-  private long character;\n-  private boolean eof;\n-  private long index;\n-  private long line;\n-  private char previous;\n-  private Reader reader;\n-  private boolean usePrevious;\n-\n-\n   /**\n-   * Construct a JSONTokener from a Reader.\n-   *\n-   * @param reader A reader.\n+   * The input JSON.\n    */\n-  public JSONTokener(Reader reader) {\n-    this.reader = reader.markSupported() ? reader : new BufferedReader(reader);\n-    this.eof = false;\n-    this.usePrevious = false;\n-    this.previous = 0;\n-    this.index = 0;\n-    this.character = 1;\n-    this.line = 1;\n-  }\n+  private final String in;\n \n+  /**\n+   * The index of the next character to be returned by {@link #next}. When the input is exhausted,\n+   * this equals the input's length.\n+   */\n+  private int pos;\n \n   /**\n-   * Construct a JSONTokener from an InputStream.\n+   * @param in JSON encoded string. Null is not permitted and will yield a tokener that throws\n+   *        {@code NullPointerExceptions} when methods are called.\n    */\n-  public JSONTokener(InputStream inputStream) throws JSONException {\n-    this(new InputStreamReader(inputStream));\n+  public JSONTokener(String in) {\n+    // consume an optional byte order mark (BOM) if it exists\n+    if (in != null && in.startsWith(\"\\ufeff\")) {\n+      in = in.substring(1);\n+    }\n+    this.in = in;\n   }\n \n+  public JSONTokener(Reader input) throws IOException {\n+    StringBuilder s = new StringBuilder();\n+    char[] readBuf = new char[102400];\n+    int n = input.read(readBuf);\n+    while (n >= 0) {\n+      s.append(readBuf, 0, n);\n+      n = input.read(readBuf);\n+    }\n+    in = s.toString();\n+    pos = 0;\n+  }\n \n   /**\n-   * Construct a JSONTokener from a string.\n+   * Returns the next value from the input.\n    *\n-   * @param s A source string.\n+   * @return a {@link JSONObject}, {@link JSONArray}, String, Boolean, Integer, Long, Double or\n+   *         {@link JSONObject#NULL}.\n+   * @throws JSONException if the input is malformed.\n    */\n-  public JSONTokener(String s) {\n-    this(new StringReader(s));\n-  }\n+  public Object nextValue() throws JSONException {\n+    int c = nextCleanInternal();\n+    switch (c) {\n+      case -1:\n+        throw syntaxError(\"End of input\");\n \n+      case '{':\n+        return readObject();\n \n-  /**\n-   * Back up one character. This provides a sort of lookahead capability, so that you can test for a\n-   * digit or letter before attempting to parse the next number or identifier.\n-   */\n-  public void back() throws JSONException {\n-    if (this.usePrevious || this.index <= 0) {\n-      throw new JSONException(\"Stepping back two steps is not supported\");\n+      case '[':\n+        return readArray();\n+\n+      case '\\'':\n+      case '\"':\n+        return nextString((char) c);\n+\n+      default:\n+        pos--;\n+        return readLiteral();\n     }\n-    this.index -= 1;\n-    this.character -= 1;\n-    this.usePrevious = true;\n-    this.eof = false;\n   }\n \n+  private int nextCleanInternal() throws JSONException {\n+    while (pos < in.length()) {\n+      int c = in.charAt(pos++);\n+      switch (c) {\n+        case '\\t':\n+        case ' ':\n+        case '\\n':\n+        case '\\r':\n+          continue;\n \n-  /**\n-   * Get the hex value of a character (base16).\n-   * \n-   * @param c A character between '0' and '9' or between 'A' and 'F' or between 'a' and 'f'.\n-   * @return An int between 0 and 15, or -1 if c was not a hex digit.\n-   */\n-  public static int dehexchar(char c) {\n-    if (c >= '0' && c <= '9') {\n-      return c - '0';\n-    }\n-    if (c >= 'A' && c <= 'F') {\n-      return c - ('A' - 10);\n-    }\n-    if (c >= 'a' && c <= 'f') {\n-      return c - ('a' - 10);\n+        case '/':\n+          if (pos == in.length()) {\n+            return c;\n+          }\n+\n+          char peek = in.charAt(pos);\n+          switch (peek) {\n+            case '*':\n+              // skip a /* c-style comment */\n+              pos++;\n+              int commentEnd = in.indexOf(\"*/\", pos);\n+              if (commentEnd == -1) {\n+                throw syntaxError(\"Unterminated comment\");\n+              }\n+              pos = commentEnd + 2;\n+              continue;\n+\n+            case '/':\n+              // skip a // end-of-line comment\n+              pos++;\n+              skipToEndOfLine();\n+              continue;\n+\n+            default:\n+              return c;\n+          }\n+\n+        case '#':\n+          /*\n+           * Skip a # hash end-of-line comment. The JSON RFC doesn't specify this behavior, but it's\n+           * required to parse existing documents. See http://b/2571423.\n+           */\n+          skipToEndOfLine();\n+          continue;\n+\n+        default:\n+          return c;\n+      }\n     }\n-    return -1;\n-  }\n \n-  public boolean end() {\n-    return this.eof && !this.usePrevious;\n+    return -1;\n   }\n \n-\n   /**\n-   * Determine if the source string still contains characters that next() can consume.\n-   * \n-   * @return true if not yet at the end of the source.\n+   * Advances the position until after the next newline character. If the line is terminated by\n+   * \"\\r\\n\", the '\\n' must be consumed as whitespace by the caller.\n    */\n-  public boolean more() throws JSONException {\n-    this.next();\n-    if (this.end()) {\n-      return false;\n+  private void skipToEndOfLine() {\n+    for (; pos < in.length(); pos++) {\n+      char c = in.charAt(pos);\n+      if (c == '\\r' || c == '\\n') {\n+        pos++;\n+        break;\n+      }\n     }\n-    this.back();\n-    return true;\n   }\n \n-\n   /**\n-   * Get the next character in the source string.\n+   * Returns the string up to but not including {@code quote}, unescaping any character escape\n+   * sequences encountered along the way. The opening quote should have already been read. This\n+   * consumes the closing quote, but does not include it in the returned string.\n    *\n-   * @return The next character, or 0 if past the end of the source string.\n+   * @param quote either ' or \".\n+   * @return The unescaped string.\n+   * @throws JSONException if the string isn't terminated by a closing quote correctly.\n    */\n-  public char next() throws JSONException {\n-    int c;\n-    if (this.usePrevious) {\n-      this.usePrevious = false;\n-      c = this.previous;\n-    } else {\n-      try {\n-        c = this.reader.read();\n-      } catch (IOException exception) {\n-        throw new JSONException(exception);\n+  public String nextString(char quote) throws JSONException {\n+    /*\n+     * For strings that are free of escape sequences, we can just extract the result as a substring\n+     * of the input. But if we encounter an escape sequence, we need to use a StringBuilder to\n+     * compose the result.\n+     */\n+    StringBuilder builder = null;\n+\n+    /* the index of the first character not yet appended to the builder. */\n+    int start = pos;\n+\n+    while (pos < in.length()) {\n+      int c = in.charAt(pos++);\n+      if (c == quote) {\n+        if (builder == null) {\n+          // a new string avoids leaking memory\n+          // noinspection RedundantStringConstructorCall\n+          return new String(in.substring(start, pos - 1));\n+        } else {\n+          builder.append(in, start, pos - 1);\n+          return builder.toString();\n+        }\n       }\n \n-      if (c <= 0) { // End of stream\n-        this.eof = true;\n-        c = 0;\n+      if (c == '\\\\') {\n+        if (pos == in.length()) {\n+          throw syntaxError(\"Unterminated escape sequence\");\n+        }\n+        if (builder == null) {\n+          builder = new StringBuilder();\n+        }\n+        builder.append(in, start, pos - 1);\n+        builder.append(readEscapeCharacter());\n+        start = pos;\n       }\n     }\n-    this.index += 1;\n-    if (this.previous == '\\r') {\n-      this.line += 1;\n-      this.character = c == '\\n' ? 0 : 1;\n-    } else if (c == '\\n') {\n-      this.line += 1;\n-      this.character = 0;\n-    } else {\n-      this.character += 1;\n-    }\n-    this.previous = (char) c;\n-    return this.previous;\n-  }\n \n+    throw syntaxError(\"Unterminated string\");\n+  }\n \n   /**\n-   * Consume the next character, and check that it matches a specified character.\n-   * \n-   * @param c The character to match.\n-   * @return The character.\n-   * @throws JSONException if the character does not match.\n+   * Unescapes the character identified by the character or characters that immediately follow a\n+   * backslash. The backslash '\\' should have already been read. This supports both unicode escapes\n+   * \"u000A\" and two-character escapes \"\\n\".\n    */\n-  public char next(char c) throws JSONException {\n-    char n = this.next();\n-    if (n != c) {\n-      throw this.syntaxError(\"Expected '\" + c + \"' and instead saw '\" + n + \"'\");\n+  private char readEscapeCharacter() throws JSONException {\n+    char escaped = in.charAt(pos++);\n+    switch (escaped) {\n+      case 'u':\n+        if (pos + 4 > in.length()) {\n+          throw syntaxError(\"Unterminated escape sequence\");\n+        }\n+        String hex = in.substring(pos, pos + 4);\n+        pos += 4;\n+        try {\n+          return (char) Integer.parseInt(hex, 16);\n+        } catch (NumberFormatException nfe) {\n+          throw syntaxError(\"Invalid escape sequence: \" + hex);\n+        }\n+\n+      case 't':\n+        return '\\t';\n+\n+      case 'b':\n+        return '\\b';\n+\n+      case 'n':\n+        return '\\n';\n+\n+      case 'r':\n+        return '\\r';\n+\n+      case 'f':\n+        return '\\f';\n+\n+      case '\\'':\n+      case '\"':\n+      case '\\\\':\n+      default:\n+        return escaped;\n     }\n-    return n;\n   }\n \n-\n   /**\n-   * Get the next n characters.\n-   *\n-   * @param n The number of characters to take.\n-   * @return A string of n characters.\n-   * @throws JSONException Substring bounds error if there are not n characters remaining in the\n-   *         source string.\n+   * Reads a null, boolean, numeric or unquoted string literal value. Numeric values will be\n+   * returned as an Integer, Long, or Double, in that order of preference.\n    */\n-  public String next(int n) throws JSONException {\n-    if (n == 0) {\n-      return \"\";\n+  private Object readLiteral() throws JSONException {\n+    String literal = nextToInternal(\"{}[]/\\\\:,=;# \\t\\f\");\n+\n+    if (literal.length() == 0) {\n+      throw syntaxError(\"Expected literal value\");\n+    } else if (\"null\".equalsIgnoreCase(literal)) {\n+      return JSONObject.NULL;\n+    } else if (\"true\".equalsIgnoreCase(literal)) {\n+      return Boolean.TRUE;\n+    } else if (\"false\".equalsIgnoreCase(literal)) {\n+      return Boolean.FALSE;\n     }\n \n-    char[] chars = new char[n];\n-    int pos = 0;\n-\n-    while (pos < n) {\n-      chars[pos] = this.next();\n-      if (this.end()) {\n-        throw this.syntaxError(\"Substring bounds error\");\n+    /* try to parse as an integral type... */\n+    if (literal.indexOf('.') == -1) {\n+      int base = 10;\n+      String number = literal;\n+      if (number.startsWith(\"0x\") || number.startsWith(\"0X\")) {\n+        number = number.substring(2);\n+        base = 16;\n+      } else if (number.startsWith(\"0\") && number.length() > 1) {\n+        number = number.substring(1);\n+        base = 8;\n+      }\n+      try {\n+        long longValue = Long.parseLong(number, base);\n+        if (longValue <= Integer.MAX_VALUE && longValue >= Integer.MIN_VALUE) {\n+          return (int) longValue;\n+        } else {\n+          return longValue;\n+        }\n+      } catch (NumberFormatException e) {\n+        /*\n+         * This only happens for integral numbers greater than Long.MAX_VALUE, numbers in\n+         * exponential form (5e-10) and unquoted strings. Fall through to try floating point.\n+         */\n       }\n-      pos += 1;\n     }\n-    return new String(chars);\n-  }\n \n+    /* ...next try to parse as a floating point... */\n+    try {\n+      return Double.valueOf(literal);\n+    } catch (NumberFormatException ignored) {\n+    }\n+\n+    /* ... finally give up. We have an unquoted string */\n+    // noinspection RedundantStringConstructorCall\n+    return new String(literal); // a new string avoids leaking memory\n+  }\n \n   /**\n-   * Get the next char in the string, skipping whitespace.\n-   * \n-   * @throws JSONException\n-   * @return A character, or 0 if there are no more characters.\n+   * Returns the string up to but not including any of the given characters or a newline character.\n+   * This does not consume the excluded character.\n    */\n-  public char nextClean() throws JSONException {\n-    for (;;) {\n-      char c = this.next();\n-      if (c == 0 || c > ' ') {\n-        return c;\n+  private String nextToInternal(String excluded) {\n+    int start = pos;\n+    for (; pos < in.length(); pos++) {\n+      char c = in.charAt(pos);\n+      if (c == '\\r' || c == '\\n' || excluded.indexOf(c) != -1) {\n+        return in.substring(start, pos);\n       }\n     }\n+    return in.substring(start);\n   }\n \n-\n   /**\n-   * Return the characters up to the next close quote character. Backslash processing is done. The\n-   * formal JSON format does not allow strings in single quotes, but an implementation is allowed to\n-   * accept them.\n-   * \n-   * @param quote The quoting character, either <code>\"</code>&nbsp;<small>(double quote)</small> or\n-   *        <code>'</code>&nbsp;<small>(single quote)</small>.\n-   * @return A String.\n-   * @throws JSONException Unterminated string.\n+   * Reads a sequence of key/value pairs and the trailing closing brace '}' of an object. The\n+   * opening brace '{' should have already been read.\n    */\n-  public String nextString(char quote) throws JSONException {\n-    char c;\n-    StringBuffer sb = new StringBuffer();\n-    for (;;) {\n-      c = this.next();\n-      switch (c) {\n-        case 0:\n-        case '\\n':\n-        case '\\r':\n-          throw this.syntaxError(\"Unterminated string\");\n-        case '\\\\':\n-          c = this.next();\n-          switch (c) {\n-            case 'b':\n-              sb.append('\\b');\n-              break;\n-            case 't':\n-              sb.append('\\t');\n-              break;\n-            case 'n':\n-              sb.append('\\n');\n-              break;\n-            case 'f':\n-              sb.append('\\f');\n-              break;\n-            case 'r':\n-              sb.append('\\r');\n-              break;\n-            case 'u':\n-              sb.append((char) Integer.parseInt(this.next(4), 16));\n-              break;\n-            case '\"':\n-            case '\\'':\n-            case '\\\\':\n-            case '/':\n-              sb.append(c);\n-              break;\n-            default:\n-              throw this.syntaxError(\"Illegal escape.\");\n-          }\n-          break;\n+  private JSONObject readObject() throws JSONException {\n+    JSONObject result = new JSONObject();\n+\n+    /* Peek to see if this is the empty object. */\n+    int first = nextCleanInternal();\n+    if (first == '}') {\n+      return result;\n+    } else if (first != -1) {\n+      pos--;\n+    }\n+\n+    while (true) {\n+      Object name = nextValue();\n+      if (!(name instanceof String)) {\n+        if (name == null) {\n+          throw syntaxError(\"Names cannot be null\");\n+        } else {\n+          throw syntaxError(\n+              \"Names must be strings, but \" + name + \" is of type \" + name.getClass().getName());\n+        }\n+      }\n+\n+      /*\n+       * Expect the name/value separator to be either a colon ':', an equals sign '=', or an arrow\n+       * \"=>\". The last two are bogus but we include them because that's what the original\n+       * implementation did.\n+       */\n+      int separator = nextCleanInternal();\n+      if (separator != ':' && separator != '=') {\n+        throw syntaxError(\"Expected ':' after \" + name);\n+      }\n+      if (pos < in.length() && in.charAt(pos) == '>') {\n+        pos++;\n+      }\n+\n+      result.put((String) name, nextValue());\n+\n+      switch (nextCleanInternal()) {\n+        case '}':\n+          return result;\n+        case ';':\n+        case ',':\n+          continue;\n         default:\n-          if (c == quote) {\n-            return sb.toString();\n-          }\n-          sb.append(c);\n+          throw syntaxError(\"Unterminated object\");\n       }\n     }\n   }\n \n-\n   /**\n-   * Get the text up but not including the specified character or the end of line, whichever comes\n-   * first.\n-   * \n-   * @param delimiter A delimiter character.\n-   * @return A string.\n+   * Reads a sequence of values and the trailing closing brace ']' of an array. The opening brace\n+   * '[' should have already been read. Note that \"[]\" yields an empty array, but \"[,]\" returns a\n+   * two-element array equivalent to \"[null,null]\".\n    */\n-  public String nextTo(char delimiter) throws JSONException {\n-    StringBuffer sb = new StringBuffer();\n-    for (;;) {\n-      char c = this.next();\n-      if (c == delimiter || c == 0 || c == '\\n' || c == '\\r') {\n-        if (c != 0) {\n-          this.back();\n-        }\n-        return sb.toString().trim();\n+  private JSONArray readArray() throws JSONException {\n+    JSONArray result = new JSONArray();\n+\n+    /* to cover input that ends with \",]\". */\n+    boolean hasTrailingSeparator = false;\n+\n+    while (true) {\n+      switch (nextCleanInternal()) {\n+        case -1:\n+          throw syntaxError(\"Unterminated array\");\n+        case ']':\n+          if (hasTrailingSeparator) {\n+            result.put(null);\n+          }\n+          return result;\n+        case ',':\n+        case ';':\n+          /* A separator without a value first means \"null\". */\n+          result.put(null);\n+          hasTrailingSeparator = true;\n+          continue;\n+        default:\n+          pos--;\n+      }\n+\n+      result.put(nextValue());\n+\n+      switch (nextCleanInternal()) {\n+        case ']':\n+          return result;\n+        case ',':\n+        case ';':\n+          hasTrailingSeparator = true;\n+          continue;\n+        default:\n+          throw syntaxError(\"Unterminated array\");\n       }\n-      sb.append(c);\n     }\n   }\n \n+  /**\n+   * Returns an exception containing the given message plus the current position and the entire\n+   * input string.\n+   *\n+   * @param message The message we want to include.\n+   * @return An exception that we can throw.\n+   */\n+  public JSONException syntaxError(String message) {\n+    return new JSONException(message + this);\n+  }\n \n   /**\n-   * Get the text up but not including one of the specified delimiter characters or the end of line,\n-   * whichever comes first.\n-   * \n-   * @param delimiters A set of delimiter characters.\n-   * @return A string, trimmed.\n+   * Returns the current position and the entire input string.\n    */\n-  public String nextTo(String delimiters) throws JSONException {\n-    char c;\n-    StringBuffer sb = new StringBuffer();\n-    for (;;) {\n-      c = this.next();\n-      if (delimiters.indexOf(c) >= 0 || c == 0 || c == '\\n' || c == '\\r') {\n-        if (c != 0) {\n-          this.back();\n-        }\n-        return sb.toString().trim();\n-      }\n-      sb.append(c);\n-    }\n+  @Override\n+  public String toString() {\n+    // consistent with the original implementation\n+    return \" at character \" + pos + \" of \" + in;\n   }\n \n+  /*\n+   * Legacy APIs.\n+   *\n+   * None of the methods below are on the critical path of parsing JSON documents. They exist only\n+   * because they were exposed by the original implementation and may be used by some clients.\n+   */\n \n   /**\n-   * Get the next value. The value can be a Boolean, Double, Integer, JSONArray, JSONObject, Long,\n-   * or String, or the JSONObject.NULL object.\n-   * \n-   * @throws JSONException If syntax error.\n+   * Returns true until the input has been exhausted.\n    *\n-   * @return An object.\n+   * @return true if more input exists.\n    */\n-  public Object nextValue() throws JSONException {\n-    char c = this.nextClean();\n-    String string;\n-\n-    switch (c) {\n-      case '\"':\n-      case '\\'':\n-        return this.nextString(c);\n-      case '{':\n-        this.back();\n-        return new JSONObject(this);\n-      case '[':\n-        this.back();\n-        return new JSONArray(this);\n-    }\n+  public boolean more() {\n+    return pos < in.length();\n+  }\n \n-    /*\n-     * Handle unquoted text. This could be the values true, false, or null, or it can be a number.\n-     * An implementation (such as this one) is allowed to also accept non-standard forms.\n-     *\n-     * Accumulate characters until we reach the end of the text or a formatting character.\n-     */\n+  /**\n+   * Returns the next available character, or the null character '\\0' if all input has been\n+   * exhausted. The return value of this method is ambiguous for JSON strings that contain the\n+   * character '\\0'.\n+   *\n+   * @return the next character.\n+   */\n+  public char next() {\n+    return pos < in.length() ? in.charAt(pos++) : '\\0';\n+  }\n \n-    StringBuffer sb = new StringBuffer();\n-    while (c >= ' ' && \",:]}/\\\\\\\"[{;=#\".indexOf(c) < 0) {\n-      sb.append(c);\n-      c = this.next();\n+  /**\n+   * Returns the next available character if it equals {@code c}. Otherwise an exception is thrown.\n+   *\n+   * @param c The character we are looking for.\n+   * @return the next character.\n+   * @throws JSONException If the next character isn't {@code c}\n+   */\n+  public char next(char c) throws JSONException {\n+    char result = next();\n+    if (result != c) {\n+      throw syntaxError(\"Expected \" + c + \" but was \" + result);\n     }\n-    this.back();\n+    return result;\n+  }\n \n-    string = sb.toString().trim();\n-    if (\"\".equals(string)) {\n-      throw this.syntaxError(\"Missing value\");\n-    }\n-    return JSONObject.stringToValue(string);\n+  /**\n+   * Returns the next character that is not whitespace and does not belong to a comment. If the\n+   * input is exhausted before such a character can be found, the null character '\\0' is returned.\n+   * The return value of this method is ambiguous for JSON strings that contain the character '\\0'.\n+   *\n+   * @return The next non-whitespace character.\n+   * @throws JSONException Should not be possible.\n+   */\n+  public char nextClean() throws JSONException {\n+    int nextCleanInt = nextCleanInternal();\n+    return nextCleanInt == -1 ? '\\0' : (char) nextCleanInt;\n   }\n \n+  /**\n+   * Returns the next {@code length} characters of the input.\n+   *\n+   * <p>\n+   * The returned string shares its backing character array with this tokener's input string. If a\n+   * reference to the returned string may be held indefinitely, you should use\n+   * {@code new String(result)} to copy it first to avoid memory leaks.\n+   *\n+   * @param length The desired number of characters to return.\n+   * @return The next few characters.\n+   * @throws JSONException if the remaining input is not long enough to satisfy this request.\n+   */\n+  public String next(int length) throws JSONException {\n+    if (pos + length > in.length()) {\n+      throw syntaxError(length + \" is out of bounds\");\n+    }\n+    String result = in.substring(pos, pos + length);\n+    pos += length;\n+    return result;\n+  }\n \n   /**\n-   * Skip characters until the next character is the requested character. If the requested character\n-   * is not found, no characters are skipped.\n-   * \n-   * @param to A character to skip to.\n-   * @return The requested character, or zero if the requested character is not found.\n+   * Returns the {@link String#trim trimmed} string holding the characters up to but not including\n+   * the first of:\n+   * <ul>\n+   * <li>any character in {@code excluded}\n+   * <li>a newline character '\\n'\n+   * <li>a carriage return '\\r'\n+   * </ul>\n+   *\n+   * <p>\n+   * The returned string shares its backing character array with this tokener's input string. If a\n+   * reference to the returned string may be held indefinitely, you should use\n+   * {@code new String(result)} to copy it first to avoid memory leaks.\n+   *\n+   * @param excluded The limiting string where the search should stop.\n+   * @return a possibly-empty string\n    */\n-  public char skipTo(char to) throws JSONException {\n-    char c;\n-    try {\n-      long startIndex = this.index;\n-      long startCharacter = this.character;\n-      long startLine = this.line;\n-      this.reader.mark(1000000);\n-      do {\n-        c = this.next();\n-        if (c == 0) {\n-          this.reader.reset();\n-          this.index = startIndex;\n-          this.character = startCharacter;\n-          this.line = startLine;\n-          return c;\n-        }\n-      } while (c != to);\n-    } catch (IOException exc) {\n-      throw new JSONException(exc);\n+  public String nextTo(String excluded) {\n+    if (excluded == null) {\n+      throw new NullPointerException(\"excluded == null\");\n     }\n+    return nextToInternal(excluded).trim();\n+  }\n \n-    this.back();\n-    return c;\n+  /**\n+   * Equivalent to {@code nextTo(String.valueOf(excluded))}.\n+   *\n+   * @param excluded The limiting character.\n+   * @return a possibly-empty string\n+   */\n+  public String nextTo(char excluded) {\n+    return nextToInternal(String.valueOf(excluded)).trim();\n   }\n \n+  /**\n+   * Advances past all input up to and including the next occurrence of {@code thru}. If the\n+   * remaining input doesn't contain {@code thru}, the input is exhausted.\n+   *\n+   * @param thru The string to skip over.\n+   */\n+  public void skipPast(String thru) {\n+    int thruStart = in.indexOf(thru, pos);\n+    pos = thruStart == -1 ? in.length() : (thruStart + thru.length());\n+  }\n \n   /**\n-   * Make a JSONException to signal a syntax error.\n+   * Advances past all input up to but not including the next occurrence of {@code to}. If the\n+   * remaining input doesn't contain {@code to}, the input is unchanged.\n    *\n-   * @param message The error message.\n-   * @return A JSONException object, suitable for throwing\n+   * @param to The character we want to skip to.\n+   * @return The value of {@code to} or null.\n    */\n-  public JSONException syntaxError(String message) {\n-    return new JSONException(message + this.toString());\n+  public char skipTo(char to) {\n+    int index = in.indexOf(to, pos);\n+    if (index != -1) {\n+      pos = index;\n+      return to;\n+    } else {\n+      return '\\0';\n+    }\n   }\n \n+  /**\n+   * Unreads the most recent character of input. If no input characters have been read, the input is\n+   * unchanged.\n+   */\n+  public void back() {\n+    if (--pos == -1) {\n+      pos = 0;\n+    }\n+  }\n \n   /**\n-   * Make a printable string of this JSONTokener.\n+   * Returns the integer [0..15] value for the given hex character, or -1 for non-hex input.\n    *\n-   * @return \" at {index} [character {character} line {line}]\"\n+   * @param hex a character in the ranges [0-9], [A-F] or [a-f]. Any other character will yield a -1\n+   *        result.\n+   * @return The decoded integer.\n    */\n-  public String toString() {\n-    return \" at \" + this.index + \" [character \" + this.character + \" line \" + this.line + \"]\";\n+  public static int dehexchar(char hex) {\n+    if (hex >= '0' && hex <= '9') {\n+      return hex - '0';\n+    } else if (hex >= 'A' && hex <= 'F') {\n+      return hex - 'A' + 10;\n+    } else if (hex >= 'a' && hex <= 'f') {\n+      return hex - 'a' + 10;\n+    } else {\n+      return -1;\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/main/java/org/json/JSONTokener.java",
                "sha": "21c9fb07744b4b0d60b3b7c4fa28aee2d5c671f3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/JSONWriter.java",
                "changes": 321,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/JSONWriter.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 321,
                "filename": "geode-json/src/main/java/org/json/JSONWriter.java",
                "patch": "@@ -1,321 +0,0 @@\n-package org.json;\n-\n-import java.io.IOException;\n-import java.io.Writer;\n-\n-/*\n- * Copyright (c) 2006 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-/**\n- * JSONWriter provides a quick and convenient way of producing JSON text. The texts produced\n- * strictly conform to JSON syntax rules. No whitespace is added, so the results are ready for\n- * transmission or storage. Each instance of JSONWriter can produce one JSON text.\n- * <p>\n- * A JSONWriter instance provides a <code>value</code> method for appending values to the text, and\n- * a <code>key</code> method for adding keys before values in objects. There are <code>array</code>\n- * and <code>endArray</code> methods that make and bound array values, and <code>object</code> and\n- * <code>endObject</code> methods which make and bound object values. All of these methods return\n- * the JSONWriter instance, permitting a cascade style. For example,\n- * \n- * <pre>\n- * new JSONWriter(myWriter).object().key(\"JSON\").value(\"Hello, World!\").endObject();\n- * </pre>\n- * \n- * which writes\n- * \n- * <pre>\n- * {\"JSON\":\"Hello, World!\"}\n- * </pre>\n- * <p>\n- * The first method called must be <code>array</code> or <code>object</code>. There are no methods\n- * for adding commas or colons. JSONWriter adds them for you. Objects and arrays can be nested up to\n- * 20 levels deep.\n- * <p>\n- * This can sometimes be easier than using a JSONObject to build a string.\n- * \n- * @author JSON.org\n- * @version 2011-11-24\n- */\n-public class JSONWriter {\n-  private static final int maxdepth = 200;\n-\n-  /**\n-   * The comma flag determines if a comma should be output before the next value.\n-   */\n-  private boolean comma;\n-\n-  /**\n-   * The current mode. Values: 'a' (array), 'd' (done), 'i' (initial), 'k' (key), 'o' (object).\n-   */\n-  protected char mode;\n-\n-  /**\n-   * The object/array stack.\n-   */\n-  private final JSONObject stack[];\n-\n-  /**\n-   * The stack top index. A value of 0 indicates that the stack is empty.\n-   */\n-  private int top;\n-\n-  /**\n-   * The writer that will receive the output.\n-   */\n-  protected Writer writer;\n-\n-  /**\n-   * Make a fresh JSONWriter. It can be used to build one JSON text.\n-   */\n-  public JSONWriter(Writer w) {\n-    this.comma = false;\n-    this.mode = 'i';\n-    this.stack = new JSONObject[maxdepth];\n-    this.top = 0;\n-    this.writer = w;\n-  }\n-\n-  /**\n-   * Append a value.\n-   * \n-   * @param string A string value.\n-   * @return this\n-   * @throws JSONException If the value is out of sequence.\n-   */\n-  private JSONWriter append(String string) throws JSONException {\n-    if (string == null) {\n-      throw new JSONException(\"Null pointer\");\n-    }\n-    if (this.mode == 'o' || this.mode == 'a') {\n-      try {\n-        if (this.comma && this.mode == 'a') {\n-          this.writer.write(',');\n-        }\n-        this.writer.write(string);\n-      } catch (IOException e) {\n-        throw new JSONException(e);\n-      }\n-      if (this.mode == 'o') {\n-        this.mode = 'k';\n-      }\n-      this.comma = true;\n-      return this;\n-    }\n-    throw new JSONException(\"Value out of sequence.\");\n-  }\n-\n-  /**\n-   * Begin appending a new array. All values until the balancing <code>endArray</code> will be\n-   * appended to this array. The <code>endArray</code> method must be called to mark the array's\n-   * end.\n-   * \n-   * @return this\n-   * @throws JSONException If the nesting is too deep, or if the object is started in the wrong\n-   *         place (for example as a key or after the end of the outermost array or object).\n-   */\n-  public JSONWriter array() throws JSONException {\n-    if (this.mode == 'i' || this.mode == 'o' || this.mode == 'a') {\n-      this.push(null);\n-      this.append(\"[\");\n-      this.comma = false;\n-      return this;\n-    }\n-    throw new JSONException(\"Misplaced array.\");\n-  }\n-\n-  /**\n-   * End something.\n-   * \n-   * @param mode Mode\n-   * @param c Closing character\n-   * @return this\n-   * @throws JSONException If unbalanced.\n-   */\n-  private JSONWriter end(char mode, char c) throws JSONException {\n-    if (this.mode != mode) {\n-      throw new JSONException(mode == 'a' ? \"Misplaced endArray.\" : \"Misplaced endObject.\");\n-    }\n-    this.pop(mode);\n-    try {\n-      this.writer.write(c);\n-    } catch (IOException e) {\n-      throw new JSONException(e);\n-    }\n-    this.comma = true;\n-    return this;\n-  }\n-\n-  /**\n-   * End an array. This method most be called to balance calls to <code>array</code>.\n-   * \n-   * @return this\n-   * @throws JSONException If incorrectly nested.\n-   */\n-  public JSONWriter endArray() throws JSONException {\n-    return this.end('a', ']');\n-  }\n-\n-  /**\n-   * End an object. This method most be called to balance calls to <code>object</code>.\n-   * \n-   * @return this\n-   * @throws JSONException If incorrectly nested.\n-   */\n-  public JSONWriter endObject() throws JSONException {\n-    return this.end('k', '}');\n-  }\n-\n-  /**\n-   * Append a key. The key will be associated with the next value. In an object, every value must be\n-   * preceded by a key.\n-   * \n-   * @param string A key string.\n-   * @return this\n-   * @throws JSONException If the key is out of place. For example, keys do not belong in arrays or\n-   *         if the key is null.\n-   */\n-  public JSONWriter key(String string) throws JSONException {\n-    if (string == null) {\n-      throw new JSONException(\"Null key.\");\n-    }\n-    if (this.mode == 'k') {\n-      try {\n-        this.stack[this.top - 1].putOnce(string, Boolean.TRUE);\n-        if (this.comma) {\n-          this.writer.write(',');\n-        }\n-        this.writer.write(JSONObject.quote(string));\n-        this.writer.write(':');\n-        this.comma = false;\n-        this.mode = 'o';\n-        return this;\n-      } catch (IOException e) {\n-        throw new JSONException(e);\n-      }\n-    }\n-    throw new JSONException(\"Misplaced key.\");\n-  }\n-\n-\n-  /**\n-   * Begin appending a new object. All keys and values until the balancing <code>endObject</code>\n-   * will be appended to this object. The <code>endObject</code> method must be called to mark the\n-   * object's end.\n-   * \n-   * @return this\n-   * @throws JSONException If the nesting is too deep, or if the object is started in the wrong\n-   *         place (for example as a key or after the end of the outermost array or object).\n-   */\n-  public JSONWriter object() throws JSONException {\n-    if (this.mode == 'i') {\n-      this.mode = 'o';\n-    }\n-    if (this.mode == 'o' || this.mode == 'a') {\n-      this.append(\"{\");\n-      this.push(new JSONObject());\n-      this.comma = false;\n-      return this;\n-    }\n-    throw new JSONException(\"Misplaced object.\");\n-\n-  }\n-\n-\n-  /**\n-   * Pop an array or object scope.\n-   * \n-   * @param c The scope to close.\n-   * @throws JSONException If nesting is wrong.\n-   */\n-  private void pop(char c) throws JSONException {\n-    if (this.top <= 0) {\n-      throw new JSONException(\"Nesting error.\");\n-    }\n-    char m = this.stack[this.top - 1] == null ? 'a' : 'k';\n-    if (m != c) {\n-      throw new JSONException(\"Nesting error.\");\n-    }\n-    this.top -= 1;\n-    this.mode = this.top == 0 ? 'd' : this.stack[this.top - 1] == null ? 'a' : 'k';\n-  }\n-\n-  /**\n-   * Push an array or object scope.\n-   * \n-   * @param jo The scope to open.\n-   * @throws JSONException If nesting is too deep.\n-   */\n-  private void push(JSONObject jo) throws JSONException {\n-    if (this.top >= maxdepth) {\n-      throw new JSONException(\"Nesting too deep.\");\n-    }\n-    this.stack[this.top] = jo;\n-    this.mode = jo == null ? 'a' : 'k';\n-    this.top += 1;\n-  }\n-\n-\n-  /**\n-   * Append either the value <code>true</code> or the value <code>false</code>.\n-   * \n-   * @param b A boolean.\n-   * @return this\n-   * @throws JSONException\n-   */\n-  public JSONWriter value(boolean b) throws JSONException {\n-    return this.append(b ? \"true\" : \"false\");\n-  }\n-\n-  /**\n-   * Append a double value.\n-   * \n-   * @param d A double.\n-   * @return this\n-   * @throws JSONException If the number is not finite.\n-   */\n-  public JSONWriter value(double d) throws JSONException {\n-    return this.value(new Double(d));\n-  }\n-\n-  /**\n-   * Append a long value.\n-   * \n-   * @param l A long.\n-   * @return this\n-   * @throws JSONException\n-   */\n-  public JSONWriter value(long l) throws JSONException {\n-    return this.append(Long.toString(l));\n-  }\n-\n-\n-  /**\n-   * Append an object value.\n-   * \n-   * @param object The object to append. It can be null, or a Boolean, Number, String, JSONObject,\n-   *        or JSONArray, or an object that implements JSONString.\n-   * @return this\n-   * @throws JSONException If the value is out of sequence.\n-   */\n-  public JSONWriter value(Object object) throws JSONException {\n-    return this.append(JSONObject.valueToString(object));\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/JSONWriter.java",
                "sha": "7d4704b2150470796a8fb1e9c2142e68c34de9fa",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/XML.java",
                "changes": 504,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/XML.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 504,
                "filename": "geode-json/src/main/java/org/json/XML.java",
                "patch": "@@ -1,504 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-import java.util.Iterator;\n-\n-\n-/**\n- * This provides static methods to convert an XML text into a JSONObject, and to covert a JSONObject\n- * into an XML text.\n- * \n- * @author JSON.org\n- * @version 2011-02-11\n- */\n-public class XML {\n-\n-  /** The Character '&'. */\n-  public static final Character AMP = new Character('&');\n-\n-  /** The Character '''. */\n-  public static final Character APOS = new Character('\\'');\n-\n-  /** The Character '!'. */\n-  public static final Character BANG = new Character('!');\n-\n-  /** The Character '='. */\n-  public static final Character EQ = new Character('=');\n-\n-  /** The Character '>'. */\n-  public static final Character GT = new Character('>');\n-\n-  /** The Character '<'. */\n-  public static final Character LT = new Character('<');\n-\n-  /** The Character '?'. */\n-  public static final Character QUEST = new Character('?');\n-\n-  /** The Character '\"'. */\n-  public static final Character QUOT = new Character('\"');\n-\n-  /** The Character '/'. */\n-  public static final Character SLASH = new Character('/');\n-\n-  /**\n-   * Replace special characters with XML escapes:\n-   * \n-   * <pre>\n-   * &amp; <small>(ampersand)</small> is replaced by &amp;amp;\n-   * &lt; <small>(less than)</small> is replaced by &amp;lt;\n-   * &gt; <small>(greater than)</small> is replaced by &amp;gt;\n-   * &quot; <small>(double quote)</small> is replaced by &amp;quot;\n-   * </pre>\n-   * \n-   * @param string The string to be escaped.\n-   * @return The escaped string.\n-   */\n-  public static String escape(String string) {\n-    StringBuffer sb = new StringBuffer();\n-    for (int i = 0, length = string.length(); i < length; i++) {\n-      char c = string.charAt(i);\n-      switch (c) {\n-        case '&':\n-          sb.append(\"&amp;\");\n-          break;\n-        case '<':\n-          sb.append(\"&lt;\");\n-          break;\n-        case '>':\n-          sb.append(\"&gt;\");\n-          break;\n-        case '\"':\n-          sb.append(\"&quot;\");\n-          break;\n-        case '\\'':\n-          sb.append(\"&apos;\");\n-          break;\n-        default:\n-          sb.append(c);\n-      }\n-    }\n-    return sb.toString();\n-  }\n-\n-  /**\n-   * Throw an exception if the string contains whitespace. Whitespace is not allowed in tagNames and\n-   * attributes.\n-   * \n-   * @param string\n-   * @throws JSONException\n-   */\n-  public static void noSpace(String string) throws JSONException {\n-    int i, length = string.length();\n-    if (length == 0) {\n-      throw new JSONException(\"Empty string.\");\n-    }\n-    for (i = 0; i < length; i += 1) {\n-      if (Character.isWhitespace(string.charAt(i))) {\n-        throw new JSONException(\"'\" + string + \"' contains a space character.\");\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Scan the content following the named tag, attaching it to the context.\n-   * \n-   * @param x The XMLTokener containing the source string.\n-   * @param context The JSONObject that will include the new material.\n-   * @param name The tag name.\n-   * @return true if the close tag is processed.\n-   * @throws JSONException\n-   */\n-  private static boolean parse(XMLTokener x, JSONObject context, String name) throws JSONException {\n-    char c;\n-    int i;\n-    JSONObject jsonobject = null;\n-    String string;\n-    String tagName;\n-    Object token;\n-\n-    // Test for and skip past these forms:\n-    // <!-- ... -->\n-    // <! ... >\n-    // <![ ... ]]>\n-    // <? ... ?>\n-    // Report errors for these forms:\n-    // <>\n-    // <=\n-    // <<\n-\n-    token = x.nextToken();\n-\n-    // <!\n-\n-    if (token == BANG) {\n-      c = x.next();\n-      if (c == '-') {\n-        if (x.next() == '-') {\n-          x.skipPast(\"-->\");\n-          return false;\n-        }\n-        x.back();\n-      } else if (c == '[') {\n-        token = x.nextToken();\n-        if (\"CDATA\".equals(token)) {\n-          if (x.next() == '[') {\n-            string = x.nextCDATA();\n-            if (string.length() > 0) {\n-              context.accumulate(\"content\", string);\n-            }\n-            return false;\n-          }\n-        }\n-        throw x.syntaxError(\"Expected 'CDATA['\");\n-      }\n-      i = 1;\n-      do {\n-        token = x.nextMeta();\n-        if (token == null) {\n-          throw x.syntaxError(\"Missing '>' after '<!'.\");\n-        } else if (token == LT) {\n-          i += 1;\n-        } else if (token == GT) {\n-          i -= 1;\n-        }\n-      } while (i > 0);\n-      return false;\n-    } else if (token == QUEST) {\n-\n-      // <?\n-\n-      x.skipPast(\"?>\");\n-      return false;\n-    } else if (token == SLASH) {\n-\n-      // Close tag </\n-\n-      token = x.nextToken();\n-      if (name == null) {\n-        throw x.syntaxError(\"Mismatched close tag \" + token);\n-      }\n-      if (!token.equals(name)) {\n-        throw x.syntaxError(\"Mismatched \" + name + \" and \" + token);\n-      }\n-      if (x.nextToken() != GT) {\n-        throw x.syntaxError(\"Misshaped close tag\");\n-      }\n-      return true;\n-\n-    } else if (token instanceof Character) {\n-      throw x.syntaxError(\"Misshaped tag\");\n-\n-      // Open tag <\n-\n-    } else {\n-      tagName = (String) token;\n-      token = null;\n-      jsonobject = new JSONObject();\n-      for (;;) {\n-        if (token == null) {\n-          token = x.nextToken();\n-        }\n-\n-        // attribute = value\n-\n-        if (token instanceof String) {\n-          string = (String) token;\n-          token = x.nextToken();\n-          if (token == EQ) {\n-            token = x.nextToken();\n-            if (!(token instanceof String)) {\n-              throw x.syntaxError(\"Missing value\");\n-            }\n-            jsonobject.accumulate(string, XML.stringToValue((String) token));\n-            token = null;\n-          } else {\n-            jsonobject.accumulate(string, \"\");\n-          }\n-\n-          // Empty tag <.../>\n-\n-        } else if (token == SLASH) {\n-          if (x.nextToken() != GT) {\n-            throw x.syntaxError(\"Misshaped tag\");\n-          }\n-          if (jsonobject.length() > 0) {\n-            context.accumulate(tagName, jsonobject);\n-          } else {\n-            context.accumulate(tagName, \"\");\n-          }\n-          return false;\n-\n-          // Content, between <...> and </...>\n-\n-        } else if (token == GT) {\n-          for (;;) {\n-            token = x.nextContent();\n-            if (token == null) {\n-              if (tagName != null) {\n-                throw x.syntaxError(\"Unclosed tag \" + tagName);\n-              }\n-              return false;\n-            } else if (token instanceof String) {\n-              string = (String) token;\n-              if (string.length() > 0) {\n-                jsonobject.accumulate(\"content\", XML.stringToValue(string));\n-              }\n-\n-              // Nested element\n-\n-            } else if (token == LT) {\n-              if (parse(x, jsonobject, tagName)) {\n-                if (jsonobject.length() == 0) {\n-                  context.accumulate(tagName, \"\");\n-                } else if (jsonobject.length() == 1 && jsonobject.opt(\"content\") != null) {\n-                  context.accumulate(tagName, jsonobject.opt(\"content\"));\n-                } else {\n-                  context.accumulate(tagName, jsonobject);\n-                }\n-                return false;\n-              }\n-            }\n-          }\n-        } else {\n-          throw x.syntaxError(\"Misshaped tag\");\n-        }\n-      }\n-    }\n-  }\n-\n-\n-  /**\n-   * Try to convert a string into a number, boolean, or null. If the string can't be converted,\n-   * return the string. This is much less ambitious than JSONObject.stringToValue, especially\n-   * because it does not attempt to convert plus forms, octal forms, hex forms, or E forms lacking\n-   * decimal points.\n-   * \n-   * @param string A String.\n-   * @return A simple JSON value.\n-   */\n-  public static Object stringToValue(String string) {\n-    if (\"\".equals(string)) {\n-      return string;\n-    }\n-    if (\"true\".equalsIgnoreCase(string)) {\n-      return Boolean.TRUE;\n-    }\n-    if (\"false\".equalsIgnoreCase(string)) {\n-      return Boolean.FALSE;\n-    }\n-    if (\"null\".equalsIgnoreCase(string)) {\n-      return JSONObject.NULL;\n-    }\n-    if (\"0\".equals(string)) {\n-      return new Integer(0);\n-    }\n-\n-    // If it might be a number, try converting it. If that doesn't work,\n-    // return the string.\n-\n-    try {\n-      char initial = string.charAt(0);\n-      boolean negative = false;\n-      if (initial == '-') {\n-        initial = string.charAt(1);\n-        negative = true;\n-      }\n-      if (initial == '0' && string.charAt(negative ? 2 : 1) == '0') {\n-        return string;\n-      }\n-      if ((initial >= '0' && initial <= '9')) {\n-        if (string.indexOf('.') >= 0) {\n-          return Double.valueOf(string);\n-        } else if (string.indexOf('e') < 0 && string.indexOf('E') < 0) {\n-          Long myLong = new Long(string);\n-          if (myLong.longValue() == myLong.intValue()) {\n-            return new Integer(myLong.intValue());\n-          } else {\n-            return myLong;\n-          }\n-        }\n-      }\n-    } catch (Exception ignore) {\n-    }\n-    return string;\n-  }\n-\n-\n-  /**\n-   * Convert a well-formed (but not necessarily valid) XML string into a JSONObject. Some\n-   * information may be lost in this transformation because JSON is a data format and XML is a\n-   * document format. XML uses elements, attributes, and content text, while JSON uses unordered\n-   * collections of name/value pairs and arrays of values. JSON does not does not like to\n-   * distinguish between elements and attributes. Sequences of similar elements are represented as\n-   * JSONArrays. Content text may be placed in a \"content\" member. Comments, prologs, DTDs, and\n-   * <code>&lt;[ [ ]]></code> are ignored.\n-   * \n-   * @param string The source string.\n-   * @return A JSONObject containing the structured data from the XML string.\n-   * @throws JSONException\n-   */\n-  public static JSONObject toJSONObject(String string) throws JSONException {\n-    JSONObject jo = new JSONObject();\n-    XMLTokener x = new XMLTokener(string);\n-    while (x.more() && x.skipPast(\"<\")) {\n-      parse(x, jo, null);\n-    }\n-    return jo;\n-  }\n-\n-\n-  /**\n-   * Convert a JSONObject into a well-formed, element-normal XML string.\n-   * \n-   * @param object A JSONObject.\n-   * @return A string.\n-   * @throws JSONException\n-   */\n-  public static String toString(Object object) throws JSONException {\n-    return toString(object, null);\n-  }\n-\n-\n-  /**\n-   * Convert a JSONObject into a well-formed, element-normal XML string.\n-   * \n-   * @param object A JSONObject.\n-   * @param tagName The optional name of the enclosing tag.\n-   * @return A string.\n-   * @throws JSONException\n-   */\n-  public static String toString(Object object, String tagName) throws JSONException {\n-    StringBuffer sb = new StringBuffer();\n-    int i;\n-    JSONArray ja;\n-    JSONObject jo;\n-    String key;\n-    Iterator keys;\n-    int length;\n-    String string;\n-    Object value;\n-    if (object instanceof JSONObject) {\n-\n-      // Emit <tagName>\n-\n-      if (tagName != null) {\n-        sb.append('<');\n-        sb.append(tagName);\n-        sb.append('>');\n-      }\n-\n-      // Loop thru the keys.\n-\n-      jo = (JSONObject) object;\n-      keys = jo.keys();\n-      while (keys.hasNext()) {\n-        key = keys.next().toString();\n-        value = jo.opt(key);\n-        if (value == null) {\n-          value = \"\";\n-        }\n-        if (value instanceof String) {\n-          string = (String) value;\n-        } else {\n-          string = null;\n-        }\n-\n-        // Emit content in body\n-\n-        if (\"content\".equals(key)) {\n-          if (value instanceof JSONArray) {\n-            ja = (JSONArray) value;\n-            length = ja.length();\n-            for (i = 0; i < length; i += 1) {\n-              if (i > 0) {\n-                sb.append('\\n');\n-              }\n-              sb.append(escape(ja.get(i).toString()));\n-            }\n-          } else {\n-            sb.append(escape(value.toString()));\n-          }\n-\n-          // Emit an array of similar keys\n-\n-        } else if (value instanceof JSONArray) {\n-          ja = (JSONArray) value;\n-          length = ja.length();\n-          for (i = 0; i < length; i += 1) {\n-            value = ja.get(i);\n-            if (value instanceof JSONArray) {\n-              sb.append('<');\n-              sb.append(key);\n-              sb.append('>');\n-              sb.append(toString(value));\n-              sb.append(\"</\");\n-              sb.append(key);\n-              sb.append('>');\n-            } else {\n-              sb.append(toString(value, key));\n-            }\n-          }\n-        } else if (\"\".equals(value)) {\n-          sb.append('<');\n-          sb.append(key);\n-          sb.append(\"/>\");\n-\n-          // Emit a new tag <k>\n-\n-        } else {\n-          sb.append(toString(value, key));\n-        }\n-      }\n-      if (tagName != null) {\n-\n-        // Emit the </tagname> close tag\n-\n-        sb.append(\"</\");\n-        sb.append(tagName);\n-        sb.append('>');\n-      }\n-      return sb.toString();\n-\n-      // XML does not have good support for arrays. If an array appears in a place\n-      // where XML is lacking, synthesize an <array> element.\n-\n-    } else {\n-      if (object.getClass().isArray()) {\n-        object = new JSONArray(object);\n-      }\n-      if (object instanceof JSONArray) {\n-        ja = (JSONArray) object;\n-        length = ja.length();\n-        for (i = 0; i < length; i += 1) {\n-          sb.append(toString(ja.opt(i), tagName == null ? \"array\" : tagName));\n-        }\n-        return sb.toString();\n-      } else {\n-        string = (object == null) ? \"null\" : escape(object.toString());\n-        return (tagName == null) ? \"\\\"\" + string + \"\\\"\"\n-            : (string.length() == 0) ? \"<\" + tagName + \"/>\"\n-                : \"<\" + tagName + \">\" + string + \"</\" + tagName + \">\";\n-      }\n-    }\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/XML.java",
                "sha": "ae6d61a49a2fbb7cad77efae77a2106d15359a82",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/XMLTokener.java",
                "changes": 362,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/main/java/org/json/XMLTokener.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 362,
                "filename": "geode-json/src/main/java/org/json/XMLTokener.java",
                "patch": "@@ -1,362 +0,0 @@\n-package org.json;\n-\n-/*\n- * Copyright (c) 2002 JSON.org\n- * \n- * Permission is hereby granted, free of charge, to any person obtaining a copy of this software and\n- * associated documentation files (the \"Software\"), to deal in the Software without restriction,\n- * including without limitation the rights to use, copy, modify, merge, publish, distribute,\n- * sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\n- * furnished to do so, subject to the following conditions:\n- * \n- * The above copyright notice and this permission notice shall be included in all copies or\n- * substantial portions of the Software.\n- * \n- * The Software shall be used for Good, not Evil.\n- * \n- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\n- * NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n- * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n- */\n-\n-/**\n- * The XMLTokener extends the JSONTokener to provide additional methods for the parsing of XML\n- * texts.\n- * \n- * @author JSON.org\n- * @version 2010-12-24\n- */\n-public class XMLTokener extends JSONTokener {\n-\n-\n-  /**\n-   * The table of entity values. It initially contains Character values for amp, apos, gt, lt, quot.\n-   */\n-  public static final java.util.HashMap entity;\n-\n-  static {\n-    entity = new java.util.HashMap(8);\n-    entity.put(\"amp\", XML.AMP);\n-    entity.put(\"apos\", XML.APOS);\n-    entity.put(\"gt\", XML.GT);\n-    entity.put(\"lt\", XML.LT);\n-    entity.put(\"quot\", XML.QUOT);\n-  }\n-\n-  /**\n-   * Construct an XMLTokener from a string.\n-   * \n-   * @param s A source string.\n-   */\n-  public XMLTokener(String s) {\n-    super(s);\n-  }\n-\n-  /**\n-   * Get the text in the CDATA block.\n-   * \n-   * @return The string up to the <code>]]&gt;</code>.\n-   * @throws JSONException If the <code>]]&gt;</code> is not found.\n-   */\n-  public String nextCDATA() throws JSONException {\n-    char c;\n-    int i;\n-    StringBuffer sb = new StringBuffer();\n-    for (;;) {\n-      c = next();\n-      if (end()) {\n-        throw syntaxError(\"Unclosed CDATA\");\n-      }\n-      sb.append(c);\n-      i = sb.length() - 3;\n-      if (i >= 0 && sb.charAt(i) == ']' && sb.charAt(i + 1) == ']' && sb.charAt(i + 2) == '>') {\n-        sb.setLength(i);\n-        return sb.toString();\n-      }\n-    }\n-  }\n-\n-\n-  /**\n-   * Get the next XML outer token, trimming whitespace. There are two kinds of tokens: the '<'\n-   * character which begins a markup tag, and the content text between markup tags.\n-   *\n-   * @return A string, or a '<' Character, or null if there is no more source text.\n-   * @throws JSONException\n-   */\n-  public Object nextContent() throws JSONException {\n-    char c;\n-    StringBuffer sb;\n-    do {\n-      c = next();\n-    } while (Character.isWhitespace(c));\n-    if (c == 0) {\n-      return null;\n-    }\n-    if (c == '<') {\n-      return XML.LT;\n-    }\n-    sb = new StringBuffer();\n-    for (;;) {\n-      if (c == '<' || c == 0) {\n-        back();\n-        return sb.toString().trim();\n-      }\n-      if (c == '&') {\n-        sb.append(nextEntity(c));\n-      } else {\n-        sb.append(c);\n-      }\n-      c = next();\n-    }\n-  }\n-\n-\n-  /**\n-   * Return the next entity. These entities are translated to Characters:\n-   * <code>&amp;  &apos;  &gt;  &lt;  &quot;</code>.\n-   * \n-   * @param ampersand An ampersand character.\n-   * @return A Character or an entity String if the entity is not recognized.\n-   * @throws JSONException If missing ';' in XML entity.\n-   */\n-  public Object nextEntity(char ampersand) throws JSONException {\n-    StringBuffer sb = new StringBuffer();\n-    for (;;) {\n-      char c = next();\n-      if (Character.isLetterOrDigit(c) || c == '#') {\n-        sb.append(Character.toLowerCase(c));\n-      } else if (c == ';') {\n-        break;\n-      } else {\n-        throw syntaxError(\"Missing ';' in XML entity: &\" + sb);\n-      }\n-    }\n-    String string = sb.toString();\n-    Object object = entity.get(string);\n-    return object != null ? object : ampersand + string + \";\";\n-  }\n-\n-\n-  /**\n-   * Returns the next XML meta token. This is used for skipping over <!...> and <?...?> structures.\n-   * \n-   * @return Syntax characters (<code>< > / = ! ?</code>) are returned as Character, and strings and\n-   *         names are returned as Boolean. We don't care what the values actually are.\n-   * @throws JSONException If a string is not properly closed or if the XML is badly structured.\n-   */\n-  public Object nextMeta() throws JSONException {\n-    char c;\n-    char q;\n-    do {\n-      c = next();\n-    } while (Character.isWhitespace(c));\n-    switch (c) {\n-      case 0:\n-        throw syntaxError(\"Misshaped meta tag\");\n-      case '<':\n-        return XML.LT;\n-      case '>':\n-        return XML.GT;\n-      case '/':\n-        return XML.SLASH;\n-      case '=':\n-        return XML.EQ;\n-      case '!':\n-        return XML.BANG;\n-      case '?':\n-        return XML.QUEST;\n-      case '\"':\n-      case '\\'':\n-        q = c;\n-        for (;;) {\n-          c = next();\n-          if (c == 0) {\n-            throw syntaxError(\"Unterminated string\");\n-          }\n-          if (c == q) {\n-            return Boolean.TRUE;\n-          }\n-        }\n-      default:\n-        for (;;) {\n-          c = next();\n-          if (Character.isWhitespace(c)) {\n-            return Boolean.TRUE;\n-          }\n-          switch (c) {\n-            case 0:\n-            case '<':\n-            case '>':\n-            case '/':\n-            case '=':\n-            case '!':\n-            case '?':\n-            case '\"':\n-            case '\\'':\n-              back();\n-              return Boolean.TRUE;\n-          }\n-        }\n-    }\n-  }\n-\n-\n-  /**\n-   * Get the next XML Token. These tokens are found inside of angle brackets. It may be one of these\n-   * characters: <code>/ > = ! ?</code> or it may be a string wrapped in single quotes or double\n-   * quotes, or it may be a name.\n-   * \n-   * @return a String or a Character.\n-   * @throws JSONException If the XML is not well formed.\n-   */\n-  public Object nextToken() throws JSONException {\n-    char c;\n-    char q;\n-    StringBuffer sb;\n-    do {\n-      c = next();\n-    } while (Character.isWhitespace(c));\n-    switch (c) {\n-      case 0:\n-        throw syntaxError(\"Misshaped element\");\n-      case '<':\n-        throw syntaxError(\"Misplaced '<'\");\n-      case '>':\n-        return XML.GT;\n-      case '/':\n-        return XML.SLASH;\n-      case '=':\n-        return XML.EQ;\n-      case '!':\n-        return XML.BANG;\n-      case '?':\n-        return XML.QUEST;\n-\n-      // Quoted string\n-\n-      case '\"':\n-      case '\\'':\n-        q = c;\n-        sb = new StringBuffer();\n-        for (;;) {\n-          c = next();\n-          if (c == 0) {\n-            throw syntaxError(\"Unterminated string\");\n-          }\n-          if (c == q) {\n-            return sb.toString();\n-          }\n-          if (c == '&') {\n-            sb.append(nextEntity(c));\n-          } else {\n-            sb.append(c);\n-          }\n-        }\n-      default:\n-\n-        // Name\n-\n-        sb = new StringBuffer();\n-        for (;;) {\n-          sb.append(c);\n-          c = next();\n-          if (Character.isWhitespace(c)) {\n-            return sb.toString();\n-          }\n-          switch (c) {\n-            case 0:\n-              return sb.toString();\n-            case '>':\n-            case '/':\n-            case '=':\n-            case '!':\n-            case '?':\n-            case '[':\n-            case ']':\n-              back();\n-              return sb.toString();\n-            case '<':\n-            case '\"':\n-            case '\\'':\n-              throw syntaxError(\"Bad character in a name\");\n-          }\n-        }\n-    }\n-  }\n-\n-\n-  /**\n-   * Skip characters until past the requested string. If it is not found, we are left at the end of\n-   * the source with a result of false.\n-   * \n-   * @param to A string to skip past.\n-   * @throws JSONException\n-   */\n-  public boolean skipPast(String to) throws JSONException {\n-    boolean b;\n-    char c;\n-    int i;\n-    int j;\n-    int offset = 0;\n-    int length = to.length();\n-    char[] circle = new char[length];\n-\n-    /*\n-     * First fill the circle buffer with as many characters as are in the to string. If we reach an\n-     * early end, bail.\n-     */\n-\n-    for (i = 0; i < length; i += 1) {\n-      c = next();\n-      if (c == 0) {\n-        return false;\n-      }\n-      circle[i] = c;\n-    }\n-    /*\n-     * We will loop, possibly for all of the remaining characters.\n-     */\n-    for (;;) {\n-      j = offset;\n-      b = true;\n-      /*\n-       * Compare the circle buffer with the to string.\n-       */\n-      for (i = 0; i < length; i += 1) {\n-        if (circle[j] != to.charAt(i)) {\n-          b = false;\n-          break;\n-        }\n-        j += 1;\n-        if (j >= length) {\n-          j -= length;\n-        }\n-      }\n-      /*\n-       * If we exit the loop with b intact, then victory is ours.\n-       */\n-      if (b) {\n-        return true;\n-      }\n-      /*\n-       * Get the next character. If there isn't one, then defeat is ours.\n-       */\n-      c = next();\n-      if (c == 0) {\n-        return false;\n-      }\n-      /*\n-       * Shove the character in the circle buffer and advance the circle offset. The offset is mod\n-       * n.\n-       */\n-      circle[offset] = c;\n-      offset += 1;\n-      if (offset >= length) {\n-        offset -= length;\n-      }\n-    }\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-json/src/main/java/org/json/XMLTokener.java",
                "sha": "f56a1f6a51fff610343aae8dd61ec1d7c6a758c1",
                "status": "removed"
            },
            {
                "additions": 227,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/test/resources/sample-01.json",
                "changes": 227,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-json/src/test/resources/sample-01.json?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-json/src/test/resources/sample-01.json",
                "patch": "@@ -0,0 +1,227 @@\n+[\n+  {\n+    \"_id\": \"58309f3bd307b72ae49a9b23\",\n+    \"index\": 0,\n+    \"guid\": \"5764ebd8-b333-469e-8d83-4eb5658f1566\",\n+    \"isActive\": true,\n+    \"balance\": \"$1,099.93\",\n+    \"picture\": \"http://placehold.it/32x32\",\n+    \"age\": 37,\n+    \"eyeColor\": \"blue\",\n+    \"name\": \"Barrera Wilkerson\",\n+    \"gender\": \"male\",\n+    \"company\": \"VURBO\",\n+    \"email\": \"barrerawilkerson@vurbo.com\",\n+    \"phone\": \"+1 (817) 429-2473\",\n+    \"address\": \"522 Vanderveer Street, Detroit, Wyoming, 4320\",\n+    \"about\": \"Et officia aute ullamco magna adipisicing non ut cupidatat cupidatat aliquip. Tempor occaecat ex ad dolore aliquip mollit ea esse ipsum. Est incididunt sunt commodo duis est. Reprehenderit in ut reprehenderit ad culpa ea fugiat et est adipisicing aliquip. Id mollit voluptate qui pariatur officia.\\r\\n\",\n+    \"registered\": \"2016-06-29T08:54:14 +07:00\",\n+    \"latitude\": -87.548434,\n+    \"longitude\": 64.251242,\n+    \"tags\": [\n+      \"aliqua\",\n+      \"ex\",\n+      \"sit\",\n+      \"magna\",\n+      \"dolor\",\n+      \"laborum\",\n+      \"non\"\n+    ],\n+    \"friends\": [\n+      {\n+        \"id\": 0,\n+        \"name\": \"Byers Pratt\"\n+      },\n+      {\n+        \"id\": 1,\n+        \"name\": \"Kennedy Contreras\"\n+      },\n+      {\n+        \"id\": 2,\n+        \"name\": \"Frazier Monroe\"\n+      }\n+    ],\n+    \"greeting\": \"Hello, Barrera Wilkerson! You have 3 unread messages.\",\n+    \"favoriteFruit\": \"banana\"\n+  },\n+  {\n+    \"_id\": \"58309f3b1f506440093a41d1\",\n+    \"index\": 1,\n+    \"guid\": \"de1a6cc9-f8b3-426e-b68a-cc30e1fff3c1\",\n+    \"isActive\": false,\n+    \"balance\": \"$3,397.60\",\n+    \"picture\": \"http://placehold.it/32x32\",\n+    \"age\": 32,\n+    \"eyeColor\": \"blue\",\n+    \"name\": \"Trisha Morris\",\n+    \"gender\": \"female\",\n+    \"company\": \"AMTAP\",\n+    \"email\": \"trishamorris@amtap.com\",\n+    \"phone\": \"+1 (805) 423-3375\",\n+    \"address\": \"495 Tampa Court, Libertytown, New Hampshire, 5177\",\n+    \"about\": \"Elit culpa Lorem dolor sit laborum ut ullamco ullamco nostrud reprehenderit adipisicing eiusmod. Aliqua quis dolor esse sint. Dolore in excepteur laborum anim ut consectetur. Nisi officia est eu ex ex id. Ipsum duis ullamco ad ut labore dolor. In amet tempor deserunt ullamco velit eu fugiat.\\r\\n\",\n+    \"registered\": \"2015-02-08T06:14:19 +08:00\",\n+    \"latitude\": -81.956277,\n+    \"longitude\": 143.685584,\n+    \"tags\": [\n+      \"cillum\",\n+      \"ullamco\",\n+      \"magna\",\n+      \"cillum\",\n+      \"voluptate\",\n+      \"magna\",\n+      \"exercitation\"\n+    ],\n+    \"friends\": [\n+      {\n+        \"id\": 0,\n+        \"name\": \"Fuentes Stout\"\n+      },\n+      {\n+        \"id\": 1,\n+        \"name\": \"Violet Vargas\"\n+      },\n+      {\n+        \"id\": 2,\n+        \"name\": \"Schmidt Wilder\"\n+      }\n+    ],\n+    \"greeting\": \"Hello, Trisha Morris! You have 4 unread messages.\",\n+    \"favoriteFruit\": \"strawberry\"\n+  },\n+  {\n+    \"_id\": \"58309f3beaef2f31339b3755\",\n+    \"index\": 2,\n+    \"guid\": \"0bf387b7-abc2-4828-becc-1269928f7c3d\",\n+    \"isActive\": false,\n+    \"balance\": \"$1,520.64\",\n+    \"picture\": \"http://placehold.it/32x32\",\n+    \"age\": 37,\n+    \"eyeColor\": \"blue\",\n+    \"name\": \"Deanna Santiago\",\n+    \"gender\": \"female\",\n+    \"company\": \"MEGALL\",\n+    \"email\": \"deannasantiago@megall.com\",\n+    \"phone\": \"+1 (916) 511-2291\",\n+    \"address\": \"919 Fayette Street, Homestead, Utah, 8669\",\n+    \"about\": \"Sit amet ex quis velit irure Lorem non quis aliquip dolor pariatur nulla Lorem officia. Deserunt officia sit velit labore sint nostrud elit aliquip labore ullamco consectetur id amet. Ullamco duis commodo sit incididunt. Fugiat consectetur ad incididunt officia. Sint cillum minim laborum laboris id cillum est exercitation in eiusmod qui.\\r\\n\",\n+    \"registered\": \"2015-11-18T08:39:28 +08:00\",\n+    \"latitude\": 79.105701,\n+    \"longitude\": -146.901754,\n+    \"tags\": [\n+      \"non\",\n+      \"ullamco\",\n+      \"cillum\",\n+      \"ipsum\",\n+      \"amet\",\n+      \"aliqua\",\n+      \"aliquip\"\n+    ],\n+    \"friends\": [\n+      {\n+        \"id\": 0,\n+        \"name\": \"Hanson Anderson\"\n+      },\n+      {\n+        \"id\": 1,\n+        \"name\": \"Pollard Soto\"\n+      },\n+      {\n+        \"id\": 2,\n+        \"name\": \"Barlow Campbell\"\n+      }\n+    ],\n+    \"greeting\": \"Hello, Deanna Santiago! You have 7 unread messages.\",\n+    \"favoriteFruit\": \"apple\"\n+  },\n+  {\n+    \"_id\": \"58309f3b49a68ad01346f27f\",\n+    \"index\": 3,\n+    \"guid\": \"d29c0dcc-48fb-4ca4-a63b-b47c0e6d6398\",\n+    \"isActive\": false,\n+    \"balance\": \"$2,069.96\",\n+    \"picture\": \"http://placehold.it/32x32\",\n+    \"age\": 29,\n+    \"eyeColor\": \"green\",\n+    \"name\": \"Brooks Gates\",\n+    \"gender\": \"male\",\n+    \"company\": \"TERRAGEN\",\n+    \"email\": \"brooksgates@terragen.com\",\n+    \"phone\": \"+1 (875) 483-2224\",\n+    \"address\": \"562 Noll Street, Kipp, Louisiana, 7659\",\n+    \"about\": \"Reprehenderit laboris mollit nulla commodo quis laborum commodo. Laborum aliquip laboris officia minim ipsum laborum ipsum reprehenderit quis laboris est sint culpa. Culpa magna aute mollit exercitation.\\r\\n\",\n+    \"registered\": \"2016-05-04T10:34:38 +07:00\",\n+    \"latitude\": 72.77079,\n+    \"longitude\": -134.291768,\n+    \"tags\": [\n+      \"est\",\n+      \"sunt\",\n+      \"laboris\",\n+      \"ea\",\n+      \"proident\",\n+      \"aute\",\n+      \"excepteur\"\n+    ],\n+    \"friends\": [\n+      {\n+        \"id\": 0,\n+        \"name\": \"Roxanne Morgan\"\n+      },\n+      {\n+        \"id\": 1,\n+        \"name\": \"Tamara Kelly\"\n+      },\n+      {\n+        \"id\": 2,\n+        \"name\": \"Cleveland Bush\"\n+      }\n+    ],\n+    \"greeting\": \"Hello, Brooks Gates! You have 1 unread messages.\",\n+    \"favoriteFruit\": \"banana\"\n+  },\n+  {\n+    \"_id\": \"58309f3be746700e9af9a645\",\n+    \"index\": 4,\n+    \"guid\": \"54382bd6-c476-469d-9e1c-e546f959db51\",\n+    \"isActive\": true,\n+    \"balance\": \"$2,012.57\",\n+    \"picture\": \"http://placehold.it/32x32\",\n+    \"age\": 40,\n+    \"eyeColor\": \"brown\",\n+    \"name\": \"Jackie Thomas\",\n+    \"gender\": \"female\",\n+    \"company\": \"HINWAY\",\n+    \"email\": \"jackiethomas@hinway.com\",\n+    \"phone\": \"+1 (843) 470-2096\",\n+    \"address\": \"910 Emerson Place, Gwynn, Federated States Of Micronesia, 4688\",\n+    \"about\": \"Id cupidatat laboris elit est eiusmod esse nostrud. Ex commodo nisi voluptate est nisi laborum officia sint incididunt pariatur qui deserunt ullamco. Fugiat proident magna ipsum sit sint id adipisicing sit nostrud labore sit officia. Eiusmod exercitation non enim excepteur amet irure ullamco consectetur cupidatat proident Lorem reprehenderit aliquip. Veniam esse dolor Lorem incididunt proident officia enim in incididunt culpa. Mollit voluptate commodo aliquip anim ipsum nostrud ut labore enim labore qui do minim incididunt. Quis irure proident voluptate nisi qui sunt aute duis irure.\\r\\n\",\n+    \"registered\": \"2014-08-03T09:21:43 +07:00\",\n+    \"latitude\": 84.871256,\n+    \"longitude\": 2.043339,\n+    \"tags\": [\n+      \"tempor\",\n+      \"ut\",\n+      \"deserunt\",\n+      \"esse\",\n+      \"nostrud\",\n+      \"dolore\",\n+      \"ex\"\n+    ],\n+    \"friends\": [\n+      {\n+        \"id\": 0,\n+        \"name\": \"Lois Walters\"\n+      },\n+      {\n+        \"id\": 1,\n+        \"name\": \"Brewer Buchanan\"\n+      },\n+      {\n+        \"id\": 2,\n+        \"name\": \"Mccormick Fleming\"\n+      }\n+    ],\n+    \"greeting\": \"Hello, Jackie Thomas! You have 2 unread messages.\",\n+    \"favoriteFruit\": \"banana\"\n+  }\n+]\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-json/src/test/resources/sample-01.json",
                "sha": "9cfef12500c50740b547db136c466539868ff719",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQuery.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQuery.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQuery.java",
                "patch": "@@ -57,9 +57,4 @@\n    */\n   public int getLimit();\n \n-  /**\n-   * Get projected fields setting of current query.\n-   */\n-  public String[] getProjectedFieldNames();\n-\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQuery.java",
                "sha": "1afb35a7ab478006eddf21ffe62edda1434f6158",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQueryFactory.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQueryFactory.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 11,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQueryFactory.java",
                "patch": "@@ -57,17 +57,6 @@\n    */\n   LuceneQueryFactory setResultLimit(int limit);\n \n-  /**\n-   * Set a list of fields for result projection.\n-   * \n-   * @param fieldNames\n-   * @return itself\n-   * \n-   * @deprecated TODO This feature is not yet implemented\n-   */\n-  @Deprecated\n-  LuceneQueryFactory setProjectionFields(String... fieldNames);\n-\n   /**\n    * Create wrapper object for lucene's QueryParser object using default standard analyzer. The\n    * queryString is using lucene QueryParser's syntax. QueryParser is for easy-to-use with human",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneQueryFactory.java",
                "sha": "174e7e15c75cc23dcdea2d72e821304535b0b727",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneResultStruct.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneResultStruct.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 8,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneResultStruct.java",
                "patch": "@@ -23,14 +23,6 @@\n  */\n @Experimental\n public interface LuceneResultStruct<K, V> {\n-  /**\n-   * Return the value associated with the given field name\n-   *\n-   * @param fieldName the String name of the field\n-   * @return the value associated with the specified field\n-   * @throws IllegalArgumentException If this struct does not have a field named fieldName\n-   */\n-  public Object getProjectedField(String fieldName);\n \n   /**\n    * Return key of the entry",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneResultStruct.java",
                "sha": "b922185a00d6087f5aff4e4f44a5e1d3ebb7a3b9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneService.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneService.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 10,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneService.java",
                "patch": "@@ -101,12 +101,18 @@ public void createIndex(String indexName, String regionPath,\n \n   /**\n    * Destroy the lucene index\n-   * \n-   * @param index index object\n-   * @deprecated TODO This feature is not yet implemented\n+   *\n+   * @param indexName the name of the index to destroy\n+   * @param regionPath the path of the region whose index to destroy\n+   */\n+  public void destroyIndex(String indexName, String regionPath);\n+\n+  /**\n+   * Destroy all the lucene indexes for the region\n+   *\n+   * @param regionPath The path of the region on which to destroy the indexes\n    */\n-  @Deprecated\n-  public void destroyIndex(LuceneIndex index);\n+  public void destroyIndexes(String regionPath);\n \n   /**\n    * Get the lucene index object specified by region name and index name\n@@ -131,17 +137,13 @@ public void createIndex(String indexName, String regionPath,\n    */\n   public LuceneQueryFactory createLuceneQueryFactory();\n \n-  /*\n+  /**\n    * wait until the current entries in cache are indexed\n    * \n    * @param indexName index name\n-   * \n    * @param regionPath region name\n-   * \n    * @param timeout max wait time\n-   * \n    * @param unit granularity of the timeout\n-   *\n    * @return if entries are flushed within timeout\n    */\n   public boolean waitUntilFlushed(String indexName, String regionPath, long timeout, TimeUnit unit)",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/LuceneService.java",
                "sha": "5cfae597dfda7eb4f76c7cb17d594955572ba86e",
                "status": "modified"
            },
            {
                "additions": 109,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/DestroyLuceneIndexMessage.java",
                "changes": 109,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/DestroyLuceneIndexMessage.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/DestroyLuceneIndexMessage.java",
                "patch": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal;\n+\n+import org.apache.geode.DataSerializer;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.lucene.LuceneServiceProvider;\n+import org.apache.geode.distributed.internal.*;\n+import org.apache.geode.internal.cache.GemFireCacheImpl;\n+import org.apache.geode.internal.logging.LogService;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Collection;\n+\n+public class DestroyLuceneIndexMessage extends PooledDistributionMessage\n+    implements MessageWithReply {\n+\n+  private int processorId;\n+\n+  private String regionPath;\n+\n+  private String indexName;\n+\n+  private static final Logger logger = LogService.getLogger();\n+\n+  /* For serialization */\n+  public DestroyLuceneIndexMessage() {}\n+\n+  protected DestroyLuceneIndexMessage(Collection recipients, int processorId, String regionPath,\n+      String indexName) {\n+    super();\n+    setRecipients(recipients);\n+    this.processorId = processorId;\n+    this.regionPath = regionPath;\n+    this.indexName = indexName;\n+  }\n+\n+  @Override\n+  protected void process(DistributionManager dm) {\n+    ReplyException replyException = null;\n+    try {\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"DestroyLuceneIndexMessage: Destroying regionPath=\" + this.regionPath\n+            + \"; indexName=\" + this.indexName);\n+      }\n+      try {\n+        Cache cache = GemFireCacheImpl.getInstance();\n+        LuceneServiceImpl impl = (LuceneServiceImpl) LuceneServiceProvider.get(cache);\n+        impl.destroyIndex(this.indexName, this.regionPath, false);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"DestroyLuceneIndexMessage: Destroyed regionPath=\" + this.regionPath\n+              + \"; indexName=\" + this.indexName);\n+        }\n+      } catch (Throwable e) {\n+        replyException = new ReplyException(e);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\n+              \"DestroyLuceneIndexMessage: Caught the following exception attempting to destroy indexName=\"\n+                  + this.indexName + \"; regionPath=\" + this.regionPath + \":\",\n+              e);\n+        }\n+      }\n+    } finally {\n+      ReplyMessage replyMsg = new ReplyMessage();\n+      replyMsg.setRecipient(getSender());\n+      replyMsg.setProcessorId(this.processorId);\n+      if (replyException != null) {\n+        replyMsg.setException(replyException);\n+      }\n+      dm.putOutgoing(replyMsg);\n+    }\n+  }\n+\n+  @Override\n+  public int getDSFID() {\n+    return DESTROY_LUCENE_INDEX_MESSAGE;\n+  }\n+\n+  @Override\n+  public void toData(DataOutput out) throws IOException {\n+    super.toData(out);\n+    out.writeInt(this.processorId);\n+    DataSerializer.writeString(this.regionPath, out);\n+    DataSerializer.writeString(this.indexName, out);\n+  }\n+\n+  @Override\n+  public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n+    super.fromData(in);\n+    this.processorId = in.readInt();\n+    this.regionPath = DataSerializer.readString(in);\n+    this.indexName = DataSerializer.readString(in);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/DestroyLuceneIndexMessage.java",
                "sha": "8bdef9bbef1a413b034706593bca66f2764ed36e",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/InternalLuceneIndex.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/InternalLuceneIndex.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/InternalLuceneIndex.java",
                "patch": "@@ -27,4 +27,9 @@\n    */\n   public void dumpFiles(String directory);\n \n+  /**\n+   * Destroy the index\n+   */\n+  public void destroy(boolean initiator);\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/InternalLuceneIndex.java",
                "sha": "c28fcdccf271d9eaa9ee55cc4a932fe443e121c8",
                "status": "modified"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneEventListener.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneEventListener.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneEventListener.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.util.List;\n import java.util.Set;\n \n+import org.apache.geode.internal.cache.wan.parallel.ParallelGatewaySenderQueue;\n import org.apache.logging.log4j.Logger;\n import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.InternalGemFireError;\n@@ -43,6 +44,10 @@\n  * An Async event queue listener that writes all of the events in batches to Lucene\n  */\n public class LuceneEventListener implements AsyncEventListener {\n+\n+  private static LuceneExceptionObserver exceptionObserver = exception -> {\n+  };\n+\n   Logger logger = LogService.getLogger();\n \n   private final RepositoryManager repositoryManager;\n@@ -56,6 +61,19 @@ public void close() {}\n \n   @Override\n   public boolean processEvents(List<AsyncEvent> events) {\n+    try {\n+      return process(events);\n+    } catch (RuntimeException e) {\n+      exceptionObserver.onException(e);\n+      throw e;\n+    } catch (Error e) {\n+      exceptionObserver.onException(e);\n+      throw e;\n+    }\n+\n+  }\n+\n+  protected boolean process(final List<AsyncEvent> events) {\n     // Try to get a PDX instance if possible, rather than a deserialized object\n     DefaultQuery.setPdxReadSerialized(true);\n \n@@ -92,17 +110,29 @@ public boolean processEvents(List<AsyncEvent> events) {\n     } catch (BucketNotFoundException | RegionDestroyedException | PrimaryBucketException e) {\n       logger.debug(\"Bucket not found while saving to lucene index: \" + e.getMessage(), e);\n       return false;\n-    } catch (IOException e) {\n-      logger.debug(\"Unable to save to lucene index\", e);\n-      return false;\n     } catch (CacheClosedException e) {\n       logger.debug(\"Unable to save to lucene index, cache has been closed\", e);\n       return false;\n     } catch (AlreadyClosedException e) {\n       logger.debug(\"Unable to commit, the lucene index is already closed\", e);\n       return false;\n+    } catch (IOException e) {\n+      throw new InternalGemFireError(\"Unable to save to lucene index\", e);\n     } finally {\n       DefaultQuery.setPdxReadSerialized(false);\n     }\n   }\n+\n+  public static void setExceptionObserver(LuceneExceptionObserver observer) {\n+    if (observer == null) {\n+      observer = exception -> {\n+      };\n+    }\n+\n+    exceptionObserver = observer;\n+  }\n+\n+  public static LuceneExceptionObserver getExceptionObserver() {\n+    return exceptionObserver;\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneEventListener.java",
                "sha": "2943ce84f25a1db3ffc0cd20bfa5d00eaef29317",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneExceptionObserver.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneExceptionObserver.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneExceptionObserver.java",
                "patch": "@@ -0,0 +1,25 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.cache.lucene.internal;\n+\n+\n+/**\n+ * A listener for exceptions that happen when writing asynchronously to a lucene index.\n+ */\n+public interface LuceneExceptionObserver {\n+\n+  void onException(Throwable t);\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneExceptionObserver.java",
                "sha": "53e0c9c9860e31d1c186a6551009e3a5f720086c",
                "status": "added"
            },
            {
                "additions": 107,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexForPartitionedRegion.java",
                "changes": 109,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexForPartitionedRegion.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexForPartitionedRegion.java",
                "patch": "@@ -15,6 +15,7 @@\n \n package org.apache.geode.cache.lucene.internal;\n \n+import org.apache.geode.CancelException;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.FixedPartitionResolver;\n@@ -24,6 +25,7 @@\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionAttributes;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.asyncqueue.internal.AsyncEventQueueImpl;\n import org.apache.geode.cache.execute.FunctionService;\n import org.apache.geode.cache.execute.ResultCollector;\n import org.apache.geode.cache.lucene.internal.directory.DumpDirectoryFiles;\n@@ -36,15 +38,23 @@\n import org.apache.geode.cache.lucene.internal.repository.serializer.HeterogeneousLuceneSerializer;\n import org.apache.geode.cache.partition.PartitionListener;\n import org.apache.geode.distributed.internal.DM;\n+import org.apache.geode.distributed.internal.ReplyException;\n+import org.apache.geode.distributed.internal.ReplyProcessor21;\n+import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.PartitionedRegion;\n \n+import java.util.Set;\n+\n /* wrapper of IndexWriter */\n public class LuceneIndexForPartitionedRegion extends LuceneIndexImpl {\n   protected Region<String, File> fileRegion;\n   protected Region<ChunkKey, byte[]> chunkRegion;\n   protected final FileSystemStats fileSystemStats;\n \n+  public static final String FILES_REGION_SUFFIX = \".files\";\n+  public static final String CHUNKS_REGION_SUFFIX = \".chunks\";\n+\n   public LuceneIndexForPartitionedRegion(String indexName, String regionPath, Cache cache) {\n     super(indexName, regionPath, cache);\n \n@@ -123,7 +133,7 @@ Region createFileRegion(final RegionShortcut regionShortCut, final String fileRe\n   }\n \n   public String createFileRegionName() {\n-    return LuceneServiceImpl.getUniqueIndexName(indexName, regionPath) + \".files\";\n+    return LuceneServiceImpl.getUniqueIndexRegionName(indexName, regionPath, FILES_REGION_SUFFIX);\n   }\n \n   boolean chunkRegionExists(String chunkRegionName) {\n@@ -139,7 +149,7 @@ boolean chunkRegionExists(String chunkRegionName) {\n   }\n \n   public String createChunkRegionName() {\n-    return LuceneServiceImpl.getUniqueIndexName(indexName, regionPath) + \".chunks\";\n+    return LuceneServiceImpl.getUniqueIndexRegionName(indexName, regionPath, CHUNKS_REGION_SUFFIX);\n   }\n \n   private PartitionAttributesFactory configureLuceneRegionAttributesFactory(\n@@ -192,4 +202,99 @@ public void dumpFiles(final String directory) {\n         .withArgs(new String[] {directory, indexName}).execute(DumpDirectoryFiles.ID);\n     results.getResult();\n   }\n+\n+  @Override\n+  public void destroy(boolean initiator) {\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"Destroying index regionPath=\" + regionPath + \"; indexName=\" + indexName\n+          + \"; initiator=\" + initiator);\n+    }\n+\n+    // Invoke super destroy to remove the extension\n+    super.destroy(initiator);\n+\n+    // Destroy the AsyncEventQueue\n+    PartitionedRegion pr = (PartitionedRegion) getDataRegion();\n+    destroyAsyncEventQueue(pr);\n+\n+    // Destroy the chunk region (colocated with the file region)\n+    // localDestroyRegion can't be used because locally destroying regions is not supported on\n+    // colocated regions\n+    if (!chunkRegion.isDestroyed()) {\n+      chunkRegion.destroyRegion();\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"Destroyed chunkRegion=\" + chunkRegion.getName());\n+      }\n+    }\n+\n+    // Destroy the file region (colocated with the application region)\n+    // localDestroyRegion can't be used because locally destroying regions is not supported on\n+    // colocated regions\n+    if (!fileRegion.isDestroyed()) {\n+      fileRegion.destroyRegion();\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"Destroyed fileRegion=\" + fileRegion.getName());\n+      }\n+    }\n+\n+    // Destroy index on remote members if necessary\n+    if (initiator) {\n+      destroyOnRemoteMembers(pr);\n+    }\n+\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"Destroyed index regionPath=\" + regionPath + \"; indexName=\" + indexName\n+          + \"; initiator=\" + initiator);\n+    }\n+  }\n+\n+  private void destroyAsyncEventQueue(PartitionedRegion pr) {\n+    String aeqId = LuceneServiceImpl.getUniqueIndexName(indexName, regionPath);\n+\n+    // Get the AsyncEventQueue\n+    AsyncEventQueueImpl aeq = (AsyncEventQueueImpl) cache.getAsyncEventQueue(aeqId);\n+\n+    // Stop the AsyncEventQueue (this stops the AsyncEventQueue's underlying GatewaySender)\n+    aeq.stop();\n+\n+    // Remove the id from the dataRegion's AsyncEventQueue ids\n+    // Note: The region may already have been destroyed by a remote member\n+    if (!pr.isDestroyed()) {\n+      pr.getAttributesMutator().removeAsyncEventQueueId(aeqId);\n+    }\n+\n+    // Destroy the aeq (this also removes it from the GemFireCacheImpl)\n+    aeq.destroy();\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"Destroyed aeqId=\" + aeqId);\n+    }\n+  }\n+\n+  private void destroyOnRemoteMembers(PartitionedRegion pr) {\n+    DM dm = pr.getDistributionManager();\n+    Set<InternalDistributedMember> recipients = pr.getRegionAdvisor().adviseDataStore();\n+    if (!recipients.isEmpty()) {\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"LuceneIndexForPartitionedRegion: About to send destroy message recipients=\"\n+            + recipients);\n+      }\n+      ReplyProcessor21 processor = new ReplyProcessor21(dm, recipients);\n+      DestroyLuceneIndexMessage message = new DestroyLuceneIndexMessage(recipients,\n+          processor.getProcessorId(), regionPath, indexName);\n+      dm.putOutgoing(message);\n+      if (logger.isDebugEnabled()) {\n+        logger.debug(\"LuceneIndexForPartitionedRegion: Sent message recipients=\" + recipients);\n+      }\n+      try {\n+        processor.waitForReplies();\n+      } catch (ReplyException e) {\n+        if (!(e.getCause() instanceof CancelException)) {\n+          throw e;\n+        }\n+      } catch (InterruptedException e) {\n+        dm.getCancelCriterion().checkCancelInProgress(e);\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexForPartitionedRegion.java",
                "sha": "f45d94dbd24740a39c2b205b2a4842b4f1030668",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexImpl.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexImpl.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.geode.internal.cache.extension.Extension;\n import org.apache.logging.log4j.Logger;\n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.standard.StandardAnalyzer;\n@@ -203,6 +204,21 @@ protected void addExtension(LocalRegion dataRegion) {\n     dataRegion.getExtensionPoint().addExtension(creation);\n   }\n \n+  public void destroy(boolean initiator) {\n+    // Find and delete the appropriate extension\n+    Extension extensionToDelete = null;\n+    for (Extension extension : getDataRegion().getExtensionPoint().getExtensions()) {\n+      LuceneIndexCreation index = (LuceneIndexCreation) extension;\n+      if (index.getName().equals(indexName)) {\n+        extensionToDelete = extension;\n+        break;\n+      }\n+    }\n+    if (extensionToDelete != null) {\n+      getDataRegion().getExtensionPoint().removeExtension(extensionToDelete);\n+    }\n+  }\n+\n   protected <K, V> Region<K, V> createRegion(final String regionName,\n       final RegionAttributes<K, V> attributes) {\n     // Create InternalRegionArguments to set isUsedForMetaRegion true to suppress xml generation",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneIndexImpl.java",
                "sha": "cf519be851ce4b76cd12aed273136f6d6b56c4ca",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImpl.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImpl.java",
                "patch": "@@ -24,7 +24,6 @@\n public class LuceneQueryFactoryImpl implements LuceneQueryFactory {\n   private int limit = DEFAULT_LIMIT;\n   private int pageSize = DEFAULT_PAGESIZE;\n-  private String[] projectionFields = null;\n   private Cache cache;\n \n   LuceneQueryFactoryImpl(Cache cache) {\n@@ -57,14 +56,9 @@ public LuceneQueryFactory setResultLimit(int limit) {\n       throw new IllegalArgumentException(\"Region not found: \" + regionName);\n     }\n     LuceneQueryImpl<K, V> luceneQuery =\n-        new LuceneQueryImpl<K, V>(indexName, region, provider, projectionFields, limit, pageSize);\n+        new LuceneQueryImpl<K, V>(indexName, region, provider, limit, pageSize);\n     return luceneQuery;\n   }\n \n-  @Override\n-  public LuceneQueryFactory setProjectionFields(String... fieldNames) {\n-    projectionFields = fieldNames.clone();\n-    return this;\n-  }\n \n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImpl.java",
                "sha": "b798e30c80f3ce94e9e2f02a5531737cccf74c87",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryImpl.java",
                "changes": 46,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 26,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryImpl.java",
                "patch": "@@ -32,13 +32,12 @@\n import org.apache.geode.cache.lucene.LuceneResultStruct;\n import org.apache.geode.cache.lucene.PageableLuceneQueryResults;\n import org.apache.geode.cache.lucene.internal.distributed.EntryScore;\n-import org.apache.geode.cache.lucene.internal.distributed.LuceneFunction;\n+import org.apache.geode.cache.lucene.internal.distributed.LuceneQueryFunction;\n import org.apache.geode.cache.lucene.internal.distributed.LuceneFunctionContext;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntries;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntriesCollector;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntriesCollectorManager;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntriesFunctionCollector;\n-import org.apache.geode.internal.cache.BucketNotFoundException;\n import org.apache.geode.internal.logging.LogService;\n import org.apache.logging.log4j.Logger;\n \n@@ -48,20 +47,17 @@\n   private int limit = LuceneQueryFactory.DEFAULT_LIMIT;\n   private int pageSize = LuceneQueryFactory.DEFAULT_PAGESIZE;\n   private String indexName;\n-  // The projected fields are local to a specific index per Query object.\n-  private String[] projectedFieldNames;\n   /* the lucene Query object to be wrapped here */\n   private LuceneQueryProvider query;\n   private Region<K, V> region;\n   private String defaultField;\n \n   public LuceneQueryImpl(String indexName, Region<K, V> region, LuceneQueryProvider provider,\n-      String[] projectionFields, int limit, int pageSize) {\n+      int limit, int pageSize) {\n     this.indexName = indexName;\n     this.region = region;\n     this.limit = limit;\n     this.pageSize = pageSize;\n-    this.projectedFieldNames = projectionFields;\n     this.query = provider;\n   }\n \n@@ -97,6 +93,11 @@ public LuceneQueryImpl(String indexName, Region<K, V> region, LuceneQueryProvide\n \n   private PageableLuceneQueryResults<K, V> findPages(int pageSize) throws LuceneQueryException {\n     TopEntries<K> entries = findTopEntries();\n+    return newPageableResults(pageSize, entries);\n+  }\n+\n+  protected PageableLuceneQueryResults<K, V> newPageableResults(final int pageSize,\n+      final TopEntries<K> entries) {\n     return new PageableLuceneQueryResultsImpl<K, V>(entries.getHits(), region, pageSize);\n   }\n \n@@ -107,23 +108,20 @@ public LuceneQueryImpl(String indexName, Region<K, V> region, LuceneQueryProvide\n \n     // TODO provide a timeout to the user?\n     TopEntries<K> entries = null;\n-    while (entries == null) {\n-      try {\n-        TopEntriesFunctionCollector collector = new TopEntriesFunctionCollector(context);\n-        ResultCollector<TopEntriesCollector, TopEntries<K>> rc =\n-            (ResultCollector<TopEntriesCollector, TopEntries<K>>) onRegion().withArgs(context)\n-                .withCollector(collector).execute(LuceneFunction.ID);\n-        entries = rc.getResult();\n-      } catch (FunctionException e) {\n-        if (e.getCause() instanceof BucketNotFoundException) {\n-          entries = null;\n-        } else if (e.getCause() instanceof LuceneQueryException) {\n-          throw new LuceneQueryException(e);\n-        } else {\n-          e.printStackTrace();\n-          throw e;\n-        }\n+    try {\n+      TopEntriesFunctionCollector collector = new TopEntriesFunctionCollector(context);\n+      ResultCollector<TopEntriesCollector, TopEntries<K>> rc =\n+          (ResultCollector<TopEntriesCollector, TopEntries<K>>) onRegion().withArgs(context)\n+              .withCollector(collector).execute(LuceneQueryFunction.ID);\n+      entries = rc.getResult();\n+    } catch (FunctionException e) {\n+      if (e.getCause() instanceof LuceneQueryException) {\n+        throw new LuceneQueryException(e);\n+      } else {\n+        e.printStackTrace();\n+        throw e;\n       }\n+\n     }\n     return entries;\n   }\n@@ -142,8 +140,4 @@ public int getLimit() {\n     return this.limit;\n   }\n \n-  @Override\n-  public String[] getProjectedFieldNames() {\n-    return this.projectedFieldNames;\n-  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneQueryImpl.java",
                "sha": "1ece774faf378ecd36aaa8cea9868bcead8190da",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneRawIndex.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneRawIndex.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneRawIndex.java",
                "patch": "@@ -36,4 +36,6 @@ public void dumpFiles(String directory) {\n     return;\n   }\n \n+  @Override\n+  public void destroy(boolean initiator) {}\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneRawIndex.java",
                "sha": "f4518aa749adbe36b3814059d4bd055ed3e1b12e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneResultStructImpl.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneResultStructImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneResultStructImpl.java",
                "patch": "@@ -28,11 +28,6 @@ public LuceneResultStructImpl(K key, V value, float score) {\n     this.score = score;\n   }\n \n-  @Override\n-  public Object getProjectedField(String fieldName) {\n-    throw new UnsupportedOperationException();\n-  }\n-\n   @Override\n   public K getKey() {\n     return key;",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneResultStructImpl.java",
                "sha": "6c310259d9e91649ba30f72cd4abf65c5109d100",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "changes": 67,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "patch": "@@ -18,8 +18,11 @@\n import java.util.*;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.geode.cache.lucene.internal.distributed.LuceneQueryFunction;\n import org.apache.geode.cache.lucene.internal.management.LuceneServiceMBean;\n import org.apache.geode.cache.lucene.internal.management.ManagementIndexListener;\n+import org.apache.geode.cache.lucene.internal.results.LuceneGetPageFunction;\n+import org.apache.geode.cache.lucene.internal.results.PageResults;\n import org.apache.geode.management.internal.beans.CacheServiceMBeanBase;\n import org.apache.logging.log4j.Logger;\n import org.apache.lucene.analysis.Analyzer;\n@@ -39,7 +42,6 @@\n import org.apache.geode.cache.lucene.LuceneQueryFactory;\n import org.apache.geode.cache.lucene.internal.directory.DumpDirectoryFiles;\n import org.apache.geode.cache.lucene.internal.distributed.EntryScore;\n-import org.apache.geode.cache.lucene.internal.distributed.LuceneFunction;\n import org.apache.geode.cache.lucene.internal.distributed.LuceneFunctionContext;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntries;\n import org.apache.geode.cache.lucene.internal.distributed.TopEntriesCollector;\n@@ -55,7 +57,6 @@\n import org.apache.geode.internal.cache.CacheService;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n import org.apache.geode.internal.cache.InternalRegionArguments;\n-import org.apache.geode.internal.cache.PartitionedRegion;\n import org.apache.geode.internal.cache.RegionListener;\n import org.apache.geode.internal.cache.xmlcache.XmlGenerator;\n import org.apache.geode.internal.i18n.LocalizedStrings;\n@@ -89,7 +90,8 @@ public void init(final Cache cache) {\n \n     this.cache = gfc;\n \n-    FunctionService.registerFunction(new LuceneFunction());\n+    FunctionService.registerFunction(new LuceneQueryFunction());\n+    FunctionService.registerFunction(new LuceneGetPageFunction());\n     FunctionService.registerFunction(new WaitUntilFlushedFunction());\n     FunctionService.registerFunction(new DumpDirectoryFiles());\n     registerDataSerializables();\n@@ -115,6 +117,11 @@ public static String getUniqueIndexName(String indexName, String regionPath) {\n     return name;\n   }\n \n+  public static String getUniqueIndexRegionName(String indexName, String regionPath,\n+      String regionSuffix) {\n+    return getUniqueIndexName(indexName, regionPath) + regionSuffix;\n+  }\n+\n   @Override\n   public void createIndex(String indexName, String regionPath, String... fields) {\n     if (fields == null || fields.length == 0) {\n@@ -257,10 +264,53 @@ public LuceneIndex getIndex(String indexName, String regionPath) {\n   }\n \n   @Override\n-  public void destroyIndex(LuceneIndex index) {\n-    LuceneIndexImpl indexImpl = (LuceneIndexImpl) index;\n+  public void destroyIndex(String indexName, String regionPath) {\n+    destroyIndex(indexName, regionPath, true);\n+  }\n+\n+  protected void destroyIndex(String indexName, String regionPath, boolean initiator) {\n+    if (!regionPath.startsWith(\"/\")) {\n+      regionPath = \"/\" + regionPath;\n+    }\n+    LuceneIndexImpl indexImpl = (LuceneIndexImpl) getIndex(indexName, regionPath);\n+    if (indexImpl == null) {\n+      throw new IllegalArgumentException(\n+          LocalizedStrings.LuceneService_INDEX_0_NOT_FOUND_IN_REGION_1.toLocalizedString(indexName,\n+              regionPath));\n+    } else {\n+      indexImpl.destroy(initiator);\n+      removeFromIndexMap(indexImpl);\n+      logger.info(LocalizedStrings.LuceneService_DESTROYED_INDEX_0_FROM_REGION_1\n+          .toLocalizedString(indexName, regionPath));\n+    }\n+  }\n+\n+  @Override\n+  public void destroyIndexes(String regionPath) {\n+    destroyIndexes(regionPath, true);\n+  }\n+\n+  protected void destroyIndexes(String regionPath, boolean initiator) {\n+    if (!regionPath.startsWith(\"/\")) {\n+      regionPath = \"/\" + regionPath;\n+    }\n+    List<LuceneIndexImpl> indexesToDestroy = new ArrayList<>();\n+    for (LuceneIndex index : getAllIndexes()) {\n+      if (index.getRegionPath().equals(regionPath)) {\n+        LuceneIndexImpl indexImpl = (LuceneIndexImpl) index;\n+        indexImpl.destroy(initiator);\n+        indexesToDestroy.add(indexImpl);\n+      }\n+    }\n+    for (LuceneIndex index : indexesToDestroy) {\n+      removeFromIndexMap(index);\n+      logger.info(LocalizedStrings.LuceneService_DESTROYED_INDEX_0_FROM_REGION_1\n+          .toLocalizedString(index.getName(), regionPath));\n+    }\n+  }\n+\n+  private void removeFromIndexMap(LuceneIndex index) {\n     indexMap.remove(getUniqueIndexName(index.getName(), index.getRegionPath()));\n-    // indexImpl.close();\n   }\n \n   @Override\n@@ -321,6 +371,11 @@ public static void registerDataSerializables() {\n \n     DSFIDFactory.registerDSFID(DataSerializableFixedID.WAIT_UNTIL_FLUSHED_FUNCTION_CONTEXT,\n         WaitUntilFlushedFunctionContext.class);\n+\n+    DSFIDFactory.registerDSFID(DataSerializableFixedID.DESTROY_LUCENE_INDEX_MESSAGE,\n+        DestroyLuceneIndexMessage.class);\n+\n+    DSFIDFactory.registerDSFID(DataSerializableFixedID.LUCENE_PAGE_RESULTS, PageResults.class);\n   }\n \n   public Collection<LuceneIndexCreationProfile> getAllDefinedIndexes() {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "sha": "a1a6ef33bdd9b9c69aa8ba08dd9441e3c34fe0c4",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImpl.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 3,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImpl.java",
                "patch": "@@ -17,14 +17,21 @@\n \n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.NoSuchElementException;\n+import java.util.Set;\n \n import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.execute.Execution;\n+import org.apache.geode.cache.execute.FunctionService;\n+import org.apache.geode.cache.execute.ResultCollector;\n import org.apache.geode.cache.lucene.PageableLuceneQueryResults;\n import org.apache.geode.cache.lucene.LuceneResultStruct;\n import org.apache.geode.cache.lucene.internal.distributed.EntryScore;\n+import org.apache.geode.cache.lucene.internal.results.LuceneGetPageFunction;\n+import org.apache.geode.cache.lucene.internal.results.MapResultCollector;\n \n /**\n  * Implementation of PageableLuceneQueryResults that fetchs a page at a time from the server, given\n@@ -74,15 +81,15 @@ public PageableLuceneQueryResultsImpl(List<EntryScore<K>> hits, Region<K, V> use\n \n   public List<LuceneResultStruct<K, V>> getHitEntries(int fromIndex, int toIndex) {\n     List<EntryScore<K>> scores = hits.subList(fromIndex, toIndex);\n-    ArrayList<K> keys = new ArrayList<K>(scores.size());\n+    Set<K> keys = new HashSet<K>(scores.size());\n     for (EntryScore<K> score : scores) {\n       keys.add(score.getKey());\n     }\n \n-    Map<K, V> values = userRegion.getAll(keys);\n+    Map<K, V> values = getValues(keys);\n \n     ArrayList<LuceneResultStruct<K, V>> results =\n-        new ArrayList<LuceneResultStruct<K, V>>(scores.size());\n+        new ArrayList<LuceneResultStruct<K, V>>(values.size());\n     for (EntryScore<K> score : scores) {\n       V value = values.get(score.getKey());\n       if (value != null)\n@@ -91,6 +98,16 @@ public PageableLuceneQueryResultsImpl(List<EntryScore<K>> hits, Region<K, V> use\n     return results;\n   }\n \n+  protected Map<K, V> getValues(final Set<K> keys) {\n+    ResultCollector resultCollector = onRegion().withFilter(keys)\n+        .withCollector(new MapResultCollector()).execute(LuceneGetPageFunction.ID);\n+    return (Map<K, V>) resultCollector.getResult();\n+  }\n+\n+  protected Execution onRegion() {\n+    return FunctionService.onRegion(userRegion);\n+  }\n+\n   @Override\n   public List<LuceneResultStruct<K, V>> next() {\n     if (!hasNext()) {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImpl.java",
                "sha": "8db98a5561afbd65aba5ea56ea82c72dade8463f",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneCliStrings.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneCliStrings.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 5,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneCliStrings.java",
                "patch": "@@ -37,7 +37,7 @@\n   public static final String LUCENE_CREATE_INDEX__NAME__HELP =\n       \"Name of the lucene index to create.\";\n   public static final String LUCENE_CREATE_INDEX__REGION_HELP =\n-      \"Name/Path of the region where the lucene index is created on.\";\n+      \"Name/Path of the region on which to create the lucene index.\";\n   public static final String LUCENE_CREATE_INDEX__FIELD = \"field\";\n   public static final String LUCENE_CREATE_INDEX__FIELD_HELP =\n       \"fields on the region values which are stored in the lucene index.\";\n@@ -61,14 +61,13 @@\n   // Describe lucene index commands\n   public static final String LUCENE_DESCRIBE_INDEX = \"describe lucene index\";\n   public static final String LUCENE_DESCRIBE_INDEX__HELP =\n-      \"Display the describe of lucene indexes created for all members.\";\n+      \"Display the description of lucene indexes created for all members.\";\n   public static final String LUCENE_DESCRIBE_INDEX__ERROR_MESSAGE =\n       \"An error occurred while collecting lucene index information across the Geode cluster: %1$s\";\n   public static final String LUCENE_DESCRIBE_INDEX__NAME__HELP =\n       \"Name of the lucene index to describe.\";\n   public static final String LUCENE_DESCRIBE_INDEX__REGION_HELP =\n-      \"Name/Path of the region where the lucene index to be described exists.\";\n-\n+      \"Name/Path of the region defining the lucene index to be described.\";\n \n   // Search lucene index commands\n   public static final String LUCENE_SEARCH_INDEX = \"search lucene\";\n@@ -78,7 +77,7 @@\n   public static final String LUCENE_SEARCH_INDEX__NAME__HELP =\n       \"Name of the lucene index to search.\";\n   public static final String LUCENE_SEARCH_INDEX__REGION_HELP =\n-      \"Name/Path of the region where the lucene index exists.\";\n+      \"Name/Path of the region defining the lucene index to be searched.\";\n   public static final String LUCENE_SEARCH_INDEX__QUERY_STRING = \"queryStrings\";\n   public static final String LUCENE_SEARCH_INDEX__LIMIT = \"limit\";\n   public static final String LUCENE_SEARCH_INDEX__LIMIT__HELP = \"Number of search results needed\";\n@@ -95,4 +94,23 @@\n   public static final String LUCENE_SEARCH_INDEX__KEYSONLY__HELP =\n       \"Return only keys of search results.\";\n \n+  // Destroy lucene index command\n+  public static final String LUCENE_DESTROY_INDEX = \"destroy lucene index\";\n+  public static final String LUCENE_DESTROY_INDEX__HELP = \"Destroy the lucene index.\";\n+  public static final String LUCENE_DESTROY_INDEX__EXCEPTION_MESSAGE =\n+      \"An unexpected exception occurred while destroying lucene index:\";\n+  public static final String LUCENE_DESTROY_INDEX__NAME__HELP =\n+      \"Name of the lucene index to destroy.\";\n+  public static final String LUCENE_DESTROY_INDEX__REGION_HELP =\n+      \"Name of the region defining the lucene index to be destroyed.\";\n+  public static final String LUCENE_DESTROY_INDEX__MSG__REGION_CANNOT_BE_EMPTY =\n+      \"Region cannot be empty.\";\n+  public static final String LUCENE_DESTROY_INDEX__MSG__INDEX_CANNOT_BE_EMPTY =\n+      \"Index cannot be empty.\";\n+  public static final String LUCENE_DESTROY_INDEX__MSG__COULDNOT_FIND_MEMBERS_FOR_REGION_0 =\n+      \"Could not find any members defining region {0}.\";\n+  public static final String LUCENE_DESTROY_INDEX__MSG__SUCCESSFULLY_DESTROYED_INDEXES_FOR_REGION_0 =\n+      \"Successfully destroyed all lucene indexes for region {0}\";\n+  public static final String LUCENE_DESTROY_INDEX__MSG__SUCCESSFULLY_DESTROYED_INDEX_0_FOR_REGION_1 =\n+      \"Successfully destroyed lucene index {0} for region {1}\";\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneCliStrings.java",
                "sha": "fbb70d21b680ea9fc48086e57b278e3a1798a8b8",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneFunctionSerializable.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneFunctionSerializable.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneFunctionSerializable.java",
                "patch": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal.cli;\n+\n+import java.io.Serializable;\n+\n+public class LuceneFunctionSerializable implements Serializable {\n+\n+  protected final String indexName;\n+  protected final String regionPath;\n+\n+  public LuceneFunctionSerializable(final String indexName, final String regionPath) {\n+    this.indexName = indexName;\n+    this.regionPath = regionPath;\n+  }\n+\n+  public String getIndexName() {\n+    return indexName;\n+  }\n+\n+  public String getRegionPath() {\n+    return regionPath;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneFunctionSerializable.java",
                "sha": "1390e22685997e494d500d71d1ee46dbcc8d3c96",
                "status": "added"
            },
            {
                "additions": 92,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommands.java",
                "changes": 113,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommands.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 21,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommands.java",
                "patch": "@@ -16,16 +16,12 @@\n \n import org.apache.geode.SystemFailure;\n import org.apache.geode.cache.Cache;\n-import org.apache.geode.cache.execute.Execution;\n-import org.apache.geode.cache.execute.FunctionAdapter;\n-import org.apache.geode.cache.execute.FunctionInvocationTargetException;\n-import org.apache.geode.cache.execute.ResultCollector;\n-import org.apache.geode.cache.lucene.internal.cli.functions.LuceneCreateIndexFunction;\n-import org.apache.geode.cache.lucene.internal.cli.functions.LuceneDescribeIndexFunction;\n-import org.apache.geode.cache.lucene.internal.cli.functions.LuceneListIndexFunction;\n-import org.apache.geode.cache.lucene.internal.cli.functions.LuceneSearchIndexFunction;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.execute.*;\n+import org.apache.geode.cache.lucene.internal.cli.functions.*;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.cache.execute.AbstractExecution;\n+import org.apache.geode.internal.lang.StringUtils;\n import org.apache.geode.internal.security.IntegratedSecurityService;\n import org.apache.geode.internal.security.SecurityService;\n import org.apache.geode.management.cli.CliMetaData;\n@@ -70,6 +66,8 @@\n       new LuceneDescribeIndexFunction();\n   private static final LuceneSearchIndexFunction searchIndexFunction =\n       new LuceneSearchIndexFunction();\n+  private static final LuceneDestroyIndexFunction destroyIndexFunction =\n+      new LuceneDestroyIndexFunction();\n   private List<LuceneSearchResults> searchResults = null;\n \n   private SecurityService securityService = IntegratedSecurityService.getSecurityService();\n@@ -316,6 +314,74 @@ public Result searchIndex(@CliOption(key = LuceneCliStrings.LUCENE__INDEX_NAME,\n     }\n   }\n \n+  @CliCommand(value = LuceneCliStrings.LUCENE_DESTROY_INDEX,\n+      help = LuceneCliStrings.LUCENE_DESTROY_INDEX__HELP)\n+  @CliMetaData(shellOnly = false,\n+      relatedTopic = {CliStrings.TOPIC_GEODE_REGION, CliStrings.TOPIC_GEODE_DATA})\n+  @ResourceOperation(resource = Resource.CLUSTER, operation = Operation.READ)\n+  public Result destroyIndex(\n+      @CliOption(key = LuceneCliStrings.LUCENE__INDEX_NAME, mandatory = false,\n+          help = LuceneCliStrings.LUCENE_DESTROY_INDEX__NAME__HELP) final String indexName,\n+\n+      @CliOption(key = LuceneCliStrings.LUCENE__REGION_PATH, mandatory = true,\n+          optionContext = ConverterHint.REGIONPATH,\n+          help = LuceneCliStrings.LUCENE_DESTROY_INDEX__REGION_HELP) final String regionPath) {\n+    if (StringUtils.isBlank(regionPath) || regionPath.equals(Region.SEPARATOR)) {\n+      return ResultBuilder.createInfoResult(\n+          CliStrings.format(LuceneCliStrings.LUCENE_DESTROY_INDEX__MSG__REGION_CANNOT_BE_EMPTY));\n+    }\n+\n+    if (StringUtils.isEmpty(indexName)) {\n+      return ResultBuilder.createInfoResult(\n+          CliStrings.format(LuceneCliStrings.LUCENE_DESTROY_INDEX__MSG__INDEX_CANNOT_BE_EMPTY));\n+    }\n+\n+    this.securityService.authorizeRegionManage(regionPath);\n+\n+    Result result = null;\n+    try {\n+      LuceneIndexInfo indexInfo = new LuceneIndexInfo(indexName, regionPath);\n+      ResultCollector<?, ?> rc = executeFunction(destroyIndexFunction, indexInfo, false);\n+      List<CliFunctionResult> functionResults = (List<CliFunctionResult>) rc.getResult();\n+      CliFunctionResult cliFunctionResult = functionResults.get(0);\n+\n+      final TabularResultData tabularResult = ResultBuilder.createTabularResultData();\n+      tabularResult.accumulate(\"Member\", cliFunctionResult.getMemberIdOrName());\n+      if (cliFunctionResult.isSuccessful()) {\n+        tabularResult.accumulate(\"Status\",\n+            indexName == null\n+                ? CliStrings.format(\n+                    LuceneCliStrings.LUCENE_DESTROY_INDEX__MSG__SUCCESSFULLY_DESTROYED_INDEXES_FOR_REGION_0,\n+                    new Object[] {regionPath})\n+                : CliStrings.format(\n+                    LuceneCliStrings.LUCENE_DESTROY_INDEX__MSG__SUCCESSFULLY_DESTROYED_INDEX_0_FOR_REGION_1,\n+                    new Object[] {indexName, regionPath}));\n+      } else {\n+        tabularResult.accumulate(\"Status\", \"Failed: \" + cliFunctionResult.getMessage());\n+      }\n+      result = ResultBuilder.buildResult(tabularResult);\n+      if (cliFunctionResult.isSuccessful()) {\n+        persistClusterConfiguration(result, () -> {\n+          // Update the xml entity (region entity) to remove the async event id(s) and index(es)\n+          getSharedConfiguration().addXmlEntity((XmlEntity) cliFunctionResult.getXmlEntity(), null);\n+        });\n+      }\n+    } catch (FunctionInvocationTargetException ignore) {\n+      result = ResultBuilder.createGemFireErrorResult(CliStrings.format(\n+          CliStrings.COULD_NOT_EXECUTE_COMMAND_TRY_AGAIN, LuceneCliStrings.LUCENE_DESTROY_INDEX));\n+    } catch (VirtualMachineError e) {\n+      SystemFailure.initiateFailure(e);\n+      throw e;\n+    } catch (IllegalArgumentException e) {\n+      result = ResultBuilder.createInfoResult(e.getMessage());\n+    } catch (Throwable t) {\n+      SystemFailure.checkFailure();\n+      getCache().getLogger().warning(LuceneCliStrings.LUCENE_DESTROY_INDEX__EXCEPTION_MESSAGE, t);\n+      result = ResultBuilder.createGemFireErrorResult(t.getMessage());\n+    }\n+    return result;\n+  }\n+\n   private Result displayResults(int pageSize, boolean keysOnly) throws Exception {\n     if (searchResults.size() == 0) {\n       return ResultBuilder\n@@ -428,25 +494,30 @@ private Result getResults(int fromIndex, int toIndex, boolean keysonly) throws E\n \n   protected ResultCollector<?, ?> executeFunctionOnGroups(FunctionAdapter function, String[] groups,\n       final LuceneIndexInfo indexInfo) throws IllegalArgumentException, CommandResultException {\n-    final Set<DistributedMember> targetMembers;\n+    ResultCollector<?, ?> results = null;\n     if (function != createIndexFunction) {\n-      targetMembers =\n-          CliUtil.getMembersForeRegionViaFunction(getCache(), indexInfo.getRegionPath(), true);\n-      if (targetMembers.isEmpty()) {\n-        throw new IllegalArgumentException(\"Region not found.\");\n-      }\n+      results = executeFunction(function, indexInfo, true);\n     } else {\n-      targetMembers = CliUtil.findMembersOrThrow(groups, null);\n+      Set<DistributedMember> targetMembers = CliUtil.findMembersOrThrow(groups, null);\n+      results = CliUtil.executeFunction(function, indexInfo, targetMembers);\n     }\n-    return CliUtil.executeFunction(function, indexInfo, targetMembers);\n+    return results;\n   }\n \n   protected ResultCollector<?, ?> executeSearch(final LuceneQueryInfo queryInfo) throws Exception {\n-    final Set<DistributedMember> targetMembers =\n-        CliUtil.getMembersForeRegionViaFunction(getCache(), queryInfo.getRegionPath(), false);\n-    if (targetMembers.isEmpty())\n-      throw new IllegalArgumentException(\"Region not found.\");\n-    return CliUtil.executeFunction(searchIndexFunction, queryInfo, targetMembers);\n+    return executeFunction(searchIndexFunction, queryInfo, false);\n+  }\n+\n+  protected ResultCollector<?, ?> executeFunction(Function function,\n+      LuceneFunctionSerializable functionArguments, boolean returnAllMembers) {\n+    Set<DistributedMember> targetMembers = CliUtil.getMembersForeRegionViaFunction(getCache(),\n+        functionArguments.getRegionPath(), returnAllMembers);\n+    if (targetMembers.isEmpty()) {\n+      throw new IllegalArgumentException(CliStrings.format(\n+          LuceneCliStrings.LUCENE_DESTROY_INDEX__MSG__COULDNOT_FIND_MEMBERS_FOR_REGION_0,\n+          new Object[] {functionArguments.getRegionPath()}));\n+    }\n+    return CliUtil.executeFunction(function, functionArguments, targetMembers);\n   }\n \n   @CliAvailabilityIndicator({LuceneCliStrings.LUCENE_SEARCH_INDEX,",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommands.java",
                "sha": "e2d85a612c79f4f86438f76e2738370774c74974",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexDetails.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexDetails.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexDetails.java",
                "patch": "@@ -29,10 +29,9 @@\n \n import org.apache.lucene.analysis.Analyzer;\n \n-public class LuceneIndexDetails implements Comparable<LuceneIndexDetails>, Serializable {\n+public class LuceneIndexDetails extends LuceneFunctionSerializable\n+    implements Comparable<LuceneIndexDetails> {\n   private static final long serialVersionUID = 1L;\n-  private final String indexName;\n-  private final String regionPath;\n   private final String serverName;\n   private final String[] searchableFieldNames;\n   private Map<String, String> fieldAnalyzers = null;\n@@ -42,8 +41,7 @@\n   public LuceneIndexDetails(final String indexName, final String regionPath,\n       final String[] searchableFieldNames, final Map<String, Analyzer> fieldAnalyzers,\n       LuceneIndexStats indexStats, boolean initialized, final String serverName) {\n-    this.indexName = indexName;\n-    this.regionPath = regionPath;\n+    super(indexName, regionPath);\n     this.serverName = serverName;\n     this.searchableFieldNames = searchableFieldNames;\n     this.fieldAnalyzers = getFieldAnalyzerStrings(fieldAnalyzers);\n@@ -141,14 +139,6 @@ public boolean getInitialized() {\n     return initialized;\n   }\n \n-  public String getIndexName() {\n-    return indexName;\n-  }\n-\n-  public String getRegionPath() {\n-    return regionPath;\n-  }\n-\n   private static <T extends Comparable<T>> int compare(final T obj1, final T obj2) {\n     return (obj1 == null && obj2 == null ? 0\n         : (obj1 == null ? 1 : (obj2 == null ? -1 : obj1.compareTo(obj2))));",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexDetails.java",
                "sha": "b2b046602ea17c9d6824316c206a7f7cccc4e1cf",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexInfo.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexInfo.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexInfo.java",
                "patch": "@@ -24,18 +24,15 @@\n \n import org.apache.lucene.analysis.Analyzer;\n \n-public class LuceneIndexInfo implements Serializable {\n+public class LuceneIndexInfo extends LuceneFunctionSerializable {\n   private static final long serialVersionUID = 1L;\n \n-  private final String indexName;\n-  private final String regionPath;\n   private final String[] searchableFieldNames;\n   private final String[] fieldAnalyzers;\n \n   public LuceneIndexInfo(final String indexName, final String regionPath,\n       final String[] searchableFieldNames, String[] fieldAnalyzers) {\n-    this.indexName = indexName;\n-    this.regionPath = regionPath;\n+    super(indexName, regionPath);\n     this.searchableFieldNames = searchableFieldNames;\n     this.fieldAnalyzers = fieldAnalyzers;\n   }\n@@ -44,14 +41,6 @@ public LuceneIndexInfo(final String indexName, final String regionPath) {\n     this(indexName, regionPath, null, null);\n   }\n \n-  public String getIndexName() {\n-    return indexName;\n-  }\n-\n-  public String getRegionPath() {\n-    return regionPath;\n-  }\n-\n   public String[] getSearchableFieldNames() {\n     return searchableFieldNames;\n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexInfo.java",
                "sha": "41b066efad7a4429700c8a51e533e4e208dd6eed",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneQueryInfo.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneQueryInfo.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 13,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneQueryInfo.java",
                "patch": "@@ -19,33 +19,22 @@\n \n import org.apache.geode.cache.lucene.LuceneQueryFactory;\n \n-public class LuceneQueryInfo implements Serializable {\n+public class LuceneQueryInfo extends LuceneFunctionSerializable {\n   private static final long serialVersionUID = 1L;\n-  private String indexName;\n-  private String regionPath;\n   private String queryString;\n   private String defaultField;\n   private int limit;\n   private boolean keysOnly;\n \n   public LuceneQueryInfo(final String indexName, final String regionPath, final String queryString,\n       final String defaultField, final int limit, final boolean keysOnly) {\n-    this.indexName = indexName;\n-    this.regionPath = regionPath;\n+    super(indexName, regionPath);\n     this.queryString = queryString;\n     this.defaultField = defaultField;\n     this.limit = limit;\n     this.keysOnly = keysOnly;\n   }\n \n-  public String getIndexName() {\n-    return indexName;\n-  }\n-\n-  public String getRegionPath() {\n-    return regionPath;\n-  }\n-\n   public String getQueryString() {\n     return queryString;\n   }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/LuceneQueryInfo.java",
                "sha": "e57badbb326ede26122ec86311d6fea33f56faf7",
                "status": "modified"
            },
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunction.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunction.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunction.java",
                "patch": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal.cli.functions;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.execute.Function;\n+import org.apache.geode.cache.execute.FunctionContext;\n+import org.apache.geode.cache.lucene.LuceneService;\n+import org.apache.geode.cache.lucene.LuceneServiceProvider;\n+import org.apache.geode.cache.lucene.internal.cli.LuceneIndexInfo;\n+import org.apache.geode.internal.InternalEntity;\n+import org.apache.geode.internal.cache.xmlcache.CacheXml;\n+import org.apache.geode.management.internal.cli.functions.CliFunctionResult;\n+import org.apache.geode.management.internal.configuration.domain.XmlEntity;\n+\n+public class LuceneDestroyIndexFunction implements Function, InternalEntity {\n+\n+  public void execute(final FunctionContext context) {\n+    String memberId = getCache().getDistributedSystem().getDistributedMember().getId();\n+    try {\n+      LuceneIndexInfo indexInfo = (LuceneIndexInfo) context.getArguments();\n+      String indexName = indexInfo.getIndexName();\n+      String regionPath = indexInfo.getRegionPath();\n+      LuceneService service = LuceneServiceProvider.get(getCache());\n+      if (indexName == null) {\n+        service.destroyIndexes(regionPath);\n+      } else {\n+        service.destroyIndex(indexName, regionPath);\n+      }\n+      context.getResultSender()\n+          .lastResult(new CliFunctionResult(memberId, getXmlEntity(regionPath)));\n+    } catch (Exception e) {\n+      context.getResultSender().lastResult(new CliFunctionResult(memberId, e, e.getMessage()));\n+    }\n+  }\n+\n+  protected XmlEntity getXmlEntity(String regionPath) {\n+    return new XmlEntity(CacheXml.REGION, \"name\", regionPath);\n+  }\n+\n+  protected Cache getCache() {\n+    return CacheFactory.getAnyInstance();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunction.java",
                "sha": "153563717da38fe49cad5620727d0c59db7f10a9",
                "status": "added"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "patch": "@@ -22,11 +22,11 @@\n import org.apache.geode.cache.execute.Function;\n import org.apache.geode.cache.lucene.internal.LuceneIndexImpl;\n import org.apache.geode.cache.lucene.internal.LuceneIndexStats;\n+import org.apache.geode.internal.cache.execute.InternalFunctionInvocationTargetException;\n import org.apache.logging.log4j.Logger;\n import org.apache.lucene.search.Query;\n \n import org.apache.geode.cache.Region;\n-import org.apache.geode.cache.execute.FunctionAdapter;\n import org.apache.geode.cache.execute.FunctionContext;\n import org.apache.geode.cache.execute.FunctionException;\n import org.apache.geode.cache.execute.RegionFunctionContext;\n@@ -43,13 +43,14 @@\n import org.apache.geode.internal.logging.LogService;\n \n /**\n- * {@link LuceneFunction} coordinates text search on a member. It receives text search query from\n- * the coordinator and arguments like region and buckets. It invokes search on the local index and\n- * provides a result collector. The locally collected results are sent to the search coordinator.\n+ * {@link LuceneQueryFunction} coordinates text search on a member. It receives text search query\n+ * from the coordinator and arguments like region and buckets. It invokes search on the local index\n+ * and provides a result collector. The locally collected results are sent to the search\n+ * coordinator.\n  */\n-public class LuceneFunction implements Function, InternalEntity {\n+public class LuceneQueryFunction implements Function, InternalEntity {\n   private static final long serialVersionUID = 1L;\n-  public static final String ID = LuceneFunction.class.getName();\n+  public static final String ID = LuceneQueryFunction.class.getName();\n \n   private static final Logger logger = LogService.getLogger();\n \n@@ -74,6 +75,10 @@ public void execute(FunctionContext context) {\n     LuceneService service = LuceneServiceProvider.get(region.getCache());\n     LuceneIndexImpl index =\n         (LuceneIndexImpl) service.getIndex(searchContext.getIndexName(), region.getFullPath());\n+    if (index == null) {\n+      throw new InternalFunctionInvocationTargetException(\n+          \"Index for Region:\" + region.getFullPath() + \" was not found\");\n+    }\n     RepositoryManager repoManager = index.getRepositoryManager();\n     LuceneIndexStats stats = index.getIndexStats();\n \n@@ -120,7 +125,7 @@ public void execute(FunctionContext context) {\n       resultSender.lastResult(mergedResult);\n     } catch (IOException | BucketNotFoundException e) {\n       logger.debug(\"Exception during lucene query function\", e);\n-      throw new FunctionException(e);\n+      throw new InternalFunctionInvocationTargetException(e);\n     }\n   }\n ",
                "previous_filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneFunction.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "sha": "dd70480d54bfca42a46bcc40554ed6d68cbd739f",
                "status": "renamed"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/WaitUntilFlushedFunction.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/WaitUntilFlushedFunction.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 4,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/WaitUntilFlushedFunction.java",
                "patch": "@@ -20,6 +20,8 @@\n import java.util.Collection;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.execute.Function;\n import org.apache.geode.cache.lucene.internal.LuceneIndexImpl;\n import org.apache.geode.cache.lucene.internal.LuceneIndexStats;\n import org.apache.geode.cache.lucene.internal.LuceneServiceImpl;\n@@ -49,7 +51,7 @@\n  * in current AEQs are flushed into index. This function enables an accessor and client to call to\n  * make sure the current events are processed.\n  */\n-public class WaitUntilFlushedFunction extends FunctionAdapter implements InternalEntity {\n+public class WaitUntilFlushedFunction implements Function, InternalEntity {\n   private static final long serialVersionUID = 1L;\n   public static final String ID = WaitUntilFlushedFunction.class.getName();\n \n@@ -61,7 +63,7 @@ public void execute(FunctionContext context) {\n     ResultSender<Boolean> resultSender = ctx.getResultSender();\n \n     Region region = ctx.getDataSet();\n-\n+    Cache cache = region.getCache();\n     WaitUntilFlushedFunctionContext arg = (WaitUntilFlushedFunctionContext) ctx.getArguments();\n     String indexName = arg.getIndexName();\n     if (indexName == null) {\n@@ -70,12 +72,12 @@ public void execute(FunctionContext context) {\n     long timeout = arg.getTimeout();\n     TimeUnit unit = arg.getTimeunit();\n \n-    LuceneService service = LuceneServiceProvider.get(region.getCache());\n+    LuceneService service = LuceneServiceProvider.get(cache);\n     LuceneIndexImpl index = (LuceneIndexImpl) service.getIndex(indexName, region.getFullPath());\n \n     boolean result = false;\n     String aeqId = LuceneServiceImpl.getUniqueIndexName(indexName, region.getFullPath());\n-    AsyncEventQueueImpl queue = (AsyncEventQueueImpl) region.getCache().getAsyncEventQueue(aeqId);\n+    AsyncEventQueueImpl queue = (AsyncEventQueueImpl) cache.getAsyncEventQueue(aeqId);\n     if (queue != null) {\n       try {\n         result = queue.waitUntilFlushed(timeout, unit);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/WaitUntilFlushedFunction.java",
                "sha": "e11384c59d2044b162c24afb53dd84d5f9acfd53",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/package-info.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/package-info.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/package-info.java",
                "patch": "@@ -14,8 +14,8 @@\n  */\n /**\n  * Classes used for distributing lucene queries to geode nodes. Contains the lucene related\n- * functions like {@link org.apache.geode.cache.lucene.internal.distributed.LuceneFunction} as well\n- * as objects that are passed between nodes like\n+ * functions like {@link org.apache.geode.cache.lucene.internal.distributed.LuceneQueryFunction} as\n+ * well as objects that are passed between nodes like\n  * {@link org.apache.geode.cache.lucene.internal.distributed.EntryScore}\n  */\n ",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/package-info.java",
                "sha": "b718c29b3b0bc6ec4f5484d48be53c463e520b2c",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java",
                "patch": "@@ -172,8 +172,8 @@ public void cleanup() {\n       stats.removeDocumentsSupplier(documentCountSupplier);\n       try {\n         writer.close();\n-      } catch (IOException e) {\n-        logger.warn(\"Unable to clean up index repository\", e);\n+      } catch (Exception e) {\n+        logger.debug(\"Unable to clean up index repository\", e);\n       }\n     } finally {\n       try {",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java",
                "sha": "f356bef6bf420d90faf90624444c48c23254441d",
                "status": "modified"
            },
            {
                "additions": 83,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunction.java",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunction.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunction.java",
                "patch": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ * \n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.cache.lucene.internal.results;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.execute.Function;\n+import org.apache.geode.cache.execute.FunctionContext;\n+import org.apache.geode.cache.execute.RegionFunctionContext;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.internal.InternalEntity;\n+import org.apache.geode.internal.cache.EntrySnapshot;\n+import org.apache.geode.internal.cache.Token;\n+import org.apache.geode.internal.logging.LogService;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.List;\n+import java.util.Set;\n+\n+/**\n+ * {@link LuceneGetPageFunction} Returns the values of entries back to the user This behaves\n+ * basically like a getAll, but it does not invoke a cache loader\n+ */\n+public class LuceneGetPageFunction implements Function, InternalEntity {\n+  private static final long serialVersionUID = 1L;\n+  public static final String ID = LuceneGetPageFunction.class.getName();\n+\n+  private static final Logger logger = LogService.getLogger();\n+\n+  @Override\n+  public void execute(FunctionContext context) {\n+    RegionFunctionContext ctx = (RegionFunctionContext) context;\n+    Region region = PartitionRegionHelper.getLocalDataForContext(ctx);\n+    Set<?> keys = ctx.getFilter();\n+\n+    List<PageEntry> results = new PageResults(keys.size());\n+\n+    for (Object key : keys) {\n+      PageEntry entry = getEntry(region, key);\n+      if (entry != null) {\n+        results.add(entry);\n+      }\n+    }\n+    ctx.getResultSender().lastResult(results);\n+  }\n+\n+  protected PageEntry getEntry(final Region region, final Object key) {\n+    final EntrySnapshot entry = (EntrySnapshot) region.getEntry(key);\n+    if (entry == null) {\n+      return null;\n+    }\n+\n+    final Object value = entry.getRegionEntry().getValue(null);\n+    if (value == null || Token.isInvalidOrRemoved(value)) {\n+      return null;\n+    }\n+\n+    return new PageEntry(key, value);\n+  }\n+\n+\n+  @Override\n+  public String getId() {\n+    return ID;\n+  }\n+\n+  @Override\n+  public boolean optimizeForWrite() {\n+    return false;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunction.java",
                "sha": "0addf48b1856c06322af8d03bc7bcda4702ec735",
                "status": "added"
            },
            {
                "additions": 58,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/MapResultCollector.java",
                "changes": 58,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/MapResultCollector.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/MapResultCollector.java",
                "patch": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal.results;\n+\n+import org.apache.geode.cache.execute.FunctionException;\n+import org.apache.geode.cache.execute.ResultCollector;\n+import org.apache.geode.distributed.DistributedMember;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MapResultCollector implements ResultCollector<List<PageEntry>, Map<Object, Object>> {\n+  private final Map<Object, Object> results = new HashMap<>();\n+\n+  @Override\n+  public Map<Object, Object> getResult() throws FunctionException {\n+    return results;\n+  }\n+\n+  @Override\n+  public Map<Object, Object> getResult(final long timeout, final TimeUnit unit)\n+      throws FunctionException, InterruptedException {\n+    return results;\n+  }\n+\n+  @Override\n+  public void addResult(final DistributedMember memberID,\n+      final List<PageEntry> resultOfSingleExecution) {\n+    for (PageEntry entry : resultOfSingleExecution) {\n+      results.put(entry.getKey(), entry.getValue());\n+    }\n+  }\n+\n+  @Override\n+  public void endResults() {\n+\n+  }\n+\n+  @Override\n+  public void clearResults() {\n+    results.clear();\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/MapResultCollector.java",
                "sha": "0a9b1104025839c11e4144887fcb77270e17aeca",
                "status": "added"
            },
            {
                "additions": 98,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageEntry.java",
                "changes": 98,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageEntry.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageEntry.java",
                "patch": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal.results;\n+\n+import org.apache.geode.DataSerializable;\n+import org.apache.geode.DataSerializer;\n+import org.apache.geode.internal.cache.CachedDeserializable;\n+import org.apache.geode.internal.offheap.StoredObject;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+\n+public class PageEntry {\n+\n+  public Object key;\n+  public Object value;\n+\n+  public PageEntry() {}\n+\n+  public PageEntry(final Object key, final Object value) {\n+    this.key = key;\n+    this.value = value;\n+  }\n+\n+  public Object getKey() {\n+    return key;\n+  }\n+\n+  public Object getValue() {\n+    if (value instanceof CachedDeserializable) {\n+      return ((CachedDeserializable) value).getDeserializedValue(null, null);\n+    }\n+\n+    return value;\n+  }\n+\n+  public void toData(final DataOutput out) throws IOException {\n+\n+    DataSerializer.writeObject(key, out);\n+    if (value instanceof StoredObject) {\n+      ((StoredObject) value).sendTo(out);\n+      return;\n+    }\n+\n+    if (value instanceof CachedDeserializable) {\n+      value = ((CachedDeserializable) value).getValue();\n+      if (value instanceof byte[]) {\n+        out.write((byte[]) value);\n+        return;\n+      }\n+    }\n+\n+    DataSerializer.writeObject(value, out);\n+  }\n+\n+  public void fromData(final DataInput in) throws IOException, ClassNotFoundException {\n+    key = DataSerializer.readObject(in);\n+    value = DataSerializer.readObject(in);\n+  }\n+\n+  @Override\n+  public boolean equals(final Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    final PageEntry pageEntry = (PageEntry) o;\n+\n+    if (!getKey().equals(pageEntry.getKey())) {\n+      return false;\n+    }\n+    return getValue().equals(pageEntry.getValue());\n+\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    int result = getKey().hashCode();\n+    result = 31 * result + getValue().hashCode();\n+    return result;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageEntry.java",
                "sha": "1f52c2eb102957fb23b72af30796bdbbd7c8f2d0",
                "status": "added"
            },
            {
                "additions": 60,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageResults.java",
                "changes": 60,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageResults.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageResults.java",
                "patch": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene.internal.results;\n+\n+import org.apache.geode.internal.DataSerializableFixedID;\n+import org.apache.geode.internal.Version;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+\n+public class PageResults extends ArrayList<PageEntry> implements DataSerializableFixedID {\n+\n+  public PageResults(final int initialCapacity) {\n+    super(initialCapacity);\n+  }\n+\n+  public PageResults() {}\n+\n+  @Override\n+  public int getDSFID() {\n+    return DataSerializableFixedID.LUCENE_PAGE_RESULTS;\n+  }\n+\n+  @Override\n+  public void toData(final DataOutput out) throws IOException {\n+    out.writeInt(this.size());\n+    for (PageEntry entry : this) {\n+      entry.toData(out);\n+    }\n+  }\n+\n+  @Override\n+  public void fromData(final DataInput in) throws IOException, ClassNotFoundException {\n+    int size = in.readInt();\n+    for (int i = 0; i < size; i++) {\n+      PageEntry entry = new PageEntry();\n+      entry.fromData(in);\n+      add(entry);\n+    }\n+  }\n+\n+  @Override\n+  public Version[] getSerializationVersions() {\n+    return new Version[0];\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/results/PageResults.java",
                "sha": "fcacff25612029a2ee155269112bd647e22f4e67",
                "status": "added"
            },
            {
                "additions": 120,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneDUnitTest.java",
                "changes": 122,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 2,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneDUnitTest.java",
                "patch": "@@ -1,7 +1,7 @@\n /*\n  * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n  * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n  * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n  * copy of the License at\n  *\n@@ -14,21 +14,139 @@\n  */\n package org.apache.geode.cache.lucene;\n \n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.EvictionAction;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.lucene.test.LuceneTestUtilities;\n import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.SerializableRunnableIF;\n import org.apache.geode.test.dunit.VM;\n+\n import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n \n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.*;\n+\n+\n public abstract class LuceneDUnitTest extends JUnit4CacheTestCase {\n   protected VM dataStore1;\n   protected VM dataStore2;\n \n+  protected static int NUM_BUCKETS = 10;\n+\n+\n   @Override\n   public void postSetUp() throws Exception {\n     Host host = Host.getHost(0);\n     dataStore1 = host.getVM(0);\n     dataStore2 = host.getVM(1);\n   }\n \n-  protected abstract void initDataStore(SerializableRunnableIF createIndex) throws Exception;\n+  protected void initDataStore(SerializableRunnableIF createIndex,\n+      RegionTestableType regionTestType) throws Exception {\n+    createIndex.run();\n+    regionTestType.createDataStore(getCache(), REGION_NAME);\n+  }\n+\n+  protected void initAccessor(SerializableRunnableIF createIndex, RegionTestableType regionTestType)\n+      throws Exception {\n+    createIndex.run();\n+    regionTestType.createAccessor(getCache(), REGION_NAME);\n+  }\n+\n+  protected RegionTestableType[] getListOfRegionTestTypes() {\n+    return new RegionTestableType[] {RegionTestableType.PARTITION,\n+        RegionTestableType.PARTITION_REDUNDANT, RegionTestableType.PARTITION_OVERFLOW_TO_DISK,\n+        RegionTestableType.PARTITION_PERSISTENT, RegionTestableType.FIXED_PARTITION};\n+  }\n+\n+  protected final Object[] parameterCombiner(Object[] aValues, Object[] bValues) {\n+    Object[] parameters = new Object[aValues.length * bValues.length];\n+    for (int i = 0; i < aValues.length; i++) {\n+      for (int j = 0; j < bValues.length; j++) {\n+        parameters[i * bValues.length + j] = new Object[] {aValues[i], bValues[j]};\n+      }\n+    }\n+    return parameters;\n+  }\n+\n+  public enum RegionTestableType {\n+    PARTITION(RegionShortcut.PARTITION_PROXY, RegionShortcut.PARTITION),\n+    PARTITION_REDUNDANT_PERSISTENT(RegionShortcut.PARTITION_PROXY_REDUNDANT,\n+        RegionShortcut.PARTITION_REDUNDANT_PERSISTENT),\n+    PARTITION_PERSISTENT(RegionShortcut.PARTITION_PROXY, RegionShortcut.PARTITION_PERSISTENT),\n+    PARTITION_REDUNDANT(RegionShortcut.PARTITION_PROXY_REDUNDANT,\n+        RegionShortcut.PARTITION_REDUNDANT),\n+    PARTITION_OVERFLOW_TO_DISK(RegionShortcut.PARTITION_PROXY, RegionShortcut.PARTITION_OVERFLOW,\n+        EvictionAttributes.createLRUEntryAttributes(1, EvictionAction.OVERFLOW_TO_DISK)),\n+    FIXED_PARTITION(RegionShortcut.PARTITION, RegionShortcut.PARTITION),\n+    PARTITION_WITH_CLIENT(RegionShortcut.PARTITION_PROXY, RegionShortcut.PARTITION);\n+\n+\n+    EvictionAttributes evictionAttributes = null;\n+    private RegionShortcut serverRegionShortcut;\n+    private RegionShortcut clientRegionShortcut;\n+\n+    RegionTestableType(RegionShortcut clientRegionShortcut, RegionShortcut serverRegionShortcut) {\n+      this(clientRegionShortcut, serverRegionShortcut, null);\n+    }\n+\n+    RegionTestableType(RegionShortcut clientRegionShortcut, RegionShortcut serverRegionShortcut,\n+        EvictionAttributes evictionAttributes) {\n+      this.clientRegionShortcut = clientRegionShortcut;\n+      this.serverRegionShortcut = serverRegionShortcut;\n+      this.evictionAttributes = evictionAttributes;\n+    }\n+\n+    public Region createDataStore(Cache cache, String regionName) {\n+      if (this.equals(FIXED_PARTITION)) {\n+        try {\n+          return LuceneTestUtilities.initDataStoreForFixedPR(cache);\n+        } catch (Exception e) {\n+          e.printStackTrace();\n+          return null;\n+        }\n+      }\n+      if (evictionAttributes == null) {\n+        return cache.createRegionFactory(serverRegionShortcut)\n+            .setPartitionAttributes(getPartitionAttributes(false)).create(regionName);\n+      } else {\n+        return cache.createRegionFactory(serverRegionShortcut)\n+            .setPartitionAttributes(getPartitionAttributes(false))\n+            .setEvictionAttributes(evictionAttributes).create(regionName);\n+      }\n+    }\n+\n+    public Region createAccessor(Cache cache, String regionName) {\n+      if (this.equals(PARTITION_WITH_CLIENT)) {\n+        return null;\n+      }\n+      if (this.equals(FIXED_PARTITION)) {\n+        return LuceneTestUtilities.createFixedPartitionedRegion(cache, regionName, null, 0);\n+      }\n+      if (evictionAttributes == null) {\n+        return cache.createRegionFactory(clientRegionShortcut)\n+            .setPartitionAttributes(getPartitionAttributes(true)).create(regionName);\n+      } else {\n+        return cache.createRegionFactory(clientRegionShortcut)\n+            .setPartitionAttributes(getPartitionAttributes(true))\n+            .setEvictionAttributes(evictionAttributes).create(regionName);\n+      }\n+    }\n+  }\n+\n+  protected static PartitionAttributes getPartitionAttributes(final boolean isAccessor) {\n+    PartitionAttributesFactory factory = new PartitionAttributesFactory();\n+    if (isAccessor) {\n+      factory.setLocalMaxMemory(0);\n+    } else {\n+      factory.setLocalMaxMemory(100);\n+    }\n+    factory.setTotalNumBuckets(NUM_BUCKETS);\n+    return factory.create();\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneDUnitTest.java",
                "sha": "db482942a716cf8fa63c907ba7a3f5aefe65e802",
                "status": "modified"
            },
            {
                "additions": 86,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "changes": 158,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 72,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "patch": "@@ -14,7 +14,6 @@\n  */\n package org.apache.geode.cache.lucene;\n \n-import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.lucene.test.LuceneTestUtilities;\n import org.apache.geode.test.dunit.SerializableRunnableIF;\n import org.apache.geode.test.junit.categories.DistributedTest;\n@@ -42,32 +41,41 @@\n @RunWith(JUnitParamsRunner.class)\n public class LuceneIndexCreationDUnitTest extends LuceneDUnitTest {\n \n-  @Override\n-  protected void initDataStore(SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache().createRegionFactory(RegionShortcut.PARTITION).create(REGION_NAME);\n+  private final Object[] parametersForMultipleIndexCreates() {\n+    Integer[] numIndexes = {1, 2, 10};\n+    RegionTestableType[] regionTestTypes = getListOfRegionTestTypes();\n+    return parameterCombiner(numIndexes, regionTestTypes);\n   }\n \n+  protected final Object[] parametersForIndexAndRegions() {\n+    Object[] indexCreations = new Object[] {getFieldsIndexWithOneField(),\n+        getFieldsIndexWithTwoFields(), get2FieldsIndexes(), getAnalyzersIndexWithOneField(),\n+        getAnalyzersIndexWithTwoFields(), getAnalyzersIndexWithNullField1()};\n+    RegionTestableType[] regionTestTypes = getListOfRegionTestTypes();\n+    return parameterCombiner(indexCreations, regionTestTypes);\n+  }\n \n   @Test\n-  @Parameters({\"1\", \"2\", \"10\"})\n-  public void verifyThatIndexObjectsAreListedWhenPresentInTheSystem(int numberOfIndexes) {\n+  @Parameters(method = \"parametersForMultipleIndexCreates\")\n+  public void verifyThatIndexObjectsAreListedWhenPresentInTheSystem(int numberOfIndexes,\n+      RegionTestableType regionType) {\n     SerializableRunnableIF createIndex = getMultipleIndexes(numberOfIndexes);\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionType));\n     dataStore1.invoke(() -> verifyIndexList(numberOfIndexes));\n \n-    dataStore2.invoke(() -> initDataStore(createIndex));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionType));\n     dataStore2.invoke(() -> verifyIndexList(numberOfIndexes));\n   }\n \n   @Test\n-  @Parameters({\"1\", \"2\", \"10\"})\n-  public void verifyThatIndexObjectIsRetrievedWhenPresentInTheSystem(int numberOfIndexes) {\n+  @Parameters(method = \"parametersForMultipleIndexCreates\")\n+  public void verifyThatIndexObjectIsRetrievedWhenPresentInTheSystem(int numberOfIndexes,\n+      RegionTestableType regionType) {\n     SerializableRunnableIF createIndex = getMultipleIndexes(numberOfIndexes);\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionType));\n     dataStore1.invoke(() -> verifyIndexes(numberOfIndexes));\n \n-    dataStore2.invoke(() -> initDataStore(createIndex));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionType));\n     dataStore2.invoke(() -> verifyIndexes(numberOfIndexes));\n   }\n \n@@ -108,132 +116,136 @@ public void verifyNullIsReturnedWhenGetIndexIsCalledWithNoMatchingIndex() {\n \n \n   @Test\n-  public void verifyDifferentFieldsFails() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldsFails(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getFieldsIndexWithOneField();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getFieldsIndexWithTwoFields();\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS));\n+    dataStore2.invoke(\n+        () -> initDataStore(createIndex2, regionType, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS));\n   }\n \n   @Test\n-  public void verifyDifferentFieldAnalyzerSizesFails1() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldAnalyzerSizesFails1(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithTwoFields();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithOneField();\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS_2));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS_2));\n   }\n \n   @Test\n-  public void verifyDifferentFieldAnalyzerSizesFails2() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldAnalyzerSizesFails2(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithOneField();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithTwoFields();\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS));\n+    dataStore2.invoke(\n+        () -> initDataStore(createIndex2, regionType, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_FIELDS));\n   }\n \n   @Test\n-  public void verifyDifferentFieldAnalyzersFails1() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldAnalyzersFails1(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithOneField(StandardAnalyzer.class);\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithOneField(KeywordAnalyzer.class);\n-    dataStore2.invoke(\n-        () -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_ANALYZERS_2));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_ANALYZERS_2));\n   }\n \n   @Test\n-  public void verifyDifferentFieldAnalyzersFails2() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldAnalyzersFails2(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithNullField1();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithNullField2();\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_ANALYZERS));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_ANALYZERS));\n   }\n \n   @Test\n-  public void verifyDifferentFieldAnalyzersFails3() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentFieldAnalyzersFails3(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithNullField2();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithNullField1();\n-    dataStore2.invoke(() -> initDataStore(createIndex2,\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n         LuceneTestUtilities.CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_ANALYZERS_3));\n   }\n \n   @Test\n-  public void verifyDifferentIndexNamesFails() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentIndexNamesFails(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME + \"1\", REGION_NAME, \"field1\");\n     };\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME + \"2\", REGION_NAME, \"field1\");\n     };\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_NAMES));\n+    dataStore2.invoke(\n+        () -> initDataStore(createIndex2, regionType, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_NAMES));\n   }\n \n   @Test\n-  public void verifyDifferentIndexesFails1() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentIndexesFails1(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getFieldsIndexWithOneField();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = () -> {\n       /* Do nothing */};\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_1));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_1));\n   }\n \n \n   @Test\n-  public void verifyDifferentIndexesFails2() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyDifferentIndexesFails2(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getFieldsIndexWithOneField();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME, REGION_NAME, \"field1\");\n       luceneService.createIndex(INDEX_NAME + \"2\", REGION_NAME, \"field2\");\n     };\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_2));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_2));\n   }\n \n   @Test\n-  public void verifyMemberWithoutIndexCreatedFirstFails() {\n+  @Parameters({\"PARTITION\"})\n+  public void verifyMemberWithoutIndexCreatedFirstFails(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = () -> {\n       /* Do nothing */};\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getFieldsIndexWithOneField();\n-    dataStore2\n-        .invoke(() -> initDataStore(createIndex2, CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_3));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType,\n+        CANNOT_CREATE_LUCENE_INDEX_DIFFERENT_INDEXES_3));\n   }\n \n   @Test\n-  @Parameters(method = \"getIndexes\")\n-  public void verifySameIndexesSucceeds(SerializableRunnableIF createIndex) {\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n-    dataStore2.invoke(() -> initDataStore(createIndex));\n+  @Parameters(method = \"parametersForIndexAndRegions\")\n+  public void verifySameIndexesSucceeds(SerializableRunnableIF createIndex,\n+      RegionTestableType regionType) {\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionType));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionType));\n   }\n \n-  protected final Object[] getIndexes() {\n-    return $(new Object[] {getFieldsIndexWithOneField()},\n-        new Object[] {getFieldsIndexWithTwoFields()}, new Object[] {get2FieldsIndexes()},\n-        new Object[] {getAnalyzersIndexWithOneField()},\n-        new Object[] {getAnalyzersIndexWithTwoFields()},\n-        new Object[] {getAnalyzersIndexWithNullField1()});\n-  }\n \n   @Test\n   @Parameters(method = \"getXmlAndExceptionMessages\")\n@@ -295,21 +307,23 @@ public void verifyXMLEmptyIndexList() {\n   }\n \n   @Test\n-  public void verifyStandardAnalyzerAndNullOnSameFieldPasses() {\n+  @Parameters(\"PARTITION\")\n+  public void verifyStandardAnalyzerAndNullOnSameFieldPasses(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithNullField1();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithTwoFields2();\n-    dataStore2.invoke(() -> initDataStore(createIndex2));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType));\n   }\n \n   @Test\n-  public void verifyStandardAnalyzerAndNullOnSameFieldPasses2() {\n+  @Parameters(\"PARTITION\")\n+  public void verifyStandardAnalyzerAndNullOnSameFieldPasses2(RegionTestableType regionType) {\n     SerializableRunnableIF createIndex1 = getAnalyzersIndexWithTwoFields2();\n-    dataStore1.invoke(() -> initDataStore(createIndex1));\n+    dataStore1.invoke(() -> initDataStore(createIndex1, regionType));\n \n     SerializableRunnableIF createIndex2 = getAnalyzersIndexWithNullField1();\n-    dataStore2.invoke(() -> initDataStore(createIndex2));\n+    dataStore2.invoke(() -> initDataStore(createIndex2, regionType));\n   }\n \n   protected String getXmlFileForTest(String testName) {\n@@ -321,11 +335,11 @@ protected String getClassSimpleName() {\n     return getClass().getSimpleName();\n   }\n \n-  protected void initDataStore(SerializableRunnableIF createIndex, String message)\n-      throws Exception {\n+  protected void initDataStore(SerializableRunnableIF createIndex, RegionTestableType regionType,\n+      String message) throws Exception {\n     createIndex.run();\n     try {\n-      getCache().createRegionFactory(RegionShortcut.PARTITION).create(REGION_NAME);\n+      regionType.createDataStore(getCache(), REGION_NAME);\n       fail(\"Should not have been able to create index\");\n     } catch (IllegalStateException e) {\n       assertEquals(message, e.getMessage());",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationDUnitTest.java",
                "sha": "60f8b65fdb2852bb7c8c31a8c736e318b565e34e",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationOnFixedPRDUnitTest.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationOnFixedPRDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 6,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationOnFixedPRDUnitTest.java",
                "patch": "@@ -14,6 +14,7 @@\n  */\n package org.apache.geode.cache.lucene;\n \n+import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.lucene.test.LuceneTestUtilities;\n import org.apache.geode.test.dunit.SerializableRunnableIF;\n import org.apache.geode.test.junit.categories.DistributedTest;\n@@ -27,16 +28,17 @@\n @Category(DistributedTest.class)\n @RunWith(JUnitParamsRunner.class)\n public class LuceneIndexCreationOnFixedPRDUnitTest extends LuceneIndexCreationDUnitTest {\n+\n   @Override\n-  protected void initDataStore(SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    LuceneTestUtilities.initDataStoreForFixedPR(getCache());\n+  protected RegionTestableType[] getListOfRegionTestTypes() {\n+    return new RegionTestableType[] {RegionTestableType.FIXED_PARTITION};\n   }\n \n-  protected void initDataStore(SerializableRunnableIF createIndex, String message)\n-      throws Exception {\n+  @Override\n+  protected void initDataStore(SerializableRunnableIF createIndex, RegionTestableType regionType,\n+      String message) throws Exception {\n     try {\n-      initDataStore(createIndex);\n+      initDataStore(createIndex, regionType);\n       fail(\"Should not have been able to create index\");\n     } catch (IllegalStateException e) {\n       assertEquals(message, e.getMessage());",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexCreationOnFixedPRDUnitTest.java",
                "sha": "4471291f7aed35540bbfcb61e9e79036de2fec7e",
                "status": "modified"
            },
            {
                "additions": 247,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexDestroyDUnitTest.java",
                "changes": 247,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexDestroyDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexDestroyDUnitTest.java",
                "patch": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.lucene.internal.LuceneIndexForPartitionedRegion;\n+import org.apache.geode.cache.lucene.internal.LuceneServiceImpl;\n+import org.apache.geode.cache.lucene.test.TestObject;\n+import org.apache.geode.internal.cache.LocalRegion;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.SerializableRunnableIF;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.INDEX_NAME;\n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.REGION_NAME;\n+import static org.apache.geode.internal.Assert.fail;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+\n+@Category(DistributedTest.class)\n+@RunWith(JUnitParamsRunner.class)\n+public class LuceneIndexDestroyDUnitTest extends LuceneDUnitTest {\n+\n+  private volatile boolean STOP_PUTS = false;\n+\n+  private final Object[] parametersForIndexDestroys() {\n+    String[] destroyDataRegionParameters = {\"true\", \"false\"};\n+    RegionTestableType[] regionTestTypes = getListOfRegionTestTypes();\n+    return parameterCombiner(destroyDataRegionParameters, regionTestTypes);\n+  }\n+\n+  @Test\n+  @Parameters(method = \"parametersForIndexDestroys\")\n+  public void verifyDestroySingleIndex(boolean destroyDataRegion, RegionTestableType regionType) {\n+    // Create index and region\n+    dataStore1.invoke(() -> initDataStore(createIndex(), regionType));\n+    dataStore2.invoke(() -> initDataStore(createIndex(), regionType));\n+\n+    // Verify index created\n+    dataStore1.invoke(() -> verifyIndexCreated());\n+    dataStore2.invoke(() -> verifyIndexCreated());\n+\n+    // Attempt to destroy data region (should fail)\n+    if (destroyDataRegion) {\n+      dataStore1.invoke(() -> destroyDataRegion(false));\n+    }\n+\n+    // Destroy index (only needs to be done on one member)\n+    dataStore1.invoke(() -> destroyIndex());\n+\n+    // Verify index destroyed\n+    dataStore1.invoke(() -> verifyIndexDestroyed());\n+    dataStore2.invoke(() -> verifyIndexDestroyed());\n+\n+    // Attempt to destroy data region (should succeed)\n+    if (destroyDataRegion) {\n+      dataStore1.invoke(() -> destroyDataRegion(true));\n+    }\n+  }\n+\n+  @Test\n+  @Parameters(method = \"parametersForIndexDestroys\")\n+  public void verifyDestroyAllIndexes(boolean destroyDataRegion, RegionTestableType regionType) {\n+    // Create indexes and region\n+    dataStore1.invoke(() -> initDataStore(createIndexes(), regionType));\n+    dataStore2.invoke(() -> initDataStore(createIndexes(), regionType));\n+\n+    // Verify indexes created\n+    dataStore1.invoke(() -> verifyIndexesCreated());\n+    dataStore2.invoke(() -> verifyIndexesCreated());\n+\n+    // Attempt to destroy data region (should fail)\n+    if (destroyDataRegion) {\n+      dataStore1.invoke(() -> destroyDataRegion(false));\n+    }\n+\n+    // Destroy indexes (only needs to be done on one member)\n+    dataStore1.invoke(() -> destroyIndexes());\n+\n+    // Verify indexes destroyed\n+    dataStore1.invoke(() -> verifyIndexesDestroyed());\n+    dataStore2.invoke(() -> verifyIndexesDestroyed());\n+\n+    // Attempt to destroy data region (should succeed)\n+    if (destroyDataRegion) {\n+      dataStore1.invoke(() -> destroyDataRegion(true));\n+    }\n+  }\n+\n+  @Ignore\n+  // Destroying an index while puts are occurring currently fails with a\n+  // GatewaySenderConfigurationException.\n+  @Parameters(method = \"getListOfServerRegionTestTypes\")\n+  public void verifyDestroySingleIndexWhileDoingPuts(RegionTestableType regionType)\n+      throws Exception {\n+    // Create index and region\n+    dataStore1.invoke(() -> initDataStore(createIndex(), regionType));\n+    dataStore2.invoke(() -> initDataStore(createIndex(), regionType));\n+\n+    // Verify index created\n+    dataStore1.invoke(() -> verifyIndexCreated());\n+    dataStore2.invoke(() -> verifyIndexCreated());\n+\n+    // Start puts\n+    AsyncInvocation putter = dataStore1.invokeAsync(() -> doPuts());\n+\n+    // Wait until puts have started\n+    dataStore1.invoke(() -> waitUntilPutsHaveStarted());\n+\n+    // Destroy index (only needs to be done on one member)\n+    dataStore1.invoke(() -> destroyIndex());\n+\n+    // Verify index destroyed\n+    dataStore1.invoke(() -> verifyIndexDestroyed());\n+    dataStore2.invoke(() -> verifyIndexDestroyed());\n+\n+    // End puts\n+    dataStore1.invoke(() -> stopPuts());\n+    putter.join();\n+  }\n+\n+\n+  private SerializableRunnableIF createIndex() {\n+    return () -> {\n+      LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+      luceneService.createIndex(INDEX_NAME, REGION_NAME, \"text\");\n+    };\n+  }\n+\n+  private SerializableRunnableIF createIndexes() {\n+    return () -> {\n+      LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+      luceneService.createIndex(INDEX_NAME + \"0\", REGION_NAME, \"text\");\n+      luceneService.createIndex(INDEX_NAME + \"1\", REGION_NAME, \"text\");\n+    };\n+  }\n+\n+  private void verifyIndexCreated() {\n+    LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+    assertNotNull(luceneService.getIndex(INDEX_NAME, REGION_NAME));\n+  }\n+\n+  private void verifyIndexesCreated() {\n+    LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+    assertNotNull(luceneService.getIndex(INDEX_NAME + \"0\", REGION_NAME));\n+    assertNotNull(luceneService.getIndex(INDEX_NAME + \"1\", REGION_NAME));\n+  }\n+\n+  private void doPuts() throws Exception {\n+    Region region = getCache().getRegion(REGION_NAME);\n+    int i = 0;\n+    while (!STOP_PUTS) {\n+      region.put(i++, new TestObject());\n+      // Thread.sleep(50);\n+    }\n+  }\n+\n+  private void stopPuts() {\n+    STOP_PUTS = true;\n+  }\n+\n+  private void waitUntilPutsHaveStarted() {\n+    Awaitility.waitAtMost(30, TimeUnit.SECONDS)\n+        .until(() -> getCache().getRegion(REGION_NAME).size() > 0);\n+  }\n+\n+  private void destroyDataRegion(boolean shouldSucceed) {\n+    Region region = getCache().getRegion(REGION_NAME);\n+    assertNotNull(region);\n+    try {\n+      region.destroyRegion();\n+      if (!shouldSucceed) {\n+        fail(\"should not have been able to destroy data region named \" + region.getFullPath());\n+      }\n+    } catch (IllegalStateException e) {\n+      if (shouldSucceed) {\n+        fail(e);\n+      }\n+    }\n+  }\n+\n+  private void destroyIndex() {\n+    LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+    luceneService.destroyIndex(INDEX_NAME, REGION_NAME);\n+  }\n+\n+  private void destroyIndexes() {\n+    LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+    luceneService.destroyIndexes(REGION_NAME);\n+  }\n+\n+  private void verifyIndexDestroyed() {\n+    verifyIndexDestroyed(INDEX_NAME);\n+  }\n+\n+  private void verifyIndexesDestroyed() {\n+    verifyIndexDestroyed(INDEX_NAME + \"0\");\n+    verifyIndexDestroyed(INDEX_NAME + \"1\");\n+  }\n+\n+  private void verifyIndexDestroyed(String indexName) {\n+    LuceneService luceneService = LuceneServiceProvider.get(getCache());\n+\n+    // Verify the index itself no longer exists\n+    assertNull(luceneService.getIndex(indexName, REGION_NAME));\n+\n+    // Verify the underlying files region no longer exists\n+    String filesRegionName = LuceneServiceImpl.getUniqueIndexRegionName(indexName, REGION_NAME,\n+        LuceneIndexForPartitionedRegion.FILES_REGION_SUFFIX);\n+    assertNull(getCache().getRegion(filesRegionName));\n+\n+    // Verify the underlying chunks region no longer exists\n+    String chunksRegionName = LuceneServiceImpl.getUniqueIndexRegionName(indexName, REGION_NAME,\n+        LuceneIndexForPartitionedRegion.CHUNKS_REGION_SUFFIX);\n+    assertNull(getCache().getRegion(chunksRegionName));\n+\n+    // Verify the underlying AsyncEventQueue no longer exists\n+    String aeqId = LuceneServiceImpl.getUniqueIndexName(indexName, REGION_NAME);\n+    assertNull(getCache().getAsyncEventQueue(aeqId));\n+\n+    // Verify the data region extension no longer exists\n+    LocalRegion region = (LocalRegion) getCache().getRegion(REGION_NAME);\n+    assertFalse(region.getExtensionPoint().getExtensions().iterator().hasNext());\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneIndexDestroyDUnitTest.java",
                "sha": "6260075ccdd5c4af59a3edf339b25e01096aca52",
                "status": "added"
            },
            {
                "additions": 211,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesAccessorBase.java",
                "changes": 211,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesAccessorBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesAccessorBase.java",
                "patch": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.lucene;\n+\n+\n+import static org.apache.geode.cache.lucene.test.IndexRepositorySpy.doOnce;\n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.DEFAULT_FIELD;\n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.INDEX_NAME;\n+import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.REGION_NAME;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.lucene.internal.LuceneIndexFactorySpy;\n+import org.apache.geode.cache.lucene.internal.LuceneIndexImpl;\n+import org.apache.geode.cache.lucene.test.IndexRepositorySpy;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedMember;\n+import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n+import org.apache.geode.internal.cache.InitialImageOperation;\n+import org.apache.geode.internal.cache.PartitionedRegion;\n+import org.apache.geode.internal.cache.partitioned.BecomePrimaryBucketMessage;\n+import org.apache.geode.internal.cache.partitioned.BecomePrimaryBucketMessage.BecomePrimaryBucketResponse;\n+import org.apache.geode.test.dunit.Host;\n+import org.apache.geode.test.dunit.VM;\n+\n+import java.io.Serializable;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+public class LuceneQueriesAccessorBase extends LuceneDUnitTest {\n+\n+  protected VM accessor;\n+\n+  @Override\n+  public void postSetUp() throws Exception {\n+    super.postSetUp();\n+    accessor = Host.getHost(0).getVM(3);\n+  }\n+\n+  protected boolean waitForFlushBeforeExecuteTextSearch(VM vm, int ms) {\n+    return vm.invoke(() -> {\n+      Cache cache = getCache();\n+\n+      LuceneService service = LuceneServiceProvider.get(cache);\n+      LuceneIndexImpl index = (LuceneIndexImpl) service.getIndex(INDEX_NAME, REGION_NAME);\n+\n+      return service.waitUntilFlushed(INDEX_NAME, REGION_NAME, ms, TimeUnit.MILLISECONDS);\n+    });\n+  }\n+\n+  protected void executeTextSearch(VM vm) {\n+    vm.invoke(() -> {\n+      Cache cache = getCache();\n+      Region<Object, Object> region = cache.getRegion(REGION_NAME);\n+\n+      LuceneService service = LuceneServiceProvider.get(cache);\n+      LuceneQuery<Integer, TestObject> query;\n+      query = service.createLuceneQueryFactory().create(INDEX_NAME, REGION_NAME, \"text:world\",\n+          DEFAULT_FIELD);\n+      PageableLuceneQueryResults<Integer, TestObject> results = query.findPages();\n+      assertEquals(3, results.size());\n+      List<LuceneResultStruct<Integer, TestObject>> page = results.next();\n+\n+      Map<Integer, TestObject> data = new HashMap<Integer, TestObject>();\n+      for (LuceneResultStruct<Integer, TestObject> row : page) {\n+        data.put(row.getKey(), row.getValue());\n+      }\n+\n+      assertEquals(new HashMap(region), data);\n+      return null;\n+    });\n+  }\n+\n+  protected void executeTextSearch(VM vm, String queryString, String defaultField,\n+      int expectedResultsSize) {\n+    vm.invoke(() -> {\n+      Cache cache = getCache();\n+\n+      LuceneService service = LuceneServiceProvider.get(cache);\n+      LuceneQuery<Integer, TestObject> query;\n+      query = service.createLuceneQueryFactory().setResultLimit(1000).setPageSize(1000)\n+          .create(INDEX_NAME, REGION_NAME, queryString, defaultField);\n+      Collection<?> results = query.findKeys();\n+\n+      assertEquals(expectedResultsSize, results.size());\n+    });\n+  }\n+\n+  protected void addCallbackToTriggerRebalance(VM vm) {\n+    vm.invoke(() -> {\n+      IndexRepositorySpy spy = IndexRepositorySpy.injectSpy();\n+\n+      spy.beforeWriteIndexRepository(doOnce(key -> rebalanceRegion(vm)));\n+    });\n+  }\n+\n+  protected void addCallbackToMoveBucket(VM vm, final DistributedMember destination) {\n+    vm.invoke(() -> {\n+      IndexRepositorySpy spy = IndexRepositorySpy.injectSpy();\n+\n+      spy.beforeWriteIndexRepository(doOnce(key -> moveBucket(destination, key)));\n+    });\n+  }\n+\n+  protected void addCallbackToMovePrimary(VM vm, final DistributedMember destination) {\n+    vm.invoke(() -> {\n+      IndexRepositorySpy spy = IndexRepositorySpy.injectSpy();\n+\n+      spy.beforeWriteIndexRepository(doOnce(key -> movePrimary(destination, key)));\n+    });\n+  }\n+\n+  protected void addCallbackToMovePrimaryOnQuery(VM vm, final DistributedMember destination) {\n+    vm.invoke(() -> {\n+      LuceneIndexFactorySpy factorySpy = LuceneIndexFactorySpy.injectSpy();\n+\n+      factorySpy.setGetRespositoryConsumer(doOnce(key -> moveBucket(destination, key)));\n+    });\n+  }\n+\n+  private void moveBucket(final DistributedMember destination, final Object key) {\n+    Region<Object, Object> region = getCache().getRegion(REGION_NAME);\n+    DistributedMember source = getCache().getDistributedSystem().getDistributedMember();\n+    PartitionRegionHelper.moveBucketByKey(region, source, destination, key);\n+  }\n+\n+  private void movePrimary(final DistributedMember destination, final Object key) {\n+    PartitionedRegion region = (PartitionedRegion) getCache().getRegion(REGION_NAME);\n+\n+    BecomePrimaryBucketResponse response =\n+        BecomePrimaryBucketMessage.send((InternalDistributedMember) destination, region,\n+            region.getKeyInfo(key).getBucketId(), true);\n+    assertNotNull(response);\n+    assertTrue(response.waitForResponse());\n+  }\n+\n+  protected void removeCallback(VM vm) {\n+    vm.invoke(() -> {\n+      IndexRepositorySpy.remove();\n+      InitialImageOperation.resetAllGIITestHooks();\n+      LuceneIndexFactorySpy.remove();\n+    });\n+  }\n+\n+  protected void rebalanceRegion(VM vm) {\n+    // Do a rebalance\n+    vm.invoke(() -> {\n+      RebalanceOperation op = getCache().getResourceManager().createRebalanceFactory().start();\n+      RebalanceResults results = op.getResults();\n+    });\n+  }\n+\n+  protected static class TestObject implements Serializable {\n+    private static final long serialVersionUID = 1L;\n+    private String text;\n+\n+    public TestObject(String text) {\n+      this.text = text;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+      final int prime = 31;\n+      int result = 1;\n+      result = prime * result + ((text == null) ? 0 : text.hashCode());\n+      return result;\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+      if (this == obj)\n+        return true;\n+      if (obj == null)\n+        return false;\n+      if (getClass() != obj.getClass())\n+        return false;\n+      TestObject other = (TestObject) obj;\n+      if (text == null) {\n+        if (other.text != null)\n+          return false;\n+      } else if (!text.equals(other.text))\n+        return false;\n+      return true;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return \"TestObject[\" + text + \"]\";\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesAccessorBase.java",
                "sha": "241d37420bf0afa86b14863aa00f8b737be1cae8",
                "status": "added"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesClientDUnitTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesClientDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 7,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesClientDUnitTest.java",
                "patch": "@@ -27,9 +27,13 @@\n import org.apache.geode.test.dunit.SerializableCallableIF;\n import org.apache.geode.test.dunit.SerializableRunnableIF;\n import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.junit.runner.RunWith;\n+\n+import junitparams.JUnitParamsRunner;\n \n @Category(DistributedTest.class)\n-public class LuceneQueriesClientDUnitTest extends LuceneQueriesBase {\n+@RunWith(JUnitParamsRunner.class)\n+public class LuceneQueriesClientDUnitTest extends LuceneQueriesDUnitTest {\n \n   @Override\n   public void postSetUp() throws Exception {\n@@ -53,13 +57,13 @@ public void postSetUp() throws Exception {\n     });\n   }\n \n-  @Override\n-  protected void initAccessor(SerializableRunnableIF createIndex) throws Exception {}\n+  protected void initAccessor(SerializableRunnableIF createIndex, RegionTestableType regionTestType)\n+      throws Exception {}\n \n-  @Override\n-  protected void initDataStore(SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache().createRegionFactory(RegionShortcut.PARTITION).create(REGION_NAME);\n+  protected RegionTestableType[] getListOfRegionTestTypes() {\n+    return new RegionTestableType[] {RegionTestableType.PARTITION_WITH_CLIENT};\n   }\n \n+\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesClientDUnitTest.java",
                "sha": "b0ae47ef79efd88c5f645e30a000449aaf8b75f0",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesDUnitTest.java",
                "changes": 155,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 123,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesDUnitTest.java",
                "patch": "@@ -17,53 +17,44 @@\n import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.*;\n import static org.junit.Assert.*;\n \n-import java.io.Serializable;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n import org.apache.geode.cache.Cache;\n import org.apache.geode.cache.Region;\n-import org.apache.geode.cache.lucene.internal.LuceneIndexImpl;\n import org.apache.geode.cache.lucene.test.LuceneTestUtilities;\n-import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.SerializableRunnableIF;\n import org.apache.geode.test.dunit.VM;\n \n+import org.apache.geode.test.junit.categories.DistributedTest;\n import org.apache.lucene.index.Term;\n import org.apache.lucene.search.TermQuery;\n import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n \n /**\n  * This test class is intended to contain basic integration tests of the lucene query class that\n  * should be executed against a number of different regions types and topologies.\n  *\n  */\n-public abstract class LuceneQueriesBase extends LuceneDUnitTest {\n+@Category(DistributedTest.class)\n+@RunWith(JUnitParamsRunner.class)\n+public class LuceneQueriesDUnitTest extends LuceneQueriesAccessorBase {\n \n   private static final long serialVersionUID = 1L;\n-  protected VM accessor;\n-\n-  @Override\n-  public void postSetUp() throws Exception {\n-    super.postSetUp();\n-    accessor = Host.getHost(0).getVM(3);\n-  }\n-\n-  protected abstract void initAccessor(SerializableRunnableIF createIndex) throws Exception;\n \n   @Test\n-  public void returnCorrectResultsFromStringQueryWithDefaultAnalyzer() {\n+  @Parameters(method = \"getListOfRegionTestTypes\")\n+  public void returnCorrectResultsFromStringQueryWithDefaultAnalyzer(\n+      RegionTestableType regionTestType) {\n     SerializableRunnableIF createIndex = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME, REGION_NAME, \"text\");\n     };\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n-    dataStore2.invoke(() -> initDataStore(createIndex));\n-    accessor.invoke(() -> initAccessor(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionTestType));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionTestType));\n+    accessor.invoke(() -> initAccessor(createIndex, regionTestType));\n \n     putDataInRegion(accessor);\n     assertTrue(waitForFlushBeforeExecuteTextSearch(accessor, 60000));\n@@ -72,14 +63,16 @@ public void returnCorrectResultsFromStringQueryWithDefaultAnalyzer() {\n   }\n \n   @Test\n-  public void defaultFieldShouldPropogateCorrectlyThroughFunction() {\n+  @Parameters(method = \"getListOfRegionTestTypes\")\n+  public void defaultFieldShouldPropogateCorrectlyThroughFunction(\n+      RegionTestableType regionTestType) {\n     SerializableRunnableIF createIndex = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME, REGION_NAME, \"text\");\n     };\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n-    dataStore2.invoke(() -> initDataStore(createIndex));\n-    accessor.invoke(() -> initAccessor(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionTestType));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionTestType));\n+    accessor.invoke(() -> initAccessor(createIndex, regionTestType));\n     putDataInRegion(accessor);\n     assertTrue(waitForFlushBeforeExecuteTextSearch(accessor, 60000));\n     assertTrue(waitForFlushBeforeExecuteTextSearch(dataStore1, 60000));\n@@ -88,14 +81,15 @@ public void defaultFieldShouldPropogateCorrectlyThroughFunction() {\n   }\n \n   @Test\n-  public void canQueryWithCustomLuceneQueryObject() {\n+  @Parameters(method = \"getListOfRegionTestTypes\")\n+  public void canQueryWithCustomLuceneQueryObject(RegionTestableType regionTestType) {\n     SerializableRunnableIF createIndex = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME, REGION_NAME, \"text\");\n     };\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n-    dataStore2.invoke(() -> initDataStore(createIndex));\n-    accessor.invoke(() -> initAccessor(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionTestType));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionTestType));\n+    accessor.invoke(() -> initAccessor(createIndex, regionTestType));\n     putDataInRegion(accessor);\n     assertTrue(waitForFlushBeforeExecuteTextSearch(accessor, 60000));\n     assertTrue(waitForFlushBeforeExecuteTextSearch(dataStore1, 60000));\n@@ -114,14 +108,16 @@ public void canQueryWithCustomLuceneQueryObject() {\n   }\n \n   @Test\n-  public void verifyWaitForFlushedFunctionOnAccessor() throws InterruptedException {\n+  @Parameters(method = \"getListOfRegionTestTypes\")\n+  public void verifyWaitForFlushedFunctionOnAccessor(RegionTestableType regionTestType)\n+      throws InterruptedException {\n     SerializableRunnableIF createIndex = () -> {\n       LuceneService luceneService = LuceneServiceProvider.get(getCache());\n       luceneService.createIndex(INDEX_NAME, REGION_NAME, \"text\");\n     };\n-    dataStore1.invoke(() -> initDataStore(createIndex));\n-    dataStore2.invoke(() -> initDataStore(createIndex));\n-    accessor.invoke(() -> initAccessor(createIndex));\n+    dataStore1.invoke(() -> initDataStore(createIndex, regionTestType));\n+    dataStore2.invoke(() -> initDataStore(createIndex, regionTestType));\n+    accessor.invoke(() -> initAccessor(createIndex, regionTestType));\n     dataStore1.invoke(() -> LuceneTestUtilities.pauseSender(getCache()));\n     dataStore2.invoke(() -> LuceneTestUtilities.pauseSender(getCache()));\n     putDataInRegion(accessor);\n@@ -133,55 +129,6 @@ public void verifyWaitForFlushedFunctionOnAccessor() throws InterruptedException\n     executeTextSearch(accessor, \"world\", \"noEntriesMapped\", 0);\n   }\n \n-  protected boolean waitForFlushBeforeExecuteTextSearch(VM vm, int ms) {\n-    return vm.invoke(() -> {\n-      Cache cache = getCache();\n-\n-      LuceneService service = LuceneServiceProvider.get(cache);\n-      LuceneIndexImpl index = (LuceneIndexImpl) service.getIndex(INDEX_NAME, REGION_NAME);\n-\n-      return service.waitUntilFlushed(INDEX_NAME, REGION_NAME, ms, TimeUnit.MILLISECONDS);\n-    });\n-  }\n-\n-  protected void executeTextSearch(VM vm) {\n-    vm.invoke(() -> {\n-      Cache cache = getCache();\n-      Region<Object, Object> region = cache.getRegion(REGION_NAME);\n-\n-      LuceneService service = LuceneServiceProvider.get(cache);\n-      LuceneQuery<Integer, TestObject> query;\n-      query = service.createLuceneQueryFactory().create(INDEX_NAME, REGION_NAME, \"text:world\",\n-          DEFAULT_FIELD);\n-      PageableLuceneQueryResults<Integer, TestObject> results = query.findPages();\n-      assertEquals(3, results.size());\n-      List<LuceneResultStruct<Integer, TestObject>> page = results.next();\n-\n-      Map<Integer, TestObject> data = new HashMap<Integer, TestObject>();\n-      for (LuceneResultStruct<Integer, TestObject> row : page) {\n-        data.put(row.getKey(), row.getValue());\n-      }\n-\n-      assertEquals(new HashMap(region), data);\n-      return null;\n-    });\n-  }\n-\n-  protected void executeTextSearch(VM vm, String queryString, String defaultField,\n-      int expectedResultsSize) {\n-    vm.invoke(() -> {\n-      Cache cache = getCache();\n-\n-      LuceneService service = LuceneServiceProvider.get(cache);\n-      LuceneQuery<Integer, TestObject> query;\n-      query = service.createLuceneQueryFactory().setResultLimit(1000).setPageSize(1000)\n-          .create(INDEX_NAME, REGION_NAME, queryString, defaultField);\n-      Collection<?> results = query.findKeys();\n-\n-      assertEquals(expectedResultsSize, results.size());\n-    });\n-  }\n-\n   protected void putDataInRegion(VM vm) {\n     vm.invoke(() -> {\n       final Cache cache = getCache();\n@@ -192,42 +139,4 @@ protected void putDataInRegion(VM vm) {\n     });\n   }\n \n-  protected static class TestObject implements Serializable {\n-    private static final long serialVersionUID = 1L;\n-    private String text;\n-\n-    public TestObject(String text) {\n-      this.text = text;\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-      final int prime = 31;\n-      int result = 1;\n-      result = prime * result + ((text == null) ? 0 : text.hashCode());\n-      return result;\n-    }\n-\n-    @Override\n-    public boolean equals(Object obj) {\n-      if (this == obj)\n-        return true;\n-      if (obj == null)\n-        return false;\n-      if (getClass() != obj.getClass())\n-        return false;\n-      TestObject other = (TestObject) obj;\n-      if (text == null) {\n-        if (other.text != null)\n-          return false;\n-      } else if (!text.equals(other.text))\n-        return false;\n-      return true;\n-    }\n-\n-    @Override\n-    public String toString() {\n-      return \"TestObject[\" + text + \"]\";\n-    }\n-  }\n }",
                "previous_filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesBase.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesDUnitTest.java",
                "sha": "5db2ed4331b68a6eac5067242f7eb42453626f39",
                "status": "renamed"
            },
            {
                "additions": 41,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesIntegrationTest.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesIntegrationTest.java",
                "patch": "@@ -29,6 +29,9 @@\n import java.util.concurrent.TimeUnit;\n import java.util.stream.Collectors;\n \n+import org.apache.geode.cache.CacheLoader;\n+import org.apache.geode.cache.CacheLoaderException;\n+import org.apache.geode.cache.LoaderHelper;\n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.Tokenizer;\n@@ -362,6 +365,44 @@ public void shouldReturnCorrectResultsOnDeletionAfterQueryExecution() throws Exc\n         allEntries.stream().map(entry -> entry.getValue()).collect(Collectors.toSet()));\n   }\n \n+  @Test\n+  public void shouldReturnCorrectResultsOnDeletionAfterQueryExecutionWithLoader() throws Exception {\n+    final int pageSize = 2;\n+    final LuceneQuery<Object, Object> query = addValuesAndCreateQuery(pageSize);\n+    region.getAttributesMutator().setCacheLoader(new CacheLoader() {\n+      @Override\n+      public Object load(final LoaderHelper helper) throws CacheLoaderException {\n+        return new TestObject(\"should not\", \"load this\");\n+      }\n+\n+      @Override\n+      public void close() {\n+\n+      }\n+    });\n+    final PageableLuceneQueryResults<Object, Object> pages = query.findPages();\n+    List<LuceneResultStruct<Object, Object>> allEntries = new ArrayList<>();\n+    assertTrue(pages.hasNext());\n+    assertEquals(7, pages.size());\n+    // Destroying an entry from the region after the query is executed.\n+    region.destroy(\"C\");\n+    final List<LuceneResultStruct<Object, Object>> page1 = pages.next();\n+    assertEquals(pageSize, page1.size());\n+    final List<LuceneResultStruct<Object, Object>> page2 = pages.next();\n+    assertEquals(pageSize, page2.size());\n+    final List<LuceneResultStruct<Object, Object>> page3 = pages.next();\n+    assertEquals(pageSize, page3.size());\n+    assertFalse(pages.hasNext());\n+\n+    allEntries.addAll(page1);\n+    allEntries.addAll(page2);\n+    allEntries.addAll(page3);\n+    assertEquals(region.keySet(),\n+        allEntries.stream().map(entry -> entry.getKey()).collect(Collectors.toSet()));\n+    assertEquals(region.values(),\n+        allEntries.stream().map(entry -> entry.getValue()).collect(Collectors.toSet()));\n+  }\n+\n   @Test\n   public void shouldReturnCorrectResultsOnMultipleDeletionsAfterQueryExecution() throws Exception {\n     final LuceneQuery<Object, Object> query = addValuesAndCreateQuery(2);",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesIntegrationTest.java",
                "sha": "6420307ec08403e089bd070101556a296e3d35f3",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerFixedPRDUnitTest.java",
                "changes": 39,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerFixedPRDUnitTest.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 39,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerFixedPRDUnitTest.java",
                "patch": "@@ -1,39 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.cache.lucene;\n-\n-import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.REGION_NAME;\n-\n-import org.apache.geode.cache.lucene.test.LuceneTestUtilities;\n-import org.apache.geode.test.dunit.SerializableRunnableIF;\n-import org.apache.geode.test.junit.categories.DistributedTest;\n-import org.junit.experimental.categories.Category;\n-\n-@Category(DistributedTest.class)\n-public class LuceneQueriesPeerFixedPRDUnitTest extends LuceneQueriesPeerPRRedundancyDUnitTest {\n-\n-  @Override\n-  protected void initAccessor(SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache();\n-    LuceneTestUtilities.createFixedPartitionedRegion(getCache(), REGION_NAME, null, 0);\n-  }\n-\n-  @Override\n-  protected void initDataStore(SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    LuceneTestUtilities.initDataStoreForFixedPR(getCache());\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerFixedPRDUnitTest.java",
                "sha": "2622063bc162a396f3468b03695f3c1413a33a72",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRDUnitTest.java",
                "changes": 41,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRDUnitTest.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 41,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRDUnitTest.java",
                "patch": "@@ -1,41 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.cache.lucene;\n-\n-import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.REGION_NAME;\n-\n-import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.test.dunit.SerializableRunnableIF;\n-import org.apache.geode.test.junit.categories.DistributedTest;\n-\n-import org.junit.experimental.categories.Category;\n-\n-@Category(DistributedTest.class)\n-public class LuceneQueriesPeerPRDUnitTest extends LuceneQueriesPRBase {\n-\n-  @Override\n-  protected void initDataStore(final SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache().createRegionFactory(RegionShortcut.PARTITION)\n-        .setPartitionAttributes(getPartitionAttributes(false)).create(REGION_NAME);\n-  }\n-\n-  @Override\n-  protected void initAccessor(final SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache().createRegionFactory(RegionShortcut.PARTITION_PROXY)\n-        .setPartitionAttributes(getPartitionAttributes(true)).create(REGION_NAME);\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRDUnitTest.java",
                "sha": "f65777fe81205ef5f7e112ef8c1037591218c7e9",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPROverflowDUnitTest.java",
                "changes": 46,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPROverflowDUnitTest.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 46,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPROverflowDUnitTest.java",
                "patch": "@@ -1,46 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.cache.lucene;\n-\n-import static org.apache.geode.cache.lucene.test.LuceneTestUtilities.*;\n-\n-import org.apache.geode.cache.EvictionAction;\n-import org.apache.geode.cache.EvictionAttributes;\n-import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.test.dunit.SerializableRunnableIF;\n-import org.apache.geode.test.junit.categories.DistributedTest;\n-\n-import org.junit.experimental.categories.Category;\n-\n-@Category(DistributedTest.class)\n-public class LuceneQueriesPeerPROverflowDUnitTest extends LuceneQueriesPRBase {\n-\n-  @Override\n-  protected void initDataStore(final SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    EvictionAttributes evicAttr =\n-        EvictionAttributes.createLRUEntryAttributes(1, EvictionAction.OVERFLOW_TO_DISK);\n-    getCache().createRegionFactory(RegionShortcut.PARTITION_OVERFLOW)\n-        .setPartitionAttributes(getPartitionAttributes(false)).setEvictionAttributes(evicAttr)\n-        .create(REGION_NAME);\n-  }\n-\n-  @Override\n-  protected void initAccessor(final SerializableRunnableIF createIndex) throws Exception {\n-    createIndex.run();\n-    getCache().createRegionFactory(RegionShortcut.PARTITION_PROXY)\n-        .setPartitionAttributes(getPartitionAttributes(true)).create(REGION_NAME);\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPROverflowDUnitTest.java",
                "sha": "86ce713102e741b9f83bfc5bac3eea884534a10f",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRPersistentDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRPersistentDUnitTest.java?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRPersistentDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRPersistentDUnitTest.java",
                "sha": "4e809cef4c191b081aad87efc8e908bf096a5c80",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/PaginationDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/PaginationDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/PaginationDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/PaginationDUnitTest.java",
                "sha": "3ff86f7501d43f909e58e39637ffa8cdef7b1ccb",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceDUnitTest.java",
                "previous_filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPRBase.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceDUnitTest.java",
                "sha": "0142b37f52aea05d6ffc9feb24df52f60ab7282d",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceWithRedundancyDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceWithRedundancyDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceWithRedundancyDUnitTest.java",
                "previous_filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/LuceneQueriesPeerPRRedundancyDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/RebalanceWithRedundancyDUnitTest.java",
                "sha": "8ee14cb4e02e85a0573042dae5f43dc41683d573",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneEventListenerJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneEventListenerJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneEventListenerJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneEventListenerJUnitTest.java",
                "sha": "03200688ec204e1e2a69193461b254947c43e7ff",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneIndexFactorySpy.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneIndexFactorySpy.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneIndexFactorySpy.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneIndexFactorySpy.java",
                "sha": "5c6d256c546e6b022022452e20efd3d085b2b466",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImplJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImplJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImplJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryFactoryImplJUnitTest.java",
                "sha": "ccc5bb7a1d6e963d02206637ac463397399826f5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryImplJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryImplJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryImplJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneQueryImplJUnitTest.java",
                "sha": "20f5d1d5360bd43b307509ae07c805ae3beb7b94",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplIntegrationTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplIntegrationTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplIntegrationTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplIntegrationTest.java",
                "sha": "9b382e6140983a691a70b959d8094c10bb3254a4",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImplJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImplJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImplJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/PageableLuceneQueryResultsImplJUnitTest.java",
                "sha": "bc38112635d4ebcf4446412cfd19eba9f2bec4d0",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsDUnitTest.java",
                "sha": "efc11ab4fdfd959520572d6bf43fe7844ac3dc13",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/LuceneIndexCommandsJUnitTest.java",
                "sha": "9e8d7a99c270cc8031522da5470ef46da4556c44",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunctionJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunctionJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunctionJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/cli/functions/LuceneDestroyIndexFunctionJUnitTest.java",
                "sha": "f86f4a19c255d5bdf7158a84c822f693ab824280",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/configuration/LuceneClusterConfigurationDUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/configuration/LuceneClusterConfigurationDUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/configuration/LuceneClusterConfigurationDUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/configuration/LuceneClusterConfigurationDUnitTest.java",
                "sha": "1a344db6be8003fe21bb505362e77a1864e88264",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionContextJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionContextJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionContextJUnitTest.java",
                "previous_filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneFunctionContextJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionContextJUnitTest.java",
                "sha": "ed77ed774d7c1eb4ea3d91ba61124755dbc8722a",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "previous_filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneFunctionJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "sha": "6a9af9b3e5f99f737ef51d4bf833e0547a8f80a8",
                "status": "renamed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunctionJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunctionJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunctionJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/LuceneGetPageFunctionJUnitTest.java",
                "sha": "5f1ca3f85b12bbe37f16d053c4efc0d708b5d28f",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageEntryJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageEntryJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageEntryJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageEntryJUnitTest.java",
                "sha": "6e26942323e5faae21bf26e234c4dce5e7c8cf51",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageResultsJUnitTest.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageResultsJUnitTest.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageResultsJUnitTest.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/results/PageResultsJUnitTest.java",
                "sha": "778e37203c88350fde090e8ec1d1e866e6a47b78",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-lucene/src/test/java/org/apache/geode/cache/lucene/test/LuceneTestUtilities.java",
                "sha": "329dee92c408a5c69063a0e70835a7e035be814f",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-pulse/src/main/webapp/META-INF/NOTICE",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-pulse/src/main/webapp/META-INF/NOTICE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-pulse/src/main/webapp/META-INF/NOTICE",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-pulse/src/main/webapp/META-INF/NOTICE",
                "sha": "1d161e9bdbdfd56d9f919ac86c5b975d8aae3edf",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/.gitignore",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/.gitignore?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/.gitignore",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/.gitignore",
                "sha": "426f0fcd123e302b0ea7db2a9a2677d14445dc63",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/.gitignore",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/.gitignore?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/.gitignore",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/.gitignore",
                "sha": "3fec32c842751033d92c8967eba40c3911333a78",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/README.md",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/README.md?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/README.md",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/README.md",
                "sha": "1f93e24baf9d30bf294dc16f5caf67f93ac9d9cd",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/Rules",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/Rules?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/Rules",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/Rules",
                "sha": "56036843710749910d30111fdc2ab4ea121328bf",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/build.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/build.sh?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/build.sh",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/build.sh",
                "sha": "00a9ed0e5f1b41fd1046e7281aa056dc1abb2c09",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/bootstrap/bootstrap.min.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/bootstrap/bootstrap.min.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/bootstrap/bootstrap.min.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/bootstrap/bootstrap.min.css",
                "sha": "93c646fe1e4e505ee6af5ecfe82ec45da45b997f",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/community/index.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/community/index.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/community/index.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/community/index.html",
                "sha": "3ad8ee2f27b20b40911883989207165f3c53a0f7",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat-extensions.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/css/bootflat-extensions.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/css/bootflat-extensions.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat-extensions.css",
                "sha": "513ecaa1b5f59b3d243dd64434b5c73a5224055c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat-square.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/css/bootflat-square.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/css/bootflat-square.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat-square.css",
                "sha": "0e448ab9667e612c9ef8db26691883d08606cba8",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/css/bootflat.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/css/bootflat.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/bootflat.css",
                "sha": "0f2f45efd0467ddf81aca113d10fa13bc7337c99",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/font-awesome.min.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/css/font-awesome.min.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/css/font-awesome.min.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/font-awesome.min.css",
                "sha": "3fdf08a72c4269d300008af474d75505a261c165",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/geode-site.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/css/geode-site.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/css/geode-site.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/css/geode-site.css",
                "sha": "bfb9ba99cfe7dbd661ad120e30044d6520b31d69",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/docs/index.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/docs/index.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/docs/index.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/docs/index.html",
                "sha": "9b4a69b00116b9eb782c05e7371290a8de9b0a3d",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/favicon.ico",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/favicon.ico?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/favicon.ico",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/favicon.ico",
                "sha": "392c7576f3799cc0191f54ba479c908f0be225a5",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/FontAwesome.otf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/FontAwesome.otf?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/FontAwesome.otf",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/FontAwesome.otf",
                "sha": "d4de13e832d567ff29c5b4e9561b8c370348cc9c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-eot.eot",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/fontawesome-webfont-eot.eot?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/fontawesome-webfont-eot.eot",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-eot.eot",
                "sha": "c7b00d2ba8896fd29de846b19f89fcf0d56ad152",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-svg.svg",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/fontawesome-webfont-svg.svg?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/fontawesome-webfont-svg.svg",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-svg.svg",
                "sha": "8b66187fe067c3aa389ce8c98108f349ceae159c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-ttf.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/fontawesome-webfont-ttf.ttf?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/fontawesome-webfont-ttf.ttf",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-ttf.ttf",
                "sha": "f221e50a2ef60738ba30932d834530cdfe55cb3e",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-woff.woff",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/fontawesome-webfont-woff.woff?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/fontawesome-webfont-woff.woff",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont-woff.woff",
                "sha": "6e7483cf61b490c08ed644d6ef802c69472eb247",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont.woff2",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/font/fontawesome-webfont.woff2?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/font/fontawesome-webfont.woff2",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/font/fontawesome-webfont.woff2",
                "sha": "7eb74fd127ee5eddf3b95fee6a20dc1684b0963b",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.eot",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.eot?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/fonts/font-awesome/fontawesome-webfont.eot",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.eot",
                "sha": "4faa486041ca2750fe47fb41a1d56bf2028e6bea",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.svg",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.svg?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/fonts/font-awesome/fontawesome-webfont.svg",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.svg",
                "sha": "d32830cb9e23a61632ca5535ed3605e79a4d6fb9",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.ttf",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.ttf?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/fonts/font-awesome/fontawesome-webfont.ttf",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.ttf",
                "sha": "9d02852c14143d311bbc4fc1f9a7c6aaf6b6d3b2",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff",
                "sha": "1b92d42f98682b1f8760edca3f472c90d200eceb",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff2",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff2?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff2",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/fonts/font-awesome/fontawesome-webfont.woff2",
                "sha": "88095c7612b30b8ed52694e433aac52ffbb3a70a",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/images/favicon.ico",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/images/favicon.ico?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/images/favicon.ico",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/images/favicon.ico",
                "sha": "00aa6300c26aaa724460a08a68bce7fb35f51fcc",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/apache_geode_logo.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/apache_geode_logo.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo.png",
                "sha": "14b6ac05bdddd26209d9a48bbd624935d0d79c2d",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo_white.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/apache_geode_logo_white.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/apache_geode_logo_white.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo_white.png",
                "sha": "2a0cda8ad4b20833e7430b060b2aa603f1f59339",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo_white_small.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/apache_geode_logo_white_small.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/apache_geode_logo_white_small.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/apache_geode_logo_white_small.png",
                "sha": "bf8aaa004bc5a7177fbc6ffd2d5fa43082155c24",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/asf_logo.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/asf_logo.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/asf_logo.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/asf_logo.png",
                "sha": "8dca81302df636f198bf408cd5d4b0f047a72a17",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/check_flat/default.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/check_flat/default.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/check_flat/default.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/check_flat/default.png",
                "sha": "5a897651595170a650c18c7e1e6150c965f98ab2",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/github.png",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/img/github.png?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/img/github.png",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/img/github.png",
                "sha": "f19ee0df7d963247cf8a99ff34d5d40b4614ee6c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/index.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/index.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/index.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/index.html",
                "sha": "55311d77aafa7e9065e27130b8662987b90e2563",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/all.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/all.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/all.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/all.js",
                "sha": "7300c7edf6ead3389fa9b5147e790d77077e6593",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/book.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/book.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/book.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/book.js",
                "sha": "20ccd63ee826b939e2241dc83c6ecb3c7a98cb49",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/bookbinder.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/bookbinder.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/bookbinder.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/bookbinder.js",
                "sha": "885c586085220d56819d9a68529fdb378716acc9",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/context.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/waypoints/context.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/waypoints/context.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/context.js",
                "sha": "a4362ddd7f31025190e65751e505e2e9236c20fa",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/group.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/waypoints/group.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/waypoints/group.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/group.js",
                "sha": "3dc9b196a22b340e42a71248b3278e422d4feb08",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/noframeworkAdapter.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/waypoints/noframeworkAdapter.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/waypoints/noframeworkAdapter.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/noframeworkAdapter.js",
                "sha": "cef93a1ca318b4c64cb61bc6f75bec885b10ce09",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/sticky.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/waypoints/sticky.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/waypoints/sticky.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/sticky.js",
                "sha": "7ca63c3dda117b4ecc081d3ad4a1c56b495f706c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/waypoint.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/javascripts/waypoints/waypoint.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/javascripts/waypoints/waypoint.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/javascripts/waypoints/waypoint.js",
                "sha": "9de3c38bb3a42e10f8ef414c9518fdac71df0c8c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/bootstrap.min.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/bootstrap.min.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/bootstrap.min.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/bootstrap.min.js",
                "sha": "9c5849624b0818c55cf24ed7ed68f4ececd0acff",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/head.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/head.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/head.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/head.js",
                "sha": "aa15cb82543dac7112a9179c5e58668e6ccffca9",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/html5shiv.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/html5shiv.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/html5shiv.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/html5shiv.js",
                "sha": "784f221caf83c7b22d5af716ffb2af11d7b14d57",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/jquery-1.10.1.min.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/jquery-1.10.1.min.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/jquery-1.10.1.min.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/jquery-1.10.1.min.js",
                "sha": "e407e7699240159f728d40f453901aa3eaf6ab8e",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/jquery.icheck.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/jquery.icheck.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/jquery.icheck.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/jquery.icheck.js",
                "sha": "c92faa0c2db2119d3991c9592b4eb5979464f4a6",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/respond.min.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/respond.min.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/respond.min.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/respond.min.js",
                "sha": "8353e994d1ad98148c1c04c2c985dd0c4790adff",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/usergrid-site.js",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/js/usergrid-site.js?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/js/usergrid-site.js",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/js/usergrid-site.js",
                "sha": "115768a1f5d5d00c98289d8620884003c3bd0121",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/releases/index.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/releases/index.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/releases/index.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/releases/index.html",
                "sha": "28ee33f843a028b7c749c0b4109b90480d9f193e",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/schema/cache/cache-1.0.xsd",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/schema/cache/cache-1.0.xsd?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/schema/cache/cache-1.0.xsd",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/schema/cache/cache-1.0.xsd",
                "sha": "e4a59ff2279b7b5a77fc98dbacbc1f2e6e9b3ecb",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/schema/cache/lucene-1.0.xsd",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/schema/cache/lucene-1.0.xsd?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/schema/cache/lucene-1.0.xsd",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/schema/cache/lucene-1.0.xsd",
                "sha": "ec82c2fe9e29f27a0447cb76e1d98f8540276cf2",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/all.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/all.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/all.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/all.css",
                "sha": "cb1ad39a9c848c5ef64d6da8ecea4199ad38f4ae",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/base",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/base?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/base",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/base",
                "sha": "36796fed9c522851809b1f55fabcefa2de2fc2b2",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/book-styles",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/book-styles?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/book-styles",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/book-styles",
                "sha": "ae2f22436f62a4445d99ce2d66ddd0506d97d946",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/layout-styles",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/layout-styles?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/layout-styles",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/layout-styles",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print-book-styles",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/print-book-styles?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/print-book-styles",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print-book-styles",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print-layout-styles",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/print-layout-styles?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/print-layout-styles",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print-layout-styles",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print.css",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/stylesheets/print.css?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/stylesheets/print.css",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/stylesheets/print.css",
                "sha": "634ade095143e6de6a03a2d4ff22b3fd5083db29",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/subnavs/geode-subnav",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/content/subnavs/geode-subnav?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/content/subnavs/geode-subnav",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/content/subnavs/geode-subnav",
                "sha": "3711fff1ba9e9b47e1b26f25f86c843726ea834f",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/community.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/community.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/community.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/community.html",
                "sha": "8f3d6f67543362f109cc95188d540d3fb3adcd9b",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/default.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/default.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/default.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/default.html",
                "sha": "0df020aacd8c848686066f11bc46f54357cfb44c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/docs.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/docs.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/docs.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/docs.html",
                "sha": "ddfaf8aa666a08e28f754045ccc925a68f129f4c",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/footer.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/footer.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/footer.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/footer.html",
                "sha": "89e9a64c3f67e9bdd37a9e9bfb9dd494e8f54e83",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/header.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/header.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/header.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/header.html",
                "sha": "ea15471d903e5c37a70514c4bd6c22545644e065",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/releases.html",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/layouts/releases.html?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/layouts/releases.html",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/layouts/releases.html",
                "sha": "fa58ee99a0c8f36b9ebc19ab89d971a034fe0f8e",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/default.rb",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/lib/default.rb?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/lib/default.rb",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/default.rb",
                "sha": "95383f23ad747a9cf53e9a97bff50e49e74fc37b",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/helpers_.rb",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/lib/helpers_.rb?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/lib/helpers_.rb",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/helpers_.rb",
                "sha": "13a83393a9124bf6ec36540556b4808abd47e206",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/pandoc.template",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/lib/pandoc.template?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/lib/pandoc.template",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/lib/pandoc.template",
                "sha": "382b0910eb804439f6be2d4d714c10d2a36d20b2",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/nanoc.yaml",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/nanoc.yaml?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/nanoc.yaml",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/nanoc.yaml",
                "sha": "5fcc351009c824264b4862ff3c4e6ba2481241f8",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/run.sh",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/run.sh?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/run.sh",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/run.sh",
                "sha": "cecf19e56f07f66c0ec3c90d6942b98fe74ed108",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/map-markers.rb",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/utilities/map-markers.rb?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/utilities/map-markers.rb",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/map-markers.rb",
                "sha": "19e2306c004aa8848eefd326a767de31c5595215",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/markers.txt",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/utilities/markers.txt?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/utilities/markers.txt",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/markers.txt",
                "sha": "994555d504dd4a364f3f660385c46ef05e6b4876",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/snapshot-apigee.rb",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-site/website/utilities/snapshot-apigee.rb?ref=c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
                "deletions": 0,
                "filename": "geode-site/website/utilities/snapshot-apigee.rb",
                "raw_url": "https://github.com/apache/geode/raw/c3dbd742cde95a2aa9266990d6c42f4ce359cea2/geode-site/website/utilities/snapshot-apigee.rb",
                "sha": "4adf0ca163a3f386a7f31a2e7e0bdcaa3945b63a",
                "status": "removed"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/WANTestBase.java",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/WANTestBase.java?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-wan/src/test/java/org/apache/geode/internal/cache/wan/WANTestBase.java",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/WANTestBase.java",
                "sha": "f0704e8ef7ce7c64cd0a0b08166d13c435139822",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web-api/build.gradle",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-web-api/build.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-web-api/build.gradle",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web-api/build.gradle",
                "sha": "795812fbad83a6f04ea4a5cf72d15c915ba215a9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web-api/src/main/webapp/META-INF/NOTICE",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-web-api/src/main/webapp/META-INF/NOTICE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-web-api/src/main/webapp/META-INF/NOTICE",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web-api/src/main/webapp/META-INF/NOTICE",
                "sha": "8070e9b05f0e83d5a249a916ad80f51c3c9e62f1",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web/src/main/webapp/META-INF/NOTICE",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-web/src/main/webapp/META-INF/NOTICE?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "geode-web/src/main/webapp/META-INF/NOTICE",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/geode-web/src/main/webapp/META-INF/NOTICE",
                "sha": "8a36d554426398ef0fe3aa8cc0c8e86951bd6778",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/dependency-versions.properties",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gradle/dependency-versions.properties?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "gradle/dependency-versions.properties",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/dependency-versions.properties",
                "sha": "aca65fa733bcb886b1579aab01e9bd873f1c411d",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/rat.gradle",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gradle/rat.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "gradle/rat.gradle",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/rat.gradle",
                "sha": "c97a9e9dc7857a51160757f01f20c1c9af80baed",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/test.gradle",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gradle/test.gradle?ref=635d3118177f6cae6b0497097e64bdb7a9aee800",
                "deletions": 0,
                "filename": "gradle/test.gradle",
                "raw_url": "https://github.com/apache/geode/raw/635d3118177f6cae6b0497097e64bdb7a9aee800/gradle/test.gradle",
                "sha": "fd44df8c167378e2eedd35a0eaeb22adab61da70",
                "status": "modified"
            }
        ],
        "message": "Merge branch 'develop' of https://git-wip-us.apache.org/repos/asf/geode into develop\n\n* 'develop' of https://git-wip-us.apache.org/repos/asf/geode: (57 commits)\n  GEODE-2551 Fix code issues found by AppChecker\n  Revert \"GEODE-1887: Now Size api goes through ServerProxy when cache is of type client and DataPolicy is Empty.\"\n  GEODE-2538: Don't deserialize values on the server when getting results\n  GEODE-2461: remove json4s-ast_2.10 as explicit dependency\n  GEODE-2547: Interest registration no longer causes a CacheLoader to be invoked\n  GEODE-2526: Enhance log statement to include ResourceTypeName\n  GEODE-880 Remove unused classes\n  GEODE-2460: update dependency versions\n  GEODE-1995: Removed ReliableMessageQueue, ReliableMessageQueueFactory, ReliableMessageQueueFactoryImpl and it's usage in the code from GemfireCacheImpl and DistributedRegion.\n  GEODE-2550 Improve README and BUILDING\n  GEODE-2538: Don't invoke a cache loader when fetching values for a lucene query\n  GEODE-2404: Added support for destroying lucene indexes\n  GEODE-2545: NPE during lucene query execution when cache is closing or region is destroyed\n  GEODE-2515: Disabling BaseLineAndCompareQueryPerfJUnitTest\n  GEODE-2142: Removing JSON licence stuff from NOTICE files\n  GEODE-2142: removing tests so run precheckin\n  GEODE-2142: final compiling build\n  GEODE-2142: cyclical dependency in gradle build\n  GEODE-2142: spotless\n  GEODE-2142: Refactoring of tests to work with new JSONObject class. Changing file export to use Base64 encoding.\n  ...",
        "parent": "https://github.com/apache/geode/commit/c3dbd742cde95a2aa9266990d6c42f4ce359cea2",
        "patched_files": [
            "HTTPTokener.java",
            "CDL.java",
            "InternalLuceneIndex.java",
            "IndexRepositoryImpl.java",
            "OpType.java",
            "CookieList.java",
            "fontawesome-webfont-eot.java",
            "JSONWriter.java",
            "bootstrap.java",
            "print.java",
            "XML.java",
            "SendQueueOperation.java",
            "releases.java",
            "markers.java",
            "favicon.java",
            "LuceneDestroyIndexFunction.java",
            "usergrid-site.java",
            "DiskInitFile.java",
            "book.java",
            "DistributedRemoveAllOperation.java",
            "TombstoneService.java",
            "FindCoordinatorResponse.java",
            "geode-site.java",
            "cache-1.java",
            "PersistentReplicatedTestBase.java",
            "FixedPartitioningTestBase.java",
            "FontAwesome.java",
            "fontawesome-webfont-woff.java",
            "jquery.java",
            "respond.java",
            "PRTombstoneMessage.java",
            "book-styles.java",
            "LuceneIndexCommands.java",
            "ReliableMessageQueueFactoryImpl.java",
            "LuceneFunctionSerializable.java",
            "ReliableMessageQueue.java",
            "Locator.java",
            "HTTP.java",
            "QueryTestUtils.java",
            "DataSerializableFixedID.java",
            "AsyncEventQueueImpl.java",
            "DistributedCacheOperation.java",
            "bootflat-square.java",
            "UpdateEntryVersionOperation.java",
            "LongBuffer.java",
            "LuceneQueriesAccessorBase.java",
            "CliUtil.java",
            "github.java",
            "ResultBuilder.java",
            "DestroyOperation.java",
            "GfJsonObject.java",
            "AbstractLauncherIntegrationTestCase.java",
            "DSFIDFactory.java",
            "GMSMembershipManager.java",
            "PersistentOplogSet.java",
            "JSON.java",
            "LuceneService.java",
            "LuceneQueryFunction.java",
            "apache_geode_logo_white.java",
            "AbstractResultData.java",
            "default.java",
            "head.java",
            "LuceneIndexImpl.java",
            "DiskRegionTestingBase.java",
            "LuceneIndexForPartitionedRegion.java",
            "BaseCommand.java",
            "Oplog.java",
            "MapResultCollector.java",
            "JsonUtil.java",
            "apache_geode_logo_white_small.java",
            "sticky.java",
            "footer.java",
            "map-markers.java",
            "LuceneIndexInfo.java",
            "UpdateOperation.java",
            "BucketRegion.java",
            "LuceneQueryImpl.java",
            "helpers_.java",
            "JSONStringer.java",
            "PageEntry.java",
            "bookbinder.java",
            "dependency-versions.java",
            "pandoc.java",
            "sample-01.java",
            "Cookie.java",
            "fontawesome-webfont.java",
            "geode-subnav.java",
            "StatArchiveHandler.java",
            "ParserUtils.java",
            "LuceneQuery.java",
            "GemFireCacheImpl.java",
            "ReliableDistributionData.java",
            "noframeworkAdapter.java",
            "expected_jars.java",
            "LuceneResultStructImpl.java",
            "LuceneEventListener.java",
            "Rules.java",
            "base.java",
            "LuceneQueryFactory.java",
            "all.java",
            "LuceneResultStruct.java",
            "LocalizedStrings.java",
            "LuceneQueryFactoryImpl.java",
            "JSONObject.java",
            "NOTICE.java",
            "build.java",
            "JSONML.java",
            "WaitUntilFlushedFunction.java",
            "fontawesome-webfont-ttf.java",
            "RestoreScript.java",
            "DistributedRegion.java",
            "asf_logo.java",
            "group.java",
            "TXCommitMessage.java",
            "ReliableMessageQueueFactory.java",
            "LuceneIndexDetails.java",
            "LuceneQueryInfo.java",
            "bootflat-extensions.java",
            "snapshot-apigee.java",
            "LuceneRawIndex.java",
            "rat.java",
            "JSONException.java",
            "nanoc.java",
            "JSONTokener.java",
            "ProcessManager.java",
            "RegionAdvisor.java",
            "LuceneExceptionObserver.java",
            "DestroyLuceneIndexMessage.java",
            "MainWithChildrenRollingFileHandler.java",
            "FileUtil.java",
            "BackupManager.java",
            "LuceneServiceImpl.java",
            "run.java",
            "docs.java",
            "PageResults.java",
            "Operation.java",
            "LuceneTestUtilities.java",
            "Services.java",
            "PageableLuceneQueryResultsImpl.java",
            "XMLTokener.java",
            "header.java",
            "index.java",
            "BUILDING.java",
            "InvalidateOperation.java",
            "LuceneIndexFactorySpy.java",
            "StatArchiveReader.java",
            "JavaExec.java",
            "font-awesome.java",
            "LuceneCliStrings.java",
            "DistributedPutAllOperation.java",
            "MergeLogFiles.java",
            "DistributionAdvisor.java",
            "waypoint.java",
            "print-layout-styles.java",
            "BatchDestroyOperation.java",
            "WANTestBase.java",
            "LuceneGetPageFunction.java",
            "fontawesome-webfont-svg.java",
            "PersistentPartitionedRegionTestBase.java",
            "jquery-1.java",
            "GMSLocator.java",
            ".java",
            "test.java",
            "layout-styles.java",
            "ProcessUtils.java",
            "JSONArray.java",
            "LICENSE.java",
            "context.java",
            "print-book-styles.java",
            "lucene-1.java",
            "AbstractRegion.java",
            "bootflat.java",
            "apache_geode_logo.java",
            "html5shiv.java",
            "README.java",
            "package-info.java",
            "DataSerializer.java",
            "community.java",
            "DiskStoreImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "TestDataSerializer.java",
            "PageableLuceneQueryResultsImplJUnitTest.java",
            "QueueCommandsDUnitTest.java",
            "BackupDUnitTest.java",
            "LogWriterLoggerPerformanceTest.java",
            "ClusterConfigurationServiceEndToEndDUnitTest.java",
            "LocatorDUnitTest.java",
            "LuceneQueryFunctionJUnitTest.java",
            "ClientServerCCEDUnitTest.java",
            "MainWithChildrenRollingFileHandlerIntegrationTest.java",
            "Log4J2PerformanceTest.java",
            "LuceneQueryImplJUnitTest.java",
            "RebalanceWithRedundancyDUnitTest.java",
            "FileUtilJUnitTest.java",
            "ClientCacheFactoryJUnitTest.java",
            "RollingUpgradeDUnitTest.java",
            "DiskStoreCommandsDUnitTest.java",
            "LuceneQueriesIntegrationTest.java",
            "LuceneQueriesPeerPRPersistentDUnitTest.java",
            "TestUtil.java",
            "PdxDeleteFieldDUnitTest.java",
            "LuceneQueriesPeerPROverflowDUnitTest.java",
            "JarDeployerDUnitTest.java",
            "LocatorUDPSecurityDUnitTest.java",
            "SSLSocketIntegrationTest.java",
            "SelectStarQueryDUnitTest.java",
            "CreateAlterDestroyRegionCommandsDUnitTest.java",
            "PdxAttributesJUnitTest.java",
            "LuceneIndexDestroyDUnitTest.java",
            "LuceneServiceImplIntegrationTest.java",
            "PageResultsJUnitTest.java",
            "QueryIndexUsingXMLDUnitTest.java",
            "PdxRenameJUnitTest.java",
            "StatArchiveWithMissingResourceTypeRegressionTest.java",
            "LuceneDestroyIndexFunctionJUnitTest.java",
            "BackupJUnitTest.java",
            "RebalanceDUnitTest.java",
            "PdxSerializableJUnitTest.java",
            "IncrementalBackupDUnitTest.java",
            "MiscellaneousCommandsExportLogsPart3DUnitTest.java",
            "UserCommandsDUnitTest.java",
            "JarDeployerIntegrationTest.java",
            "LuceneQueryFactoryImplJUnitTest.java",
            "DiskRegionAsyncRecoveryJUnitTest.java",
            "LuceneIndexCreationDUnitTest.java",
            "InterestListDUnitTest.java",
            "PersistentColocatedPartitionedRegionDUnitTest.java",
            "PageEntryJUnitTest.java",
            "GemFireCacheImplTest.java",
            "DataSerializableJUnitTest.java",
            "MiscellaneousCommandsExportLogsPart4DUnitTest.java",
            "LuceneIndexCreationOnFixedPRDUnitTest.java",
            "DiskSpaceLimitIntegrationTest.java",
            "LuceneQueriesClientDUnitTest.java",
            "LuceneQueriesPeerPRDUnitTest.java",
            "LuceneClusterConfigurationDUnitTest.java",
            "BackupInspectorJUnitTest.java",
            "LuceneGetPageFunctionJUnitTest.java",
            "ClearTXLockingDUnitTest.java",
            "InstallerJUnitTest.java",
            "LuceneIndexForPartitionedRegionTest.java",
            "IndexCreationJUnitTest.java",
            "DistributionManagerDUnitTest.java",
            "MiscellaneousCommandsExportLogsPart1DUnitTest.java",
            "BaseLineAndCompareQueryPerfJUnitTest.java",
            "LuceneDUnitTest.java",
            "PartitionedRegionStatsJUnitTest.java",
            "RollingUpgrade2DUnitTest.java",
            "OplogRVVJUnitTest.java",
            "MiscellaneousCommandsExportLogsPart2DUnitTest.java",
            "LuceneEventListenerJUnitTest.java",
            "PersistentPartitionedRegionJUnitTest.java",
            "LuceneQueriesDUnitTest.java",
            "BundledJarsJUnitTest.java",
            "PaginationDUnitTest.java",
            "LuceneQueryFunctionContextJUnitTest.java",
            "StatArchiveHandlerIntegrationTest.java",
            "LuceneQueriesPeerFixedPRDUnitTest.java",
            "LuceneIndexCommandsDUnitTest.java",
            "LuceneIndexCommandsJUnitTest.java",
            "PdxDeleteFieldJUnitTest.java",
            "PdxRenameDUnitTest.java"
        ]
    },
    "geode_638b058": {
        "bug_id": "geode_638b058",
        "commit": "https://github.com/apache/geode/commit/638b05840d388f7d6476bad7ea0729510b67aca3",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java?ref=638b05840d388f7d6476bad7ea0729510b67aca3",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "patch": "@@ -39,6 +39,7 @@\n import java.util.concurrent.atomic.AtomicLong;\n import java.util.concurrent.atomic.AtomicReference;\n \n+import org.apache.geode.cache.CacheXmlException;\n import org.apache.logging.log4j.Logger;\n \n import org.apache.geode.CancelCriterion;\n@@ -2741,6 +2742,12 @@ private void reconnect(boolean forcedDisconnect, String reason) {\n               } else {\n                 // this try failed. The new cache will call reconnect again\n               }\n+            } catch (CacheXmlException e) {\n+              logger.warn(\"Exception occured while trying to create the cache during reconnect\", e);\n+              reconnectDS.disconnect();\n+              reconnectDS = null;\n+              reconnectCancelled = true;\n+              break;\n             } catch (CancelException ignor) {\n               logger.warn(\"Exception occured while trying to create the cache during reconnect\",\n                   ignor);",
                "raw_url": "https://github.com/apache/geode/raw/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "sha": "fad9206583fdc093b1f74397c321442335cf80d4",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java?ref=638b05840d388f7d6476bad7ea0729510b67aca3",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "patch": "@@ -2500,6 +2500,9 @@ public void stopReconnecting() {\n   // see Cache.getReconnectedCache()\n   public Cache getReconnectedCache() {\n     GemFireCacheImpl c = GemFireCacheImpl.getInstance();\n+    if (c == null) {\n+      return null;\n+    }\n     if (c == this || !c.isInitialized()) {\n       c = null;\n     }",
                "raw_url": "https://github.com/apache/geode/raw/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "sha": "943a240055a7a1e6a30116679bd3a9a491ab80dd",
                "status": "modified"
            },
            {
                "additions": 69,
                "blob_url": "https://github.com/apache/geode/blob/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/test/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "changes": 72,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/cache30/ReconnectDUnitTest.java?ref=638b05840d388f7d6476bad7ea0729510b67aca3",
                "deletions": 3,
                "filename": "geode-core/src/test/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "patch": "@@ -1096,6 +1096,60 @@ public String description() {\n     });\n   }\n \n+  /**\n+   * GEODE-2155 Auto-reconnect fails with NPE due to a cache listener not implementing Declarable\n+   */\n+  @Test\n+  public void testReconnectFailsDueToBadCacheXML() throws Exception {\n+\n+    Host host = Host.getHost(0);\n+    VM vm0 = host.getVM(0);\n+    VM vm1 = host.getVM(1);\n+\n+    final int locPort = locatorPort;\n+\n+    final String xmlFileLoc = (new File(\".\")).getAbsolutePath();\n+\n+    SerializableRunnable createCache = new SerializableRunnable(\"Create Cache and Regions\") {\n+      public void run() {\n+        locatorPort = locPort;\n+        final Properties props = getDistributedSystemProperties();\n+        props.put(MAX_WAIT_TIME_RECONNECT, \"1000\");\n+        dsProperties = props;\n+        ReconnectDUnitTest.savedSystem = getSystem(props);\n+        ReconnectDUnitTest.savedCache = (GemFireCacheImpl) getCache();\n+        Region myRegion = createRegion(\"myRegion\", createAtts());\n+        myRegion.put(\"MyKey\", \"MyValue\");\n+        myRegion.getAttributesMutator().addCacheListener(new NonDeclarableListener());\n+      }\n+    };\n+\n+    vm0.invoke(createCache); // vm0 keeps the locator from losing quorum when vm1 crashes\n+\n+    createCache.run();\n+    IgnoredException.addIgnoredException(\n+        \"DistributedSystemDisconnectedException|ForcedDisconnectException\", vm1);\n+    forceDisconnect(null);\n+\n+    final GemFireCacheImpl cache = ReconnectDUnitTest.savedCache;\n+    Wait.waitForCriterion(new WaitCriterion() {\n+      public boolean done() {\n+        return cache.isReconnecting() || cache.getDistributedSystem().isReconnectCancelled();\n+      }\n+\n+      public String description() {\n+        return \"waiting for cache to begin reconnecting\";\n+      }\n+    }, 30000, 100, true);\n+    try {\n+      cache.waitUntilReconnected(20, TimeUnit.SECONDS);\n+    } catch (InterruptedException e) {\n+      fail(\"interrupted\");\n+    }\n+    assertTrue(cache.getDistributedSystem().isReconnectCancelled());\n+    assertNull(cache.getReconnectedCache());\n+  }\n+\n   private CacheSerializableRunnable getRoleAPlayerRunnable(final int locPort,\n       final String regionName, final String myKey, final String myValue,\n       final String startupMessage) {\n@@ -1200,8 +1254,8 @@ private void waitTimeout() throws InterruptedException {\n \n   }\n \n-  public boolean forceDisconnect(VM vm) {\n-    return (Boolean) vm.invoke(new SerializableCallable(\"crash distributed system\") {\n+  public boolean forceDisconnect(VM vm) throws Exception {\n+    SerializableCallable fd = new SerializableCallable(\"crash distributed system\") {\n       public Object call() throws Exception {\n         // since the system will disconnect and attempt to reconnect\n         // a new system the old reference to DTC.system can cause\n@@ -1224,7 +1278,12 @@ public String description() {\n         }\n         return true;\n       }\n-    });\n+    };\n+    if (vm != null) {\n+      return (Boolean) vm.invoke(fd);\n+    } else {\n+      return (Boolean) fd.call();\n+    }\n   }\n \n   private static int getPID() {\n@@ -1238,6 +1297,13 @@ private static int getPID() {\n     return 0;\n   }\n \n+  /**\n+   * A non-Declarable listener will be rejected by the XML parser when rebuilding the cache, causing\n+   * auto-reconnect to fail.\n+   */\n+  public static class NonDeclarableListener extends CacheListenerAdapter {\n+  }\n+\n   /**\n    * CacheKillingListener crashes the distributed system when it is invoked for the first time.\n    * After that it ignores any notifications.",
                "raw_url": "https://github.com/apache/geode/raw/638b05840d388f7d6476bad7ea0729510b67aca3/geode-core/src/test/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "sha": "d0ca831bfb2ec4c12f1d226060b16e45cf2a2190",
                "status": "modified"
            }
        ],
        "message": "GEODE-2155 Auto-reconnect fails with NPE\n\nI created a test to reproduce the problem by introducing a non-Declarable\ncache listener and then initiating a forced-disconnect.  cache.xml is\ngenerated and when it's used to rebuild the cache a CacheXmlException\nis thrown, reliably reproducing the problem.\n\nThe fix is to simply catch the CacheXmlException in\nInternalDistributedSystem.reconnect() and terminate reconnection attempt",
        "parent": "https://github.com/apache/geode/commit/0182a1bb744d25fe490d142dfed7d9a6f20b2713",
        "patched_files": [
            "InternalDistributedSystem.java",
            "GemFireCacheImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ReconnectDUnitTest.java",
            "GemFireCacheImplTest.java"
        ]
    },
    "geode_63d549b": {
        "bug_id": "geode_63d549b",
        "commit": "https://github.com/apache/geode/commit/63d549b4aab36fc9615fca659f33f5a0edfc93fb",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/63d549b4aab36fc9615fca659f33f5a0edfc93fb/geode-core/src/main/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgent.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgent.java?ref=63d549b4aab36fc9615fca659f33f5a0edfc93fb",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgent.java",
                "patch": "@@ -940,6 +940,11 @@ public InternalDistributedSystem getDSConnection() {\n     return system;\n   }\n \n+  @VisibleForTesting\n+  void setDSConnection(InternalDistributedSystem system) {\n+    this.system = system;\n+  }\n+\n   /**\n    * Handles a membership join asynchronously from the memberJoined notification. Sets and clears\n    * current join. Also makes several checks to support aborting of the current join.",
                "raw_url": "https://github.com/apache/geode/raw/63d549b4aab36fc9615fca659f33f5a0edfc93fb/geode-core/src/main/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgent.java",
                "sha": "cc54036457d39162a5f9a069743d7adc7f74c77b",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/63d549b4aab36fc9615fca659f33f5a0edfc93fb/geode-core/src/test/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgentTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgentTest.java?ref=63d549b4aab36fc9615fca659f33f5a0edfc93fb",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgentTest.java",
                "patch": "@@ -28,6 +28,7 @@\n import org.mockito.junit.MockitoJUnit;\n import org.mockito.junit.MockitoRule;\n \n+import org.apache.geode.CancelCriterion;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n import org.apache.geode.internal.admin.GfManagerAgentConfig;\n@@ -55,10 +56,13 @@ public void setUp() {\n \n     when(config.getLogWriter()).thenReturn(mock(InternalLogWriter.class));\n     when(config.getTransport()).thenReturn(mock(RemoteTransportConfig.class));\n+    when(system.getCancelCriterion()).thenReturn(mock(CancelCriterion.class));\n \n     agent = new RemoteGfManagerAgent(config, props -> system, agent -> mock(JoinProcessor.class),\n         agent -> mock(SnapshotResultDispatcher.class), agent -> mock(DSConnectionDaemon.class),\n         agent -> mock(MyMembershipListener.class));\n+\n+    agent.setDSConnection(system);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/63d549b4aab36fc9615fca659f33f5a0edfc93fb/geode-core/src/test/java/org/apache/geode/internal/admin/remote/RemoteGfManagerAgentTest.java",
                "sha": "ae4750533ef1b010e4f9aa8bd3160be2261e9d82",
                "status": "modified"
            }
        ],
        "message": "GEODE-7586: Fix NPE in RemoteGfManagerAgentTest (#4492)\n\nIf the thread invoking disconnect gets enough cpu cycles before the\r\nthread invoking removeMember, then it tries to invoke listApplications\r\nwith null for system.\r\n\r\nThe fix sets the system so the field is non-null which also simulates a\r\nreal run more closely as well.",
        "parent": "https://github.com/apache/geode/commit/0f05e9ccd94c04a205ace82de6616e9bffa92fa7",
        "patched_files": [
            "RemoteGfManagerAgent.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "RemoteGfManagerAgentTest.java"
        ]
    },
    "geode_65b416e": {
        "bug_id": "geode_65b416e",
        "commit": "https://github.com/apache/geode/commit/65b416e799aba2237f2ec9894f2cb7be2dace45e",
        "file": [
            {
                "additions": 84,
                "blob_url": "https://github.com/apache/geode/blob/65b416e799aba2237f2ec9894f2cb7be2dace45e/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "changes": 160,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java?ref=65b416e799aba2237f2ec9894f2cb7be2dace45e",
                "deletions": 76,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "patch": "@@ -12,19 +12,20 @@\n  * or implied. See the License for the specific language governing permissions and limitations under\n  * the License.\n  */\n-/*\n- * ClearRvvLockingDUnitTest.java\n- *\n- * Created on September 6, 2005, 2:57 PM\n- */\n package org.apache.geode.internal.cache;\n \n+import static org.apache.geode.test.dunit.VM.getController;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.apache.geode.test.dunit.internal.DUnitLauncher.getDistributedSystemProperties;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n import java.util.HashMap;\n-import java.util.Iterator;\n import java.util.Map;\n import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n-import org.assertj.core.api.JUnitSoftAssertions;\n+import org.junit.After;\n import org.junit.Before;\n import org.junit.Ignore;\n import org.junit.Rule;\n@@ -38,61 +39,73 @@\n import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.Scope;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n-import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.VM;\n-import org.apache.geode.test.dunit.cache.internal.JUnit4CacheTestCase;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n \n /**\n  * Test class to verify proper locking interaction between transactions and the CLEAR region\n  * operation.\n  *\n+ * <p>\n  * GEODE-1740: It was observed that operations performed within a transaction were not holding\n  * region modification locks for the duration of commit processing. This lock is used to ensure\n  * region consistency during CLEAR processing. By not holding the lock for the duration of commit\n  * processing, a window was opened that allowed region operations such as clear to occur in\n  * mid-commit.\n  *\n+ * <p>\n  * The fix for GEODE-1740 was to acquire and hold read locks for any region involved in the commit.\n  * This forces CLEAR to wait until commit processing is complete.\n+ *\n+ * <p>\n+ * This test performs operations within a transaction and during commit processing schedules a\n+ * clear to be performed on the relevant region. The scheduled clear should wait until commit\n+ * processing is complete before clearing the region. Failure to do so, would result in region\n+ * inconsistencies.\n  */\n @SuppressWarnings(\"serial\")\n+public class ClearTXLockingDUnitTest implements Serializable {\n \n-public class ClearTXLockingDUnitTest extends JUnit4CacheTestCase {\n-\n-  @Rule\n-  public transient JUnitSoftAssertions softly = new JUnitSoftAssertions();\n-  /*\n-   * This test performs operations within a transaction and during commit processing schedules a\n-   * clear to be performed on the relevant region. The scheduled clear should wait until commit\n-   * processing is complete before clearing the region. Failure to do so, would result in region\n-   * inconsistencies.\n-   */\n   private static final String THE_KEY = \"theKey\";\n   private static final String THE_VALUE = \"theValue\";\n   private static final int NUMBER_OF_PUTS = 2;\n   private static final String REGION_NAME1 = \"testRegion1\";\n   private static final String REGION_NAME2 = \"testRegion2\";\n \n-  static Cache cache;\n-  static CountDownLatch opsLatch;\n-  private static CountDownLatch regionLatch;\n-  private static CountDownLatch verifyLatch;\n+  private static final CountDownLatch opsLatch = new CountDownLatch(1);\n+  private static final CountDownLatch regionLatch = new CountDownLatch(1);\n+  private static final CountDownLatch verifyLatch = new CountDownLatch(1);\n+\n+  private static volatile InternalCache cache;\n \n   private VM vm0;\n   private VM vm1;\n   private VM opsVM;\n   private VM regionVM;\n \n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule();\n+\n   @Before\n-  public void setup() {\n-    Host host = Host.getHost(0);\n-    vm0 = host.getVM(0);\n-    vm1 = host.getVM(1);\n+  public void setUp() {\n+    vm0 = getVM(0);\n+    vm1 = getVM(1);\n \n     createCache(vm0);\n     createCache(vm1);\n   }\n \n+  @After\n+  public void tearDown() {\n+    for (VM vm : VM.toArray(vm0, vm1, getController())) {\n+      vm.invoke(() -> {\n+        opsLatch.countDown();\n+        regionLatch.countDown();\n+        verifyLatch.countDown();\n+      });\n+    }\n+  }\n+\n   @Test\n   public void testPutWithClearSameVM() {\n     setupRegions(vm0, vm0);\n@@ -107,7 +120,7 @@ public void testPutWithClearDifferentVM() {\n     performTestAndCheckResults();\n   }\n \n-  /*\n+  /**\n    * The CLOSE tests are ignored until the close operation has been updated to acquire a write lock\n    * during processing.\n    */\n@@ -119,6 +132,10 @@ public void testPutWithCloseSameVM() {\n     performTestAndCheckResults();\n   }\n \n+  /**\n+   * The CLOSE tests are ignored until the close operation has been updated to acquire a write lock\n+   * during processing.\n+   */\n   @Ignore\n   @Test\n   public void testPutWithCloseDifferentVM() {\n@@ -127,7 +144,7 @@ public void testPutWithCloseDifferentVM() {\n     performTestAndCheckResults();\n   }\n \n-  /*\n+  /**\n    * The DESTROY_REGION tests are ignored until the destroy operation has been updated to acquire a\n    * write lock during processing.\n    */\n@@ -139,6 +156,10 @@ public void testPutWithDestroyRegionSameVM() {\n     performTestAndCheckResults();\n   }\n \n+  /**\n+   * The DESTROY_REGION tests are ignored until the destroy operation has been updated to acquire a\n+   * write lock during processing.\n+   */\n   @Ignore\n   @Test\n   public void testPutWithDestroyRegionDifferentVM() {\n@@ -147,9 +168,7 @@ public void testPutWithDestroyRegionDifferentVM() {\n     performTestAndCheckResults();\n   }\n \n-  // Local methods\n-\n-  /*\n+  /**\n    * This method executes a runnable test and then checks for region consistency\n    */\n   private void performTestAndCheckResults() {\n@@ -162,7 +181,7 @@ private void performTestAndCheckResults() {\n     }\n   }\n \n-  /*\n+  /**\n    * Set which vm will perform the transaction and which will perform the region operation and\n    * create the regions on the vms\n    */\n@@ -176,10 +195,10 @@ private void setupRegions(VM opsTarget, VM regionTarget) {\n   }\n \n   private void putOperationsTest() {\n-    opsVM.invoke(() -> doPuts(getCache(), regionVM));\n+    opsVM.invoke(() -> doPuts(cache, regionVM));\n   }\n \n-  /*\n+  /**\n    * Set arm hook to detect when region operation is attempting to acquire write lock and stage the\n    * clear that will be released half way through commit processing.\n    */\n@@ -188,21 +207,18 @@ private void setClearHook(String rname, VM whereOps, VM whereClear) {\n     whereClear.invokeAsync(() -> stageClear(rname, whereOps));\n   }\n \n-  // remote test methods\n-\n-  /*\n+  /**\n    * Wait to be notified and then execute the clear. Once the clear completes, notify waiter to\n    * perform region verification.\n    */\n   private static void stageClear(String rname, VM whereOps) throws InterruptedException {\n-    regionLatch = new CountDownLatch(1);\n     regionOperationWait(regionLatch);\n     LocalRegion r = (LocalRegion) cache.getRegion(rname);\n     r.clear();\n     whereOps.invoke(() -> releaseVerify());\n   }\n \n-  /*\n+  /**\n    * Set and stage method for close and destroy are the same as clear\n    */\n   private void setCloseHook(String rname, VM whereOps, VM whereClear) {\n@@ -211,7 +227,6 @@ private void setCloseHook(String rname, VM whereOps, VM whereClear) {\n   }\n \n   private static void stageClose(String rname, VM whereOps) throws InterruptedException {\n-    regionLatch = new CountDownLatch(1);\n     regionOperationWait(regionLatch);\n     LocalRegion r = (LocalRegion) cache.getRegion(rname);\n     r.close();\n@@ -224,14 +239,13 @@ private void setDestroyRegionHook(String rname, VM whereOps, VM whereClear) {\n   }\n \n   private static void stageDestroyRegion(String rname, VM whereOps) throws InterruptedException {\n-    regionLatch = new CountDownLatch(1);\n     regionOperationWait(regionLatch);\n     LocalRegion r = (LocalRegion) cache.getRegion(rname);\n     r.destroyRegion();\n     whereOps.invoke(() -> releaseVerify());\n   }\n \n-  /*\n+  /**\n    * Set the abstract region map lock hook to detect attempt to acquire write lock by region\n    * operation.\n    */\n@@ -241,35 +255,29 @@ private void setArmHook(String rname) {\n     ((AbstractRegionMap) r.entries).setARMLockTestHook(theArmHook);\n   }\n \n-  /*\n+  /**\n    * Cleanup arm lock hook by setting it null\n    */\n   private void resetArmHook(String rname) {\n     LocalRegion r = (LocalRegion) cache.getRegion(rname);\n     ((AbstractRegionMap) r.entries).setARMLockTestHook(null);\n   }\n \n-  /*\n+  /**\n    * Wait to be notified it is time to perform region operation (i.e. CLEAR)\n    */\n   private static void regionOperationWait(CountDownLatch latch) throws InterruptedException {\n     latch.await();\n-    /*\n-     * regionLatch = new CountDownLatch(1); regionLatch.await();\n-     */\n   }\n \n-  /*\n+  /**\n    * A simple transaction that will have a region operation execute during commit. opsLatch is used\n    * to wait until region operation has been scheduled during commit and verifyLatch is used to\n    * ensure commit and clear processing have both completed.\n    */\n   private static void doPuts(Cache cache, VM whereRegion) throws InterruptedException {\n     TXManagerImpl txManager = (TXManagerImpl) cache.getCacheTransactionManager();\n \n-    opsLatch = new CountDownLatch(1);\n-    verifyLatch = new CountDownLatch(1);\n-\n     txManager.begin();\n     TXStateInterface txState = ((TXStateProxyImpl) txManager.getTXState()).getRealDeal(null, null);\n     ((TXState) txState).setDuringApplyChanges(new CommitTestCallback(whereRegion));\n@@ -285,21 +293,21 @@ private static void doPuts(Cache cache, VM whereRegion) throws InterruptedExcept\n     verifyLatch.await();\n   }\n \n-  /*\n+  /**\n    * Release the region operation that has been previously staged\n    */\n   private static void releaseRegionOperation(VM whereRegion) {\n     whereRegion.invoke(() -> regionLatch.countDown());\n   }\n \n-  /*\n+  /**\n    * Region operation has been scheduled, now resume commit processing\n    */\n   private static void releaseOps() {\n     opsLatch.countDown();\n   }\n \n-  /*\n+  /**\n    * Notify waiter it is time to verify region contents\n    */\n   private static void releaseVerify() {\n@@ -308,8 +316,9 @@ private static void releaseVerify() {\n \n   private InternalDistributedMember createCache(VM vm) {\n     return vm.invoke(() -> {\n-      cache = getCache(new CacheFactory().set(\"conserve-sockets\", \"true\"));\n-      return getSystem().getDistributedMember();\n+      cache = (InternalCache) new CacheFactory(getDistributedSystemProperties())\n+          .set(\"conserve-sockets\", \"true\").create();\n+      return cache.getInternalDistributedSystem().getDistributedMember();\n     });\n   }\n \n@@ -320,7 +329,7 @@ private static void createRegion(String rgnName) {\n     factory.create(rgnName);\n   }\n \n-  /*\n+  /**\n    * Get region contents from each member and verify they are consistent\n    */\n   private void checkForConsistencyErrors(String regionName) {\n@@ -330,46 +339,46 @@ private void checkForConsistencyErrors(String regionName) {\n     for (int i = 0; i < NUMBER_OF_PUTS; i++) {\n       String theKey = regionName + THE_KEY + i;\n       if (r0Contents.containsKey(theKey)) {\n-        softly.assertThat(r1Contents.get(theKey))\n+        assertThat(r1Contents.get(theKey))\n             .as(\"region contents are not consistent for key %s\", theKey)\n             .isEqualTo(r0Contents.get(theKey));\n       } else {\n-        softly.assertThat(r1Contents).as(\"expected containsKey for %s to return false\", theKey)\n+        assertThat(r1Contents).as(\"expected containsKey for %s to return false\", theKey)\n             .doesNotContainKey(theKey);\n       }\n     }\n   }\n \n-  @SuppressWarnings(\"rawtypes\")\n   private static Map<Object, Object> getRegionContents(String rname) {\n     LocalRegion r = (LocalRegion) cache.getRegion(rname);\n     Map<Object, Object> result = new HashMap<>();\n-    for (Iterator i = r.entrySet().iterator(); i.hasNext();) {\n-      Region.Entry e = (Region.Entry) i.next();\n+    for (Object o : r.entrySet()) {\n+      Region.Entry e = (Region.Entry) o;\n       result.put(e.getKey(), e.getValue());\n     }\n     return result;\n   }\n \n-  /*\n+  /**\n    * Test callback called for each operation during commit processing. Half way through commit\n    * processing, release the region operation.\n    */\n-  static class CommitTestCallback implements Runnable {\n-    private VM whereRegionOperation;\n-    private int callCount;\n-    /* entered twice for each put lap since there are 2 regions */\n-    private int releasePoint = NUMBER_OF_PUTS;\n+  private static class CommitTestCallback implements Runnable {\n+\n+    /** entered twice for each put lap since there are 2 regions */\n+    private final int releasePoint = NUMBER_OF_PUTS;\n+    private final AtomicInteger callCount = new AtomicInteger();\n+\n+    private final VM whereRegionOperation;\n \n     CommitTestCallback(VM whereRegion) {\n       whereRegionOperation = whereRegion;\n-      callCount = 0;\n     }\n \n     @Override\n     public void run() {\n-      callCount++;\n-      if (callCount == releasePoint) {\n+      callCount.incrementAndGet();\n+      if (callCount.get() == releasePoint) {\n         releaseRegionOperation(whereRegionOperation);\n         try {\n           opsLatch.await();\n@@ -379,13 +388,13 @@ public void run() {\n     }\n   }\n \n-  /*\n+  /**\n    * The region operations attempt to acquire the write lock will hang while commit processing is\n    * occurring. Before this occurs, resume commit processing.\n    */\n-  public class ArmLockHook extends ARMLockTestHookAdapter {\n+  private static class ArmLockHook extends ARMLockTestHookAdapter {\n     @Override\n-    public void beforeLock(InternalRegion owner, CacheEvent event) {\n+    public void beforeLock(InternalRegion region, CacheEvent event) {\n       if (event != null) {\n         if (event.getOperation().isClear() || event.getOperation().isRegionDestroy()\n             || event.getOperation().isClose()) {\n@@ -394,5 +403,4 @@ public void beforeLock(InternalRegion owner, CacheEvent event) {\n       }\n     }\n   }\n-\n }",
                "raw_url": "https://github.com/apache/geode/raw/65b416e799aba2237f2ec9894f2cb7be2dace45e/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClearTXLockingDUnitTest.java",
                "sha": "12276ae8853cc284c7ce0ea4d5ee0c287b41cd13",
                "status": "modified"
            }
        ],
        "message": "GEODE-2275: Update and cleanup ClearTXLockingDUnitTest (#3326)\n\nMake latches final in all VMs to prevent NPE. Release latches in all VMs in tearDown.",
        "parent": "https://github.com/apache/geode/commit/77fe516d82678097a5aa222f4fce4f87664aa7df",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "ClearTXLockingDUnitTest.java"
        ]
    },
    "geode_6a8af5b": {
        "bug_id": "geode_6a8af5b",
        "commit": "https://github.com/apache/geode/commit/6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 8,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "patch": "@@ -28,7 +28,7 @@\n   private String url;\n   private String user;\n   private String password;\n-  private Map<String, String> parameters = new HashMap<>();\n+  private Map<String, String> parameters;\n \n   public ConnectionConfigBuilder withName(String name) {\n     this.name = name;\n@@ -51,25 +51,26 @@ public ConnectionConfigBuilder withPassword(String password) {\n   }\n \n   public ConnectionConfigBuilder withParameters(String[] params) {\n-    if (params == null) {\n-      parameters = null;\n-    } else {\n+    if (params != null) {\n+      parameters = new HashMap<>();\n       for (String param : params) {\n         if (param.isEmpty()) {\n           continue;\n         }\n         String[] keyValuePair = param.split(PARAMS_DELIMITER);\n         validateParam(keyValuePair, param);\n-        if (keyValuePair.length == 2) {\n-          parameters.put(keyValuePair[0], keyValuePair[1]);\n-        }\n+        parameters.put(keyValuePair[0], keyValuePair[1]);\n       }\n+    } else {\n+      parameters = null;\n     }\n     return this;\n   }\n \n   private void validateParam(String[] paramKeyValue, String param) {\n-    if ((paramKeyValue.length <= 1) || paramKeyValue[0].isEmpty() || paramKeyValue[1].isEmpty()) {\n+    // paramKeyValue is produced by split which will never give us\n+    // an empty second element\n+    if ((paramKeyValue.length != 2) || paramKeyValue[0].isEmpty()) {\n       throw new IllegalArgumentException(\"Parameter '\" + param\n           + \"' is not of the form 'parameterName\" + PARAMS_DELIMITER + \"value'\");\n     }",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "sha": "4ab2b7f4799c2ff5bc516099d4bb71c99449b4f9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 3,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "patch": "@@ -23,9 +23,6 @@\n \n @Experimental\n public class ConnectionConfiguration implements Serializable {\n-  private static final Object USER = \"user\";\n-  private static final Object PASSWORD = \"password\";\n-\n   private final String name;\n   private final String url;\n   private final String user;",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "sha": "c80e1460966c5a35300a4dc5527018a2e6b6d599",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 9,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "patch": "@@ -50,14 +50,15 @@ public RegionMappingBuilder withConnectionConfigName(String connectionConfigName\n     return this;\n   }\n \n-  // TODO: delete withPrimaryKeyInValue(String)\n-  public RegionMappingBuilder withPrimaryKeyInValue(String primaryKeyInValue) {\n-    this.primaryKeyInValue = Boolean.parseBoolean(primaryKeyInValue);\n+  public RegionMappingBuilder withPrimaryKeyInValue(String v) {\n+    if (v != null) {\n+      withPrimaryKeyInValue(Boolean.parseBoolean(v));\n+    }\n     return this;\n   }\n \n-  public RegionMappingBuilder withPrimaryKeyInValue(Boolean primaryKeyInValue) {\n-    this.primaryKeyInValue = primaryKeyInValue;\n+  public RegionMappingBuilder withPrimaryKeyInValue(Boolean v) {\n+    this.primaryKeyInValue = v;\n     return this;\n   }\n \n@@ -76,16 +77,16 @@ public RegionMappingBuilder withFieldToColumnMappings(String[] mappings) {\n         }\n         String[] keyValuePair = mapping.split(MAPPINGS_DELIMITER);\n         validateParam(keyValuePair, mapping);\n-        if (keyValuePair.length == 2) {\n-          fieldToColumnMap.put(keyValuePair[0], keyValuePair[1]);\n-        }\n+        fieldToColumnMap.put(keyValuePair[0], keyValuePair[1]);\n       }\n     }\n     return this;\n   }\n \n   private void validateParam(String[] paramKeyValue, String mapping) {\n-    if (paramKeyValue.length <= 1 || paramKeyValue[0].isEmpty() || paramKeyValue[1].isEmpty()) {\n+    // paramKeyValue is produced by split which will never give us\n+    // an empty second element\n+    if (paramKeyValue.length != 2 || paramKeyValue[0].isEmpty()) {\n       throw new IllegalArgumentException(\"Field to column mapping '\" + mapping\n           + \"' is not of the form 'Field\" + MAPPINGS_DELIMITER + \"Column'\");\n     }",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "sha": "0d989a48c1cf5efa55b7ae383db8ac7e45f811b0",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 4,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "patch": "@@ -103,9 +103,11 @@ private void fillResultData(ConnectionConfiguration config, CompositeResultData\n     }\n     TabularResultData tabularResultData = sectionResult.addTable(CREATE_CONNECTION__PARAMS);\n     tabularResultData.setHeader(\"Additional connection parameters:\");\n-    config.getParameters().entrySet().forEach((entry) -> {\n-      tabularResultData.accumulate(\"Param Name\", entry.getKey());\n-      tabularResultData.accumulate(\"Value\", entry.getValue());\n-    });\n+    if (config.getParameters() != null) {\n+      config.getParameters().entrySet().forEach((entry) -> {\n+        tabularResultData.accumulate(\"Param Name\", entry.getKey());\n+        tabularResultData.accumulate(\"Value\", entry.getValue());\n+      });\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "sha": "3295340cad2b4c5e1016df4c6384296e3191f579",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 9,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "patch": "@@ -51,21 +51,22 @@ void startElement(Stack<Object> stack, Attributes attributes) {\n         throw new CacheXmlException(\n             \"jdbc <connection> elements must occur within <connector-service> elements\");\n       }\n-      ConnectionConfigBuilder connectionConfig = new ConnectionConfigBuilder()\n+      ConnectionConfigBuilder connectionConfigBuilder = new ConnectionConfigBuilder()\n           .withName(attributes.getValue(JdbcConnectorServiceXmlParser.NAME))\n           .withUrl(attributes.getValue(JdbcConnectorServiceXmlParser.URL))\n           .withUser(attributes.getValue(JdbcConnectorServiceXmlParser.USER))\n-          .withPassword(attributes.getValue(JdbcConnectorServiceXmlParser.PASSWORD));\n-      addParameters(connectionConfig,\n-          attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS));\n-      stack.push(connectionConfig);\n+          .withPassword(attributes.getValue(JdbcConnectorServiceXmlParser.PASSWORD))\n+          .withParameters(parseParameters(attributes));\n+      stack.push(connectionConfigBuilder);\n     }\n \n-    private void addParameters(ConnectionConfigBuilder connectionConfig, String value) {\n-      if (value == null) {\n-        return;\n+    private String[] parseParameters(Attributes attributes) {\n+      String[] result = null;\n+      String value = attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS);\n+      if (value != null) {\n+        result = value.split(\",\");\n       }\n-      connectionConfig.withParameters(value.split(\",\"));\n+      return result;\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "sha": "716e15f32a0c6c8796b76368ed950f14d4d80836",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 18,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "patch": "@@ -102,9 +102,15 @@ private void outputConnectionConfiguration(ContentHandler handler, ConnectionCon\n     AttributesImpl attributes = new AttributesImpl();\n     XmlGeneratorUtils.addAttribute(attributes, NAME, config.getName());\n     XmlGeneratorUtils.addAttribute(attributes, URL, config.getUrl());\n-    XmlGeneratorUtils.addAttribute(attributes, USER, config.getUser());\n-    XmlGeneratorUtils.addAttribute(attributes, PASSWORD, config.getPassword());\n-    XmlGeneratorUtils.addAttribute(attributes, PARAMETERS, createParametersString(config));\n+    if (config.getUser() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, USER, config.getUser());\n+    }\n+    if (config.getPassword() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PASSWORD, config.getPassword());\n+    }\n+    if (config.getParameters() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PARAMETERS, createParametersString(config));\n+    }\n     XmlGeneratorUtils.emptyElement(handler, PREFIX, ElementType.CONNECTION.getTypeName(),\n         attributes);\n   }\n@@ -114,17 +120,23 @@ private void outputRegionMapping(ContentHandler handler, RegionMapping mapping)\n     AttributesImpl attributes = new AttributesImpl();\n     XmlGeneratorUtils.addAttribute(attributes, CONNECTION_NAME, mapping.getConnectionConfigName());\n     XmlGeneratorUtils.addAttribute(attributes, REGION, mapping.getRegionName());\n-    XmlGeneratorUtils.addAttribute(attributes, TABLE, mapping.getTableName());\n-    XmlGeneratorUtils.addAttribute(attributes, PDX_CLASS, mapping.getPdxClassName());\n-    XmlGeneratorUtils.addAttribute(attributes, PRIMARY_KEY_IN_VALUE,\n-        Boolean.toString(mapping.isPrimaryKeyInValue()));\n+    if (mapping.getTableName() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, TABLE, mapping.getTableName());\n+    }\n+    if (mapping.getPdxClassName() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PDX_CLASS, mapping.getPdxClassName());\n+    }\n+    if (mapping.isPrimaryKeyInValue() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PRIMARY_KEY_IN_VALUE,\n+          Boolean.toString(mapping.isPrimaryKeyInValue()));\n+    }\n \n-    XmlGeneratorUtils.startElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName(),\n-        attributes);\n     if (mapping.getFieldToColumnMap() != null) {\n+      XmlGeneratorUtils.startElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName(),\n+          attributes);\n       addFieldMappings(handler, mapping.getFieldToColumnMap());\n+      XmlGeneratorUtils.endElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName());\n     }\n-    XmlGeneratorUtils.endElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName());\n   }\n \n   private void addFieldMappings(ContentHandler handler, Map<String, String> fieldMappings)\n@@ -139,16 +151,13 @@ private void addFieldMappings(ContentHandler handler, Map<String, String> fieldM\n   }\n \n   private String createParametersString(ConnectionConfiguration config) {\n-    Properties properties = config.getConnectionProperties();\n+    assert config.getParameters() != null;\n     StringBuilder stringBuilder = new StringBuilder();\n-    for (Map.Entry<Object, Object> entry : properties.entrySet()) {\n-      Object key = entry.getKey();\n-      if (!key.equals(USER) && !key.equals(PASSWORD)) {\n-        if (stringBuilder.length() > 0) {\n-          stringBuilder.append(\",\");\n-        }\n-        stringBuilder.append(key).append(PARAMS_DELIMITER).append(entry.getValue());\n+    for (Map.Entry<String, String> entry : config.getParameters().entrySet()) {\n+      if (stringBuilder.length() > 0) {\n+        stringBuilder.append(\",\");\n       }\n+      stringBuilder.append(entry.getKey()).append(PARAMS_DELIMITER).append(entry.getValue());\n     }\n     return stringBuilder.toString();\n   }",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "sha": "70f9540ea41e568a70bd3b4ad8caa7c26e7be464",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 1,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "patch": "@@ -12,7 +12,7 @@\n  * or implied. See the License for the specific language governing permissions and limitations under\n  * the License.\n  */\n-package org.apache.geode.connectors.jdbc.internal.xml;\n+package org.apache.geode.connectors.jdbc.internal;\n \n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n@@ -51,6 +51,30 @@ public void createsObjectWithCorrectValues() {\n         .containsEntry(\"param2\", \"value2\");\n   }\n \n+  @Test\n+  public void createsObjectWithEmptyParameterElement() {\n+    ConnectionConfiguration config = new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\")\n+        .withUser(\"user\").withPassword(\"password\")\n+        .withParameters(new String[] {\"param1:value1\", \"\", \"param2:value2\"}).build();\n+\n+    assertThat(config.getName()).isEqualTo(\"name\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getUser()).isEqualTo(\"user\");\n+    assertThat(config.getPassword()).isEqualTo(\"password\");\n+    assertThat(config.getConnectionProperties()).containsEntry(\"param1\", \"value1\")\n+        .containsEntry(\"param2\", \"value2\");\n+  }\n+\n+  @Test\n+  public void createsObjectWithNullParameters() {\n+    ConnectionConfiguration config =\n+        new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\").withParameters(null).build();\n+\n+    assertThat(config.getName()).isEqualTo(\"name\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getParameters()).isNull();\n+  }\n+\n   @Test\n   public void throwsExceptionWithInvalidParams() {\n     ConnectionConfigBuilder config = new ConnectionConfigBuilder();\n@@ -60,6 +84,8 @@ public void throwsExceptionWithInvalidParams() {\n         .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(() -> config.withParameters(new String[] {\"param1value1:\"}))\n         .isInstanceOf(IllegalArgumentException.class);\n+    assertThatThrownBy(() -> config.withParameters(new String[] {\"1:2:3\"}))\n+        .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(() -> config.withParameters(new String[] {\":\"}))\n         .isInstanceOf(IllegalArgumentException.class);\n   }",
                "previous_filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ConnectionConfigBuilderTest.java",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "sha": "4e4b18ca685ccf9cffd86e95fe7ebbe5c9491e93",
                "status": "renamed"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 1,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "patch": "@@ -12,7 +12,7 @@\n  * or implied. See the License for the specific language governing permissions and limitations under\n  * the License.\n  */\n-package org.apache.geode.connectors.jdbc.internal.xml;\n+package org.apache.geode.connectors.jdbc.internal;\n \n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n@@ -53,6 +53,26 @@ public void createsMappingWithSpecifiedValues() {\n     assertThat(regionMapping.getColumnNameForField(\"fieldName\")).isEqualTo(\"columnName\");\n   }\n \n+  @Test\n+  public void createsMappingWithNullAsPrimaryKeyInValue() {\n+    RegionMapping regionMapping = new RegionMappingBuilder().withRegionName(\"regionName\")\n+        .withConnectionConfigName(\"configName\").withPrimaryKeyInValue((String) null).build();\n+\n+    assertThat(regionMapping.getRegionName()).isEqualTo(\"regionName\");\n+    assertThat(regionMapping.getConnectionConfigName()).isEqualTo(\"configName\");\n+    assertThat(regionMapping.isPrimaryKeyInValue()).isNull();\n+  }\n+\n+  @Test\n+  public void createsMappingWithNullFieldToColumnMappings() {\n+    RegionMapping regionMapping = new RegionMappingBuilder().withRegionName(\"regionName\")\n+        .withConnectionConfigName(\"configName\").withFieldToColumnMappings(null).build();\n+\n+    assertThat(regionMapping.getRegionName()).isEqualTo(\"regionName\");\n+    assertThat(regionMapping.getConnectionConfigName()).isEqualTo(\"configName\");\n+    assertThat(regionMapping.getFieldToColumnMap()).isNull();\n+  }\n+\n   @Test\n   public void createsFieldMappingsFromArray() {\n     String[] fieldMappings = new String[] {\"field1:column1\", \"field2:column2\"};\n@@ -63,6 +83,16 @@ public void createsFieldMappingsFromArray() {\n     assertThat(regionMapping.getColumnNameForField(\"field2\")).isEqualTo(\"column2\");\n   }\n \n+  @Test\n+  public void createsFieldMappingsFromArrayWithEmptyElement() {\n+    String[] fieldMappings = new String[] {\"field1:column1\", \"\", \"field2:column2\"};\n+    RegionMapping regionMapping =\n+        new RegionMappingBuilder().withFieldToColumnMappings(fieldMappings).build();\n+\n+    assertThat(regionMapping.getColumnNameForField(\"field1\")).isEqualTo(\"column1\");\n+    assertThat(regionMapping.getColumnNameForField(\"field2\")).isEqualTo(\"column2\");\n+  }\n+\n   @Test\n   public void throwsExceptionForInvalidFieldMappings() {\n     RegionMappingBuilder regionMappingbuilder = new RegionMappingBuilder();\n@@ -73,6 +103,9 @@ public void throwsExceptionForInvalidFieldMappings() {\n     assertThatThrownBy(\n         () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\":field1column1\"}))\n             .isInstanceOf(IllegalArgumentException.class);\n+    assertThatThrownBy(\n+        () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\"field1:column1:extra\"}))\n+            .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(\n         () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\"field1column1:\"}))\n             .isInstanceOf(IllegalArgumentException.class);",
                "previous_filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/RegionMappingBuilderTest.java",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "sha": "5abfd74796ca905199f0023b45726f5849febb50",
                "status": "renamed"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "patch": "@@ -106,6 +106,30 @@ public void displaysConnectionInformationWhenConfigurationExists() throws Except\n \n   }\n \n+  @Test\n+  public void displaysConnectionInformationForConfigurationWithNullParameters() throws Exception {\n+    connectionConfig = new ConnectionConfigBuilder().withName(CONNECTION).withUrl(\"myUrl\")\n+        .withParameters(null).build();\n+    service.createConnectionConfig(connectionConfig);\n+    Result result = command.describeConnection(CONNECTION);\n+\n+    assertThat(result.getStatus()).isSameAs(Result.Status.OK);\n+    CommandResult commandResult = (CommandResult) result;\n+    GfJsonObject sectionContent = commandResult.getTableContent()\n+        .getJSONObject(SECTION_DATA_ACCESSOR + \"-\" + RESULT_SECTION_NAME);\n+\n+    assertThat(sectionContent.get(CREATE_CONNECTION__NAME)).isEqualTo(connectionConfig.getName());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__URL)).isEqualTo(connectionConfig.getUrl());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__USER)).isEqualTo(connectionConfig.getUser());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__PASSWORD)).isEqualTo(null);\n+\n+    GfJsonObject tableContent =\n+        sectionContent.getJSONObject(TABLE_DATA_ACCESSOR + \"-\" + CREATE_CONNECTION__PARAMS)\n+            .getJSONObject(\"content\");\n+    assertThat(tableContent.get(\"Param Name\")).isNull();\n+    assertThat(tableContent.get(\"Value\")).isNull();\n+  }\n+\n   @Test\n   public void doesNotDisplayParametersWithNoValue() throws Exception {\n     connectionConfig = new ConnectionConfigBuilder().withName(CONNECTION).withUrl(\"myUrl\").build();",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "sha": "84e93c371b0d902686c3ebb960550828456ba9cb",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "patch": "@@ -34,6 +34,8 @@\n import static org.mockito.Mockito.verifyZeroInteractions;\n import static org.mockito.Mockito.when;\n \n+import java.util.HashMap;\n+import java.util.Map;\n import java.util.Stack;\n \n import org.junit.Before;\n@@ -136,6 +138,29 @@ public void startElementConnection() {\n     assertThat(config.getUrl()).isEqualTo(\"url\");\n     assertThat(config.getUser()).isEqualTo(\"username\");\n     assertThat(config.getPassword()).isEqualTo(\"secret\");\n+    assertThat(config.getParameters()).isNull();\n+  }\n+\n+  @Test\n+  public void startElementConnectionWithParameters() {\n+    JdbcServiceConfiguration serviceConfiguration = mock(JdbcServiceConfiguration.class);\n+    stack.push(serviceConfiguration);\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.NAME)).thenReturn(\"connectionName\");\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.URL)).thenReturn(\"url\");\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS))\n+        .thenReturn(\"key1:value1,key2:value2\");\n+\n+    CONNECTION.startElement(stack, attributes);\n+\n+    ConnectionConfiguration config = ((ConnectionConfigBuilder) stack.pop()).build();\n+    assertThat(config.getName()).isEqualTo(\"connectionName\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getUser()).isNull();\n+    assertThat(config.getPassword()).isNull();\n+    Map<String, String> expectedParams = new HashMap<>();\n+    expectedParams.put(\"key1\", \"value1\");\n+    expectedParams.put(\"key2\", \"value2\");\n+    assertThat(config.getParameters()).isEqualTo(expectedParams);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "sha": "7612527747b14d465cf4ac2f302a29a032d50b6e",
                "status": "modified"
            },
            {
                "additions": 43,
                "blob_url": "https://github.com/apache/geode/blob/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "changes": 43,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java?ref=6a8af5b4482e650d78e94b60ed44b93cc621b8e9",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "patch": "@@ -174,6 +174,35 @@ public void generatedXmlWithConnectionConfigurationCanBeParsed() throws Exceptio\n     assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n   }\n \n+  @Test\n+  public void generatedXmlWithConnectionConfigurationWithNoUserNameAndPasswordCanBeParsed()\n+      throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    ConnectionConfiguration config =\n+        new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\").build();\n+    service.createConnectionConfig(config);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n+  }\n+\n+  @Test\n+  public void generatedXmlWithConnectionConfigurationWithParametersCanBeParsed() throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    ConnectionConfiguration config = new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\")\n+        .withParameters(new String[] {\"key1:value1\", \"key2:value2\"}).build();\n+    service.createConnectionConfig(config);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n+  }\n+\n   @Test\n   public void generatedXmlWithRegionMappingCanBeParsed() throws Exception {\n     JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n@@ -190,6 +219,20 @@ public void generatedXmlWithRegionMappingCanBeParsed() throws Exception {\n     assertThat(service.getMappingForRegion(\"region\")).isEqualTo(mapping);\n   }\n \n+  @Test\n+  public void generatedXmlWithRegionMappingWithNoOptionalParametersCanBeParsed() throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    RegionMapping mapping = new RegionMappingBuilder().withRegionName(\"region\")\n+        .withConnectionConfigName(\"connection\").build();\n+    service.createRegionMapping(mapping);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getMappingForRegion(\"region\")).isEqualTo(mapping);\n+  }\n+\n   @Test\n   public void generatedXmlWithEverythingCanBeParsed() throws Exception {\n     JdbcConnectorService service = cache.getService(JdbcConnectorService.class);",
                "raw_url": "https://github.com/apache/geode/raw/6a8af5b4482e650d78e94b60ed44b93cc621b8e9/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "sha": "1ba728f44121293971332b18c74e1278c85a2365",
                "status": "modified"
            }
        ],
        "message": "GEODE-4160: fix gfsh describe jdbc-connection (#1223)\n\n* GEODE-4160: fix gfsh describe jdbc-connection\r\n\r\nIf the connection had no parameters set, then running\r\ngfsh describe jdbc-connection would fail with an NPE.",
        "parent": "https://github.com/apache/geode/commit/21d243d950270bb9f265f3a47c4d2ddd8be15cec",
        "patched_files": [
            "RegionMappingBuilder.java",
            "DescribeConnectionCommand.java",
            "JdbcConnectorServiceXmlGenerator.java",
            "ElementType.java",
            "ConnectionConfiguration.java",
            "ConnectionConfigBuilder.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "RegionMappingBuilderTest.java",
            "ConnectionConfigBuilderTest.java",
            "ConnectionConfigurationTest.java",
            "JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
            "JdbcConnectorServiceXmlGeneratorTest.java",
            "DescribeConnectionCommandIntegrationTest.java",
            "ElementTypeTest.java"
        ]
    },
    "geode_6f4bbbd": {
        "bug_id": "geode_6f4bbbd",
        "commit": "https://github.com/apache/geode/commit/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b",
        "file": [
            {
                "additions": 135,
                "blob_url": "https://github.com/apache/geode/blob/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/wan/asyncqueue/AsyncEventListenerDistributedTest.java",
                "changes": 195,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/wan/asyncqueue/AsyncEventListenerDistributedTest.java?ref=6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b",
                "deletions": 60,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/wan/asyncqueue/AsyncEventListenerDistributedTest.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import static org.apache.geode.cache.RegionShortcut.PARTITION;\n import static org.apache.geode.cache.RegionShortcut.REPLICATE;\n+import static org.apache.geode.cache.asyncqueue.internal.AsyncEventQueueFactoryImpl.DEFAULT_BATCH_TIME_INTERVAL;\n import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n import static org.apache.geode.test.dunit.VM.getCurrentVMNum;\n import static org.apache.geode.test.dunit.VM.getVM;\n@@ -26,6 +27,7 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.io.UncheckedIOException;\n+import java.nio.file.Files;\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.List;\n@@ -57,6 +59,7 @@\n import org.apache.geode.cache.asyncqueue.AsyncEventQueueFactory;\n import org.apache.geode.cache.asyncqueue.internal.InternalAsyncEventQueue;\n import org.apache.geode.cache.util.CacheListenerAdapter;\n+import org.apache.geode.distributed.ConfigurationProperties;\n import org.apache.geode.internal.cache.InternalCache;\n import org.apache.geode.internal.cache.RegionQueue;\n import org.apache.geode.internal.cache.wan.InternalGatewaySender;\n@@ -127,9 +130,9 @@ protected Properties getDistributedSystemProperties() {\n \n   @Test // serial, ReplicateRegion\n   public void testSerialAsyncEventQueueSize() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false,\n         100, dispatcherThreadCount, 100));\n@@ -146,9 +149,9 @@ public void testSerialAsyncEventQueueSize() {\n     vm1.invoke(() -> getInternalGatewaySender().pause());\n     vm2.invoke(() -> getInternalGatewaySender().pause());\n \n-    vm0.invoke(() -> waitForDispatcherToPause());\n-    vm1.invoke(() -> waitForDispatcherToPause());\n-    vm2.invoke(() -> waitForDispatcherToPause());\n+    vm0.invoke(this::waitForDispatcherToPause);\n+    vm1.invoke(this::waitForDispatcherToPause);\n+    vm2.invoke(this::waitForDispatcherToPause);\n \n     vm0.invoke(() -> doPuts(replicateRegionName, 1000));\n \n@@ -159,9 +162,9 @@ public void testSerialAsyncEventQueueSize() {\n \n   @Test // serial, ReplicateRegion\n   public void testReplicatedSerialAsyncEventQueue() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false,\n         100, dispatcherThreadCount, 100));\n@@ -186,9 +189,9 @@ public void testReplicatedSerialAsyncEventQueue() {\n \n   @Test // serial, conflation, ReplicateRegion\n   public void testReplicatedSerialAsyncEventQueueWithConflationEnabled() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), true,\n         100, dispatcherThreadCount, 100));\n@@ -205,9 +208,9 @@ public void testReplicatedSerialAsyncEventQueueWithConflationEnabled() {\n     vm1.invoke(() -> getInternalGatewaySender().pause());\n     vm2.invoke(() -> getInternalGatewaySender().pause());\n \n-    vm0.invoke(() -> waitForDispatcherToPause());\n-    vm1.invoke(() -> waitForDispatcherToPause());\n-    vm2.invoke(() -> waitForDispatcherToPause());\n+    vm0.invoke(this::waitForDispatcherToPause);\n+    vm1.invoke(this::waitForDispatcherToPause);\n+    vm2.invoke(this::waitForDispatcherToPause);\n \n     Map<Integer, Integer> keyValues = new HashMap<>();\n     for (int i = 0; i < 1000; i++) {\n@@ -252,16 +255,19 @@ public void testReplicatedSerialAsyncEventQueueWithConflationEnabled() {\n \n   @Test // serial, persistent, conflation, ReplicateRegion\n   public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm1.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm2.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        true, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n \n     vm0.invoke(() -> createReplicateRegion(replicateRegionName, asyncEventQueueId));\n     vm1.invoke(() -> createReplicateRegion(replicateRegionName, asyncEventQueueId));\n@@ -283,7 +289,8 @@ public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart()\n       createCache();\n \n       createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false, 100,\n-          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100);\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+          DEFAULT_BATCH_TIME_INTERVAL);\n \n       createReplicateRegion(replicateRegionName, asyncEventQueueId);\n \n@@ -298,7 +305,8 @@ public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart()\n \n       createCache();\n       createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false, 100,\n-          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100);\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+          DEFAULT_BATCH_TIME_INTERVAL);\n       createReplicateRegion(replicateRegionName, asyncEventQueueId);\n \n       // primary sender\n@@ -315,16 +323,19 @@ public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart()\n   @Ignore(\"TODO: Disabled for 52351\")\n   @Test // serial, persistent, ReplicateRegion\n   public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart2() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm1.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm2.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n \n     vm0.invoke(() -> {\n       createReplicateRegion(replicateRegionName, asyncEventQueueId);\n@@ -334,11 +345,11 @@ public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart2()\n     vm1.invoke(() -> createReplicateRegion(replicateRegionName, asyncEventQueueId));\n     vm2.invoke(() -> createReplicateRegion(replicateRegionName, asyncEventQueueId));\n \n-    vm1.invoke(() -> waitForSenderToBecomePrimary());\n+    vm1.invoke(this::waitForSenderToBecomePrimary);\n     vm1.invoke(() -> doPuts(replicateRegionName, 2000));\n \n-    vm1.invoke(() -> waitForRegionQueuesToEmpty());\n-    vm2.invoke(() -> waitForRegionQueuesToEmpty());\n+    vm1.invoke(this::waitForRegionQueuesToEmpty);\n+    vm2.invoke(this::waitForRegionQueuesToEmpty);\n \n     int vm1size = vm1.invoke(() -> ((Map<?, ?>) getSpyAsyncEventListener().getEventsMap()).size());\n     int vm2size = vm2.invoke(() -> ((Map<?, ?>) getSpyAsyncEventListener().getEventsMap()).size());\n@@ -347,11 +358,65 @@ public void testReplicatedSerialAsyncEventQueueWithPersistenceEnabled_Restart2()\n     assertThat(vm1size + vm2size).isGreaterThanOrEqualTo(2000);\n   }\n \n+  @Test\n+  // See GEODE-7079: a NullPointerException was thrown whenever the queue was recovered from disk\n+  // and the processor started dispatching events before the actual region was available.\n+  public void replicatedRegionWithPersistentSerialAsyncEventQueueAndConflationEnabledShouldNotLooseEventsNorThrowNullPointerExceptionsWhenMemberIsRestartedWhileEventsAreStillOnTheQueue()\n+      throws IOException {\n+    // Custom Log File to manually search for exceptions.\n+    File customLogFile = temporaryFolder.newFile(\"memberLog.log\");\n+    Properties dsProperties = getDistributedSystemProperties();\n+    dsProperties.setProperty(ConfigurationProperties.LOG_FILE, customLogFile.getAbsolutePath());\n+\n+    // Create Region, AsyncEventQueue and Insert Some Entries.\n+    vm0.invoke(() -> {\n+      createCache();\n+      // Large batch time interval and low batch size so no events are processed before the restart.\n+      createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), true, 10,\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100, 120000);\n+      createReplicateRegion(replicateRegionName, asyncEventQueueId);\n+      doPuts(replicateRegionName, 5);\n+      waitForAsyncEventQueueSize(5);\n+    });\n+\n+    vm0.invoke(() -> {\n+      // Restart the cache.\n+      getCache().close();\n+      cacheRule.createCache(dsProperties);\n+\n+      // Recover the queue from disk, reduce thresholds so processing starts right away.\n+      SpyAsyncEventListener spyAsyncEventListener = new SpyAsyncEventListener();\n+      createPersistentAsyncEventQueue(asyncEventQueueId, spyAsyncEventListener, true, 5,\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+          DEFAULT_BATCH_TIME_INTERVAL);\n+      waitForSenderToBecomePrimary();\n+\n+      // Wait for the processors to start.\n+      await().until(() -> {\n+        Set<Thread> threads = Thread.getAllStackTraces().keySet();\n+        return threads\n+            .stream()\n+            .filter(t -> t.getName().contains(\"Processor for GatewaySender_AsyncEventQueue\"))\n+            .allMatch(Thread::isAlive);\n+      });\n+\n+      // Create the region, processing will continue and no NPE should be thrown anymore.\n+      createReplicateRegion(replicateRegionName, asyncEventQueueId);\n+      waitForRegionQueuesToEmpty();\n+      assertThat(spyAsyncEventListener.getEventsMap().size()).isEqualTo(5);\n+    });\n+\n+    Files.lines(customLogFile.toPath()).forEach((line) -> assertThat(line)\n+        .as(\"Dispatcher shouldn't have thrown any errors while processing batches\")\n+        .doesNotContain(\"An Exception occurred. The dispatcher will continue.\")\n+        .doesNotContain(\"java.lang.NullPointerException\"));\n+  }\n+\n   @Test // serial, PartitionedRegion\n   public void testPartitionedSerialAsyncEventQueue() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false,\n         100, dispatcherThreadCount, 100));\n@@ -377,9 +442,9 @@ public void testPartitionedSerialAsyncEventQueue() {\n \n   @Test // serial, conflation, PartitionedRegion\n   public void testPartitionedSerialAsyncEventQueueWithConflationEnabled() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), true,\n         100, dispatcherThreadCount, 100));\n@@ -396,9 +461,9 @@ public void testPartitionedSerialAsyncEventQueueWithConflationEnabled() {\n     vm1.invoke(() -> getInternalGatewaySender().pause());\n     vm2.invoke(() -> getInternalGatewaySender().pause());\n \n-    vm0.invoke(() -> waitForDispatcherToPause());\n-    vm1.invoke(() -> waitForDispatcherToPause());\n-    vm2.invoke(() -> waitForDispatcherToPause());\n+    vm0.invoke(this::waitForDispatcherToPause);\n+    vm1.invoke(this::waitForDispatcherToPause);\n+    vm2.invoke(this::waitForDispatcherToPause);\n \n     Map<Integer, Integer> keyValues = new HashMap<>();\n     for (int i = 0; i < 1000; i++) {\n@@ -451,16 +516,19 @@ public void testPartitionedSerialAsyncEventQueueWithConflationEnabled() {\n    */\n   @Test // persistent, PartitionedRegion\n   public void testPartitionedSerialAsyncEventQueueWithPersistenceEnabled() {\n-    vm0.invoke(() -> createCache());\n-    vm1.invoke(() -> createCache());\n-    vm2.invoke(() -> createCache());\n+    vm0.invoke(this::createCache);\n+    vm1.invoke(this::createCache);\n+    vm2.invoke(this::createCache);\n \n     vm0.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm1.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n     vm2.invoke(() -> createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(),\n-        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100));\n+        false, 100, createDiskStoreName(asyncEventQueueId), false, dispatcherThreadCount, 100,\n+        DEFAULT_BATCH_TIME_INTERVAL));\n \n     vm0.invoke(() -> createPartitionedRegion(partitionedRegionName, asyncEventQueueId, 0, 16));\n     vm1.invoke(() -> createPartitionedRegion(partitionedRegionName, asyncEventQueueId, 0, 16));\n@@ -483,7 +551,8 @@ public void testPartitionedSerialAsyncEventQueueWithPersistenceEnabled_Restart()\n       createCache();\n \n       createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false, 100,\n-          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100);\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+          DEFAULT_BATCH_TIME_INTERVAL);\n \n       createPartitionedRegion(partitionedRegionName, asyncEventQueueId, 0, 16);\n \n@@ -497,7 +566,8 @@ public void testPartitionedSerialAsyncEventQueueWithPersistenceEnabled_Restart()\n \n       createCache();\n       createPersistentAsyncEventQueue(asyncEventQueueId, new SpyAsyncEventListener(), false, 100,\n-          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100);\n+          createDiskStoreName(asyncEventQueueId), true, dispatcherThreadCount, 100,\n+          DEFAULT_BATCH_TIME_INTERVAL);\n       createPartitionedRegion(partitionedRegionName, asyncEventQueueId, 0, 16);\n \n       // primary sender\n@@ -600,11 +670,12 @@ private void createPersistentAsyncEventQueue(String asyncEventQueueId,\n       String diskStoreName,\n       boolean isDiskSynchronous,\n       int dispatcherThreads,\n-      int maximumQueueMemory) {\n+      int maximumQueueMemory,\n+      int batchTimeInterval) {\n+\n     assertThat(asyncEventQueueId).isNotEmpty();\n     assertThat(asyncEventListener).isNotNull();\n     assertThat(diskStoreName).isNotEmpty();\n-\n     createDiskStore(diskStoreName, asyncEventQueueId);\n \n     AsyncEventQueueFactory asyncEventQueueFactory = getCache().createAsyncEventQueueFactory();\n@@ -614,6 +685,7 @@ private void createPersistentAsyncEventQueue(String asyncEventQueueId,\n     asyncEventQueueFactory.setDiskSynchronous(isDiskSynchronous);\n     asyncEventQueueFactory.setDispatcherThreads(dispatcherThreads);\n     asyncEventQueueFactory.setMaximumQueueMemory(maximumQueueMemory);\n+    asyncEventQueueFactory.setBatchTimeInterval(batchTimeInterval);\n     asyncEventQueueFactory.setParallel(false);\n     asyncEventQueueFactory.setPersistent(true);\n \n@@ -623,17 +695,18 @@ private void createPersistentAsyncEventQueue(String asyncEventQueueId,\n   private void addClosingCacheListener(String regionName, int closeAfterCreateKey) {\n     assertThat(regionName).isNotEmpty();\n \n-    Region region = getCache().getRegion(regionName);\n+    Region<Integer, Integer> region = getCache().getRegion(regionName);\n     assertNotNull(region);\n \n-    CacheListenerAdapter cacheListener = new CacheListenerAdapter() {\n-      @Override\n-      public void afterCreate(EntryEvent event) {\n-        if ((Integer) event.getKey() == closeAfterCreateKey) {\n-          getCache().close();\n-        }\n-      }\n-    };\n+    CacheListenerAdapter<Integer, Integer> cacheListener =\n+        new CacheListenerAdapter<Integer, Integer>() {\n+          @Override\n+          public void afterCreate(EntryEvent event) {\n+            if ((Integer) event.getKey() == closeAfterCreateKey) {\n+              getCache().close();\n+            }\n+          }\n+        };\n \n     region.getAttributesMutator().addCacheListener(cacheListener);\n   }\n@@ -676,6 +749,7 @@ private int getTotalRegionQueueSize() {\n     return totalSize;\n   }\n \n+  @SuppressWarnings(\"unchecked\")\n   private void waitForAsyncEventListenerWithEventsMapSize(int expectedSize) {\n     await().untilAsserted(\n         () -> assertThat(getSpyAsyncEventListener().getEventsMap()).hasSize(expectedSize));\n@@ -745,6 +819,7 @@ private AsyncEventQueue getAsyncEventQueue() {\n     }\n \n     @Override\n+    @SuppressWarnings(\"unchecked\")\n     public boolean processEvents(List<AsyncEvent> events) {\n       for (AsyncEvent<K, V> event : events) {\n         eventsMap.put(event.getKey(), event.getDeserializedValue());",
                "raw_url": "https://github.com/apache/geode/raw/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/wan/asyncqueue/AsyncEventListenerDistributedTest.java",
                "sha": "09cab0e6373f70477483b6a43468bff25215cf49",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/main/java/org/apache/geode/internal/cache/wan/AbstractGatewaySenderEventProcessor.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/wan/AbstractGatewaySenderEventProcessor.java?ref=6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/wan/AbstractGatewaySenderEventProcessor.java",
                "patch": "@@ -783,7 +783,7 @@ public List conflate(List<GatewaySenderEventImpl> events) {\n         if (gsEvent.shouldBeConflated()) {\n           // The event should be conflated. Create the conflation key\n           // (comprised of the event's region, key and the operation).\n-          ConflationKey key = new ConflationKey(gsEvent.getRegion().getFullPath(),\n+          ConflationKey key = new ConflationKey(gsEvent.getRegionPath(),\n               gsEvent.getKeyToConflate(), gsEvent.getOperation());\n \n           // Get the entry at that key\n@@ -799,7 +799,7 @@ public List conflate(List<GatewaySenderEventImpl> events) {\n         } else {\n           // The event should not be conflated (create or destroy). Add it to\n           // the map.\n-          ConflationKey key = new ConflationKey(gsEvent.getRegion().getFullPath(),\n+          ConflationKey key = new ConflationKey(gsEvent.getRegionPath(),\n               gsEvent.getKeyToConflate(), gsEvent.getOperation(), gsEvent.getShadowKey());\n           conflatedEventsMap.put(key, gsEvent);\n         }",
                "raw_url": "https://github.com/apache/geode/raw/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/main/java/org/apache/geode/internal/cache/wan/AbstractGatewaySenderEventProcessor.java",
                "sha": "698bc7ce9b0271c9db2e9595f5016d3fae0ffa1d",
                "status": "modified"
            },
            {
                "additions": 35,
                "blob_url": "https://github.com/apache/geode/blob/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/test/java/org/apache/geode/internal/cache/wan/parallel/ParallelGatewaySenderEventProcessorJUnitTest.java",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/wan/parallel/ParallelGatewaySenderEventProcessorJUnitTest.java?ref=6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/wan/parallel/ParallelGatewaySenderEventProcessorJUnitTest.java",
                "patch": "@@ -15,7 +15,10 @@\n package org.apache.geode.internal.cache.wan.parallel;\n \n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.mockito.Mockito.doReturn;\n import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n import static org.mockito.Mockito.when;\n \n import java.util.ArrayList;\n@@ -106,6 +109,38 @@ public void validateBatchConflationWithBatchContainingDuplicateConflatableEvents\n     assertThat(gsei2.getShadowKey()).isEqualTo(lastUpdateShadowKey);\n   }\n \n+  // See GEODE-7079: a NullPointerException was thrown whenever the queue was recovered from disk\n+  // and the processor started dispatching events before the actual region was available.\n+  @Test\n+  public void verifyBatchConflationWithNullEventRegionDoesNowThrowException()\n+      throws Exception {\n+    AbstractGatewaySenderEventProcessor processor =\n+        ParallelGatewaySenderHelper.createParallelGatewaySenderEventProcessor(this.sender);\n+\n+    List<GatewaySenderEventImpl> events = new ArrayList<GatewaySenderEventImpl>();\n+\n+    LocalRegion lr = mock(LocalRegion.class);\n+    when(lr.getFullPath()).thenReturn(\"/dataStoreRegion\");\n+    when(lr.getCache()).thenReturn(this.cache);\n+\n+    // Create two events for the same key, so that conflation will be needed. Mock the getRegion()\n+    // value to return as null so we will hit the NPE if\n+    // it is referenced.\n+    GatewaySenderEventImpl gsei1 =\n+        spy(ParallelGatewaySenderHelper.createGatewaySenderEvent(lr, Operation.CREATE,\n+            \"Object_13964\", \"Object_13964_1\", 100, 27709));\n+    doReturn(null).when(gsei1).getRegion();\n+\n+    GatewaySenderEventImpl gsei2 =\n+        spy(ParallelGatewaySenderHelper.createGatewaySenderEvent(lr, Operation.UPDATE,\n+            \"Object_13964\", \"Object_13964_2\", 101, 27822));\n+    doReturn(null).when(gsei2).getRegion();\n+\n+    events.add(gsei1);\n+    events.add(gsei2);\n+    assertThatCode(() -> processor.conflate(events)).doesNotThrowAnyException();\n+  }\n+\n   @Test\n   public void validateBatchConflationWithBatchContainingDuplicateNonConflatableEvents()\n       throws Exception {",
                "raw_url": "https://github.com/apache/geode/raw/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-core/src/test/java/org/apache/geode/internal/cache/wan/parallel/ParallelGatewaySenderEventProcessorJUnitTest.java",
                "sha": "e6abad59ffea44be2c96ade4b0f58c29f531ca46",
                "status": "modified"
            },
            {
                "additions": 202,
                "blob_url": "https://github.com/apache/geode/blob/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-wan/src/distributedTest/java/org/apache/geode/internal/cache/wan/serial/SerialWANConflationDUnitTest.java",
                "changes": 216,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-wan/src/distributedTest/java/org/apache/geode/internal/cache/wan/serial/SerialWANConflationDUnitTest.java?ref=6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b",
                "deletions": 14,
                "filename": "geode-wan/src/distributedTest/java/org/apache/geode/internal/cache/wan/serial/SerialWANConflationDUnitTest.java",
                "patch": "@@ -14,23 +14,149 @@\n  */\n package org.apache.geode.internal.cache.wan.serial;\n \n+import static org.apache.geode.cache.wan.GatewaySender.DEFAULT_BATCH_TIME_INTERVAL;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.nio.file.Files;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n \n+import org.junit.Rule;\n import org.junit.Test;\n \n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.DiskStore;\n+import org.apache.geode.cache.DiskStoreFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.Scope;\n+import org.apache.geode.cache.wan.GatewayEventFilter;\n+import org.apache.geode.cache.wan.GatewaySender;\n+import org.apache.geode.cache.wan.GatewaySenderFactory;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.cache.RegionQueue;\n+import org.apache.geode.internal.cache.wan.AbstractGatewaySender;\n+import org.apache.geode.internal.cache.wan.InternalGatewaySenderFactory;\n import org.apache.geode.internal.cache.wan.WANTestBase;\n+import org.apache.geode.test.dunit.IgnoredException;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.junit.rules.serializable.SerializableTemporaryFolder;\n \n \n public class SerialWANConflationDUnitTest extends WANTestBase {\n \n+  @Rule\n+  public SerializableTemporaryFolder temporaryFolder = new SerializableTemporaryFolder();\n+\n+  private void createCacheWithLogFile(Integer locPort, String logFile) {\n+    WANTestBase test = new WANTestBase();\n+    Properties props = test.getDistributedSystemProperties();\n+    props.setProperty(MCAST_PORT, \"0\");\n+    String logLevel = System.getProperty(LOG_LEVEL, \"info\");\n+    props.setProperty(LOG_LEVEL, logLevel);\n+    props.setProperty(LOCATORS, \"localhost[\" + locPort + \"]\");\n+    props.setProperty(LOG_FILE, logFile);\n+\n+    InternalDistributedSystem ds = test.getSystem(props);\n+    cache = CacheFactory.create(ds);\n+  }\n+\n+  private File createDirectory(String name) {\n+    assertThat(name).isNotEmpty();\n+\n+    File directory = new File(temporaryFolder.getRoot(), name);\n+    if (!directory.exists()) {\n+      try {\n+        return temporaryFolder.newFolder(name);\n+      } catch (IOException e) {\n+        throw new UncheckedIOException(e);\n+      }\n+    }\n+\n+    return directory;\n+  }\n+\n+  private GatewaySenderFactory configureGateway(DiskStoreFactory dsf, File[] dirs1, String dsName,\n+      boolean isParallel, Integer maxMemory, Integer batchSize, boolean isConflation,\n+      boolean isPersistent, GatewayEventFilter filter, int numDispatchers,\n+      GatewaySender.OrderPolicy policy, int socketBufferSize, int batchTimeInterval) {\n+    InternalGatewaySenderFactory gateway =\n+        (InternalGatewaySenderFactory) cache.createGatewaySenderFactory();\n+    gateway.setParallel(isParallel);\n+    gateway.setMaximumQueueMemory(maxMemory);\n+    gateway.setBatchSize(batchSize);\n+    gateway.setBatchConflationEnabled(isConflation);\n+    gateway.setDispatcherThreads(numDispatchers);\n+    gateway.setOrderPolicy(policy);\n+    gateway.setLocatorDiscoveryCallback(new MyLocatorCallback());\n+    gateway.setSocketBufferSize(socketBufferSize);\n+    gateway.setBatchTimeInterval(batchTimeInterval);\n+\n+    if (filter != null) {\n+      eventFilter = filter;\n+      gateway.addGatewayEventFilter(filter);\n+    }\n+\n+    if (isPersistent) {\n+      gateway.setPersistenceEnabled(true);\n+      gateway.setDiskStoreName(dsf.setDiskDirs(dirs1).create(dsName).getName());\n+    } else {\n+      DiskStore store = dsf.setDiskDirs(dirs1).create(dsName);\n+      gateway.setDiskStoreName(store.getName());\n+    }\n+\n+    return gateway;\n+  }\n+\n+  private void createSender(String dsName, int remoteDsId, boolean isParallel, Integer maxMemory,\n+      Integer batchSize, boolean isConflation, boolean isPersistent, GatewayEventFilter filter,\n+      int batchTimeInterval) {\n+    final IgnoredException exln = IgnoredException.addIgnoredException(\"Could not connect\");\n+    try {\n+      File persistentDirectory = createDirectory(dsName + \"_disk_\" + VM.getCurrentVMNum());\n+      DiskStoreFactory dsf = cache.createDiskStoreFactory();\n+      File[] dirs1 = new File[] {persistentDirectory};\n+      GatewaySenderFactory gateway = configureGateway(dsf, dirs1, dsName, isParallel, maxMemory,\n+          batchSize, isConflation, isPersistent, filter, numDispatcherThreadsForTheRun,\n+          GatewaySender.DEFAULT_ORDER_POLICY,\n+          GatewaySender.DEFAULT_SOCKET_BUFFER_SIZE, batchTimeInterval);\n+      gateway.create(dsName, remoteDsId);\n+\n+    } finally {\n+      exln.remove();\n+    }\n+  }\n+\n+  private void waitForEventQueueSize(int expectedQueueSize) {\n+    await().untilAsserted(() -> {\n+      Set<GatewaySender> senders = cache.getGatewaySenders();\n+      Optional<GatewaySender> sender =\n+          senders.stream().filter(s -> s.getId().equals(\"ln\")).findFirst();\n+      assertThat(sender.isPresent()).isTrue();\n+      Set<RegionQueue> queues = ((AbstractGatewaySender) sender.get()).getQueues();\n+      int totalEvents = queues.stream().mapToInt(RegionQueue::size).sum();\n+      assertThat(totalEvents).isEqualTo(expectedQueueSize);\n+    });\n+  }\n+\n   @Test\n-  public void testSerialPropagationPartitionRegionBatchConflation() throws Exception {\n-    Integer lnPort = (Integer) vm0.invoke(() -> createFirstLocatorWithDSId(1));\n-    Integer nyPort = (Integer) vm1.invoke(() -> createFirstRemoteLocator(2, lnPort));\n+  public void testSerialPropagationPartitionRegionBatchConflation() {\n+    Integer lnPort = vm0.invoke(() -> createFirstLocatorWithDSId(1));\n+    Integer nyPort = vm1.invoke(() -> createFirstRemoteLocator(2, lnPort));\n \n     createCacheInVMs(nyPort, vm2, vm3);\n \n@@ -59,7 +185,7 @@ public void testSerialPropagationPartitionRegionBatchConflation() throws Excepti\n     vm7.invoke(() -> pauseSender(\"ln\"));\n \n \n-    final Map keyValues = new HashMap();\n+    final Map<Integer, Integer> keyValues = new HashMap<>();\n \n     for (int i = 1; i <= 10; i++) {\n       for (int j = 1; j <= 10; j++) {\n@@ -92,9 +218,9 @@ public void testSerialPropagationPartitionRegionBatchConflation() throws Excepti\n   }\n \n   @Test\n-  public void testSerialPropagationPartitionRegionConflationDuringEnqueue() throws Exception {\n-    Integer lnPort = (Integer) vm0.invoke(() -> createFirstLocatorWithDSId(1));\n-    Integer nyPort = (Integer) vm1.invoke(() -> createFirstRemoteLocator(2, lnPort));\n+  public void testSerialPropagationPartitionRegionConflationDuringEnqueue() {\n+    Integer lnPort = vm0.invoke(() -> createFirstLocatorWithDSId(1));\n+    Integer nyPort = vm1.invoke(() -> createFirstRemoteLocator(2, lnPort));\n \n     createCacheInVMs(nyPort, vm2, vm3);\n \n@@ -123,7 +249,7 @@ public void testSerialPropagationPartitionRegionConflationDuringEnqueue() throws\n     vm7.invoke(() -> pauseSender(\"ln\"));\n \n \n-    final Map keyValues = new HashMap();\n+    final Map<Integer, Integer> keyValues = new HashMap<>();\n \n     for (int i = 1; i <= 10; i++) {\n       for (int j = 1; j <= 10; j++) {\n@@ -134,8 +260,8 @@ public void testSerialPropagationPartitionRegionConflationDuringEnqueue() throws\n \n     ArrayList<Integer> v4List =\n         (ArrayList<Integer>) vm4.invoke(() -> WANTestBase.getSenderStats(\"ln\", 20));\n-    assertTrue(\"After conflation during enqueue, there should be only 20 events\",\n-        v4List.get(0) == 20);\n+    assertEquals(\"After conflation during enqueue, there should be only 20 events\", 20,\n+        (int) v4List.get(0));\n \n     vm4.invoke(() -> resumeSender(\"ln\"));\n     vm5.invoke(() -> resumeSender(\"ln\"));\n@@ -150,13 +276,75 @@ public void testSerialPropagationPartitionRegionConflationDuringEnqueue() throws\n     ArrayList<Integer> v7List =\n         (ArrayList<Integer>) vm7.invoke(() -> WANTestBase.getSenderStats(\"ln\", 0));\n \n-    assertTrue(\"No events in secondary queue stats since it's serial sender\",\n-        (v4List.get(10) + v5List.get(10) + v6List.get(10) + v7List.get(10)) == 0);\n-    assertTrue(\"Total queued events should be 100\",\n-        (v4List.get(2) + v5List.get(2) + v6List.get(2) + v7List.get(2)) == 100);\n+    assertEquals(\"No events in secondary queue stats since it's serial sender\", 0,\n+        (v4List.get(10) + v5List.get(10) + v6List.get(10) + v7List.get(10)));\n+    assertEquals(\"Total queued events should be 100\", 100,\n+        (v4List.get(2) + v5List.get(2) + v6List.get(2) + v7List.get(2)));\n \n     vm2.invoke(() -> validateRegionSize(getTestMethodName(), 10));\n \n   }\n \n+  @Test\n+  // See GEODE-7079: a NullPointerException was thrown whenever the queue was recovered from disk\n+  // and the processor started dispatching events before the actual region was available.\n+  public void persistentSerialGatewayWithConflationShouldNotLooseEventsNorThrowNullPointerExceptionsWhenMemberIsRestartedWhileEventsAreStillOnTheQueue()\n+      throws IOException {\n+    Integer lnPort = vm0.invoke(() -> createFirstLocatorWithDSId(1));\n+    Integer nyPort = vm1.invoke(() -> createFirstRemoteLocator(2, lnPort));\n+\n+    createCacheInVMs(nyPort, vm2);\n+    vm2.invoke(() -> createReplicatedRegion(getTestMethodName(), null, Scope.DISTRIBUTED_ACK,\n+        DataPolicy.PERSISTENT_REPLICATE, isOffHeap()));\n+    createReceiverInVMs(vm2);\n+\n+    // Create Region, associate gateway and insert some entries.\n+    vm4.invoke(() -> {\n+      createCache(lnPort);\n+      createReplicatedRegion(getTestMethodName(), \"ln\", Scope.DISTRIBUTED_ACK, DataPolicy.REPLICATE,\n+          isOffHeap());\n+\n+      // Large batch time interval and low batch size so no events are processed before the restart.\n+      createSender(\"ln\", 2, false, 100, 10, true, true, null, 120000);\n+\n+      Region<Integer, Integer> region = cache.getRegion(getTestMethodName());\n+      for (int i = 0; i < 5; i++) {\n+        region.put(i, i);\n+      }\n+      waitForEventQueueSize(5);\n+    });\n+    vm2.invoke(() -> validateRegionSize(getTestMethodName(), 0));\n+\n+    // Custom Log File to manually search for exceptions.\n+    File customLogFile = temporaryFolder.newFile(\"memberLog.log\");\n+\n+    vm4.invoke(() -> {\n+      // Restart the cache.\n+      cache.close();\n+      createCacheWithLogFile(lnPort, customLogFile.getAbsolutePath());\n+\n+      // Recover the queue from disk, reduce batch thresholds so processing starts right away.\n+      createSender(\"ln\", 2, false, 100, 5, true, true, null, DEFAULT_BATCH_TIME_INTERVAL);\n+      waitForSenderToBecomePrimary(\"ln\");\n+\n+      // Wait for the processors to start.\n+      await().until(() -> {\n+        Set<Thread> threads = Thread.getAllStackTraces().keySet();\n+        return threads\n+            .stream()\n+            .filter(t -> t.getName().contains(\"Processor for GatewaySender_ln\"))\n+            .allMatch(Thread::isAlive);\n+      });\n+\n+      // Create the region, processing will continue and no NPE should be thrown anymore.\n+      createReplicatedRegion(getTestMethodName(), \"ln\", Scope.DISTRIBUTED_ACK, DataPolicy.REPLICATE,\n+          isOffHeap());\n+    });\n+    vm2.invoke(() -> validateRegionSize(getTestMethodName(), 5));\n+\n+    Files.lines(customLogFile.toPath()).forEach((line) -> assertThat(line)\n+        .as(\"Dispatchers shouldn't have thrown any errors while processing batches\")\n+        .doesNotContain(\"An Exception occurred. The dispatcher will continue.\")\n+        .doesNotContain(\"java.lang.NullPointerException\"));\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/6f4bbbd96bcecdb82cf7753ce1dae9fa6baebf9b/geode-wan/src/distributedTest/java/org/apache/geode/internal/cache/wan/serial/SerialWANConflationDUnitTest.java",
                "sha": "df3a19db71cb1c922e9e7a9ea4526a2172095a1a",
                "status": "modified"
            }
        ],
        "message": "GEODE-7079: Prevent NPE During Queue Conflation (#3911)\n\n* GEODE-7079: Prevent NPE During Queue Conflation\r\n\r\n- Added tests.\r\n- Fixed minor warnings.\r\n- Use the cached region name when doing conflation instead of the actual region so the processor doesn't need to wait for the actual region to be fully initialized.\r\n\r\nCo-authored-by: Benjamin Ross <bross@pivotal.io>",
        "parent": "https://github.com/apache/geode/commit/374eff722708947570eb9367fc626181a1c9f4ce",
        "patched_files": [
            "AbstractGatewaySenderEventProcessor.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "AsyncEventListenerDistributedTest.java",
            "ParallelGatewaySenderEventProcessorJUnitTest.java",
            "SerialWANConflationDUnitTest.java"
        ]
    },
    "geode_6ff83bc": {
        "bug_id": "geode_6ff83bc",
        "commit": "https://github.com/apache/geode/commit/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/CompiledSelect.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/CompiledSelect.java?ref=6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7",
                "deletions": 2,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/CompiledSelect.java",
                "patch": "@@ -23,6 +23,7 @@\n import com.gemstone.gemfire.cache.query.Index;\n import com.gemstone.gemfire.cache.query.NameNotFoundException;\n import com.gemstone.gemfire.cache.query.NameResolutionException;\n+import com.gemstone.gemfire.cache.query.Query;\n import com.gemstone.gemfire.cache.query.QueryInvalidException;\n import com.gemstone.gemfire.cache.query.QueryInvocationTargetException;\n import com.gemstone.gemfire.cache.query.QueryService;\n@@ -360,9 +361,9 @@ private void evalCanonicalizedExpressionForCSC(CompiledSortCriterion csc, Execut\n    * @param cache the cache the query will be executed in the context of\n    * @return the empty result set of the appropriate type\n    */\n-  public SelectResults getEmptyResultSet(Object[] parameters, Cache cache)\n+  public SelectResults getEmptyResultSet(Object[] parameters, Cache cache, Query query)\n   throws FunctionDomainException, TypeMismatchException, NameResolutionException, QueryInvocationTargetException {\n-    ExecutionContext context = new QueryExecutionContext(parameters, cache);\n+    ExecutionContext context = new QueryExecutionContext(parameters, cache, query);\n     computeDependencies(context);\n     context.newScope(this.scopeID);\n     context.pushExecCache(scopeID);",
                "raw_url": "https://github.com/apache/geode/raw/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/CompiledSelect.java",
                "sha": "0b072119c066c0cad2d2f618b05c55449b3e2665",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/PartitionedRegion.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/PartitionedRegion.java?ref=6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/PartitionedRegion.java",
                "patch": "@@ -1979,7 +1979,7 @@ private Object doExecuteQuery(DefaultQuery query, Object[] parameters,\n     // this can return a BAG even if it's a DISTINCT select expression,\n     // since the expectation is that the duplicates will be removed at the end\n     SelectResults results = selectExpr\n-        .getEmptyResultSet(parameters, getCache());\n+        .getEmptyResultSet(parameters, getCache(), query);\n \n     PartitionedRegionQueryEvaluator prqe = new PartitionedRegionQueryEvaluator(this.getSystem(), this, query,\n         parameters, results, allBuckets);",
                "raw_url": "https://github.com/apache/geode/raw/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/PartitionedRegion.java",
                "sha": "c00789186b11354039a2ef14ad0cf11d4a7abd27",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryDUnitTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryDUnitTest.java?ref=6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7",
                "deletions": 4,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryDUnitTest.java",
                "patch": "@@ -398,7 +398,7 @@ public void hook(int spot) throws RuntimeException {\n       final DefaultQuery query = (DefaultQuery)getCache().getQueryService()\n           .newQuery(\"select distinct * from \" + pr.getFullPath());\n       final SelectResults results = query.getSimpleSelect().getEmptyResultSet(\n-          params, getCache());\n+          params, getCache(), query);\n \n       // TODO assert this is the correct set of bucket Ids,\n       final HashSet<Integer> buckets = new HashSet<Integer>();\n@@ -477,7 +477,7 @@ public void run2() throws CacheException {\n       for (int q=0; q < queries.length; q++) {\n         Object[] params = new Object[0];\n         final DefaultQuery query = (DefaultQuery)getCache().getQueryService().newQuery(queries[q]);\n-        final SelectResults results = query.getSimpleSelect().getEmptyResultSet(params, getCache());\n+        final SelectResults results = query.getSimpleSelect().getEmptyResultSet(params, getCache(), query);\n \n         // TODO assert this is the correct set of bucket Ids,\n         final HashSet<Integer> buckets = new HashSet<Integer>();\n@@ -583,7 +583,7 @@ public void run2() throws CacheException {\n       for (int q=0; q < queries.length; q++) {\n         Object[] params = new Object[0];\n         final DefaultQuery query = (DefaultQuery)getCache().getQueryService().newQuery(queries[q]);\n-        final SelectResults results = query.getSimpleSelect().getEmptyResultSet(params, getCache());\n+        final SelectResults results = query.getSimpleSelect().getEmptyResultSet(params, getCache(), query);\n \n         // TODO assert this is the correct set of bucket Ids,\n         final HashSet<Integer> buckets = new HashSet<Integer>();\n@@ -688,7 +688,7 @@ public Object call() throws Exception {\n         final DefaultQuery query = (DefaultQuery)getCache().getQueryService()\n             .newQuery(\"select distinct * from \" + pr.getFullPath());\n         final SelectResults results = query.getSimpleSelect()\n-            .getEmptyResultSet(params, getCache());\n+            .getEmptyResultSet(params, getCache(), query);\n \n         // Fake data loss\n         final HashSet<Integer> buckets = new HashSet<Integer>();",
                "raw_url": "https://github.com/apache/geode/raw/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryDUnitTest.java",
                "sha": "5fb711c8dd99f22c7c7b930c85545884f0e66501",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/geode/blob/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryJUnitTest.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryJUnitTest.java?ref=6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7",
                "deletions": 0,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryJUnitTest.java",
                "patch": "@@ -10,14 +10,19 @@\n import static org.junit.Assert.fail;\n \n import java.util.HashMap;\n+import java.util.Iterator;\n \n import org.junit.Before;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n \n import com.gemstone.gemfire.LogWriter;\n+import com.gemstone.gemfire.cache.Cache;\n import com.gemstone.gemfire.cache.Region;\n+import com.gemstone.gemfire.cache.RegionShortcut;\n+import com.gemstone.gemfire.cache.query.CacheUtils;\n import com.gemstone.gemfire.cache.query.Query;\n+import com.gemstone.gemfire.cache.query.QueryService;\n import com.gemstone.gemfire.cache.query.SelectResults;\n import com.gemstone.gemfire.cache.query.data.PortfolioData;\n import com.gemstone.gemfire.internal.Assert;\n@@ -134,6 +139,31 @@ public void testOrderByQuery() throws Exception\n     }\n   }\n \n+  @Test\n+  public void testNestedPRQuery() throws Exception {\n+    Cache cache = CacheUtils.getCache();\n+    QueryService queryService = CacheUtils.getCache().getQueryService();\n+    Region region = cache.createRegionFactory(RegionShortcut.PARTITION).create(\"TEST_REGION\");\n+    Query query = queryService.newQuery(\"SELECT distinct COUNT(*) FROM (SELECT DISTINCT tr.id, tr.domain FROM /TEST_REGION tr)\");\n+    region.put(\"1\", cache.createPdxInstanceFactory(\"obj1\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain1\").create());\n+    region.put(\"2\", cache.createPdxInstanceFactory(\"obj2\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain1\").create());\n+    region.put(\"3\", cache.createPdxInstanceFactory(\"obj3\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain1\").create());\n+    region.put(\"4\", cache.createPdxInstanceFactory(\"obj4\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain1\").create());\n+    region.put(\"5\", cache.createPdxInstanceFactory(\"obj5\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain1\").create());\n+    region.put(\"6\", cache.createPdxInstanceFactory(\"obj6\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+    region.put(\"7\", cache.createPdxInstanceFactory(\"obj7\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+    region.put(\"8\", cache.createPdxInstanceFactory(\"obj8\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+    region.put(\"9\", cache.createPdxInstanceFactory(\"obj9\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+    region.put(\"10\", cache.createPdxInstanceFactory(\"obj10\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+    region.put(\"11\", cache.createPdxInstanceFactory(\"obj11\").writeString(\"id\", \"1\").writeString(\"domain\", \"domain2\").create());\n+\n+    SelectResults queryResults = (SelectResults) query.execute();\n+    Assert.assertTrue(queryResults.size() == 1);\n+    Iterator iterator = queryResults.iterator();\n+    Assert.assertTrue(iterator.hasNext());\n+    Assert.assertTrue((\"\" + iterator.next()).equals(\"2\"));\n+ }\n+\n   /**\n    * Populates the region with the Objects stores in the data Object array.\n    * ",
                "raw_url": "https://github.com/apache/geode/raw/6ff83bcd64a14b2fe731f4468f9ab798f8cc85f7/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/partitioned/PRQueryJUnitTest.java",
                "sha": "ccc9db2fbd20e7f586b69a825adadfa04f1147a9",
                "status": "modified"
            }
        ],
        "message": "GEODE-100: Nested count(*) query on pr causes NullPointerException\nQuery object in query execution was being used without being set for nested queries.\n\nReviewed by agingade",
        "parent": "https://github.com/apache/geode/commit/9d7949555fce852b10d0b2e023a578aa446ea23a",
        "patched_files": [
            "PartitionedRegion.java",
            "CompiledSelect.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PRQueryDUnitTest.java",
            "PRQueryJUnitTest.java"
        ]
    },
    "geode_7041507": {
        "bug_id": "geode_7041507",
        "commit": "https://github.com/apache/geode/commit/70415070443137941ff1c1b750af81cf4442f6ef",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/70415070443137941ff1c1b750af81cf4442f6ef/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java?ref=70415070443137941ff1c1b750af81cf4442f6ef",
                "deletions": 1,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "patch": "@@ -225,7 +225,6 @@ private void createIndexOnExistingRegion(PartitionedRegion region, String indexN\n     validateRegionAttributes(region.getAttributes());\n \n     String aeqId = LuceneServiceImpl.getUniqueIndexName(indexName, regionPath);\n-    region.addAsyncEventQueueId(aeqId, true);\n \n     region.addCacheServiceProfile(new LuceneIndexCreationProfile(indexName, regionPath, fields,\n         analyzer, fieldAnalyzers, serializer));\n@@ -235,6 +234,8 @@ private void createIndexOnExistingRegion(PartitionedRegion region, String indexN\n \n     afterDataRegionCreated(luceneIndex);\n \n+    region.addAsyncEventQueueId(aeqId, true);\n+\n     createLuceneIndexOnDataRegion(region, luceneIndex);\n   }\n \n@@ -252,6 +253,10 @@ protected boolean createLuceneIndexOnDataRegion(final PartitionedRegion userRegi\n         int primaryBucketId = (Integer) primaryBucketIterator.next();\n         try {\n           BucketRegion userBucket = userRegion.getDataStore().getLocalBucketById(primaryBucketId);\n+          if (userBucket == null) {\n+            throw new BucketNotFoundException(\n+                \"Bucket ID : \" + primaryBucketId + \" not found during lucene indexing\");\n+          }\n           if (!userBucket.isEmpty()) {\n             /**\n              *",
                "raw_url": "https://github.com/apache/geode/raw/70415070443137941ff1c1b750af81cf4442f6ef/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/LuceneServiceImpl.java",
                "sha": "b5987e2a7e8f93220fe12a122ac193e099d459d2",
                "status": "modified"
            },
            {
                "additions": 74,
                "blob_url": "https://github.com/apache/geode/blob/70415070443137941ff1c1b750af81cf4442f6ef/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplJUnitTest.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplJUnitTest.java?ref=70415070443137941ff1c1b750af81cf4442f6ef",
                "deletions": 3,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplJUnitTest.java",
                "patch": "@@ -16,39 +16,59 @@\n \n import static org.junit.Assert.*;\n import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyString;\n import static org.mockito.ArgumentMatchers.eq;\n import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n \n import java.lang.reflect.Field;\n+import java.util.Arrays;\n import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.lucene.analysis.Analyzer;\n import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n import org.junit.rules.ExpectedException;\n import org.mockito.Mockito;\n \n-import org.apache.geode.cache.Region;\n+import org.apache.geode.Statistics;\n+import org.apache.geode.StatisticsFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.EvictionAlgorithm;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.RegionAttributes;\n+import org.apache.geode.cache.asyncqueue.internal.AsyncEventQueueFactoryImpl;\n import org.apache.geode.cache.lucene.LuceneIndexFactory;\n import org.apache.geode.cache.lucene.LuceneSerializer;\n+import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.internal.cache.GemFireCacheImpl;\n+import org.apache.geode.internal.cache.PartitionedRegion;\n+import org.apache.geode.internal.cache.PartitionedRegionDataStore;\n import org.apache.geode.test.junit.categories.UnitTest;\n \n @Category(UnitTest.class)\n public class LuceneServiceImplJUnitTest {\n   @Rule\n   public ExpectedException thrown = ExpectedException.none();\n \n-  Region region;\n+  PartitionedRegion region;\n   GemFireCacheImpl cache;\n   LuceneServiceImpl service = new LuceneServiceImpl();\n \n   @Before\n   public void createMocks() throws NoSuchFieldException, SecurityException,\n       IllegalArgumentException, IllegalAccessException {\n-    region = mock(Region.class);\n+    region = mock(PartitionedRegion.class);\n     cache = mock(GemFireCacheImpl.class);\n     Field f = LuceneServiceImpl.class.getDeclaredField(\"cache\");\n     f.setAccessible(true);\n@@ -86,4 +106,55 @@ public void shouldReturnFalseIfRegionNotFoundInWaitUntilFlush() throws Interrupt\n     assertFalse(result);\n   }\n \n+  @Test\n+  public void userRegionShouldNotBeSetBeforeIndexInitialized() throws Exception {\n+    TestLuceneServiceImpl testService = new TestLuceneServiceImpl();\n+    Field f = LuceneServiceImpl.class.getDeclaredField(\"cache\");\n+    f.setAccessible(true);\n+    f.set(testService, cache);\n+    AsyncEventQueueFactoryImpl aeqFactory = mock(AsyncEventQueueFactoryImpl.class);\n+    when(cache.createAsyncEventQueueFactory()).thenReturn(aeqFactory);\n+\n+    DistributedSystem ds = mock(DistributedSystem.class);\n+    Statistics luceneIndexStats = mock(Statistics.class);\n+    when(cache.getDistributedSystem()).thenReturn(ds);\n+    when(((StatisticsFactory) ds).createAtomicStatistics(any(), anyString()))\n+        .thenReturn(luceneIndexStats);\n+    when(cache.getRegion(anyString())).thenReturn(region);\n+\n+    RegionAttributes ratts = mock(RegionAttributes.class);\n+    when(region.getAttributes()).thenReturn(ratts);\n+    when(ratts.getDataPolicy()).thenReturn(DataPolicy.PARTITION);\n+    EvictionAttributes evictionAttrs = mock(EvictionAttributes.class);\n+    when(ratts.getEvictionAttributes()).thenReturn(evictionAttrs);\n+    when(evictionAttrs.getAlgorithm()).thenReturn(EvictionAlgorithm.NONE);\n+\n+    Map<String, Analyzer> fieldMap = new HashMap<String, Analyzer>();\n+    fieldMap.put(\"field1\", null);\n+    fieldMap.put(\"field2\", null);\n+    testService.createIndex(\"index\", \"region\", fieldMap, null, true);\n+  }\n+\n+  @Test\n+  public void createLuceneIndexOnExistingRegionShouldNotThrowNPEIfBucketMovedDuringReindexing() {\n+    LuceneIndexImpl index = mock(LuceneIndexImpl.class);\n+    PartitionedRegionDataStore dataStore = mock(PartitionedRegionDataStore.class);\n+    when(region.getDataStore()).thenReturn(dataStore);\n+    Integer bucketIds[] = {1, 2, 3, 4, 5};\n+    Set<Integer> primaryBucketIds = new HashSet(Arrays.asList(bucketIds));\n+    when(dataStore.getAllLocalPrimaryBucketIds()).thenReturn(primaryBucketIds);\n+    when(dataStore.getLocalBucketById(3)).thenReturn(null);\n+    boolean result = service.createLuceneIndexOnDataRegion(region, index);\n+    assertTrue(result);\n+  }\n+\n+  private class TestLuceneServiceImpl extends LuceneServiceImpl {\n+\n+    @Override\n+    public void afterDataRegionCreated(LuceneIndexImpl index) {\n+      PartitionedRegion userRegion =\n+          (PartitionedRegion) index.getCache().getRegion(index.getRegionPath());\n+      verify(userRegion, never()).addAsyncEventQueueId(anyString(), anyBoolean());\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/70415070443137941ff1c1b750af81cf4442f6ef/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/LuceneServiceImplJUnitTest.java",
                "sha": "1b799f5413f87491ad5ec76523af1bf8e4b94170",
                "status": "modified"
            }
        ],
        "message": "GEODE-4764: Address NPEs during Lucene index creation on existing region\n\n* Don't add the aeq to the region until the data region has been created\n* When iterating over list of local primary bucketIds (during reindexing), check for null return value when retrieving a specific bucket\n* Added tests for same.",
        "parent": "https://github.com/apache/geode/commit/c16f28040523e72efdada6da0398657723e6c262",
        "patched_files": [
            "LuceneServiceImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "LuceneServiceImplJUnitTest.java"
        ]
    },
    "geode_71c863b": {
        "bug_id": "geode_71c863b",
        "commit": "https://github.com/apache/geode/commit/71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f/geode-core/src/main/java/com/gemstone/gemfire/internal/GemFireVersion.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/com/gemstone/gemfire/internal/GemFireVersion.java?ref=71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f",
                "deletions": 1,
                "filename": "geode-core/src/main/java/com/gemstone/gemfire/internal/GemFireVersion.java",
                "patch": "@@ -207,7 +207,7 @@ public VersionDescription(String name) {\n     }\n \n     public String getProperty(String key) {\n-      return error.orElse(description.getProperty(key));\n+      return error.orElseGet(() -> description.getProperty(key));\n     }\n     \n     public String getNativeCodeVersion() {",
                "raw_url": "https://github.com/apache/geode/raw/71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f/geode-core/src/main/java/com/gemstone/gemfire/internal/GemFireVersion.java",
                "sha": "73c36c504fde4a594a24cd9496f6e1e71d5ae72a",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f/geode-core/src/test/java/com/gemstone/gemfire/internal/GemFireVersionJUnitTest.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/internal/GemFireVersionJUnitTest.java?ref=71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f",
                "deletions": 0,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/internal/GemFireVersionJUnitTest.java",
                "patch": "@@ -17,6 +17,7 @@\n package com.gemstone.gemfire.internal;\n \n import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertEquals;\n \n import java.io.PrintWriter;\n import java.io.StringWriter;\n@@ -64,4 +65,13 @@ public void testNoFile() {\n     String noFileOutput = sw.toString();\n     assertTrue(noFileOutput.contains(LocalizedStrings.GemFireVersion_COULD_NOT_FIND_RESOURCE_COM_GEMSTONE_GEMFIRE_INTERNAL_0.toLocalizedString(noFile)));\n   }\n+  \n+  @Test\n+  public void testNoFileGetProperty() {\n+    String noFile = \"not a property file\";\n+    VersionDescription noVersion = new VersionDescription(noFile);\n+\n+    String err = LocalizedStrings.GemFireVersion_COULD_NOT_FIND_RESOURCE_COM_GEMSTONE_GEMFIRE_INTERNAL_0.toLocalizedString(noFile);\n+    assertEquals(err, noVersion.getProperty(VersionDescription.GEMFIRE_VERSION));\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/71c863b5c6ffda7fc212a13b05ff3c47b6e13d3f/geode-core/src/test/java/com/gemstone/gemfire/internal/GemFireVersionJUnitTest.java",
                "sha": "44df2ca555860b83039a4486b350200317999ebc",
                "status": "modified"
            }
        ],
        "message": "GEODE-1809: Fix NPE in GemFireVersion\n\nAdd a unit test to validate behavior when properties file is not\npresent.",
        "parent": "https://github.com/apache/geode/commit/e4a09a6a784ff729c006dba28ec697fd89ac86cd",
        "patched_files": [
            "GemFireVersion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GemFireVersionJUnitTest.java"
        ]
    },
    "geode_7482c00": {
        "bug_id": "geode_7482c00",
        "commit": "https://github.com/apache/geode/commit/7482c00bfe838414825cbd0d2a39b8c00fa476d5",
        "file": [
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/geode/blob/7482c00bfe838414825cbd0d2a39b8c00fa476d5/geode-core/src/main/java/org/apache/geode/internal/ClassPathLoader.java",
                "changes": 49,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/ClassPathLoader.java?ref=7482c00bfe838414825cbd0d2a39b8c00fa476d5",
                "deletions": 27,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/ClassPathLoader.java",
                "patch": "@@ -16,7 +16,6 @@\n \n import static java.util.stream.Collectors.joining;\n \n-import org.apache.commons.io.FileUtils;\n import org.apache.geode.distributed.internal.DistributionConfig;\n import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.util.CollectionUtils;\n@@ -26,13 +25,13 @@\n import java.io.IOException;\n import java.io.InputStream;\n import java.lang.reflect.Proxy;\n-import java.net.MalformedURLException;\n import java.net.URL;\n import java.net.URLClassLoader;\n-import java.util.*;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicReference;\n-import java.util.stream.Collectors;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Enumeration;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n \n /**\n  * The delegating <tt>ClassLoader</tt> used by GemFire to load classes and other resources. This\n@@ -57,30 +56,27 @@\n  * <li>4. <tt>ClassLoader.getSystemClassLoader()</tt> If the attempt to acquire any of the above\n  * class loaders results in either a {@link java.lang.SecurityException SecurityException} or a\n  * null, then that class loader is quietly skipped. Duplicate class loaders will be skipped.\n- * \n+ * <p>\n+ * This class it not an extension of ClassLoader due to #43080. See also\n+ * http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-5.html\n+ *\n  * @since GemFire 6.5.1.4\n  */\n-public final class ClassPathLoader {\n-  /*\n-   * This class it not an extension of ClassLoader due to reasons outlined in\n-   * https://svn.gemstone.com/trac/gemfire/ticket/43080\n-   * \n-   * See also http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-5.html\n-   */\n+public class ClassPathLoader {\n   private static final Logger logger = LogService.getLogger();\n \n-  public static final String EXCLUDE_TCCL_PROPERTY =\n+  static final String EXCLUDE_TCCL_PROPERTY =\n       DistributionConfig.GEMFIRE_PREFIX + \"excludeThreadContextClassLoader\";\n-  public static final boolean EXCLUDE_TCCL_DEFAULT_VALUE = false;\n \n   private static volatile ClassPathLoader latest;\n \n   private volatile URLClassLoader classLoaderForDeployedJars;\n+\n   private final JarDeployer jarDeployer;\n \n   private boolean excludeTCCL;\n \n-  public void rebuildClassLoaderForDeployedJars() {\n+  void rebuildClassLoaderForDeployedJars() {\n     ClassLoader parent = ClassPathLoader.class.getClassLoader();\n \n     this.classLoaderForDeployedJars = new URLClassLoader(jarDeployer.getDeployedJarURLs(), parent);\n@@ -98,7 +94,7 @@ public ClassPathLoader(boolean excludeTCCL, File workingDir) {\n     rebuildClassLoaderForDeployedJars();\n   }\n \n-  public static ClassPathLoader setLatestToDefault() {\n+  static ClassPathLoader setLatestToDefault() {\n     latest = new ClassPathLoader(Boolean.getBoolean(EXCLUDE_TCCL_PROPERTY));\n     return latest;\n   }\n@@ -112,7 +108,9 @@ public JarDeployer getJarDeployer() {\n     return this.jarDeployer;\n   }\n \n-  // This is exposed for testing.\n+  /**\n+   * createWithDefaults is exposed for testing.\n+   */\n   static ClassPathLoader createWithDefaults(final boolean excludeTCCL) {\n     return new ClassPathLoader(excludeTCCL);\n   }\n@@ -174,7 +172,7 @@ public URL getResource(final String name) {\n   /**\n    * See {@link Proxy#getProxyClass(ClassLoader, Class...)}\n    */\n-  public Class<?> getProxyClass(final Class<?>[] classObjs) {\n+  Class<?> getProxyClass(final Class<?>... classObjs) {\n     IllegalArgumentException ex = null;\n \n     for (ClassLoader classLoader : this.getClassLoaders()) {\n@@ -227,11 +225,9 @@ public URL getResource(final Class<?> contextClass, final String name) {\n \n   /**\n    * Returns an input stream for reading the specified resource.\n-   *\n    * <p>\n    * The search order is described in the documentation for {@link #getResource(String)}.\n-   * </p>\n-   * \n+   *\n    * @param name The resource name\n    * @return An input stream for reading the resource, or <tt>null</tt> if the resource could not be\n    *         found\n@@ -265,7 +261,6 @@ public InputStream getResourceAsStream(final Class<?> contextClass, final String\n     return getResourceAsStream(name);\n   }\n \n-\n   /**\n    * Finds all the resources with the given name. This method will first search the class loader of\n    * the context class for the resource before searching all other {@link ClassLoader}s.\n@@ -278,7 +273,7 @@ public InputStream getResourceAsStream(final Class<?> contextClass, final String\n    * @throws IOException If I/O errors occur\n    * @see ClassLoader#getResources(String)\n    */\n-  public Enumeration<URL> getResources(final Class<?> contextClass, final String name)\n+  private Enumeration<URL> getResources(final Class<?> contextClass, final String name)\n       throws IOException {\n     final LinkedHashSet<URL> urls = new LinkedHashSet<URL>();\n \n@@ -369,8 +364,8 @@ public static ClassPathLoader getLatest() {\n    * @return {@link ClassLoader} for current {@link ClassPathLoader}.\n    * @since GemFire 8.1\n    */\n-  public static final ClassLoader getLatestAsClassLoader() {\n-    return latest.asClassLoader();\n+  public static ClassLoader getLatestAsClassLoader() {\n+    return getLatest().asClassLoader();\n   }\n \n }",
                "raw_url": "https://github.com/apache/geode/raw/7482c00bfe838414825cbd0d2a39b8c00fa476d5/geode-core/src/main/java/org/apache/geode/internal/ClassPathLoader.java",
                "sha": "b272f8a35d26d5b4b8967c1b5eb3a814a36a5eff",
                "status": "modified"
            }
        ],
        "message": "GEODE-2884: fix NPE when calling getLatestAsClassLoader before getLatest\n\nWithout this fix, CacheXmlParserJUnitTest.testGetDelegate() fails when\nrun in isolation but passes when run with all tests.",
        "parent": "https://github.com/apache/geode/commit/34deeabb9474a47052d06e8f25de018524f188e5",
        "patched_files": [
            "ClassPathLoader.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ClassPathLoaderTest.java"
        ]
    },
    "geode_7661eca": {
        "bug_id": "geode_7661eca",
        "commit": "https://github.com/apache/geode/commit/7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/ClusterCommunicationsDUnitTest.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/ClusterCommunicationsDUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 1,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/ClusterCommunicationsDUnitTest.java",
                "patch": "@@ -30,6 +30,7 @@\n import static org.apache.geode.distributed.ConfigurationProperties.USE_CLUSTER_CONFIGURATION;\n import static org.apache.geode.internal.DataSerializableFixedID.SERIAL_ACKED_MESSAGE;\n import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.getTimeout;\n import static org.assertj.core.api.Assertions.assertThat;\n \n import java.io.DataInput;\n@@ -216,7 +217,7 @@ public void performARollingUpgrade() {\n       // System.setProperty(\"javax.net.debug\", \"all\");\n       Properties props = getDistributedSystemProperties();\n       // locator must restart with the same port so that it reconnects to the server\n-      await().atMost(15, TimeUnit.SECONDS)\n+      await().atMost(getTimeout().getValueInMS(), TimeUnit.MILLISECONDS)\n           .until(() -> Locator.startLocatorAndDS(locatorPort, new File(\"\"), props) != null);\n       assertThat(Locator.getLocator().getDistributedSystem().getAllOtherMembers().size())\n           .isGreaterThan(0);",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/ClusterCommunicationsDUnitTest.java",
                "sha": "c970f778735c2f1f5560520b9398ad82c018d50c",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "changes": 39,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectDUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 16,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "patch": "@@ -15,6 +15,8 @@\n package org.apache.geode.cache30;\n \n import static java.lang.System.out;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.MINUTES;\n import static java.util.concurrent.TimeUnit.SECONDS;\n import static org.apache.geode.cache.DataPolicy.REPLICATE;\n import static org.apache.geode.cache.LossAction.RECONNECT;\n@@ -37,9 +39,11 @@\n import static org.apache.geode.distributed.internal.membership.gms.MembershipManagerHelper.getMembershipManager;\n import static org.apache.geode.internal.cache.xmlcache.CacheXmlGenerator.generate;\n import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.getTimeout;\n import static org.apache.geode.test.dunit.Host.getHost;\n import static org.apache.geode.test.dunit.IgnoredException.addIgnoredException;\n import static org.apache.geode.test.dunit.ThreadUtils.join;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n import static org.hamcrest.Matchers.notNullValue;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertFalse;\n@@ -63,6 +67,7 @@\n \n import org.apache.geode.CancelException;\n import org.apache.geode.cache.AttributesFactory;\n+import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.CacheException;\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.DataPolicy;\n@@ -80,6 +85,7 @@\n import org.apache.geode.cache.util.CacheListenerAdapter;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.DistributedSystem;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n import org.apache.geode.distributed.Locator;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.InternalDistributedSystem.ReconnectListener;\n@@ -401,7 +407,7 @@ public String description() {\n             System.out.println(\"ds.isReconnecting() = \" + ds.isReconnecting());\n             boolean failure = true;\n             try {\n-              ds.waitUntilReconnected(60, SECONDS);\n+              ds.waitUntilReconnected(getTimeout().getValueInMS(), MILLISECONDS);\n               savedSystem = ds.getReconnectedSystem();\n               locator = (InternalLocator) getLocator();\n               assertTrue(\"Expected system to be restarted\", ds.getReconnectedSystem() != null);\n@@ -480,15 +486,14 @@ public Object call() {\n \n   /** this will throw an exception if location services aren't running */\n   private void ensureLocationServiceRunning(VM vm) {\n-    vm.invoke(new SerializableRunnable(\"ensureLocationServiceRunning\") {\n-      @Override\n-      public void run() {\n+    vm.invoke(\"ensureLocationServiceRunning\", () -> {\n+      await().untilAsserted(() -> {\n         InternalLocator intloc = (InternalLocator) locator;\n         ServerLocator serverLocator = intloc.getServerLocatorAdvisee();\n         // the initialization flag in the locator's ControllerAdvisor will\n         // be set if a handshake has been performed\n         assertTrue(serverLocator.getDistributionAdvisor().isInitialized());\n-      }\n+      });\n     });\n   }\n \n@@ -511,7 +516,7 @@ public String description() {\n                 return \"waiting for ds to begin reconnecting\";\n               }\n             });\n-            long waitTime = 120;\n+            long waitTime = 600;\n             System.out.println(\"VM\" + VM.getCurrentVMNum() + \" waiting up to \"\n                 + waitTime + \" seconds for reconnect to complete\");\n             try {\n@@ -1070,7 +1075,8 @@ public void run() {\n         ReconnectDUnitTest.savedCache = (GemFireCacheImpl) getCache();\n         Region myRegion = createRegion(\"myRegion\", createAtts());\n         myRegion.put(\"MyKey\", \"MyValue\");\n-        myRegion.getAttributesMutator().addCacheListener(new CacheKillingListener());\n+        myRegion.getAttributesMutator()\n+            .addCacheListener(new CacheListenerTriggeringForcedDisconnect());\n       }\n     };\n \n@@ -1098,7 +1104,7 @@ public String description() {\n         });\n         out.println(\"entering reconnect wait for \" + cache);\n         try {\n-          cache.waitUntilReconnected(20, SECONDS);\n+          cache.waitUntilReconnected(5, MINUTES);\n         } catch (InterruptedException e) {\n           fail(\"interrupted\");\n         }\n@@ -1155,11 +1161,10 @@ public String description() {\n         return \"waiting for cache to begin reconnecting\";\n       }\n     });\n-    try {\n-      cache.waitUntilReconnected(20, SECONDS);\n-    } catch (InterruptedException e) {\n-      fail(\"interrupted\");\n-    }\n+    assertThatThrownBy(() -> cache.waitUntilReconnected(getTimeout().getValueInMS(), MILLISECONDS))\n+        .isInstanceOf(CacheClosedException.class)\n+        .hasMessageContaining(\"Cache could not be recreated\")\n+        .hasCauseExactlyInstanceOf(DistributedSystemDisconnectedException.class);\n     assertTrue(cache.getInternalDistributedSystem().isReconnectCancelled());\n     assertNull(cache.getReconnectedCache());\n   }\n@@ -1290,7 +1295,7 @@ public Object call() throws Exception {\n           WaitCriterion wc = new WaitCriterion() {\n             @Override\n             public boolean done() {\n-              return msys.isReconnecting();\n+              return msys.isReconnecting() || msys.getReconnectedSystem() != null;\n             }\n \n             @Override\n@@ -1323,10 +1328,12 @@ public void init(Properties props) {\n   }\n \n   /**\n-   * CacheKillingListener crashes the distributed system when it is invoked for the first time.\n+   * CacheListenerTriggeringForcedDisconnect crashes the distributed system when it is invoked for\n+   * the first time.\n    * After that it ignores any notifications.\n    */\n-  public static class CacheKillingListener extends CacheListenerAdapter implements Declarable {\n+  public static class CacheListenerTriggeringForcedDisconnect extends CacheListenerAdapter\n+      implements Declarable {\n     public static int crashCount = 0;\n \n     @Override",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectDUnitTest.java",
                "sha": "232d72985c5591017790e497c97291171e41c554",
                "status": "modified"
            },
            {
                "additions": 193,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectWithClusterConfigurationDUnitTest.java",
                "changes": 193,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectWithClusterConfigurationDUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectWithClusterConfigurationDUnitTest.java",
                "patch": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache30;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.DISABLE_AUTO_RECONNECT;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_CLUSTER_CONFIGURATION;\n+import static org.apache.geode.distributed.ConfigurationProperties.ENABLE_NETWORK_PARTITION_DETECTION;\n+import static org.apache.geode.distributed.ConfigurationProperties.HTTP_SERVICE_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_LEVEL;\n+import static org.apache.geode.distributed.ConfigurationProperties.MAX_WAIT_TIME_RECONNECT;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.apache.geode.distributed.ConfigurationProperties.MEMBER_TIMEOUT;\n+import static org.apache.geode.distributed.ConfigurationProperties.NAME;\n+import static org.apache.geode.distributed.ConfigurationProperties.USE_CLUSTER_CONFIGURATION;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.distributed.DistributedSystem;\n+import org.apache.geode.distributed.Locator;\n+import org.apache.geode.distributed.internal.InternalConfigurationPersistenceService;\n+import org.apache.geode.distributed.internal.InternalLocator;\n+import org.apache.geode.distributed.internal.membership.gms.MembershipManagerHelper;\n+import org.apache.geode.internal.AvailablePort;\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.Assert;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.Disconnect;\n+import org.apache.geode.test.dunit.IgnoredException;\n+import org.apache.geode.test.dunit.Invoke;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+public class ReconnectWithClusterConfigurationDUnitTest implements Serializable {\n+  static final int NUM_LOCATORS = 2;\n+  static final int NUM_VMS = 4;\n+  static DistributedSystem system;\n+  static Cache cache;\n+  static Locator locator;\n+  static int[] locatorPorts = new int[NUM_LOCATORS];\n+  static Properties dsProperties;\n+\n+  @Rule\n+  public DistributedRule distributedRule = DistributedRule.builder().withVMCount(NUM_VMS).build();\n+\n+  @Before\n+  public void setup() {\n+    List<AvailablePort.Keeper> randomAvailableTCPPortKeepers =\n+        AvailablePortHelper.getRandomAvailableTCPPortKeepers(NUM_LOCATORS);\n+    for (int i = 0; i < NUM_LOCATORS; i++) {\n+      AvailablePort.Keeper keeper = randomAvailableTCPPortKeepers.get(i);\n+      locatorPorts[i] = keeper.getPort();\n+    }\n+    final int[] locPorts = locatorPorts;\n+    Invoke.invokeInEveryVM(\"set locator ports\", () -> locatorPorts = locPorts);\n+    for (int i = 0; i < NUM_LOCATORS; i++) {\n+      final int locatorNumber = i;\n+      randomAvailableTCPPortKeepers.get(locatorNumber).release();\n+      VM.getVM(i).invoke(\"start locator\", () -> {\n+        try {\n+          Disconnect.disconnectFromDS();\n+          dsProperties = null;\n+          Properties props = getDistributedSystemProperties();\n+          locator = Locator.startLocatorAndDS(locatorPorts[locatorNumber], new File(\"\"), props);\n+          system = locator.getDistributedSystem();\n+          cache = ((InternalLocator) locator).getCache();\n+          ReconnectDUnitTest.savedSystem = locator.getDistributedSystem();\n+          IgnoredException.addIgnoredException(\n+              \"org.apache.geode.ForcedDisconnectException||Possible loss of quorum\");\n+        } catch (IOException e) {\n+          Assert.fail(\"unable to start locator\", e);\n+        }\n+      });\n+    }\n+  }\n+\n+  @After\n+  public void teardown() {\n+    for (int i = 0; i < NUM_LOCATORS; i++) {\n+      VM.getVM(i).invoke(() -> {\n+        InternalLocator locator = InternalLocator.getLocator();\n+        if (locator != null) {\n+          InternalConfigurationPersistenceService sharedConfig =\n+              locator.getConfigurationPersistenceService();\n+          if (sharedConfig != null) {\n+            sharedConfig.destroySharedConfiguration();\n+          }\n+          locator.stop();\n+        }\n+      });\n+    }\n+    Invoke.invokeInEveryVM(() -> {\n+      if (system != null) {\n+        system.disconnect();\n+      }\n+      system = null;\n+      cache = null;\n+    });\n+  }\n+\n+  public Properties getDistributedSystemProperties() {\n+    dsProperties = new Properties();\n+    dsProperties.put(MAX_WAIT_TIME_RECONNECT, \"\" + (5000 * NUM_VMS));\n+    dsProperties.put(ENABLE_NETWORK_PARTITION_DETECTION, \"true\");\n+    dsProperties.put(DISABLE_AUTO_RECONNECT, \"false\");\n+    dsProperties.put(ENABLE_CLUSTER_CONFIGURATION, \"true\");\n+    dsProperties.put(USE_CLUSTER_CONFIGURATION, \"true\");\n+    dsProperties.put(HTTP_SERVICE_PORT, \"0\");\n+    StringBuilder stringBuilder = new StringBuilder();\n+    stringBuilder.append(\"localHost[\")\n+        .append(locatorPorts[0])\n+        .append(']');\n+    for (int i = 1; i < NUM_LOCATORS; i++) {\n+      stringBuilder.append(\",localHost[\")\n+          .append(locatorPorts[0])\n+          .append(']');\n+    }\n+    dsProperties.put(LOCATORS, stringBuilder.toString());\n+    dsProperties.put(MCAST_PORT, \"0\");\n+    dsProperties.put(MEMBER_TIMEOUT, \"5000\");\n+    dsProperties.put(LOG_LEVEL, \"info\");\n+    int vmNumber = VM.getCurrentVMNum();\n+    if (vmNumber < NUM_LOCATORS) {\n+      dsProperties.put(NAME, \"loc\" + VM.getCurrentVMNum());\n+    } else {\n+      dsProperties.put(NAME, \"vm\" + VM.getCurrentVMNum());\n+    }\n+    return dsProperties;\n+  }\n+\n+\n+  @Test\n+  public void testReconnectAfterMeltdown() throws InterruptedException {\n+\n+    for (int i = NUM_LOCATORS; i < NUM_VMS; i++) {\n+      VM.getVM(i).invoke(\"create cache\", () -> {\n+        cache = new CacheFactory(getDistributedSystemProperties()).create();\n+        system = cache.getDistributedSystem();\n+      });\n+    }\n+    AsyncInvocation[] crashers = new AsyncInvocation[NUM_VMS];\n+    for (int i = 0; i < NUM_VMS; i++) {\n+      crashers[i] = VM.getVM(i).invokeAsync(\"crash\",\n+          () -> MembershipManagerHelper.crashDistributedSystem(system));\n+    }\n+    for (AsyncInvocation crasher : crashers) {\n+      crasher.join();\n+    }\n+    AsyncInvocation[] waiters = new AsyncInvocation[NUM_VMS];\n+    for (int i = NUM_VMS - 1; i >= 0; i--) {\n+      waiters[i] = VM.getVM(i).invokeAsync(\"wait for reconnect\", () -> {\n+        system.waitUntilReconnected(GeodeAwaitility.getTimeout().getValueInMS(),\n+            TimeUnit.MILLISECONDS);\n+        system = system.getReconnectedSystem();\n+        cache = cache.getReconnectedCache();\n+        await().untilAsserted(() -> assertThat(system.getAllOtherMembers().size())\n+            .withFailMessage(\"wrong number of members: \" + system.getAllOtherMembers())\n+            .isEqualTo(NUM_VMS - 1));\n+      });\n+    }\n+    for (AsyncInvocation waiter : waiters) {\n+      waiter.join();\n+    }\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/distributedTest/java/org/apache/geode/cache30/ReconnectWithClusterConfigurationDUnitTest.java",
                "sha": "964383acc336c51f0b0b217facaa4650dd7ee5fe",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/MembershipJUnitTest.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/MembershipJUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 15,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/MembershipJUnitTest.java",
                "patch": "@@ -47,7 +47,6 @@\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.InternalLocator;\n import org.apache.geode.distributed.internal.SerialAckedMessage;\n-import org.apache.geode.distributed.internal.membership.gms.GMSUtil;\n import org.apache.geode.distributed.internal.membership.gms.ServiceConfig;\n import org.apache.geode.distributed.internal.membership.gms.Services;\n import org.apache.geode.distributed.internal.membership.gms.interfaces.JoinLeave;\n@@ -450,20 +449,6 @@ public void testMulticastDiscoveryNotAllowed() {\n     }\n   }\n \n-  /**\n-   * test the GMSUtil.formatBytes() method\n-   */\n-  @Test\n-  public void testFormatBytes() throws Exception {\n-    byte[] bytes = new byte[200];\n-    for (int i = 0; i < bytes.length; i++) {\n-      bytes[i] = (byte) (i % 255);\n-    }\n-    String str = GMSUtil.formatBytes(bytes, 0, bytes.length);\n-    System.out.println(str);\n-    assertEquals(600 + 4, str.length());\n-  }\n-\n   @Test\n   public void testMessagesThrowExceptionIfProcessed() throws Exception {\n     ClusterDistributionManager dm = null;",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/MembershipJUnitTest.java",
                "sha": "69184ffe68cff99467c347d7c541ba15d8a0b4d8",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 31,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "patch": "@@ -165,6 +165,7 @@ public void initMocks(boolean enableNetworkPartition, boolean useTestGMSJoinLeav\n     gmsJoinLeave.init(services);\n     gmsJoinLeave.start();\n     gmsJoinLeave.started();\n+    gmsJoinLeave.setLocalAddress(gmsJoinLeaveMemberId);\n   }\n \n   @After\n@@ -333,13 +334,6 @@ public void testProcessJoinResponseIsRecorded() throws IOException {\n     gmsJoinLeave.processMessage(jrm);\n     // this should log..\n     Assert.assertEquals(jrm, joinResponse[0]);\n-\n-    gmsJoinLeave.setJoinResponseMessage(null);\n-\n-    jrm = new JoinResponseMessage(mockMembers[0], new NetView(), 0);\n-    gmsJoinLeave.processMessage(jrm);\n-    // this should log..\n-    Assert.assertEquals(jrm, joinResponse[0]);\n   }\n \n   /**\n@@ -622,7 +616,7 @@ public void testRemoveRequestCausesForcedDisconnectInRogue() throws Exception {\n     previousMemberId.setVmViewId(0);\n     NetView view = new NetView(mockMembers[0], 1,\n         createMemberList(mockMembers[0], previousMemberId, mockMembers[1]));\n-    InstallViewMessage viewMessage = new InstallViewMessage(view, 0, true);\n+    InstallViewMessage viewMessage = new InstallViewMessage(view, 0, false);\n     viewMessage.setSender(mockMembers[0]);\n     gmsJoinLeave.processMessage(viewMessage);\n     assertEquals(0, gmsJoinLeaveMemberId.getVmViewId());\n@@ -634,29 +628,6 @@ public void testRemoveRequestCausesForcedDisconnectInRogue() throws Exception {\n     verify(manager).forceDisconnect(\"removing for test\");\n   }\n \n-  @Test\n-  public void testViewWithOldIDNotAcceptedAsJoinResponse() throws Exception {\n-    initMocks();\n-    when(messenger.isOldMembershipIdentifier(any(DistributedMember.class)))\n-        .thenReturn(Boolean.TRUE);\n-    List<InternalDistributedMember> mbrs = new LinkedList<>();\n-    Set<InternalDistributedMember> shutdowns = new HashSet<>();\n-    Set<InternalDistributedMember> crashes = new HashSet<>();\n-    mbrs.add(mockMembers[0]);\n-    mbrs.add(mockMembers[1]);\n-    mbrs.add(mockMembers[2]);\n-    InternalDistributedMember oldId = new InternalDistributedMember(\n-        gmsJoinLeaveMemberId.getInetAddress(), gmsJoinLeaveMemberId.getPort());\n-    oldId.setVmViewId(0);\n-    mbrs.add(oldId);\n-\n-    // prepare the view\n-    NetView netView = new NetView(mockMembers[0], 1, mbrs, shutdowns, crashes);\n-    gmsJoinLeave.processMessage(new InstallViewMessage(netView, null, true));\n-    assertEquals(-1, gmsJoinLeaveMemberId.getVmViewId());\n-    verify(messenger).isOldMembershipIdentifier(isA(DistributedMember.class));\n-  }\n-\n   @Test\n   public void testRemoveCausesForcedDisconnect() throws Exception {\n     String reason = \"testing\";",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "sha": "b0481e7dae66de24cfc41bdc965f2fcb025c3a7f",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 1,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "patch": "@@ -52,6 +52,7 @@\n import java.util.Map;\n import java.util.Properties;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n \n import org.apache.commons.lang3.SerializationException;\n import org.jgroups.Address;\n@@ -877,7 +878,8 @@ public void testUseOldJChannel() throws Exception {\n     initMocks(false);\n     JChannel channel = messenger.myChannel;\n     services.getConfig().getTransport().setOldDSMembershipInfo(new MembershipInformation(channel,\n-        Collections.singleton(new InternalDistributedMember(\"localhost\", 10000))));\n+        Collections.singleton(new InternalDistributedMember(\"localhost\", 10000)),\n+        new ConcurrentLinkedQueue<>()));\n     JGroupsMessenger newMessenger = new JGroupsMessenger();\n     newMessenger.init(services);\n     newMessenger.start();",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/integrationTest/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessengerJUnitTest.java",
                "sha": "d5239e8a1e254e9cd8218f1326c30533721a714e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/cache/Cache.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/Cache.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/Cache.java",
                "patch": "@@ -413,6 +413,8 @@\n \n   /**\n    * Wait for the Cache to finish reconnecting to the distributed system and recreate a new Cache.\n+   * This may throw a CacheClosedException if reconnect attempts fail due to an exception. The\n+   * exception will detail what went wrong.\n    *\n    * @see #getReconnectedCache\n    * @param time amount of time to wait, or -1 to wait forever",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/cache/Cache.java",
                "sha": "fc7f4f3fd47e00be491d9fbeefd211194b294406",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/DistributedSystem.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/DistributedSystem.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/DistributedSystem.java",
                "patch": "@@ -650,6 +650,8 @@ private static URL getFileURL(String fileName) {\n \n   /**\n    * Wait for the DistributedSystem to finish reconnecting to the system and recreate the cache.\n+   * This may throw a DistributedSystemDisconnectedException if reconnect fails. The exception\n+   * will detail what went wrong.\n    *\n    * @param time amount of time to wait, or -1 to wait forever\n    * @return true if the system was reconnected",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/DistributedSystem.java",
                "sha": "bc913d22baa28b95e82628d4d65a7ed3548056eb",
                "status": "modified"
            },
            {
                "additions": 58,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "changes": 95,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 37,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "patch": "@@ -61,7 +61,6 @@\n import org.apache.geode.annotations.internal.MutableForTesting;\n import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.CacheFactory;\n-import org.apache.geode.cache.CacheXmlException;\n import org.apache.geode.cache.server.CacheServer;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.DistributedSystem;\n@@ -93,6 +92,7 @@\n import org.apache.geode.internal.cache.execute.InternalFunctionService;\n import org.apache.geode.internal.cache.tier.sockets.EncryptorImpl;\n import org.apache.geode.internal.cache.xmlcache.CacheServerCreation;\n+import org.apache.geode.internal.config.ClusterConfigurationNotAvailableException;\n import org.apache.geode.internal.logging.InternalLogWriter;\n import org.apache.geode.internal.logging.LogConfig;\n import org.apache.geode.internal.logging.LogConfigListener;\n@@ -1271,7 +1271,7 @@ public void disconnect(String reason, Throwable cause, boolean shunned) {\n     boolean isForcedDisconnect = dm.getRootCause() instanceof ForcedDisconnectException;\n     boolean rejoined = false;\n     this.reconnected = false;\n-    if (isForcedDisconnect) {\n+    if (isForcedDisconnect && !this.isReconnectingDS) {\n       this.forcedDisconnect = true;\n       resetReconnectAttemptCounter();\n       rejoined = tryReconnect(true, reason, GemFireCacheImpl.getInstance());\n@@ -2325,6 +2325,11 @@ public Properties getSecurityProperties() {\n    */\n   private volatile boolean reconnected = false;\n \n+  /**\n+   * If reconnect fails due to an exception it will be in this field\n+   */\n+  private Exception reconnectException;\n+\n   /**\n    * Boolean indicating that this member has been shunned by other members or a network partition\n    * has occurred\n@@ -2655,20 +2660,19 @@ private void reconnect(boolean forcedDisconnect, String reason) {\n             logger.warn(\"Exception occurred while trying to connect the system during reconnect\",\n                 e);\n             attemptingToReconnect = false;\n+            reconnectException = e;\n             return;\n           }\n           logger.warn(\"Caught SystemConnectException in reconnect\", e);\n           continue;\n         } catch (GemFireConfigException e) {\n-          if (isDebugEnabled) {\n-            logger.debug(\"Attempt to reconnect failed with GemFireConfigException\");\n-          }\n           logger.warn(\"Caught GemFireConfigException in reconnect\", e);\n           continue;\n-        } catch (Exception ee) {\n+        } catch (Exception e) {\n           logger.warn(\"Exception occurred while trying to connect the system during reconnect\",\n-              ee);\n+              e);\n           attemptingToReconnect = false;\n+          reconnectException = e;\n           return;\n         } finally {\n           if (this.locatorDMTypeForced) {\n@@ -2683,41 +2687,47 @@ private void reconnect(boolean forcedDisconnect, String reason) {\n           // Admin systems don't carry a cache, but for others we can now create\n           // a cache\n           if (newDM.getDMType() != ClusterDistributionManager.ADMIN_ONLY_DM_TYPE) {\n-            try {\n-              CacheConfig config = new CacheConfig();\n-              if (cacheXML != null) {\n-                config.setCacheXMLDescription(cacheXML);\n-              }\n-              cache = GemFireCacheImpl.create(this.reconnectDS, config);\n+            boolean retry;\n+            do {\n+              retry = false;\n+              try {\n+                CacheConfig config = new CacheConfig();\n+                if (cacheXML != null) {\n+                  config.setCacheXMLDescription(cacheXML);\n+                }\n+                cache = GemFireCacheImpl.create(this.reconnectDS, config);\n \n-              if (!cache.isClosed()) {\n-                createAndStartCacheServers(cacheServerCreation, cache);\n-                if (cache.getCachePerfStats().getReliableRegionsMissing() == 0) {\n-                  reconnectAttemptCounter = 0;\n+                if (!cache.isClosed()) {\n+                  createAndStartCacheServers(cacheServerCreation, cache);\n+                  if (cache.getCachePerfStats().getReliableRegionsMissing() == 0) {\n+                    reconnectAttemptCounter = 0;\n+                  }\n                 }\n-              }\n \n-            } catch (CacheXmlException e) {\n-              logger.warn(\"Exception occurred while trying to create the cache during reconnect\",\n-                  e);\n-              reconnectDS.disconnect();\n-              reconnectDS = null;\n-              reconnectCancelled = true;\n-              break;\n-            } catch (CancelException ignor) {\n-              // If this reconnect is for required-roles the algorithm is recursive and we\n-              // shouldn't retry at this level\n-              if (!forcedDisconnect) {\n+              } catch (GemFireConfigException e) {\n+                if (e.getCause() instanceof ClusterConfigurationNotAvailableException) {\n+                  retry = true;\n+                  logger.info(\"Reconnected to the cluster but the cluster configuration service \"\n+                      + \"isn't available - will retry creating the cache\");\n+                  try {\n+                    Thread.sleep(5000);\n+                  } catch (InterruptedException e1) {\n+                    reconnectCancelled = true;\n+                    reconnectException = e;\n+                    break;\n+                  }\n+                }\n+              } catch (Exception e) {\n+                // We need to give up because we'll probably get the same exception in\n+                // the next attempt to build the cache.\n+                logger.warn(\n+                    \"Exception occurred while trying to create the cache during reconnect.  Auto-reconnect is terminating.\",\n+                    e);\n+                reconnectCancelled = true;\n+                reconnectException = e;\n                 break;\n               }\n-              logger.warn(\"Exception occurred while trying to create the cache during reconnect\",\n-                  ignor);\n-              reconnectDS.disconnect();\n-              reconnectDS = null;\n-            } catch (Exception e) {\n-              logger.warn(\"Exception occurred while trying to create the cache during reconnect\",\n-                  e);\n-            }\n+            } while (retry);\n           }\n         }\n \n@@ -2728,6 +2738,8 @@ private void reconnect(boolean forcedDisconnect, String reason) {\n           } catch (InterruptedException e) {\n             logger.info(\"Reconnect thread has been interrupted - exiting\");\n             Thread.currentThread().interrupt();\n+            reconnectCancelled = true;\n+            reconnectException = e;\n             return;\n           }\n         }\n@@ -2757,6 +2769,11 @@ private void reconnect(boolean forcedDisconnect, String reason) {\n       } else {\n         System.setProperty(InternalLocator.INHIBIT_DM_BANNER, inhibitBanner);\n       }\n+      dm.getMembershipManager().setReconnectCompleted(true);\n+      InternalDistributedSystem newds = reconnectDS;\n+      if (newds != null) {\n+        newds.getDM().getMembershipManager().setReconnectCompleted(true);\n+      }\n       if (quorumChecker != null) {\n         mbrMgr.releaseQuorumChecker(quorumChecker, reconnectDS);\n       }\n@@ -2941,6 +2958,10 @@ public boolean waitUntilReconnected(long time, TimeUnit units) throws Interrupte\n         }\n       }\n \n+      if (reconnectException != null) {\n+        throw new DistributedSystemDisconnectedException(\n+            \"Reconnect attempts terminated due to exception\", reconnectException);\n+      }\n       InternalDistributedSystem recon = this.reconnectDS;\n       return !attemptingToReconnect && recon != null && recon.isConnected();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalDistributedSystem.java",
                "sha": "4011669d3fd7696cba073137cf02b5fa3b7eeda6",
                "status": "modified"
            },
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -952,7 +952,11 @@ public void waitToStop() throws InterruptedException {\n           Thread.sleep(5000);\n         }\n         logger.info(\"waiting for distributed system to reconnect...\");\n-        restarted = ds.waitUntilReconnected(-1, TimeUnit.SECONDS);\n+        try {\n+          restarted = ds.waitUntilReconnected(-1, TimeUnit.SECONDS);\n+        } catch (CancelException e) {\n+          // reconnect attempt failed\n+        }\n         if (restarted) {\n           logger.info(\"system restarted\");\n         } else {\n@@ -1049,7 +1053,12 @@ private boolean attemptReconnect() throws InterruptedException, IOException {\n           }\n           this.stoppedForReconnect = false;\n         }\n-        restartWithDS(newSystem, GemFireCacheImpl.getInstance());\n+        try {\n+          restartWithDS(newSystem, GemFireCacheImpl.getInstance());\n+        } catch (CancelException e) {\n+          this.stoppedForReconnect = true;\n+          return false;\n+        }\n         setLocator(this);\n         restarted = true;\n       }\n@@ -1091,7 +1100,14 @@ private void restartWithDS(InternalDistributedSystem newSystem, InternalCache ne\n       this.myDs.setDependentLocator(this);\n       logger.info(\"Locator restart: initializing TcpServer\");\n \n-      this.server.restarting(newSystem, newCache, this.configurationPersistenceService);\n+      try {\n+        this.server.restarting(newSystem, newCache, this.configurationPersistenceService);\n+      } catch (CancelException e) {\n+        this.myDs = null;\n+        this.myCache = null;\n+        logger.info(\"Locator restart: attempt to restart location services failed\", e);\n+        throw e;\n+      }\n       if (this.productUseLog.isClosed()) {\n         this.productUseLog.reopen();\n       }\n@@ -1110,6 +1126,7 @@ private void restartWithDS(InternalDistributedSystem newSystem, InternalCache ne\n       endStartLocator(this.myDs);\n       logger.info(\"Locator restart completed\");\n     }\n+    this.server.restartCompleted(newSystem);\n   }\n \n   public ClusterManagementService getClusterManagementService() {\n@@ -1262,6 +1279,15 @@ public void restarting(DistributedSystem ds, GemFireCache cache,\n       }\n     }\n \n+    @Override\n+    public void restartCompleted(DistributedSystem ds) {\n+      if (ds != null) {\n+        for (TcpHandler handler : this.allHandlers) {\n+          handler.restartCompleted(ds);\n+        }\n+      }\n+    }\n+\n     @Override\n     public Object processRequest(Object request) throws IOException {\n       long giveup = 0;",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "788d71b9dab10cb7dd65357bb80b6d0c902b43fb",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/ServerLocator.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/ServerLocator.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/ServerLocator.java",
                "patch": "@@ -290,10 +290,12 @@ public void restarting(DistributedSystem ds, GemFireCache cache,\n       this.loadSnapshot = new LocatorLoadSnapshot();\n       this.ds = (InternalDistributedSystem) ds;\n       this.advisor = ControllerAdvisor.createControllerAdvisor(this); // escapes constructor but\n-                                                                      // allows field to be final\n-      if (ds.isConnected()) {\n-        this.advisor.handshake(); // GEODE-1393: need to get server information during restart\n-      }\n+    }\n+  }\n+\n+  public void restartCompleted(DistributedSystem ds) {\n+    if (ds.isConnected()) {\n+      this.advisor.handshake(); // GEODE-1393: need to get server information during restart\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/ServerLocator.java",
                "sha": "2ed366efc2685548b4bd9c1fba0543654c6f6c1e",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/MembershipManager.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/MembershipManager.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/MembershipManager.java",
                "patch": "@@ -149,6 +149,12 @@\n   void setShutdown();\n \n \n+  /**\n+   * informs the membership manager that a reconnect has been completed\n+   */\n+  public void setReconnectCompleted(boolean reconnectCompleted);\n+\n+\n   /**\n    * Determine whether GCS shutdown has commenced\n    *",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/MembershipManager.java",
                "sha": "0a3b0b092d82d4f0c9c7745233d1e8528e4b569e",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 21,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "patch": "@@ -128,25 +128,4 @@ public static String replaceStrings(String properties, String property, String v\n     return sb.toString();\n   }\n \n-\n-  /**\n-   * Formats the bytes in a buffer into hex octets, 50 per line\n-   */\n-  public static String formatBytes(byte[] buf, int startIndex, int length) {\n-    StringBuilder w = new StringBuilder(20000);\n-    int count = 0;\n-    for (int i = startIndex; i < length; i++, count++) {\n-      String s = Integer.toHexString(buf[i] & 0xff);\n-      if (s.length() == 1) {\n-        w.append('0');\n-      }\n-      w.append(s).append(' ');\n-      if ((count % 50) == 49) {\n-        w.append(\"\\n\");\n-      }\n-    }\n-    return w.toString();\n-  }\n-\n-\n }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "sha": "0e1491849059e6fea993a42383d3a0e9aaf15b98",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "patch": "@@ -180,6 +180,14 @@ protected void start() {\n     }\n   }\n \n+  public void setLocalAddress(InternalDistributedMember address) {\n+    this.auth.setLocalAddress(address);\n+    this.messenger.setLocalAddress(address);\n+    this.joinLeave.setLocalAddress(address);\n+    this.healthMon.setLocalAddress(address);\n+    this.manager.setLocalAddress(address);\n+  }\n+\n   public void emergencyClose() {\n     if (this.stopping) {\n       return;",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/Services.java",
                "sha": "e8bc0b9db5dc47614995be6c78db5a9b797746a9",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitor.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitor.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitor.java",
                "patch": "@@ -317,7 +317,8 @@ public void run() {\n         if (playingDead) {\n           logger.debug(\"HealthMonitor: simulating sick member in health check\");\n         } else if (uuidLSBs == myUUID.getLeastSignificantBits()\n-            && uuidMSBs == myUUID.getMostSignificantBits() && vmViewId == myVmViewId) {\n+            && uuidMSBs == myUUID.getMostSignificantBits()\n+            && (vmViewId == myVmViewId || myVmViewId < 0)) {\n           logger.debug(\"HealthMonitor: sending OK reply\");\n           out.write(OK);\n           out.flush();\n@@ -1009,7 +1010,8 @@ public void emergencyClose() {\n     stopServices();\n   }\n \n-  void setLocalAddress(InternalDistributedMember idm) {\n+  @Override\n+  public void setLocalAddress(InternalDistributedMember idm) {\n     this.localAddress = idm;\n   }\n \n@@ -1062,7 +1064,7 @@ private void processHeartbeatRequest(HeartbeatRequestMessage m) {\n     // only respond if the intended recipient is this member\n     InternalDistributedMember me = localAddress;\n \n-    if (me.getVmViewId() >= 0 && m.getTarget().equals(me)) {\n+    if (me == null || me.getVmViewId() >= 0 && m.getTarget().equals(me)) {\n       HeartbeatMessage hm = new HeartbeatMessage(m.getRequestId());\n       hm.setRecipient(m.getSender());\n       Set<InternalDistributedMember> membersNotReceivedMsg = services.getMessenger().send(hm);",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitor.java",
                "sha": "ab72a07c59159f67b5cb88c4eb252f51dcae3e81",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Manager.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Manager.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Manager.java",
                "patch": "@@ -110,4 +110,10 @@\n    */\n   boolean isReconnectingDS();\n \n+  /**\n+   * If this.isReconnectingDS() then this method will inform whether the reconnect\n+   * has completed\n+   */\n+  boolean isReconnectCompleted();\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Manager.java",
                "sha": "4a0ef6bbc0ba12a108ed1c9c01f91190e0367244",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Service.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Service.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Service.java",
                "patch": "@@ -78,4 +78,5 @@ void memberSuspected(InternalDistributedMember initiator, InternalDistributedMem\n       String reason);\n \n \n+  default void setLocalAddress(InternalDistributedMember address) {}\n }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/interfaces/Service.java",
                "sha": "403518d2122e02fa9f6be49c3207d29a4d5d295e",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "patch": "@@ -178,6 +178,10 @@ public void installView(NetView view) {\n \n   @Override\n   public void setIsCoordinator(boolean isCoordinator) {\n+    if (isCoordinator) {\n+      logger.info(\"Location services has received notification that this node is becoming\"\n+          + \" membership coordinator\");\n+    }\n     this.isCoordinator = isCoordinator;\n   }\n \n@@ -250,6 +254,9 @@ private FindCoordinatorResponse processFindCoordinatorRequest(\n \n     synchronized (registrants) {\n       registrants.add(findRequest.getMemberID());\n+      if (recoveredView != null) {\n+        recoveredView.remove(findRequest.getMemberID());\n+      }\n     }\n \n     if (v != null) {\n@@ -299,9 +306,7 @@ private FindCoordinatorResponse processFindCoordinatorRequest(\n     synchronized (registrants) {\n       if (isCoordinator) {\n         coordinator = localAddress;\n-\n         if (v != null && localAddress != null && !localAddress.equals(v.getCoordinator())) {\n-          logger.info(\"This member is becoming coordinator since view {}\", v);\n           v = null;\n           fromView = false;\n         }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/locator/GMSLocator.java",
                "sha": "407cff1bb4c16659e20456448662c9c95f9be2c5",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "changes": 102,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 41,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "patch": "@@ -264,6 +264,7 @@\n     int locatorsContacted = 0;\n     boolean hasContactedAJoinedLocator;\n     NetView view;\n+    int lastFindCoordinatorInViewId = -1000;\n     final Set<FindCoordinatorResponse> responses = new HashSet<>();\n     public int responsesExpected;\n \n@@ -459,8 +460,7 @@ boolean attemptToJoin() {\n       throw new GemFireSecurityException(failReason);\n     }\n \n-    // there is no way we can rech here right now\n-    throw new RuntimeException(\"Join Request Failed with response \" + joinResponse[0]);\n+    throw new RuntimeException(\"Join Request Failed with response \" + response);\n   }\n \n   private JoinResponseMessage waitForJoinResponse() throws InterruptedException {\n@@ -476,29 +476,31 @@ private JoinResponseMessage waitForJoinResponse() throws InterruptedException {\n       }\n       response = joinResponse[0];\n \n-      if (response != null && response.getCurrentView() != null && !isJoined) {\n-        // reset joinResponse[0]\n-        joinResponse[0] = null;\n-        // we got view here that means either we have to wait for\n-        NetView v = response.getCurrentView();\n-        InternalDistributedMember coord = v.getCoordinator();\n-        if (searchState.alreadyTried.contains(coord)) {\n-          searchState.view = response.getCurrentView();\n-          // we already sent join request to it..so lets wait some more time here\n-          // assuming we got this response immediately, so wait for same timeout here..\n-          long timeout = Math.max(services.getConfig().getMemberTimeout(),\n-              services.getConfig().getJoinTimeout() / 5);\n-          joinResponse.wait(timeout);\n-          response = joinResponse[0];\n-        } else {\n-          // try on this coordinator\n-          searchState.view = response.getCurrentView();\n-          response = null;\n+      if (services.getConfig().getDistributionConfig().getSecurityUDPDHAlgo().length() > 0) {\n+        if (response != null && response.getCurrentView() != null && !isJoined) {\n+          // reset joinResponse[0]\n+          joinResponse[0] = null;\n+          // we got view here that means either we have to wait for\n+          NetView v = response.getCurrentView();\n+          InternalDistributedMember coord = v.getCoordinator();\n+          if (searchState.alreadyTried.contains(coord)) {\n+            searchState.view = response.getCurrentView();\n+            // we already sent join request to it..so lets wait some more time here\n+            // assuming we got this response immediately, so wait for same timeout here..\n+            long timeout = Math.max(services.getConfig().getMemberTimeout(),\n+                services.getConfig().getJoinTimeout() / 5);\n+            joinResponse.wait(timeout);\n+            response = joinResponse[0];\n+          } else {\n+            // try on this coordinator\n+            searchState.view = response.getCurrentView();\n+            response = null;\n+          }\n+          searchState.view = v;\n+        }\n+        if (isJoined) {\n+          return null;\n         }\n-        searchState.view = v;\n-      }\n-      if (isJoined) {\n-        return null;\n       }\n     }\n     return response;\n@@ -616,7 +618,7 @@ private void processLeaveRequest(LeaveRequestMessage incomingRequest) {\n           services.getHealthMonitor().getMembersFailingAvailabilityCheck();\n       check.removeAll(suspectMembers);\n       logger.info(\n-          \"View with removed and left members removed is {}\\nremoved members: {}\\nleft members: {}\\nsuspect members: {}\",\n+          \"View with removed and left members removed is {}; removed members: {}; left members: {}; suspect members: {}\",\n           check, removedMembers, leftMembers, suspectMembers);\n       if (check.getCoordinator().equals(localAddress)) {\n         synchronized (viewInstallationLock) {\n@@ -995,6 +997,7 @@ private void addPublicKeysToView(NetView view) {\n   }\n \n   private void processViewMessage(final InstallViewMessage m) {\n+    logger.debug(\"processing membership view message {}\", m);\n \n     NetView view = m.getView();\n \n@@ -1016,12 +1019,11 @@ private void processViewMessage(final InstallViewMessage m) {\n     }\n \n     boolean viewContainsMyNewAddress = false;\n-    if (!this.isJoined) {\n+    if (!this.isJoined && !m.isPreparing()) {\n       // if we're still waiting for a join response and we're in this view we\n       // should install the view so join() can finish its work\n       for (InternalDistributedMember mbr : view.getMembers()) {\n-        if (localAddress.equals(mbr)\n-            && !services.getMessenger().isOldMembershipIdentifier(mbr)) {\n+        if (localAddress.equals(mbr)) {\n           viewContainsMyNewAddress = true;\n           break;\n         }\n@@ -1030,12 +1032,24 @@ private void processViewMessage(final InstallViewMessage m) {\n \n     if (m.isPreparing()) {\n       if (this.preparedView != null && this.preparedView.getViewId() >= view.getViewId()) {\n-        services.getMessenger()\n-            .send(new ViewAckMessage(view.getViewId(), m.getSender(), this.preparedView));\n+        if (this.preparedView.getViewId() == view.getViewId() &&\n+            this.preparedView.getCreator().equals(view.getCreator())) {\n+          // this can happen if we received two prepares during auto-reconnect\n+        } else {\n+          services.getMessenger()\n+              .send(new ViewAckMessage(view.getViewId(), m.getSender(), this.preparedView));\n+        }\n       } else {\n         this.preparedView = view;\n-        if (viewContainsMyNewAddress) {\n-          installView(view); // this will notifyAll the joinResponse\n+        // complete filling in the member ID of this node, if possible\n+        for (InternalDistributedMember mbr : view.getMembers()) {\n+          if (this.localAddress.equals(mbr)) {\n+            this.birthViewId = mbr.getVmViewId();\n+            this.localAddress.setVmViewId(this.birthViewId);\n+            GMSMember me = (GMSMember) this.localAddress.getNetMember();\n+            me.setBirthViewId(birthViewId);\n+            break;\n+          }\n         }\n         ackView(m);\n       }\n@@ -1096,12 +1110,10 @@ boolean findCoordinator() {\n \n     assert this.localAddress != null;\n \n-    // If we've already tried to bootstrap from locators that\n-    // haven't joined the system (e.g., a collocated locator)\n-    // then jump to using the membership view to try to find\n-    // the coordinator\n     if (!state.hasContactedAJoinedLocator && state.registrants.size() >= locators.size()\n-        && state.view != null) {\n+        && state.view != null && state.viewId > state.lastFindCoordinatorInViewId) {\n+      state.lastFindCoordinatorInViewId = state.viewId;\n+      logger.info(\"using findCoordinatorFromView\");\n       return findCoordinatorFromView();\n     }\n \n@@ -1163,7 +1175,8 @@ boolean findCoordinator() {\n               // the QuorumChecker would have contacted a quorum of live nodes and one of\n               // them should already be the coordinator, or should become the coordinator soon\n               boolean isMyOldAddress =\n-                  services.getConfig().isReconnecting() && localAddress.equals(responseCoordinator);\n+                  services.getConfig().isReconnecting() && localAddress.equals(responseCoordinator)\n+                      && responseCoordinator.getVmViewId() >= 0;\n               if (!isMyOldAddress) {\n                 possibleCoordinators.add(response.getCoordinator());\n               }\n@@ -1224,6 +1237,8 @@ boolean findCoordinator() {\n         }\n       }\n     }\n+    logger.info(\"findCoordinator chose {} out of these possible coordinators: {}\",\n+        state.possibleCoordinator, possibleCoordinators);\n     return true;\n   }\n \n@@ -1348,9 +1363,12 @@ private void processJoinResponse(JoinResponseMessage rsp) {\n         // 2. Member which was coordinator but just now some other member became coordinator\n         // 3. we got message with secret key, but still view is coming and that will inform the\n         // joining thread\n-        if (rsp.getRejectionMessage() != null || rsp.getCurrentView() != null) {\n+        if (rsp.getRejectionMessage() != null) {\n           joinResponse[0] = rsp;\n           joinResponse.notifyAll();\n+        } else if (rsp.getCurrentView() != null) {\n+          // ignore - we get to join when we receive a view. Joining earlier may\n+          // confuse other members if we've reused an old address\n         } else {\n           // we got secret key lets add it\n           services.getMessenger().setClusterSecretKey(rsp.getSecretPk());\n@@ -1646,8 +1664,10 @@ public void beHealthy() {\n   public void start() {}\n \n   @Override\n-  public void started() {\n-    this.localAddress = services.getMessenger().getMemberID();\n+  public void started() {}\n+\n+  public void setLocalAddress(InternalDistributedMember address) {\n+    this.localAddress = address;\n     GMSMember mbr = (GMSMember) this.localAddress.getNetMember();\n \n     if (services.getConfig().areLocatorsPreferredAsCoordinators()) {",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeave.java",
                "sha": "261bb70d536d37a1ffc11596726f23ec34fd7205",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSQuorumChecker.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSQuorumChecker.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSQuorumChecker.java",
                "patch": "@@ -23,6 +23,7 @@\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n \n import org.apache.logging.log4j.Logger;\n import org.jgroups.Address;\n@@ -55,6 +56,7 @@\n   private JGAddress myAddress;\n   private final long partitionThreshold;\n   private Set<DistributedMember> oldDistributedMemberIdentifiers;\n+  private ConcurrentLinkedQueue<Message> messageQueue = new ConcurrentLinkedQueue<>();\n \n   public GMSQuorumChecker(NetView jgView, int partitionThreshold, JChannel channel,\n       Set<DistributedMember> oldDistributedMemberIdentifiers) {\n@@ -125,7 +127,7 @@ public NetView getView() {\n \n   @Override\n   public MembershipInformation getMembershipInfo() {\n-    return new MembershipInformation(channel, oldDistributedMemberIdentifiers);\n+    return new MembershipInformation(channel, oldDistributedMemberIdentifiers, messageQueue);\n   }\n \n   private boolean calculateQuorum() {\n@@ -219,9 +221,15 @@ public void receive(Message msg) {\n         }\n       } else if (pingPonger.isPongMessage(msgBytes)) {\n         pongReceived(msg.getSrc());\n+      } else {\n+        queueMessage(msg);\n       }\n     }\n \n+    private void queueMessage(Message msg) {\n+      messageQueue.add(msg);\n+    }\n+\n     @Override\n     public void getState(OutputStream output) throws Exception {}\n ",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/GMSQuorumChecker.java",
                "sha": "14adc8d1231ea0fd5bf5a3c204c751c01554d15e",
                "status": "modified"
            },
            {
                "additions": 42,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessenger.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessenger.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessenger.java",
                "patch": "@@ -38,6 +38,7 @@\n import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n+import java.util.Queue;\n import java.util.Random;\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n@@ -86,6 +87,7 @@\n import org.apache.geode.distributed.internal.membership.QuorumChecker;\n import org.apache.geode.distributed.internal.membership.gms.GMSMember;\n import org.apache.geode.distributed.internal.membership.gms.Services;\n+import org.apache.geode.distributed.internal.membership.gms.interfaces.HealthMonitor;\n import org.apache.geode.distributed.internal.membership.gms.interfaces.MessageHandler;\n import org.apache.geode.distributed.internal.membership.gms.interfaces.Messenger;\n import org.apache.geode.distributed.internal.membership.gms.locator.FindCoordinatorRequest;\n@@ -173,6 +175,19 @@\n    */\n   private Set<DistributedMember> usedDistributedMemberIdentifiers = new HashSet<>();\n \n+  /**\n+   * During reconnect a QuorumChecker holds the JGroups channel and responds to Ping\n+   * and Pong messages but also queues any messages it doesn't recognize. These need\n+   * to be delivered to handlers after membership services have been rebuilt.\n+   */\n+  private Queue<Message> queuedMessagesFromReconnect;\n+\n+  /**\n+   * The JGroupsReceiver is handed messages by the JGroups Channel. It is responsible\n+   * for deserializating and dispatching those messages to the appropriate handler\n+   */\n+  private JGroupsReceiver jgroupsReceiver;\n+\n   @Override\n   @edu.umd.cs.findbugs.annotations.SuppressWarnings(\n       value = \"ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD\")\n@@ -309,6 +324,7 @@ public void start() {\n         MembershipInformation oldInfo = (MembershipInformation) oldDSMembershipInfo;\n         myChannel = oldInfo.getChannel();\n         usedDistributedMemberIdentifiers = oldInfo.getMembershipIdentifiers();\n+        queuedMessagesFromReconnect = oldInfo.getQueuedMessages();\n \n         // scrub the old channel\n         ViewId vid = new ViewId(new JGAddress(), 0);\n@@ -345,7 +361,8 @@ public void start() {\n \n     try {\n       myChannel.setReceiver(null);\n-      myChannel.setReceiver(new JGroupsReceiver());\n+      jgroupsReceiver = new JGroupsReceiver();\n+      myChannel.setReceiver(jgroupsReceiver);\n       if (!reconnecting) {\n         myChannel.connect(\"AG\"); // apache g***** (whatever we end up calling it)\n       }\n@@ -387,7 +404,17 @@ private void checkForIPv6() throws Exception {\n   }\n \n   @Override\n-  public void started() {}\n+  public void started() {\n+    if (queuedMessagesFromReconnect != null) {\n+      logger.info(\"Delivering {} messages queued by quorum checker\",\n+          queuedMessagesFromReconnect.size());\n+      for (Message message : queuedMessagesFromReconnect) {\n+        jgroupsReceiver.receive(message, true);\n+      }\n+      queuedMessagesFromReconnect.clear();\n+      queuedMessagesFromReconnect = null;\n+    }\n+  }\n \n   @Override\n   public void stop() {\n@@ -529,6 +556,8 @@ private void establishLocalAddress() {\n     gmsMember.setMemberWeight((byte) (services.getConfig().getMemberWeight() & 0xff));\n     gmsMember.setNetworkPartitionDetectionEnabled(\n         services.getConfig().getDistributionConfig().getEnableNetworkPartitionDetection());\n+\n+    services.setLocalAddress(localAddress);\n   }\n \n   @Override\n@@ -1226,6 +1255,10 @@ public QuorumChecker getQuorumChecker() {\n \n     @Override\n     public void receive(Message jgmsg) {\n+      receive(jgmsg, false);\n+    }\n+\n+    private void receive(Message jgmsg, boolean fromQuorumChecker) {\n       long startTime = DistributionStats.getStatTime();\n       try {\n         if (services.getManager().shutdownInProgress()) {\n@@ -1279,7 +1312,13 @@ public void receive(Message jgmsg) {\n             logger.trace(\"JGroupsMessenger dispatching {} from {}\", msg, msg.getSender());\n           }\n           filterIncomingMessage(msg);\n-          getMessageHandler(msg).processMessage(msg);\n+          MessageHandler handler = getMessageHandler(msg);\n+          if (fromQuorumChecker && handler instanceof HealthMonitor) {\n+            // ignore suspect / heartbeat messages that happened during\n+            // auto-reconnect because they very likely have old member IDs in them\n+          } else {\n+            handler.processMessage(msg);\n+          }\n \n           // record the scheduling of broadcast messages\n           NakAckHeader2 header = (NakAckHeader2) jgmsg.getHeader(nackack2HeaderId);",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/JGroupsMessenger.java",
                "sha": "8475bcbee5ceb9d8d5c5dfc5293d3edb20b0de42",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/MembershipInformation.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/MembershipInformation.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/MembershipInformation.java",
                "patch": "@@ -14,9 +14,11 @@\n  */\n package org.apache.geode.distributed.internal.membership.gms.messenger;\n \n+import java.util.Queue;\n import java.util.Set;\n \n import org.jgroups.JChannel;\n+import org.jgroups.Message;\n \n import org.apache.geode.distributed.DistributedMember;\n \n@@ -27,12 +29,15 @@\n public class MembershipInformation {\n   private final JChannel channel;\n   private final Set<DistributedMember> membershipIdentifiers;\n+  private final Queue<Message> queuedMessages;\n \n   protected MembershipInformation(JChannel channel,\n-      Set<DistributedMember> oldMembershipIdentifiers) {\n+      Set<DistributedMember> oldMembershipIdentifiers,\n+      Queue<Message> queuedMessages) {\n \n     this.channel = channel;\n     this.membershipIdentifiers = oldMembershipIdentifiers;\n+    this.queuedMessages = queuedMessages;\n   }\n \n   public JChannel getChannel() {\n@@ -42,4 +47,8 @@ public JChannel getChannel() {\n   public Set<DistributedMember> getMembershipIdentifiers() {\n     return membershipIdentifiers;\n   }\n+\n+  public Queue<Message> getQueuedMessages() {\n+    return this.queuedMessages;\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/messenger/MembershipInformation.java",
                "sha": "80bc6e71a116d8c8f6d5ed3d038381dafd08cc08",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "patch": "@@ -107,6 +107,12 @@\n    */\n   private boolean wasReconnectingSystem;\n \n+  /**\n+   * This indicates that the DistributedSystem using this membership manager performed\n+   * a successful auto-reconnect. This may include successful recreation of a Cache\n+   */\n+  private boolean reconnectCompleted;\n+\n   /**\n    * A quorum checker is created during reconnect and is held here so it is available to the UDP\n    * protocol for passing off the ping-pong responses used in the quorum-checking algorithm.\n@@ -1788,7 +1794,7 @@ public boolean isConnected() {\n    */\n   @Override\n   public boolean isReconnectingDS() {\n-    return !this.hasJoined && this.wasReconnectingSystem;\n+    return this.wasReconnectingSystem && !this.reconnectCompleted;\n   }\n \n   @Override\n@@ -2183,6 +2189,17 @@ void setDirectChannel(DirectChannel dc) {\n     this.tcpDisabled = false;\n   }\n \n+  @Override\n+  public void setReconnectCompleted(boolean reconnectCompleted) {\n+    this.reconnectCompleted = reconnectCompleted;\n+  }\n+\n+  @Override\n+  public boolean isReconnectCompleted() {\n+    return reconnectCompleted;\n+  }\n+\n+\n   /*\n    * non-thread-owned serial channels and high priority channels are not included\n    */\n@@ -2546,11 +2563,17 @@ public void forceDisconnect(final String reason) {\n           shutdownCause);\n     }\n \n+    if (this.isReconnectingDS()) {\n+      logger.info(\"Reconnecting system failed to connect\");\n+      uncleanShutdown(reason,\n+          new ForcedDisconnectException(\"reconnecting system failed to connect\"));\n+      return;\n+    }\n+\n     if (!services.getConfig().getDistributionConfig().getDisableAutoReconnect()) {\n       saveCacheXmlForReconnect();\n     }\n \n-\n     Thread reconnectThread = new LoggingThread(\"DisconnectThread\", false, () -> {\n       // stop server locators immediately since they may not have correct\n       // information. This has caused client failures in bridge/wan",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/mgr/GMSMembershipManager.java",
                "sha": "592c749a27c932eaac3a3b514527de38e49670cf",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpHandler.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpHandler.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpHandler.java",
                "patch": "@@ -50,6 +50,11 @@\n   void restarting(DistributedSystem ds, GemFireCache cache,\n       InternalConfigurationPersistenceService sharedConfig);\n \n+  /**\n+   * Informs the handler that restart has completed\n+   */\n+  default void restartCompleted(DistributedSystem ds) {}\n+\n   /**\n    * Initialize the handler with the TcpServer. Called before the TcpServer starts accepting\n    * connections.",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpHandler.java",
                "sha": "1d19bf5f2750832bc4ea9abe1c1b735b0d0698ef",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "patch": "@@ -205,6 +205,10 @@ public void restarting(InternalDistributedSystem ds, InternalCache cache,\n         + System.identityHashCode(this.serverThread) + \";alive=\" + this.serverThread.isAlive());\n   }\n \n+  public void restartCompleted(InternalDistributedSystem ds) {\n+    this.handler.restartCompleted(ds);\n+  }\n+\n   public void start() throws IOException {\n     this.shuttingDown = false;\n     startServerThread();",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "sha": "c91a04d378c15b67efb29dcafba99b3aacdd5563",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/cache/CacheServerLauncher.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/CacheServerLauncher.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/CacheServerLauncher.java",
                "patch": "@@ -35,6 +35,7 @@\n import java.util.Properties;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.geode.CancelException;\n import org.apache.geode.LogWriter;\n import org.apache.geode.SystemFailure;\n import org.apache.geode.annotations.internal.MakeNotStatic;\n@@ -730,7 +731,11 @@ public void server(final String[] args) throws Exception {\n         // system.isReconnecting());\n         boolean reconnected = false;\n         if (system.isReconnecting()) {\n-          reconnected = system.waitUntilReconnected(-1, TimeUnit.SECONDS);\n+          try {\n+            reconnected = system.waitUntilReconnected(-1, TimeUnit.SECONDS);\n+          } catch (CancelException e) {\n+            // reconnect failed\n+          }\n           if (reconnected) {\n             system = (InternalDistributedSystem) system.getReconnectedSystem();\n             cache = system.getCache();",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/cache/CacheServerLauncher.java",
                "sha": "30dc64054d6185ffac549ae9ad6706cd330ff1a5",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 5,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "patch": "@@ -2470,12 +2470,16 @@ public boolean isReconnecting() {\n \n   @Override\n   public boolean waitUntilReconnected(long time, TimeUnit units) throws InterruptedException {\n-    boolean systemReconnected = this.system.waitUntilReconnected(time, units);\n-    if (!systemReconnected) {\n-      return false;\n+    try {\n+      boolean systemReconnected = this.system.waitUntilReconnected(time, units);\n+      if (!systemReconnected) {\n+        return false;\n+      }\n+      GemFireCacheImpl cache = getInstance();\n+      return cache != null && cache.isInitialized();\n+    } catch (CancelException e) {\n+      throw new CacheClosedException(\"Cache could not be recreated\", e);\n     }\n-    GemFireCacheImpl cache = getInstance();\n-    return cache != null && cache.isInitialized();\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "sha": "2fa37ae0b521aceb86a8c639d65f19b220f8a8ff",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/tcp/Connection.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/tcp/Connection.java?ref=7661eca53df6fa5c71ec21dc3de35eba5cb3e202",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/tcp/Connection.java",
                "patch": "@@ -46,6 +46,7 @@\n import org.apache.logging.log4j.Logger;\n \n import org.apache.geode.CancelException;\n+import org.apache.geode.SerializationException;\n import org.apache.geode.SystemFailure;\n import org.apache.geode.annotations.internal.MakeNotStatic;\n import org.apache.geode.annotations.internal.MutableForTesting;\n@@ -2831,7 +2832,7 @@ public void readAck(final DirectReplyProcessor processor)\n \n       Header header = msgReader.readHeader();\n \n-      ReplyMessage msg;\n+      ReplyMessage msg = null;\n       int len;\n       if (header.getMessageType() == NORMAL_MSG_TYPE) {\n         msg = (ReplyMessage) msgReader.readMessage(header);\n@@ -2941,8 +2942,12 @@ private void processInputBuffer() throws ConnectionException, IOException {\n           peerDataBuffer.limit(startPos + messageLength);\n \n           if (this.handshakeRead) {\n-            readMessage(peerDataBuffer);\n-\n+            try {\n+              readMessage(peerDataBuffer);\n+            } catch (SerializationException e) {\n+              logger.info(\"input buffer startPos {} oldLimit {}\", startPos, oldLimit);\n+              throw e;\n+            }\n           } else {\n             ByteBufferInputStream bbis = new ByteBufferInputStream(peerDataBuffer);\n             DataInputStream dis = new DataInputStream(bbis);\n@@ -3127,7 +3132,16 @@ private void readMessage(ByteBuffer peerDataBuffer) {\n         ReplyProcessor21.initMessageRPId();\n         // add serialization stats\n         long startSer = this.owner.getConduit().getStats().startMsgDeserialization();\n-        msg = (DistributionMessage) InternalDataSerializer.readDSFID(bbis);\n+        int startingPosition = peerDataBuffer.position();\n+        try {\n+          msg = (DistributionMessage) InternalDataSerializer.readDSFID(bbis);\n+        } catch (SerializationException e) {\n+          logger.info(\"input buffer starting position {} \"\n+              + \" current position {} limit {} capacity {} message length {}\",\n+              startingPosition, peerDataBuffer.position(), peerDataBuffer.limit(),\n+              peerDataBuffer.capacity(), messageLength);\n+          throw e;\n+        }\n         this.owner.getConduit().getStats().endMsgDeserialization(startSer);\n         if (bbis.available() != 0) {\n           logger.warn(\"Message deserialization of {} did not read {} bytes.\",",
                "raw_url": "https://github.com/apache/geode/raw/7661eca53df6fa5c71ec21dc3de35eba5cb3e202/geode-core/src/main/java/org/apache/geode/internal/tcp/Connection.java",
                "sha": "7fcbee5efb69428b24c46b3d3287f836b99c7f5d",
                "status": "modified"
            }
        ],
        "message": "GEODE-6369 Cache-creation failure after a successful auto-reconnect causes subsequent NPE\n\nIf an error occurs while rebuilding the cache on auto-reconnect & we can't\ncontinue we should throw an exception to any thread waiting for the\nreconnect to complete.\n\nIf we're unable to contact the cluster configuration service we do not\nterminate auto-reconnect attempts.\n\nNew members are now only allowed to join after view preparation has\ncompleted.  This will reduce the number of \"surprise members\" and also\nensures that any old member IDs have been removed from the view.\n\nWe now only attempt to use findCoordinatorFromView multiple times if the\nview actually changes.  Instead we contact locators again to see if\nthere are new registrants.\n\nfixing the above exposed other problems in auto-reconnect:\n\n* messages were being thrown away by the location service quorum checker\nduring auto-reconnect.  some of these were \"join\" messages that needed\nto be delivered to the new membership service\n\n* registrants weren't being removed from the recovered membership view\nin the locator.  This confused restarting nodes because the recovered\nmembership view has stale info in it that they don't want to use\n\n* locator services restart were hanging due to profile interchange being\ndone under synchronization",
        "parent": "https://github.com/apache/geode/commit/49696f83c70606673758a19cf904b544d1df4346",
        "patched_files": [
            "Service.java",
            "MembershipManager.java",
            "GemFireCacheImpl.java",
            "DistributedSystem.java",
            "ServerLocator.java",
            "GMSHealthMonitor.java",
            "GMSUtil.java",
            "Cache.java",
            "TcpHandler.java",
            "MembershipInformation.java",
            "JGroupsMessenger.java",
            "GMSQuorumChecker.java",
            "GMSMembershipManager.java",
            "CacheServerLauncher.java",
            "InternalLocator.java",
            "GMSJoinLeave.java",
            "TcpServer.java",
            "InternalDistributedSystem.java",
            "Connection.java",
            "Services.java",
            "Manager.java",
            "GMSLocator.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ReconnectDUnitTest.java",
            "MembershipJUnitTest.java",
            "ReconnectWithClusterConfigurationDUnitTest.java",
            "GemFireCacheImplTest.java",
            "GMSJoinLeaveJUnitTest.java",
            "JGroupsMessengerJUnitTest.java",
            "InternalDistributedSystemTest.java",
            "ClusterCommunicationsDUnitTest.java",
            "ConnectionTest.java"
        ]
    },
    "geode_769d9b3": {
        "bug_id": "geode_769d9b3",
        "commit": "https://github.com/apache/geode/commit/769d9b3ae6435beb967b7c2f648ee01aa909d271",
        "file": [
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/geode/blob/769d9b3ae6435beb967b7c2f648ee01aa909d271/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunction.java",
                "changes": 69,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunction.java?ref=769d9b3ae6435beb967b7c2f648ee01aa909d271",
                "deletions": 39,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunction.java",
                "patch": "@@ -20,55 +20,46 @@\n import java.util.Set;\n \n import org.apache.geode.cache.Cache;\n-import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.Region;\n-import org.apache.geode.cache.execute.FunctionAdapter;\n+import org.apache.geode.cache.execute.Function;\n import org.apache.geode.cache.execute.FunctionContext;\n import org.apache.geode.internal.InternalEntity;\n import org.apache.geode.management.internal.cli.domain.RegionInformation;\n \n /**\n  * Function that retrieves regions hosted on every member\n- *\n  */\n-public class GetRegionsFunction extends FunctionAdapter implements InternalEntity {\n+public class GetRegionsFunction implements Function, InternalEntity {\n+\n+  private static final long serialVersionUID = 1L;\n+\n+  @Override\n+  public String getId() {\n+    // TODO Auto-generated method stub\n+    return GetRegionsFunction.class.toString();\n+  }\n+\n+  @Override\n+  public void execute(FunctionContext functionContext) {\n+    try {\n+      Cache cache = CacheFactory.getAnyInstance();\n+      Set<Region<?, ?>> regions = cache.rootRegions(); // should never return a null\n \n-\t/**\n-\t * \n-\t */\n-\tprivate static final long\tserialVersionUID\t= 1L;\n+      if (regions == null || regions.isEmpty()) {\n+        functionContext.getResultSender().lastResult(null);\n+      } else {\n+        Set<RegionInformation> regionInformationSet = new HashSet<>();\n \n-\t@Override\n-\tpublic String getId() {\n-\t\t// TODO Auto-generated method stub\n-\t\treturn GetRegionsFunction.class.toString();\n-\t}\n-\t\n-\t@Override\n-\tpublic void execute(FunctionContext functionContext) {\n-\t\ttry {\n-\t\t\t\n-\t\t\tCache cache = CacheFactory.getAnyInstance();\n-\t\t\tSet <Region<?,?>> regions = cache.rootRegions();\n-\t\t\t\n-\t\t\tif (regions.isEmpty() || regions == null) {\n-\t\t\t\tfunctionContext.getResultSender().lastResult(null);\n-\t\t\t} else {\n-\t\t\t\t//Set<RegionInformation> regionInformationSet = RegionInformation.getRegionInformation(regions, true);\n-\t\t\t\tSet<RegionInformation> regionInformationSet = new HashSet<RegionInformation>();\n-\t\t\t\t\n-\t\t\t\tfor (Region<?,?> region : regions) {\n-\t\t\t\t  RegionInformation regInfo = new RegionInformation(region, true);\n-\t\t\t\t  regionInformationSet.add(regInfo);\n-\t\t\t\t}\n-\t\t\t\tfunctionContext.getResultSender().lastResult(regionInformationSet.toArray());\n-\t\t\t}\n-\t\t} catch (CacheClosedException e) {\n-\t\t\tfunctionContext.getResultSender().sendException(e);\n-\t\t} catch (Exception e) {\n-\t\t\tfunctionContext.getResultSender().sendException(e);\n-\t\t}\n-\t}\n+        for (Region<?, ?> region : regions) {\n+          RegionInformation regInfo = new RegionInformation(region, true);\n+          regionInformationSet.add(regInfo);\n+        }\n+        functionContext.getResultSender().lastResult(regionInformationSet.toArray());\n+      }\n+    } catch (Exception e) {\n+      functionContext.getResultSender().sendException(e);\n+    }\n+  }\n \n }",
                "raw_url": "https://github.com/apache/geode/raw/769d9b3ae6435beb967b7c2f648ee01aa909d271/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunction.java",
                "sha": "658f0120a9643d7946ff55dd1191ed6803afea1c",
                "status": "modified"
            },
            {
                "additions": 111,
                "blob_url": "https://github.com/apache/geode/blob/769d9b3ae6435beb967b7c2f648ee01aa909d271/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunctionJUnitTest.java",
                "changes": 111,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunctionJUnitTest.java?ref=769d9b3ae6435beb967b7c2f648ee01aa909d271",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunctionJUnitTest.java",
                "patch": "@@ -0,0 +1,111 @@\n+package org.apache.geode.management.internal.cli.functions;\n+\n+import static org.mockito.Mockito.*;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.mockito.InjectMocks;\n+import org.mockito.Mock;\n+import org.mockito.MockitoAnnotations;\n+import org.powermock.api.mockito.PowerMockito;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import org.apache.geode.CancelCriterion;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionAttributes;\n+import org.apache.geode.cache.Scope;\n+import org.apache.geode.cache.execute.FunctionContext;\n+import org.apache.geode.cache.execute.ResultSender;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.cache.GemFireCacheImpl;\n+import org.apache.geode.internal.cache.LocalRegion;\n+import org.apache.geode.internal.cache.control.InternalResourceManager;\n+import org.apache.geode.internal.security.AuthorizeRequest;\n+import org.apache.geode.test.junit.categories.UnitTest;\n+\n+@Category(UnitTest.class)\n+@RunWith(PowerMockRunner.class)\n+@PowerMockIgnore(\"*.UnitTest\")\n+@PrepareForTest({ CacheFactory.class })\n+public class GetRegionsFunctionJUnitTest {\n+\n+  TestResultSender testResultSender = new TestResultSender();\n+  Set<Region<?, ?>> regions = new HashSet<>();\n+  Set<Region<?, ?>> subregions = new HashSet<>();\n+  @Mock\n+  private RegionAttributes regionAttributes;\n+  @Mock\n+  private AuthorizeRequest authzRequest;\n+  @Mock\n+  private LocalRegion region;\n+  @Mock\n+  private GemFireCacheImpl cache;\n+  @Mock\n+  private InternalResourceManager internalResourceManager;\n+  @Mock\n+  private FunctionContext functionContext;\n+  @InjectMocks\n+  private GetRegionsFunction getRegionsFunction;\n+\n+  @Before\n+  public void before() throws Exception {\n+    System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"statsDisabled\", \"true\");\n+    getRegionsFunction = new GetRegionsFunction();\n+    MockitoAnnotations.initMocks(this);\n+\n+    when(this.cache.getCancelCriterion()).thenReturn(mock(CancelCriterion.class));\n+    when(this.cache.getDistributedSystem()).thenReturn(mock(InternalDistributedSystem.class));\n+    when(this.cache.getResourceManager()).thenReturn(this.internalResourceManager);\n+    when(functionContext.getResultSender()).thenReturn(testResultSender);\n+\n+    PowerMockito.mockStatic(CacheFactory.class);\n+    when(CacheFactory.getAnyInstance()).thenReturn(cache);\n+  }\n+\n+  @Test\n+  public void testExecuteWithoutRegions() throws Exception {\n+    getRegionsFunction.execute(functionContext);\n+  }\n+\n+  @Test\n+  public void testExecuteWithRegions() throws Exception {\n+    when(cache.rootRegions()).thenReturn(regions);\n+    when(region.getFullPath()).thenReturn(\"/MyRegion\");\n+\n+    when(region.getParentRegion()).thenReturn(null);\n+    when(region.subregions(true)).thenReturn(subregions);\n+    when(region.subregions(false)).thenReturn(subregions);\n+    when(region.getAttributes()).thenReturn(regionAttributes);\n+    when(regionAttributes.getDataPolicy()).thenReturn(mock(DataPolicy.class));\n+    when(regionAttributes.getScope()).thenReturn(mock(Scope.class));\n+    regions.add(region);\n+    getRegionsFunction.execute(functionContext);\n+  }\n+\n+  private static class TestResultSender implements ResultSender {\n+\n+    @Override\n+    public void lastResult(final Object lastResult) {\n+    }\n+\n+    @Override\n+    public void sendResult(final Object oneResult) {\n+    }\n+\n+    @Override\n+    public void sendException(final Throwable t) {\n+      throw new RuntimeException(t);\n+    }\n+  }\n+\n+} ",
                "raw_url": "https://github.com/apache/geode/raw/769d9b3ae6435beb967b7c2f648ee01aa909d271/geode-core/src/test/java/org/apache/geode/management/internal/cli/functions/GetRegionsFunctionJUnitTest.java",
                "sha": "6c57160372a5417b34f9d4ea96a103405031b045",
                "status": "added"
            }
        ],
        "message": "GEODE-136: Fix possible NullPointerException in Gfsh's 'list regions' command's GetRegionsFunction.\n\n* this closes #253",
        "parent": "https://github.com/apache/geode/commit/71f6d677e4519852b8427fb827131f5fd176ffd2",
        "patched_files": [
            "GetRegionsFunction.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GetRegionsFunctionJUnitTest.java"
        ]
    },
    "geode_79d2990": {
        "bug_id": "geode_79d2990",
        "commit": "https://github.com/apache/geode/commit/79d2990eb2be920e93a5bb413830db0c8458fb91",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/79d2990eb2be920e93a5bb413830db0c8458fb91/geode-core/src/test/java/com/gemstone/gemfire/disttx/DistTXManagerImplJUnitTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/disttx/DistTXManagerImplJUnitTest.java?ref=79d2990eb2be920e93a5bb413830db0c8458fb91",
                "deletions": 0,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/disttx/DistTXManagerImplJUnitTest.java",
                "patch": "@@ -18,6 +18,7 @@\n \n import java.util.Properties;\n \n+import com.gemstone.gemfire.internal.cache.TXManagerImpl;\n import org.junit.experimental.categories.Category;\n \n import com.gemstone.gemfire.cache.CacheFactory;\n@@ -27,6 +28,7 @@\n import com.gemstone.gemfire.test.junit.categories.DistributedTransactionsTest;\n import com.gemstone.gemfire.test.junit.categories.IntegrationTest;\n \n+import static junit.framework.TestCase.assertTrue;\n \n /**\n  * Same tests as that of {@link TXManagerImplJUnitTest} after setting\n@@ -51,4 +53,8 @@ protected void createCache() {\n     assert(txmgr.isDistributed());\n   }\n \n+  @Override\n+  protected void callIsDistributed(TXManagerImpl txMgr) {\n+    assertTrue(txMgr.isDistributed());\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/79d2990eb2be920e93a5bb413830db0c8458fb91/geode-core/src/test/java/com/gemstone/gemfire/disttx/DistTXManagerImplJUnitTest.java",
                "sha": "e4db28592ba5d8c3f5629b25db6b0235bc0f9a9a",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/79d2990eb2be920e93a5bb413830db0c8458fb91/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java?ref=79d2990eb2be920e93a5bb413830db0c8458fb91",
                "deletions": 0,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "patch": "@@ -336,6 +336,10 @@ public void testSuspendTimeout() throws Exception {\n   public void testIsDistributedDoesNotThrowNPE() {\n     TXManagerImpl txMgr = (TXManagerImpl) cache.getCacheTransactionManager();\n     cache.getDistributedSystem().disconnect();\n+    callIsDistributed(txMgr);\n+  }\n+\n+  protected void callIsDistributed(TXManagerImpl txMgr) {\n     assertFalse(txMgr.isDistributed());\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/79d2990eb2be920e93a5bb413830db0c8458fb91/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/TXManagerImplJUnitTest.java",
                "sha": "fa4c640adcfe588e2389f60d1e615378b249092c",
                "status": "modified"
            }
        ],
        "message": "GEODE-1099: NPE thrown from TXManagerImpl.isDistributed()\n\nfixing the DistTXManagerImplJUnitTest that was overriding the test added\nin the last commit for this issue.",
        "parent": "https://github.com/apache/geode/commit/82faa8affc7517776418d84c21df9304ebf988de",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "DistTXManagerImplJUnitTest.java",
            "TXManagerImplJUnitTest.java"
        ]
    },
    "geode_82bc8f9": {
        "bug_id": "geode_82bc8f9",
        "commit": "https://github.com/apache/geode/commit/82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -166,6 +166,8 @@\n    */\n   private volatile boolean stoppedForReconnect;\n \n+  private volatile boolean reconnected;\n+\n   /**\n    * whether the locator was stopped during forced-disconnect processing\n    */\n@@ -936,6 +938,7 @@ public void run() {\n           if (!restarted) {\n             stoppedForReconnect = false;\n           }\n+          reconnected = restarted;\n         }\n         InternalLocator.this.restartThread = null;\n       }\n@@ -944,6 +947,10 @@ public void run() {\n     this.restartThread.start();\n   }\n \n+  public boolean isReconnected() {\n+    return reconnected;\n+  }\n+\n   /**\n    * reconnects the locator to a restarting DistributedSystem. If quorum checks are enabled this\n    * will start peer location services before a distributed system is available if the quorum check",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "2ed7b9a2a21bc05acdd74ca4c969ff0d7668b9a7",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/management/internal/configuration/callbacks/ConfigurationChangeListener.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/configuration/callbacks/ConfigurationChangeListener.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/configuration/callbacks/ConfigurationChangeListener.java",
                "patch": "@@ -17,7 +17,6 @@\n import java.io.File;\n import java.io.IOException;\n import java.util.HashSet;\n-import java.util.Optional;\n import java.util.Set;\n \n import org.apache.commons.io.FileUtils;\n@@ -92,6 +91,10 @@ private void addOrRemoveJarFromFilesystem(EntryEvent<String, Configuration> even\n     }\n \n     String triggerMemberId = (String) event.getCallbackArgument();\n+    if (triggerMemberId == null || newJars.isEmpty()) {\n+      return;\n+    }\n+\n     DistributedMember locator = getDistributedMember(triggerMemberId);\n     for (String jarAdded : newJars) {\n       try {\n@@ -106,8 +109,9 @@ private DistributedMember getDistributedMember(String memberName) {\n     Set<DistributedMember> locators = new HashSet<>(\n         cache.getDistributionManager().getAllHostedLocatorsWithSharedConfiguration().keySet());\n \n-    Optional<DistributedMember> locator =\n-        locators.stream().filter(x -> x.getId().equals(memberName)).findFirst();\n-    return locator.get();\n+    return locators.stream()\n+        .filter(x -> x.getId().equals(memberName))\n+        .findFirst()\n+        .orElse(null);\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/management/internal/configuration/callbacks/ConfigurationChangeListener.java",
                "sha": "64e9724f0c68f8abba30131d9de64f98cef3e2c5",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/management/internal/security/MBeanServerWrapper.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/security/MBeanServerWrapper.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/security/MBeanServerWrapper.java",
                "patch": "@@ -61,7 +61,6 @@\n  */\n public class MBeanServerWrapper implements MBeanServerForwarder {\n \n-  // TODO: make volatile or verify this is thread-safe\n   private MBeanServer mbs;\n \n   private final SecurityService securityService;",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/main/java/org/apache/geode/management/internal/security/MBeanServerWrapper.java",
                "sha": "24f0dbefa5f2aad4f36d5b5e24442f3b961314ff",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/MembershipManagerHelper.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/MembershipManagerHelper.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/MembershipManagerHelper.java",
                "patch": "@@ -124,10 +124,11 @@ public String description() {\n \n   public static void crashDistributedSystem(final DistributedSystem msys) {\n     msys.getLogWriter().info(\"crashing distributed system: \" + msys);\n+    GMSMembershipManager mgr = ((GMSMembershipManager) getMembershipManager(msys));\n+    mgr.saveCacheXmlForReconnect(false);\n     MembershipManagerHelper.inhibitForcedDisconnectLogging(true);\n     MembershipManagerHelper.beSickMember(msys);\n     MembershipManagerHelper.playDead(msys);\n-    GMSMembershipManager mgr = ((GMSMembershipManager) getMembershipManager(msys));\n     mgr.forceDisconnect(\"for testing\");\n     // wait at most 10 seconds for system to be disconnected\n     Awaitility.await().pollInterval(1, TimeUnit.SECONDS).until(() -> !msys.isConnected());",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/MembershipManagerHelper.java",
                "sha": "09169f2c7e84a2b698b88e6b2954b862ec868c7b",
                "status": "modified"
            },
            {
                "additions": 305,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/management/JMXMBeanReconnectDUnitTest.java",
                "changes": 305,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/JMXMBeanReconnectDUnitTest.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/JMXMBeanReconnectDUnitTest.java",
                "patch": "@@ -0,0 +1,305 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.management;\n+\n+import static java.util.concurrent.TimeUnit.MINUTES;\n+import static java.util.stream.Collectors.toList;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.SoftAssertions.assertSoftly;\n+import static org.awaitility.Awaitility.waitAtMost;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+\n+import javax.management.MBeanServerConnection;\n+import javax.management.ObjectName;\n+import javax.management.remote.JMXConnector;\n+import javax.management.remote.JMXConnectorFactory;\n+import javax.management.remote.JMXServiceURL;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.distributed.ConfigurationProperties;\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.management.internal.SystemManagementService;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.junit.categories.DistributedTest;\n+import org.apache.geode.test.junit.categories.JMXTest;\n+import org.apache.geode.test.junit.rules.GfshCommandRule;\n+import org.apache.geode.test.junit.rules.MBeanServerConnectionRule;\n+\n+@Category({DistributedTest.class, JMXTest.class})\n+public class JMXMBeanReconnectDUnitTest {\n+  private static final String LOCATOR_1_NAME = \"locator-one\";\n+  private static final String LOCATOR_2_NAME = \"locator-two\";\n+  private static final String REGION_PATH = \"/test-region-1\";\n+  private static final int LOCATOR_1_VM_INDEX = 0;\n+  private static final int LOCATOR_2_VM_INDEX = 1;\n+  private static final int LOCATOR_COUNT = 2;\n+  private static final int SERVER_1_VM_INDEX = 2;\n+  private static final int SERVER_2_VM_INDEX = 3;\n+  private static final int SERVER_COUNT = 2;\n+\n+  private int locator1JmxPort, locator2JmxPort;\n+\n+  private MemberVM locator1, locator2, server1, server2;\n+\n+  @Rule\n+  public ClusterStartupRule lsRule = new ClusterStartupRule();\n+\n+  @Rule\n+  public GfshCommandRule gfsh = new GfshCommandRule();\n+\n+  @Rule\n+  public MBeanServerConnectionRule jmxConnectionRule = new MBeanServerConnectionRule();\n+\n+  @Before\n+  public void before() throws Exception {\n+    int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(LOCATOR_COUNT);\n+    locator1JmxPort = ports[0];\n+    locator2JmxPort = ports[1];\n+\n+    locator1 = lsRule.startLocatorVM(LOCATOR_1_VM_INDEX, locator1Properties());\n+    locator2 = lsRule.startLocatorVM(LOCATOR_2_VM_INDEX, locator2Properties(), locator1.getPort());\n+\n+    server1 = lsRule.startServerVM(SERVER_1_VM_INDEX, locator1.getPort());\n+    server2 = lsRule.startServerVM(SERVER_2_VM_INDEX, locator1.getPort());\n+\n+    gfsh.connectAndVerify(locator1);\n+    gfsh.executeAndAssertThat(\n+        \"create region --type=REPLICATE --name=\" + REGION_PATH + \" --enable-statistics=true\")\n+        .statusIsSuccess();\n+\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+    waitForLocatorsToAgreeOnMembership();\n+  }\n+\n+  @Test\n+  public void testLocalBeans_MaintainServerAndCrashLocator() {\n+    List<String> initialServerBeans = canonicalBeanNamesFor(server1);\n+\n+    locator1.forceDisconnectMember();\n+\n+    List<String> intermediateServerBeans = canonicalBeanNamesFor(server1);\n+\n+    assertThat(intermediateServerBeans)\n+        .containsExactlyElementsOf(initialServerBeans);\n+\n+    locator1.waitTilLocatorFullyReconnected();\n+\n+    List<String> finalServerBeans = canonicalBeanNamesFor(server1);\n+\n+    assertThat(finalServerBeans)\n+        .containsExactlyElementsOf(initialServerBeans);\n+  }\n+\n+  @Test\n+  public void testLocalBeans_MaintainLocatorAndCrashServer() {\n+    List<String> initialLocatorBeans = canonicalBeanNamesFor(locator1);\n+\n+    server1.forceDisconnectMember();\n+\n+    List<String> intermediateLocatorBeans = canonicalBeanNamesFor(locator1);\n+\n+    assertThat(intermediateLocatorBeans)\n+        .containsExactlyElementsOf(initialLocatorBeans);\n+\n+    server1.waitTilServerFullyReconnected();\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+\n+    List<String> finalLocatorBeans = canonicalBeanNamesFor(locator1);\n+\n+    assertThat(finalLocatorBeans)\n+        .containsExactlyElementsOf(initialLocatorBeans);\n+  }\n+\n+  @Test\n+  public void testRemoteBeanKnowledge_MaintainServerAndCrashLocator() throws IOException {\n+    List<ObjectName> initialLocator1GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator1);\n+    List<ObjectName> initialLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    assertThat(initialLocator1GemfireBeans)\n+        .containsExactlyElementsOf(initialLocator2GemfireBeans);\n+\n+    locator1.forceDisconnectMember();\n+\n+    List<ObjectName> intermediateLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    List<ObjectName> locatorBeansExcludingStoppedMember = initialLocator2GemfireBeans.stream()\n+        .filter(excludingBeansFor(LOCATOR_1_NAME)).collect(toList());\n+\n+    assertThat(intermediateLocator2GemfireBeans)\n+        .containsExactlyElementsOf(locatorBeansExcludingStoppedMember);\n+\n+    locator1.waitTilLocatorFullyReconnected();\n+    waitForLocatorsToAgreeOnMembership();\n+\n+    List<ObjectName> finalLocator1GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator1);\n+    List<ObjectName> finalLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    assertSoftly(softly -> {\n+      softly.assertThat(finalLocator1GemfireBeans)\n+          .containsExactlyElementsOf(finalLocator2GemfireBeans);\n+      softly.assertThat(finalLocator1GemfireBeans)\n+          .containsExactlyElementsOf(initialLocator2GemfireBeans);\n+    });\n+  }\n+\n+  @Test\n+  public void testRemoteBeanKnowledge_MaintainLocatorAndCrashServer()\n+      throws IOException {\n+    List<ObjectName> initialLocator1GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator1);\n+    List<ObjectName> initialLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    assertThat(initialLocator1GemfireBeans)\n+        .containsExactlyElementsOf(initialLocator2GemfireBeans);\n+\n+    server1.forceDisconnectMember();\n+\n+    List<ObjectName> intermediateLocator1GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator1);\n+    List<ObjectName> intermediateLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    List<ObjectName> locatorBeansExcludingStoppedMember = initialLocator1GemfireBeans.stream()\n+        .filter(excludingBeansFor(\"server-\" + SERVER_1_VM_INDEX))\n+        .collect(toList());\n+\n+    assertSoftly(softly -> {\n+      softly.assertThat(intermediateLocator2GemfireBeans)\n+          .containsExactlyElementsOf(intermediateLocator1GemfireBeans);\n+      softly.assertThat(intermediateLocator2GemfireBeans)\n+          .containsExactlyElementsOf(locatorBeansExcludingStoppedMember);\n+    });\n+\n+    server1.waitTilServerFullyReconnected();\n+    locator1.waitTillRegionsAreReadyOnServers(REGION_PATH, SERVER_COUNT);\n+    waitForLocatorsToAgreeOnMembership();\n+\n+    List<ObjectName> finalLocator1GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator1);\n+    List<ObjectName> finalLocator2GemfireBeans =\n+        getFederatedGemfireBeansFrom(locator2);\n+\n+    assertSoftly(softly -> {\n+      softly.assertThat(finalLocator1GemfireBeans)\n+          .containsExactlyElementsOf(finalLocator2GemfireBeans);\n+      softly.assertThat(finalLocator1GemfireBeans)\n+          .containsExactlyElementsOf(initialLocator2GemfireBeans);\n+    });\n+  }\n+\n+  private static List<ObjectName> getFederatedGemfireBeansFrom(MemberVM member)\n+      throws IOException {\n+    String url = jmxBeanLocalhostUrlString(member.getJmxPort());\n+    MBeanServerConnection remoteMBS = connectToMBeanServer(url);\n+    return getFederatedGemfireBeanObjectNames(remoteMBS);\n+  }\n+\n+  private static MBeanServerConnection connectToMBeanServer(String url) throws IOException {\n+    final JMXServiceURL serviceURL = new JMXServiceURL(url);\n+    JMXConnector conn = JMXConnectorFactory.connect(serviceURL);\n+    return conn.getMBeanServerConnection();\n+  }\n+\n+  private static List<ObjectName> getFederatedGemfireBeanObjectNames(\n+      MBeanServerConnection remoteMBS)\n+      throws IOException {\n+    Set<ObjectName> allBeans = remoteMBS.queryNames(null, null);\n+    // Each locator will have a \"Manager\" bean that is a part of the above query,\n+    // representing the ManagementAdapter.\n+    // This bean is registered (and so included in its own queries),\n+    // but *not* federated (and so is not included in another locator's bean queries).\n+    // For the scope of this test, we do not consider these \"service=Manager\" beans.\n+    return allBeans.stream()\n+        .filter(b -> b.toString().contains(\"GemFire\"))\n+        .filter(b -> !b.toString().contains(\"service=Manager,type=Member,member=locator\"))\n+        .sorted()\n+        .collect(toList());\n+  }\n+\n+  private static List<String> canonicalBeanNamesFor(MemberVM member) {\n+    return member.invoke(JMXMBeanReconnectDUnitTest::getLocalCanonicalBeanNames);\n+  }\n+\n+  private static List<String> getLocalCanonicalBeanNames() {\n+    Cache cache = ClusterStartupRule.getCache();\n+    SystemManagementService service =\n+        (SystemManagementService) ManagementService.getExistingManagementService(cache);\n+    Map<ObjectName, Object> gfBeanMap = service.getJMXAdapter().getLocalGemFireMBean();\n+    return gfBeanMap.keySet().stream()\n+        .map(ObjectName::getCanonicalName)\n+        .sorted()\n+        .collect(toList());\n+  }\n+\n+  private void waitForLocatorsToAgreeOnMembership() {\n+    waitAtMost(1, MINUTES)\n+        .until(\n+            () -> {\n+              int locator1BeanCount =\n+                  getFederatedGemfireBeansFrom(locator1)\n+                      .size();\n+              int locator2BeanCount =\n+                  getFederatedGemfireBeansFrom(locator2)\n+                      .size();\n+              return locator1BeanCount == locator2BeanCount;\n+            });\n+  }\n+\n+  private static Predicate<ObjectName> excludingBeansFor(String memberName) {\n+    return b -> !b.getCanonicalName().contains(\"member=\" + memberName);\n+  }\n+\n+  private static String jmxBeanLocalhostUrlString(int port) {\n+    return \"service:jmx:rmi:///jndi/rmi://localhost\"\n+        + \":\" + port + \"/jmxrmi\";\n+  }\n+\n+  private Properties locator1Properties() {\n+    Properties props = new Properties();\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_HOSTNAME_FOR_CLIENTS, \"localhost\");\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_PORT, \"\" + locator1JmxPort);\n+    props.setProperty(ConfigurationProperties.NAME, LOCATOR_1_NAME);\n+    props.setProperty(ConfigurationProperties.MAX_WAIT_TIME_RECONNECT, \"5000\");\n+    return props;\n+  }\n+\n+  private Properties locator2Properties() {\n+    Properties props = new Properties();\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_HOSTNAME_FOR_CLIENTS, \"localhost\");\n+    props.setProperty(ConfigurationProperties.JMX_MANAGER_PORT, \"\" + locator2JmxPort);\n+    props.setProperty(ConfigurationProperties.NAME, LOCATOR_2_NAME);\n+    props.setProperty(ConfigurationProperties.LOCATORS, \"localhost[\" + locator1.getPort() + \"]\");\n+    return props;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/management/JMXMBeanReconnectDUnitTest.java",
                "sha": "2bf49c7dc1d688b6d9cb034fa67339eac9b70f1b",
                "status": "added"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "patch": "@@ -14,11 +14,18 @@\n  */\n package org.apache.geode.test.dunit.rules;\n \n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n import java.io.File;\n import java.util.Arrays;\n+import java.util.concurrent.TimeUnit;\n \n import org.apache.commons.io.FileUtils;\n+import org.awaitility.Awaitility;\n \n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.InternalLocator;\n+import org.apache.geode.internal.cache.InternalCache;\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.junit.rules.Locator;\n import org.apache.geode.test.junit.rules.Member;\n@@ -102,6 +109,26 @@ public void forceDisconnectMember() {\n     vm.invoke(() -> ClusterStartupRule.memberStarter.forceDisconnectMember());\n   }\n \n+  public void waitTilLocatorFullyReconnected() {\n+    vm.invoke(() -> Awaitility.waitAtMost(30, TimeUnit.SECONDS).until(() -> {\n+      InternalLocator intLocator = InternalLocator.getLocator();\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      return intLocator != null && cache != null && intLocator.getDistributedSystem().isConnected()\n+          && intLocator.isReconnected();\n+    }));\n+  }\n+\n+  public void waitTilServerFullyReconnected() {\n+    vm.invoke(() -> Awaitility.waitAtMost(30, SECONDS).until(() -> {\n+      InternalDistributedSystem internalDistributedSystem =\n+          InternalDistributedSystem.getConnectedInstance();\n+      return internalDistributedSystem != null\n+          && internalDistributedSystem.getCache() != null\n+          && !internalDistributedSystem.getCache().getCacheServers().isEmpty();\n+    }));\n+\n+  }\n+\n   /**\n    * this should called on a locatorVM or a serverVM with jmxManager enabled\n    */",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "sha": "eef2990dc35a3840253411df26c72a68d9377adf",
                "status": "modified"
            },
            {
                "additions": 77,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleIntegrationTest.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleIntegrationTest.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleIntegrationTest.java",
                "patch": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.test.dunit.rules.tests;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.cache.server.CacheServer;\n+import org.apache.geode.distributed.internal.InternalLocator;\n+import org.apache.geode.internal.AvailablePort;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.apache.geode.test.junit.rules.LocatorStarterRule;\n+import org.apache.geode.test.junit.rules.ServerStarterRule;\n+\n+@Category(IntegrationTest.class)\n+public class MemberStarterRuleIntegrationTest {\n+\n+\n+  private LocatorStarterRule locator;\n+  private ServerStarterRule server;\n+\n+  @After\n+  public void cleanupAnyStartedMembers() {\n+    if (locator != null) {\n+      locator.after();\n+    }\n+    if (server != null) {\n+      server.after();\n+    }\n+  }\n+\n+  @Test\n+  public void testWithPortOnLocator() {\n+    int targetPort = AvailablePort.getRandomAvailablePort(1);\n+    locator = new LocatorStarterRule().withPort(targetPort).withAutoStart();\n+    locator.before();\n+\n+    InternalLocator internalMember = locator.getLocator();\n+\n+    // This is the rule framework's port\n+    assertThat(locator.getPort()).isEqualTo(targetPort);\n+    // This is the actual, live member's port.\n+    assertThat(internalMember.getPort()).isEqualTo(targetPort);\n+\n+  }\n+\n+  @Test\n+  public void testWithPortOnServer() {\n+    int targetPort = AvailablePort.getRandomAvailablePort(1);\n+    server = new ServerStarterRule().withPort(targetPort).withAutoStart();\n+    server.before();\n+\n+    CacheServer internalMember = server.getServer();\n+\n+    // This is the rule framework's port\n+    assertThat(server.getPort()).isEqualTo(targetPort);\n+    // This is the actual, live member's port.\n+    assertThat(internalMember.getPort()).isEqualTo(targetPort);\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleIntegrationTest.java",
                "sha": "359fcaf806fbb8b2fb9c8d617d212f73694adfbd",
                "status": "added"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleTest.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleTest.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleTest.java",
                "patch": "@@ -67,6 +67,15 @@ public void testSetJMXPortWithAPIThenProperty() {\n     assertThat(locator.getJmxPort()).isEqualTo(port);\n   }\n \n+  @Test\n+  public void testWithPort() {\n+    int targetPort = 12345;\n+    locator = new LocatorStarterRule().withPort(targetPort);\n+    locator.before();\n+\n+    assertThat(locator.getPort()).isEqualTo(targetPort);\n+  }\n+\n   @Test\n   public void testUseRandomPortByDefault() {\n     locator = new LocatorStarterRule();",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/dunit/rules/tests/MemberStarterRuleTest.java",
                "sha": "30d83bdfe7dfbccd1f6caf6bc64d4a8abd2f8e44",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/LocatorStarterRule.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/rules/LocatorStarterRule.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/rules/LocatorStarterRule.java",
                "patch": "@@ -77,11 +77,14 @@ protected void stopMember() {\n   public void startLocator() {\n     try {\n       // this will start a jmx manager and admin rest service by default\n-      locator = (InternalLocator) startLocatorAndDS(0, null, properties);\n+      locator = (InternalLocator) startLocatorAndDS(memberPort, null, properties);\n     } catch (IOException e) {\n       throw new UncheckedIOException(e);\n     }\n+    // memberPort is by default zero, which translates to \"randomly select an available port,\"\n+    // which is why it is updated here after being specified above.\n     memberPort = locator.getPort();\n+\n     DistributionConfig config = locator.getConfig();\n     jmxPort = config.getJmxManagerPort();\n     httpPort = config.getHttpServicePort();",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/LocatorStarterRule.java",
                "sha": "10e9a7a28eb53d2298953eda018d938323d83434",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "patch": "@@ -63,7 +63,7 @@\n \n   protected transient TemporaryFolder temporaryFolder;\n   protected File workingDir;\n-  protected int memberPort = -1;\n+  protected int memberPort = 0;\n   protected int jmxPort = -1;\n   protected int httpPort = -1;\n \n@@ -105,6 +105,11 @@ public void after() {\n     }\n   }\n \n+  public T withPort(int memberPort) {\n+    this.memberPort = memberPort;\n+    return (T) this;\n+  }\n+\n   public T withWorkingDir(File workingDir) {\n     this.workingDir = workingDir;\n     if (workingDir != null) {",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "sha": "b42cba09e611527ee9bbb417bb60e769d199a2fb",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/ServerStarterRule.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/rules/ServerStarterRule.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/rules/ServerStarterRule.java",
                "patch": "@@ -173,7 +173,9 @@ public void startServer() {\n     DistributionConfig config =\n         ((InternalDistributedSystem) cache.getDistributedSystem()).getConfig();\n     server = cache.addCacheServer();\n-    server.setPort(0);\n+    // memberPort is by default zero, which translates to \"randomly select an available port,\"\n+    // which is why it is updated after this try block\n+    server.setPort(memberPort);\n     try {\n       server.start();\n     } catch (IOException e) {",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/ServerStarterRule.java",
                "sha": "ca60fac86c78076c81d3c8e24592a21e070f6ed5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/VMProvider.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/junit/rules/VMProvider.java?ref=82bc8f9cb82806b6e5b5e3a91c382d8372eade00",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/test/junit/rules/VMProvider.java",
                "patch": "@@ -35,7 +35,7 @@ public void stopMember(boolean cleanWorkingDir) {\n       ClusterStartupRule.stopElementInsideVM();\n       MemberStarterRule.disconnectDSIfAny();\n     });\n-  };\n+  }\n \n   public boolean isClient() {\n     return getVM().invoke(() -> {",
                "raw_url": "https://github.com/apache/geode/raw/82bc8f9cb82806b6e5b5e3a91c382d8372eade00/geode-core/src/test/java/org/apache/geode/test/junit/rules/VMProvider.java",
                "sha": "1b8f014c90254fed66c88838663f876649dc4fd1",
                "status": "modified"
            }
        ],
        "message": "GEODE-5284: Add testing surrounding MBean persistence during member failure and reconnection. (#2066)\n\n* Add null-check to ConfigurationChangeListener to avoid NPE when a locator joins.\r\n* Add withPort method to MemberStarterRule to specify membership port\r\n* Add testing associated with MemberStarterRule addition\r\n* Ensure cleanup of members in MemberStarterRuleIntegrationTest.\r\n* Improve names and extract helper methods\r\n* use the methods provided by the starter rules to force disconnect and\r\nto reconnect servers and locators. Adds a parameter in InternalLocator\r\nto track the status of the reconnect. Adds export of cache xml for\r\nreconnect so that the server is able to restore its state following\r\ndisconnect.\r\n\r\nCo-Authored-by: Helena Bales <hbales@pivotal.io>\r\nCo-Authored-by: Dale Emery <dale@dhemery.com>\r\nCo-Authored-by: Patrick Rhomberg <prhomberg@pivotal.io>\r\nCo-Authored-By: Jinmei Liao <jinmeiliao@pivotal.io>",
        "parent": "https://github.com/apache/geode/commit/c9be10e3077b4ff1958f44637183799afd00dbab",
        "patched_files": [
            "MembershipManagerHelper.java",
            "ConfigurationChangeListener.java",
            "VMProvider.java",
            "InternalLocator.java",
            "ServerStarterRule.java",
            "MemberVM.java",
            "MBeanServerWrapper.java",
            "LocatorStarterRule.java",
            "MemberStarterRule.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "MemberStarterRuleTest.java",
            "MemberStarterRuleIntegrationTest.java",
            "JMXMBeanReconnectDUnitTest.java"
        ]
    },
    "geode_8a644c2": {
        "bug_id": "geode_8a644c2",
        "commit": "https://github.com/apache/geode/commit/8a644c25de9c4bc5a413de96dfac88451fda7fc8",
        "file": [
            {
                "additions": 176,
                "blob_url": "https://github.com/apache/geode/blob/8a644c25de9c4bc5a413de96dfac88451fda7fc8/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/Bug37377DUnitTest.java",
                "changes": 393,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/Bug37377DUnitTest.java?ref=8a644c25de9c4bc5a413de96dfac88451fda7fc8",
                "deletions": 217,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/internal/cache/Bug37377DUnitTest.java",
                "patch": "@@ -22,32 +22,22 @@\n import static org.junit.Assert.*;\n \n import com.gemstone.gemfire.test.dunit.cache.internal.JUnit4CacheTestCase;\n-import com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase;\n import com.gemstone.gemfire.test.junit.categories.DistributedTest;\n \n import java.io.File;\n import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n \n import com.gemstone.gemfire.cache.AttributesFactory;\n import com.gemstone.gemfire.cache.Cache;\n import com.gemstone.gemfire.cache.CacheFactory;\n import com.gemstone.gemfire.cache.DataPolicy;\n-import com.gemstone.gemfire.cache.EntryEvent;\n-import com.gemstone.gemfire.cache.Operation;\n import com.gemstone.gemfire.cache.Region;\n import com.gemstone.gemfire.cache.RegionAttributes;\n import com.gemstone.gemfire.cache.Scope;\n-import com.gemstone.gemfire.cache30.CacheSerializableRunnable;\n-import com.gemstone.gemfire.cache30.CacheTestCase;\n import com.gemstone.gemfire.distributed.DistributedSystem;\n-import com.gemstone.gemfire.internal.cache.lru.EnableLRU;\n-import com.gemstone.gemfire.internal.util.concurrent.CustomEntryConcurrentHashMap.HashEntry;\n-import com.gemstone.gemfire.test.dunit.AsyncInvocation;\n import com.gemstone.gemfire.test.dunit.Host;\n-import com.gemstone.gemfire.test.dunit.SerializableRunnable;\n-import com.gemstone.gemfire.test.dunit.ThreadUtils;\n import com.gemstone.gemfire.test.dunit.VM;\n-import com.gemstone.gemfire.test.dunit.Wait;\n \n /**\n  * Bug37377 DUNIT Test: The Clear operation during a GII in progress can leave a\n@@ -67,16 +57,18 @@\n \n   protected static DistributedSystem distributedSystem = null;\n \n-  private static VM vm0 = null;\n-\n-  private static VM vm1 = null;\n+  VM vm0, vm1;\n \n   protected static Cache cache = null;\n \n   protected static File[] dirs = null;\n \n   private static final int maxEntries = 10000;\n \n+  transient private static CountDownLatch clearLatch = new CountDownLatch(1);\n+\n+  static Boolean clearOccured = false;\n+\n   public Bug37377DUnitTest() {\n     super();\n     File file1 = new File(getTestMethodName() + \"1\");\n@@ -99,206 +91,161 @@ public final void postSetUp() throws Exception {\n \n   @Override\n   public final void preTearDownCacheTestCase() throws Exception {\n-    vm1.invoke(destroyRegion());\n-    vm0.invoke(destroyRegion());\n+    vm1.invoke(() -> destroyRegion());\n+    vm0.invoke(() -> destroyRegion());\n   }\n \n   /**\n    * This method is used to create Cache in VM0\n-   * \n-   * @return CacheSerializableRunnable\n    */\n \n-  private CacheSerializableRunnable createCacheForVM0()\n-  {\n-    SerializableRunnable createCache = new CacheSerializableRunnable(\n-        \"createCache\") {\n-      public void run2()\n-      {\n-        try {\n-\n-          distributedSystem = (new Bug37377DUnitTest())\n-              .getSystem(props);\n-          assertTrue(distributedSystem != null);\n-          cache = CacheFactory.create(distributedSystem);\n-          assertTrue(cache != null);\n-          AttributesFactory factory = new AttributesFactory();\n-          factory.setScope(Scope.DISTRIBUTED_ACK);\n-          factory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n-          factory.setDiskSynchronous(false);\n-          factory.setDiskStoreName(cache.createDiskStoreFactory()\n-                                   .setDiskDirs(dirs)\n-                                   .create(\"Bug37377DUnitTest\")\n-                                   .getName());\n-          RegionAttributes attr = factory.create();\n-          cache.createRegion(regionName, attr);\n-        }\n-        catch (Exception ex) {\n-          ex.printStackTrace();\n-          fail(\"Error Creating cache / region \");\n-        }\n-      }\n-    };\n-    return (CacheSerializableRunnable)createCache;\n+  @SuppressWarnings(\"deprecation\")\n+  private void createCacheForVM0() {\n+    try {\n+\n+      distributedSystem = (new Bug37377DUnitTest())\n+          .getSystem(props);\n+      assertTrue(distributedSystem != null);\n+      cache = CacheFactory.create(distributedSystem);\n+      assertTrue(cache != null);\n+      AttributesFactory factory = new AttributesFactory();\n+      factory.setScope(Scope.DISTRIBUTED_ACK);\n+      factory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+      factory.setDiskSynchronous(false);\n+      factory.setDiskStoreName(cache.createDiskStoreFactory()\n+          .setDiskDirs(dirs)\n+          .create(\"Bug37377DUnitTest\")\n+          .getName());\n+      RegionAttributes attr = factory.create();\n+      cache.createRegion(regionName, attr);\n+    }\n+    catch (Exception ex) {\n+      ex.printStackTrace();\n+      fail(\"Error Creating cache / region \");\n+    }\n   }\n \n   /**\n    * This method is used to create Cache in VM1\n-   * \n-   * @return CacheSerializableRunnable\n    */\n-  private CacheSerializableRunnable createCacheForVM1()\n-  {\n-    SerializableRunnable createCache = new CacheSerializableRunnable(\n-        \"createCache\") {\n-      public void run2()\n-      {\n-        try {\n-          distributedSystem = (new Bug37377DUnitTest())\n-              .getSystem(props);\n-          assertTrue(distributedSystem != null);\n-          cache = CacheFactory.create(distributedSystem);\n-          assertTrue(\"cache found null\", cache != null);\n-\n-          AttributesFactory factory = new AttributesFactory();\n-          factory.setScope(Scope.DISTRIBUTED_ACK);\n-          factory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n-          factory.setDiskSynchronous(false);\n-          factory.setDiskStoreName(cache.createDiskStoreFactory()\n-                                   .setDiskDirs(dirs)\n-                                   .create(\"Bug37377DUnitTest\")\n-                                   .getName());\n-          RegionAttributes attr = factory.create();\n-          DistributedRegion distRegion = new DistributedRegion(regionName,\n-              attr, null, (GemFireCacheImpl)cache, new InternalRegionArguments()\n-                  .setDestroyLockFlag(true).setRecreateFlag(false)\n-                  .setSnapshotInputStream(null).setImageTarget(null));\n-//          assertTrue(\"Distributed Region is null\", distRegion != null); (cannot be null)\n-\n-          ((AbstractRegionMap)distRegion.entries)\n-              .setEntryFactory(TestAbstractDiskRegionEntry.getEntryFactory());\n-\n-          LocalRegion region = (LocalRegion)((GemFireCacheImpl)cache)\n-              .createVMRegion(regionName, attr, new InternalRegionArguments()\n-                  .setInternalMetaRegion(distRegion).setDestroyLockFlag(true)\n-                  .setSnapshotInputStream(null).setImageTarget(null));\n-          assertTrue(\"Local Region is null\", region != null);\n+  @SuppressWarnings(\"deprecation\")\n+  private void createCacheForVM1() {\n+    try {\n+      distributedSystem = (new Bug37377DUnitTest())\n+          .getSystem(props);\n+      assertTrue(distributedSystem != null);\n+      cache = CacheFactory.create(distributedSystem);\n+      assertTrue(\"cache found null\", cache != null);\n+\n+      AttributesFactory factory = new AttributesFactory();\n+      factory.setScope(Scope.DISTRIBUTED_ACK);\n+      factory.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);\n+      factory.setDiskSynchronous(false);\n+      factory.setDiskStoreName(cache.createDiskStoreFactory()\n+          .setDiskDirs(dirs)\n+          .create(\"Bug37377DUnitTest\")\n+          .getName());\n+      RegionAttributes attr = factory.create();\n+      DistributedRegion distRegion = new DistributedRegion(regionName,\n+          attr, null, (GemFireCacheImpl)cache, new InternalRegionArguments()\n+          .setDestroyLockFlag(true).setRecreateFlag(false)\n+          .setSnapshotInputStream(null).setImageTarget(null));\n+      //      assertTrue(\"Distributed Region is null\", distRegion != null); (cannot be null)\n+\n+      TestAbstractDiskRegionEntry.setMembers(vm1, vm0);    // vm1 is thisVM, vm0 is otherVM\n+\n+      ((AbstractRegionMap)distRegion.entries)\n+      .setEntryFactory(TestAbstractDiskRegionEntry.getEntryFactory());\n+\n+      LocalRegion region = (LocalRegion)((GemFireCacheImpl)cache)\n+          .createVMRegion(regionName, attr, new InternalRegionArguments()\n+              .setInternalMetaRegion(distRegion).setDestroyLockFlag(true)\n+              .setSnapshotInputStream(null).setImageTarget(null));\n+      assertTrue(\"Local Region is null\", region != null);\n \n-        }\n-        catch (Exception ex) {\n-          ex.printStackTrace();\n-          fail(\"Error Creating cache / region \" + ex);\n-        }\n-      }\n-    };\n-    return (CacheSerializableRunnable)createCache;\n+    }\n+    catch (Exception ex) {\n+      ex.printStackTrace();\n+      fail(\"Error Creating cache / region \" + ex);\n+    }  \n   }\n \n   /**\n    * This method puts in maxEntries in the Region\n-   * \n-   * @return CacheSerializableRunnable\n    */\n-  private CacheSerializableRunnable putSomeEntries()\n-  {\n-    SerializableRunnable puts = new CacheSerializableRunnable(\"putSomeEntries\") {\n-      public void run2()\n-      {\n-        assertTrue(\"Cache is found as null \", cache != null);\n-        Region rgn = cache.getRegion(regionName);\n-        for (int i = 0; i < maxEntries; i++) {\n-          rgn.put(new Long(i), new Long(i));\n-        }\n-      }\n-    };\n-    return (CacheSerializableRunnable)puts;\n+  private void putSomeEntries() {\n+    assertTrue(\"Cache is found as null \", cache != null);\n+    Region rgn = cache.getRegion(regionName);\n+    for (int i = 0; i < maxEntries; i++) {\n+      rgn.put(new Long(i), new Long(i));\n+    }\n   }\n \n   /**\n-   * This method destroys the Region\n+   * This method clears the region and \n+   * notifies the other member when complete\n    * \n-   * @return CacheSerializableRunnable\n+   * @throws InterruptedException \n    */\n-  private CacheSerializableRunnable destroyRegion()\n-  {\n-    SerializableRunnable puts = new CacheSerializableRunnable(\"destroyRegion\") {\n-      public void run2()\n-      {\n-        try {\n-          assertTrue(\"Cache is found as null \", cache != null);\n-\n-          Region rgn = cache.getRegion(regionName);\n-          rgn.localDestroyRegion();\n-          cache.close();\n-        }\n-        catch (Exception ex) {\n-\n-        }\n-      }\n-    };\n-    return (CacheSerializableRunnable)puts;\n+  private static void invokeRemoteClearAndWait(VM remoteVM, VM thisVM) {\n+    remoteVM.invoke(() -> clearRegionAndNotify(thisVM));\n+    try {\n+      clearLatch.await();\n+    } catch (InterruptedException e) {\n+      fail(\"wait for remote clear to complete failed\");\n+    }\n   }\n \n   /**\n-   * This method is used to close cache on the calling VM\n-   * \n-   * @return CacheSerializableRunnable\n+   * This method clears the region and \n+   * notifies the other member when complete\n    */\n-  private CacheSerializableRunnable closeCacheForVM(final int vmNo)\n-  {\n-    SerializableRunnable cclose = new CacheSerializableRunnable(\n-        \"closeCacheForVM\") {\n-      public void run2()\n-      {\n-        if (vmNo == 0) {\n-          cache.getRegion(regionName).localDestroyRegion();\n-        }\n-        assertTrue(\"Cache is found as null \", cache != null);\n-        cache.close();\n-      }\n-    };\n-    return (CacheSerializableRunnable)cclose;\n+  private static void clearRegionAndNotify(VM otherVM) {\n+    assertTrue(\"Cache is found as null \", cache != null);\n+    Region rgn = cache.getRegion(regionName);\n+    rgn.clear();\n+    otherVM.invoke(() -> notifyClearComplete());\n   }\n \n   /**\n-   * This method is used to close cache on the calling VM\n-   * \n-   * @return CacheSerializableRunnable\n+   * Decrement countdown latch to notify clear complete \n    */\n-  private CacheSerializableRunnable closeCacheInVM()\n-  {\n-    SerializableRunnable cclose = new CacheSerializableRunnable(\n-        \"closeCacheInVM\") {\n-      public void run2()\n-      {\n-\n-        cache.getRegion(regionName).localDestroyRegion();\n-        assertTrue(\"Cache is found as null \", cache != null);\n-        cache.close();\n-      }\n-    };\n-    return (CacheSerializableRunnable)cclose;\n+  private static void notifyClearComplete() {\n+    clearLatch.countDown();\n   }\n \n   /**\n-   * This method verifies that the reintialized region size should be zero\n-   * \n-   * @return CacheSerializableRunnable\n+   * This method destroys the Region\n    */\n-  private CacheSerializableRunnable verifyExtraEntryFromOpLogs()\n-  {\n-    SerializableRunnable verify = new CacheSerializableRunnable(\n-        \"verifyExtraEntryFromOpLogs\") {\n-      public void run2()\n-      {\n-        assertTrue(\"Cache is found as null \", cache != null);\n-        Region rgn = cache.getRegion(regionName);\n-        // should be zero after reinit\n-        assertEquals(0, rgn.size());\n-      }\n-    };\n-    return (CacheSerializableRunnable)verify;\n+  private void destroyRegion() {\n+    try {\n+      assertTrue(\"Cache is found as null \", cache != null);\n+      Region rgn = cache.getRegion(regionName);\n+      rgn.localDestroyRegion();\n+      cache.close();\n+    }\n+    catch (Exception ex) {}\n+  }\n \n+  /**\n+   * This method closes the cache on the specified VM\n+   */\n+  private void closeCacheForVM(final int vmNo) {\n+    if (vmNo == 0) {\n+      cache.getRegion(regionName).localDestroyRegion();\n+    }\n+    assertTrue(\"Cache is found as null \", cache != null);\n+    cache.close();\n+  }\n+ \n+  /**\n+   * This method verifies that the reintialized region size is zero\n+   */\n+  private void verifyExtraEntryFromOpLogs() {\n+    assertTrue(\"Cache is found as null \", cache != null);\n+    Region rgn = cache.getRegion(regionName);\n+    // should be zero after clear\n+    assertEquals(0, rgn.size());\n   }\n \n   /**\n@@ -309,44 +256,45 @@ public void run2()\n    */\n \n   @Test\n-  public void testGIIputWithClear()\n-  {\n-    vm0.invoke(createCacheForVM0());\n-    vm0.invoke(putSomeEntries());\n-    AsyncInvocation as1 = vm1.invokeAsync(createCacheForVM1());\n-    Wait.pause(10000);\n-    ThreadUtils.join(as1, 30 * 1000);\n-    vm0.invoke(closeCacheForVM(0));\n-    vm1.invoke(closeCacheForVM(1));\n-    vm1.invoke(createCacheForVM1());\n-    vm1.invoke(verifyExtraEntryFromOpLogs());\n+  public void testGIIputWithClear() {\n+    vm0.invoke(() -> createCacheForVM0());\n+    vm0.invoke(() -> putSomeEntries());\n+\n+    vm1.invoke(() -> createCacheForVM1());\n+\n+    vm0.invoke(() -> closeCacheForVM(0));\n+    vm1.invoke(() -> closeCacheForVM(1));\n+\n+    vm1.invoke(() -> createCacheForVM1());\n+    vm1.invoke(() -> verifyExtraEntryFromOpLogs());\n   }\n \n-  static class TestAbstractDiskRegionEntry extends VMThinDiskRegionEntryHeapObjectKey\n-  {\n-    protected TestAbstractDiskRegionEntry(RegionEntryContext r, Object key,\n-        Object value) {\n+  static class TestAbstractDiskRegionEntry extends VersionedThinDiskRegionEntryHeapObjectKey {\n+    static private VM thisVM, otherVM;\n+\n+    static void setMembers(VM localVM, VM remoteVM) {\n+      thisVM = localVM;\n+      otherVM = remoteVM;\n+    }\n+\n+    protected TestAbstractDiskRegionEntry(RegionEntryContext r, Object key, Object value) {\n       super(r, key, value);\n     }\n-    \n-    private static RegionEntryFactory factory = new RegionEntryFactory() {\n-      public final RegionEntry createEntry(RegionEntryContext r, Object key,\n-          Object value)\n-      {\n \n+    private static RegionEntryFactory factory = new RegionEntryFactory() {\n+      \n+      public final RegionEntry createEntry(RegionEntryContext r, Object key, Object value) {\n         return new TestAbstractDiskRegionEntry(r, key, value);\n       }\n \n-      public final Class getEntryClass()\n-      {\n-\n+      public final Class getEntryClass() {\n         return TestAbstractDiskRegionEntry.class;\n       }\n \n       public RegionEntryFactory makeVersioned() {\n         return this;\n       }\n-      \n+\n       public RegionEntryFactory makeOnHeap() {\n         return this;\n       }\n@@ -358,24 +306,35 @@ public RegionEntryFactory makeOnHeap() {\n      */\n     @Override\n     public boolean initialImageInit(final LocalRegion r,\n-                                    final long lastModifiedTime,\n-                                    final Object newValue,\n-                                    final boolean create,\n-                                    final boolean wasRecovered,\n-                                    final boolean versionTagAccepted) throws RegionClearedException\n+        final long lastModifiedTime,\n+        final Object newValue,\n+        final boolean create,\n+        final boolean wasRecovered,\n+        final boolean versionTagAccepted) throws RegionClearedException\n     {\n-      RegionEventImpl event = new RegionEventImpl(r, Operation.REGION_CLEAR,\n-                                                  null, true /* isOriginRemote */,\n-                                                  r.cache.getMyId());\n-      ((DistributedRegion)r).cmnClearRegion(event, false, false);\n-      boolean result = super.initialImageInit(r, lastModifiedTime, newValue, create, wasRecovered, versionTagAccepted);\n-      fail(\"expected RegionClearedException\");\n-      return result;\n+      synchronized(clearOccured) {\n+        if(!clearOccured) {\n+          // Force other member to perform a clear during our GII\n+          invokeRemoteClearAndWait(otherVM, thisVM);\n+          clearOccured = true;\n+        }\n+      }\n+\n+      // Continue GII processing, which should throw RegionClearedException after the clear\n+      try {\n+        boolean result = super.initialImageInit(r, lastModifiedTime, newValue, create, wasRecovered, versionTagAccepted);\n+      } catch (RegionClearedException rce) {\n+        throw rce;\n+      } catch (Exception ex) {\n+        fail(\"Caught exception during initialImageInit: \" + ex );\n+      }\n+\n+      return true;\n     }\n \n-    public static RegionEntryFactory getEntryFactory()\n-    {\n+    public static RegionEntryFactory getEntryFactory() {\n       return factory;\n     }\n   }\n }\n+",
                "raw_url": "https://github.com/apache/geode/raw/8a644c25de9c4bc5a413de96dfac88451fda7fc8/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/Bug37377DUnitTest.java",
                "sha": "35e9caffdb1cfb66dfc0b439439a38995c85ad97",
                "status": "modified"
            }
        ],
        "message": "GEODE-1818: fix NPE in Bug37377DUnitTest\n\nThis closes #235",
        "parent": "https://github.com/apache/geode/commit/ea5516c53fa124da7ff7ee91f69d52e78949bbfd",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "Bug37377DUnitTest.java"
        ]
    },
    "geode_92ced79": {
        "bug_id": "geode_92ced79",
        "commit": "https://github.com/apache/geode/commit/92ced7912800128c078bccc65ad7476cc25cacee",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 8,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "patch": "@@ -28,7 +28,7 @@\n   private String url;\n   private String user;\n   private String password;\n-  private Map<String, String> parameters = new HashMap<>();\n+  private Map<String, String> parameters;\n \n   public ConnectionConfigBuilder withName(String name) {\n     this.name = name;\n@@ -51,25 +51,26 @@ public ConnectionConfigBuilder withPassword(String password) {\n   }\n \n   public ConnectionConfigBuilder withParameters(String[] params) {\n-    if (params == null) {\n-      parameters = null;\n-    } else {\n+    if (params != null) {\n+      parameters = new HashMap<>();\n       for (String param : params) {\n         if (param.isEmpty()) {\n           continue;\n         }\n         String[] keyValuePair = param.split(PARAMS_DELIMITER);\n         validateParam(keyValuePair, param);\n-        if (keyValuePair.length == 2) {\n-          parameters.put(keyValuePair[0], keyValuePair[1]);\n-        }\n+        parameters.put(keyValuePair[0], keyValuePair[1]);\n       }\n+    } else {\n+      parameters = null;\n     }\n     return this;\n   }\n \n   private void validateParam(String[] paramKeyValue, String param) {\n-    if ((paramKeyValue.length <= 1) || paramKeyValue[0].isEmpty() || paramKeyValue[1].isEmpty()) {\n+    // paramKeyValue is produced by split which will never give us\n+    // an empty second element\n+    if ((paramKeyValue.length != 2) || paramKeyValue[0].isEmpty()) {\n       throw new IllegalArgumentException(\"Parameter '\" + param\n           + \"' is not of the form 'parameterName\" + PARAMS_DELIMITER + \"value'\");\n     }",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilder.java",
                "sha": "4ab2b7f4799c2ff5bc516099d4bb71c99449b4f9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 3,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "patch": "@@ -23,9 +23,6 @@\n \n @Experimental\n public class ConnectionConfiguration implements Serializable {\n-  private static final Object USER = \"user\";\n-  private static final Object PASSWORD = \"password\";\n-\n   private final String name;\n   private final String url;\n   private final String user;",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfiguration.java",
                "sha": "c80e1460966c5a35300a4dc5527018a2e6b6d599",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 9,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "patch": "@@ -50,14 +50,15 @@ public RegionMappingBuilder withConnectionConfigName(String connectionConfigName\n     return this;\n   }\n \n-  // TODO: delete withPrimaryKeyInValue(String)\n-  public RegionMappingBuilder withPrimaryKeyInValue(String primaryKeyInValue) {\n-    this.primaryKeyInValue = Boolean.parseBoolean(primaryKeyInValue);\n+  public RegionMappingBuilder withPrimaryKeyInValue(String v) {\n+    if (v != null) {\n+      withPrimaryKeyInValue(Boolean.parseBoolean(v));\n+    }\n     return this;\n   }\n \n-  public RegionMappingBuilder withPrimaryKeyInValue(Boolean primaryKeyInValue) {\n-    this.primaryKeyInValue = primaryKeyInValue;\n+  public RegionMappingBuilder withPrimaryKeyInValue(Boolean v) {\n+    this.primaryKeyInValue = v;\n     return this;\n   }\n \n@@ -76,16 +77,16 @@ public RegionMappingBuilder withFieldToColumnMappings(String[] mappings) {\n         }\n         String[] keyValuePair = mapping.split(MAPPINGS_DELIMITER);\n         validateParam(keyValuePair, mapping);\n-        if (keyValuePair.length == 2) {\n-          fieldToColumnMap.put(keyValuePair[0], keyValuePair[1]);\n-        }\n+        fieldToColumnMap.put(keyValuePair[0], keyValuePair[1]);\n       }\n     }\n     return this;\n   }\n \n   private void validateParam(String[] paramKeyValue, String mapping) {\n-    if (paramKeyValue.length <= 1 || paramKeyValue[0].isEmpty() || paramKeyValue[1].isEmpty()) {\n+    // paramKeyValue is produced by split which will never give us\n+    // an empty second element\n+    if (paramKeyValue.length != 2 || paramKeyValue[0].isEmpty()) {\n       throw new IllegalArgumentException(\"Field to column mapping '\" + mapping\n           + \"' is not of the form 'Field\" + MAPPINGS_DELIMITER + \"Column'\");\n     }",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilder.java",
                "sha": "0d989a48c1cf5efa55b7ae383db8ac7e45f811b0",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 4,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "patch": "@@ -103,9 +103,11 @@ private void fillResultData(ConnectionConfiguration config, CompositeResultData\n     }\n     TabularResultData tabularResultData = sectionResult.addTable(CREATE_CONNECTION__PARAMS);\n     tabularResultData.setHeader(\"Additional connection parameters:\");\n-    config.getParameters().entrySet().forEach((entry) -> {\n-      tabularResultData.accumulate(\"Param Name\", entry.getKey());\n-      tabularResultData.accumulate(\"Value\", entry.getValue());\n-    });\n+    if (config.getParameters() != null) {\n+      config.getParameters().entrySet().forEach((entry) -> {\n+        tabularResultData.accumulate(\"Param Name\", entry.getKey());\n+        tabularResultData.accumulate(\"Value\", entry.getValue());\n+      });\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommand.java",
                "sha": "3295340cad2b4c5e1016df4c6384296e3191f579",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 9,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "patch": "@@ -51,21 +51,22 @@ void startElement(Stack<Object> stack, Attributes attributes) {\n         throw new CacheXmlException(\n             \"jdbc <connection> elements must occur within <connector-service> elements\");\n       }\n-      ConnectionConfigBuilder connectionConfig = new ConnectionConfigBuilder()\n+      ConnectionConfigBuilder connectionConfigBuilder = new ConnectionConfigBuilder()\n           .withName(attributes.getValue(JdbcConnectorServiceXmlParser.NAME))\n           .withUrl(attributes.getValue(JdbcConnectorServiceXmlParser.URL))\n           .withUser(attributes.getValue(JdbcConnectorServiceXmlParser.USER))\n-          .withPassword(attributes.getValue(JdbcConnectorServiceXmlParser.PASSWORD));\n-      addParameters(connectionConfig,\n-          attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS));\n-      stack.push(connectionConfig);\n+          .withPassword(attributes.getValue(JdbcConnectorServiceXmlParser.PASSWORD))\n+          .withParameters(parseParameters(attributes));\n+      stack.push(connectionConfigBuilder);\n     }\n \n-    private void addParameters(ConnectionConfigBuilder connectionConfig, String value) {\n-      if (value == null) {\n-        return;\n+    private String[] parseParameters(Attributes attributes) {\n+      String[] result = null;\n+      String value = attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS);\n+      if (value != null) {\n+        result = value.split(\",\");\n       }\n-      connectionConfig.withParameters(value.split(\",\"));\n+      return result;\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/ElementType.java",
                "sha": "716e15f32a0c6c8796b76368ed950f14d4d80836",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 18,
                "filename": "geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "patch": "@@ -102,9 +102,15 @@ private void outputConnectionConfiguration(ContentHandler handler, ConnectionCon\n     AttributesImpl attributes = new AttributesImpl();\n     XmlGeneratorUtils.addAttribute(attributes, NAME, config.getName());\n     XmlGeneratorUtils.addAttribute(attributes, URL, config.getUrl());\n-    XmlGeneratorUtils.addAttribute(attributes, USER, config.getUser());\n-    XmlGeneratorUtils.addAttribute(attributes, PASSWORD, config.getPassword());\n-    XmlGeneratorUtils.addAttribute(attributes, PARAMETERS, createParametersString(config));\n+    if (config.getUser() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, USER, config.getUser());\n+    }\n+    if (config.getPassword() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PASSWORD, config.getPassword());\n+    }\n+    if (config.getParameters() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PARAMETERS, createParametersString(config));\n+    }\n     XmlGeneratorUtils.emptyElement(handler, PREFIX, ElementType.CONNECTION.getTypeName(),\n         attributes);\n   }\n@@ -114,17 +120,23 @@ private void outputRegionMapping(ContentHandler handler, RegionMapping mapping)\n     AttributesImpl attributes = new AttributesImpl();\n     XmlGeneratorUtils.addAttribute(attributes, CONNECTION_NAME, mapping.getConnectionConfigName());\n     XmlGeneratorUtils.addAttribute(attributes, REGION, mapping.getRegionName());\n-    XmlGeneratorUtils.addAttribute(attributes, TABLE, mapping.getTableName());\n-    XmlGeneratorUtils.addAttribute(attributes, PDX_CLASS, mapping.getPdxClassName());\n-    XmlGeneratorUtils.addAttribute(attributes, PRIMARY_KEY_IN_VALUE,\n-        Boolean.toString(mapping.isPrimaryKeyInValue()));\n+    if (mapping.getTableName() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, TABLE, mapping.getTableName());\n+    }\n+    if (mapping.getPdxClassName() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PDX_CLASS, mapping.getPdxClassName());\n+    }\n+    if (mapping.isPrimaryKeyInValue() != null) {\n+      XmlGeneratorUtils.addAttribute(attributes, PRIMARY_KEY_IN_VALUE,\n+          Boolean.toString(mapping.isPrimaryKeyInValue()));\n+    }\n \n-    XmlGeneratorUtils.startElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName(),\n-        attributes);\n     if (mapping.getFieldToColumnMap() != null) {\n+      XmlGeneratorUtils.startElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName(),\n+          attributes);\n       addFieldMappings(handler, mapping.getFieldToColumnMap());\n+      XmlGeneratorUtils.endElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName());\n     }\n-    XmlGeneratorUtils.endElement(handler, PREFIX, ElementType.REGION_MAPPING.getTypeName());\n   }\n \n   private void addFieldMappings(ContentHandler handler, Map<String, String> fieldMappings)\n@@ -139,16 +151,13 @@ private void addFieldMappings(ContentHandler handler, Map<String, String> fieldM\n   }\n \n   private String createParametersString(ConnectionConfiguration config) {\n-    Properties properties = config.getConnectionProperties();\n+    assert config.getParameters() != null;\n     StringBuilder stringBuilder = new StringBuilder();\n-    for (Map.Entry<Object, Object> entry : properties.entrySet()) {\n-      Object key = entry.getKey();\n-      if (!key.equals(USER) && !key.equals(PASSWORD)) {\n-        if (stringBuilder.length() > 0) {\n-          stringBuilder.append(\",\");\n-        }\n-        stringBuilder.append(key).append(PARAMS_DELIMITER).append(entry.getValue());\n+    for (Map.Entry<String, String> entry : config.getParameters().entrySet()) {\n+      if (stringBuilder.length() > 0) {\n+        stringBuilder.append(\",\");\n       }\n+      stringBuilder.append(entry.getKey()).append(PARAMS_DELIMITER).append(entry.getValue());\n     }\n     return stringBuilder.toString();\n   }",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/main/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGenerator.java",
                "sha": "70f9540ea41e568a70bd3b4ad8caa7c26e7be464",
                "status": "modified"
            },
            {
                "additions": 27,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 1,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "patch": "@@ -12,7 +12,7 @@\n  * or implied. See the License for the specific language governing permissions and limitations under\n  * the License.\n  */\n-package org.apache.geode.connectors.jdbc.internal.xml;\n+package org.apache.geode.connectors.jdbc.internal;\n \n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n@@ -51,6 +51,30 @@ public void createsObjectWithCorrectValues() {\n         .containsEntry(\"param2\", \"value2\");\n   }\n \n+  @Test\n+  public void createsObjectWithEmptyParameterElement() {\n+    ConnectionConfiguration config = new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\")\n+        .withUser(\"user\").withPassword(\"password\")\n+        .withParameters(new String[] {\"param1:value1\", \"\", \"param2:value2\"}).build();\n+\n+    assertThat(config.getName()).isEqualTo(\"name\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getUser()).isEqualTo(\"user\");\n+    assertThat(config.getPassword()).isEqualTo(\"password\");\n+    assertThat(config.getConnectionProperties()).containsEntry(\"param1\", \"value1\")\n+        .containsEntry(\"param2\", \"value2\");\n+  }\n+\n+  @Test\n+  public void createsObjectWithNullParameters() {\n+    ConnectionConfiguration config =\n+        new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\").withParameters(null).build();\n+\n+    assertThat(config.getName()).isEqualTo(\"name\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getParameters()).isNull();\n+  }\n+\n   @Test\n   public void throwsExceptionWithInvalidParams() {\n     ConnectionConfigBuilder config = new ConnectionConfigBuilder();\n@@ -60,6 +84,8 @@ public void throwsExceptionWithInvalidParams() {\n         .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(() -> config.withParameters(new String[] {\"param1value1:\"}))\n         .isInstanceOf(IllegalArgumentException.class);\n+    assertThatThrownBy(() -> config.withParameters(new String[] {\"1:2:3\"}))\n+        .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(() -> config.withParameters(new String[] {\":\"}))\n         .isInstanceOf(IllegalArgumentException.class);\n   }",
                "previous_filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ConnectionConfigBuilderTest.java",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/ConnectionConfigBuilderTest.java",
                "sha": "4e4b18ca685ccf9cffd86e95fe7ebbe5c9491e93",
                "status": "renamed"
            },
            {
                "additions": 34,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 1,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "patch": "@@ -12,7 +12,7 @@\n  * or implied. See the License for the specific language governing permissions and limitations under\n  * the License.\n  */\n-package org.apache.geode.connectors.jdbc.internal.xml;\n+package org.apache.geode.connectors.jdbc.internal;\n \n import static org.assertj.core.api.Assertions.assertThat;\n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n@@ -53,6 +53,26 @@ public void createsMappingWithSpecifiedValues() {\n     assertThat(regionMapping.getColumnNameForField(\"fieldName\")).isEqualTo(\"columnName\");\n   }\n \n+  @Test\n+  public void createsMappingWithNullAsPrimaryKeyInValue() {\n+    RegionMapping regionMapping = new RegionMappingBuilder().withRegionName(\"regionName\")\n+        .withConnectionConfigName(\"configName\").withPrimaryKeyInValue((String) null).build();\n+\n+    assertThat(regionMapping.getRegionName()).isEqualTo(\"regionName\");\n+    assertThat(regionMapping.getConnectionConfigName()).isEqualTo(\"configName\");\n+    assertThat(regionMapping.isPrimaryKeyInValue()).isNull();\n+  }\n+\n+  @Test\n+  public void createsMappingWithNullFieldToColumnMappings() {\n+    RegionMapping regionMapping = new RegionMappingBuilder().withRegionName(\"regionName\")\n+        .withConnectionConfigName(\"configName\").withFieldToColumnMappings(null).build();\n+\n+    assertThat(regionMapping.getRegionName()).isEqualTo(\"regionName\");\n+    assertThat(regionMapping.getConnectionConfigName()).isEqualTo(\"configName\");\n+    assertThat(regionMapping.getFieldToColumnMap()).isNull();\n+  }\n+\n   @Test\n   public void createsFieldMappingsFromArray() {\n     String[] fieldMappings = new String[] {\"field1:column1\", \"field2:column2\"};\n@@ -63,6 +83,16 @@ public void createsFieldMappingsFromArray() {\n     assertThat(regionMapping.getColumnNameForField(\"field2\")).isEqualTo(\"column2\");\n   }\n \n+  @Test\n+  public void createsFieldMappingsFromArrayWithEmptyElement() {\n+    String[] fieldMappings = new String[] {\"field1:column1\", \"\", \"field2:column2\"};\n+    RegionMapping regionMapping =\n+        new RegionMappingBuilder().withFieldToColumnMappings(fieldMappings).build();\n+\n+    assertThat(regionMapping.getColumnNameForField(\"field1\")).isEqualTo(\"column1\");\n+    assertThat(regionMapping.getColumnNameForField(\"field2\")).isEqualTo(\"column2\");\n+  }\n+\n   @Test\n   public void throwsExceptionForInvalidFieldMappings() {\n     RegionMappingBuilder regionMappingbuilder = new RegionMappingBuilder();\n@@ -73,6 +103,9 @@ public void throwsExceptionForInvalidFieldMappings() {\n     assertThatThrownBy(\n         () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\":field1column1\"}))\n             .isInstanceOf(IllegalArgumentException.class);\n+    assertThatThrownBy(\n+        () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\"field1:column1:extra\"}))\n+            .isInstanceOf(IllegalArgumentException.class);\n     assertThatThrownBy(\n         () -> regionMappingbuilder.withFieldToColumnMappings(new String[] {\"field1column1:\"}))\n             .isInstanceOf(IllegalArgumentException.class);",
                "previous_filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/RegionMappingBuilderTest.java",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/RegionMappingBuilderTest.java",
                "sha": "5abfd74796ca905199f0023b45726f5849febb50",
                "status": "renamed"
            },
            {
                "additions": 24,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "patch": "@@ -106,6 +106,30 @@ public void displaysConnectionInformationWhenConfigurationExists() throws Except\n \n   }\n \n+  @Test\n+  public void displaysConnectionInformationForConfigurationWithNullParameters() throws Exception {\n+    connectionConfig = new ConnectionConfigBuilder().withName(CONNECTION).withUrl(\"myUrl\")\n+        .withParameters(null).build();\n+    service.createConnectionConfig(connectionConfig);\n+    Result result = command.describeConnection(CONNECTION);\n+\n+    assertThat(result.getStatus()).isSameAs(Result.Status.OK);\n+    CommandResult commandResult = (CommandResult) result;\n+    GfJsonObject sectionContent = commandResult.getTableContent()\n+        .getJSONObject(SECTION_DATA_ACCESSOR + \"-\" + RESULT_SECTION_NAME);\n+\n+    assertThat(sectionContent.get(CREATE_CONNECTION__NAME)).isEqualTo(connectionConfig.getName());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__URL)).isEqualTo(connectionConfig.getUrl());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__USER)).isEqualTo(connectionConfig.getUser());\n+    assertThat(sectionContent.get(CREATE_CONNECTION__PASSWORD)).isEqualTo(null);\n+\n+    GfJsonObject tableContent =\n+        sectionContent.getJSONObject(TABLE_DATA_ACCESSOR + \"-\" + CREATE_CONNECTION__PARAMS)\n+            .getJSONObject(\"content\");\n+    assertThat(tableContent.get(\"Param Name\")).isNull();\n+    assertThat(tableContent.get(\"Value\")).isNull();\n+  }\n+\n   @Test\n   public void doesNotDisplayParametersWithNoValue() throws Exception {\n     connectionConfig = new ConnectionConfigBuilder().withName(CONNECTION).withUrl(\"myUrl\").build();",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/cli/DescribeConnectionCommandIntegrationTest.java",
                "sha": "84e93c371b0d902686c3ebb960550828456ba9cb",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "patch": "@@ -34,6 +34,8 @@\n import static org.mockito.Mockito.verifyZeroInteractions;\n import static org.mockito.Mockito.when;\n \n+import java.util.HashMap;\n+import java.util.Map;\n import java.util.Stack;\n \n import org.junit.Before;\n@@ -136,6 +138,29 @@ public void startElementConnection() {\n     assertThat(config.getUrl()).isEqualTo(\"url\");\n     assertThat(config.getUser()).isEqualTo(\"username\");\n     assertThat(config.getPassword()).isEqualTo(\"secret\");\n+    assertThat(config.getParameters()).isNull();\n+  }\n+\n+  @Test\n+  public void startElementConnectionWithParameters() {\n+    JdbcServiceConfiguration serviceConfiguration = mock(JdbcServiceConfiguration.class);\n+    stack.push(serviceConfiguration);\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.NAME)).thenReturn(\"connectionName\");\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.URL)).thenReturn(\"url\");\n+    when(attributes.getValue(JdbcConnectorServiceXmlParser.PARAMETERS))\n+        .thenReturn(\"key1:value1,key2:value2\");\n+\n+    CONNECTION.startElement(stack, attributes);\n+\n+    ConnectionConfiguration config = ((ConnectionConfigBuilder) stack.pop()).build();\n+    assertThat(config.getName()).isEqualTo(\"connectionName\");\n+    assertThat(config.getUrl()).isEqualTo(\"url\");\n+    assertThat(config.getUser()).isNull();\n+    assertThat(config.getPassword()).isNull();\n+    Map<String, String> expectedParams = new HashMap<>();\n+    expectedParams.put(\"key1\", \"value1\");\n+    expectedParams.put(\"key2\", \"value2\");\n+    assertThat(config.getParameters()).isEqualTo(expectedParams);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/ElementTypeTest.java",
                "sha": "7612527747b14d465cf4ac2f302a29a032d50b6e",
                "status": "modified"
            },
            {
                "additions": 43,
                "blob_url": "https://github.com/apache/geode/blob/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "changes": 43,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java?ref=92ced7912800128c078bccc65ad7476cc25cacee",
                "deletions": 0,
                "filename": "geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "patch": "@@ -174,6 +174,35 @@ public void generatedXmlWithConnectionConfigurationCanBeParsed() throws Exceptio\n     assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n   }\n \n+  @Test\n+  public void generatedXmlWithConnectionConfigurationWithNoUserNameAndPasswordCanBeParsed()\n+      throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    ConnectionConfiguration config =\n+        new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\").build();\n+    service.createConnectionConfig(config);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n+  }\n+\n+  @Test\n+  public void generatedXmlWithConnectionConfigurationWithParametersCanBeParsed() throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    ConnectionConfiguration config = new ConnectionConfigBuilder().withName(\"name\").withUrl(\"url\")\n+        .withParameters(new String[] {\"key1:value1\", \"key2:value2\"}).build();\n+    service.createConnectionConfig(config);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getConnectionConfig(\"name\")).isEqualTo(config);\n+  }\n+\n   @Test\n   public void generatedXmlWithRegionMappingCanBeParsed() throws Exception {\n     JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n@@ -190,6 +219,20 @@ public void generatedXmlWithRegionMappingCanBeParsed() throws Exception {\n     assertThat(service.getMappingForRegion(\"region\")).isEqualTo(mapping);\n   }\n \n+  @Test\n+  public void generatedXmlWithRegionMappingWithNoOptionalParametersCanBeParsed() throws Exception {\n+    JdbcConnectorService service = cache.getService(JdbcConnectorService.class);\n+    RegionMapping mapping = new RegionMappingBuilder().withRegionName(\"region\")\n+        .withConnectionConfigName(\"connection\").build();\n+    service.createRegionMapping(mapping);\n+    generateXml();\n+    cache.close();\n+\n+    createCacheUsingXml();\n+    service = cache.getService(JdbcConnectorService.class);\n+    assertThat(service.getMappingForRegion(\"region\")).isEqualTo(mapping);\n+  }\n+\n   @Test\n   public void generatedXmlWithEverythingCanBeParsed() throws Exception {\n     JdbcConnectorService service = cache.getService(JdbcConnectorService.class);",
                "raw_url": "https://github.com/apache/geode/raw/92ced7912800128c078bccc65ad7476cc25cacee/geode-connectors/src/test/java/org/apache/geode/connectors/jdbc/internal/xml/JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
                "sha": "1ba728f44121293971332b18c74e1278c85a2365",
                "status": "modified"
            }
        ],
        "message": "GEODE-4160: fix gfsh describe jdbc-connection (#1223)\n\n* GEODE-4160: fix gfsh describe jdbc-connection\r\n\r\nIf the connection had no parameters set, then running\r\ngfsh describe jdbc-connection would fail with an NPE.",
        "parent": "https://github.com/apache/geode/commit/78438f8586610f084c3eec462bc69abe05e1e1b7",
        "patched_files": [
            "RegionMappingBuilder.java",
            "DescribeConnectionCommand.java",
            "JdbcConnectorServiceXmlGenerator.java",
            "ElementType.java",
            "ConnectionConfiguration.java",
            "ConnectionConfigBuilder.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "RegionMappingBuilderTest.java",
            "ConnectionConfigBuilderTest.java",
            "ConnectionConfigurationTest.java",
            "JdbcConnectorServiceXmlGeneratorIntegrationTest.java",
            "JdbcConnectorServiceXmlGeneratorTest.java",
            "DescribeConnectionCommandIntegrationTest.java",
            "ElementTypeTest.java"
        ]
    },
    "geode_9934558": {
        "bug_id": "geode_9934558",
        "commit": "https://github.com/apache/geode/commit/99345585e2a746eba35ceedad5790fe9bd25bc5f",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/99345585e2a746eba35ceedad5790fe9bd25bc5f/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java?ref=99345585e2a746eba35ceedad5790fe9bd25bc5f",
                "deletions": 5,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "patch": "@@ -334,18 +334,15 @@ void removeMemberArtifacts(DistributedMember member, boolean crashed) {\n \n     // If cache is closed all the regions would have been destroyed implicitly\n     if (!cache.isClosed()) {\n-      try {\n-        proxyFactory.removeAllProxies(member, monitoringRegion);\n-      } catch (CancelException | RegionDestroyedException ignore) {\n-        // ignored\n-      }\n       try {\n         if (monitoringRegion != null) {\n+          proxyFactory.removeAllProxies(member, monitoringRegion);\n           monitoringRegion.localDestroyRegion();\n         }\n       } catch (CancelException | RegionDestroyedException ignore) {\n         // ignored\n       }\n+\n       try {\n         if (notificationRegion != null) {\n           notificationRegion.localDestroyRegion();",
                "raw_url": "https://github.com/apache/geode/raw/99345585e2a746eba35ceedad5790fe9bd25bc5f/geode-core/src/main/java/org/apache/geode/management/internal/FederatingManager.java",
                "sha": "bc3fe34286192522e75f2e8289add4c2fa9320ed",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/99345585e2a746eba35ceedad5790fe9bd25bc5f/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java?ref=99345585e2a746eba35ceedad5790fe9bd25bc5f",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "patch": "@@ -21,6 +21,7 @@\n import static org.mockito.Mockito.doThrow;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyZeroInteractions;\n import static org.powermock.api.mockito.PowerMockito.when;\n \n import java.net.InetAddress;\n@@ -429,6 +430,23 @@ public void startManagerGetsNewExecutorServiceFromSupplier() {\n     verify(executorServiceSupplier).get();\n   }\n \n+  @Test\n+  public void removeMemberArtifactsDoesNotRemoveAllProxiesIfMonitoringRegionIsNull() {\n+    InternalDistributedMember member = member();\n+    when(repo.getEntryFromMonitoringRegionMap(eq(member)))\n+        .thenReturn(null);\n+    when(repo.getEntryFromNotifRegionMap(eq(member)))\n+        .thenReturn(mock(Region.class));\n+    when(system.getDistributedMember())\n+        .thenReturn(member);\n+    FederatingManager federatingManager = new FederatingManager(repo, system, service, cache,\n+        statisticsFactory, statisticsClock, proxyFactory, messenger, executorService);\n+\n+    federatingManager.removeMemberArtifacts(member, false);\n+\n+    verifyZeroInteractions(proxyFactory);\n+  }\n+\n   private InternalDistributedMember member() {\n     return member(1, 1);\n   }",
                "raw_url": "https://github.com/apache/geode/raw/99345585e2a746eba35ceedad5790fe9bd25bc5f/geode-core/src/test/java/org/apache/geode/management/internal/FederatingManagerTest.java",
                "sha": "e6f960165937c3ebe963c9ee97453fe69bfa348e",
                "status": "modified"
            }
        ],
        "message": "GEODE-7525: Prevent NPE in MBeanProxyFactory (#4478)\n\nFederatingManager should not invoke MBeanProxyFactory.removeAllProxies\r\nwhen monitoringRegion is null.",
        "parent": "https://github.com/apache/geode/commit/71871922567c873db0fa00b7d2c95334f10291bb",
        "patched_files": [
            "FederatingManager.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "FederatingManagerTest.java"
        ]
    },
    "geode_9f91611": {
        "bug_id": "geode_9f91611",
        "commit": "https://github.com/apache/geode/commit/9f91611407863e30a0131fc85aa6905b3c886318",
        "file": [
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java?ref=9f91611407863e30a0131fc85aa6905b3c886318",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "patch": "@@ -89,10 +89,21 @@ public Connection getConnection() throws SQLException {\n           loadDriver();\n       }\n     }\n+\n     if (url != null) {\n       Properties props = new Properties();\n-      props.put(\"user\", user);\n-      props.put(\"password\", password);\n+\n+      // If no default username or password is specified don't add these properties - the user may\n+      // be connecting to a system which does not require authentication\n+      if (user != null) {\n+        props.put(\"user\", user);\n+      }\n+\n+      // check for password separately from username - some drivers may throw different error\n+      // messages we want to capture\n+      if (password != null) {\n+        props.put(\"password\", password);\n+      }\n       connection = driverObject.connect(url, props);\n     } else {\n       StringId exception =\n@@ -109,7 +120,6 @@ public Connection getConnection() throws SQLException {\n    *\n    * @param clUsername The username for the database connection.\n    * @param clPassword The password for the database connection.\n-   * @return ???\n    */\n   @Override\n   public Connection getConnection(String clUsername, String clPassword) throws SQLException {",
                "raw_url": "https://github.com/apache/geode/raw/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "sha": "cafa8ae38304b2d78ac5bf71a7cf3df99d452292",
                "status": "modified"
            },
            {
                "additions": 73,
                "blob_url": "https://github.com/apache/geode/blob/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "changes": 73,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java?ref=9f91611407863e30a0131fc85aa6905b3c886318",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "patch": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.internal.datasource;\n+\n+import static org.assertj.core.api.AssertionsForClassTypes.assertThatThrownBy;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+\n+public class GemFireBasicDataSourceJUnitTest {\n+  private GemFireBasicDataSource dataSource;\n+  private Map params = new HashMap();\n+\n+  @Before\n+  public void setUp() {\n+    params.put(\"connection-url\", \"jdbc:postgresql://myurl:5432\");\n+    params.put(\"jdbc-driver-class\", \"org.apache.geode.internal.datasource.TestDriver\");\n+    params.put(\"jndi-name\", \"datasource\");\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    params.clear();\n+  }\n+\n+  @Test\n+  public void connectWithoutUsernameOrPassword() throws DataSourceCreateException {\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+  }\n+\n+  @Test\n+  public void connectWithUsernameButNoPassword() throws DataSourceCreateException {\n+    params.put(\"user-name\", \"myUser\");\n+\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+  }\n+\n+\n+  @Test\n+  public void connectWithPasswordButNoUsername() throws DataSourceCreateException {\n+    params.put(\"password\", \"myPassword\");\n+\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "sha": "d7d7d5d22f2341d0ecbac786fdb19961a223f6c3",
                "status": "added"
            },
            {
                "additions": 62,
                "blob_url": "https://github.com/apache/geode/blob/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "changes": 62,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java?ref=9f91611407863e30a0131fc85aa6905b3c886318",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "patch": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.internal.datasource;\n+\n+import java.sql.Connection;\n+import java.sql.Driver;\n+import java.sql.DriverPropertyInfo;\n+import java.sql.SQLException;\n+import java.sql.SQLFeatureNotSupportedException;\n+import java.util.Properties;\n+import java.util.logging.Logger;\n+\n+public class TestDriver implements Driver {\n+\n+  @Override\n+  public Connection connect(String url, Properties info) throws SQLException {\n+    throw new SQLException(\"Test Driver Connection attempted!\");\n+  }\n+\n+  @Override\n+  public boolean acceptsURL(String url) throws SQLException {\n+    return false;\n+  }\n+\n+  @Override\n+  public DriverPropertyInfo[] getPropertyInfo(String url, Properties info) throws SQLException {\n+    return new DriverPropertyInfo[0];\n+  }\n+\n+  @Override\n+  public int getMajorVersion() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public int getMinorVersion() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public boolean jdbcCompliant() {\n+    return false;\n+  }\n+\n+  @Override\n+  public Logger getParentLogger() throws SQLFeatureNotSupportedException {\n+    return null;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/9f91611407863e30a0131fc85aa6905b3c886318/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "sha": "568efa2aca44754b663c9d8b391924fdb255dc13",
                "status": "added"
            }
        ],
        "message": "Merge pull request #2185 from BenjaminPerryRoss/fix-npe-jndi-command-159205020\n\nGEODE-5450: Added protection for NPE in GemFireBasicDataSource with no credentials",
        "parent": "https://github.com/apache/geode/commit/0f765b98b4ea03180e9df6c3415247d377d5eb67",
        "patched_files": [
            "GemFireBasicDataSource.java",
            "Driver.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "TestDriver.java",
            "GemFireBasicDataSourceJUnitTest.java"
        ]
    },
    "geode_9fdcca1": {
        "bug_id": "geode_9fdcca1",
        "commit": "https://github.com/apache/geode/commit/9fdcca129845a1ffa4c935146cdd04aa2af7e4e8",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/9fdcca129845a1ffa4c935146cdd04aa2af7e4e8/geode-core/src/test/java/com/gemstone/gemfire/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java?ref=9fdcca129845a1ffa4c935146cdd04aa2af7e4e8",
                "deletions": 4,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "patch": "@@ -1015,14 +1015,20 @@ public void testPreparedViewFoundDuringBecomeCoordinator() throws Exception {\n \n     Thread.sleep(2000);\n     ViewCreator vc = gmsJoinLeave.getViewCreator();\n-    \n-    ViewAckMessage vack = new ViewAckMessage(gmsJoinLeaveMemberId, gmsJoinLeave.getPreparedView().getViewId(), true);\n+    int viewId = 0;\n+    if (gmsJoinLeave.getPreparedView() == null) {\n+      viewId = gmsJoinLeave.getView().getViewId();\n+    }\n+    else {\n+      viewId = gmsJoinLeave.getPreparedView().getViewId();\n+    }\n+    ViewAckMessage vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n     vack.setSender(mockMembers[0]);\n     gmsJoinLeave.processMessage(vack);\n-    vack = new ViewAckMessage(gmsJoinLeaveMemberId, gmsJoinLeave.getPreparedView().getViewId(), true);\n+    vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n     vack.setSender(mockMembers[1]);\n     gmsJoinLeave.processMessage(vack);\n-    vack = new ViewAckMessage(gmsJoinLeaveMemberId, gmsJoinLeave.getPreparedView().getViewId(), true);\n+    vack = new ViewAckMessage(gmsJoinLeaveMemberId, viewId, true);\n     vack.setSender(gmsJoinLeaveMemberId);\n     gmsJoinLeave.processMessage(vack);\n     ",
                "raw_url": "https://github.com/apache/geode/raw/9fdcca129845a1ffa4c935146cdd04aa2af7e4e8/geode-core/src/test/java/com/gemstone/gemfire/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "sha": "33fa2ea61cce8f63fd8ffa34e9e21ff468b600a6",
                "status": "modified"
            }
        ],
        "message": "GEODE-990 CI Failure GMSJoinLeaveJUnitTest.testPreparedViewFoundDuringBecomeCoordinator\nfailed with NullPointerException",
        "parent": "https://github.com/apache/geode/commit/374d2f435ef5c291ebd3c3a4573110cb1298f290",
        "patched_files": [],
        "repo": "geode",
        "unit_tests": [
            "GMSJoinLeaveJUnitTest.java"
        ]
    },
    "geode_a60b8d4": {
        "bug_id": "geode_a60b8d4",
        "commit": "https://github.com/apache/geode/commit/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/main/java/org/apache/geode/cache/client/internal/ClientSideHandshakeImpl.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/cache/client/internal/ClientSideHandshakeImpl.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/cache/client/internal/ClientSideHandshakeImpl.java",
                "patch": "@@ -340,7 +340,7 @@ public ServerQueueStatus handshakeWithSubscriptionFeed(Socket sock, boolean isPr\n         Integer id = (Integer) dataSerializer.getKey();\n         InternalDataSerializer.register((String) dataSerializer.getValue(), false, null, null, id);\n       }\n-      HashMap<Integer, ArrayList<String>> dsToSupportedClassNames = DataSerializer.readHashMap(dis);\n+      Map<Integer, List<String>> dsToSupportedClassNames = DataSerializer.readHashMap(dis);\n       InternalDataSerializer.updateSupportedClassesMap(dsToSupportedClassNames);\n \n       // the server's ping interval is only sent to subscription feeds so we can't read it as",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/main/java/org/apache/geode/cache/client/internal/ClientSideHandshakeImpl.java",
                "sha": "57a1b26a8556193d91307925da3afb4d68cfcc8a",
                "status": "modified"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/main/java/org/apache/geode/internal/InternalDataSerializer.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/InternalDataSerializer.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/InternalDataSerializer.java",
                "patch": "@@ -828,7 +828,7 @@ public static OldClientSupportService getOldClientSupportService() {\n    *\n    * @see DataSerializer#register(Class)\n    */\n-  private static DataSerializer newInstance(Class c) {\n+  static DataSerializer newInstance(Class c) {\n     if (!DataSerializer.class.isAssignableFrom(c)) {\n       throw new IllegalArgumentException(\n           LocalizedStrings.DataSerializer_0_DOES_NOT_EXTEND_DATASERIALIZER\n@@ -1019,7 +1019,7 @@ public static DataSerializer _register(DataSerializer s, boolean distribute) {\n \n   /**\n    * Marks a {@code DataSerializer} className for registration with the data serialization\n-   * framework. Does not necessarily load the classes into this VM.\n+   * framework if and when it is needed. Does not necessarily load the classes into this VM.\n    *\n    * @param className Name of the DataSerializer class.\n    * @param distribute If true, distribute this data serializer.\n@@ -1073,18 +1073,38 @@ private static void register(String className, boolean distribute,\n     }\n   }\n \n-  public static void updateSupportedClassesMap(HashMap<Integer, ArrayList<String>> map) {\n-    for (Entry<Integer, ArrayList<String>> e : map.entrySet()) {\n+  /**\n+   * During client/server handshakes the server may send a collection of DataSerializers and\n+   * the classes they support. The DataSerializers are registered as \"holders\" to avoid loading the\n+   * actual classes until they're needed. This method registers the names of classes supported\n+   * by the DataSerializers\n+   *\n+   * @param map The classes returned by DataSerializer.supportedClasses()\n+   */\n+  public static void updateSupportedClassesMap(Map<Integer, List<String>> map) {\n+    for (Entry<Integer, List<String>> e : map.entrySet()) {\n       for (String supportedClassName : e.getValue()) {\n-        supportedClassesToHolders.putIfAbsent(supportedClassName, idsToHolders.get(e.getKey()));\n+        SerializerAttributesHolder serializerAttributesHolder = idsToHolders.get(e.getKey());\n+        if (serializerAttributesHolder != null) {\n+          supportedClassesToHolders.putIfAbsent(supportedClassName, serializerAttributesHolder);\n+        }\n       }\n     }\n   }\n \n   public static void updateSupportedClassesMap(String dsClassName, String supportedClassName) {\n-    supportedClassesToHolders.putIfAbsent(supportedClassName, dsClassesToHolders.get(dsClassName));\n+    SerializerAttributesHolder holder = dsClassesToHolders.get(dsClassName);\n+    if (holder != null) {\n+      supportedClassesToHolders.putIfAbsent(supportedClassName, holder);\n+    }\n   }\n \n+  /**\n+   * A SerializerAttributesHolder holds information required to load a DataSerializer\n+   * and exists to allow client/server connections to be created more quickly than\n+   * they would if the DataSerializer information downloaded from the server were\n+   * used to immediately load the corresponding classes.\n+   */\n   public static class SerializerAttributesHolder {\n     private String className = \"\";\n     private EventID eventId = null;",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/main/java/org/apache/geode/internal/InternalDataSerializer.java",
                "sha": "7ab6284439b35e89a256439ac73f991b7ba449bd",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/deadlock/GemFireDeadlockDetectorDUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/deadlock/GemFireDeadlockDetectorDUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 2,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/deadlock/GemFireDeadlockDetectorDUnitTest.java",
                "patch": "@@ -108,8 +108,6 @@ public void testNoDeadlock() {\n \n   private static final Lock lock = new ReentrantLock();\n \n-  // @Category(FlakyTest.class) // GEODE-516 & GEODE-576: async actions, thread sleeps, time\n-  // sensitive\n   @Test\n   public void testDistributedDeadlockWithFunction() throws Throwable {\n     Host host = Host.getHost(0);",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/deadlock/GemFireDeadlockDetectorDUnitTest.java",
                "sha": "41e89b61dfe4640fe061334ff62fa7b5297e3494",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitorJUnitTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitorJUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitorJUnitTest.java",
                "patch": "@@ -195,7 +195,6 @@ public void testHMNextNeighborVerify() throws IOException {\n     assertEquals(mockMembers.get(myAddressIndex + 1), gmsHealthMonitor.getNextNeighbor());\n   }\n \n-  // @Category(FlakyTest.class) // GEODE-2073\n   @Test\n   public void testHMNextNeighborAfterTimeout() throws Exception {\n     System.out.println(\"testHMNextNeighborAfterTimeout starting\");",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/fd/GMSHealthMonitorJUnitTest.java",
                "sha": "468943a166f4c600dfa3aeb04ec7cad2e227da21",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "patch": "@@ -512,7 +512,6 @@ public void testDuplicateRemoveRequestDoesNotCauseNewView() throws Exception {\n         view.getCrashedMembers().contains(mockMembers[0]));\n   }\n \n-  // @Category(FlakyTest.class) // GEODE-2074: timed out waiting for view #7\n   @Test\n   public void testDuplicateJoinRequestDoesNotCauseNewView() throws Exception {\n     initMocks();",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/membership/GMSJoinLeaveJUnitTest.java",
                "sha": "89e620822cee9a59994d36e5e592d8d4ecaf1037",
                "status": "modified"
            },
            {
                "additions": 511,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/internal/DataSerializerHolderJUnitTest.java",
                "changes": 511,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/DataSerializerHolderJUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/DataSerializerHolderJUnitTest.java",
                "patch": "@@ -0,0 +1,511 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import junit.framework.TestCase;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.DataSerializer;\n+import org.apache.geode.test.junit.categories.UnitTest;\n+\n+@Category(UnitTest.class)\n+public class DataSerializerHolderJUnitTest extends TestCase {\n+\n+  @After\n+  public void tearDown() {\n+    InternalDataSerializer.reinitialize();\n+  }\n+\n+  @Test\n+  public void testHandshakeDatSerializerRegistrationDoesNotHitNPE() throws Throwable {\n+    // a thread performing a handshake from the client side may receive a list of\n+    // DataSerializer class names. It registers these with InternalDataSerializer to\n+    // create placeholders for later lazy loading of the classes\n+    Class[] serializers = new Class[] {DataSerializer1.class, DataSerializer2.class,\n+        DataSerializer3.class, DataSerializer4.class, DataSerializer5.class, DataSerializer6.class,\n+        DataSerializer7.class, DataSerializer8.class, DataSerializer9.class, DataSerializer10.class,\n+        DataSerializer11.class, DataSerializer12.class, DataSerializer13.class};\n+    for (int index = 0; index < serializers.length; index++) {\n+      int id = InternalDataSerializer.newInstance(serializers[index]).getId();\n+      InternalDataSerializer.register(serializers[index].getName(), false, null, null, id);\n+    }\n+\n+    // The thread will then register classes handled by the DataSerializers, but if\n+    // getSerializers() or a similar method is invoked by some other thread first the\n+    // placeholders will be wiped out, causing an NPE when registering the handled\n+    // classes. The NPE is caused by the placeholder being null in updateSupportedClassesMap().\n+    // Here we avoid creating a multithreaded test by invoking getSerializers() in-line\n+    InternalDataSerializer.getSerializers();\n+\n+\n+    // Now we perform the second step in the handshake code of registering the classes\n+    // handled by the DataSerializers. Without the bugfix this causes an NPE\n+    Map<Integer, List<String>> supportedClasses = new HashMap<>();\n+    for (int index = 0; index < serializers.length; index++) {\n+      DataSerializer serializer = InternalDataSerializer.newInstance(serializers[index]);\n+      List<String> classes = Arrays.<Class>asList(serializer.getSupportedClasses()).stream()\n+          .map((clazz) -> clazz.getName()).collect(Collectors.toList());\n+      supportedClasses.put(serializer.getId(), classes);\n+    }\n+    InternalDataSerializer.updateSupportedClassesMap(supportedClasses);\n+  }\n+\n+  public static class DataSerializer1 extends DataSerializer {\n+    int tempField = 5;\n+\n+    public DataSerializer1() {\n+\n+    }\n+\n+    @Override\n+    public int getId() {\n+      return 1;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {MyClass1.class, MyClass2.class, MyClass3.class, MyClass4.class,\n+          MyClass5.class, MyClass6.class, MyClass7.class, MyClass8.class, MyClass9.class,\n+          MyClass10.class};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      return true;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer2 extends DataSerializer {\n+    int tempField = 15;\n+\n+    public DataSerializer2() {}\n+\n+    @Override\n+    public int getId() {\n+      return 2;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {MyClass11.class, MyClass12.class, MyClass13.class, MyClass14.class,\n+          MyClass15.class, MyClass16.class, MyClass17.class, MyClass18.class, MyClass19.class,\n+          MyClass20.class};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      return true;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer3 extends DataSerializer {\n+    int tempField = 25;\n+\n+    public DataSerializer3() {}\n+\n+    @Override\n+    public int getId() {\n+      return 3;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer4 extends DataSerializer {\n+    int tempField = 5;\n+\n+    public DataSerializer4() {\n+\n+    }\n+\n+    @Override\n+    public int getId() {\n+      return 4;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer5 extends DataSerializer {\n+    int tempField = 15;\n+\n+    public DataSerializer5() {}\n+\n+    @Override\n+    public int getId() {\n+      return 5;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer6 extends DataSerializer {\n+    int tempField = 25;\n+\n+    public DataSerializer6() {}\n+\n+    @Override\n+    public int getId() {\n+      return 6;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer7 extends DataSerializer {\n+    int tempField = 5;\n+\n+    public DataSerializer7() {\n+\n+    }\n+\n+    @Override\n+    public int getId() {\n+      return 7;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer8 extends DataSerializer {\n+    int tempField = 15;\n+\n+    public DataSerializer8() {}\n+\n+    @Override\n+    public int getId() {\n+      return 8;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer9 extends DataSerializer {\n+    int tempField = 25;\n+\n+    public DataSerializer9() {}\n+\n+    @Override\n+    public int getId() {\n+      return 9;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer10 extends DataSerializer {\n+    int tempField = 5;\n+\n+    public DataSerializer10() {\n+\n+    }\n+\n+    @Override\n+    public int getId() {\n+      return 10;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer11 extends DataSerializer {\n+    int tempField = 15;\n+\n+    public DataSerializer11() {}\n+\n+    @Override\n+    public int getId() {\n+      return 11;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer12 extends DataSerializer {\n+    int tempField = 25;\n+\n+    public DataSerializer12() {}\n+\n+    @Override\n+    public int getId() {\n+      return 12;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class DataSerializer13 extends DataSerializer {\n+    int tempField = 25;\n+\n+    public DataSerializer13() {}\n+\n+    @Override\n+    public int getId() {\n+      return 19;\n+    }\n+\n+    @Override\n+    public Class[] getSupportedClasses() {\n+      return new Class[] {this.getClass()};\n+    }\n+\n+    @Override\n+    public boolean toData(Object o, DataOutput out) throws IOException {\n+      out.write(tempField);\n+      return false;\n+    }\n+\n+    @Override\n+    public Object fromData(DataInput in) throws IOException, ClassNotFoundException {\n+      readInteger(in);\n+      return null;\n+    }\n+  }\n+\n+  public static class MyClass1 {\n+    public MyClass1() {}\n+  }\n+  public static class MyClass2 {\n+    public MyClass2() {}\n+  }\n+  public static class MyClass3 {\n+    public MyClass3() {}\n+  }\n+  public static class MyClass4 {\n+    public MyClass4() {}\n+  }\n+  public static class MyClass5 {\n+    public MyClass5() {}\n+  }\n+  public static class MyClass6 {\n+    public MyClass6() {}\n+  }\n+  public static class MyClass7 {\n+    public MyClass7() {}\n+  }\n+  public static class MyClass8 {\n+    public MyClass8() {}\n+  }\n+  public static class MyClass9 {\n+    public MyClass9() {}\n+  }\n+  public static class MyClass10 {\n+    public MyClass10() {}\n+  }\n+  public static class MyClass11 {\n+    public MyClass11() {}\n+  }\n+  public static class MyClass12 {\n+    public MyClass12() {}\n+  }\n+  public static class MyClass13 {\n+    public MyClass13() {}\n+  }\n+  public static class MyClass14 {\n+    public MyClass14() {}\n+  }\n+  public static class MyClass15 {\n+    public MyClass15() {}\n+  }\n+  public static class MyClass16 {\n+    public MyClass16() {}\n+  }\n+  public static class MyClass17 {\n+    public MyClass17() {}\n+  }\n+  public static class MyClass18 {\n+    public MyClass18() {}\n+  }\n+  public static class MyClass19 {\n+    public MyClass19() {}\n+  }\n+  public static class MyClass20 {\n+    public MyClass20() {}\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/internal/DataSerializerHolderJUnitTest.java",
                "sha": "5d45344b36ebaf2c0483112e17e67dcfaa583f63",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/management/UniversalMembershipListenerAdapterDUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/UniversalMembershipListenerAdapterDUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 2,
                "filename": "geode-core/src/test/java/org/apache/geode/management/UniversalMembershipListenerAdapterDUnitTest.java",
                "patch": "@@ -80,7 +80,6 @@\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.rules.DistributedRestoreSystemProperties;\n import org.apache.geode.test.junit.categories.DistributedTest;\n-import org.apache.geode.test.junit.categories.FlakyTest;\n \n /**\n  * Distributed tests for {@link UniversalMembershipListenerAdapter}.\n@@ -1077,7 +1076,6 @@ private void assertArrayTrue(String msg, boolean[] array) {\n   /**\n    * Tests notification of events for bridge server in system bridge client process.\n    */\n-  @Category(FlakyTest.class) // GEODE-1879\n   @Test\n   public void testServerEventsInPeerSystem() throws Exception {\n     boolean[] firedSystem = new boolean[3];",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/management/UniversalMembershipListenerAdapterDUnitTest.java",
                "sha": "a8fc177a8f5cef8d7a653a97e31d2c58e77031d6",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/redis/RedisDistDUnitTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/redis/RedisDistDUnitTest.java?ref=a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c",
                "deletions": 8,
                "filename": "geode-core/src/test/java/org/apache/geode/redis/RedisDistDUnitTest.java",
                "patch": "@@ -38,7 +38,6 @@\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n import org.apache.geode.test.junit.categories.DistributedTest;\n-import org.apache.geode.test.junit.categories.FlakyTest;\n import org.apache.geode.test.junit.categories.RedisTest;\n \n @Category({DistributedTest.class, RedisTest.class})\n@@ -108,9 +107,6 @@ public final void preTearDown() throws Exception {\n     disconnectAllFromDS();\n   }\n \n-  @Category(FlakyTest.class) // GEODE-1092: random ports, failure stack involves TCPTransport\n-                             // ConnectionHandler (are we eating BindExceptions somewhere?), uses\n-                             // Random, async actions\n   @Test\n   public void testConcListOps() throws Exception {\n     final Jedis jedis1 = new Jedis(localHost, server1Port, JEDIS_TIMEOUT);\n@@ -146,8 +142,6 @@ public Object call() throws Exception {\n     assertEquals(result1, result2);\n   }\n \n-  @Category(FlakyTest.class) // GEODE-717: random ports, BindException in failure stack, async\n-                             // actions\n   @Test\n   public void testConcCreateDestroy() throws Exception {\n     IgnoredException.addIgnoredException(\"RegionDestroyedException\");\n@@ -208,8 +202,6 @@ public Object call() throws Exception {\n   /**\n    * Just make sure there are no unexpected server crashes\n    */\n-  @Category(FlakyTest.class) // GEODE-1697\n-  @Test\n   public void testConcOps() throws Exception {\n \n     final int ops = 100;",
                "raw_url": "https://github.com/apache/geode/raw/a60b8d4237f0d27b9b31af304ae6ec3bfcdc077c/geode-core/src/test/java/org/apache/geode/redis/RedisDistDUnitTest.java",
                "sha": "a8f165c173d610629c0ea99ec3ab546de9034d78",
                "status": "modified"
            }
        ],
        "message": "GEODE-5198 NPE in DataSerializer registration when forming a client/server connection during handshake\n\nIf a holder can't be found do not record supported classes for it.\nAbsense of the holder, which had just been inserted into the\nidsToHolders collection, means that another thread has resolved the\nholder into an actual DataSerializer class and has removed the holder\nand its supported classes.\n\nThis closes #1943",
        "parent": "https://github.com/apache/geode/commit/8ed21ab9e2ffc3d40d5909d1d124930a93282e9c",
        "patched_files": [
            "InternalDataSerializer.java",
            "ClientSideHandshakeImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "DataSerializerHolderJUnitTest.java",
            "UniversalMembershipListenerAdapterDUnitTest.java",
            "RedisDistDUnitTest.java",
            "GMSJoinLeaveJUnitTest.java",
            "GemFireDeadlockDetectorDUnitTest.java",
            "GMSHealthMonitorJUnitTest.java"
        ]
    },
    "geode_a8e1fab": {
        "bug_id": "geode_a8e1fab",
        "commit": "https://github.com/apache/geode/commit/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4",
        "file": [
            {
                "additions": 57,
                "blob_url": "https://github.com/apache/geode/blob/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-assembly/src/test/java/org/apache/geode/tools/pulse/PulseSecurityIntegrationTest.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-assembly/src/test/java/org/apache/geode/tools/pulse/PulseSecurityIntegrationTest.java?ref=a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4",
                "deletions": 0,
                "filename": "geode-assembly/src/test/java/org/apache/geode/tools/pulse/PulseSecurityIntegrationTest.java",
                "patch": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.tools.pulse;\n+\n+import static java.util.concurrent.TimeUnit.MINUTES;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.awaitility.Awaitility.await;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.examples.SimpleSecurityManager;\n+import org.apache.geode.management.ManagementService;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.apache.geode.test.junit.rules.EmbeddedPulseRule;\n+import org.apache.geode.test.junit.rules.LocatorStarterRule;\n+import org.apache.geode.tools.pulse.internal.data.Cluster;\n+\n+@Category(IntegrationTest.class)\n+public class PulseSecurityIntegrationTest {\n+\n+  @Rule\n+  public LocatorStarterRule locator =\n+      new LocatorStarterRule().withSecurityManager(SimpleSecurityManager.class).withAutoStart();\n+\n+  @Rule\n+  public EmbeddedPulseRule pulse = new EmbeddedPulseRule();\n+\n+  @Test\n+  public void getAttributesWithSecurityManager() throws Exception {\n+    pulse.useJmxPort(locator.getJmxPort());\n+\n+    ManagementService service =\n+        ManagementService.getExistingManagementService(locator.getLocator().getCache());\n+\n+    await().atMost(2, MINUTES).until(() -> assertThat(service.getMemberMXBean()).isNotNull());\n+\n+    Cluster cluster = pulse.getRepository().getCluster(\"cluster\", \"cluster\");\n+    Cluster.Member[] members = cluster.getMembers();\n+    assertThat(members.length).isEqualTo(1);\n+    assertThat(members[0].getName()).isEqualTo(\"locator\");\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-assembly/src/test/java/org/apache/geode/tools/pulse/PulseSecurityIntegrationTest.java",
                "sha": "7e331d7f27cdd2c2c58c67b48338ae9a7aed0c54",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-core/src/main/java/org/apache/geode/management/internal/beans/LocatorMBeanBridge.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/beans/LocatorMBeanBridge.java?ref=a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/beans/LocatorMBeanBridge.java",
                "patch": "@@ -16,6 +16,7 @@\n \n import java.io.File;\n import java.io.IOException;\n+import java.net.InetAddress;\n import java.util.List;\n \n import org.apache.logging.log4j.Logger;\n@@ -44,7 +45,8 @@ public LocatorMBeanBridge(Locator loc) {\n   }\n \n   public String getBindAddress() {\n-    return loc.getBindAddress().getCanonicalHostName();\n+    InetAddress bindAddress = loc.getBindAddress();\n+    return bindAddress != null ? bindAddress.getCanonicalHostName() : null;\n   }\n \n   public String getHostnameForClients() {",
                "raw_url": "https://github.com/apache/geode/raw/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-core/src/main/java/org/apache/geode/management/internal/beans/LocatorMBeanBridge.java",
                "sha": "bb86ac07f68029494f364353e195a6afef8ff9ba",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/geode/blob/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-pulse/src/main/java/org/apache/geode/tools/pulse/internal/data/JMXDataUpdater.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-pulse/src/main/java/org/apache/geode/tools/pulse/internal/data/JMXDataUpdater.java?ref=a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4",
                "deletions": 10,
                "filename": "geode-pulse/src/main/java/org/apache/geode/tools/pulse/internal/data/JMXDataUpdater.java",
                "patch": "@@ -17,16 +17,10 @@\n \n package org.apache.geode.tools.pulse.internal.data;\n \n-import com.fasterxml.jackson.databind.ObjectMapper;\n-import com.fasterxml.jackson.databind.node.ObjectNode;\n-import org.apache.commons.lang.StringUtils;\n-import org.apache.geode.tools.pulse.internal.data.JmxManagerFinder.JmxManagerInfo;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-\n import java.io.IOException;\n import java.io.PrintWriter;\n import java.io.StringWriter;\n+import java.lang.reflect.Array;\n import java.math.BigDecimal;\n import java.net.Inet4Address;\n import java.net.Inet6Address;\n@@ -43,11 +37,14 @@\n import java.util.Map.Entry;\n import java.util.ResourceBundle;\n import java.util.Set;\n+import java.util.stream.Collectors;\n+\n import javax.management.Attribute;\n import javax.management.AttributeList;\n import javax.management.AttributeNotFoundException;\n import javax.management.InstanceNotFoundException;\n import javax.management.IntrospectionException;\n+import javax.management.MBeanAttributeInfo;\n import javax.management.MBeanException;\n import javax.management.MBeanServerConnection;\n import javax.management.MalformedObjectNameException;\n@@ -62,6 +59,14 @@\n import javax.management.remote.JMXServiceURL;\n import javax.rmi.ssl.SslRMIClientSocketFactory;\n \n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import org.apache.geode.tools.pulse.internal.data.JmxManagerFinder.JmxManagerInfo;\n+\n /**\n  * Class JMXDataUpdater Class used for creating JMX connection and getting all the required MBeans\n  * \n@@ -1256,15 +1261,20 @@ private void updateClusterStatement(ObjectName mbeanName) throws IOException {\n    * function used to iterate through all member attributes and return the updated member\n    */\n   private Cluster.Member initializeMember(ObjectName mbeanName, Cluster.Member member)\n-      throws InstanceNotFoundException, ReflectionException, IOException {\n+      throws InstanceNotFoundException, ReflectionException, IOException, IntrospectionException {\n+\n+    MBeanAttributeInfo[] mbeanAttributes = this.mbs.getMBeanInfo(mbeanName).getAttributes();\n+    Set<String> mbeanAttributeNames =\n+        Arrays.stream(mbeanAttributes).map(MBeanAttributeInfo::getName).collect(Collectors.toSet());\n \n     AttributeList attributeList =\n-        this.mbs.getAttributes(mbeanName, PulseConstants.MEMBER_MBEAN_ATTRIBUTES);\n+        this.mbs.getAttributes(mbeanName, mbeanAttributeNames.toArray(new String[0]));\n \n     for (int i = 0; i < attributeList.size(); i++) {\n \n       Attribute attribute = (Attribute) attributeList.get(i);\n       String name = attribute.getName();\n+\n       switch (name) {\n         case PulseConstants.MBEAN_ATTRIBUTE_GEMFIREVERSION:\n           if (member.getGemfireVersion() == null) {\n@@ -1424,7 +1434,7 @@ private void updateClusterMember(ObjectName mbeanName) throws IOException {\n         memberList.add(clusterMember);\n         cluster.getPhysicalToMember().put(clusterMember.getHost(), memberList);\n       }\n-    } catch (InstanceNotFoundException | ReflectionException infe) {\n+    } catch (InstanceNotFoundException | ReflectionException | IntrospectionException infe) {\n       logger.warn(infe);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-pulse/src/main/java/org/apache/geode/tools/pulse/internal/data/JMXDataUpdater.java",
                "sha": "f9b6825a0b91e65560a73a8027699db372a31790",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-pulse/src/main/webapp/WEB-INF/spring-security.xml",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-pulse/src/main/webapp/WEB-INF/spring-security.xml?ref=a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4",
                "deletions": 0,
                "filename": "geode-pulse/src/main/webapp/WEB-INF/spring-security.xml",
                "patch": "@@ -29,6 +29,7 @@\n \t\t<!-- Can be invoked w/o auth -->\n \t\t<intercept-url pattern=\"/login.html\" access=\"permitAll\"  />\n \t\t<intercept-url pattern=\"/authenticateUser\" access=\"permitAll\" />\n+\t\t<intercept-url pattern=\"/pulseVersion\" access=\"permitAll\" />\n \t\t<!-- Can be invoked w/o auth -->\n \n \t\t<!-- Restricted urls -->",
                "raw_url": "https://github.com/apache/geode/raw/a8e1fab63848b064fdecb2c63fa2fa26e8f06cb4/geode-pulse/src/main/webapp/WEB-INF/spring-security.xml",
                "sha": "8cc035dd56aa0d9691cd590b997d88b4379af8bd",
                "status": "modified"
            }
        ],
        "message": "GEODE-3941: Pulse issues when SecurityManager is enabled (#1007)\n\n- Pulse UI is not updated correctly - missing servers for ex.\r\n- NPE regarding JMXUpdater in pulse.log",
        "parent": "https://github.com/apache/geode/commit/235790c14af58b89c57643c066ff25ca9b7afb14",
        "patched_files": [
            "LocatorMBeanBridge.java",
            "spring-security.java",
            "JMXDataUpdater.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PulseSecurityIntegrationTest.java"
        ]
    },
    "geode_ab9cedf": {
        "bug_id": "geode_ab9cedf",
        "commit": "https://github.com/apache/geode/commit/ab9cedf8f253e3c049138df282352dd28c0b252a",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AbstractOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AbstractOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AbstractOp.java",
                "patch": "@@ -114,7 +114,7 @@ public String getShortClassName() {\n   protected void sendMessage(Connection cnx) throws Exception {\n     if (cnx.getServer().getRequiresCredentials()) {\n       // Security is enabled on client as well as on server\n-      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);\n+      getMessage().setMessageHasSecurePartFlag();\n       HeapDataOutputStream hdos = new HeapDataOutputStream(Version.CURRENT);\n       long userId = -1;\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AbstractOp.java",
                "sha": "28c1e0fda6c98f60134c080180f7bc3d822497d6",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXEnumOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXEnumOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXEnumOp.java",
                "patch": "@@ -91,7 +91,7 @@ protected boolean participateInTransaction() {\n     //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXEnumOp.java",
                "sha": "ff2bf1c9f8ec8a1c442b7b78222173102ebd76b1",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXTypeOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXTypeOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 3,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXTypeOp.java",
                "patch": "@@ -87,11 +87,9 @@ protected boolean participateInTransaction() {\n       return false;\n     }\n     \n-    //TODO - no idea what this mumbo jumbo means, but it's on\n-    //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AddPDXTypeOp.java",
                "sha": "9fbc674a7a0312e4bb8e7c7050d82e54d6b17c17",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AuthenticateUserOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AuthenticateUserOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 2,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AuthenticateUserOp.java",
                "patch": "@@ -121,7 +121,7 @@ public AuthenticateUserOpImpl(Connection con, ExecutablePool pool) {\n           tmpSecurityProperties, server, false, (InternalLogWriter)sys.getLogWriter(), (InternalLogWriter)sys\n               .getSecurityLogWriter());\n       \n-      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);\n+      getMessage().setMessageHasSecurePartFlag();\n       HeapDataOutputStream heapdos = new HeapDataOutputStream(Version.CURRENT);\n       try {\n         DataSerializer.writeProperties(credentials, heapdos);\n@@ -144,7 +144,7 @@ public AuthenticateUserOpImpl(ExecutablePool pool, Properties securityProps, boo\n       this.securityProperties = securityProps;\n       this.needsServerLocation = needsServer;\n \n-      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);\n+      getMessage().setMessageHasSecurePartFlag();\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/AuthenticateUserOp.java",
                "sha": "b03c7b9669524d756074b8ba80056fc9b87bea4f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CloseConnectionOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CloseConnectionOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CloseConnectionOp.java",
                "patch": "@@ -67,7 +67,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CloseConnectionOp.java",
                "sha": "7de38fe897c8237f1fded6e90b67dd8fbed5f69e",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CommitOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CommitOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CommitOp.java",
                "patch": "@@ -85,7 +85,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }    \n     ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/CommitOp.java",
                "sha": "c9c6dd7a6c3d8ca3c42f4c0bce8508843fd99cb8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPRMetaDataOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPRMetaDataOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPRMetaDataOp.java",
                "patch": "@@ -81,7 +81,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPRMetaDataOp.java",
                "sha": "8bae6fffc551d5263859d39d0a4f49fc9996173f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPartitionAttributesOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPartitionAttributesOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPartitionAttributesOp.java",
                "patch": "@@ -86,7 +86,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetClientPartitionAttributesOp.java",
                "sha": "e1a8870e3bda27efadb1ec94cf03f01e9bacbce8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetEventValueOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetEventValueOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetEventValueOp.java",
                "patch": "@@ -72,7 +72,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetEventValueOp.java",
                "sha": "1038ede4f42ffe998c226c8415fd8094083c87e8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetFunctionAttributeOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetFunctionAttributeOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetFunctionAttributeOp.java",
                "patch": "@@ -77,7 +77,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetFunctionAttributeOp.java",
                "sha": "177ea261872cc8e8619c528c81319c4222bcc885",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumByIdOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumByIdOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 3,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumByIdOp.java",
                "patch": "@@ -83,11 +83,9 @@ protected boolean participateInTransaction() {\n       return false;\n     }\n     \n-    //TODO - no idea what this mumbo jumbo means, but it's on\n-    //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumByIdOp.java",
                "sha": "1e22d81ec7d5af1251bebf77ee7e15ae4e01da41",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumsOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumsOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumsOp.java",
                "patch": "@@ -105,7 +105,7 @@ protected boolean participateInTransaction() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXEnumsOp.java",
                "sha": "0590cafa5ee9683ff0e4bc996435dfdd19f9b7eb",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForEnumOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForEnumOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 3,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForEnumOp.java",
                "patch": "@@ -104,11 +104,9 @@ protected boolean needsUserId() {\n     protected boolean participateInTransaction() {\n       return false;\n     }\n-    //TODO - no idea what this mumbo jumbo means, but it's on\n-    //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForEnumOp.java",
                "sha": "bac2e8063ad377adf2aa808655984523a7a2b0f8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForTypeOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForTypeOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 3,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForTypeOp.java",
                "patch": "@@ -104,11 +104,9 @@ protected boolean needsUserId() {\n     protected boolean participateInTransaction() {\n       return false;\n     }\n-    //TODO - no idea what this mumbo jumbo means, but it's on\n-    //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXIdForTypeOp.java",
                "sha": "1b71f71d03c0bbb1a605ca06dd4274ce06bd4388",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypeByIdOp.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypeByIdOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 3,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypeByIdOp.java",
                "patch": "@@ -83,11 +83,9 @@ protected boolean participateInTransaction() {\n       return false;\n     }\n     \n-    //TODO - no idea what this mumbo jumbo means, but it's on\n-    //most of the other messages like this.\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypeByIdOp.java",
                "sha": "1d9bd2d58fecbbc8f654218db10bcbbde3e07b54",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypesOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypesOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypesOp.java",
                "patch": "@@ -105,7 +105,7 @@ protected boolean participateInTransaction() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/GetPDXTypesOp.java",
                "sha": "262cb9a5c2c1b40726780f8ef96c05d07648beae",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/MakePrimaryOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/MakePrimaryOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/MakePrimaryOp.java",
                "patch": "@@ -62,7 +62,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/MakePrimaryOp.java",
                "sha": "27d80b1b8b583a824c625129c738e42f5b16c477",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PingOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PingOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PingOp.java",
                "patch": "@@ -66,7 +66,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       startTime = System.currentTimeMillis();\n       getMessage().send(false);\n       Message.messageType.set(MessageType.PING);",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PingOp.java",
                "sha": "e70d50acc53e437aeba59d5052c8f83489c37b2c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PrimaryAckOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PrimaryAckOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PrimaryAckOp.java",
                "patch": "@@ -72,7 +72,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/PrimaryAckOp.java",
                "sha": "4ee680a4efdec0175b6823a75ec9cf6084546333",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ProxyCacheCloseOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ProxyCacheCloseOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ProxyCacheCloseOp.java",
                "patch": "@@ -45,7 +45,7 @@ private ProxyCacheCloseOp() {\n     public ProxyCacheCloseOpImpl(ExecutablePool pool, Properties securityProps,\n         boolean keepAlive) {\n       super(MessageType.REMOVE_USER_AUTH, 1);\n-      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);\n+      getMessage().setMessageHasSecurePartFlag();\n       getMessage().addBytesPart(keepAlive ? new byte[] {1} : new byte[] {0});\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ProxyCacheCloseOp.java",
                "sha": "2747fa8f7a6a7423eb024f69c5975466f30d2824",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ReadyForEventsOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ReadyForEventsOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ReadyForEventsOp.java",
                "patch": "@@ -62,7 +62,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/ReadyForEventsOp.java",
                "sha": "d2631fc76d944ed05a08351224167ad77349f568",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterDataSerializersOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterDataSerializersOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterDataSerializersOp.java",
                "patch": "@@ -131,7 +131,7 @@ protected boolean needsUserId() {\n     }\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterDataSerializersOp.java",
                "sha": "869ad644dde655557901b71dd921220ea99ce565",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterInstantiatorsOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterInstantiatorsOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterInstantiatorsOp.java",
                "patch": "@@ -173,7 +173,7 @@ protected boolean needsUserId() {\n     }\n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RegisterInstantiatorsOp.java",
                "sha": "0d5a1376efef5a98ade6f7637293905811b9cce5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RollbackOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RollbackOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RollbackOp.java",
                "patch": "@@ -92,7 +92,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/RollbackOp.java",
                "sha": "6f01b966f817b3516a49a9ffa0f56046826ce3e6",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/SizeOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/SizeOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/SizeOp.java",
                "patch": "@@ -85,7 +85,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/SizeOp.java",
                "sha": "42cc225960ffdfddda334a716a891349f973665c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXFailoverOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXFailoverOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXFailoverOp.java",
                "patch": "@@ -86,7 +86,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXFailoverOp.java",
                "sha": "64ee66ee61eb1e6850233e8feb16a849d06d180d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXSynchronizationOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXSynchronizationOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXSynchronizationOp.java",
                "patch": "@@ -155,7 +155,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n   }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/cache/client/internal/TXSynchronizationOp.java",
                "sha": "34ecf4d05c49ebfbd5997475e00a06d259ed6db7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "patch": "@@ -777,7 +777,7 @@ public TXStateProxy masqueradeAs(Message msg,InternalDistributedMember memberId,\n     if (val == null) {\n       synchronized(this.hostedTXStates) {\n         val = this.hostedTXStates.get(key);\n-        if (val == null && msg.canStartRemoteTransaction()) {\n+        if (val == null) {\n           // [sjigyasu] TODO: Conditionally create object based on distributed or non-distributed tx mode \n           if (msg instanceof TransactionMessage && ((TransactionMessage)msg).isTransactionDistributed()) {\n             val = new DistTXStateProxyImplOnDatanode(this, key, memberId);",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/TXManagerImpl.java",
                "sha": "de49fead8e0188d6b1316e1bc37d05d452cb9de5",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/BaseCommand.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/BaseCommand.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/BaseCommand.java",
                "patch": "@@ -931,7 +931,7 @@ static Message readRequest(ServerConnection servConn) {\n     try {\n       requestMsg = servConn.getRequestMessage();\n       requestMsg.recv(servConn, MAX_INCOMING_DATA, incomingDataLimiter,\n-          MAX_INCOMING_MSGS, incomingMsgLimiter);\n+          incomingMsgLimiter);\n       return requestMsg;\n     }\n     catch (EOFException eof) {",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/BaseCommand.java",
                "sha": "dd13f191ce6dbf3787adc6cd44a3037a810e65ab",
                "status": "modified"
            },
            {
                "additions": 73,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Message.java",
                "changes": 236,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Message.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 163,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Message.java",
                "patch": "@@ -34,14 +34,12 @@\n import com.gemstone.gemfire.internal.HeapDataOutputStream;\n import com.gemstone.gemfire.internal.SocketUtils;\n import com.gemstone.gemfire.internal.Version;\n-import com.gemstone.gemfire.internal.cache.CachedDeserializable;\n import com.gemstone.gemfire.internal.cache.TXManagerImpl;\n import com.gemstone.gemfire.internal.cache.tier.MessageType;\n import com.gemstone.gemfire.internal.i18n.LocalizedStrings;\n import com.gemstone.gemfire.internal.logging.LogService;\n import com.gemstone.gemfire.internal.logging.log4j.LocalizedMessage;\n import com.gemstone.gemfire.internal.offheap.StoredObject;\n-import com.gemstone.gemfire.internal.offheap.annotations.Retained;\n import com.gemstone.gemfire.internal.offheap.annotations.Unretained;\n import com.gemstone.gemfire.internal.util.BlobHelper;\n \n@@ -61,7 +59,7 @@\n  * transId       - int - 4 bytes  filled in by the requestor, copied back into\n  *                    the response\n  *\n- * earlyAck      - byte- 1 byte   filled in by the requestor\n+ * flags         - byte- 1 byte   filled in by the requestor\n  * len1\n  * part1\n  * .\n@@ -81,33 +79,17 @@\n  *\n  * @see com.gemstone.gemfire.internal.cache.tier.MessageType\n  *\n- * @author Sudhir Menon\n- * @since 2.0.2\n  */\n public class Message  {\n \n   private static final Logger logger = LogService.getLogger();\n   \n-  @Override\n-  public String toString() {\n-    StringBuffer sb = new StringBuffer();\n-    sb.append(\"type=\" + MessageType.getString(msgType));\n-    sb.append(\"; payloadLength=\" + payloadLength);\n-    sb.append(\"; numberOfParts=\" + numberOfParts);\n-    sb.append(\"; transactionId=\" + transactionId);\n-    //sb.append(\"; bufferLength=\" + bufferLength);\n-    sb.append(\"; currentPart=\" + currentPart);\n-    sb.append(\"; messageModified=\" + messageModified);\n-    sb.append(\"; earlyAck=\" + earlyAck);\n-    for (int i = 0; i < numberOfParts; i ++) {\n-      sb.append(\"; part[\" + i + \"]={\");\n-      sb.append(this.partsList[i].toString());\n-      sb.append(\"}\");\n-    }\n-    return sb.toString();\n-  }\n+  private static final int PART_HEADER_SIZE = 5; // 4 bytes for length, 1 byte for isObject\n+  \n+  private static final int FIXED_LENGTH = 17;\n+\n+  private static final ThreadLocal<ByteBuffer> tlCommBuffer = new ThreadLocal<>();\n \n-  protected final static int FIXED_LENGTH = 17;\n   protected int msgType;\n   protected int payloadLength=0;\n   protected int numberOfParts =0;\n@@ -122,19 +104,21 @@ public String toString() {\n   protected boolean messageModified = true;\n   /** is this message a retry of a previously sent message? */\n   protected boolean isRetry;\n-  private byte earlyAck = 0x00;\n+  private byte flags = 0x00;\n   protected MessageStats msgStats = null;\n   protected ServerConnection sc = null;\n-  private int MAX_DATA = -1;\n+  private int maxIncomingMessageLength = -1;\n   private Semaphore dataLimiter = null;\n //  private int MAX_MSGS = -1;\n   private Semaphore msgLimiter = null;\n   private boolean hdrRead = false;  \n   private int chunkSize = 1024;//Default Chunk Size.\n \n   protected Part securePart = null;\n+  private boolean isMetaRegion = false;\n+\n \n-  // These two statics are fields shoved into the earlyAck byte for transmission.\n+  // These two statics are fields shoved into the flags byte for transmission.\n   // The MESSAGE_IS_RETRY bit is stripped out during deserialization but the other\n   // is left in place\n   public static final byte MESSAGE_HAS_SECURE_PART = (byte)0x02;\n@@ -181,31 +165,14 @@ public void setVersion(Version clientVersion) {\n     this.version = clientVersion;\n   }\n \n-  /**\n-   * Sets whether this message is early-ack\n-   * @param earlyAck whether this message is early-ack\n-   */\n-  public void setEarlyAck(boolean earlyAck) {\n-    if (earlyAck) {\n-      this.earlyAck = 0x01;\n-    } else {\n-      this.earlyAck = 0x00;\n-    }\n+  public void setMessageHasSecurePartFlag() {\n+    this.flags = (byte)(this.flags | MESSAGE_HAS_SECURE_PART);\n   }\n-\n-  // TODO (ashetkar) To be removed later.\n-  public void setEarlyAck(byte earlyAck) {\n-    // Check that the passed in value is within the acceptable range.\n-    if (0x00 <= earlyAck && earlyAck <= 0x02) {\n-      this.earlyAck |= earlyAck;\n-    }\n+  \n+  public void clearMessageHasSecurePartFlag() {\n+    this.flags = (byte)(this.flags & MESSAGE_HAS_SECURE_PART);\n   }\n \n-  /*\n-   * public void setPayloadLength(int payloadLength) {\n-     this.payloadLength = payloadLength;\n-  }*/\n-\n   /**\n    *  Sets and builds the {@link Part}s that are sent\n    *  in the payload of the Message\n@@ -252,6 +219,14 @@ public boolean isRetry() {\n   public void setChunkSize(int chunkSize) {\n     this.chunkSize = chunkSize;\n   }\n+  \n+  /**\n+   * When building a Message this will return the number of the\n+   * next Part to be added to the message\n+   */\n+  public int getNextPartNumber() {\n+    return this.currentPart;\n+  }\n \n   public void addStringPart(String str) {\n     if (str==null) {\n@@ -266,15 +241,6 @@ public void addStringPart(String str) {\n     }\n   }\n \n-  /**\n-   * Sets whether or not a\n-   * <code>DataOutputStream</code>/<code>DataOutputStream</code>\n-   * should be used to send/receive data.\n-      public void setUseDataStream (boolean useDataStream) {\n-        this.useDataStream = useDataStream;\n-    }\n-   */\n-\n   /*\n    * Adds a new part to this message that contains a <code>byte</code>\n    * array (as opposed to a serialized object).\n@@ -295,7 +261,7 @@ public void addStringOrObjPart(Object o) {\n     }\n   }\n \n-  public void addDeltaPart(HeapDataOutputStream hdos) { // TODO: Amogh- Should it be just DataOutput?\n+  public void addDeltaPart(HeapDataOutputStream hdos) {\n     this.messageModified = true;\n     Part part = partsList[this.currentPart];\n     part.setPartState(hdos, false);\n@@ -364,12 +330,6 @@ private void serializeAndAddPartNoCopying(Object o) {\n     // the heap bb to the existing direct bb without needing to allocate extra direct bbs.\n     // Delaying the flush uses more direct memory but reduces the number of system calls.\n     try {\n-//      logger.fine(\"hitesh before serializatino: \" );\n-//      \n-//      if (o != null ){\n-//        logger.fine(\"hitesh before serializatino: \" + o.toString());\n-//        logger.fine(\"hitesh before serializatino: \" + o.getClass().getName());\n-//      }\n       BlobHelper.serializeTo(o, hdos);\n     } catch (IOException ex) {\n       throw new SerializationException(\"failed serializing object\", ex);\n@@ -385,8 +345,6 @@ private void serializeAndAddPart(Object o, boolean zipValues) {\n     if (zipValues) {\n       throw new UnsupportedOperationException(\"zipValues no longer supported\");    \n       \n-//       byte[] b = CacheServerHelper.serialize(o, zipValues);\n-//       addRawPart(b, true);\n     } else {\n       HeapDataOutputStream hdos;\n       Version v = version;\n@@ -395,12 +353,6 @@ private void serializeAndAddPart(Object o, boolean zipValues) {\n       }\n       hdos = new HeapDataOutputStream(chunkSize, v);\n       try {\n-//        logger.fine(\"hitesh before serializatino: \" );\n-//        \n-//        if (o != null ){\n-//          logger.fine(\"hitesh before serializatino: \" + o.toString());\n-//          logger.fine(\"hitesh before serializatino: \" + o.getClass().getName());\n-//        }\n         BlobHelper.serializeTo(o, hdos);\n       } catch (IOException ex) {\n         throw new SerializationException(\"failed serializing object\", ex);\n@@ -468,19 +420,8 @@ public Part getPart(int index) {\n     return null;\n   }\n \n-  public boolean getEarlyAck() {\n-    return this.earlyAck == 0x01 ? true: false;\n-  }\n-\n-  // TODO (ashetkar) To be removed\n-  public byte getEarlyAckByte() {\n-    return this.earlyAck;\n-  }\n-\n-  private static ThreadLocal tlCommBuffer = new ThreadLocal();\n-\n   public static ByteBuffer setTLCommBuffer(ByteBuffer bb) {\n-    ByteBuffer result = (ByteBuffer)tlCommBuffer.get();\n+    ByteBuffer result = tlCommBuffer.get();\n     tlCommBuffer.set(bb);\n     return result;\n   }\n@@ -490,7 +431,7 @@ public ByteBuffer getCommBuffer() {\n       return this.cachedCommBuffer;\n     }\n     else {\n-      return (ByteBuffer)tlCommBuffer.get();\n+      return tlCommBuffer.get();\n     }\n   }\n \n@@ -505,14 +446,15 @@ public void clear() {\n         this.msgStats.decMessagesBeingReceived(len);\n       }\n     }\n-    if (this.socket != null) {\n-      getCommBuffer().clear();\n+    ByteBuffer buffer = getCommBuffer();\n+    if (buffer != null) {\n+      buffer.clear();\n     }\n     clearParts();\n     if (len != 0 && this.dataLimiter != null) {\n       this.dataLimiter.release(len);\n       this.dataLimiter = null;\n-      this.MAX_DATA = 0;\n+      this.maxIncomingMessageLength = 0;\n     }\n     if (this.hdrRead) {\n       if (this.msgLimiter != null) {\n@@ -521,29 +463,28 @@ public void clear() {\n       }\n       this.hdrRead = false;\n     }\n+    this.flags = 0;\n   }\n \n   protected void packHeaderInfoForSending(int msgLen, boolean isSecurityHeader) {\n-    //TODO:hitesh setting second bit of early ack for client \n+    //TODO:hitesh setting second bit of flags byte for client \n     //this is not require but this makes all changes easily at client side right now\n     //just see this bit and process security header\n-    byte eAck = this.earlyAck;\n+    byte flagsByte = this.flags;\n     if (isSecurityHeader) {\n-      eAck |= MESSAGE_HAS_SECURE_PART;\n+      flagsByte |= MESSAGE_HAS_SECURE_PART;\n     }\n     if (this.isRetry) {\n-      eAck |= MESSAGE_IS_RETRY;\n+      flagsByte |= MESSAGE_IS_RETRY;\n     }\n     getCommBuffer()\n       .putInt(this.msgType)\n       .putInt(msgLen)\n       .putInt(this.numberOfParts)\n       .putInt(this.transactionId)\n-      .put(eAck);\n+      .put(flagsByte);\n   }\n \n-  private static final int PART_HEADER_SIZE = 5; // 4 bytes for length, 1 byte for isObject\n-  \n   protected Part getSecurityPart() {\n     if (this.sc != null ) {\n       //look types right put get etc\n@@ -557,15 +498,13 @@ public void setSecurePart(byte[] bytes) {\n     this.securePart.setPartState(bytes, false);\n   }\n \n-  private boolean m_isMetaRegion = false;\n-\n   public void setMetaRegion(boolean isMetaRegion) {\n-    this.m_isMetaRegion = isMetaRegion;\n+    this.isMetaRegion = isMetaRegion;\n   }\n \n   public boolean getAndResetIsMetaRegion() {\n-    boolean isMetaRegion = this.m_isMetaRegion;\n-    this.m_isMetaRegion = false;\n+    boolean isMetaRegion = this.isMetaRegion;\n+    this.isMetaRegion = false;\n     return isMetaRegion;\n   }\n \n@@ -598,7 +537,6 @@ else if (this.securePart != null) {\n           numOfSecureParts = 1;          \n         }\n \n-        //this.logger.fine(\"hitesh sendbytes forServer_SecurityPart \" + numOfSecureParts);\n         int totalPartLen = 0;\n         for (int i=0;i<this.numberOfParts;i++){\n           Part part = this.partsList[i];\n@@ -740,7 +678,7 @@ private void readHeaderAndPayload()\n     final int len = cb.getInt();\n     final int numParts = cb.getInt();\n     final int txid = cb.getInt();\n-    byte early = cb.get();\n+    byte bits = cb.get();\n     cb.clear();\n \n     if (!MessageType.validate(type)) {\n@@ -783,8 +721,8 @@ private void readHeaderAndPayload()\n         } // for\n     }\n     if (len > 0) {\n-      if (this.MAX_DATA > 0 && len > this.MAX_DATA) {\n-        throw new IOException(LocalizedStrings.Message_MESSAGE_SIZE_0_EXCEEDED_MAX_LIMIT_OF_1.toLocalizedString(new Object[] {Integer.valueOf(len), Integer.valueOf(this.MAX_DATA)}));\n+      if (this.maxIncomingMessageLength > 0 && len > this.maxIncomingMessageLength) {\n+        throw new IOException(LocalizedStrings.Message_MESSAGE_SIZE_0_EXCEEDED_MAX_LIMIT_OF_1.toLocalizedString(new Object[] {Integer.valueOf(len), Integer.valueOf(this.maxIncomingMessageLength)}));\n       }\n       if (this.dataLimiter != null) {\n         for (;;) {\n@@ -825,13 +763,12 @@ private void readHeaderAndPayload()\n       this.payloadLength = len; // makes sure payloadLength gets set now so we will dec on clear\n     }\n     \n-    this.isRetry = (early & MESSAGE_IS_RETRY) != 0;\n-    early = (byte)(early & MESSAGE_IS_RETRY_MASK);\n-\n-    //TODO:hitesh it was below ??\n-    this.earlyAck = early;\n+    this.isRetry = (bits & MESSAGE_IS_RETRY) != 0;\n+    bits = (byte)(bits & MESSAGE_IS_RETRY_MASK);\n+    this.flags = bits;\n+    // TODO why is the msgType set twice, here and after reading the payload fields?\n     this.msgType = type;\n-    //this.logger.fine(\"Before reading message parts, earlyAck already read as \" + this.earlyAck);\n+\n     readPayloadFields(numParts, len);\n \n     // Set the header and payload fields only after receiving all the\n@@ -841,43 +778,13 @@ private void readHeaderAndPayload()\n     this.payloadLength = len;\n     // this.numberOfParts = numParts;  Already set in setPayloadFields via setNumberOfParts\n     this.transactionId = txid;\n-    this.earlyAck = early;\n+    this.flags = bits;\n     if (this.sc != null) {\n       // Keep track of the fact that a message is being processed.\n       this.sc.updateProcessingMessage();\n     }\n   }\n \n-//   static final int MAX_PART_BUFFERS = 2;\n-//   static final int MIN_PART_BUFFER_SIZE = 999;\n-//   static final int MAX_PART_BUFFER_SIZE = 1024*1024*11;\n-//   static ArrayList partBuffers = new ArrayList(2);\n-//   static int partBufferIdx = 0;\n-//   static {\n-//     for (int i=0; i < MAX_PART_BUFFERS; i++) {\n-//       partBuffers.add(i, null);\n-//     }\n-//   }\n-\n-//   private static synchronized byte[] getPartBuffer(int size) {\n-//     byte[] result;\n-//     synchronized (partBuffers) {\n-//       result = (byte[])partBuffers.get(partBufferIdx);\n-//       if (result == null) {\n-//         result = new byte[size];\n-//         partBuffers.add(partBufferIdx, result);\n-//       } else if (result.length != size) {\n-//         // can't use a cached one\n-//         return null;\n-//       }\n-//       partBufferIdx++;\n-//       if (partBufferIdx >= MAX_PART_BUFFERS) {\n-//         partBufferIdx = 0;\n-//       }\n-//     }\n-//     return result;\n-//   }\n-\n   protected void readPayloadFields(final int numParts, final int len)\n   throws IOException {\n     //TODO:Hitesh\n@@ -912,11 +819,9 @@ protected void readPayloadFields(final int numParts, final int len)\n \n     int readSecurePart = 0;\n     //TODO:Hitesh look if securePart can be cached here\n-    //this.logger.fine(\"readPayloadFields() early ack = \" + this.earlyAck);\n     readSecurePart = checkAndSetSecurityPart();\n     \n     int bytesRemaining = len;\n-    //this.logger.fine(\"readPayloadFields() : numParts=\" + numParts + \" len=\" + len);\n     for (int i = 0; ((i < numParts + readSecurePart) || ((readSecurePart == 1) && (cb\n         .remaining() > 0))); i++) {\n       int bytesReadThisTime = readPartChunk(bytesRemaining);\n@@ -934,14 +839,8 @@ protected void readPayloadFields(final int numParts, final int len)\n       int partLen = cb.getInt();\n       byte partType = cb.get();\n       byte[] partBytes = null;\n-//      this.logger.fine(\"readPayloadFields(): partLen=\" + partLen + \" partType=\" + partType);\n       if (partLen > 0) {\n-//         if (partLen >= MIN_PART_BUFFER_SIZE && partLen <= MAX_PART_BUFFER_SIZE) {\n-//           partBytes = getPartBuffer(partLen);\n-//         }\n-//         if (partBytes == null) {\n-          partBytes = new byte[partLen];\n-//         }\n+        partBytes = new byte[partLen];\n         int alreadyReadBytes = cb.remaining();\n         if (alreadyReadBytes > 0) {\n           if (partLen < alreadyReadBytes) {\n@@ -961,7 +860,6 @@ protected void readPayloadFields(final int numParts, final int len)\n             }\n             cb.limit(bytesThisTime);\n             int res = this.sockCh.read(cb);\n-            //System.out.println(\"DEBUG: part read \" + res + \" bytes commBuffer=\" + cb);\n             if (res != -1) {\n               cb.flip();\n               bytesRemaining -= res;\n@@ -980,7 +878,6 @@ protected void readPayloadFields(final int numParts, final int len)\n               res = this.is.read(partBytes, off, remaining);\n             }\n             catch (SocketTimeoutException e) {\n-//              res = 0;\n               // TODO: add cancellation check\n               throw e;\n             }\n@@ -1002,7 +899,7 @@ protected void readPayloadFields(final int numParts, final int len)\n   }\n \n   protected int checkAndSetSecurityPart() {\n-    if ((this.earlyAck | MESSAGE_HAS_SECURE_PART) == this.earlyAck) {\n+    if ((this.flags | MESSAGE_HAS_SECURE_PART) == this.flags) {\n       this.securePart = new Part();\n       return 1;\n     }\n@@ -1018,7 +915,6 @@ protected int checkAndSetSecurityPart() {\n    */\n   private int readPartChunk(int bytesRemaining) throws IOException {\n     final ByteBuffer cb = getCommBuffer();\n-    //this.logger.info(\"DEBUG: commBuffer.remaining=\" + cb.remaining());\n     if (cb.remaining() >= PART_HEADER_SIZE) {\n       // we already have the next part header in commBuffer so just return\n       return 0;\n@@ -1042,7 +938,6 @@ private int readPartChunk(int bytesRemaining) throws IOException {\n       }\n       while (remaining > 0) {\n         int res = this.sockCh.read(cb);\n-        //System.out.println(\"DEBUG: partChunk read \" + res + \" bytes commBuffer=\" + cb);\n         if (res != -1) {\n           remaining -= res;\n           bytesRead += res;\n@@ -1067,7 +962,6 @@ private int readPartChunk(int bytesRemaining) throws IOException {\n           res = this.is.read(cb.array(), pos, bytesToRead);\n         }\n         catch (SocketTimeoutException e) {\n-//          res = 0;\n           // TODO add a cancellation check\n           throw e;\n         }\n@@ -1097,6 +991,26 @@ public void clearParts() {\n     }\n     this.currentPart=0;\n   }\n+\n+  @Override\n+  public String toString() {\n+    StringBuffer sb = new StringBuffer();\n+    sb.append(\"type=\").append(MessageType.getString(msgType));\n+    sb.append(\"; payloadLength=\").append(payloadLength);\n+    sb.append(\"; numberOfParts=\").append(numberOfParts);\n+    sb.append(\"; transactionId=\").append(transactionId);\n+    sb.append(\"; currentPart=\").append(currentPart);\n+    sb.append(\"; messageModified=\").append(messageModified);\n+    sb.append(\"; flags=\").append(Integer.toHexString(flags));\n+    for (int i = 0; i < numberOfParts; i ++) {\n+      sb.append(\"; part[\").append(i).append(\"]={\");\n+      sb.append(this.partsList[i].toString());\n+      sb.append(\"}\");\n+    }\n+    return sb.toString();\n+  }\n+\n+  \n   public void setComms(ServerConnection sc, Socket socket, ByteBuffer bb, MessageStats msgStats) throws IOException {\n     this.sc = sc;\n     setComms(socket, bb, msgStats);\n@@ -1174,17 +1088,13 @@ public void recv()\n       throw new IOException(LocalizedStrings.Message_DEAD_CONNECTION.toLocalizedString());\n     }\n   }\n-  public void recv(ServerConnection sc, int MAX_DATA, Semaphore dataLimiter, int MAX_MSGS, Semaphore msgLimiter)\n+  public void recv(ServerConnection sc, int maxMessageLength, Semaphore dataLimiter, Semaphore msgLimiter)\n   throws IOException {\n     this.sc = sc;\n-    this.MAX_DATA = MAX_DATA;\n+    this.maxIncomingMessageLength = maxMessageLength;\n     this.dataLimiter = dataLimiter;\n-//    this.MAX_MSGS = MAX_MSGS;\n     this.msgLimiter = msgLimiter;\n     recv();\n   }\n \n-  public boolean canStartRemoteTransaction() {\n-    return true;\n-  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Message.java",
                "sha": "4bfd44b9bdce5f747934798b7d9c78d2027ef7df",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Part.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Part.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 7,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Part.java",
                "patch": "@@ -69,10 +69,6 @@ public void init(byte[] v, byte tc) {\n     this.typeCode = tc;\n   }\n \n-//   public void init(HeapDataOutputStream os, byte typeCode) {\n-//     this.part = os;\n-//     this.typeCode = typeCode;\n-//   }\n \n   public void clear() {\n     this.part = null;\n@@ -97,9 +93,7 @@ public boolean isObject() {\n   public boolean isBytes() {\n     return this.typeCode == BYTE_CODE || this.typeCode == EMPTY_BYTEARRAY_CODE;\n   }\n-//   public boolean isString() {\n-//     return this.typeCode == STRING_CODE;\n-//   }\n+\n   public void setPartState(byte[] b, boolean isObject) {\n     if (isObject) {\n       this.typeCode = OBJECT_CODE;\n@@ -111,6 +105,7 @@ public void setPartState(byte[] b, boolean isObject) {\n     }\n     this.part = b;\n   }\n+  \n   public void setPartState(HeapDataOutputStream os, boolean isObject) {\n     if (isObject) {\n       this.typeCode = OBJECT_CODE;",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/Part.java",
                "sha": "f5f63269f3564f3eda26c21f845faa3cd331ba72",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/test/java/com/gemstone/gemfire/distributed/LocatorDUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/distributed/LocatorDUnitTest.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 0,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/distributed/LocatorDUnitTest.java",
                "patch": "@@ -1091,6 +1091,8 @@ public void testNoLocator() {\n    * members of the distributed system join it.  This ensures that\n    * members start up okay, and that handling of a stopped locator\n    * is correct.\n+   * <p>The locator is then restarted and is shown to take over the\n+   * role of membership coordinator.\n    */\n   public void testOneLocator() throws Exception {\n     disconnectAllFromDS();",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/test/java/com/gemstone/gemfire/distributed/LocatorDUnitTest.java",
                "sha": "3c6a90ad970e2bab194d055a5c61dbc0f2cd535d",
                "status": "modified"
            },
            {
                "additions": 75,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/MessageJUnitTest.java",
                "changes": 75,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/MessageJUnitTest.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 0,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/MessageJUnitTest.java",
                "patch": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.gemstone.gemfire.internal.cache.tier.sockets;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Matchers.*;\n+import static org.mockito.Mockito.*;\n+\n+import java.net.Socket;\n+import java.nio.ByteBuffer;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import com.gemstone.gemfire.internal.Version;\n+import com.gemstone.gemfire.internal.offheap.HeapByteBufferMemoryChunkJUnitTest;\n+import com.gemstone.gemfire.test.junit.categories.UnitTest;\n+\n+@Category(UnitTest.class)\n+public class MessageJUnitTest {\n+\n+  Message message;\n+  Socket mockSocket;\n+  MessageStats mockStats;\n+  ByteBuffer msgBuffer;\n+  \n+  @Before\n+  public void setUp() throws Exception {\n+    mockSocket = mock(Socket.class);\n+    message = new Message(5, Version.CURRENT);\n+    assertEquals(5, message.getNumberOfParts());\n+    mockStats = mock(MessageStats.class);\n+    msgBuffer = ByteBuffer.allocate(1000);\n+    message.setComms(mockSocket, msgBuffer, mockStats);\n+  }\n+\n+  @Test\n+  public void clearDoesNotThrowNPE() throws Exception{\n+    // unsetComms clears the message's ByteBuffer, which was causing an NPE during shutdown\n+    // when clear() was invoked\n+    message.unsetComms();\n+    message.clear();\n+  }\n+  \n+  @Test\n+  public void numberOfPartsIsAdjusted() {\n+    int numParts = message.getNumberOfParts();\n+    message.setNumberOfParts(2*numParts);\n+    assertEquals(2*numParts, message.getNumberOfParts());\n+    message.addBytesPart(new byte[1]);\n+    message.addIntPart(2);\n+    message.addLongPart(3);\n+    message.addObjPart(\"4\");\n+    message.addStringPart(\"5\");\n+    assertEquals(5, message.getNextPartNumber());\n+  }\n+  \n+  // TODO many more tests are needed\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-core/src/test/java/com/gemstone/gemfire/internal/cache/tier/sockets/MessageJUnitTest.java",
                "sha": "3dc5a7dc5b057a82b84fe42097996599fd447604",
                "status": "added"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-wan/src/main/java/com/gemstone/gemfire/cache/client/internal/GatewaySenderBatchOp.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-wan/src/main/java/com/gemstone/gemfire/cache/client/internal/GatewaySenderBatchOp.java?ref=ab9cedf8f253e3c049138df282352dd28c0b252a",
                "deletions": 1,
                "filename": "gemfire-wan/src/main/java/com/gemstone/gemfire/cache/client/internal/GatewaySenderBatchOp.java",
                "patch": "@@ -241,7 +241,7 @@ protected boolean needsUserId() {\n \n     @Override\n     protected void sendMessage(Connection cnx) throws Exception {\n-      getMessage().setEarlyAck((byte)(getMessage().getEarlyAckByte() & Message.MESSAGE_HAS_SECURE_PART));\n+      getMessage().clearMessageHasSecurePartFlag();\n       getMessage().send(false);\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ab9cedf8f253e3c049138df282352dd28c0b252a/gemfire-wan/src/main/java/com/gemstone/gemfire/cache/client/internal/GatewaySenderBatchOp.java",
                "sha": "564591d874d7558339adcadd33c6c168a6a01db3",
                "status": "modified"
            }
        ],
        "message": "GEODE-981: NPE in Message.clear()\n\nThis fixes the NPE and adds a unit test for it.  I also did some cleanup\nof Message, removing unused methods and old commented out code and\nchanging the earlyAck byte to be \"flags\" and not allow external\nmanipulation of the byte's bits.",
        "parent": "https://github.com/apache/geode/commit/75d6a8b68fc07248cfd7450b44aa0678a0cd924e",
        "patched_files": [
            "PingOp.java",
            "AbstractOp.java",
            "RollbackOp.java",
            "GetClientPartitionAttributesOp.java",
            "GetClientPRMetaDataOp.java",
            "ReadyForEventsOp.java",
            "Message.java",
            "TXFailoverOp.java",
            "ProxyCacheCloseOp.java",
            "CloseConnectionOp.java",
            "PrimaryAckOp.java",
            "GetPDXTypesOp.java",
            "TXSynchronizationOp.java",
            "TXManagerImpl.java",
            "AuthenticateUserOp.java",
            "RegisterInstantiatorsOp.java",
            "RegisterDataSerializersOp.java",
            "GetEventValueOp.java",
            "GetPDXEnumsOp.java",
            "BaseCommand.java",
            "AddPDXEnumOp.java",
            "GatewaySenderBatchOp.java",
            "GetPDXEnumByIdOp.java",
            "AddPDXTypeOp.java",
            "CommitOp.java",
            "GetPDXTypeByIdOp.java",
            "MakePrimaryOp.java",
            "GetPDXIdForEnumOp.java",
            "Part.java",
            "SizeOp.java",
            "GetFunctionAttributeOp.java",
            "GetPDXIdForTypeOp.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PartTest.java",
            "MessageJUnitTest.java",
            "LocatorDUnitTest.java",
            "TXFailoverOpTest.java",
            "AbstractOpTest.java",
            "TXManagerImplTest.java"
        ]
    },
    "geode_b31ff34": {
        "bug_id": "geode_b31ff34",
        "commit": "https://github.com/apache/geode/commit/b31ff3404fc8821a85a05735c19a4f0b2fb9111e",
        "file": [
            {
                "additions": 516,
                "blob_url": "https://github.com/apache/geode/blob/b31ff3404fc8821a85a05735c19a4f0b2fb9111e/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClientServerReadConflictTransactionDistributedTest.java",
                "changes": 516,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClientServerReadConflictTransactionDistributedTest.java?ref=b31ff3404fc8821a85a05735c19a4f0b2fb9111e",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClientServerReadConflictTransactionDistributedTest.java",
                "patch": "@@ -0,0 +1,516 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.getTimeout;\n+import static org.apache.geode.test.dunit.Invoke.invokeInEveryVM;\n+import static org.apache.geode.test.dunit.VM.getHostName;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.catchThrowable;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.CacheTransactionManager;\n+import org.apache.geode.cache.CommitConflictException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.TransactionId;\n+import org.apache.geode.cache.client.ClientRegionFactory;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.client.PoolFactory;\n+import org.apache.geode.cache.client.PoolManager;\n+import org.apache.geode.cache.client.internal.PoolImpl;\n+import org.apache.geode.cache.server.CacheServer;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.ClientCacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRestoreSystemProperties;\n+import org.apache.geode.test.junit.rules.serializable.SerializableTestName;\n+\n+public class ClientServerReadConflictTransactionDistributedTest implements Serializable {\n+  private static volatile DUnitBlackboard blackboard;\n+  private static final int key1 = 1;\n+  private static final int key2 = 2;\n+  private static final int key3 = 3;\n+  private static final String value1 = \"value1\";\n+  private static final String value2 = \"value2\";\n+  private static final String value3 = \"value3\";\n+  private static final String newValue1 = \"newValue1\";\n+  private static final String newValue3 = \"newValue3\";\n+  private static final long TIMEOUT_MILLIS = getTimeout().getValueInMS();\n+  private static final String allowReadTransactionCommitToProceed =\n+      \"allowReadTransactionCommitToProceed\";\n+  private static final String allowSecondTransactionToProceed = \"allowSecondTransactionToProceed\";\n+\n+  private String hostName;\n+  private String uniqueName;\n+  private String regionName;\n+  private String regionName2;\n+  private VM server1;\n+  private VM server2;\n+  private VM client1;\n+  private VM client2;\n+  private int port1;\n+  private int port2;\n+\n+  @Rule\n+  public DistributedRestoreSystemProperties restoreSystemProperties =\n+      new DistributedRestoreSystemProperties();\n+\n+  @Rule\n+  public CacheRule cacheRule = new CacheRule();\n+\n+  @Rule\n+  public ClientCacheRule clientCacheRule = new ClientCacheRule();\n+\n+  @Rule\n+  public SerializableTestName testName = new SerializableTestName();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    invokeInEveryVM(() -> {\n+      System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"detectReadConflicts\", \"true\");\n+    });\n+    server1 = getVM(0);\n+    server2 = getVM(1);\n+    client1 = getVM(2);\n+    client2 = getVM(3);\n+\n+    hostName = getHostName();\n+    uniqueName = getClass().getSimpleName() + \"_\" + testName.getMethodName();\n+    regionName = uniqueName + \"_region\";\n+    regionName2 = uniqueName + \"_region2\";\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    invokeInEveryVM(() -> {\n+      if (blackboard != null) {\n+        blackboard.clearGate(allowReadTransactionCommitToProceed);\n+        blackboard.clearGate(allowSecondTransactionToProceed);\n+      }\n+    });\n+  }\n+\n+  @Test\n+  public void readTransactionCanBlockWriteTransactionOnPartitionedRegion() {\n+    createPRRegionOnServers();\n+    createRegionsOnClient(false);\n+\n+    TransactionId readTXId = client1.invoke(() -> doReadTransaction());\n+    server1.invoke(() -> setAfterReservationForReadTransaction());\n+    client1.invokeAsync(() -> commitReadTransaction(readTXId));\n+\n+    client2.invoke(() -> doPutOnReadKeyTransaction(true));\n+    client1.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client2.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client1.invoke(() -> verifyClientResults(regionName, key1, value1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, value1));\n+\n+  }\n+\n+  @Test\n+  public void readTransactionDoesNotBlockReadTransactionOnPartitionedRegion() {\n+    createPRRegionOnServers();\n+    createRegionsOnClient(false);\n+\n+    TransactionId readTXId = client1.invoke(() -> doReadTransaction());\n+    server1.invoke(() -> setAfterReservationForReadTransaction());\n+    client1.invokeAsync(() -> commitReadTransaction(readTXId));\n+\n+    client2.invoke(() -> doSecondReadTransaction());\n+    client1.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client2.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client1.invoke(() -> verifyClientResults(regionName, key1, value1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, value1));\n+  }\n+\n+  private void createPRRegionOnServers() {\n+    port1 = server1.invoke(() -> createServerPRRegion(2));\n+    server1.invoke(() -> {\n+      // make sure key1 is on server1.\n+      cacheRule.getCache().getRegion(regionName).put(key1, value1);\n+    });\n+    port2 = server2.invoke(() -> createServerPRRegion(2));\n+    server2.invoke(() -> {\n+      cacheRule.getCache().getRegion(regionName).put(key2, value2);\n+      cacheRule.getCache().getRegion(regionName).put(key3, value3);\n+    });\n+  }\n+\n+  private void createRegionsOnClient(boolean createBothRegions) {\n+    client1.invoke(() -> createClientRegions(createBothRegions, port1));\n+    client2.invoke(() -> createClientRegions(createBothRegions, port2));\n+\n+    client1.invoke(() -> getAndVerifyOriginalData());\n+    client2.invoke(() -> getAndVerifyOriginalData());\n+  }\n+\n+  private int createServerPRRegion(int totalNumBuckets) throws Exception {\n+    PartitionAttributesFactory factory = new PartitionAttributesFactory();\n+    factory.setTotalNumBuckets(totalNumBuckets);\n+    PartitionAttributes partitionAttributes = factory.create();\n+    cacheRule.getOrCreateCache().createRegionFactory(RegionShortcut.PARTITION)\n+        .setPartitionAttributes(partitionAttributes).create(regionName);\n+\n+    CacheServer server = cacheRule.getCache().addCacheServer();\n+    server.setPort(0);\n+    server.start();\n+    return server.getPort();\n+  }\n+\n+  private void createClientRegions(boolean createBothRegions, int... ports) {\n+    clientCacheRule.createClientCache();\n+\n+    PoolImpl pool;\n+    PoolFactory factory = PoolManager.createFactory();\n+    for (int port : ports) {\n+      factory.addServer(hostName, port);\n+    }\n+    factory.setSubscriptionEnabled(true).setReadTimeout(12000).setSocketBufferSize(1000);\n+\n+    pool = (PoolImpl) factory.create(uniqueName);\n+\n+    ClientRegionFactory crf =\n+        clientCacheRule.getClientCache().createClientRegionFactory(ClientRegionShortcut.LOCAL);\n+    crf.setPoolName(pool.getName());\n+    Region region = crf.create(regionName);\n+    region.registerInterest(\"ALL_KEYS\");\n+    if (createBothRegions) {\n+      Region region2 = crf.create(regionName2);\n+      region2.registerInterest(\"ALL_KEYS\");\n+    }\n+  }\n+\n+  private void getAndVerifyOriginalData() {\n+    assertThat(clientCacheRule.getClientCache().getRegion(regionName).get(key1)).isEqualTo(value1);\n+    assertThat(clientCacheRule.getClientCache().getRegion(regionName).get(key2)).isEqualTo(value2);\n+    assertThat(clientCacheRule.getClientCache().getRegion(regionName).get(key3)).isEqualTo(value3);\n+  }\n+\n+  private TransactionId doReadTransaction() {\n+    Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+    TXManagerImpl txManager =\n+        (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+    txManager.begin();\n+    assertThat(region.get(key1)).isEqualTo(value1);\n+    region.put(key3, newValue3);\n+    return txManager.suspend();\n+  }\n+\n+  private void setAfterReservationForReadTransaction() {\n+    TXManagerImpl txManager = cacheRule.getCache().getTxManager();\n+    ArrayList<TXId> txIds = txManager.getHostedTxIds();\n+    TXStateProxyImpl txStateProxy = (TXStateProxyImpl) txManager.getHostedTXState(txIds.get(0));\n+    TXState txState = (TXState) txStateProxy.getRealDeal(null, null);\n+    txState.setAfterReservation(() -> readTransactionAfterReservation());\n+  }\n+\n+  private void readTransactionAfterReservation() {\n+    getBlackboard().signalGate(allowSecondTransactionToProceed);\n+    try {\n+      getBlackboard().waitForGate(allowReadTransactionCommitToProceed, TIMEOUT_MILLIS,\n+          MILLISECONDS);\n+    } catch (TimeoutException | InterruptedException e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  private void commitReadTransaction(TransactionId readTXId) {\n+    CacheTransactionManager txManager =\n+        clientCacheRule.getClientCache().getCacheTransactionManager();\n+    txManager.resume(readTXId);\n+    txManager.commit();\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private void verifyClientResults(String regionName, int key, String expectedValue) {\n+    Region region = clientCacheRule.getClientCache().getRegion(regionName);\n+    await(\"Awaiting transaction to be committed\")\n+        .untilAsserted(() -> assertThat(region.get(key)).isEqualTo(expectedValue));\n+  }\n+\n+  private void doSecondReadTransaction() {\n+    try {\n+      getBlackboard().waitForGate(allowSecondTransactionToProceed, TIMEOUT_MILLIS, MILLISECONDS);\n+      Region region = clientCacheRule.getClientCache().getRegion(regionName);\n+      TXManagerImpl txManager =\n+          (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+      txManager.begin();\n+      assertThat(region.get(key1)).isEqualTo(value1);\n+      txManager.commit();\n+    } catch (TimeoutException | InterruptedException e) {\n+      throw new RuntimeException(e);\n+    } finally {\n+      getBlackboard().signalGate(allowReadTransactionCommitToProceed);\n+    }\n+  }\n+\n+  @Test\n+  public void readConflictsTransactionCanDetectStateChangeOnPartitionedRegion() {\n+    createPRRegionOnServers();\n+    createRegionsOnClient(false);\n+\n+    client2.invokeAsync(() -> doPutTransaction());\n+    client1.invoke(() -> doReadKeyDetectStateChangeTransaction());\n+    client1.invoke(() -> verifyClientResults(regionName, key1, newValue1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, newValue1));\n+  }\n+\n+  private void doPutTransaction() {\n+    try {\n+      getBlackboard().waitForGate(allowSecondTransactionToProceed, TIMEOUT_MILLIS, MILLISECONDS);\n+      Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+      TXManagerImpl txManager =\n+          (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+      txManager.begin();\n+      region.put(key1, newValue1);\n+      txManager.commit();\n+    } catch (TimeoutException | InterruptedException e) {\n+      throw new RuntimeException(e);\n+    } finally {\n+      getBlackboard().signalGate(allowReadTransactionCommitToProceed);\n+    }\n+  }\n+\n+  private void doReadKeyDetectStateChangeTransaction() {\n+    try {\n+      Region region = clientCacheRule.getClientCache().getRegion(regionName);\n+      TXManagerImpl txManager =\n+          (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+      txManager.begin();\n+      assertThat(region.get(key1)).isEqualTo(value1);\n+      getBlackboard().signalGate(allowSecondTransactionToProceed);\n+      getBlackboard().waitForGate(allowReadTransactionCommitToProceed, TIMEOUT_MILLIS,\n+          MILLISECONDS);\n+      Throwable thrown = catchThrowable(() -> txManager.commit());\n+      assertThat(thrown).isInstanceOf(CommitConflictException.class);\n+    } catch (TimeoutException | InterruptedException e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  @Test\n+  public void readTransactionCanBlockWriteTransactionOnReplicateRegion() {\n+    createReplicateRegionOnServers(regionName);\n+    createRegionsOnClient(false);\n+\n+    TransactionId readTXId = client1.invoke(() -> doReadTransaction());\n+    server1.invoke(() -> setAfterReservationForReadTransaction());\n+    client1.invokeAsync(() -> commitReadTransaction(readTXId));\n+\n+    client2.invoke(() -> doPutOnReadKeyTransaction(true));\n+    client1.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client2.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client1.invoke(() -> verifyClientResults(regionName, key1, value1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, value1));\n+  }\n+\n+  private void createReplicateRegionOnServers(String name) {\n+    port1 = server1.invoke(() -> createServerReplicateRegion(name));\n+    server1.invoke(() -> {\n+      // make sure key1 is on server1.\n+      cacheRule.getCache().getRegion(name).put(key1, value1);\n+    });\n+    port2 = server2.invoke(() -> createServerReplicateRegion(name));\n+    server2.invoke(() -> {\n+      cacheRule.getCache().getRegion(name).put(key2, value2);\n+      cacheRule.getCache().getRegion(name).put(key3, value3);\n+    });\n+  }\n+\n+  private int createServerReplicateRegion(String name) throws Exception {\n+    cacheRule.getOrCreateCache().createRegionFactory(RegionShortcut.REPLICATE).create(name);\n+\n+    CacheServer server = cacheRule.getCache().addCacheServer();\n+    server.setPort(0);\n+    server.start();\n+    return server.getPort();\n+  }\n+\n+  @Test\n+  public void readTransactionDoesNotBlockReadTransactionOnReplicateRegion() {\n+    createReplicateRegionOnServers(regionName);\n+    createRegionsOnClient(false);\n+\n+    TransactionId readTXId = client1.invoke(() -> doReadTransaction());\n+    server1.invoke(() -> setAfterReservationForReadTransaction());\n+    client1.invokeAsync(() -> commitReadTransaction(readTXId));\n+\n+    client2.invoke(() -> doSecondReadTransaction());\n+    client1.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client2.invoke(() -> verifyClientResults(regionName, key3, newValue3));\n+    client1.invoke(() -> verifyClientResults(regionName, key1, value1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, value1));\n+  }\n+\n+  @Test\n+  public void readConflictsTransactionCanDetectStateChangeOnReplicateRegion() {\n+    createReplicateRegionOnServers(regionName);\n+    createRegionsOnClient(false);\n+\n+    client2.invokeAsync(() -> doPutTransaction());\n+    client1.invoke(() -> doReadKeyDetectStateChangeTransaction());\n+    client1.invoke(() -> verifyClientResults(regionName, key1, newValue1));\n+    client2.invoke(() -> verifyClientResults(regionName, key1, newValue1));\n+  }\n+\n+  @Test\n+  public void transactionsReleaseLocksAfterCommitComplete() {\n+    createPRRegionOnServers();\n+    createReplicateRegionOnServers(regionName2);\n+    createRegionsOnClient(true);\n+\n+    client2.invoke(() -> addData());\n+\n+    TransactionId readTXId = client1.invoke(() -> doReadKeysTransaction());\n+    server1.invoke(() -> setAfterReservationForReadTransaction());\n+    client1.invokeAsync(() -> commitReadTransaction(readTXId));\n+\n+    client2.invoke(() -> doPutOnReadKeyTransaction(false));\n+    client2.invoke(() -> doFailedPutOnReadKeyTransactions());\n+    client2.invoke(() -> doSuccessfulPutTransactions());\n+    client2.invoke(() -> {\n+      getBlackboard().signalGate(allowReadTransactionCommitToProceed);\n+    });\n+\n+    client1.invoke(() -> verifyData());\n+    client2.invoke(() -> verifyData());\n+  }\n+\n+  private void addData() {\n+    Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+    Region<Integer, String> region2 = clientCacheRule.getClientCache().getRegion(regionName2);\n+    for (int i = 0; i <= 10; i++) {\n+      region.put(i, \"value\" + i);\n+      region2.put(i, \"value\" + i);\n+    }\n+  }\n+\n+  private TransactionId doReadKeysTransaction() {\n+    Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+    Region<Integer, String> region2 = clientCacheRule.getClientCache().getRegion(regionName2);\n+    TXManagerImpl txManager =\n+        (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+    txManager.begin();\n+    assertThat(region.get(key1)).isEqualTo(value1);\n+    assertThat(region2.get(key1)).isEqualTo(value1);\n+    return txManager.suspend();\n+  }\n+\n+  private void doPutOnReadKeyTransaction(boolean doSignal) {\n+    try {\n+      getBlackboard().waitForGate(allowSecondTransactionToProceed, TIMEOUT_MILLIS, MILLISECONDS);\n+      Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+      TXManagerImpl txManager =\n+          (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+      txManager.begin();\n+      region.put(key1, newValue1);\n+      Throwable thrown = catchThrowable(() -> txManager.commit());\n+      assertThat(thrown).isInstanceOf(CommitConflictException.class);\n+    } catch (TimeoutException | InterruptedException e) {\n+      throw new RuntimeException(e);\n+    } finally {\n+      if (doSignal) {\n+        getBlackboard().signalGate(allowReadTransactionCommitToProceed);\n+      }\n+    }\n+  }\n+\n+  private void doFailedPutOnReadKeyTransactions() {\n+    Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+    Region<Integer, String> region2 = clientCacheRule.getClientCache().getRegion(regionName2);\n+    TXManagerImpl txManager =\n+        (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+    for (int i = 0; i <= 10; i++) {\n+      txManager.begin();\n+      if (i % 2 != 0) {\n+        // first key on bucket 1 so transaction hosted on server1\n+        region.put(i, \"failedValue\" + i);\n+        if (i < 9) {\n+          assertThat(region.get(i + 2)).isEqualTo(\"value\" + (i + 2));\n+          assertThat(region2.get(i + 1)).isEqualTo(\"value\" + (i + 1));\n+        }\n+        region2.put(i, \"failedValue\" + i);\n+        // will get conflict during commit on partitioned region key held by the read transaction\n+        region.put(key1, newValue1);\n+        region2.put(i + 1, \"failedValue\" + (i + 1));\n+      } else {\n+        // transaction hosted on server2.\n+        region.put(i, \"failedValue\" + i);\n+        if (i < 9) {\n+          assertThat(region.get(i + 2)).isEqualTo(\"value\" + (i + 2));\n+          assertThat(region2.get(i + 1)).isEqualTo(\"value\" + (i + 1));\n+        }\n+        region2.put(i, \"failedValue\" + i);\n+        // will get conflict during commit on replicate region key held by the read transaction\n+        region2.put(key1, newValue1);\n+        region2.put(i + 1, \"failedValue\" + (i + 1));\n+      }\n+      Throwable thrown = catchThrowable(() -> txManager.commit());\n+      assertThat(thrown).isInstanceOf(CommitConflictException.class);\n+    }\n+  }\n+\n+  private void doSuccessfulPutTransactions() {\n+    Region<Integer, String> region = clientCacheRule.getClientCache().getRegion(regionName);\n+    Region<Integer, String> region2 = clientCacheRule.getClientCache().getRegion(regionName2);\n+    TXManagerImpl txManager =\n+        (TXManagerImpl) clientCacheRule.getClientCache().getCacheTransactionManager();\n+    for (int i = 0; i <= 10; i++) {\n+      txManager.begin();\n+      if (i != 1) {\n+        region.put(i, \"newValue\" + i);\n+        region2.put(i, \"newValue\" + i);\n+      }\n+      if (i < 10) {\n+        assertThat(region2.get(i + 1)).isEqualTo(\"value\" + (i + 1));\n+      }\n+      txManager.commit();\n+    }\n+  }\n+\n+  private void verifyData() {\n+    for (int i = 0; i <= 10; i++) {\n+      if (i == 1) {\n+        verifyClientResults(regionName, key1, value1);\n+        verifyClientResults(regionName2, key1, value1);\n+      } else {\n+        verifyClientResults(regionName, i, \"newValue\" + i);\n+        verifyClientResults(regionName2, i, \"newValue\" + i);\n+      }\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/b31ff3404fc8821a85a05735c19a4f0b2fb9111e/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/ClientServerReadConflictTransactionDistributedTest.java",
                "sha": "0e62f9e5a8e5f28e70ce282ca74a6857fa2fa235",
                "status": "added"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/b31ff3404fc8821a85a05735c19a4f0b2fb9111e/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java?ref=b31ff3404fc8821a85a05735c19a4f0b2fb9111e",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "patch": "@@ -1338,6 +1338,10 @@ public FilterRoutingInfo fillInInterestRoutingInfo(CacheEvent event, Profile[] p\n         continue;\n       }\n \n+      if (event.getOperation() == null) {\n+        continue;\n+      }\n+\n       if (event.getOperation().isEntry()) {\n         EntryEvent entryEvent = (EntryEvent) event;\n         if (pf.allKeyClientsInv != null || pf.keysOfInterestInv != null",
                "raw_url": "https://github.com/apache/geode/raw/b31ff3404fc8821a85a05735c19a4f0b2fb9111e/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "sha": "b0d8b453e21e58f0cb62e37d1bac4c7c13576035",
                "status": "modified"
            }
        ],
        "message": "GEODE-6955: Fix a NullPointerException. (#3794)\n\n* In transaction with detectReadConflicts enabled, filter information on read locked\r\n   keys are not needed.\r\n * Add dunit test cases with detectReadConflicts enabled.",
        "parent": "https://github.com/apache/geode/commit/07032b448befc0b2820abba52056f69c20b0bdd4",
        "patched_files": [
            "FilterProfile.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ClientServerReadConflictTransactionDistributedTest.java"
        ]
    },
    "geode_b40303d": {
        "bug_id": "geode_b40303d",
        "commit": "https://github.com/apache/geode/commit/b40303ddfdaa428321ed541805abb62d4c68c461",
        "file": [
            {
                "additions": 86,
                "blob_url": "https://github.com/apache/geode/blob/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PersistentRegionRecoveryDUnitTest.java",
                "changes": 86,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PersistentRegionRecoveryDUnitTest.java?ref=b40303ddfdaa428321ed541805abb62d4c68c461",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PersistentRegionRecoveryDUnitTest.java",
                "patch": "@@ -29,6 +29,7 @@\n import org.junit.Rule;\n import org.junit.Test;\n \n+import org.apache.geode.cache.DiskStore;\n import org.apache.geode.cache.DiskStoreFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionFactory;\n@@ -409,6 +410,91 @@ public void testRecoveryFromBackupOfAsyncRegionAfterShutdownAfterGIIAndBeforeCrf\n     });\n   }\n \n+  @Test\n+  public void testRecoveryFromBackupAndRequestingDeltaGiiDoesFullGiiIfTombstoneGCVersionDiffers()\n+      throws Exception {\n+    getBlackboard().initBlackboard();\n+    vm1.invoke(() -> cacheRule.createCache());\n+\n+    vm0.invoke(() -> createAsyncDiskRegion(true));\n+    vm0.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(regionName);\n+      region.put(\"KEY-1\", \"VALUE-1\");\n+      region.put(\"KEY-2\", \"VALUE-2\");\n+      flushAsyncDiskRegion();\n+    });\n+\n+    vm1.invoke(() -> createAsyncDiskRegion(true));\n+    vm1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(regionName);\n+      region.put(\"KEY-1\", \"VALUE-1\");\n+      region.put(\"KEY-2\", \"VALUE-2\");\n+      region.put(\"KEY-1\", \"VALUE-3\");\n+      region.put(\"KEY-2\", \"VALUE-4\");\n+      flushAsyncDiskRegion();\n+    });\n+\n+    vm0.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(regionName);\n+      region.destroy(\"KEY-1\");\n+    });\n+\n+    vm0.bounceForcibly();\n+\n+    vm1.invoke(() -> flushAsyncDiskRegion());\n+\n+    vm1.invoke(() -> {\n+      DistributionMessageObserver.setInstance(\n+          new DistributionMessageObserver() {\n+            @Override\n+            public void beforeProcessMessage(ClusterDistributionManager dm,\n+                DistributionMessage message) {\n+              if (message instanceof InitialImageOperation.RequestImageMessage) {\n+                InitialImageOperation.RequestImageMessage rim =\n+                    (InitialImageOperation.RequestImageMessage) message;\n+                if (rim.regionPath.contains(regionName)) {\n+                  getBlackboard().signalGate(\"GotRegionIIRequest\");\n+                  await().until(() -> getBlackboard().isGateSignaled(\"TombstoneGCDone\"));\n+                }\n+              }\n+            }\n+          });\n+    });\n+\n+    AsyncInvocation vm0createRegion = vm0.invokeAsync(() -> createAsyncDiskRegion(true));\n+\n+    vm1.invoke(() -> {\n+      await().until(() -> getBlackboard().isGateSignaled(\"GotRegionIIRequest\"));\n+      cacheRule.getCache().getTombstoneService().forceBatchExpirationForTests(1);\n+      flushAsyncDiskRegion();\n+      getBlackboard().signalGate(\"TombstoneGCDone\");\n+    });\n+\n+    vm0createRegion.await();\n+\n+    vm1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(regionName);\n+      assertThat(region.get(\"KEY-1\")).isEqualTo(null);\n+      assertThat(region.get(\"KEY-2\")).isEqualTo(\"VALUE-4\");\n+    });\n+\n+    vm0.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(regionName);\n+      assertThat(region.get(\"KEY-1\")).isEqualTo(null);\n+      assertThat(region.get(\"KEY-2\")).isEqualTo(\"VALUE-4\");\n+\n+      CachePerfStats stats = ((LocalRegion) region).getRegionPerfStats();\n+      assertThat(stats.getDeltaGetInitialImagesCompleted()).isEqualTo(0);\n+      assertThat(stats.getGetInitialImagesCompleted()).isEqualTo(1);\n+    });\n+  }\n+\n+  private void flushAsyncDiskRegion() {\n+    for (DiskStore store : cacheRule.getCache().listDiskStoresIncludingRegionOwned()) {\n+      ((DiskStoreImpl) store).forceFlush();\n+    }\n+  }\n+\n   private void createSyncDiskRegion() throws IOException {\n     createDiskRegion(false, false, regionName);\n   }",
                "raw_url": "https://github.com/apache/geode/raw/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PersistentRegionRecoveryDUnitTest.java",
                "sha": "01d3f4b6a28ca4f9139d871c27a34c99c152ce74",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/main/java/org/apache/geode/internal/cache/InitialImageOperation.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InitialImageOperation.java?ref=b40303ddfdaa428321ed541805abb62d4c68c461",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InitialImageOperation.java",
                "patch": "@@ -1596,7 +1596,6 @@ public boolean goWithFullGII(DistributedRegion rgn, RegionVersionVector requeste\n         }\n         return true;\n       }\n-      // TODO GGG: verify GII after UpgradeDiskStore\n       return false;\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/main/java/org/apache/geode/internal/cache/InitialImageOperation.java",
                "sha": "a3e892df34d144d10b7a565170936a692928c582",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/main/java/org/apache/geode/internal/cache/versions/RegionVersionVector.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/versions/RegionVersionVector.java?ref=b40303ddfdaa428321ed541805abb62d4c68c461",
                "deletions": 12,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/versions/RegionVersionVector.java",
                "patch": "@@ -977,7 +977,8 @@ public boolean isNewerThanOrCanFillExceptionsFor(RegionVersionVector<T> other) {\n     return false;\n   }\n \n-  private boolean isGCVersionDominatedByHolder(Long gcVersion, RegionVersionHolder<T> otherHolder) {\n+  private boolean isGCVersionDominatedByOtherHolder(Long gcVersion,\n+      RegionVersionHolder<T> otherHolder) {\n     if (gcVersion == null || gcVersion.longValue() == 0) {\n       return true;\n     } else {\n@@ -987,24 +988,24 @@ private boolean isGCVersionDominatedByHolder(Long gcVersion, RegionVersionHolder\n   }\n \n   /**\n-   * Test to see if this vector's rvvgc has updates that has not seen.\n+   * See if this vector's rvvgc has updates that has not seen.\n    */\n-  public synchronized boolean isRVVGCDominatedBy(RegionVersionVector<T> other) {\n-    if (other.singleMember) {\n+  public synchronized boolean isRVVGCDominatedBy(RegionVersionVector<T> requesterRVV) {\n+    if (requesterRVV.singleMember) {\n       // do the diff for only a single member. This is typically a member that\n       // recently crashed.\n       Map.Entry<T, RegionVersionHolder<T>> entry =\n-          other.memberToVersion.entrySet().iterator().next();\n+          requesterRVV.memberToVersion.entrySet().iterator().next();\n \n       Long gcVersion = this.memberToGCVersion.get(entry.getKey());\n-      return isGCVersionDominatedByHolder(gcVersion, entry.getValue());\n+      return isGCVersionDominatedByOtherHolder(gcVersion, entry.getValue());\n     }\n \n     boolean isDominatedByRemote = true;\n     long localgcversion = this.localGCVersion.get();\n     if (localgcversion > 0) {\n-      RegionVersionHolder<T> otherHolder = other.memberToVersion.get(this.myId);\n-      isDominatedByRemote = isGCVersionDominatedByHolder(localgcversion, otherHolder);\n+      RegionVersionHolder<T> otherHolder = requesterRVV.memberToVersion.get(this.myId);\n+      isDominatedByRemote = isGCVersionDominatedByOtherHolder(localgcversion, otherHolder);\n       if (isDominatedByRemote == false) {\n         return false;\n       }\n@@ -1014,12 +1015,12 @@ public synchronized boolean isRVVGCDominatedBy(RegionVersionVector<T> other) {\n       T mbr = entry.getKey();\n       Long gcVersion = entry.getValue();\n       RegionVersionHolder<T> otherHolder = null;\n-      if (mbr.equals(other.getOwnerId())) {\n-        otherHolder = localExceptions;\n+      if (mbr.equals(requesterRVV.getOwnerId())) {\n+        otherHolder = requesterRVV.localExceptions;\n       } else {\n-        otherHolder = other.memberToVersion.get(mbr);\n+        otherHolder = requesterRVV.memberToVersion.get(mbr);\n       }\n-      isDominatedByRemote = isGCVersionDominatedByHolder(gcVersion, otherHolder);\n+      isDominatedByRemote = isGCVersionDominatedByOtherHolder(gcVersion, otherHolder);\n       if (isDominatedByRemote == false) {\n         return false;\n       }",
                "raw_url": "https://github.com/apache/geode/raw/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/main/java/org/apache/geode/internal/cache/versions/RegionVersionVector.java",
                "sha": "de88adca4eed64c18b2d23b3e13407e47335a31a",
                "status": "modified"
            },
            {
                "additions": 161,
                "blob_url": "https://github.com/apache/geode/blob/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/test/java/org/apache/geode/internal/cache/versions/RegionVersionVectorTest.java",
                "changes": 161,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/versions/RegionVersionVectorTest.java?ref=b40303ddfdaa428321ed541805abb62d4c68c461",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/versions/RegionVersionVectorTest.java",
                "patch": "@@ -684,6 +684,167 @@ public void doesNotHangIfOtherThreadChangedVersion() throws Exception {\n     assertThat(rvv.getVersionForMember(ownerId)).isEqualTo(newVersion);\n   }\n \n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsTrueIfRequesterRvvForLostMemberDominates()\n+      throws Exception {\n+    InternalDistributedMember lostMember = mock(InternalDistributedMember.class);\n+    ConcurrentHashMap<InternalDistributedMember, Long> memberToGcVersion =\n+        new ConcurrentHashMap<>();\n+    memberToGcVersion.put(lostMember, new Long(1) /* lostMemberGcVersion */);\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(lostMember, null,\n+        0, memberToGcVersion, 0, true, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(lostMember);\n+    regionVersionHolder.setVersion(2);\n+    memberToRegionVersionHolder.put(lostMember, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(lostMember, memberToRegionVersionHolder,\n+            0, null, 0, true, null);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isTrue();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsFalseIfRequesterRvvForLostMemberDominates()\n+      throws Exception {\n+    InternalDistributedMember lostMember = mock(InternalDistributedMember.class);\n+    ConcurrentHashMap<InternalDistributedMember, Long> memberToGcVersion =\n+        new ConcurrentHashMap<>();\n+    memberToGcVersion.put(lostMember, new Long(1) /* lostMemberGcVersion */);\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(lostMember, null,\n+        0, memberToGcVersion, 0, true, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(lostMember);\n+    regionVersionHolder.setVersion(0);\n+    memberToRegionVersionHolder.put(lostMember, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(lostMember, memberToRegionVersionHolder,\n+            0, null, 0, true, null);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isFalse();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsFalseIfProviderRvvIsNotPresent()\n+      throws Exception {\n+    final String local = getIPLiteral();\n+    InternalDistributedMember provider = new InternalDistributedMember(local, 101);\n+    InternalDistributedMember requester = new InternalDistributedMember(local, 102);\n+\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(provider, null,\n+        1, null, 1, false, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(provider);\n+    regionVersionHolder.setVersion(0);\n+    // memberToRegionVersionHolder.put(provider, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(requester, memberToRegionVersionHolder,\n+            0, null, 0, false, null);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isFalse();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsFalseIfRequesterRvvDominatesProvider()\n+      throws Exception {\n+    final String local = getIPLiteral();\n+    InternalDistributedMember provider = new InternalDistributedMember(local, 101);\n+    InternalDistributedMember requester = new InternalDistributedMember(local, 102);\n+\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(provider, null,\n+        1, null, 1, false, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(provider);\n+    regionVersionHolder.setVersion(0);\n+    memberToRegionVersionHolder.put(provider, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(requester, memberToRegionVersionHolder,\n+            0, null, 0, false, null);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isFalse();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsTrueIfRequesterRvvDominatesWithNoGcVersion()\n+      throws Exception {\n+    final String local = getIPLiteral();\n+    InternalDistributedMember provider = new InternalDistributedMember(local, 101);\n+    InternalDistributedMember requester = new InternalDistributedMember(local, 102);\n+\n+    ConcurrentHashMap<InternalDistributedMember, Long> memberToGcVersion =\n+        new ConcurrentHashMap<>();\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(provider, null,\n+        1, memberToGcVersion, 1, false, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(provider);\n+    regionVersionHolder.setVersion(2);\n+    memberToRegionVersionHolder.put(provider, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(requester, memberToRegionVersionHolder,\n+            0, null, 0, false, null);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isTrue();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsTrueIfRequesterRvvDominates() throws Exception {\n+    final String local = getIPLiteral();\n+    InternalDistributedMember provider = new InternalDistributedMember(local, 101);\n+    InternalDistributedMember requester = new InternalDistributedMember(local, 102);\n+    ConcurrentHashMap<InternalDistributedMember, Long> memberToGcVersion =\n+        new ConcurrentHashMap<>();\n+    memberToGcVersion.put(requester, new Long(1));\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(provider, null,\n+        1, memberToGcVersion, 1, false, null);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(provider);\n+    regionVersionHolder.setVersion(2);\n+    memberToRegionVersionHolder.put(provider, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(requester, memberToRegionVersionHolder,\n+            2, null, 0, false, regionVersionHolder);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isTrue();\n+  }\n+\n+  @Test\n+  public void isRvvGcDominatedByRequesterRvvReturnsFalseIfRequesterRvvDominates() throws Exception {\n+    final String local = getIPLiteral();\n+    InternalDistributedMember provider = new InternalDistributedMember(local, 101);\n+    InternalDistributedMember requester = new InternalDistributedMember(local, 102);\n+    ConcurrentHashMap<InternalDistributedMember, Long> memberToGcVersion =\n+        new ConcurrentHashMap<>();\n+    memberToGcVersion.put(requester, new Long(3));\n+    RegionVersionHolder pRegionVersionHolder = new RegionVersionHolder(provider);\n+    pRegionVersionHolder.setVersion(4);\n+\n+    RegionVersionVector providerRvv = new VMRegionVersionVector(provider, null,\n+        1, memberToGcVersion, 1, false, pRegionVersionHolder);\n+\n+    ConcurrentHashMap<InternalDistributedMember, RegionVersionHolder<InternalDistributedMember>> memberToRegionVersionHolder =\n+        new ConcurrentHashMap<>();\n+    RegionVersionHolder regionVersionHolder = new RegionVersionHolder(provider);\n+    regionVersionHolder.setVersion(2);\n+    memberToRegionVersionHolder.put(provider, regionVersionHolder);\n+    RegionVersionVector requesterRvv =\n+        new VMRegionVersionVector(requester, memberToRegionVersionHolder,\n+            2, null, 0, false, regionVersionHolder);\n+\n+    assertThat(providerRvv.isRVVGCDominatedBy(requesterRvv)).isFalse();\n+  }\n+\n   private RegionVersionVector createRegionVersionVector(InternalDistributedMember ownerId,\n       LocalRegion owner) {\n     @SuppressWarnings({\"unchecked\", \"rawtypes\"})",
                "raw_url": "https://github.com/apache/geode/raw/b40303ddfdaa428321ed541805abb62d4c68c461/geode-core/src/test/java/org/apache/geode/internal/cache/versions/RegionVersionVectorTest.java",
                "sha": "1d052a30f309ca73918403e9ba77f05eca4cc680",
                "status": "modified"
            }
        ],
        "message": "GEODE-6013: Use expected initial image requester's rvv information (#2857)\n\nRe-submitting after fixing NPE from previous checkin.\r\n\r\nMade changes to use the expected initial image requester's rvv\r\ninformation instead of the image provider's local rvv while\r\ndetermining full or delta GII.\r\n\r\nThere was logical error where it was using provider's local\r\nexception(rvv) instead of using requester's local exception(rvv).\r\nThis could result in performing Delta GII instead of Full GII.",
        "parent": "https://github.com/apache/geode/commit/348debe3d8273685d1d84ede6d201b448ae5b117",
        "patched_files": [
            "InitialImageOperation.java",
            "RegionVersionVector.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PersistentRegionRecoveryDUnitTest.java",
            "RegionVersionVectorTest.java",
            "InitialImageOperationTest.java"
        ]
    },
    "geode_b7da1f5": {
        "bug_id": "geode_b7da1f5",
        "commit": "https://github.com/apache/geode/commit/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/integrationTest/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 5,
                "filename": "geode-core/src/integrationTest/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "patch": "@@ -895,9 +895,11 @@ org/apache/geode/internal/cache/DestroyOperation$DestroyWithContextMessage,2\n fromData,14\n toData,14\n \n-org/apache/geode/internal/cache/DestroyPartitionedRegionMessage,2\n-fromData,76\n-toData,77\n+org/apache/geode/internal/cache/DestroyPartitionedRegionMessage,4\n+fromData,17\n+fromDataPre_GEODE_1_9_0_0,76\n+toData,14\n+toDataPre_GEODE_1_9_0_0,77\n \n org/apache/geode/internal/cache/DestroyRegionOperation$DestroyRegionMessage,2\n fromData,41\n@@ -1115,9 +1117,11 @@ org/apache/geode/internal/cache/InvalidateOperation$InvalidateWithContextMessage\n fromData,14\n toData,14\n \n-org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage,2\n-fromData,14\n+org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage,4\n+fromData,17\n+fromDataPre_GEODE_1_9_0_0,14\n toData,14\n+toDataPre_GEODE_1_9_0_0,14\n \n org/apache/geode/internal/cache/InvalidateRegionOperation$InvalidateRegionMessage,2\n fromData,17",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/integrationTest/resources/org/apache/geode/codeAnalysis/sanctionedDataSerializables.txt",
                "sha": "97798d0e03880893c543286797dd0da09a94fd02",
                "status": "modified"
            },
            {
                "additions": 32,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyPartitionedRegionMessage.java",
                "changes": 33,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyPartitionedRegionMessage.java?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/DestroyPartitionedRegionMessage.java",
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.geode.distributed.internal.ReplyMessage;\n import org.apache.geode.distributed.internal.ReplyProcessor21;\n import org.apache.geode.internal.Assert;\n+import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.partitioned.PartitionMessage;\n import org.apache.geode.internal.cache.partitioned.RegionAdvisor;\n import org.apache.geode.internal.cache.partitioned.RegionAdvisor.PartitionProfile;\n@@ -72,6 +73,15 @@\n   /** Serial numbers of the buckets for this region */\n   private int bucketSerials[];\n \n+  /** Event ID of the destroy operation created at the origin */\n+  private EventID eventID;\n+\n+  @Override\n+  public EventID getEventID() {\n+    return eventID;\n+  }\n+\n+\n   /**\n    * Empty constructor to satisfy {@link DataSerializer} requirements\n    */\n@@ -92,6 +102,7 @@ private DestroyPartitionedRegionMessage(Set recipients, PartitionedRegion region\n     this.prSerial = region.getSerialNumber();\n     Assert.assertTrue(this.prSerial != DistributionAdvisor.ILLEGAL_SERIAL);\n     this.bucketSerials = serials;\n+    this.eventID = event.getEventId();\n   }\n \n   /**\n@@ -177,7 +188,8 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager dm, Part\n       logger.trace(LogMarker.DM_VERBOSE, \"{} operateOnRegion: {}\", getClass().getName(),\n           r.getFullPath());\n     }\n-    RegionEventImpl event = new RegionEventImpl(r, this.op, this.cbArg, true, r.getMyId());\n+    RegionEventImpl event =\n+        new RegionEventImpl(r, this.op, this.cbArg, true, r.getMyId(), getEventID());\n     r.basicDestroyRegion(event, false, false, true);\n \n     return true;\n@@ -202,8 +214,20 @@ public int getDSFID() {\n     return DESTROY_PARTITIONED_REGION_MESSAGE;\n   }\n \n+  @Override\n+  public Version[] getSerializationVersions() {\n+    return new Version[] {Version.GEODE_190};\n+  }\n+\n+\n   @Override\n   public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n+    fromDataPre_GEODE_1_9_0_0(in);\n+    this.eventID = DataSerializer.readObject(in);\n+\n+  }\n+\n+  public void fromDataPre_GEODE_1_9_0_0(DataInput in) throws IOException, ClassNotFoundException {\n     super.fromData(in);\n     this.cbArg = DataSerializer.readObject(in);\n     this.op = Operation.fromOrdinal(in.readByte());\n@@ -217,6 +241,11 @@ public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n \n   @Override\n   public void toData(DataOutput out) throws IOException {\n+    toDataPre_GEODE_1_9_0_0(out);\n+    DataSerializer.writeObject(this.eventID, out);\n+  }\n+\n+  public void toDataPre_GEODE_1_9_0_0(DataOutput out) throws IOException {\n     super.toData(out);\n     DataSerializer.writeObject(this.cbArg, out);\n     out.writeByte(this.op.ordinal);\n@@ -227,6 +256,8 @@ public void toData(DataOutput out) throws IOException {\n     }\n   }\n \n+\n+\n   /**\n    * The response on which to wait for all the replies. This response ignores any exceptions\n    * received from the \"far side\"",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/DestroyPartitionedRegionMessage.java",
                "sha": "65c0fa3116d815476345a824cd5685c8d04ba696",
                "status": "modified"
            },
            {
                "additions": 31,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage.java",
                "changes": 38,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage.java?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 7,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage.java",
                "patch": "@@ -25,24 +25,33 @@\n import org.apache.geode.cache.query.QueryException;\n import org.apache.geode.distributed.internal.ClusterDistributionManager;\n import org.apache.geode.distributed.internal.ReplyProcessor21;\n+import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.partitioned.PartitionMessage;\n \n public class InvalidatePartitionedRegionMessage extends PartitionMessage {\n \n   private Object callbackArg;\n \n+  @Override\n+  public EventID getEventID() {\n+    return eventID;\n+  }\n+\n+  private EventID eventID;\n+\n   public InvalidatePartitionedRegionMessage() {}\n \n   public InvalidatePartitionedRegionMessage(Set recipients, Object callbackArg, PartitionedRegion r,\n-      ReplyProcessor21 processor) {\n+      ReplyProcessor21 processor, EventID eventID) {\n     super(recipients, r.getPRId(), processor);\n     this.callbackArg = callbackArg;\n+    this.eventID = eventID;\n   }\n \n   public static ReplyProcessor21 send(Set recipients, PartitionedRegion r, RegionEventImpl event) {\n     ReplyProcessor21 response = new ReplyProcessor21(r.getSystem(), recipients);\n     InvalidatePartitionedRegionMessage msg = new InvalidatePartitionedRegionMessage(recipients,\n-        event.getCallbackArgument(), r, response);\n+        event.getCallbackArgument(), r, response, event.getEventId());\n     msg.setTransactionDistributed(r.getCache().getTxManager().isDistributed());\n     r.getSystem().getDistributionManager().putOutgoing(msg);\n     return response;\n@@ -62,7 +71,7 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager dm, Part\n       throws CacheException, QueryException, ForceReattemptException, InterruptedException {\n \n     RegionEventImpl event = new RegionEventImpl(pr, Operation.REGION_INVALIDATE, this.callbackArg,\n-        !dm.getId().equals(getSender()), getSender());\n+        !dm.getId().equals(getSender()), getSender(), getEventID());\n     pr.basicInvalidateRegion(event);\n     return true;\n   }\n@@ -77,15 +86,25 @@ public int getDSFID() {\n     return INVALIDATE_PARTITIONED_REGION_MESSAGE;\n   }\n \n+  public void fromDataPre_GEODE_1_9_0_0(DataInput in) throws IOException, ClassNotFoundException {\n+    super.fromData(in);\n+    this.callbackArg = DataSerializer.readObject(in);\n+  }\n+\n   /*\n    * (non-Javadoc)\n    *\n    * @see org.apache.geode.internal.cache.partitioned.PartitionMessage#fromData(java.io.DataInput)\n    */\n   @Override\n   public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n-    super.fromData(in);\n-    this.callbackArg = DataSerializer.readObject(in);\n+    fromDataPre_GEODE_1_9_0_0(in);\n+    this.eventID = DataSerializer.readObject(in);\n+  }\n+\n+  public void toDataPre_GEODE_1_9_0_0(DataOutput out) throws IOException {\n+    super.toData(out);\n+    DataSerializer.writeObject(this.callbackArg, out);\n   }\n \n   /*\n@@ -95,7 +114,12 @@ public void fromData(DataInput in) throws IOException, ClassNotFoundException {\n    */\n   @Override\n   public void toData(DataOutput out) throws IOException {\n-    super.toData(out);\n-    DataSerializer.writeObject(this.callbackArg, out);\n+    toDataPre_GEODE_1_9_0_0(out);\n+    DataSerializer.writeObject(this.eventID, out);\n+  }\n+\n+  @Override\n+  public Version[] getSerializationVersions() {\n+    return new Version[] {Version.GEODE_190};\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/InvalidatePartitionedRegionMessage.java",
                "sha": "aabacaed31dfd47e16d7d865dd78013805eaabe7",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEventImpl.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEventImpl.java?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/RegionEventImpl.java",
                "patch": "@@ -26,7 +26,6 @@\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.distributed.DistributedSystem;\n import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n-import org.apache.geode.internal.Assert;\n import org.apache.geode.internal.DSFIDFactory;\n import org.apache.geode.internal.DataSerializableFixedID;\n import org.apache.geode.internal.InternalDataSerializer;\n@@ -105,8 +104,6 @@ public RegionEventImpl(Region region, Operation op, Object callbackArgument, boo\n     this.callbackArgument = callbackArgument;\n     this.originRemote = originRemote;\n     this.distributedMember = distributedMember;\n-    // TODO:ASIF: Remove this Assert from production env.\n-    Assert.assertTrue(eventID != null);\n     this.eventId = eventID;\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEventImpl.java",
                "sha": "fc339cdda0d4fd511f4e9a771548b002a84406c6",
                "status": "modified"
            },
            {
                "additions": 124,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/DestroyPartitionedRegionMessageDUnitTest.java",
                "changes": 124,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/DestroyPartitionedRegionMessageDUnitTest.java?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 0,
                "filename": "geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/DestroyPartitionedRegionMessageDUnitTest.java",
                "patch": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.query.cq.dunit;\n+\n+\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientCache;\n+import org.apache.geode.cache.client.ClientCacheFactory;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.query.CqAttributes;\n+import org.apache.geode.cache.query.CqAttributesFactory;\n+import org.apache.geode.cache.query.CqEvent;\n+import org.apache.geode.cache.query.CqListener;\n+import org.apache.geode.cache.query.QueryService;\n+import org.apache.geode.cache.query.data.Portfolio;\n+import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.junit.categories.ClientSubscriptionTest;\n+import org.apache.geode.test.junit.rules.VMProvider;\n+\n+@RunWith(JUnitParamsRunner.class)\n+@Category(ClientSubscriptionTest.class)\n+public class DestroyPartitionedRegionMessageDUnitTest implements Serializable {\n+  private MemberVM server1, server2;\n+  private TestCqListener testListener;\n+\n+  @Rule\n+  public ClusterStartupRule clusterStartupRule = new ClusterStartupRule();\n+\n+  @Before\n+  public void before() throws Exception {\n+    MemberVM locator = clusterStartupRule.startLocatorVM(0, new Properties());\n+    Integer locator1Port = locator.getPort();\n+    server1 = clusterStartupRule.startServerVM(1, locator1Port);\n+    server2 = clusterStartupRule.startServerVM(2, locator1Port);\n+\n+    VMProvider.invokeInEveryMember(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      assertThat(cache).isNotNull();\n+      cache.createRegionFactory(RegionShortcut.PARTITION).create(\"region\");\n+    }, server1, server2);\n+\n+    ClientCacheFactory clientCacheFactory = new ClientCacheFactory();\n+    clientCacheFactory.addPoolServer(\"localhost\", server1.getPort());\n+    clientCacheFactory.setPoolSubscriptionEnabled(true);\n+    ClientCache clientCache = clientCacheFactory.create();\n+    clientCache.createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY).create(\"region\");\n+\n+    QueryService queryService = clientCache.getQueryService();\n+    CqAttributesFactory cqaf = new CqAttributesFactory();\n+    testListener = new TestCqListener();\n+    cqaf.addCqListener(testListener);\n+    CqAttributes cqAttributes = cqaf.create();\n+\n+    queryService.newCq(\"Select * from /region r where r.ID + 3 > 4\", cqAttributes).execute();\n+  }\n+\n+  @Test\n+  @Parameters({\"1\", \"2\"})\n+  @TestCaseName(\"[{index}] {method}: server{params}\")\n+  public void closeMethodShouldBeCalledWhenRegionIsDestroyed(int serverIndex) {\n+    // The test is run twice with destroy being invoked in each server\n+    clusterStartupRule.getMember(serverIndex).invoke(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      assertThat(cache).isNotNull();\n+      Region<Integer, Portfolio> regionOnServer = cache.getRegion(\"region\");\n+      regionOnServer.destroyRegion();\n+    });\n+\n+    // Wait until region destroy operation has been distributed.\n+    VMProvider.invokeInEveryMember(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      assertThat(cache).isNotNull();\n+      await().until(() -> cache.getRegion(\"region\") == null);\n+    }, server1, server2);\n+\n+    assertThat(testListener.closeInvoked.get()).isTrue();\n+  }\n+\n+  private class TestCqListener implements CqListener, Serializable {\n+    AtomicBoolean closeInvoked = new AtomicBoolean();\n+\n+    @Override\n+    public void onEvent(CqEvent aCqEvent) {}\n+\n+    @Override\n+    public void onError(CqEvent aCqEvent) {}\n+\n+    @Override\n+    public void close() {\n+      closeInvoked.set(true);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/DestroyPartitionedRegionMessageDUnitTest.java",
                "sha": "d2eed8d4f1c1e7488a0cbaac304ac2a2d6bd5a60",
                "status": "added"
            },
            {
                "additions": 115,
                "blob_url": "https://github.com/apache/geode/blob/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/InvalidatePartitionedRegionMessageDUnitTest.java",
                "changes": 115,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/InvalidatePartitionedRegionMessageDUnitTest.java?ref=b7da1f57abbde2ded2b6bbcb2459e269a9c5477a",
                "deletions": 0,
                "filename": "geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/InvalidatePartitionedRegionMessageDUnitTest.java",
                "patch": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.cache.query.cq.dunit;\n+\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientCache;\n+import org.apache.geode.cache.client.ClientCacheFactory;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.query.CqAttributes;\n+import org.apache.geode.cache.query.CqAttributesFactory;\n+import org.apache.geode.cache.query.CqEvent;\n+import org.apache.geode.cache.query.CqListener;\n+import org.apache.geode.cache.query.QueryService;\n+import org.apache.geode.cache.query.data.Portfolio;\n+import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.junit.categories.ClientSubscriptionTest;\n+import org.apache.geode.test.junit.rules.VMProvider;\n+\n+@RunWith(JUnitParamsRunner.class)\n+@Category(ClientSubscriptionTest.class)\n+public class InvalidatePartitionedRegionMessageDUnitTest implements Serializable {\n+  private MemberVM server1, server2;\n+  private TestCqListener testListener;\n+\n+  @Rule\n+  public ClusterStartupRule clusterStartupRule = new ClusterStartupRule();\n+\n+  @Before\n+  public void before() throws Exception {\n+    MemberVM locator = clusterStartupRule.startLocatorVM(0, new Properties());\n+    Integer locator1Port = locator.getPort();\n+    server1 = clusterStartupRule.startServerVM(1, locator1Port);\n+    server2 = clusterStartupRule.startServerVM(2, locator1Port);\n+\n+    VMProvider.invokeInEveryMember(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      assertThat(cache).isNotNull();\n+      cache.createRegionFactory(RegionShortcut.PARTITION).create(\"region\");\n+    }, server1, server2);\n+\n+    ClientCacheFactory clientCacheFactory = new ClientCacheFactory();\n+    clientCacheFactory.addPoolServer(\"localhost\", server1.getPort());\n+    clientCacheFactory.setPoolSubscriptionEnabled(true);\n+    ClientCache clientCache = clientCacheFactory.create();\n+    clientCache.createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY).create(\"region\");\n+\n+    QueryService queryService = clientCache.getQueryService();\n+    CqAttributesFactory cqaf = new CqAttributesFactory();\n+    testListener = new TestCqListener();\n+    cqaf.addCqListener(testListener);\n+    CqAttributes cqAttributes = cqaf.create();\n+\n+    queryService.newCq(\"Select * from /region r where r.ID + 3 > 4\", cqAttributes).execute();\n+  }\n+\n+  @Test\n+  @Parameters({\"1\", \"2\"})\n+  @TestCaseName(\"[{index}] {method}: server{params}\")\n+  public void closeMethodShouldBeCalledWhenRegionIsDestroyed(int serverIndex) {\n+    // The test is run twice with destroy being invoked in each server\n+    clusterStartupRule.getMember(serverIndex).invoke(() -> {\n+      InternalCache cache = ClusterStartupRule.getCache();\n+      assertThat(cache).isNotNull();\n+      Region<Integer, Portfolio> regionOnServer = cache.getRegion(\"region\");\n+      regionOnServer.invalidateRegion();\n+    });\n+\n+  }\n+\n+  private class TestCqListener implements CqListener, Serializable {\n+    AtomicBoolean closeInvoked = new AtomicBoolean();\n+\n+    @Override\n+    public void onEvent(CqEvent aCqEvent) {}\n+\n+    @Override\n+    public void onError(CqEvent aCqEvent) {}\n+\n+    @Override\n+    public void close() {\n+      closeInvoked.set(true);\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/b7da1f57abbde2ded2b6bbcb2459e269a9c5477a/geode-cq/src/distributedTest/java/org/apache/geode/cache/query/cq/dunit/InvalidatePartitionedRegionMessageDUnitTest.java",
                "sha": "0207c75bc6d134ef3518525b2608d3cd384d5a28",
                "status": "added"
            }
        ],
        "message": "GEODE-6391: Adding the event ID to the messages (#3184)\n\n        * Event id is included in the DestroyPartitionedRegionMessage and InvalidatePartitionedRegionMessage\r\n\t* This is to prevent the NPE\r\n\t* The NPE occurs when server tries to notify the clients after receiving the message\r\n\t* While getting the thread id and sequence id it ends up with an NPE and event id is null.",
        "parent": "https://github.com/apache/geode/commit/67ed50f0410d641adb35eae8093e872b5625c65e",
        "patched_files": [
            "InvalidatePartitionedRegionMessage.java",
            "DestroyPartitionedRegionMessage.java",
            "sanctionedDataSerializables.java",
            "RegionEventImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "DestroyPartitionedRegionMessageDUnitTest.java",
            "InvalidatePartitionedRegionMessageDUnitTest.java"
        ]
    },
    "geode_bc2a2fa": {
        "bug_id": "geode_bc2a2fa",
        "commit": "https://github.com/apache/geode/commit/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8",
        "file": [
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/CacheClientNotifier.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/CacheClientNotifier.java?ref=bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/CacheClientNotifier.java",
                "patch": "@@ -40,6 +40,7 @@\n import java.util.concurrent.CopyOnWriteArraySet;\n import java.util.concurrent.ScheduledThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n import org.apache.logging.log4j.Logger;\n@@ -171,15 +172,15 @@ public void registerClient(final ClientRegistrationMetadata clientRegistrationMe\n     try {\n       if (isClientPermitted(clientRegistrationMetadata, clientProxyMembershipID)) {\n         registrationQueueManager.create(clientProxyMembershipID, new ConcurrentLinkedQueue<>(),\n-            new ReentrantReadWriteLock());\n+            new ReentrantReadWriteLock(), new ReentrantLock());\n \n         try {\n           registerClientInternal(clientRegistrationMetadata, socket, isPrimary, acceptorId,\n               notifyBySubscription);\n         } finally {\n-          registrationQueueManager.drain(\n-              clientProxyMembershipID,\n-              this);\n+          if (isProxyInitialized(clientProxyMembershipID)) {\n+            registrationQueueManager.drain(clientProxyMembershipID, this);\n+          }\n         }\n       }\n     } catch (final AuthenticationRequiredException ex) {\n@@ -1219,6 +1220,16 @@ public void unregisterClientInterest(String regionName, List keysOfInterest, boo\n     }\n   }\n \n+  /**\n+   * Determines whether a client proxy has been initialized\n+   *\n+   * @param clientProxyMembershipID The client proxy membership ID\n+   * @return Whether the client proxy is initialized\n+   */\n+  private boolean isProxyInitialized(final ClientProxyMembershipID clientProxyMembershipID) {\n+    return getClientProxy(clientProxyMembershipID) != null;\n+  }\n+\n   /**\n    * Returns the <code>CacheClientProxy</code> associated to the membershipID *\n    *",
                "raw_url": "https://github.com/apache/geode/raw/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/CacheClientNotifier.java",
                "sha": "da141d25a16868366b650322845c6701b3663b12",
                "status": "modified"
            },
            {
                "additions": 66,
                "blob_url": "https://github.com/apache/geode/blob/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManager.java",
                "changes": 99,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManager.java?ref=bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8",
                "deletions": 33,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManager.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantLock;\n \n import org.apache.logging.log4j.Logger;\n \n@@ -95,39 +96,58 @@ void add(final InternalCacheEvent event,\n \n   void drain(final ClientProxyMembershipID clientProxyMembershipID,\n       final CacheClientNotifier cacheClientNotifier) {\n-    // As an optimization, we drain as many events from the queue as we can\n-    // before taking out a lock to drain the remaining events\n-    if (logger.isDebugEnabled()) {\n-      logger.debug(\"Draining events from registration queue for client proxy \"\n-          + clientProxyMembershipID\n-          + \" without synchronization\");\n-    }\n-\n-    drainEventsReceivedWhileRegisteringClient(clientProxyMembershipID, cacheClientNotifier);\n-\n     ClientRegistrationEventQueue registrationEventQueue =\n         registeringProxyEventQueues.get(clientProxyMembershipID);\n \n-    registrationEventQueue.lockForDraining();\n-    try {\n-      if (logger.isDebugEnabled()) {\n-        logger.debug(\"Draining remaining events from registration queue for client proxy \"\n-            + clientProxyMembershipID + \" with synchronization\");\n-      }\n+    if (registrationEventQueue != null) {\n+      // It is possible that several client registration threads are active for the same\n+      // ClientProxyMembershipID, in which case we only want a single drainer to drain\n+      // and remove the queue.\n+      registrationEventQueue.lockForSingleDrainer();\n+      try {\n+        // See if the queue is still available after acquiring the lock as it may have\n+        // been removed from registeringProxyEventQueues by the previous thread\n+        if (registeringProxyEventQueues.containsKey(clientProxyMembershipID)) {\n+          // As an optimization, we drain as many events from the queue as we can\n+          // before taking out a lock to drain the remaining events. When we lock for draining,\n+          // it prevents additional events from being added to the queue while the queue is drained\n+          // and removed.\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"Draining events from registration queue for client proxy \"\n+                + clientProxyMembershipID\n+                + \" without synchronization\");\n+          }\n+\n+          drainEventsReceivedWhileRegisteringClient(clientProxyMembershipID, registrationEventQueue,\n+              cacheClientNotifier);\n+\n+          // Prevents additional events from being added to the queue while we process and remove it\n+          registrationEventQueue.lockForDraining();\n+          try {\n+            if (logger.isDebugEnabled()) {\n+              logger.debug(\"Draining remaining events from registration queue for client proxy \"\n+                  + clientProxyMembershipID + \" with synchronization\");\n+            }\n \n-      drainEventsReceivedWhileRegisteringClient(clientProxyMembershipID, cacheClientNotifier);\n+            drainEventsReceivedWhileRegisteringClient(clientProxyMembershipID,\n+                registrationEventQueue,\n+                cacheClientNotifier);\n \n-      registeringProxyEventQueues.remove(clientProxyMembershipID);\n-    } finally {\n-      registrationEventQueue.unlockForDraining();\n+            registeringProxyEventQueues.remove(clientProxyMembershipID);\n+          } finally {\n+            registrationEventQueue.unlockForDraining();\n+          }\n+        }\n+      } finally {\n+        registrationEventQueue.unlockForSingleDrainer();\n+      }\n     }\n   }\n \n   private void drainEventsReceivedWhileRegisteringClient(final ClientProxyMembershipID proxyID,\n+      final ClientRegistrationEventQueue registrationEventQueue,\n       final CacheClientNotifier cacheClientNotifier) {\n     ClientRegistrationEvent queuedEvent;\n-    ClientRegistrationEventQueue registrationEventQueue = registeringProxyEventQueues.get(proxyID);\n-\n     while ((queuedEvent = registrationEventQueue.poll()) != null) {\n       InternalCacheEvent internalCacheEvent = queuedEvent.internalCacheEvent;\n       Conflatable conflatable = queuedEvent.conflatable;\n@@ -139,23 +159,28 @@ private void drainEventsReceivedWhileRegisteringClient(final ClientProxyMembersh\n   public ClientRegistrationEventQueue create(\n       final ClientProxyMembershipID clientProxyMembershipID,\n       final Queue<ClientRegistrationEvent> eventQueue,\n-      final ReadWriteLock putDrainLock) {\n+      final ReadWriteLock eventAddDrainLock,\n+      final ReentrantLock singleDrainerLock) {\n     final ClientRegistrationEventQueue clientRegistrationEventQueue =\n         new ClientRegistrationEventQueue(eventQueue,\n-            putDrainLock);\n-    registeringProxyEventQueues.put(clientProxyMembershipID,\n+            eventAddDrainLock, singleDrainerLock);\n+    registeringProxyEventQueues.putIfAbsent(clientProxyMembershipID,\n         clientRegistrationEventQueue);\n     return clientRegistrationEventQueue;\n   }\n \n   class ClientRegistrationEventQueue {\n-    Queue<ClientRegistrationEvent> eventQueue;\n-    ReadWriteLock readWriteLock;\n+    private final Queue<ClientRegistrationEvent> eventQueue;\n+    private final ReadWriteLock eventAddDrainLock;\n+    private final ReentrantLock singleDrainerLock;\n \n     ClientRegistrationEventQueue(\n-        final Queue<ClientRegistrationEvent> eventQueue, final ReadWriteLock readWriteLock) {\n+        final Queue<ClientRegistrationEvent> eventQueue,\n+        final ReadWriteLock eventAddDrainLock,\n+        final ReentrantLock singleDrainerLock) {\n       this.eventQueue = eventQueue;\n-      this.readWriteLock = readWriteLock;\n+      this.eventAddDrainLock = eventAddDrainLock;\n+      this.singleDrainerLock = singleDrainerLock;\n     }\n \n     boolean isEmpty() {\n@@ -171,19 +196,27 @@ public ClientRegistrationEvent poll() {\n     }\n \n     private void lockForDraining() {\n-      readWriteLock.writeLock().lock();\n+      eventAddDrainLock.writeLock().lock();\n     }\n \n     private void unlockForDraining() {\n-      readWriteLock.writeLock().unlock();\n+      eventAddDrainLock.writeLock().unlock();\n     }\n \n     private void lockForPutting() {\n-      readWriteLock.readLock().lock();\n+      eventAddDrainLock.readLock().lock();\n     }\n \n     private void unlockForPutting() {\n-      readWriteLock.readLock().unlock();\n+      eventAddDrainLock.readLock().unlock();\n+    }\n+\n+    private void lockForSingleDrainer() {\n+      singleDrainerLock.lock();\n+    }\n+\n+    private void unlockForSingleDrainer() {\n+      singleDrainerLock.unlock();\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/main/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManager.java",
                "sha": "23d8ef5c92afcf64dee0058e110f5e9c302cf8e8",
                "status": "modified"
            },
            {
                "additions": 55,
                "blob_url": "https://github.com/apache/geode/blob/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManagerTest.java",
                "changes": 59,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManagerTest.java?ref=bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManagerTest.java",
                "patch": "@@ -27,7 +27,9 @@\n import java.util.concurrent.ConcurrentLinkedQueue;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ThreadLocalRandom;\n import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantLock;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n import org.junit.Test;\n@@ -68,7 +70,7 @@ public void messageDeliveredAfterRegisteringOnDrainIfNewFilterIDsIncludesClient(\n         });\n \n     clientRegistrationEventQueueManager.create(clientProxyMembershipID,\n-        new ConcurrentLinkedQueue<>(), mockPutDrainLock);\n+        new ConcurrentLinkedQueue<>(), mockPutDrainLock, new ReentrantLock());\n \n     InternalCacheEvent internalCacheEvent = mock(InternalCacheEvent.class);\n     LocalRegion localRegion = mock(LocalRegion.class);\n@@ -125,7 +127,7 @@ public void clientRemovedFromFilterClientsListIfEventAddedToRegistrationQueue()\n     ClientProxyMembershipID clientProxyMembershipID = mock(ClientProxyMembershipID.class);\n \n     clientRegistrationEventQueueManager.create(clientProxyMembershipID,\n-        new ConcurrentLinkedQueue<>(), new ReentrantReadWriteLock());\n+        new ConcurrentLinkedQueue<>(), new ReentrantReadWriteLock(), new ReentrantLock());\n \n     InternalCacheEvent internalCacheEvent = mock(InternalCacheEvent.class);\n     when(internalCacheEvent.getRegion()).thenReturn(mock(LocalRegion.class));\n@@ -170,7 +172,7 @@ public void addAndDrainQueueContentionTest() throws ExecutionException, Interrup\n \n     ClientRegistrationEventQueueManager.ClientRegistrationEventQueue clientRegistrationEventQueue =\n         clientRegistrationEventQueueManager.create(clientProxyMembershipID,\n-            new ConcurrentLinkedQueue<>(), mockPutDrainLock);\n+            new ConcurrentLinkedQueue<>(), mockPutDrainLock, new ReentrantLock());\n \n     InternalCacheEvent internalCacheEvent = mock(InternalCacheEvent.class);\n     when(internalCacheEvent.getRegion()).thenReturn(mock(LocalRegion.class));\n@@ -180,7 +182,7 @@ public void addAndDrainQueueContentionTest() throws ExecutionException, Interrup\n     CacheClientNotifier cacheClientNotifier = mock(CacheClientNotifier.class);\n \n     CompletableFuture<Void> addEventsToQueueTask = CompletableFuture.runAsync(() -> {\n-      for (int i = 0; i < 100000; ++i) {\n+      for (int numAdds = 0; numAdds < 100000; ++numAdds) {\n         // In thread one, we add events to the queue\n         clientRegistrationEventQueueManager\n             .add(internalCacheEvent, conflatable, filterClientIDs, cacheClientNotifier);\n@@ -196,4 +198,53 @@ public void addAndDrainQueueContentionTest() throws ExecutionException, Interrup\n \n     assertThat(clientRegistrationEventQueue.isEmpty()).isTrue();\n   }\n+\n+  @Test\n+  public void twoThreadsRegisteringSameClientNoEventsLost()\n+      throws ExecutionException, InterruptedException {\n+    ClientRegistrationEventQueueManager clientRegistrationEventQueueManager =\n+        new ClientRegistrationEventQueueManager();\n+\n+    InternalCacheEvent internalCacheEvent = mock(InternalCacheEvent.class);\n+    when(internalCacheEvent.getRegion()).thenReturn(mock(LocalRegion.class));\n+\n+    Conflatable conflatable = mock(Conflatable.class);\n+    Set<ClientProxyMembershipID> filterClientIDs = new HashSet<>();\n+    CacheClientNotifier cacheClientNotifier = mock(CacheClientNotifier.class);\n+    ClientProxyMembershipID clientProxyMembershipID = mock(ClientProxyMembershipID.class);\n+\n+    ClientRegistrationEventQueueManager.ClientRegistrationEventQueue clientRegistrationEventQueue =\n+        clientRegistrationEventQueueManager.create(clientProxyMembershipID,\n+            new ConcurrentLinkedQueue<>(), new ReentrantReadWriteLock(), new ReentrantLock());\n+\n+    for (int registrationIterations = 0; registrationIterations < 1000; ++registrationIterations) {\n+      Runnable clientRegistrationSimulation = () -> {\n+        for (int numAdds = 0; numAdds < getRandomNumberOfAdds(); ++numAdds) {\n+          // In thread one, we add events to the queue\n+          clientRegistrationEventQueueManager\n+              .add(internalCacheEvent, conflatable, filterClientIDs, cacheClientNotifier);\n+        }\n+        // In thread two, we drain events from the queue\n+        clientRegistrationEventQueueManager.drain(clientProxyMembershipID, cacheClientNotifier);\n+      };\n+\n+      CompletableFuture<Void> registrationFutureOne =\n+          CompletableFuture.runAsync(clientRegistrationSimulation);\n+      CompletableFuture<Void> registrationFutureTwo =\n+          CompletableFuture.runAsync(clientRegistrationSimulation);\n+\n+      CompletableFuture.allOf(registrationFutureOne, registrationFutureTwo).get();\n+\n+      assertThat(clientRegistrationEventQueue.isEmpty()).isTrue();\n+    }\n+  }\n+\n+  /*\n+   * This helps to create contention between registration threads during the drain phase\n+   */\n+  private static int getRandomNumberOfAdds() {\n+    int min = 10_000;\n+    int max = 50_000;\n+    return ThreadLocalRandom.current().nextInt(min, max + 1);\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/bc2a2fa5af374cfedfba4dc1abe6cbc2a7b719c8/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/ClientRegistrationEventQueueManagerTest.java",
                "sha": "f9af4017d9be5c4f08c5ef3b28e7d8656f7bce70",
                "status": "modified"
            }
        ],
        "message": "GEODE-6708: Ensuring single drainer and preventing NPE",
        "parent": "https://github.com/apache/geode/commit/76c98e8cae602fded710f7c05caaaf5d669b8745",
        "patched_files": [
            "ClientRegistrationEventQueueManager.java",
            "CacheClientNotifier.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ClientRegistrationEventQueueManagerTest.java",
            "CacheClientNotifierTest.java"
        ]
    },
    "geode_bc990cf": {
        "bug_id": "geode_bc990cf",
        "commit": "https://github.com/apache/geode/commit/bc990cf068b2a167bd4671e497914f81e8333568",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/bc990cf068b2a167bd4671e497914f81e8333568/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java?ref=bc990cf068b2a167bd4671e497914f81e8333568",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "patch": "@@ -99,7 +99,10 @@ private static boolean memberBeanDiskStoreExists(DistributedSystemMXBean dsMXBea\n         .filter(Objects::nonNull)\n         .map(DistributedSystemMXBean::listMemberDiskstore)\n         .filter(Objects::nonNull)\n-        .flatMap(mds -> Stream.of(mds.get(memberName)))\n+        .map(mds -> mds.get(memberName))\n+        .filter(Objects::nonNull)\n+        .flatMap(Stream::of)\n+        .filter(Objects::nonNull)\n         .anyMatch(dsName -> dsName.equals(diskStore));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/bc990cf068b2a167bd4671e497914f81e8333568/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "sha": "f9795f023c26126aea232d59141966d4168f3274",
                "status": "modified"
            },
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/geode/blob/bc990cf068b2a167bd4671e497914f81e8333568/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java?ref=bc990cf068b2a167bd4671e497914f81e8333568",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "patch": "@@ -91,4 +91,34 @@ public void diskStoreBeanExistsMemberDiskStoreIsNull() throws Exception {\n         DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n             memberName, diskStoreName)).isFalse();\n   }\n+\n+  @Test\n+  public void diskStoreBeanExistsMemberDiskStoreContainsNullArray() throws Exception {\n+    Map<String, String[]> memberDiskStore = new HashMap<>();\n+    memberDiskStore.put(memberName, null);\n+    ObjectName objectName = new ObjectName(\"\");\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(memberDiskStore).when(distributedSystemMXBean).listMemberDiskstore();\n+    doReturn(objectName).when(distributedSystemMXBean).fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isFalse();\n+  }\n+\n+  @Test\n+  public void diskStoreBeanExistsMemberDiskStoreNamesHasNullValues() throws Exception {\n+    Map<String, String[]> memberDiskStore = new HashMap<>();\n+    memberDiskStore.put(memberName, new String[] {null, null});\n+    ObjectName objectName = new ObjectName(\"\");\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(memberDiskStore).when(distributedSystemMXBean).listMemberDiskstore();\n+    doReturn(objectName).when(distributedSystemMXBean).fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isFalse();\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/bc990cf068b2a167bd4671e497914f81e8333568/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "sha": "00317d7a0ceaac57e959eb0de6298f944bd4d30b",
                "status": "modified"
            }
        ],
        "message": "GEODE-6779: added NPE checks (#3818)\n\n* GEODE-6779: added NPE checks\r\n\r\n- DUnit tests show that beans can contain null values in any imaginable\r\nplace so we have to enhance the null value filtering\r\n- Unit test enhanced to verify the checks\r\n\r\nAuthored-by: Joris Melchior <joris.melchior@gmail.com>\r\n\r\n* GEODE-6779: spotless fix\r\n\r\nAuthored-by: Joris Melchior <joris.melchior@gmail.com>",
        "parent": "https://github.com/apache/geode/commit/d3384447810a7e6d71394180c8ea84c52bcc54e6",
        "patched_files": [
            "DiskStoreCommandsUtils.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "DiskStoreCommandsUtilsTest.java"
        ]
    },
    "geode_bee0b7d": {
        "bug_id": "geode_bee0b7d",
        "commit": "https://github.com/apache/geode/commit/bee0b7d570f62848318ffcd719efaee6e5884102",
        "file": [
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/geode/blob/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java?ref=bee0b7d570f62848318ffcd719efaee6e5884102",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "patch": "@@ -2039,6 +2039,16 @@ public OffHeapEvictor getOffHeapEvictor() {\n     }\n   }\n \n+  /** Used by test to inject an evictor */\n+  void setOffHeapEvictor(OffHeapEvictor evictor) {\n+    this.offHeapEvictor = evictor;\n+  }\n+\n+  /** Used by test to inject an evictor */\n+  void setHeapEvictor(HeapEvictor evictor) {\n+    this.heapEvictor = evictor;\n+  }\n+\n   @Override\n   public PersistentMemberManager getPersistentMemberManager() {\n     return this.persistentMemberManager;\n@@ -2313,10 +2323,8 @@ public void close(String reason, Throwable systemFailureCause, boolean keepAlive\n           if (cms != null) {\n             cms.close();\n           }\n-          HeapEvictor he = this.heapEvictor;\n-          if (he != null) {\n-            he.close();\n-          }\n+          closeHeapEvictor();\n+          closeOffHeapEvictor();\n         } catch (CancelException ignore) {\n           // make sure the disk stores get closed\n           closeDiskStores();\n@@ -2385,6 +2393,20 @@ public void close(String reason, Throwable systemFailureCause, boolean keepAlive\n \n   }\n \n+  private void closeOffHeapEvictor() {\n+    OffHeapEvictor evictor = this.offHeapEvictor;\n+    if (evictor != null) {\n+      evictor.close();\n+    }\n+  }\n+\n+  private void closeHeapEvictor() {\n+    HeapEvictor evictor = this.heapEvictor;\n+    if (evictor != null) {\n+      evictor.close();\n+    }\n+  }\n+\n   @Override\n   public boolean isReconnecting() {\n     return this.system.isReconnecting();",
                "raw_url": "https://github.com/apache/geode/raw/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/GemFireCacheImpl.java",
                "sha": "de7558c22b1509a99866ceb580f5bfc0e84f5877",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEvictorTask.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEvictorTask.java?ref=bee0b7d570f62848318ffcd719efaee6e5884102",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/RegionEvictorTask.java",
                "patch": "@@ -34,7 +34,7 @@\n  * @since GemFire 6.0\n  * \n  */\n-public class RegionEvictorTask implements Callable<Object> {\n+public class RegionEvictorTask implements Runnable {\n \n   private static final Logger logger = LogService.getLogger();\n \n@@ -85,7 +85,8 @@ private HeapEvictor getHeapEvictor() {\n     return this.evictor;\n   }\n \n-  public Object call() throws Exception {\n+  @Override\n+  public void run() {\n     getGemFireCache().getCachePerfStats().incEvictorJobsStarted();\n     long bytesEvicted = 0;\n     long totalBytesEvicted = 0;\n@@ -96,7 +97,7 @@ public Object call() throws Exception {\n         synchronized (this.regionSet) {\n           if (this.regionSet.isEmpty()) {\n             lastTaskCompletionTime = System.currentTimeMillis();\n-            return null;\n+            return;\n           }\n           // TODO: Yogesh : try Fisher-Yates shuffle algorithm\n           Iterator<LocalRegion> iter = regionSet.iterator();\n@@ -111,7 +112,7 @@ public Object call() throws Exception {\n               if (totalBytesEvicted >= bytesToEvictPerTask || !getHeapEvictor().mustEvict()\n                   || this.regionSet.size() == 0) {\n                 lastTaskCompletionTime = System.currentTimeMillis();\n-                return null;\n+                return;\n               }\n             } catch (RegionDestroyedException rd) {\n               region.cache.getCancelCriterion().checkCancelInProgress(rd);",
                "raw_url": "https://github.com/apache/geode/raw/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/RegionEvictorTask.java",
                "sha": "a4677265574dcca37600616aaff7ea7af76aa84c",
                "status": "modified"
            },
            {
                "additions": 42,
                "blob_url": "https://github.com/apache/geode/blob/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/lru/HeapEvictor.java",
                "changes": 73,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/lru/HeapEvictor.java?ref=bee0b7d570f62848318ffcd719efaee6e5884102",
                "deletions": 31,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/lru/HeapEvictor.java",
                "patch": "@@ -89,12 +89,12 @@\n \n   protected final Cache cache;\n \n-  private final ArrayList testTaskSetSizes = new ArrayList();\n+  private final ArrayList<Integer> testTaskSetSizes = new ArrayList<>();\n   public volatile int testAbortAfterLoopCount = Integer.MAX_VALUE;\n \n   private BlockingQueue<Runnable> poolQueue;\n \n-  private AtomicBoolean isRunning = new AtomicBoolean(true);\n+  private final AtomicBoolean isRunning = new AtomicBoolean(true);\n \n   public HeapEvictor(Cache gemFireCache) {\n     this.cache = gemFireCache;\n@@ -198,12 +198,19 @@ public Thread newThread(Runnable command) {\n   /**\n    * The task(i.e the region on which eviction needs to be performed) is assigned to the threadpool.\n    */\n-  private void submitRegionEvictionTask(Callable<Object> task) {\n-    evictorThreadPool.submit(task);\n+  private void executeInThreadPool(Runnable task) {\n+    try {\n+      evictorThreadPool.execute(task);\n+    } catch (RejectedExecutionException ex) {\n+      // ignore rejection if evictor no longer running\n+      if (isRunning()) {\n+        throw ex;\n+      }\n+    }\n   }\n \n   public ThreadPoolExecutor getEvictorThreadPool() {\n-    if (isRunning.get()) {\n+    if (isRunning()) {\n       return evictorThreadPool;\n     }\n     return null;\n@@ -215,7 +222,7 @@ public ThreadPoolExecutor getEvictorThreadPool() {\n    * @return sum of scheduled and running tasks\n    */\n   public int getRunningAndScheduledTasks() {\n-    if (isRunning.get()) {\n+    if (isRunning()) {\n       return this.evictorThreadPool.getActiveCount() + this.evictorThreadPool.getQueue().size();\n     }\n     return -1;\n@@ -243,35 +250,36 @@ private void createAndSubmitWeightedRegionEvictionTasks() {\n       long bytesToEvictPerTask = (long) (getTotalBytesToEvict() * percentage);\n       regionsForSingleTask.add(lr);\n       if (mustEvict()) {\n-        submitRegionEvictionTask(\n-            new RegionEvictorTask(regionsForSingleTask, this, bytesToEvictPerTask));\n+        executeInThreadPool(new RegionEvictorTask(regionsForSingleTask, this, bytesToEvictPerTask));\n       } else {\n         break;\n       }\n     }\n   }\n \n-  private Set<Callable<Object>> createRegionEvictionTasks() {\n-    Set<Callable<Object>> evictorTaskSet = new HashSet<Callable<Object>>();\n-    int threadsAvailable = getEvictorThreadPool().getCorePoolSize();\n+  private Set<RegionEvictorTask> createRegionEvictionTasks() {\n+    ThreadPoolExecutor pool = getEvictorThreadPool();\n+    if (pool == null) {\n+      return Collections.emptySet();\n+    }\n+    int threadsAvailable = pool.getCorePoolSize();\n     long bytesToEvictPerTask = getTotalBytesToEvict() / threadsAvailable;\n     List<LocalRegion> allRegionList = getAllRegionList();\n+    if (allRegionList.isEmpty()) {\n+      return Collections.emptySet();\n+    }\n     // This shuffling is not required when eviction triggered for the first time\n     Collections.shuffle(allRegionList);\n     int allRegionSetSize = allRegionList.size();\n-    if (allRegionList.isEmpty()) {\n-      return evictorTaskSet;\n-    }\n+    Set<RegionEvictorTask> evictorTaskSet = new HashSet<>();\n     if (allRegionSetSize <= threadsAvailable) {\n       for (LocalRegion region : allRegionList) {\n         List<LocalRegion> regionList = new ArrayList<LocalRegion>(1);\n         regionList.add(region);\n-        Callable<Object> task = new RegionEvictorTask(regionList, this, bytesToEvictPerTask);\n+        RegionEvictorTask task = new RegionEvictorTask(regionList, this, bytesToEvictPerTask);\n         evictorTaskSet.add(task);\n       }\n-      Iterator iterator = evictorTaskSet.iterator();\n-      while (iterator.hasNext()) {\n-        RegionEvictorTask regionEvictorTask = (RegionEvictorTask) iterator.next();\n+      for (RegionEvictorTask regionEvictorTask : evictorTaskSet) {\n         testTaskSetSizes.add(regionEvictorTask.getRegionList().size());\n       }\n       return evictorTaskSet;\n@@ -295,9 +303,7 @@ private void createAndSubmitWeightedRegionEvictionTasks() {\n       regionsForSingleTask.add(itr.next());\n     }\n \n-    Iterator iterator = evictorTaskSet.iterator();\n-    while (iterator.hasNext()) {\n-      RegionEvictorTask regionEvictorTask = (RegionEvictorTask) iterator.next();\n+    for (RegionEvictorTask regionEvictorTask : evictorTaskSet) {\n       testTaskSetSizes.add(regionEvictorTask.getRegionList().size());\n     }\n     return evictorTaskSet;\n@@ -327,7 +333,7 @@ public void onEvent(final MemoryEvent event) {\n \n     // Do we care about eviction events and did the eviction event originate\n     // in this VM ...\n-    if (this.isRunning.get() && event.isLocal()) {\n+    if (isRunning() && event.isLocal()) {\n       if (event.getState().isEviction()) {\n         final LogWriter logWriter = cache.getLogger();\n \n@@ -378,8 +384,8 @@ public void run() {\n                 if (EVICT_HIGH_ENTRY_COUNT_BUCKETS_FIRST) {\n                   createAndSubmitWeightedRegionEvictionTasks();\n                 } else {\n-                  for (Callable<Object> task : createRegionEvictionTasks()) {\n-                    submitRegionEvictionTask(task);\n+                  for (RegionEvictorTask task : createRegionEvictionTasks()) {\n+                    executeInThreadPool(task);\n                   }\n                 }\n                 RegionEvictorTask.setLastTaskCompletionTime(System.currentTimeMillis());\n@@ -408,22 +414,22 @@ public void run() {\n                 if (HeapEvictor.this.mustEvict.get()) {\n                   // Submit this runnable back into the thread pool and execute\n                   // another pass at eviction.\n-                  HeapEvictor.this.evictorThreadPool.submit(this);\n+                  executeInThreadPool(this);\n                 }\n               } catch (RegionDestroyedException e) {\n                 // A region destroyed exception might be thrown for Region.size() when a bucket\n                 // moves due to rebalancing. retry submitting the eviction task without\n                 // logging an error message. fixes bug 48162\n                 if (HeapEvictor.this.mustEvict.get()) {\n-                  HeapEvictor.this.evictorThreadPool.submit(this);\n+                  executeInThreadPool(this);\n                 }\n               }\n             }\n           }\n         };\n \n         // Submit the first pass at eviction into the pool\n-        this.evictorThreadPool.execute(evictionManagerTask);\n+        executeInThreadPool(evictionManagerTask);\n \n       } else {\n         this.mustEvict.set(false);\n@@ -447,12 +453,17 @@ public boolean mustEvict() {\n   }\n \n   public void close() {\n-    getEvictorThreadPool().shutdownNow();\n-    isRunning.set(false);\n+    if (isRunning.compareAndSet(true, false)) {\n+      evictorThreadPool.shutdownNow();\n+    }\n+  }\n+\n+  public boolean isRunning() {\n+    return isRunning.get();\n   }\n \n-  public ArrayList testOnlyGetSizeOfTasks() {\n-    if (isRunning.get())\n+  public ArrayList<Integer> testOnlyGetSizeOfTasks() {\n+    if (isRunning())\n       return testTaskSetSizes;\n     return null;\n   }",
                "raw_url": "https://github.com/apache/geode/raw/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/main/java/org/apache/geode/internal/cache/lru/HeapEvictor.java",
                "sha": "707b4080a667ff3bcc795220ebf7447b226fe428",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/test/java/org/apache/geode/internal/cache/EvictionTestBase.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/EvictionTestBase.java?ref=bee0b7d570f62848318ffcd719efaee6e5884102",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/EvictionTestBase.java",
                "patch": "@@ -283,7 +283,7 @@ public void createCache() {\n     }\n   }\n \n-  public ArrayList getTestTaskSetSizes() {\n+  public ArrayList<Integer> getTestTaskSetSizes() {\n     return getEvictor().testOnlyGetSizeOfTasks();\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/test/java/org/apache/geode/internal/cache/EvictionTestBase.java",
                "sha": "e30636c48e9a53d8d6fc5080ea0379bfc1893224",
                "status": "modified"
            },
            {
                "additions": 21,
                "blob_url": "https://github.com/apache/geode/blob/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "changes": 21,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java?ref=bee0b7d570f62848318ffcd719efaee6e5884102",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "patch": "@@ -28,6 +28,8 @@\n \n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.internal.SystemTimer;\n+import org.apache.geode.internal.cache.lru.HeapEvictor;\n+import org.apache.geode.internal.cache.lru.OffHeapEvictor;\n import org.apache.geode.pdx.internal.TypeRegistry;\n import org.apache.geode.test.fake.Fakes;\n import org.apache.geode.test.junit.categories.UnitTest;\n@@ -61,6 +63,25 @@ public void checkPurgeCCPTimer() {\n     }\n   }\n \n+  @Test\n+  public void checkEvictorsClosed() {\n+    InternalDistributedSystem ds = Fakes.distributedSystem();\n+    CacheConfig cc = new CacheConfig();\n+    TypeRegistry typeRegistry = mock(TypeRegistry.class);\n+    SystemTimer ccpTimer = mock(SystemTimer.class);\n+    HeapEvictor he = mock(HeapEvictor.class);\n+    OffHeapEvictor ohe = mock(OffHeapEvictor.class);\n+    GemFireCacheImpl gfc = GemFireCacheImpl.createWithAsyncEventListeners(ds, cc, typeRegistry);\n+    try {\n+      gfc.setHeapEvictor(he);\n+      gfc.setOffHeapEvictor(ohe);\n+    } finally {\n+      gfc.close();\n+    }\n+    verify(he, times(1)).close();\n+    verify(ohe, times(1)).close();\n+  }\n+\n   @Test\n   public void checkThatAsyncEventListenersUseAllThreadsInPool() {\n     InternalDistributedSystem ds = Fakes.distributedSystem();",
                "raw_url": "https://github.com/apache/geode/raw/bee0b7d570f62848318ffcd719efaee6e5884102/geode-core/src/test/java/org/apache/geode/internal/cache/GemFireCacheImplTest.java",
                "sha": "a24fc5a0898ea4276ce3b0ac28a8ba703708ec30",
                "status": "modified"
            }
        ],
        "message": "GEODE-2811: close OffHeapEvictor when cache is closed\n\nRejected executions are now ignored if shutting down.\nexecute now used instead of submit.\nClose logic on HeapEvictor improved to prevent race conditions and NPEs.",
        "parent": "https://github.com/apache/geode/commit/c98bc8bdbf6a6f1f32031a1aba390a3b14edd6b4",
        "patched_files": [
            "RegionEvictorTask.java",
            "EvictionTestBase.java",
            "GemFireCacheImpl.java",
            "HeapEvictor.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GemFireCacheImplTest.java"
        ]
    },
    "geode_c16f280": {
        "bug_id": "geode_c16f280",
        "commit": "https://github.com/apache/geode/commit/c16f28040523e72efdada6da0398657723e6c262",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/geode/blob/c16f28040523e72efdada6da0398657723e6c262/geode-wan/src/main/java/org/apache/geode/internal/cache/wan/GatewayReceiverImpl.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-wan/src/main/java/org/apache/geode/internal/cache/wan/GatewayReceiverImpl.java?ref=c16f28040523e72efdada6da0398657723e6c262",
                "deletions": 5,
                "filename": "geode-wan/src/main/java/org/apache/geode/internal/cache/wan/GatewayReceiverImpl.java",
                "patch": "@@ -217,12 +217,17 @@ public void stop() {\n \n   public void destroy() {\n     logger.info(\"Destroying Gateway Receiver: \" + this);\n-    if (receiver.isRunning()) {\n-      throw new GatewayReceiverException(\n-          \"Gateway Receiver is running and needs to be stopped first\");\n+    if (receiver == null) {\n+      // receiver was not started\n+      this.cache.removeGatewayReceiver(this);\n+    } else {\n+      if (receiver.isRunning()) {\n+        throw new GatewayReceiverException(\n+            \"Gateway Receiver is running and needs to be stopped first\");\n+      }\n+      this.cache.removeGatewayReceiver(this);\n+      this.cache.removeCacheServer(receiver);\n     }\n-    this.cache.removeGatewayReceiver(this);\n-    this.cache.removeCacheServer(receiver);\n     InternalDistributedSystem system = this.cache.getInternalDistributedSystem();\n     system.handleResourceEvent(ResourceEvent.GATEWAYRECEIVER_DESTROY, this);\n   }",
                "raw_url": "https://github.com/apache/geode/raw/c16f28040523e72efdada6da0398657723e6c262/geode-wan/src/main/java/org/apache/geode/internal/cache/wan/GatewayReceiverImpl.java",
                "sha": "0f0fc6301bdf25ad70e5bc2135f29571d0097acc",
                "status": "modified"
            },
            {
                "additions": 46,
                "blob_url": "https://github.com/apache/geode/blob/c16f28040523e72efdada6da0398657723e6c262/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/serial/GatewayReceiverDUnitTest.java",
                "changes": 46,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/serial/GatewayReceiverDUnitTest.java?ref=c16f28040523e72efdada6da0398657723e6c262",
                "deletions": 0,
                "filename": "geode-wan/src/test/java/org/apache/geode/internal/cache/wan/serial/GatewayReceiverDUnitTest.java",
                "patch": "@@ -78,6 +78,18 @@ public void canAddReceiverAfterRemovingFromPartitionedRegion() throws Exception\n             .getDistributionAdvisor());\n   }\n \n+  @Test\n+  public void canDestroyUnstartedGatewayReceiverFromReplicated() throws Exception {\n+    testCanDestroyUnstartedGatewayReceiver(\n+        () -> WANTestBase.createReplicatedRegion(getTestMethodName(), null, isOffHeap()));\n+  }\n+\n+  @Test\n+  public void canDestroyUnstartedReceiverFromPartitionedRegion() throws Exception {\n+    testCanDestroyUnstartedGatewayReceiver(\n+        () -> WANTestBase.createPartitionedRegion(getTestMethodName(), null, 1, 10, isOffHeap()));\n+  }\n+\n   public <T> void testRemoveGatewayReceiver(SerializableRunnableIF createRegionLambda,\n       SerializableCallableIF<DistributionAdvisor> extractAdvisorLambda) throws Exception {\n     InternalDistributedMember[] memberIds = new InternalDistributedMember[8];\n@@ -184,6 +196,30 @@ public void canAddReceiverAfterRemovingFromPartitionedRegion() throws Exception\n \n   }\n \n+  public <T> void testCanDestroyUnstartedGatewayReceiver(SerializableRunnableIF createRegionLambda)\n+      throws Exception {\n+    InternalDistributedMember[] memberIds = new InternalDistributedMember[8];\n+\n+    Integer lnPort = (Integer) vm0.invoke(() -> WANTestBase.createFirstLocatorWithDSId(1));\n+    Integer nyPort = (Integer) vm1.invoke(() -> WANTestBase.createFirstRemoteLocator(2, lnPort));\n+\n+    vm2.invoke(() -> WANTestBase.createCache(nyPort));\n+\n+    memberIds[2] = (InternalDistributedMember) vm2\n+        .invoke(() -> WANTestBase.cache.getDistributedSystem().getDistributedMember());\n+    vm2.invoke(createRegionLambda);\n+\n+    vm2.invoke(() -> {\n+      GatewayReceiverDUnitTest.receiver =\n+          GatewayReceiverDUnitTest.createAndReturnUnstartedReceiver();\n+      return;\n+    });\n+\n+    vm2.invoke(() -> {\n+      GatewayReceiverDUnitTest.receiver.destroy();\n+    });\n+  }\n+\n \n \n   private void assertProfileCacheServerFlagEquals(InternalDistributedMember member,\n@@ -212,4 +248,14 @@ public static GatewayReceiver createAndReturnReceiver() {\n     return receiver;\n   }\n \n+  public static GatewayReceiver createAndReturnUnstartedReceiver() {\n+    GatewayReceiverFactory fact = cache.createGatewayReceiverFactory();\n+    int port = AvailablePortHelper.getRandomAvailablePortForDUnitSite();\n+    fact.setStartPort(port);\n+    fact.setEndPort(port);\n+    fact.setManualStart(true);\n+    GatewayReceiver receiver = fact.create();\n+    return receiver;\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/geode/raw/c16f28040523e72efdada6da0398657723e6c262/geode-wan/src/test/java/org/apache/geode/internal/cache/wan/serial/GatewayReceiverDUnitTest.java",
                "sha": "21cbaebe338b64946f07d12277d08340a7125fbe",
                "status": "modified"
            }
        ],
        "message": "GEODE-4770: Prevent NPE when destroying unstarted GatewayReceiver (#1556)",
        "parent": "https://github.com/apache/geode/commit/3453736e37f8134f9987b5fdda6a7496c0144d2f",
        "patched_files": [
            "GatewayReceiverImpl.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GatewayReceiverDUnitTest.java"
        ]
    },
    "geode_c2ef3c6": {
        "bug_id": "geode_c2ef3c6",
        "commit": "https://github.com/apache/geode/commit/c2ef3c682c885b4d49aad51edc1c11e80553bdfa",
        "file": [
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java?ref=c2ef3c682c885b4d49aad51edc1c11e80553bdfa",
                "deletions": 11,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "patch": "@@ -540,15 +540,20 @@ protected LocalRegion(String regionName, RegionAttributes attrs, LocalRegion par\n       InternalDataView internalDataView) throws DiskAccessException {\n     this(regionName, attrs, parentRegion, cache, internalRegionArgs, internalDataView,\n         RegionMapFactory::createVM, new DefaultServerRegionProxyConstructor(),\n-        new DefaultEntryEventFactory(), poolName -> (PoolImpl) PoolManager.find(poolName));\n+        new DefaultEntryEventFactory(), poolName -> (PoolImpl) PoolManager.find(poolName),\n+        (LocalRegion region) -> new RegionPerfStats(\n+            cache.getInternalDistributedSystem().getStatisticsManager(),\n+            \"RegionStats-\" + regionName, cache.getCachePerfStats(),\n+            region, cache.getMeterRegistry()));\n   }\n \n   @VisibleForTesting\n   LocalRegion(String regionName, RegionAttributes attrs, LocalRegion parentRegion,\n       InternalCache cache, InternalRegionArguments internalRegionArgs,\n       InternalDataView internalDataView, RegionMapConstructor regionMapConstructor,\n       ServerRegionProxyConstructor serverRegionProxyConstructor,\n-      EntryEventFactory entryEventFactory, PoolFinder poolFinder)\n+      EntryEventFactory entryEventFactory, PoolFinder poolFinder,\n+      java.util.function.Function<LocalRegion, RegionPerfStats> regionPerfStatsFactory)\n       throws DiskAccessException {\n     super(cache, attrs, regionName, internalRegionArgs, poolFinder);\n \n@@ -587,6 +592,11 @@ protected LocalRegion(String regionName, RegionAttributes attrs, LocalRegion par\n     }\n     initializingRegion.set(this);\n \n+    diskStoreImpl = findDiskStore(attrs, internalRegionArgs);\n+    diskRegion = createDiskRegion(internalRegionArgs);\n+    entries = createRegionMap(internalRegionArgs);\n+    subregions = new ConcurrentHashMap();\n+\n     if (internalRegionArgs.getCachePerfStatsHolder() != null) {\n       hasOwnStats = false;\n       cachePerfStats = internalRegionArgs.getCachePerfStatsHolder().getCachePerfStats();\n@@ -597,18 +607,10 @@ protected LocalRegion(String regionName, RegionAttributes attrs, LocalRegion par\n         cachePerfStats = cache.getCachePerfStats();\n       } else {\n         hasOwnStats = true;\n-        cachePerfStats =\n-            new RegionPerfStats(cache.getInternalDistributedSystem().getStatisticsManager(),\n-                \"RegionStats-\" + regionName, cache.getCachePerfStats(),\n-                this, cache.getMeterRegistry());\n+        cachePerfStats = regionPerfStatsFactory.apply(this);\n       }\n     }\n \n-    diskStoreImpl = findDiskStore(attrs, internalRegionArgs);\n-    diskRegion = createDiskRegion(internalRegionArgs);\n-    entries = createRegionMap(internalRegionArgs);\n-    subregions = new ConcurrentHashMap();\n-\n     // we only need a destroy lock if this is a root\n     if (parentRegion == null) {\n       initRoot();",
                "raw_url": "https://github.com/apache/geode/raw/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/main/java/org/apache/geode/internal/cache/LocalRegion.java",
                "sha": "49ca50695e679db6f65f455cea8638e286226310",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/test/java/org/apache/geode/internal/cache/AbstractRegionJUnitTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/AbstractRegionJUnitTest.java?ref=c2ef3c682c885b4d49aad51edc1c11e80553bdfa",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/AbstractRegionJUnitTest.java",
                "patch": "@@ -20,6 +20,7 @@\n import static org.mockito.Mockito.when;\n \n import java.util.Set;\n+import java.util.function.Function;\n \n import org.junit.Test;\n \n@@ -113,8 +114,11 @@ private AbstractRegion createTestableAbstractRegion() {\n     DiskWriteAttributes diskWriteAttributes = mock(DiskWriteAttributes.class);\n     when(regionAttributes.getDiskWriteAttributes()).thenReturn(diskWriteAttributes);\n     RegionMapConstructor regionMapConstructor = mock(RegionMapConstructor.class);\n+    Function<LocalRegion, RegionPerfStats> regionPerfStatsFactory =\n+        (localRegion) -> mock(RegionPerfStats.class);\n     AbstractRegion region = new LocalRegion(\"regionName\", regionAttributes, null, Fakes.cache(),\n-        new InternalRegionArguments(), null, regionMapConstructor, null, null, null);\n+        new InternalRegionArguments(), null, regionMapConstructor, null, null, null,\n+        regionPerfStatsFactory);\n     return region;\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/test/java/org/apache/geode/internal/cache/AbstractRegionJUnitTest.java",
                "sha": "09c7c5f1c5d4d9ba9971ef8589509a40a7bf2edb",
                "status": "modified"
            },
            {
                "additions": 92,
                "blob_url": "https://github.com/apache/geode/blob/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/test/java/org/apache/geode/internal/cache/LocalRegionTest.java",
                "changes": 92,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/LocalRegionTest.java?ref=c2ef3c682c885b4d49aad51edc1c11e80553bdfa",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/LocalRegionTest.java",
                "patch": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.internal.cache;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.function.Function;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.DiskWriteAttributes;\n+import org.apache.geode.cache.EvictionAction;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.ExpirationAttributes;\n+import org.apache.geode.cache.RegionAttributes;\n+import org.apache.geode.distributed.internal.DSClock;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.internal.cache.AbstractRegion.PoolFinder;\n+import org.apache.geode.internal.cache.LocalRegion.RegionMapConstructor;\n+import org.apache.geode.internal.cache.LocalRegion.ServerRegionProxyConstructor;\n+\n+public class LocalRegionTest {\n+\n+  private RegionAttributes regionAttributes;\n+  private InternalCache cache;\n+  private InternalRegionArguments internalRegionArguments;\n+  private InternalDataView internalDataView;\n+  private RegionMapConstructor regionMapConstructor;\n+  private ServerRegionProxyConstructor serverRegionProxyConstructor;\n+  private EntryEventFactory entryEventFactory;\n+  private PoolFinder poolFinder;\n+\n+  @Before\n+  public void setup() {\n+    cache = mock(InternalCache.class);\n+    entryEventFactory = mock(EntryEventFactory.class);\n+    internalDataView = mock(InternalDataView.class);\n+    internalRegionArguments = mock(InternalRegionArguments.class);\n+    poolFinder = mock(PoolFinder.class);\n+    regionAttributes = mock(RegionAttributes.class);\n+    regionMapConstructor = mock(RegionMapConstructor.class);\n+    serverRegionProxyConstructor = mock(ServerRegionProxyConstructor.class);\n+\n+    DiskWriteAttributes diskWriteAttributes = mock(DiskWriteAttributes.class);\n+    EvictionAttributes evictionAttributes = mock(EvictionAttributes.class);\n+    ExpirationAttributes expirationAttributes = mock(ExpirationAttributes.class);\n+    InternalDistributedSystem internalDistributedSystem = mock(InternalDistributedSystem.class);\n+\n+    when(cache.getInternalDistributedSystem()).thenReturn(internalDistributedSystem);\n+    when(evictionAttributes.getAction()).thenReturn(EvictionAction.NONE);\n+    when(internalDistributedSystem.getClock()).thenReturn(mock(DSClock.class));\n+    when(regionAttributes.getDataPolicy()).thenReturn(DataPolicy.DEFAULT);\n+    when(regionAttributes.getDiskWriteAttributes()).thenReturn(diskWriteAttributes);\n+    when(regionAttributes.getEntryIdleTimeout()).thenReturn(expirationAttributes);\n+    when(regionAttributes.getEntryTimeToLive()).thenReturn(expirationAttributes);\n+    when(regionAttributes.getEvictionAttributes()).thenReturn(evictionAttributes);\n+    when(regionAttributes.getRegionIdleTimeout()).thenReturn(expirationAttributes);\n+    when(regionAttributes.getRegionTimeToLive()).thenReturn(expirationAttributes);\n+    when(regionMapConstructor.create(any(), any(), any())).thenReturn(mock(RegionMap.class));\n+  }\n+\n+  @Test\n+  public void getLocalSizeDoesNotThrowNullPointerExceptionDuringConstruction() {\n+    Function<LocalRegion, RegionPerfStats> regionPerfStatsFactory = (localRegion) -> {\n+      localRegion.getLocalSize();\n+      return mock(RegionPerfStats.class);\n+    };\n+\n+    assertThatCode(() -> new LocalRegion(\"region\", regionAttributes, null, cache,\n+        internalRegionArguments, internalDataView, regionMapConstructor,\n+        serverRegionProxyConstructor, entryEventFactory, poolFinder, regionPerfStatsFactory))\n+            .doesNotThrowAnyException();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/c2ef3c682c885b4d49aad51edc1c11e80553bdfa/geode-core/src/test/java/org/apache/geode/internal/cache/LocalRegionTest.java",
                "sha": "22adf2bc602af9175a169a8e8f4e22120daed7c4",
                "status": "added"
            }
        ],
        "message": "GEODE-7001: Prevent potential NPE in LocalRegion\n\nPrevent potential NPE during LocalRegion construction when stat sampling\nis enabled. Specifically, if getLocalSize() is invoked by the callback\nsampler before the RegionMap inside LocalRegion is created then it will\nthrow an NPE.\n\nCo-authored-by: Aaron Lindsey <alindsey@pivotal.io>\nCo-authored-by: Kirk Lund <klund@apache.org>",
        "parent": "https://github.com/apache/geode/commit/81f8f9c1ca1ec9a591287905e559051284117057",
        "patched_files": [
            "LocalRegion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "LocalRegionTest.java",
            "AbstractRegionJUnitTest.java"
        ]
    },
    "geode_c3fb776": {
        "bug_id": "geode_c3fb776",
        "commit": "https://github.com/apache/geode/commit/c3fb77604f1b2566048e48ce9c8b7383c3b176ef",
        "file": [
            {
                "additions": 105,
                "blob_url": "https://github.com/apache/geode/blob/c3fb77604f1b2566048e48ce9c8b7383c3b176ef/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "changes": 105,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java?ref=c3fb77604f1b2566048e48ce9c8b7383c3b176ef",
                "deletions": 0,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "patch": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.LOCATORS;\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.util.Properties;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.contrib.java.lang.system.RestoreSystemProperties;\n+import org.junit.rules.TestName;\n+\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.distributed.internal.DistributionConfig;\n+\n+\n+/**\n+ * junit test for detecting read conflicts\n+ */\n+public class TXDetectReadConflictJUnitTest {\n+\n+  @Rule\n+  public RestoreSystemProperties restoreSystemProperties = new RestoreSystemProperties();\n+\n+  @Rule\n+  public TestName name = new TestName();\n+\n+  protected Cache cache = null;\n+  protected Region region = null;\n+  protected Region regionpr = null;\n+\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    System.setProperty(DistributionConfig.GEMFIRE_PREFIX + \"detectReadConflicts\", \"true\");\n+    createCache();\n+  }\n+\n+  protected void createCache() {\n+    Properties props = new Properties();\n+    props.put(MCAST_PORT, \"0\");\n+    props.put(LOCATORS, \"\");\n+    cache = new CacheFactory(props).create();\n+    region = cache.createRegionFactory(RegionShortcut.REPLICATE).create(\"testRegionRR\");\n+  }\n+\n+  protected void createCachePR() {\n+    Properties props = new Properties();\n+    props.put(MCAST_PORT, \"0\");\n+    props.put(LOCATORS, \"\");\n+    cache = new CacheFactory(props).create();\n+    regionpr = cache.createRegionFactory(RegionShortcut.PARTITION).create(\"testRegionPR\");\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    cache.close();\n+  }\n+\n+  @Test\n+  public void testReadConflictsRR() throws Exception {\n+    cache.close();\n+    createCache();\n+    region.put(\"key\", \"value\");\n+    region.put(\"key1\", \"value1\");\n+    TXManagerImpl mgr = (TXManagerImpl) cache.getCacheTransactionManager();\n+    mgr.begin();\n+    assertEquals(\"value\", region.get(\"key\"));\n+    assertEquals(\"value1\", region.get(\"key1\"));\n+    mgr.commit();\n+  }\n+\n+  @Test\n+  public void testReadConflictsPR() throws Exception {\n+    cache.close();\n+    createCachePR();\n+    regionpr.put(\"key\", \"value\");\n+    regionpr.put(\"key1\", \"value1\");\n+    TXManagerImpl mgr = (TXManagerImpl) cache.getCacheTransactionManager();\n+    mgr.begin();\n+    assertEquals(\"value\", regionpr.get(\"key\"));\n+    assertEquals(\"value1\", regionpr.get(\"key1\"));\n+    mgr.commit();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/c3fb77604f1b2566048e48ce9c8b7383c3b176ef/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/TXDetectReadConflictJUnitTest.java",
                "sha": "810f148796fdb2f1bd849ff844963077bb42b7e5",
                "status": "added"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/c3fb77604f1b2566048e48ce9c8b7383c3b176ef/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java?ref=c3fb77604f1b2566048e48ce9c8b7383c3b176ef",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "patch": "@@ -1882,6 +1882,9 @@ void performRemoveAllAdjunctMessaging(DistributedRemoveAllOperation op,\n       Set<InternalDistributedMember> cacheOpReceivers, Set<InternalDistributedMember> twoMessages,\n       FilterRoutingInfo routing) {\n     Operation op = event.getOperation();\n+    if (op == null) {\n+      return Collections.emptySet();\n+    }\n     if (op.isUpdate() || op.isCreate() || op.isDestroy() || op.isInvalidate()) {\n       // this method can safely assume that the operation is being distributed from\n       // the primary bucket holder to other nodes",
                "raw_url": "https://github.com/apache/geode/raw/c3fb77604f1b2566048e48ce9c8b7383c3b176ef/geode-core/src/main/java/org/apache/geode/internal/cache/BucketRegion.java",
                "sha": "48530907cce9d69539155cafed2e8b79c50d046c",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #3459 from Nordix/feature/GEODE-6651\n\nGEODE-6651: Fixed NPE",
        "parent": "https://github.com/apache/geode/commit/2b2fda692868b0096b17ce55bc084b2f3f9637f2",
        "patched_files": [
            "BucketRegion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "BucketRegionTest.java",
            "TXDetectReadConflictJUnitTest.java"
        ]
    },
    "geode_c4a5ab2": {
        "bug_id": "geode_c4a5ab2",
        "commit": "https://github.com/apache/geode/commit/c4a5ab284baba371418cb7a389cb0f327d8becdc",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/c4a5ab284baba371418cb7a389cb0f327d8becdc/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java?ref=c4a5ab284baba371418cb7a389cb0f327d8becdc",
                "deletions": 0,
                "filename": "geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "patch": "@@ -75,6 +75,10 @@ public void execute(FunctionContext context) {\n     LuceneService service = LuceneServiceProvider.get(region.getCache());\n     LuceneIndexImpl index =\n         (LuceneIndexImpl) service.getIndex(searchContext.getIndexName(), region.getFullPath());\n+    if (index == null) {\n+      throw new InternalFunctionInvocationTargetException(\n+          \"Index for Region:\" + region.getFullPath() + \" was not found\");\n+    }\n     RepositoryManager repoManager = index.getRepositoryManager();\n     LuceneIndexStats stats = index.getIndexStats();\n ",
                "raw_url": "https://github.com/apache/geode/raw/c4a5ab284baba371418cb7a389cb0f327d8becdc/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunction.java",
                "sha": "dd70480d54bfca42a46bcc40554ed6d68cbd739f",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/c4a5ab284baba371418cb7a389cb0f327d8becdc/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java?ref=c4a5ab284baba371418cb7a389cb0f327d8becdc",
                "deletions": 14,
                "filename": "geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "patch": "@@ -208,20 +208,17 @@ public void testIndexRepoQueryFails() throws Exception {\n     function.execute(mockContext);\n   }\n \n-  // Disabled currently as we are retrying the function if a bucket is not found\n-  // @Test(expected = FunctionException.class)\n-  // public void testBucketNotFound() throws Exception {\n-  // when(mockContext.getDataSet()).thenReturn(mockRegion);\n-  // when(mockContext.getArguments()).thenReturn(searchArgs);\n-  // when(mockContext.<TopEntriesCollector>getResultSender()).thenReturn(mockResultSender);\n-  // when(mockRepoManager.getRepositories(eq(mockContext)))\n-  // .thenThrow(new BucketNotFoundException(\"\"));\n-  // LuceneQueryFunction function = new LuceneQueryFunction();\n-  //\n-  // function.execute(mockContext);\n-  //\n-  // verify(mockResultSender).sendException(any(BucketNotFoundException.class));\n-  // }\n+  @Test(expected = FunctionException.class)\n+  public void whenServiceReturnsNullIndexDuringQueryExecutionFunctionExceptionShouldBeThrown()\n+      throws Exception {\n+    when(mockContext.getDataSet()).thenReturn(mockRegion);\n+    when(mockContext.getArguments()).thenReturn(searchArgs);\n+    LuceneQueryFunction function = new LuceneQueryFunction();\n+\n+    when(mockService.getIndex(eq(\"indexName\"), eq(regionPath))).thenReturn(null);\n+\n+    function.execute(mockContext);\n+  }\n \n   @Test(expected = FunctionException.class)\n   public void testReduceError() throws Exception {",
                "raw_url": "https://github.com/apache/geode/raw/c4a5ab284baba371418cb7a389cb0f327d8becdc/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/distributed/LuceneQueryFunctionJUnitTest.java",
                "sha": "6a9af9b3e5f99f737ef51d4bf833e0547a8f80a8",
                "status": "modified"
            }
        ],
        "message": "GEODE-2545: NPE during lucene query execution when cache is closing or region is destroyed\n\n* Throw an InternalFunctionTargetInvocationException if executing a query while cache is closing",
        "parent": "https://github.com/apache/geode/commit/8ff2fd4017ade81510e7705bf0f3254154a8805d",
        "patched_files": [
            "LuceneQueryFunction.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "LuceneQueryFunctionJUnitTest.java"
        ]
    },
    "geode_c5b4401": {
        "bug_id": "geode_c5b4401",
        "commit": "https://github.com/apache/geode/commit/c5b44019dd21847f9f79fc1fbfcf78df70f660e0",
        "file": [
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/c5b44019dd21847f9f79fc1fbfcf78df70f660e0/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java?ref=c5b44019dd21847f9f79fc1fbfcf78df70f660e0",
                "deletions": 10,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "patch": "@@ -817,39 +817,44 @@ public String generateCqName(String serverCqName) {\n     return (serverCqName + this.hashCode());\n   }\n \n+  void processRegisterCq(String serverCqName, ServerCQ ServerCQ, boolean addToCqMap) {\n+    processRegisterCq(serverCqName, ServerCQ, addToCqMap, GemFireCacheImpl.getInstance());\n+  }\n+\n+\n   /**\n    * adds a new CQ to this profile during a delta operation or deserialization\n    *\n    * @param serverCqName the query objects' name\n    * @param ServerCQ the new query object\n    * @param addToCqMap whether to add the query to this.cqs\n    */\n-  void processRegisterCq(String serverCqName, ServerCQ ServerCQ, boolean addToCqMap) {\n+  void processRegisterCq(String serverCqName, ServerCQ ServerCQ, boolean addToCqMap,\n+      GemFireCacheImpl cache) {\n     ServerCQ cq = (ServerCQ) ServerCQ;\n     try {\n-      CqService cqService = GemFireCacheImpl.getInstance().getCqService();\n+      CqService cqService = cache.getCqService();\n       cqService.start();\n       cq.setCqService(cqService);\n       CqStateImpl cqState = (CqStateImpl) cq.getState();\n       cq.setName(generateCqName(serverCqName));\n       cq.registerCq(null, null, cqState.getState());\n     } catch (Exception ex) {\n-      // Change it to Info level.\n-      if (logger.isDebugEnabled()) {\n-        logger.debug(\"Error while initializing the CQs with FilterProfile for CQ {}, Error : {}\",\n-            serverCqName, ex.getMessage(), ex);\n-      }\n+      logger.info(\"Error while initializing the CQs with FilterProfile for CQ {}, Error : {}\",\n+          serverCqName, ex.getMessage(), ex);\n+\n     }\n     if (logger.isDebugEnabled()) {\n       logger.debug(\"Adding CQ to remote members FilterProfile using name: {}\", serverCqName);\n     }\n-    if (addToCqMap) {\n-      this.cqs.put(serverCqName, cq);\n-    }\n \n     // The region's FilterProfile is accessed through CQ reference as the\n     // region is not set on the FilterProfile created for the peer nodes.\n     if (cq.getCqBaseRegion() != null) {\n+      if (addToCqMap) {\n+        this.cqs.put(serverCqName, cq);\n+      }\n+\n       FilterProfile pf = cq.getCqBaseRegion().getFilterProfile();\n       if (pf != null) {\n         pf.incCqCount();",
                "raw_url": "https://github.com/apache/geode/raw/c5b44019dd21847f9f79fc1fbfcf78df70f660e0/geode-core/src/main/java/org/apache/geode/internal/cache/FilterProfile.java",
                "sha": "8a2e8843a4adb7ab34a0acf01e160c45b31a678d",
                "status": "modified"
            },
            {
                "additions": 74,
                "blob_url": "https://github.com/apache/geode/blob/c5b44019dd21847f9f79fc1fbfcf78df70f660e0/geode-core/src/test/java/org/apache/geode/internal/cache/FilterProfileNullCqBaseRegionJUnitTest.java",
                "changes": 74,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/FilterProfileNullCqBaseRegionJUnitTest.java?ref=c5b44019dd21847f9f79fc1fbfcf78df70f660e0",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/FilterProfileNullCqBaseRegionJUnitTest.java",
                "patch": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+import static org.mockito.ArgumentMatchers.anyInt;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.geode.cache.query.CqException;\n+import org.apache.geode.cache.query.RegionNotFoundException;\n+import org.apache.geode.cache.query.internal.CqStateImpl;\n+import org.apache.geode.cache.query.internal.cq.CqService;\n+import org.apache.geode.cache.query.internal.cq.ServerCQ;\n+import org.apache.geode.test.junit.categories.UnitTest;\n+\n+@Category(UnitTest.class)\n+public class FilterProfileNullCqBaseRegionJUnitTest {\n+\n+  private FilterProfile filterProfile;\n+  private CqService mockCqService;\n+  private GemFireCacheImpl mockCache;\n+  private CqStateImpl cqState;\n+  private ServerCQ serverCQ;\n+\n+  @Before\n+  public void setUp() {\n+    mockCache = mock(GemFireCacheImpl.class);\n+    mockCqService = mock(CqService.class);\n+    cqState = mock(CqStateImpl.class);\n+    serverCQ = mock(ServerCQ.class);\n+\n+    when(mockCache.getCqService()).thenReturn(mockCqService);\n+    doNothing().when(mockCqService).start();\n+    when(mockCache.getCacheServers()).thenReturn(Collections.emptyList());\n+    when(serverCQ.getState()).thenReturn(cqState);\n+    when(serverCQ.getCqBaseRegion()).thenReturn(null);\n+\n+  }\n+\n+  @Test\n+  public void whenCqBaseRegionIsNullThenTheCqShouldNotBeAddedToTheCqMap()\n+      throws CqException, RegionNotFoundException {\n+    doThrow(RegionNotFoundException.class).when(serverCQ).registerCq(eq(null), eq(null), anyInt());\n+\n+    filterProfile = new FilterProfile();\n+    filterProfile.processRegisterCq(\"TestCq\", serverCQ, true, mockCache);\n+    assertEquals(0, filterProfile.getCqMap().size());\n+    filterProfile.processCloseCq(\"TestCq\");\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/c5b44019dd21847f9f79fc1fbfcf78df70f660e0/geode-core/src/test/java/org/apache/geode/internal/cache/FilterProfileNullCqBaseRegionJUnitTest.java",
                "sha": "179cf0e4e1306006a7dd5cc2a2feee0cb3bd59c9",
                "status": "added"
            }
        ],
        "message": "GEODE-4827: CQ not added to cq map on exception (#1602)\n\n        * Log level set to info when FilterProfile gets an exception while registering CQ\r\n\t* Before, when there is an exception while registering cq like while cache closing the cq's base region is null\r\n\t* There is an exception which is logged in debug level but execution continues and adds the cq to the cp map with base region set to null\r\n\t* This results in a NullPointerException while closing cq as methods are executed on null region\r\n\t* Now the operation to put the cq into the cq map is inside a if check for null cq base region.",
        "parent": "https://github.com/apache/geode/commit/076d9abfc2aa2d365adfead168f05e054bea0248",
        "patched_files": [
            "FilterProfile.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "FilterProfileNullCqBaseRegionJUnitTest.java"
        ]
    },
    "geode_c7d414a": {
        "bug_id": "geode_c7d414a",
        "commit": "https://github.com/apache/geode/commit/c7d414a8a077f914be27a548cd7644c2f8750dec",
        "file": [
            {
                "additions": 87,
                "blob_url": "https://github.com/apache/geode/blob/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "changes": 87,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java?ref=c7d414a8a077f914be27a548cd7644c2f8750dec",
                "deletions": 0,
                "filename": "geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "patch": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.distributed.internal;\n+\n+\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.test.dunit.IgnoredException;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class RestartOfMemberDistributedTest {\n+  public List<MemberVM> locators = new ArrayList<>();\n+  public List<MemberVM> servers = new ArrayList<>();\n+\n+\n+\n+  @Rule\n+  public ClusterStartupRule clusterStartupRule = new ClusterStartupRule();\n+\n+  @Before\n+  public void before() {\n+    Properties properties = new Properties();\n+\n+    locators.add(clusterStartupRule.startLocatorVM(0, properties));\n+    servers.add(clusterStartupRule.startServerVM(1, properties, locators.get(0).getPort()));\n+    locators.add(clusterStartupRule.startLocatorVM(2, properties, locators.get(0).getPort()));\n+    servers.add(clusterStartupRule.startServerVM(3, properties, locators.get(0).getPort()));\n+  }\n+\n+  @After\n+  public void after() {\n+    servers.clear();\n+    locators.clear();\n+  }\n+\n+  @Test\n+  public void exCoordinatorJoiningQuorumDoesNotThrowNullPointerException() {\n+    IgnoredException exp1 =\n+        IgnoredException.addIgnoredException(ForcedDisconnectException.class.getName());\n+    IgnoredException exp2 =\n+        IgnoredException.addIgnoredException(\"Possible loss of quorum due to the loss\");\n+    IgnoredException exp3 =\n+        IgnoredException.addIgnoredException(\"Received invalid result from\");\n+    try {\n+      int locator2port = locators.get(1).getPort();\n+      Properties properties = new Properties();\n+      int locator0port = locators.get(0).getPort();\n+      clusterStartupRule.crashVM(1);\n+      clusterStartupRule.crashVM(0);\n+      await().until(() -> {\n+        clusterStartupRule.startLocatorVM(0, locator0port, properties, locator2port);\n+        return true;\n+      });\n+      clusterStartupRule.startServerVM(1, properties, locator2port);\n+      locators.get(1).waitTilFullyReconnected();\n+    } finally {\n+      exp1.remove();\n+      exp2.remove();\n+      exp3.remove();\n+    }\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-core/src/distributedTest/java/org/apache/geode/distributed/internal/RestartOfMemberDistributedTest.java",
                "sha": "bc95fc99052b1d3c91c05b37053419e2fefffd25",
                "status": "added"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=c7d414a8a077f914be27a548cd7644c2f8750dec",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -1111,6 +1111,11 @@ private boolean attemptReconnect() throws InterruptedException, IOException {\n       InternalDistributedSystem newSystem =\n           (InternalDistributedSystem) system.getReconnectedSystem();\n       if (newSystem != null) {\n+        boolean noprevlocator = false;\n+        if (!hasLocator()) {\n+          setLocator(this);\n+          noprevlocator = true;\n+        }\n         if (!tcpServerStarted) {\n           if (locatorListener != null) {\n             locatorListener.clearLocatorInfo();\n@@ -1122,10 +1127,12 @@ private boolean attemptReconnect() throws InterruptedException, IOException {\n           restartWithSystem(newSystem, GemFireCacheImpl.getInstance());\n         } catch (CancelException e) {\n           stoppedForReconnect = true;\n+          if (noprevlocator) {\n+            removeLocator(this);\n+          }\n           return false;\n         }\n \n-        setLocator(this);\n         restarted = true;\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "f2408588f712996bc0d512885806312474f0b36d",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java?ref=c7d414a8a077f914be27a548cd7644c2f8750dec",
                "deletions": 3,
                "filename": "geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "patch": "@@ -211,16 +211,21 @@ public MemberVM startLocatorVM(int index, Properties properties, int... locatorP\n         x -> x.withProperties(properties).withConnectionToLocator(locatorPort));\n   }\n \n+  public MemberVM startLocatorVM(int index, int port, Properties properties, int... locatorPort) {\n+    return startLocatorVM(index, port, VersionManager.CURRENT_VERSION,\n+        x -> x.withProperties(properties).withConnectionToLocator(locatorPort));\n+  }\n+\n   public MemberVM startLocatorVM(int index, String version) {\n-    return startLocatorVM(index, version, x -> x);\n+    return startLocatorVM(index, 0, version, x -> x);\n   }\n \n   public MemberVM startLocatorVM(int index,\n       SerializableFunction<LocatorStarterRule> ruleOperator) {\n-    return startLocatorVM(index, VersionManager.CURRENT_VERSION, ruleOperator);\n+    return startLocatorVM(index, 0, VersionManager.CURRENT_VERSION, ruleOperator);\n   }\n \n-  public MemberVM startLocatorVM(int index, String version,\n+  public MemberVM startLocatorVM(int index, int port, String version,\n       SerializableFunction<LocatorStarterRule> ruleOperator) {\n     final String defaultName = \"locator-\" + index;\n     VM locatorVM = getVM(index, version);\n@@ -233,6 +238,9 @@ public MemberVM startLocatorVM(int index, String version,\n       ruleOperator.apply(locatorStarter);\n       locatorStarter.withName(defaultName);\n       locatorStarter.withAutoStart();\n+      if (port != 0) {\n+        locatorStarter.withPort(port);\n+      }\n       locatorStarter.before();\n       return locatorStarter;\n     });",
                "raw_url": "https://github.com/apache/geode/raw/c7d414a8a077f914be27a548cd7644c2f8750dec/geode-dunit/src/main/java/org/apache/geode/test/dunit/rules/ClusterStartupRule.java",
                "sha": "d021e553a7f466903e6c945341eab7089800b1fe",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #3882 from Nordix/feature/GEODE-7036\n\nGEODE-7036: Fix for NPE caused by ex-coordinator joining quorum",
        "parent": "https://github.com/apache/geode/commit/6c6dc146c2044f916fc772e079a144b5cbef6740",
        "patched_files": [
            "ClusterStartupRule.java",
            "InternalLocator.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "RestartOfMemberDistributedTest.java"
        ]
    },
    "geode_ca12f78": {
        "bug_id": "geode_ca12f78",
        "commit": "https://github.com/apache/geode/commit/ca12f781c14409ee87873f604be64d98952c0a9a",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/Locator.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 6,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "patch": "@@ -14,17 +14,17 @@\n  */\n package org.apache.geode.distributed;\n \n+import org.apache.geode.distributed.internal.InternalLocator;\n+import org.apache.geode.internal.i18n.LocalizedStrings;\n+import org.apache.geode.internal.net.SocketCreator;\n+\n import java.io.File;\n import java.io.IOException;\n import java.net.InetAddress;\n import java.util.Collections;\n import java.util.List;\n import java.util.Properties;\n \n-import org.apache.geode.distributed.internal.InternalLocator;\n-import org.apache.geode.internal.net.SocketCreator;\n-import org.apache.geode.internal.i18n.LocalizedStrings;\n-\n /**\n  * Represents a distribution locator server that provides discovery information to members and\n  * clients of a GemFire distributed system. In most GemFire distributed cache architectures,\n@@ -250,8 +250,8 @@ public static Locator startLocatorAndDS(int port, File logFile, InetAddress bind\n   private static Locator startLocator(int port, File logFile, InetAddress bindAddress,\n       java.util.Properties dsProperties, boolean peerLocator, boolean serverLocator,\n       String hostnameForClients) throws IOException {\n-    return InternalLocator.startLocator(port, logFile, null, null, null, bindAddress, dsProperties,\n-        hostnameForClients);\n+    return InternalLocator.startLocator(port, logFile, null, null, null, bindAddress, true,\n+        dsProperties, hostnameForClients);\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/Locator.java",
                "sha": "645b2614f1c6931143855a9b07cae8ec2632d4dc",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/LocatorLauncher.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/LocatorLauncher.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/LocatorLauncher.java",
                "patch": "@@ -649,7 +649,7 @@ public void setStatus(final String statusMessage) {\n         // TODO : remove the extra param for loadFromSharedConfigDir\n         try {\n           this.locator = InternalLocator.startLocator(getPort(), getLogFile(), null, null, null,\n-              getBindAddress(), getDistributedSystemProperties(), getHostnameForClients());\n+              getBindAddress(), true, getDistributedSystemProperties(), getHostnameForClients());\n         } finally {\n           ProcessLauncherContext.remove();\n         }",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/LocatorLauncher.java",
                "sha": "43ab546fadb3553cbe440a700d31f65e0500cb66",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 35,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 26,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -228,11 +228,13 @@ private static boolean removeLocator(InternalLocator locator) {\n       return false;\n     }\n     synchronized (locatorLock) {\n-      if (hasLocator()) {\n-        if (locator.equals(InternalLocator.locator)) {\n-          InternalLocator.locator = null;\n-          return true;\n-        }\n+      LogWriterAppenders.stop(LogWriterAppenders.Identifier.MAIN);\n+      LogWriterAppenders.stop(LogWriterAppenders.Identifier.SECURITY);\n+      LogWriterAppenders.destroy(LogWriterAppenders.Identifier.MAIN);\n+      LogWriterAppenders.destroy(LogWriterAppenders.Identifier.SECURITY);\n+      if (locator != null && locator.equals(InternalLocator.locator)) {\n+        InternalLocator.locator = null;\n+        return true;\n       }\n       return false;\n     }\n@@ -283,26 +285,6 @@ private static void setLocator(InternalLocator locator) {\n     }\n   }\n \n-  /**\n-   * Creates a distribution locator that runs in this VM on the given port and bind address and\n-   * creates a distributed system.\n-   * \n-   * @param port the tcp/ip port to listen on\n-   * @param logFile the file that log messages should be written to\n-   * @param logger a log writer that should be used (logFile parameter is ignored)\n-   * @param securityLogger the logger to be used for security related log messages\n-   * @param dsProperties optional properties to configure the distributed system (e.g., mcast\n-   *        addr/port, other locators)\n-   * @param hostnameForClients the name to give to clients for connecting to this locator\n-   * @since GemFire 7.0\n-   */\n-  public static InternalLocator startLocator(int port, File logFile, File stateFile,\n-      InternalLogWriter logger, InternalLogWriter securityLogger, InetAddress bindAddress,\n-      Properties dsProperties, String hostnameForClients) throws IOException {\n-    return startLocator(port, logFile, stateFile, logger, securityLogger, bindAddress, true,\n-        dsProperties, hostnameForClients);\n-  }\n-\n   /**\n    * Creates a distribution locator that runs in this VM on the given port and bind address.\n    * <p>\n@@ -615,7 +597,8 @@ public static InternalLocator startLocator(int locatorPort, File logFile, File s\n       InternalLogWriter logger, InternalLogWriter logger1, InetAddress addr,\n       Properties dsProperties, boolean peerLocator, boolean serverLocator, String s, boolean b1)\n       throws IOException {\n-    return startLocator(locatorPort, logFile, stateFile, logger, logger1, addr, dsProperties, s);\n+    return startLocator(locatorPort, logFile, stateFile, logger, logger1, addr, true, dsProperties,\n+        s);\n   }\n \n   class SharedConfigurationRunnable implements Runnable {",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "c299dd0d64647fbbb5fe7448cc1e7e46d6ba6b9d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/internal/DistributionLocator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/DistributionLocator.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/DistributionLocator.java",
                "patch": "@@ -167,7 +167,7 @@ public void run() {\n       try {\n \n         InternalLocator locator = InternalLocator.startLocator(port, new File(DEFAULT_LOG_FILE),\n-            null, null, null, address, (Properties) null, hostnameForClients);\n+            null, null, null, address, true, (Properties) null, hostnameForClients);\n \n         ManagerInfo.setLocatorStarted(directory, port, address);\n         locator.waitToStop();",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/internal/DistributionLocator.java",
                "sha": "e190d0b44bd6fdc33a65f181192e97f165bda624",
                "status": "modified"
            },
            {
                "additions": 116,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ConfigCommands.java",
                "changes": 245,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ConfigCommands.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 129,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ConfigCommands.java",
                "patch": "@@ -18,11 +18,11 @@\n \n import org.apache.commons.lang.StringUtils;\n import org.apache.geode.SystemFailure;\n-import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.execute.FunctionInvocationTargetException;\n import org.apache.geode.cache.execute.ResultCollector;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.cache.xmlcache.CacheXml;\n+import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.logging.log4j.LogLevel;\n import org.apache.geode.management.cli.CliMetaData;\n import org.apache.geode.management.cli.ConverterHint;\n@@ -47,6 +47,7 @@\n import org.apache.geode.management.internal.security.ResourceOperation;\n import org.apache.geode.security.ResourcePermission.Operation;\n import org.apache.geode.security.ResourcePermission.Resource;\n+import org.apache.logging.log4j.Logger;\n import org.springframework.shell.core.annotation.CliAvailabilityIndicator;\n import org.springframework.shell.core.annotation.CliCommand;\n import org.springframework.shell.core.annotation.CliOption;\n@@ -72,6 +73,7 @@\n       new GetMemberConfigInformationFunction();\n   private final AlterRuntimeConfigFunction alterRunTimeConfigFunction =\n       new AlterRuntimeConfigFunction();\n+  private static Logger logger = LogService.getLogger();\n \n   @CliCommand(value = {CliStrings.DESCRIBE_CONFIG}, help = CliStrings.DESCRIBE_CONFIG__HELP)\n   @CliMetaData(relatedTopic = {CliStrings.TOPIC_GEODE_CONFIG})\n@@ -252,10 +254,10 @@ public Result exportConfig(\n   public Result alterRuntimeConfig(\n       @CliOption(key = {CliStrings.ALTER_RUNTIME_CONFIG__MEMBER},\n           optionContext = ConverterHint.ALL_MEMBER_IDNAME,\n-          help = CliStrings.ALTER_RUNTIME_CONFIG__MEMBER__HELP) String memberNameOrId,\n+          help = CliStrings.ALTER_RUNTIME_CONFIG__MEMBER__HELP) String[] memberNameOrId,\n       @CliOption(key = {CliStrings.ALTER_RUNTIME_CONFIG__GROUP},\n           optionContext = ConverterHint.MEMBERGROUP,\n-          help = CliStrings.ALTER_RUNTIME_CONFIG__MEMBER__HELP) String group,\n+          help = CliStrings.ALTER_RUNTIME_CONFIG__MEMBER__HELP) String[] group,\n       @CliOption(key = {CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__DISK__SPACE__LIMIT},\n           help = CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__DISK__SPACE__LIMIT__HELP) Integer archiveDiskSpaceLimit,\n       @CliOption(key = {CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__FILE__SIZE__LIMIT},\n@@ -287,153 +289,138 @@ public Result alterRuntimeConfig(\n \n     Map<String, String> runTimeDistributionConfigAttributes = new HashMap<>();\n     Map<String, String> rumTimeCacheAttributes = new HashMap<>();\n-    Set<DistributedMember> targetMembers;\n-\n-    try {\n+    Set<DistributedMember> targetMembers = CliUtil.findMembers(group, memberNameOrId);\n \n-      targetMembers = CliUtil.findMembersOrThrow(group, memberNameOrId);\n+    if (targetMembers.isEmpty()) {\n+      return ResultBuilder.createUserErrorResult(CliStrings.NO_MEMBERS_FOUND_MESSAGE);\n+    }\n \n-      if (archiveDiskSpaceLimit != null) {\n-        runTimeDistributionConfigAttributes.put(\n-            CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__DISK__SPACE__LIMIT,\n-            archiveDiskSpaceLimit.toString());\n-      }\n+    if (archiveDiskSpaceLimit != null) {\n+      runTimeDistributionConfigAttributes.put(\n+          CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__DISK__SPACE__LIMIT,\n+          archiveDiskSpaceLimit.toString());\n+    }\n \n-      if (archiveFileSizeLimit != null) {\n-        runTimeDistributionConfigAttributes.put(\n-            CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__FILE__SIZE__LIMIT,\n-            archiveFileSizeLimit.toString());\n-      }\n+    if (archiveFileSizeLimit != null) {\n+      runTimeDistributionConfigAttributes.put(\n+          CliStrings.ALTER_RUNTIME_CONFIG__ARCHIVE__FILE__SIZE__LIMIT,\n+          archiveFileSizeLimit.toString());\n+    }\n \n-      if (logDiskSpaceLimit != null) {\n-        runTimeDistributionConfigAttributes.put(\n-            CliStrings.ALTER_RUNTIME_CONFIG__LOG__DISK__SPACE__LIMIT, logDiskSpaceLimit.toString());\n-      }\n+    if (logDiskSpaceLimit != null) {\n+      runTimeDistributionConfigAttributes.put(\n+          CliStrings.ALTER_RUNTIME_CONFIG__LOG__DISK__SPACE__LIMIT, logDiskSpaceLimit.toString());\n+    }\n \n-      if (logFileSizeLimit != null) {\n-        runTimeDistributionConfigAttributes.put(\n-            CliStrings.ALTER_RUNTIME_CONFIG__LOG__FILE__SIZE__LIMIT, logFileSizeLimit.toString());\n-      }\n+    if (logFileSizeLimit != null) {\n+      runTimeDistributionConfigAttributes.put(\n+          CliStrings.ALTER_RUNTIME_CONFIG__LOG__FILE__SIZE__LIMIT, logFileSizeLimit.toString());\n+    }\n \n-      if (logLevel != null && !logLevel.isEmpty()) {\n-        runTimeDistributionConfigAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOG__LEVEL,\n-            logLevel);\n-      }\n+    if (logLevel != null && !logLevel.isEmpty()) {\n+      runTimeDistributionConfigAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOG__LEVEL,\n+          logLevel);\n+    }\n \n-      if (statisticArchiveFile != null && !statisticArchiveFile.isEmpty()) {\n-        runTimeDistributionConfigAttributes\n-            .put(CliStrings.ALTER_RUNTIME_CONFIG__STATISTIC__ARCHIVE__FILE, statisticArchiveFile);\n-      }\n+    if (statisticArchiveFile != null && !statisticArchiveFile.isEmpty()) {\n+      runTimeDistributionConfigAttributes\n+          .put(CliStrings.ALTER_RUNTIME_CONFIG__STATISTIC__ARCHIVE__FILE, statisticArchiveFile);\n+    }\n \n-      if (statisticSampleRate != null) {\n-        runTimeDistributionConfigAttributes.put(\n-            CliStrings.ALTER_RUNTIME_CONFIG__STATISTIC__SAMPLE__RATE,\n-            statisticSampleRate.toString());\n-      }\n+    if (statisticSampleRate != null) {\n+      runTimeDistributionConfigAttributes.put(\n+          CliStrings.ALTER_RUNTIME_CONFIG__STATISTIC__SAMPLE__RATE, statisticSampleRate.toString());\n+    }\n \n-      if (statisticSamplingEnabled != null) {\n-        runTimeDistributionConfigAttributes.put(STATISTIC_SAMPLING_ENABLED,\n-            statisticSamplingEnabled.toString());\n-      }\n+    if (statisticSamplingEnabled != null) {\n+      runTimeDistributionConfigAttributes.put(STATISTIC_SAMPLING_ENABLED,\n+          statisticSamplingEnabled.toString());\n+    }\n \n \n-      // Attributes that are set on the cache.\n-      if (setCopyOnRead != null) {\n-        rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__COPY__ON__READ,\n-            setCopyOnRead.toString());\n-      }\n+    // Attributes that are set on the cache.\n+    if (setCopyOnRead != null) {\n+      rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__COPY__ON__READ,\n+          setCopyOnRead.toString());\n+    }\n \n-      if (lockLease != null && lockLease > 0 && lockLease < Integer.MAX_VALUE) {\n-        rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOCK__LEASE,\n-            lockLease.toString());\n-      }\n+    if (lockLease != null && lockLease > 0 && lockLease < Integer.MAX_VALUE) {\n+      rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOCK__LEASE,\n+          lockLease.toString());\n+    }\n \n-      if (lockTimeout != null && lockTimeout > 0 && lockTimeout < Integer.MAX_VALUE) {\n-        rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOCK__TIMEOUT,\n-            lockTimeout.toString());\n-      }\n+    if (lockTimeout != null && lockTimeout > 0 && lockTimeout < Integer.MAX_VALUE) {\n+      rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__LOCK__TIMEOUT,\n+          lockTimeout.toString());\n+    }\n \n-      if (messageSyncInterval != null && messageSyncInterval > 0\n-          && messageSyncInterval < Integer.MAX_VALUE) {\n-        rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__MESSAGE__SYNC__INTERVAL,\n-            messageSyncInterval.toString());\n-      }\n+    if (messageSyncInterval != null && messageSyncInterval > 0\n+        && messageSyncInterval < Integer.MAX_VALUE) {\n+      rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__MESSAGE__SYNC__INTERVAL,\n+          messageSyncInterval.toString());\n+    }\n \n-      if (searchTimeout != null && searchTimeout > 0 && searchTimeout < Integer.MAX_VALUE) {\n-        rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__SEARCH__TIMEOUT,\n-            searchTimeout.toString());\n-      }\n+    if (searchTimeout != null && searchTimeout > 0 && searchTimeout < Integer.MAX_VALUE) {\n+      rumTimeCacheAttributes.put(CliStrings.ALTER_RUNTIME_CONFIG__SEARCH__TIMEOUT,\n+          searchTimeout.toString());\n+    }\n \n-      if (!runTimeDistributionConfigAttributes.isEmpty() || !rumTimeCacheAttributes.isEmpty()) {\n-        Map<String, String> allRunTimeAttributes = new HashMap<>();\n-        allRunTimeAttributes.putAll(runTimeDistributionConfigAttributes);\n-        allRunTimeAttributes.putAll(rumTimeCacheAttributes);\n-\n-        ResultCollector<?, ?> rc = CliUtil.executeFunction(alterRunTimeConfigFunction,\n-            allRunTimeAttributes, targetMembers);\n-        List<CliFunctionResult> results = CliFunctionResult.cleanResults((List<?>) rc.getResult());\n-        CompositeResultData crd = ResultBuilder.createCompositeResultData();\n-        TabularResultData tabularData = crd.addSection().addTable();\n-        Set<String> successfulMembers = new TreeSet<>();\n-        Set<String> errorMessages = new TreeSet<>();\n-\n-\n-        for (CliFunctionResult result : results) {\n-          if (result.getThrowable() != null) {\n-            errorMessages.add(result.getThrowable().getMessage());\n-          } else {\n-            successfulMembers.add(result.getMemberIdOrName());\n-          }\n-        }\n-        final String lineSeparator = System.getProperty(\"line.separator\");\n-        if (!successfulMembers.isEmpty()) {\n-          StringBuilder successMessageBuilder = new StringBuilder();\n+    if (runTimeDistributionConfigAttributes.isEmpty() && rumTimeCacheAttributes.isEmpty()) {\n+      return ResultBuilder\n+          .createUserErrorResult(CliStrings.ALTER_RUNTIME_CONFIG__RELEVANT__OPTION__MESSAGE);\n+    }\n \n-          successMessageBuilder.append(CliStrings.ALTER_RUNTIME_CONFIG__SUCCESS__MESSAGE);\n-          successMessageBuilder.append(lineSeparator);\n+    Map<String, String> allRunTimeAttributes = new HashMap<>();\n+    allRunTimeAttributes.putAll(runTimeDistributionConfigAttributes);\n+    allRunTimeAttributes.putAll(rumTimeCacheAttributes);\n \n-          for (String member : successfulMembers) {\n-            successMessageBuilder.append(member);\n-            successMessageBuilder.append(lineSeparator);\n-          }\n+    ResultCollector<?, ?> rc =\n+        CliUtil.executeFunction(alterRunTimeConfigFunction, allRunTimeAttributes, targetMembers);\n+    List<CliFunctionResult> results = CliFunctionResult.cleanResults((List<?>) rc.getResult());\n+    Set<String> successfulMembers = new TreeSet<>();\n+    Set<String> errorMessages = new TreeSet<>();\n \n-          Properties properties = new Properties();\n-          properties.putAll(runTimeDistributionConfigAttributes);\n-\n-          Result result = ResultBuilder.createInfoResult(successMessageBuilder.toString());\n-\n-          // Set the Cache attributes to be modified\n-          final XmlEntity xmlEntity = XmlEntity.builder().withType(CacheXml.CACHE)\n-              .withAttributes(rumTimeCacheAttributes).build();\n-          persistClusterConfiguration(result,\n-              () -> getSharedConfiguration().modifyXmlAndProperties(properties, xmlEntity,\n-                  group != null ? group.split(\",\") : null));\n-          return result;\n-        } else {\n-          StringBuilder errorMessageBuilder = new StringBuilder();\n-          errorMessageBuilder.append(\"Following errors occurred while altering runtime config\");\n-          errorMessageBuilder.append(lineSeparator);\n-\n-          for (String errorMessage : errorMessages) {\n-            errorMessageBuilder.append(errorMessage);\n-            errorMessageBuilder.append(lineSeparator);\n-          }\n-          return ResultBuilder.createUserErrorResult(errorMessageBuilder.toString());\n-        }\n+    for (CliFunctionResult result : results) {\n+      if (result.getThrowable() != null) {\n+        logger.info(\"Function failed: \" + result.getThrowable());\n+        errorMessages.add(result.getThrowable().getMessage());\n       } else {\n-        return ResultBuilder\n-            .createUserErrorResult(CliStrings.ALTER_RUNTIME_CONFIG__RELEVANT__OPTION__MESSAGE);\n+        successfulMembers.add(result.getMemberIdOrName());\n       }\n-    } catch (CommandResultException crex) {\n-      return crex.getResult();\n-    } catch (CacheClosedException e) {\n-      return ResultBuilder.createGemFireErrorResult(e.getMessage());\n-    } catch (FunctionInvocationTargetException e) {\n-      return ResultBuilder.createGemFireErrorResult(CliStrings\n-          .format(CliStrings.COULD_NOT_EXECUTE_COMMAND_TRY_AGAIN, CliStrings.ALTER_RUNTIME_CONFIG));\n-    } catch (Exception e) {\n-      return ResultBuilder.createGemFireErrorResult(\n-          CliStrings.format(CliStrings.EXCEPTION_CLASS_AND_MESSAGE, e.getClass(), e.getMessage()));\n+    }\n+    final String lineSeparator = System.getProperty(\"line.separator\");\n+    if (!successfulMembers.isEmpty()) {\n+      StringBuilder successMessageBuilder = new StringBuilder();\n+\n+      successMessageBuilder.append(CliStrings.ALTER_RUNTIME_CONFIG__SUCCESS__MESSAGE);\n+      successMessageBuilder.append(lineSeparator);\n+\n+      for (String member : successfulMembers) {\n+        successMessageBuilder.append(member);\n+        successMessageBuilder.append(lineSeparator);\n+      }\n+\n+      Properties properties = new Properties();\n+      properties.putAll(runTimeDistributionConfigAttributes);\n+\n+      Result result = ResultBuilder.createInfoResult(successMessageBuilder.toString());\n+\n+      // Set the Cache attributes to be modified\n+      final XmlEntity xmlEntity = XmlEntity.builder().withType(CacheXml.CACHE)\n+          .withAttributes(rumTimeCacheAttributes).build();\n+      persistClusterConfiguration(result,\n+          () -> getSharedConfiguration().modifyXmlAndProperties(properties, xmlEntity, group));\n+      return result;\n+    } else {\n+      StringBuilder errorMessageBuilder = new StringBuilder();\n+      errorMessageBuilder.append(\"Following errors occurred while altering runtime config\");\n+      errorMessageBuilder.append(lineSeparator);\n+\n+      for (String errorMessage : errorMessages) {\n+        errorMessageBuilder.append(errorMessage);\n+        errorMessageBuilder.append(lineSeparator);\n+      }\n+      return ResultBuilder.createUserErrorResult(errorMessageBuilder.toString());\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/ConfigCommands.java",
                "sha": "6d3f50ff2bcdf9d0450dd40a8defb83c2f2f6e04",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/AlterRuntimeConfigFunction.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/AlterRuntimeConfigFunction.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 4,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/AlterRuntimeConfigFunction.java",
                "patch": "@@ -14,10 +14,6 @@\n  */\n package org.apache.geode.management.internal.cli.functions;\n \n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.Set;\n-\n import org.apache.geode.cache.CacheClosedException;\n import org.apache.geode.cache.CacheFactory;\n import org.apache.geode.cache.execute.FunctionAdapter;\n@@ -26,13 +22,21 @@\n import org.apache.geode.internal.ConfigSource;\n import org.apache.geode.internal.InternalEntity;\n import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.management.internal.cli.CliUtil;\n import org.apache.geode.management.internal.cli.i18n.CliStrings;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Set;\n \n public class AlterRuntimeConfigFunction extends FunctionAdapter implements InternalEntity {\n \n   private static final long serialVersionUID = 1L;\n \n+  private static Logger logger = LogService.getLogger();\n+\n   private InternalCache getCache() {\n     return (InternalCache) CacheFactory.getAnyInstance();\n   }\n@@ -78,6 +82,7 @@ public void execute(FunctionContext context) {\n       context.getResultSender().lastResult(result);\n \n     } catch (Exception e) {\n+      logger.error(\"Exception happened on : \" + memberId, e);\n       CliFunctionResult cliFuncResult =\n           new CliFunctionResult(memberId, e, CliUtil.stackTraceAsString(e));\n       context.getResultSender().lastResult(cliFuncResult);",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/main/java/org/apache/geode/management/internal/cli/functions/AlterRuntimeConfigFunction.java",
                "sha": "53d3ab78f6700f03ee455d0e656f02e9660f6238",
                "status": "modified"
            },
            {
                "additions": 79,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/distributed/internal/InternalLocatorIntegrationTest.java",
                "changes": 79,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/InternalLocatorIntegrationTest.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/InternalLocatorIntegrationTest.java",
                "patch": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.distributed.internal;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.LOG_FILE;\n+import static org.apache.geode.distributed.ConfigurationProperties.NAME;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import org.apache.geode.distributed.Locator;\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.internal.logging.log4j.LogWriterAppender;\n+import org.apache.geode.internal.logging.log4j.LogWriterAppenders;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TemporaryFolder;\n+\n+import java.util.Properties;\n+\n+@Category(IntegrationTest.class)\n+public class InternalLocatorIntegrationTest {\n+\n+  private Locator locator;\n+  private LogWriterAppender appender;\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Test\n+  public void testLogWriterAppenderShouldBeRemovedForALocatorWithNoDS() throws Exception {\n+    Properties properties = new Properties();\n+    properties.setProperty(NAME, \"testVM\");\n+    properties.setProperty(LOG_FILE, temporaryFolder.newFile(\"testVM.log\").getAbsolutePath());\n+\n+    int port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    locator =\n+        InternalLocator.startLocator(port, null, null, null, null, null, false, properties, null);\n+\n+    appender = LogWriterAppenders.getAppender(LogWriterAppenders.Identifier.MAIN);\n+    assertThat(appender).isNotNull();\n+\n+    locator.stop();\n+\n+    appender = LogWriterAppenders.getAppender(LogWriterAppenders.Identifier.MAIN);\n+    assertThat(appender).isNull();\n+  }\n+\n+  @Test\n+  public void testLogWriterAppenderShouldBeRemovedForALocatorWithDS() throws Exception {\n+    Properties properties = new Properties();\n+    properties.setProperty(NAME, \"testVM\");\n+    properties.setProperty(LOG_FILE, temporaryFolder.newFile(\"testVM.log\").getAbsolutePath());\n+\n+    int port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    locator = InternalLocator.startLocatorAndDS(port, null, properties);\n+\n+    appender = LogWriterAppenders.getAppender(LogWriterAppenders.Identifier.MAIN);\n+    assertThat(appender).isNotNull();\n+\n+    locator.stop();\n+\n+    appender = LogWriterAppenders.getAppender(LogWriterAppenders.Identifier.MAIN);\n+    assertThat(appender).isNull();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/distributed/internal/InternalLocatorIntegrationTest.java",
                "sha": "356c79f33f9d2e1f036a7998ac815ea9e2645351",
                "status": "added"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandsDUnitTest.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandsDUnitTest.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 8,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandsDUnitTest.java",
                "patch": "@@ -59,6 +59,7 @@\n import org.apache.geode.management.internal.cli.result.CommandResult;\n import org.apache.geode.management.internal.cli.util.CommandStringBuilder;\n import org.apache.geode.test.dunit.Host;\n+import org.apache.geode.test.dunit.IgnoredException;\n import org.apache.geode.test.dunit.SerializableCallable;\n import org.apache.geode.test.dunit.SerializableRunnable;\n import org.apache.geode.test.dunit.VM;\n@@ -331,9 +332,10 @@ public void testAlterRuntimeConfig() throws Exception {\n         commandProcessor.createCommandStatement(\"alter runtime\", Collections.EMPTY_MAP).process();\n   }\n \n-  @Category(FlakyTest.class) // GEODE-1313\n   @Test\n   public void testAlterRuntimeConfigRandom() throws Exception {\n+    IgnoredException.addIgnoredException(\n+        \"java.lang.IllegalArgumentException: Could not set \\\"log-disk-space-limit\\\"\");\n     final String member1 = \"VM1\";\n     final String controller = \"controller\";\n \n@@ -352,17 +354,14 @@ public void run() {\n         Properties localProps = new Properties();\n         localProps.setProperty(NAME, member1);\n         getSystem(localProps);\n-        Cache cache = getCache();\n+        getCache();\n       }\n     });\n \n     CommandStringBuilder csb = new CommandStringBuilder(CliStrings.ALTER_RUNTIME_CONFIG);\n     CommandResult cmdResult = executeCommand(csb.getCommandString());\n     String resultAsString = commandResultToString(cmdResult);\n \n-    getLogWriter().info(\"#SB Result\\n\");\n-    getLogWriter().info(resultAsString);\n-\n     assertEquals(true, cmdResult.getStatus().equals(Status.ERROR));\n     assertTrue(resultAsString.contains(CliStrings.ALTER_RUNTIME_CONFIG__RELEVANT__OPTION__MESSAGE));\n \n@@ -371,10 +370,9 @@ public void run() {\n     cmdResult = executeCommand(csb.getCommandString());\n     resultAsString = commandResultToString(cmdResult);\n \n-    getLogWriter().info(\"#SB Result\\n\");\n-    getLogWriter().info(resultAsString);\n-\n     assertEquals(true, cmdResult.getStatus().equals(Status.ERROR));\n+    assertTrue(\n+        resultAsString.contains(\"Could not set \\\"log-disk-space-limit\\\" to \\\"2,000,000,000\\\"\"));\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandsDUnitTest.java",
                "sha": "a11002562ba10c39c2ab6108b2099e51a63c8df1",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 3,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "patch": "@@ -75,8 +75,7 @@ protected void after() {\n     DUnitLauncher.closeAndCheckForSuspects();\n     restoreSystemProperties.after();\n     temporaryFolder.delete();\n-    Arrays.stream(members).filter(Objects::nonNull)\n-        .forEach(MemberVM::stopMemberAndCleanupVMIfNecessary);\n+    Arrays.stream(members).filter(Objects::nonNull).forEach(MemberVM::stopMember);\n   }\n \n   public MemberVM<Locator> startLocatorVM(int index) throws Exception {\n@@ -139,7 +138,7 @@ public MemberVM startServerAsEmbededLocator(int index) throws IOException {\n \n   public void stopMember(int index) {\n     MemberVM member = members[index];\n-    member.stopMemberAndCleanupVMIfNecessary();\n+    member.stopMember();\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "sha": "dcdc5c4aa9eb74129547253c912356fd3c6e445a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java?ref=ca12f781c14409ee87873f604be64d98952c0a9a",
                "deletions": 9,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "patch": "@@ -76,12 +76,9 @@ public String getName() {\n     return member.getName();\n   }\n \n-  public void stopMemberAndCleanupVMIfNecessary() {\n-    stopMember();\n-    cleanupVMIfNecessary();\n-  }\n+  public void stopMember() {\n \n-  private void cleanupVMIfNecessary() {\n+    this.invoke(LocatorServerStartupRule::stopMemberInThisVM);\n     /**\n      * The LocatorServerStarterRule may dynamically change the \"user.dir\" system property to point\n      * to a temporary folder. The Path API caches the first value of \"user.dir\" that it sees, and\n@@ -93,8 +90,4 @@ private void cleanupVMIfNecessary() {\n       this.getVM().bounce();\n     }\n   }\n-\n-  public void stopMember() {\n-    this.invoke(LocatorServerStartupRule::stopMemberInThisVM);\n-  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/ca12f781c14409ee87873f604be64d98952c0a9a/geode-core/src/test/java/org/apache/geode/test/dunit/rules/MemberVM.java",
                "sha": "7e5ce1f1e41eff125c5d2e75f389f5ea8b1f90ed",
                "status": "modified"
            }
        ],
        "message": "GEODE-2970: clearing LogWriterAppender when shutting down locator.\n\n* Do not bury the NPE in AlterRuntimeConfigFunction\n* destroy the LogWriterAppender when removing the locator\n* added test",
        "parent": "https://github.com/apache/geode/commit/f9099df50ae061a158a00f1c3a69327bbf583d1a",
        "patched_files": [
            "AlterRuntimeConfigFunction.java",
            "ConfigCommands.java",
            "InternalLocator.java",
            "LocatorServerStartupRule.java",
            "LocatorLauncher.java",
            "DistributionLocator.java",
            "MemberVM.java",
            "Locator.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "InternalLocatorIntegrationTest.java",
            "ConfigCommandsDUnitTest.java",
            "LocatorLauncherTest.java"
        ]
    },
    "geode_cd295f5": {
        "bug_id": "geode_cd295f5",
        "commit": "https://github.com/apache/geode/commit/cd295f5b369176b6ddae15acf224cf288e2e30bf",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/cd295f5b369176b6ddae15acf224cf288e2e30bf/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/AbstractRegionMap.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/AbstractRegionMap.java?ref=cd295f5b369176b6ddae15acf224cf288e2e30bf",
                "deletions": 0,
                "filename": "geode-core/src/main/java/com/gemstone/gemfire/internal/cache/AbstractRegionMap.java",
                "patch": "@@ -804,6 +804,9 @@ public final boolean initialImagePut(final Object key,\n         // server in the VM\n         HAContainerWrapper haContainer = (HAContainerWrapper)CacheClientNotifier\n             .getInstance().getHaContainer();\n+        if (haContainer == null) {\n+          return false;\n+        }\n         Map.Entry entry = null;\n         HAEventWrapper original = null;\n         synchronized (haContainer) {",
                "raw_url": "https://github.com/apache/geode/raw/cd295f5b369176b6ddae15acf224cf288e2e30bf/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/AbstractRegionMap.java",
                "sha": "0cbec19408198a5d4fc7f975b43ad4075e29a580",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/cd295f5b369176b6ddae15acf224cf288e2e30bf/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/CacheClientNotifier.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/CacheClientNotifier.java?ref=cd295f5b369176b6ddae15acf224cf288e2e30bf",
                "deletions": 1,
                "filename": "geode-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/CacheClientNotifier.java",
                "patch": "@@ -1433,6 +1433,9 @@ public void unregisterClientInterest(String regionName, List keysOfInterest,\n    * @since 5.7\n    */\n   private void checkAndRemoveFromClientMsgsRegion(Conflatable conflatable) {\n+    if (haContainer == null) {\n+      return;\n+    }\n     if (conflatable instanceof HAEventWrapper) {\n       HAEventWrapper wrapper = (HAEventWrapper)conflatable;\n       if (!wrapper.getIsRefFromHAContainer()) {\n@@ -2536,7 +2539,7 @@ public void run2() {\n    * (in case of eviction policy \"none\"). In both the cases, it'll store\n    * HAEventWrapper as its key and ClientUpdateMessage as its value.\n    */\n-  private HAContainerWrapper haContainer;\n+  private volatile HAContainerWrapper haContainer;\n \n   //   /**\n   //    * The singleton <code>CacheClientNotifier</code> instance",
                "raw_url": "https://github.com/apache/geode/raw/cd295f5b369176b6ddae15acf224cf288e2e30bf/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/tier/sockets/CacheClientNotifier.java",
                "sha": "712244be152e3e45f43e9bbcea11525ab473c330",
                "status": "modified"
            }
        ],
        "message": "GEODE-1460 RemoveAll fails with NPE in com.gemstone.gemfire.internal.cache.tier.sockets.CacheClientNotifier.checkAndRemoveFromClientMsgsRegion()\n\nMake haContainer volatile.",
        "parent": "https://github.com/apache/geode/commit/11e4b25613a9af24c2f7efff70c8bccbde7d0a7f",
        "patched_files": [
            "AbstractRegionMap.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "AbstractRegionMapTest.java"
        ]
    },
    "geode_cf7ff85": {
        "bug_id": "geode_cf7ff85",
        "commit": "https://github.com/apache/geode/commit/cf7ff85112cc26d11dcbae48a498996a38e9dfea",
        "file": [
            {
                "additions": 29,
                "blob_url": "https://github.com/apache/geode/blob/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/AbstractExecutor.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/AbstractExecutor.java?ref=cf7ff85112cc26d11dcbae48a498996a38e9dfea",
                "deletions": 16,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/AbstractExecutor.java",
                "patch": "@@ -39,6 +39,12 @@ public AbstractExecutor(ThreadsMonitoring tMonitoring) {\n     this.threadID = Thread.currentThread().getId();\n   }\n \n+  public AbstractExecutor(ThreadsMonitoring tMonitoring, long threadID) {\n+    this.startTime = System.currentTimeMillis();\n+    this.numIterationsStuck = 0;\n+    this.threadID = threadID;\n+  }\n+\n   public void handleExpiry(long stuckTime) {\n     this.incNumIterationsStuck();\n     logger.warn(handleLogMessage(stuckTime));\n@@ -50,33 +56,40 @@ private String handleLogMessage(long stuckTime) {\n \n     ThreadInfo thread =\n         ManagementFactory.getThreadMXBean().getThreadInfo(this.threadID, THREAD_DUMP_DEPTH);\n+    boolean logThreadDetails = (thread != null);\n \n     StringBuilder strb = new StringBuilder();\n \n     strb.append(\"Thread <\").append(this.threadID).append(\"> that was executed at <\")\n         .append(dateFormat.format(this.getStartTime())).append(\"> has been stuck for <\")\n         .append((float) stuckTime / 1000)\n         .append(\" seconds> and number of thread monitor iteration <\")\n-        .append(this.numIterationsStuck).append(\"> \").append(System.lineSeparator())\n-        .append(\"Thread Name <\").append(thread.getThreadName()).append(\">\")\n-        .append(System.lineSeparator()).append(\"Thread state <\").append(thread.getThreadState())\n-        .append(\">\").append(System.lineSeparator());\n-\n-    if (thread.getLockName() != null)\n-      strb.append(\"Waiting on <\").append(thread.getLockName()).append(\">\")\n-          .append(System.lineSeparator());\n+        .append(this.numIterationsStuck).append(\"> \").append(System.lineSeparator());\n+    if (logThreadDetails) {\n+      strb.append(\"Thread Name <\").append(thread.getThreadName()).append(\">\")\n+          .append(System.lineSeparator()).append(\"Thread state <\").append(thread.getThreadState())\n+          .append(\">\").append(System.lineSeparator());\n+\n+      if (thread.getLockName() != null)\n+        strb.append(\"Waiting on <\").append(thread.getLockName()).append(\">\")\n+            .append(System.lineSeparator());\n+\n+      if (thread.getLockOwnerName() != null)\n+        strb.append(\"Owned By <\").append(thread.getLockOwnerName()).append(\"> and ID <\")\n+            .append(thread.getLockOwnerId()).append(\">\").append(System.lineSeparator());\n+    }\n \n-    if (thread.getLockOwnerName() != null)\n-      strb.append(\"Owned By <\").append(thread.getLockOwnerName()).append(\"> and ID <\")\n-          .append(thread.getLockOwnerId()).append(\">\").append(System.lineSeparator());\n \n     strb.append(\"Executor Group <\").append(groupName).append(\">\").append(System.lineSeparator())\n         .append(\"Monitored metric <ResourceManagerStats.numThreadsStuck>\")\n-        .append(System.lineSeparator()).append(\"Thread Stack:\").append(System.lineSeparator());\n-\n-    for (int i = 0; i < thread.getStackTrace().length; i++) {\n-      String row = thread.getStackTrace()[i].toString();\n-      strb.append(row).append(System.lineSeparator());\n+        .append(System.lineSeparator());\n+\n+    if (logThreadDetails) {\n+      strb.append(\"Thread Stack:\").append(System.lineSeparator());\n+      for (int i = 0; i < thread.getStackTrace().length; i++) {\n+        String row = thread.getStackTrace()[i].toString();\n+        strb.append(row).append(System.lineSeparator());\n+      }\n     }\n \n     return strb.toString();",
                "raw_url": "https://github.com/apache/geode/raw/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/AbstractExecutor.java",
                "sha": "6864e29f2496813d5936b4dbe9ab6f75096862f3",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/PooledExecutorGroup.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/PooledExecutorGroup.java?ref=cf7ff85112cc26d11dcbae48a498996a38e9dfea",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/PooledExecutorGroup.java",
                "patch": "@@ -25,4 +25,8 @@ public PooledExecutorGroup(ThreadsMonitoring tMonitoring) {\n     setGroupName(GROUPNAME);\n   }\n \n+  public PooledExecutorGroup(ThreadsMonitoring tMonitoring, long threadID) {\n+    super(tMonitoring, threadID);\n+    setGroupName(GROUPNAME);\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/main/java/org/apache/geode/internal/monitoring/executor/PooledExecutorGroup.java",
                "sha": "4ecacef2c005e141e0e04e93b168555fe1942575",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/geode/blob/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/test/java/org/apache/geode/internal/monitoring/ThreadsMonitoringProcessJUnitTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/monitoring/ThreadsMonitoringProcessJUnitTest.java?ref=cf7ff85112cc26d11dcbae48a498996a38e9dfea",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/monitoring/ThreadsMonitoringProcessJUnitTest.java",
                "patch": "@@ -63,6 +63,24 @@ public void testThreadIsStuck() {\n     threadsMonitoringImpl.close();\n   }\n \n+  @Test\n+  public void monitorHandlesDefunctThread() {\n+    final Properties nonDefault = new Properties();\n+    final DistributionConfigImpl distributionConfigImpl = new DistributionConfigImpl(nonDefault);\n+    final long threadID = Long.MAX_VALUE;\n+\n+    int timeLimit = distributionConfigImpl.getThreadMonitorTimeLimit();\n+\n+    AbstractExecutor absExtgroup = new PooledExecutorGroup(threadsMonitoringImpl, threadID);\n+    absExtgroup.setStartTime(absExtgroup.getStartTime() - timeLimit - 1);\n+\n+    threadsMonitoringImpl.getMonitorMap().put(threadID, absExtgroup);\n+\n+    assertTrue(threadsMonitoringImpl.getThreadsMonitoringProcess().mapValidation());\n+\n+    threadsMonitoringImpl.close();\n+  }\n+\n   /**\n    * Tests that indeed thread is NOT considered stuck when it shouldn't\n    */",
                "raw_url": "https://github.com/apache/geode/raw/cf7ff85112cc26d11dcbae48a498996a38e9dfea/geode-core/src/test/java/org/apache/geode/internal/monitoring/ThreadsMonitoringProcessJUnitTest.java",
                "sha": "a5e6563af8db2d2200175ab106d3133e5eccd416",
                "status": "modified"
            }
        ],
        "message": "GEODE-5142 new Thread Monitoring Mechanism\n\nFixing an NPE that may occur if a monitored thread disappears during\nexpiry but before we've reported on its state.",
        "parent": "https://github.com/apache/geode/commit/3f2654cc031b2f812b394fda9e806b4b9f1e167b",
        "patched_files": [
            "PooledExecutorGroup.java",
            "AbstractExecutor.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ThreadsMonitoringProcessJUnitTest.java"
        ]
    },
    "geode_d4d9f7f": {
        "bug_id": "geode_d4d9f7f",
        "commit": "https://github.com/apache/geode/commit/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitor.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitor.java?ref=d4d9f7f83f7ae10fb82d36eeca39b929d99d068e",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitor.java",
                "patch": "@@ -281,9 +281,9 @@ public void handleNotification(StatisticsNotification notification) {\n      */\n     void decreaseParStats() {\n       synchronized (statsMap) {\n-        bucketCount -= statsMap.get(StatsKey.BUCKET_COUNT).intValue();\n-        totalBucketSize -= statsMap.get(StatsKey.TOTAL_BUCKET_SIZE).intValue();\n-        primaryBucketCount -= statsMap.get(StatsKey.PRIMARY_BUCKET_COUNT).intValue();\n+        bucketCount -= statsMap.getOrDefault(StatsKey.BUCKET_COUNT, 0).intValue();\n+        totalBucketSize -= statsMap.getOrDefault(StatsKey.TOTAL_BUCKET_SIZE, 0).intValue();\n+        primaryBucketCount -= statsMap.getOrDefault(StatsKey.PRIMARY_BUCKET_COUNT, 0).intValue();\n         removed = true;\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitor.java",
                "sha": "55f3f67f02e6425e864cbfe7a69a17c731900f14",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitor.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitor.java?ref=d4d9f7f83f7ae10fb82d36eeca39b929d99d068e",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitor.java",
                "patch": "@@ -310,8 +310,8 @@ public void handleNotification(StatisticsNotification notification) {\n      */\n     void decreaseDiskStoreStats() {\n       synchronized (statsMap) {\n-        queueSize -= statsMap.get(StatsKey.DISK_QUEUE_SIZE).intValue();\n-        backupsInProgress -= statsMap.get(StatsKey.BACKUPS_IN_PROGRESS).intValue();;\n+        queueSize -= statsMap.getOrDefault(StatsKey.DISK_QUEUE_SIZE, 0).intValue();\n+        backupsInProgress -= statsMap.getOrDefault(StatsKey.BACKUPS_IN_PROGRESS, 0).intValue();;\n         removed = true;\n       }\n     }",
                "raw_url": "https://github.com/apache/geode/raw/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/main/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitor.java",
                "sha": "392e6c8e45bcb40842220d09163b2840bfcacdbf",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/geode/blob/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitorTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitorTest.java?ref=d4d9f7f83f7ae10fb82d36eeca39b929d99d068e",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitorTest.java",
                "patch": "@@ -245,4 +245,11 @@ public void stopListenerShouldRemoveListenerAndMonitor() {\n     assertThat(aggregateRegionStatsMonitor.getMonitors()).isEmpty();\n     assertThat(aggregateRegionStatsMonitor.getListeners()).isEmpty();\n   }\n+\n+  @Test\n+  public void decreaseDiskStoreStatsShouldNotThrowNPE() {\n+    Statistics statistics = mock(Statistics.class);\n+    aggregateRegionStatsMonitor.addStatisticsToMonitor(statistics);\n+    aggregateRegionStatsMonitor.getListeners().values().forEach((l) -> l.decreaseParStats());\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/AggregateRegionStatsMonitorTest.java",
                "sha": "8c33df3856c502d68fcca82a6501b0679d4ff5aa",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/geode/blob/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitorTest.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitorTest.java?ref=d4d9f7f83f7ae10fb82d36eeca39b929d99d068e",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitorTest.java",
                "patch": "@@ -230,4 +230,12 @@ public void removeStatisticsFromMonitorShouldRemoveListenerAndMonitor() {\n     verify(regionMonitor, times(1)).removeListener(listener);\n     verify(regionMonitor, times(1)).removeStatistics(statistics);\n   }\n+\n+  @Test\n+  public void decreaseDiskStoreStatsShouldNotThrowNPE() {\n+    Statistics statistics = mock(Statistics.class);\n+    memberLevelDiskMonitor.addStatisticsToMonitor(statistics);\n+    memberLevelDiskMonitor.getListeners().values().forEach((l) -> l.decreaseDiskStoreStats());\n+\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/d4d9f7f83f7ae10fb82d36eeca39b929d99d068e/geode-core/src/test/java/org/apache/geode/management/internal/beans/stats/MemberLevelDiskMonitorTest.java",
                "sha": "97a653ed2f7c21341ec35b988d84a0ab2fe631e6",
                "status": "modified"
            }
        ],
        "message": "GEODE-5523: Fixed NPE by converting remaining getOrDefault calls (#2539)",
        "parent": "https://github.com/apache/geode/commit/821c8e1aced91b2b532a90433f8672be853dd84d",
        "patched_files": [
            "AggregateRegionStatsMonitor.java",
            "MemberLevelDiskMonitor.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "AggregateRegionStatsMonitorTest.java",
            "MemberLevelDiskMonitorTest.java"
        ]
    },
    "geode_d79b74a": {
        "bug_id": "geode_d79b74a",
        "commit": "https://github.com/apache/geode/commit/d79b74ab37e2787d07534713392365b5a6a446d0",
        "file": [
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/geode/blob/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java?ref=d79b74ab37e2787d07534713392365b5a6a446d0",
                "deletions": 3,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "patch": "@@ -89,10 +89,21 @@ public Connection getConnection() throws SQLException {\n           loadDriver();\n       }\n     }\n+\n     if (url != null) {\n       Properties props = new Properties();\n-      props.put(\"user\", user);\n-      props.put(\"password\", password);\n+\n+      // If no default username or password is specified don't add these properties - the user may\n+      // be connecting to a system which does not require authentication\n+      if (user != null) {\n+        props.put(\"user\", user);\n+      }\n+\n+      // check for password separately from username - some drivers may throw different error\n+      // messages we want to capture\n+      if (password != null) {\n+        props.put(\"password\", password);\n+      }\n       connection = driverObject.connect(url, props);\n     } else {\n       StringId exception =\n@@ -109,7 +120,6 @@ public Connection getConnection() throws SQLException {\n    *\n    * @param clUsername The username for the database connection.\n    * @param clPassword The password for the database connection.\n-   * @return ???\n    */\n   @Override\n   public Connection getConnection(String clUsername, String clPassword) throws SQLException {",
                "raw_url": "https://github.com/apache/geode/raw/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/main/java/org/apache/geode/internal/datasource/GemFireBasicDataSource.java",
                "sha": "cafa8ae38304b2d78ac5bf71a7cf3df99d452292",
                "status": "modified"
            },
            {
                "additions": 73,
                "blob_url": "https://github.com/apache/geode/blob/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "changes": 73,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java?ref=d79b74ab37e2787d07534713392365b5a6a446d0",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "patch": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.internal.datasource;\n+\n+import static org.assertj.core.api.AssertionsForClassTypes.assertThatThrownBy;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+\n+public class GemFireBasicDataSourceJUnitTest {\n+  private GemFireBasicDataSource dataSource;\n+  private Map params = new HashMap();\n+\n+  @Before\n+  public void setUp() {\n+    params.put(\"connection-url\", \"jdbc:postgresql://myurl:5432\");\n+    params.put(\"jdbc-driver-class\", \"org.apache.geode.internal.datasource.TestDriver\");\n+    params.put(\"jndi-name\", \"datasource\");\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    params.clear();\n+  }\n+\n+  @Test\n+  public void connectWithoutUsernameOrPassword() throws DataSourceCreateException {\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+  }\n+\n+  @Test\n+  public void connectWithUsernameButNoPassword() throws DataSourceCreateException {\n+    params.put(\"user-name\", \"myUser\");\n+\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+  }\n+\n+\n+  @Test\n+  public void connectWithPasswordButNoUsername() throws DataSourceCreateException {\n+    params.put(\"password\", \"myPassword\");\n+\n+    dataSource = (GemFireBasicDataSource) DataSourceFactory.getSimpleDataSource(params);\n+\n+    assertThatThrownBy(() -> dataSource.getConnection())\n+        .hasMessage(\"Test Driver Connection attempted!\");\n+\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/test/java/org/apache/geode/internal/datasource/GemFireBasicDataSourceJUnitTest.java",
                "sha": "d7d7d5d22f2341d0ecbac786fdb19961a223f6c3",
                "status": "added"
            },
            {
                "additions": 62,
                "blob_url": "https://github.com/apache/geode/blob/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "changes": 62,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java?ref=d79b74ab37e2787d07534713392365b5a6a446d0",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "patch": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.internal.datasource;\n+\n+import java.sql.Connection;\n+import java.sql.Driver;\n+import java.sql.DriverPropertyInfo;\n+import java.sql.SQLException;\n+import java.sql.SQLFeatureNotSupportedException;\n+import java.util.Properties;\n+import java.util.logging.Logger;\n+\n+public class TestDriver implements Driver {\n+\n+  @Override\n+  public Connection connect(String url, Properties info) throws SQLException {\n+    throw new SQLException(\"Test Driver Connection attempted!\");\n+  }\n+\n+  @Override\n+  public boolean acceptsURL(String url) throws SQLException {\n+    return false;\n+  }\n+\n+  @Override\n+  public DriverPropertyInfo[] getPropertyInfo(String url, Properties info) throws SQLException {\n+    return new DriverPropertyInfo[0];\n+  }\n+\n+  @Override\n+  public int getMajorVersion() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public int getMinorVersion() {\n+    return 0;\n+  }\n+\n+  @Override\n+  public boolean jdbcCompliant() {\n+    return false;\n+  }\n+\n+  @Override\n+  public Logger getParentLogger() throws SQLFeatureNotSupportedException {\n+    return null;\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/d79b74ab37e2787d07534713392365b5a6a446d0/geode-core/src/test/java/org/apache/geode/internal/datasource/TestDriver.java",
                "sha": "568efa2aca44754b663c9d8b391924fdb255dc13",
                "status": "added"
            }
        ],
        "message": "Added protection for NPE in GemFireBasicDataSource with no credentials\n\nAdded protection against NullPointerExceptions being thrown by\nGemFireBasicDataSource.getConnection() in the event the default username or password\nwere null. Also added tests to confirm this is working as intended.\n\n[GEODE-5450]\n\nCo-authored-by: Benjamin Ross <bross@pivotal.io>\nCo-authored-by: Patrick Johnson <kcirtap1324@gmail.com>",
        "parent": "https://github.com/apache/geode/commit/67d2241be0ffcf1cd16bed48cfb6a74883db5dba",
        "patched_files": [
            "GemFireBasicDataSource.java",
            "Driver.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "TestDriver.java",
            "GemFireBasicDataSourceJUnitTest.java"
        ]
    },
    "geode_da87d64": {
        "bug_id": "geode_da87d64",
        "commit": "https://github.com/apache/geode/commit/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CompactDiskStoreCommand.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CompactDiskStoreCommand.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 11,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CompactDiskStoreCommand.java",
                "patch": "@@ -23,7 +23,6 @@\n import java.util.Map;\n import java.util.Set;\n \n-import org.apache.commons.lang3.ArrayUtils;\n import org.springframework.shell.core.annotation.CliCommand;\n import org.springframework.shell.core.annotation.CliOption;\n \n@@ -163,16 +162,9 @@ public ResultModel compactDiskStore(\n   private boolean diskStoreExists(String diskStoreName) {\n     ManagementService managementService = getManagementService();\n     DistributedSystemMXBean dsMXBean = managementService.getDistributedSystemMXBean();\n-    Map<String, String[]> diskstore = dsMXBean.listMemberDiskstore();\n \n-    Set<Map.Entry<String, String[]>> entrySet = diskstore.entrySet();\n-\n-    for (Map.Entry<String, String[]> entry : entrySet) {\n-      String[] value = entry.getValue();\n-      if (diskStoreName != null && ArrayUtils.contains(value, diskStoreName)) {\n-        return true;\n-      }\n-    }\n-    return false;\n+    return Arrays.stream(dsMXBean.listMembers()).anyMatch(\n+        member -> DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(dsMXBean, member,\n+            diskStoreName));\n   }\n }",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CompactDiskStoreCommand.java",
                "sha": "ab7da0d5271d1a2bcb7be77711096cf99ec2b36f",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateDiskStoreCommand.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateDiskStoreCommand.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 19,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateDiskStoreCommand.java",
                "patch": "@@ -23,7 +23,6 @@\n import java.util.concurrent.TimeUnit;\n \n import org.apache.commons.lang3.tuple.Pair;\n-import org.apache.logging.log4j.Logger;\n import org.springframework.shell.core.annotation.CliCommand;\n import org.springframework.shell.core.annotation.CliOption;\n \n@@ -36,7 +35,6 @@\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.cache.DiskStoreAttributes;\n import org.apache.geode.internal.cache.execute.AbstractExecution;\n-import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.management.DistributedSystemMXBean;\n import org.apache.geode.management.cli.CliMetaData;\n import org.apache.geode.management.cli.ConverterHint;\n@@ -51,7 +49,6 @@\n import org.apache.geode.security.ResourcePermission;\n \n public class CreateDiskStoreCommand extends SingleGfshCommand {\n-  private static final Logger logger = LogService.getLogger();\n   private static final int MBEAN_CREATION_WAIT_TIME = 10000;\n \n   @CliCommand(value = CliStrings.CREATE_DISK_STORE, help = CliStrings.CREATE_DISK_STORE__HELP)\n@@ -155,21 +152,9 @@ boolean waitForDiskStoreMBeanCreation(String diskStore,\n \n     return poll(MBEAN_CREATION_WAIT_TIME, TimeUnit.MILLISECONDS,\n         () -> membersToCreateDiskStoreOn.stream()\n-            .allMatch(m -> diskStoreBeanExists(dsMXBean, m.getName(), diskStore)));\n-  }\n-\n-  private boolean diskStoreBeanExists(DistributedSystemMXBean dsMXBean, String memberName,\n-      String diskStore) {\n-    try {\n-      dsMXBean.fetchDiskStoreObjectName(memberName, diskStore);\n-      return true;\n-    } catch (Exception e) {\n-      if (!e.getMessage().toLowerCase().contains(\"not found\")) {\n-        logger.warn(\"Unable to retrieve Disk Store ObjectName for member: {}, diskstore: {} - {}\",\n-            memberName, diskStore, e.getMessage());\n-      }\n-    }\n-    return false;\n+            .allMatch(\n+                m -> DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(dsMXBean,\n+                    m.getName(), diskStore)));\n   }\n \n   @VisibleForTesting\n@@ -218,7 +203,7 @@ private DiskStoreType createDiskStoreType(String name, DiskStoreAttributes diskS\n   }\n \n   @SuppressWarnings(\"unchecked\")\n-  List<DiskStoreDetails> getDiskStoreListing(Set<DistributedMember> members) {\n+  private List<DiskStoreDetails> getDiskStoreListing(Set<DistributedMember> members) {\n     final Execution membersFunctionExecutor = getMembersFunctionExecutor(members);\n     if (membersFunctionExecutor instanceof AbstractExecution) {\n       ((AbstractExecution) membersFunctionExecutor).setIgnoreDepartedMembers(true);",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateDiskStoreCommand.java",
                "sha": "36d9541d1f1d7b1c2c065a6e9006dadf03939e89",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateRegionCommand.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateRegionCommand.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 19,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateRegionCommand.java",
                "patch": "@@ -18,12 +18,10 @@\n import java.util.Arrays;\n import java.util.Collections;\n import java.util.List;\n-import java.util.Map;\n import java.util.Set;\n import java.util.stream.Collectors;\n \n import joptsimple.internal.Strings;\n-import org.apache.commons.lang3.ArrayUtils;\n import org.apache.commons.lang3.StringUtils;\n import org.apache.commons.lang3.builder.EqualsBuilder;\n import org.springframework.shell.core.annotation.CliCommand;\n@@ -312,7 +310,7 @@ public ResultModel createRegion(\n           !colocatedRegionBean.getRegionType().equals(\"PERSISTENT_PARTITION\")) {\n         return ResultModel.createError(CliStrings.format(\n             CliStrings.CREATE_REGION__MSG__COLOCATEDWITH_REGION_0_IS_NOT_PARTITIONEDREGION,\n-            (Object) prColocatedWith));\n+            prColocatedWith));\n       }\n     }\n \n@@ -538,7 +536,7 @@ String getFullRegionPath() {\n     private final RegionConfig regionConfig;\n     private final String fullRegionPath;\n \n-    public CreateRegionResult(RegionConfig regionConfig, String fullRegionPath) {\n+    CreateRegionResult(RegionConfig regionConfig, String fullRegionPath) {\n       this.regionConfig = regionConfig;\n       this.fullRegionPath = fullRegionPath;\n     }\n@@ -561,12 +559,12 @@ public boolean updateConfigForGroup(String group, CacheConfig config, Object con\n     }\n \n     String[] regionsOnPath = regionPathData.getRegionsOnParentPath();\n-    RegionConfig rootConfig = config.getRegions().stream()\n-        .filter(r -> r.getName().equals(regionsOnPath[0]))\n+\n+    RegionConfig currentConfig = config.getRegions().stream()\n+        .filter(r1 -> r1.getName().equals(regionsOnPath[0]))\n         .findFirst()\n         .get();\n \n-    RegionConfig currentConfig = rootConfig;\n     for (int i = 1; i < regionsOnPath.length; i++) {\n       final String curRegionName = regionsOnPath[i];\n       currentConfig = currentConfig.getRegions()\n@@ -663,24 +661,16 @@ boolean regionExists(String regionPath) {\n     DistributedSystemMXBean dsMBean = managementService.getDistributedSystemMXBean();\n \n     String[] allRegionPaths = dsMBean.listAllRegionPaths();\n-    return Arrays.stream(allRegionPaths).anyMatch(regionPath::equals);\n+    return Arrays.asList(allRegionPaths).contains(regionPath);\n   }\n \n   private boolean diskStoreExists(String diskStoreName) {\n     ManagementService managementService = getManagementService();\n     DistributedSystemMXBean dsMXBean = managementService.getDistributedSystemMXBean();\n-    Map<String, String[]> diskstore = dsMXBean.listMemberDiskstore();\n-\n-    Set<Map.Entry<String, String[]>> entrySet = diskstore.entrySet();\n-\n-    for (Map.Entry<String, String[]> entry : entrySet) {\n-      String[] value = entry.getValue();\n-      if (diskStoreName != null && ArrayUtils.contains(value, diskStoreName)) {\n-        return true;\n-      }\n-    }\n \n-    return false;\n+    return Arrays.stream(dsMXBean.listMembers()).anyMatch(\n+        member -> DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(dsMXBean, member,\n+            diskStoreName));\n   }\n \n   DistributedSystemMXBean getDSMBean() {",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/CreateRegionCommand.java",
                "sha": "09254ed425bb03950d0f5a041c10289c3f3e0cfe",
                "status": "modified"
            },
            {
                "additions": 38,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "changes": 38,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "patch": "@@ -19,17 +19,22 @@\n import java.io.File;\n import java.net.URL;\n import java.util.List;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.stream.Stream;\n \n import org.apache.commons.lang3.StringUtils;\n+import org.apache.logging.log4j.Logger;\n \n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.cache.InternalCache;\n import org.apache.geode.internal.logging.Configuration;\n import org.apache.geode.internal.logging.LogService;\n+import org.apache.geode.management.DistributedSystemMXBean;\n import org.apache.geode.management.internal.cli.CliUtil;\n \n class DiskStoreCommandsUtils {\n+  private static final Logger logger = LogService.getLogger();\n \n   static void configureLogging(final List<String> commandList) {\n     String configFilePropertyValue = System.getProperty(CONFIGURATION_FILE_PROPERTY);\n@@ -64,4 +69,37 @@ static String validatedDirectories(String[] diskDirs) {\n   static Set<DistributedMember> getNormalMembers(final InternalCache cache) {\n     return CliUtil.getAllNormalMembers(cache);\n   }\n+\n+\n+  static boolean diskStoreBeanAndMemberBeanDiskStoreExists(DistributedSystemMXBean dsMXBean,\n+      String memberName,\n+      String diskStore) {\n+    return diskStoreBeanExists(dsMXBean, memberName, diskStore) &&\n+        memberBeanDiskStoreExists(dsMXBean, memberName, diskStore);\n+  }\n+\n+  private static boolean diskStoreBeanExists(DistributedSystemMXBean dsMXBean, String memberName,\n+      String diskStore) {\n+    try {\n+      dsMXBean.fetchDiskStoreObjectName(memberName, diskStore);\n+      return true;\n+    } catch (Exception e) {\n+      if (!e.getMessage().toLowerCase().contains(\"not found\")) {\n+        logger.warn(\"Unable to retrieve Disk Store ObjectName for member: {}, diskstore: {}  {}\",\n+            memberName, diskStore, e.getMessage());\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static boolean memberBeanDiskStoreExists(DistributedSystemMXBean dsMXBean,\n+      String memberName,\n+      String diskStore) {\n+    return Stream.of(dsMXBean)\n+        .filter(Objects::nonNull)\n+        .map(DistributedSystemMXBean::listMemberDiskstore)\n+        .filter(Objects::nonNull)\n+        .flatMap(mds -> Stream.of(mds.get(memberName)))\n+        .anyMatch(dsName -> dsName.equals(diskStore));\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/main/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtils.java",
                "sha": "8e5bbda0492c7076745f28bd2f13587b539d3691",
                "status": "modified"
            },
            {
                "additions": 94,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "changes": 94,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "patch": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.management.internal.cli.commands;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.doReturn;\n+import static org.mockito.Mockito.doThrow;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import javax.management.ObjectName;\n+\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.geode.management.DistributedSystemMXBean;\n+\n+public class DiskStoreCommandsUtilsTest {\n+  private String memberName = \"memberONe\";\n+  private String diskStoreName = \"diskStoreOne\";\n+\n+  @Test\n+  public void diskStoreBeanAndMemberBeanDiskStoreExists() throws Exception {\n+    Map<String, String[]> memberDiskStore = new HashMap<>();\n+    memberDiskStore.put(memberName, new String[] {diskStoreName});\n+    ObjectName objectName = new ObjectName(\"\");\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(memberDiskStore).when(distributedSystemMXBean).listMemberDiskstore();\n+    doReturn(objectName).when(distributedSystemMXBean).fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isTrue();\n+  }\n+\n+  @Test\n+  public void diskStoreBeanExistsAndMemberDiskStoreNotFound() throws Exception {\n+    Map<String, String[]> memberDiskStore = new HashMap<>();\n+    memberDiskStore.put(memberName, new String[] {});\n+    ObjectName objectName = new ObjectName(\"\");\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(memberDiskStore).when(distributedSystemMXBean).listMemberDiskstore();\n+    doReturn(objectName).when(distributedSystemMXBean).fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isFalse();\n+  }\n+\n+  @Test\n+  public void diskStoreBeanNotFoundAndMemberDiskStoreExists() throws Exception {\n+    Map<String, String[]> memberDiskStore = new HashMap<>();\n+    memberDiskStore.put(memberName, new String[] {diskStoreName});\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(memberDiskStore).when(distributedSystemMXBean).listMemberDiskstore();\n+    doThrow(new Exception(\"not found\")).when(distributedSystemMXBean)\n+        .fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isFalse();\n+  }\n+\n+  @Test\n+  public void diskStoreBeanExistsMemberDiskStoreIsNull() throws Exception {\n+    ObjectName objectName = new ObjectName(\"\");\n+\n+    DistributedSystemMXBean distributedSystemMXBean = Mockito.mock(DistributedSystemMXBean.class);\n+    doReturn(null).when(distributedSystemMXBean).listMemberDiskstore();\n+    doReturn(objectName).when(distributedSystemMXBean).fetchDiskStoreObjectName(any(), any());\n+\n+    assertThat(\n+        DiskStoreCommandsUtils.diskStoreBeanAndMemberBeanDiskStoreExists(distributedSystemMXBean,\n+            memberName, diskStoreName)).isFalse();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/DiskStoreCommandsUtilsTest.java",
                "sha": "72f46137a5ca9091132d19c70144766a30dabffc",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/GfshCommandJUnitTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/GfshCommandJUnitTest.java?ref=da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/GfshCommandJUnitTest.java",
                "patch": "@@ -16,30 +16,23 @@\n \n import static org.assertj.core.api.Assertions.assertThatThrownBy;\n import static org.mockito.Mockito.doReturn;\n-import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.spy;\n \n import java.util.Collections;\n \n import org.junit.Before;\n import org.junit.Test;\n \n-import org.apache.geode.distributed.internal.InternalConfigurationPersistenceService;\n import org.apache.geode.management.cli.GfshCommand;\n-import org.apache.geode.management.internal.cli.shell.Gfsh;\n import org.apache.geode.management.internal.exceptions.EntityNotFoundException;\n \n public class GfshCommandJUnitTest {\n \n   private GfshCommand command;\n-  private Gfsh gfsh;\n-  private InternalConfigurationPersistenceService clusterConfigurationService;\n \n   @Before\n   public void before() throws Exception {\n     command = spy(GfshCommand.class);\n-    gfsh = mock(Gfsh.class);\n-    clusterConfigurationService = mock(InternalConfigurationPersistenceService.class);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/geode/raw/da87d6482aa53b7d34473f8d3eb47c4bbd8ab2b8/geode-core/src/test/java/org/apache/geode/management/internal/cli/commands/GfshCommandJUnitTest.java",
                "sha": "767b609f140cccc2b942a266dc556db2ba8907d8",
                "status": "modified"
            }
        ],
        "message": "GEODE-6779: fix issues with DUnit failures (#3810)\n\n- due to different ways of determining existence of disk stores\r\n- added more protection against NPEs\r\n- Move diskStore presence checking to DiskStoreCommandsUtils\r\n- Move tests to newly created DiskStoreCommandsUtilsTest",
        "parent": "https://github.com/apache/geode/commit/1d3ae3c46c097948c7e04a1f93793d54e351a376",
        "patched_files": [
            "CreateRegionCommand.java",
            "CreateDiskStoreCommand.java",
            "DiskStoreCommandsUtils.java",
            "CompactDiskStoreCommand.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "GfshCommandJUnitTest.java",
            "CreateRegionCommandTest.java",
            "CreateDiskStoreCommandTest.java",
            "DiskStoreCommandsUtilsTest.java"
        ]
    },
    "geode_dd15fec": {
        "bug_id": "geode_dd15fec",
        "commit": "https://github.com/apache/geode/commit/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/adapter/GMSMembershipManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/adapter/GMSMembershipManager.java?ref=dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/adapter/GMSMembershipManager.java",
                "patch": "@@ -2585,7 +2585,7 @@ public void forceDisconnect(final String reason) {\n       services.setShutdownCause(shutdownCause);\n       services.getCancelCriterion().cancel(reason);\n \n-      AlertAppender.getInstance().stopSession();\n+      AlertAppender.stopSessionIfRunning();\n \n       if (!inhibitForceDisconnectLogging) {\n         logger.fatal(",
                "raw_url": "https://github.com/apache/geode/raw/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/adapter/GMSMembershipManager.java",
                "sha": "300b36f7bc15d5663c7e98aacc2ebbd0d80a56bd",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/geode/blob/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/main/java/org/apache/geode/internal/logging/log4j/AlertAppender.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/logging/log4j/AlertAppender.java?ref=dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/logging/log4j/AlertAppender.java",
                "patch": "@@ -36,6 +36,7 @@\n import org.apache.logging.log4j.core.config.plugins.PluginBuilderAttribute;\n import org.apache.logging.log4j.core.config.plugins.PluginBuilderFactory;\n \n+import org.apache.geode.annotations.VisibleForTesting;\n import org.apache.geode.annotations.internal.MakeNotStatic;\n import org.apache.geode.distributed.DistributedMember;\n import org.apache.geode.internal.alerting.AlertLevel;\n@@ -337,7 +338,20 @@ public String toString() {\n     return listeners;\n   }\n \n-  public static AlertAppender getInstance() {\n+  @VisibleForTesting\n+  static AlertAppender getInstance() {\n     return instanceRef.get();\n   }\n+\n+  @VisibleForTesting\n+  static void setInstance(AlertAppender alertAppender) {\n+    instanceRef.set(alertAppender);\n+  }\n+\n+  public static void stopSessionIfRunning() {\n+    AlertAppender instance = instanceRef.get();\n+    if (instance != null) {\n+      instance.stopSession();\n+    }\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/main/java/org/apache/geode/internal/logging/log4j/AlertAppender.java",
                "sha": "40332da907a2a3f344e1f2de114c3d1e1c768e43",
                "status": "modified"
            },
            {
                "additions": 26,
                "blob_url": "https://github.com/apache/geode/blob/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/AlertAppenderTest.java",
                "changes": 26,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/AlertAppenderTest.java?ref=dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/logging/log4j/AlertAppenderTest.java",
                "patch": "@@ -15,9 +15,13 @@\n package org.apache.geode.internal.logging.log4j;\n \n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.verify;\n \n import org.apache.logging.log4j.Level;\n+import org.junit.After;\n import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n@@ -52,6 +56,11 @@ public void setUp() {\n     asAlertingProvider = alertAppender;\n   }\n \n+  @After\n+  public void tearDown() {\n+    AlertAppender.setInstance(null);\n+  }\n+\n   @Test\n   public void alertListenersIsEmptyByDefault() {\n     assertThat(alertAppender.getAlertListeners()).isEmpty();\n@@ -164,4 +173,21 @@ public void addAlertListenerOrdersByDescendingAddIfAlertLevelMatches() {\n     assertThat(alertAppender.getAlertListeners()).containsExactly(listener1, listener2,\n         listener3);\n   }\n+\n+  @Test\n+  public void stopSessionIfRunningDoesNotThrowIfReferenceIsNull() {\n+    AlertAppender.setInstance(null);\n+\n+    assertThatCode(AlertAppender::stopSessionIfRunning).doesNotThrowAnyException();\n+  }\n+\n+  @Test\n+  public void stopSessionIfRunningStopCurrentInstance() {\n+    alertAppender = spy(alertAppender);\n+    AlertAppender.setInstance(alertAppender);\n+\n+    AlertAppender.stopSessionIfRunning();\n+\n+    verify(alertAppender).stopSession();\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/dd15fec1f2ecbc3bc0cdfc42072252c379e0bb89/geode-core/src/test/java/org/apache/geode/internal/logging/log4j/AlertAppenderTest.java",
                "sha": "6779b20842ea7ee4b42303999057260eb270023c",
                "status": "modified"
            }
        ],
        "message": "GEODE-6959: Prevent NPE in GMSMembershipManager for null AlertAppender (#3899)\n\nIf a custom log4j2.xml is used without specifying the Geode AlertAppender,\r\nGMSMembershipManager may throw a NullPointerException when invoking\r\nAlertAppender.getInstance().stopSession() during a forceDisconnect. This\r\nchange prevents the NullPointerException allowing forceDisconnect to finish.\r\n\r\nUsers using Spring Boot with Logback are more likely to hit this bug.\r\n\r\nCo-authored-by: Mark Hanson mhanson@pivotal.io",
        "parent": "https://github.com/apache/geode/commit/62317207b2ea3b4b4d7ded96e66250caa01ce76e",
        "patched_files": [
            "GMSMembershipManager.java",
            "AlertAppender.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "AlertAppenderTest.java"
        ]
    },
    "geode_deaa7aa": {
        "bug_id": "geode_deaa7aa",
        "commit": "https://github.com/apache/geode/commit/deaa7aa68e368b26d8fea203d5273a37e7892a2a",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/deaa7aa68e368b26d8fea203d5273a37e7892a2a/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXState.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXState.java?ref=deaa7aa68e368b26d8fea203d5273a37e7892a2a",
                "deletions": 2,
                "filename": "geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXState.java",
                "patch": "@@ -1362,7 +1362,7 @@ protected TXEntryState txReadEntry(KeyInfo keyInfo, LocalRegion localRegion,\n       if (txr == null) {\n         txr = txWriteRegion(localRegion, keyInfo);\n       }\n-      result = localRegion.createReadEntry(txr, keyInfo, createIfAbsent);\n+      result = dataReg.createReadEntry(txr, keyInfo, createIfAbsent);\n     }\n     \n     if (result != null) {\n@@ -1379,7 +1379,7 @@ protected TXEntryState txReadEntry(KeyInfo keyInfo, LocalRegion localRegion,\n        * \n        */\n       if (txr!=null) {\n-        txr.cleanupNonDirtyEntries(localRegion);\n+        txr.cleanupNonDirtyEntries(dataReg);\n       }\n       if (expectedOldValue==null) {\n         /*",
                "raw_url": "https://github.com/apache/geode/raw/deaa7aa68e368b26d8fea203d5273a37e7892a2a/geode-core/src/main/java/com/gemstone/gemfire/internal/cache/TXState.java",
                "sha": "02237b7c2e6171669da6221ed4807f2d53a038ad",
                "status": "modified"
            },
            {
                "additions": 85,
                "blob_url": "https://github.com/apache/geode/blob/deaa7aa68e368b26d8fea203d5273a37e7892a2a/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/lru/TransactionsWithOverflowTest.java",
                "changes": 85,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/lru/TransactionsWithOverflowTest.java?ref=deaa7aa68e368b26d8fea203d5273a37e7892a2a",
                "deletions": 0,
                "filename": "geode-core/src/test/java/com/gemstone/gemfire/internal/cache/lru/TransactionsWithOverflowTest.java",
                "patch": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.gemstone.gemfire.internal.cache.lru;\n+\n+import com.gemstone.gemfire.cache.*;\n+import com.gemstone.gemfire.test.junit.categories.IntegrationTest;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.File;\n+import java.util.Properties;\n+\n+/**\n+ * Test for transactional operations on overflowed data\n+ */\n+@Category(IntegrationTest.class)\n+public class TransactionsWithOverflowTest {\n+\n+  @Rule\n+  public TestName name = new TestName();\n+\n+  private Cache cache;\n+\n+  private String createDiskStoreAndGetName() {\n+    Cache cache = getCache();\n+    File[] diskDirs = new File[1];\n+    diskDirs[0] = new File(\"diskRegionDirs/\"+getClass().getCanonicalName());\n+    diskDirs[0].mkdirs();\n+    DiskStoreFactory diskStoreFactory = cache.createDiskStoreFactory();\n+    diskStoreFactory.setDiskDirs(diskDirs);\n+    String diskStoreName = getClass().getName();\n+    diskStoreFactory.create(diskStoreName);\n+    return diskStoreName;\n+  }\n+\n+  @Test\n+  public void testpartitionedRegionWithOverflow() {\n+    Cache cache = getCache();\n+    String diskStoreName = createDiskStoreAndGetName();\n+    Region pr = createOverflowPR(cache, diskStoreName);\n+    for (int i=0; i<5;i++) {\n+      pr.put(i, \"value\"+i);\n+    }\n+    CacheTransactionManager mgr = cache.getCacheTransactionManager();\n+    mgr.begin();\n+    pr.destroy(1);\n+    mgr.commit();\n+  }\n+\n+  private Cache getCache() {\n+    if (cache == null) {\n+      Properties props = new Properties();\n+      props.setProperty(\"locators\", \"\");\n+      props.setProperty(\"mcast-port\",\"0\");\n+      cache = new CacheFactory(props).create();\n+    }\n+    return cache;\n+  }\n+\n+  private Region createOverflowPR(Cache cache, String diskStoreName) {\n+    RegionFactory rf = cache.createRegionFactory();\n+    rf.setDataPolicy(DataPolicy.PARTITION);\n+    rf.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(1, EvictionAction.OVERFLOW_TO_DISK));\n+    rf.setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(1).create());\n+    rf.setDiskStoreName(diskStoreName);\n+    return rf.create(name.getMethodName());\n+  }\n+}\n\\ No newline at end of file",
                "raw_url": "https://github.com/apache/geode/raw/deaa7aa68e368b26d8fea203d5273a37e7892a2a/geode-core/src/test/java/com/gemstone/gemfire/internal/cache/lru/TransactionsWithOverflowTest.java",
                "sha": "fc906b6ef32408c10d213cc51b30968394d88497",
                "status": "added"
            }
        ],
        "message": "GEODE-983: NPE with transactions on PR with overflow\n\nUse a BucketRegion while faulting-in an overflowed value.",
        "parent": "https://github.com/apache/geode/commit/d50623b04f253b51182114c9fd277db20afeba8b",
        "patched_files": [
            "TXState.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "TransactionsWithOverflowTest.java"
        ]
    },
    "geode_df30df1": {
        "bug_id": "geode_df30df1",
        "commit": "https://github.com/apache/geode/commit/df30df1c8e9a1216a3f9bd07b712e3c4fa99031d",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/df30df1c8e9a1216a3f9bd07b712e3c4fa99031d/geode-dunit/src/main/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-dunit/src/main/java/org/apache/geode/test/junit/rules/MemberStarterRule.java?ref=df30df1c8e9a1216a3f9bd07b712e3c4fa99031d",
                "deletions": 1,
                "filename": "geode-dunit/src/main/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "patch": "@@ -129,10 +129,10 @@ public void after() {\n     // invoke stop() first and then ds.disconnect\n     stopMember();\n \n+    disconnectDSIfAny();\n     // this will clean up the SocketCreators created in this VM so that it won't contaminate\n     // future tests\n     SocketCreatorFactory.close();\n-    disconnectDSIfAny();\n \n     if (temporaryFolder != null) {\n       temporaryFolder.delete();",
                "raw_url": "https://github.com/apache/geode/raw/df30df1c8e9a1216a3f9bd07b712e3c4fa99031d/geode-dunit/src/main/java/org/apache/geode/test/junit/rules/MemberStarterRule.java",
                "sha": "c7ac32e20204100cbe9e07d4c9cb61fa37aecdfb",
                "status": "modified"
            }
        ],
        "message": "GEODE-5676: Disconnect system before closing SocketCreatorFactory\n\nThe MemberStarterRule was closing SocketCreatorFactory before calling\nDistributedSystem.disconnect. In the case of\nClusterConfigLocatorRestartDUnitTest there was a reconnect thread\nrunning in the background that ended up throwing a NullPointerException\nif the SocketCreatorFactory was closed. This led to an infinite loop in\nthe reconnect thread.\n\nWe should not be messing with the internal state of Geode until we call\ndisconnect to stop all of Geode's background threads.\n\nCo-Authored-By: Dale Emery <demery@pivotal.io>",
        "parent": "https://github.com/apache/geode/commit/c80d85baafee1d2e296130d49528d633c9b035ea",
        "patched_files": [
            "MemberStarterRule.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "MemberStarterRuleTest.java"
        ]
    },
    "geode_dfd2a40": {
        "bug_id": "geode_dfd2a40",
        "commit": "https://github.com/apache/geode/commit/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java?ref=dfd2a406618b446a2efc5abc11c5ccba14cd7ea5",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "patch": "@@ -228,6 +228,9 @@ Pattern getFilePattern(String name) {\n \n   private File[] findChildrenExcept(final File dir, final Pattern pattern, final File exception) {\n     final String exceptionName = (exception == null) ? null : exception.getName();\n+    if (dir == null) {\n+      return new File[] {};\n+    }\n     return dir\n         .listFiles((dir1, name) -> !name.equals(exceptionName) && pattern.matcher(name).matches());\n   }",
                "raw_url": "https://github.com/apache/geode/raw/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-core/src/main/java/org/apache/geode/internal/io/MainWithChildrenRollingFileHandler.java",
                "sha": "86667999dd3d150d5d17e5b1e301be2e9c89b88a",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/geode/blob/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java?ref=dfd2a406618b446a2efc5abc11c5ccba14cd7ea5",
                "deletions": 7,
                "filename": "geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "patch": "@@ -107,15 +107,17 @@ protected void before() throws Throwable {\n \n   @Override\n   protected void after() {\n-    DUnitLauncher.closeAndCheckForSuspects();\n+    try {\n+      DUnitLauncher.closeAndCheckForSuspects();\n+    } finally {\n+      MemberStarterRule.disconnectDSIfAny();\n+      IntStream.range(0, DUnitLauncher.NUM_VMS).forEach(this::stopVM);\n \n-    MemberStarterRule.disconnectDSIfAny();\n-    IntStream.range(0, DUnitLauncher.NUM_VMS).forEach(this::stopVM);\n-\n-    if (useTempWorkingDir()) {\n-      tempWorkingDir.delete();\n+      if (useTempWorkingDir()) {\n+        tempWorkingDir.delete();\n+      }\n+      restoreSystemProperties.after();\n     }\n-    restoreSystemProperties.after();\n   }\n \n   public MemberVM<Locator> startLocatorVM(int index) throws Exception {",
                "raw_url": "https://github.com/apache/geode/raw/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-core/src/test/java/org/apache/geode/test/dunit/rules/LocatorServerStartupRule.java",
                "sha": "3079373b630fbe60771452f8d8f1f9094945a5fa",
                "status": "modified"
            },
            {
                "additions": 152,
                "blob_url": "https://github.com/apache/geode/blob/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-web/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandDUnitTest.java",
                "changes": 153,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-web/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandDUnitTest.java?ref=dfd2a406618b446a2efc5abc11c5ccba14cd7ea5",
                "deletions": 1,
                "filename": "geode-web/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandDUnitTest.java",
                "patch": "@@ -54,7 +54,8 @@\n @RunWith(JUnitParamsRunner.class)\n public class ConfigCommandDUnitTest {\n   @Rule\n-  public LocatorServerStartupRule startupRule = new LocatorServerStartupRule();\n+  public LocatorServerStartupRule startupRule =\n+      new LocatorServerStartupRule().withTempWorkingDir().withLogFile();\n \n   @Rule\n   public GfshShellConnectionRule gfsh = new GfshShellConnectionRule();\n@@ -213,6 +214,156 @@ public void testAlterRuntimeConfig(final boolean connectOverHttp) throws Excepti\n         .contains(\"Could not set \\\"log-disk-space-limit\\\" to \\\"2,000,000,000\\\"\");\n   }\n \n+  @Test\n+  @Parameters({\"true\", \"false\"})\n+  public void alterRuntimeConfig_logDiskSpaceLimitWithFileSizeLimitNotSet_OK(\n+      final boolean connectOverHttp) throws Exception {\n+\n+    Properties props = new Properties();\n+    props.setProperty(LOG_LEVEL, \"error\");\n+    MemberVM locator = startupRule.startLocatorVM(0, props);\n+    MemberVM server1 = startupRule.startServerVM(1, locator.getPort());\n+    MemberVM server2 = startupRule.startServerVM(2, locator.getPort());\n+\n+    if (connectOverHttp) {\n+      gfsh.connectAndVerify(locator.getHttpPort(), GfshShellConnectionRule.PortType.http);\n+    } else {\n+      gfsh.connectAndVerify(locator.getJmxPort(), GfshShellConnectionRule.PortType.jmxManger);\n+    }\n+\n+    CommandStringBuilder csb = new CommandStringBuilder(CliStrings.ALTER_RUNTIME_CONFIG);\n+    csb.addOption(CliStrings.ALTER_RUNTIME_CONFIG__LOG__DISK__SPACE__LIMIT, \"10\");\n+\n+    gfsh.executeAndVerifyCommand(csb.toString());\n+    String resultStr = gfsh.getGfshOutput();\n+\n+    server1.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(0);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(10);\n+    });\n+    server2.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(0);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(10);\n+    });\n+  }\n+\n+  @Test\n+  @Parameters({\"true\", \"false\"})\n+  public void alterRuntimeConfig_logDiskSpaceLimitWithFileSizeLimitSet_OK(\n+      final boolean connectOverHttp) throws Exception {\n+\n+    Properties props = new Properties();\n+    props.setProperty(LOG_LEVEL, \"error\");\n+    MemberVM locator = startupRule.startLocatorVM(0, props);\n+    MemberVM server1 = startupRule.startServerVM(1, locator.getPort());\n+    MemberVM server2 = startupRule.startServerVM(2, locator.getPort());\n+\n+    if (connectOverHttp) {\n+      gfsh.connectAndVerify(locator.getHttpPort(), GfshShellConnectionRule.PortType.http);\n+    } else {\n+      gfsh.connectAndVerify(locator.getJmxPort(), GfshShellConnectionRule.PortType.jmxManger);\n+    }\n+\n+    CommandStringBuilder csbSetFileSizeLimit =\n+        new CommandStringBuilder(CliStrings.ALTER_RUNTIME_CONFIG);\n+    csbSetFileSizeLimit.addOption(CliStrings.ALTER_RUNTIME_CONFIG__LOG__FILE__SIZE__LIMIT, \"50\");\n+    gfsh.executeAndVerifyCommand(csbSetFileSizeLimit.toString());\n+\n+    server2.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(50);\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(0);\n+    });\n+\n+    CommandStringBuilder csbSetDiskSpaceLimit =\n+        new CommandStringBuilder(CliStrings.ALTER_RUNTIME_CONFIG);\n+    csbSetDiskSpaceLimit.addOption(CliStrings.ALTER_RUNTIME_CONFIG__LOG__FILE__SIZE__LIMIT, \"50\");\n+    csbSetDiskSpaceLimit.addOption(CliStrings.ALTER_RUNTIME_CONFIG__LOG__DISK__SPACE__LIMIT, \"10\");\n+\n+    gfsh.executeAndVerifyCommand(csbSetDiskSpaceLimit.toString());\n+    String resultStr = gfsh.getGfshOutput();\n+\n+    server1.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(50);\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(10);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+    });\n+    server2.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(50);\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(10);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+    });\n+  }\n+\n+  @Test\n+  @Parameters({\"true\", \"false\"})\n+  public void alterRuntimeConfig_logDiskSpaceLimitOnMember_OK(final boolean connectOverHttp)\n+      throws Exception {\n+\n+    Properties props = new Properties();\n+    props.setProperty(LOG_LEVEL, \"error\");\n+    MemberVM locator = startupRule.startLocatorVM(0, props);\n+    MemberVM server1 = startupRule.startServerVM(1, locator.getPort());\n+    MemberVM server2 = startupRule.startServerVM(2, locator.getPort());\n+\n+    if (connectOverHttp) {\n+      gfsh.connectAndVerify(locator.getHttpPort(), GfshShellConnectionRule.PortType.http);\n+    } else {\n+      gfsh.connectAndVerify(locator.getJmxPort(), GfshShellConnectionRule.PortType.jmxManger);\n+    }\n+\n+    CommandStringBuilder csb = new CommandStringBuilder(CliStrings.ALTER_RUNTIME_CONFIG);\n+    csb.addOption(CliStrings.MEMBERS, server1.getName());\n+    csb.addOption(CliStrings.ALTER_RUNTIME_CONFIG__LOG__DISK__SPACE__LIMIT, \"10\");\n+\n+    gfsh.executeAndVerifyCommand(csb.toString());\n+    String resultStr = gfsh.getGfshOutput();\n+\n+    server1.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(0);\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(10);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+    });\n+    server2.invoke(() -> {\n+      InternalCache cache = LocatorServerStartupRule.serverStarter.getCache();\n+      DistributionConfig config = cache.getInternalDistributedSystem().getConfig();\n+      assertThat(config.getLogFileSizeLimit()).isEqualTo(0);\n+      assertThat(config.getLogDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getArchiveDiskSpaceLimit()).isEqualTo(0);\n+      assertThat(config.getStatisticSampleRate()).isEqualTo(1000);\n+      assertThat(config.getStatisticArchiveFile().getName()).isEqualTo(\"\");\n+      assertThat(config.getStatisticSamplingEnabled()).isTrue();\n+    });\n+  }\n+\n   @Test\n   @Parameters({\"true\", \"false\"})\n   public void testAlterUpdatesSharedConfig(final boolean connectOverHttp) throws Exception {",
                "raw_url": "https://github.com/apache/geode/raw/dfd2a406618b446a2efc5abc11c5ccba14cd7ea5/geode-web/src/test/java/org/apache/geode/management/internal/cli/commands/ConfigCommandDUnitTest.java",
                "sha": "e5ee4285d96b5c1a89d7055677c7e1762b1dceaa",
                "status": "modified"
            }
        ],
        "message": "GEODE-3620: check for null argument to prevent NPE\n\nAdded new tests\n\nFixes problem in LocatorServerStartupRule where a faiulure due to\nsuspect strings caused dunit VM cleanup to be skipped.",
        "parent": "https://github.com/apache/geode/commit/8f6b0b9fced9ed06710bf39d56ef72750171f7ff",
        "patched_files": [
            "MainWithChildrenRollingFileHandler.java",
            "LocatorServerStartupRule.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "ConfigCommandDUnitTest.java"
        ]
    },
    "geode_e7beb92": {
        "bug_id": "geode_e7beb92",
        "commit": "https://github.com/apache/geode/commit/e7beb9290175405c1f285add7c538a0a18df674e",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/e7beb9290175405c1f285add7c538a0a18df674e/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java?ref=e7beb9290175405c1f285add7c538a0a18df674e",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java",
                "patch": "@@ -6606,6 +6606,10 @@ public int getRegionSize() {\n \n   @Override\n   public int getLocalSize() {\n+    if (dataStore == null) {\n+      return 0;\n+    }\n+\n     return dataStore.getLocalBucket2RegionMap().values().stream()\n         .mapToInt(BucketRegion::getLocalSize)\n         .sum();",
                "raw_url": "https://github.com/apache/geode/raw/e7beb9290175405c1f285add7c538a0a18df674e/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java",
                "sha": "4456920b6e548d96e0acfca01bced6d674681f45",
                "status": "modified"
            },
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/geode/blob/e7beb9290175405c1f285add7c538a0a18df674e/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionTest.java",
                "changes": 20,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionTest.java?ref=e7beb9290175405c1f285add7c538a0a18df674e",
                "deletions": 4,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionTest.java",
                "patch": "@@ -17,6 +17,7 @@\n import static org.apache.geode.cache.asyncqueue.internal.AsyncEventQueueImpl.getSenderIdFromAsyncEventQueueId;\n import static org.apache.geode.internal.statistics.StatisticsClockFactory.disabledClock;\n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.ArgumentMatchers.anyInt;\n import static org.mockito.ArgumentMatchers.eq;\n@@ -43,6 +44,7 @@\n import org.junit.Test;\n import org.junit.runner.RunWith;\n \n+import org.apache.geode.Statistics;\n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.CacheLoader;\n import org.apache.geode.cache.CacheWriter;\n@@ -60,7 +62,8 @@\n public class PartitionedRegionTest {\n   private InternalCache internalCache;\n   private PartitionedRegion partitionedRegion;\n-  private Properties gemfireProperties = new Properties();\n+  @SuppressWarnings(\"deprecation\")\n+  private AttributesFactory attributesFactory;\n \n   @Before\n   public void setup() {\n@@ -69,15 +72,16 @@ public void setup() {\n     InternalResourceManager resourceManager =\n         mock(InternalResourceManager.class, RETURNS_DEEP_STUBS);\n     when(internalCache.getInternalResourceManager()).thenReturn(resourceManager);\n-    @SuppressWarnings(\"deprecation\")\n-    AttributesFactory attributesFactory = new AttributesFactory();\n+    attributesFactory = new AttributesFactory();\n     attributesFactory.setPartitionAttributes(\n         new PartitionAttributesFactory().setTotalNumBuckets(1).setRedundantCopies(1).create());\n     partitionedRegion = new PartitionedRegion(\"prTestRegion\", attributesFactory.create(), null,\n         internalCache, mock(InternalRegionArguments.class), disabledClock());\n     DistributedSystem mockDistributedSystem = mock(DistributedSystem.class);\n     when(internalCache.getDistributedSystem()).thenReturn(mockDistributedSystem);\n-    when(mockDistributedSystem.getProperties()).thenReturn(gemfireProperties);\n+    when(mockDistributedSystem.getProperties()).thenReturn(new Properties());\n+    when(mockDistributedSystem.createAtomicStatistics(any(), any()))\n+        .thenReturn(mock(Statistics.class));\n   }\n \n   @SuppressWarnings(\"unused\")\n@@ -303,4 +307,12 @@ public void filterOutNonParallelAsyncEventQueuesShouldReturnCorrectly() {\n         Stream.of(\"parallel\", \"serial\", \"anotherParallel\").collect(Collectors.toSet())))\n             .isNotEmpty().containsExactly(\"parallel\", \"anotherParallel\");\n   }\n+\n+  @Test\n+  public void getLocalSizeDoesNotThrowIfRegionUninitialized() {\n+    partitionedRegion = new PartitionedRegion(\"region\", attributesFactory.create(), null,\n+        internalCache, mock(InternalRegionArguments.class), disabledClock());\n+\n+    assertThatCode(partitionedRegion::getLocalSize).doesNotThrowAnyException();\n+  }\n }",
                "raw_url": "https://github.com/apache/geode/raw/e7beb9290175405c1f285add7c538a0a18df674e/geode-core/src/test/java/org/apache/geode/internal/cache/PartitionedRegionTest.java",
                "sha": "fa46dfec36c62803a4144bb99c8982650daf2371",
                "status": "modified"
            }
        ],
        "message": "GEODE-7081: Prevent NPE in getLocalSize()\n\nPrevent PartitionedRegion's getLocalSize() from throwing a\nNullPointerException if called before its internal data store is\ninitialized. The stats sampler uses this method to get the region's\nentry count, and stats sampling may start before the internal data store\nis initialized.",
        "parent": "https://github.com/apache/geode/commit/3d97e5b3f2e87479886be51f8bf30ea91e29ccc0",
        "patched_files": [
            "PartitionedRegion.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "PartitionedRegionTest.java"
        ]
    },
    "geode_eb3c9bb": {
        "bug_id": "geode_eb3c9bb",
        "commit": "https://github.com/apache/geode/commit/eb3c9bbfd294e32451d8ed5d7458a2084588e827",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 2,
                "filename": "extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "patch": "@@ -309,17 +309,18 @@ public void invalidate() {\n   }\n \n   public void processExpired() {\n-    if (((DeltaSessionManager) getManager()).getLogger().isDebugEnabled()) {\n+    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n+    if (manager != null && manager.getLogger() != null && manager.getLogger().isDebugEnabled()) {\n       ((DeltaSessionManager) getManager()).getLogger().debug(this + \": Expired\");\n     }\n+\n     // Set expired (so region.destroy is not called again)\n     setExpired(true);\n \n     // Do expire processing\n     expire();\n \n     // Update statistics\n-    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n     if (manager != null) {\n       manager.getStatistics().incSessionsExpired();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession8.java",
                "sha": "0b9f58fa7341eb12119f1f5701e68fe41ff37620",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/EmbeddedTomcat8.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/EmbeddedTomcat8.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 5,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/EmbeddedTomcat8.java",
                "patch": "@@ -52,11 +52,6 @@\n   private Tomcat container = null;\n   private Log logger = LogFactory.getLog(getClass());\n \n-  /**\n-   * The directory to create the Tomcat server configuration under.\n-   */\n-  private String catalinaHome = \"doh\";\n-\n   /**\n    * The port to run the Tomcat server on.\n    */\n@@ -90,6 +85,7 @@ public EmbeddedTomcat8(String contextPath, int port, String jvmRoute) throws Mal\n \n     try {\n       new File(localHost.getAppBaseFile().getAbsolutePath()).mkdir();\n+      new File(localHost.getCatalinaBase().getAbsolutePath(), \"logs\").mkdir();\n       rootContext = container.addContext(\"\", localHost.getAppBaseFile().getAbsolutePath());\n     }\n     catch (Exception e) {",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/EmbeddedTomcat8.java",
                "sha": "39c43116c8b9a53f6f5339d80566440a55211b14",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "changes": 54,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 43,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "patch": "@@ -35,60 +35,28 @@\n import org.junit.Before;\n import org.junit.Test;\n \n+import com.gemstone.gemfire.cache.Cache;\n import com.gemstone.gemfire.cache.Region;\n-import com.gemstone.gemfire.internal.AvailablePortHelper;\n-import com.gemstone.gemfire.modules.session.catalina.ClientServerCacheLifecycleListener;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n-import com.gemstone.gemfire.modules.session.catalina.PeerToPeerCacheLifecycleListener;\n+import com.gemstone.gemfire.test.dunit.VM;\n+import com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase;\n \n-public abstract class TestSessionsTomcat8Base {\n+public abstract class TestSessionsTomcat8Base extends JUnit4DistributedTestCase{\n \n-  private static EmbeddedTomcat8 server;\n+  protected static EmbeddedTomcat8 server;\n \n-  private static Region<String, HttpSession> region;\n+  protected static Region<String, HttpSession> region;\n \n-  private static StandardWrapper servlet;\n+  protected static StandardWrapper servlet;\n \n-  private static DeltaSessionManager sessionManager;\n+  protected static DeltaSessionManager sessionManager;\n \n-  private static int port;\n+  protected static int port;\n \n-  // Set up the servers we need\n-  public static void setupServer(DeltaSessionManager manager) throws Exception {\n-    port = AvailablePortHelper.getRandomAvailableTCPPort();\n-    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+  protected Cache cache;\n \n-    PeerToPeerCacheLifecycleListener p2pListener = new PeerToPeerCacheLifecycleListener();\n-    p2pListener.setProperty(MCAST_PORT, \"0\");\n-    p2pListener.setProperty(LOG_LEVEL, \"config\");\n-    server.addLifecycleListener(p2pListener);\n-    sessionManager = manager;\n-    sessionManager.setEnableCommitValve(true);\n-    server.getRootContext().setManager(sessionManager);\n+  protected VM vm0;\n \n-    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n-    server.startContainer();\n-\n-    /*\n-     * Can only retrieve the region once the container has started up\n-     * (and the cache has started too).\n-     */\n-    region = sessionManager.getSessionCache().getSessionRegion();\n-  }\n-\n-  @AfterClass\n-  public static void teardownClass() throws Exception {\n-    server.stopContainer();\n-  }\n-\n-  /**\n-   * Reset some data\n-   */\n-  @Before\n-  public void setup() throws Exception {\n-    sessionManager.getTheContext().setSessionTimeout(30);\n-    region.clear();\n-  }\n \n   /**\n    * Check that the basics are working",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/TestSessionsTomcat8Base.java",
                "sha": "f8604bf9d5707134f379008d5fd3547986bd7819",
                "status": "modified"
            },
            {
                "additions": 96,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "changes": 96,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 0,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "patch": "@@ -0,0 +1,96 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*      http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package com.gemstone.gemfire.modules.session;\n+\n+import static com.gemstone.gemfire.distributed.ConfigurationProperties.*;\n+import static com.gemstone.gemfire.internal.cache.CacheServerLauncher.serverPort;\n+\n+import java.util.Properties;\n+\n+import org.junit.experimental.categories.Category;\n+\n+import com.gemstone.gemfire.cache.Cache;\n+import com.gemstone.gemfire.cache.CacheFactory;\n+import com.gemstone.gemfire.cache.client.PoolFactory;\n+import com.gemstone.gemfire.cache.client.PoolManager;\n+import com.gemstone.gemfire.cache.server.CacheServer;\n+import com.gemstone.gemfire.internal.AvailablePortHelper;\n+import com.gemstone.gemfire.internal.cache.GemFireCacheImpl;\n+import com.gemstone.gemfire.modules.session.catalina.ClientServerCacheLifecycleListener;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n+import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n+import com.gemstone.gemfire.test.dunit.Host;\n+import com.gemstone.gemfire.test.junit.categories.DistributedTest;\n+import com.gemstone.gemfire.test.junit.categories.UnitTest;\n+\n+@Category(DistributedTest.class)\n+public class Tomcat8SessionsClientServerDUnitTest extends TestSessionsTomcat8Base {\n+\n+  // Set up the session manager we need\n+  @Override\n+  public void postSetUp() throws Exception {\n+    setupServer(new Tomcat8DeltaSessionManager());\n+  }\n+\n+  @Override\n+  public void preTearDown() {\n+    vm0.invoke(() -> {\n+      GemFireCacheImpl.getInstance().getCacheServers().forEach(e -> ((CacheServer)e).stop());\n+    });\n+    server.stopContainer();\n+  }\n+\n+  // Set up the servers we need\n+  public void setupServer(DeltaSessionManager manager) throws Exception {\n+    Host host = Host.getHost(0);\n+    vm0 = host.getVM(1);\n+    String hostName = vm0.getHost().getHostName();\n+    int cacheServerPort = vm0.invoke(() -> {\n+      Properties props = new Properties();\n+      CacheFactory cf = new CacheFactory(props);\n+      Cache cache = cf.create();\n+      CacheServer server = cache.addCacheServer();\n+      server.start();\n+      return server.getPort();\n+    });\n+\n+    port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+\n+    ClientServerCacheLifecycleListener listener = new ClientServerCacheLifecycleListener();\n+    listener.setProperty(MCAST_PORT, \"0\");\n+    listener.setProperty(LOG_LEVEL, \"config\");\n+    server.addLifecycleListener(listener);\n+    sessionManager = manager;\n+    sessionManager.setEnableCommitValve(true);\n+    server.getRootContext().setManager(sessionManager);\n+\n+    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n+    server.startContainer();\n+\n+    PoolFactory pf = PoolManager.createFactory();\n+    pf.addServer(hostName, cacheServerPort);\n+    pf.create(\"Pool Connecting to Cache Server\");\n+\n+    /*\n+     * Can only retrieve the region once the container has started up\n+     * (and the cache has started too).\n+     */\n+    region = sessionManager.getSessionCache().getSessionRegion();\n+    sessionManager.getTheContext().setSessionTimeout(30);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsClientServerDUnitTest.java",
                "sha": "ca9cdbe081cf1dbd6262e209830cd7fd46fb9a3f",
                "status": "added"
            },
            {
                "additions": 77,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 0,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "patch": "@@ -0,0 +1,77 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*      http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package com.gemstone.gemfire.modules.session;\n+\n+import static com.gemstone.gemfire.distributed.ConfigurationProperties.*;\n+\n+import com.gemstone.gemfire.internal.AvailablePortHelper;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n+import com.gemstone.gemfire.modules.session.catalina.PeerToPeerCacheLifecycleListener;\n+import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n+import com.gemstone.gemfire.test.junit.categories.DistributedTest;\n+import com.gemstone.gemfire.test.junit.categories.UnitTest;\n+\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.experimental.categories.Category;\n+\n+@Category(DistributedTest.class)\n+public class Tomcat8SessionsDUnitTest extends TestSessionsTomcat8Base {\n+\n+  // Set up the session manager we need\n+  @Override\n+  public void postSetUp() throws Exception {\n+    setupServer(new Tomcat8DeltaSessionManager());\n+  }\n+\n+  @Override\n+  public void preTearDown() throws Exception {\n+    server.stopContainer();\n+  }\n+\n+  public void setupServer(DeltaSessionManager manager) throws Exception {\n+    port = AvailablePortHelper.getRandomAvailableTCPPort();\n+    server = new EmbeddedTomcat8(\"/test\", port, \"JVM-1\");\n+\n+    PeerToPeerCacheLifecycleListener p2pListener = new PeerToPeerCacheLifecycleListener();\n+    p2pListener.setProperty(MCAST_PORT, \"0\");\n+    p2pListener.setProperty(LOG_LEVEL, \"config\");\n+    server.addLifecycleListener(p2pListener);\n+    sessionManager = manager;\n+    sessionManager.setEnableCommitValve(true);\n+    server.getRootContext().setManager(sessionManager);\n+\n+    servlet = server.addServlet(\"/test/*\", \"default\", CommandServlet.class.getName());\n+    server.startContainer();\n+\n+    /*\n+     * Can only retrieve the region once the container has started up\n+     * (and the cache has started too).\n+     */\n+    region = sessionManager.getSessionCache().getSessionRegion();\n+  }\n+\n+  /**\n+   * Reset some data\n+   */\n+  @Before\n+  public void setup() throws Exception {\n+    sessionManager.getTheContext().setSessionTimeout(30);\n+    region.clear();\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsDUnitTest.java",
                "sha": "e573c4e48aee4a1b8e6dff487a07c7b1d711af70",
                "status": "added"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/geode/blob/9fa589708c03754c85e7d10e353fbe47294673db/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "changes": 32,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java?ref=9fa589708c03754c85e7d10e353fbe47294673db",
                "deletions": 32,
                "filename": "extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "patch": "@@ -1,32 +0,0 @@\n-/*\n-* Licensed to the Apache Software Foundation (ASF) under one or more\n-* contributor license agreements.  See the NOTICE file distributed with\n-* this work for additional information regarding copyright ownership.\n-* The ASF licenses this file to You under the Apache License, Version 2.0\n-* (the \"License\"); you may not use this file except in compliance with\n-* the License.  You may obtain a copy of the License at\n-*\n-*      http://www.apache.org/licenses/LICENSE-2.0\n-*\n-* Unless required by applicable law or agreed to in writing, software\n-* distributed under the License is distributed on an \"AS IS\" BASIS,\n-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-* See the License for the specific language governing permissions and\n-* limitations under the License.\n-*/\n-package com.gemstone.gemfire.modules.session;\n-\n-import com.gemstone.gemfire.modules.session.catalina.Tomcat8DeltaSessionManager;\n-import com.gemstone.gemfire.test.junit.categories.UnitTest;\n-import org.junit.BeforeClass;\n-import org.junit.experimental.categories.Category;\n-\n-@Category(UnitTest.class)\n-public class Tomcat8SessionsJUnitTest extends TestSessionsTomcat8Base {\n-\n-  // Set up the session manager we need\n-  @BeforeClass\n-  public static void setupClass() throws Exception {\n-    setupServer(new Tomcat8DeltaSessionManager());\n-  }\n-}",
                "raw_url": "https://github.com/apache/geode/raw/9fa589708c03754c85e7d10e353fbe47294673db/extensions/geode-modules-tomcat8/src/test/java/com/gemstone/gemfire/modules/session/Tomcat8SessionsJUnitTest.java",
                "sha": "df65690ee0cb1badb12cf16425aea9732bc07f07",
                "status": "removed"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 3,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "patch": "@@ -90,9 +90,7 @@ public void lifecycleEvent(LifecycleTypeAdapter eventType) {\n         rebalanceCache();\n       }\n     } else if (eventType.equals(LifecycleTypeAdapter.STOP)) {\n-      // Close the cache\n-//      closeCache();\n-      // TODO: Do we need to reset the started flag here?\n+      started.set(false);\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/AbstractCache.java",
                "sha": "9704853131a3de61a996abd08249339a1ef32d95",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 1,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "patch": "@@ -52,7 +52,7 @@ protected void createOrRetrieveCache() {\n \n     // If no cache exists, create one\n     String message = null;\n-    if (this.cache == null) {\n+    if (this.cache == null || this.cache.isClosed()) {\n       // enable pool subscription so that default cache can be used by hibernate module\n       this.cache = new ClientCacheFactory(createDistributedSystemProperties()).create();\n       message = \"Created \";",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/ClientServerCache.java",
                "sha": "a4bd7a5af6e39d7be19d2a00da5a818534b2f5f8",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 1,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "patch": "@@ -55,7 +55,7 @@ protected void createOrRetrieveCache() {\n \n     // If no cache exists, create one\n     String message = null;\n-    if (this.cache == null) {\n+    if (this.cache == null || cache.isClosed()) {\n       this.cache = new CacheFactory(createDistributedSystemProperties()).create();\n       message = \"Created \";\n     } else {",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/bootstrap/PeerToPeerCache.java",
                "sha": "92c5f1fd157df0117a3b70de799ebc3426b27792",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 2,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "patch": "@@ -317,17 +317,18 @@ public void invalidate() {\n   }\n \n   public void processExpired() {\n-    if (((DeltaSessionManager) getManager()).getLogger().isDebugEnabled()) {\n+    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n+    if (manager != null && manager.getLogger() != null && manager.getLogger().isDebugEnabled()) {\n       ((DeltaSessionManager) getManager()).getLogger().debug(this + \": Expired\");\n     }\n+\n     // Set expired (so region.destroy is not called again)\n     setExpired(true);\n \n     // Do expire processing\n     expire();\n \n     // Update statistics\n-    DeltaSessionManager manager = (DeltaSessionManager) getManager();\n     if (manager != null) {\n       manager.getStatistics().incSessionsExpired();\n     }",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSession.java",
                "sha": "754376a16e990c420cdbea7845531a90d941221f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 0,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "patch": "@@ -49,4 +49,5 @@\n   void setOwner(Object manager);\n   void activate();\n \n+  void processExpired();\n }",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/DeltaSessionInterface.java",
                "sha": "a2934328f7b0d3441186414bdecb6d78310b31ef",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java?ref=eb3c9bbfd294e32451d8ed5d7458a2084588e827",
                "deletions": 2,
                "filename": "extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "patch": "@@ -21,6 +21,7 @@\n import com.gemstone.gemfire.cache.Operation;\n import com.gemstone.gemfire.cache.util.CacheListenerAdapter;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSession;\n+import com.gemstone.gemfire.modules.session.catalina.DeltaSessionInterface;\n import com.gemstone.gemfire.modules.session.catalina.DeltaSessionManager;\n import com.gemstone.gemfire.modules.util.ContextMapper;\n \n@@ -35,9 +36,9 @@ public void afterDestroy(EntryEvent<String, HttpSession> event) {\n     // A Session expired. If it was destroyed by GemFire expiration, process it.\n     // If it was destroyed via Session.invalidate, ignore it since it has\n     // already been processed.\n-    DeltaSession session = null;\n+    DeltaSessionInterface session = null;\n     if (event.getOperation() == Operation.EXPIRE_DESTROY) {\n-      session = (DeltaSession) event.getOldValue();\n+      session = (DeltaSessionInterface) event.getOldValue();\n     } else {\n       /*\n        * This comes into play when we're dealing with an empty client proxy. We",
                "raw_url": "https://github.com/apache/geode/raw/eb3c9bbfd294e32451d8ed5d7458a2084588e827/extensions/geode-modules/src/main/java/com/gemstone/gemfire/modules/session/catalina/callback/SessionExpirationCacheListener.java",
                "sha": "4fd1136b8ffee750fe32789102d54ba371248ac6",
                "status": "modified"
            }
        ],
        "message": "GEODE-1675: Fix ClassCastException in ClientServer expiry\n\n* Also fix for NPE if session manager somehow is null in a session\n* Added tests for client/server session management\n* Refactored existing tests so they can share tests with client/server set up\n* EmbeddedTomcat will explictly create a log directory",
        "parent": "https://github.com/apache/geode/commit/9fa589708c03754c85e7d10e353fbe47294673db",
        "patched_files": [
            "AbstractCache.java",
            "EmbeddedTomcat8.java",
            "PeerToPeerCache.java",
            "DeltaSession8.java",
            "DeltaSession.java",
            "DeltaSessionInterface.java",
            "ClientServerCache.java",
            "SessionExpirationCacheListener.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "Tomcat8SessionsDUnitTest.java",
            "Tomcat8SessionsJUnitTest.java",
            "TestSessionsTomcat8Base.java",
            "Tomcat8SessionsClientServerDUnitTest.java"
        ]
    },
    "geode_f30f936": {
        "bug_id": "geode_f30f936",
        "commit": "https://github.com/apache/geode/commit/f30f9367bd7334a4e9f191d80568d7a1e0c13536",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/integrationTest/java/org/apache/geode/pdx/internal/MultipleCacheJUnitTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/integrationTest/java/org/apache/geode/pdx/internal/MultipleCacheJUnitTest.java?ref=f30f9367bd7334a4e9f191d80568d7a1e0c13536",
                "deletions": 1,
                "filename": "geode-core/src/integrationTest/java/org/apache/geode/pdx/internal/MultipleCacheJUnitTest.java",
                "patch": "@@ -72,7 +72,7 @@ public void startLocator() throws IOException {\n \n     locator = Locator.startLocatorAndDS(0, locatorFolder.newFile(\"locator.log\"), null);\n     configProperties = new Properties();\n-    configProperties.setProperty(LOCATORS, \"locahost[\" + locator.getPort() + \"]\");\n+    configProperties.setProperty(LOCATORS, \"localhost[\" + locator.getPort() + \"]\");\n   }\n \n   @After",
                "raw_url": "https://github.com/apache/geode/raw/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/integrationTest/java/org/apache/geode/pdx/internal/MultipleCacheJUnitTest.java",
                "sha": "e17d95026c6bab5b5f3a2885e4b6642d857f13dc",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java?ref=f30f9367bd7334a4e9f191d80568d7a1e0c13536",
                "deletions": 2,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "patch": "@@ -589,8 +589,6 @@ int startPeerLocation() throws IOException {\n     }\n     logger.info(\"Starting peer location for {}\", this);\n \n-    String locatorsConfigValue = distributionConfig.getLocators();\n-\n     // check for settings that would require only locators to hold the\n     // coordinator - e.g., security and network-partition detection\n     boolean locatorsAreCoordinators;\n@@ -608,6 +606,8 @@ int startPeerLocation() throws IOException {\n       }\n     }\n \n+    final String locatorsConfigValue = distributionConfig.getLocators();\n+\n     netLocator = NetLocatorFactory.newLocatorHandler(bindAddress, locatorsConfigValue,\n         locatorsAreCoordinators, networkPartitionDetectionEnabled, locatorStats, securityUDPDHAlgo,\n         workingDirectory);",
                "raw_url": "https://github.com/apache/geode/raw/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/InternalLocator.java",
                "sha": "bfb223c30b308ae12e36fc2e83a9e0c7723fe8de",
                "status": "modified"
            },
            {
                "additions": 61,
                "blob_url": "https://github.com/apache/geode/blob/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "changes": 98,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java?ref=f30f9367bd7334a4e9f191d80568d7a1e0c13536",
                "deletions": 37,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "patch": "@@ -102,62 +102,86 @@ public static GMSMember readMemberID(DataInput in,\n    * @param locatorsString a DistributionConfig \"locators\" string\n    * @param bindAddress optional address to check for loopback compatibility\n    * @return addresses of locators\n+   *\n+   * @see org.apache.geode.distributed.ConfigurationProperties#LOCATORS for format\n    */\n   public static List<HostAddress> parseLocators(String locatorsString, InetAddress bindAddress) {\n     List<HostAddress> result = new ArrayList<>(2);\n     Set<InetSocketAddress> inetAddresses = new HashSet<>();\n     String host;\n-    int port;\n     boolean checkLoopback = (bindAddress != null);\n     boolean isLoopback = (checkLoopback && bindAddress.isLoopbackAddress());\n \n     StringTokenizer parts = new StringTokenizer(locatorsString, \",\");\n     while (parts.hasMoreTokens()) {\n+      String str = parts.nextToken();\n+\n+      final int portSpecificationStart = str.indexOf('[');\n+\n+      if (portSpecificationStart == -1) {\n+        throw createBadPortException(str);\n+      }\n+\n+      host = str.substring(0, portSpecificationStart);\n+\n+      int idx = host.lastIndexOf('@');\n+      if (idx < 0) {\n+        idx = host.lastIndexOf(':');\n+      }\n+      String start = host.substring(0, idx > -1 ? idx : host.length());\n+      if (start.indexOf(':') >= 0) { // a single numeric ipv6 address\n+        idx = host.lastIndexOf('@');\n+      }\n+      if (idx >= 0) {\n+        host = host.substring(idx + 1, host.length());\n+      }\n+\n+      int startIdx = portSpecificationStart + 1;\n+      int endIdx = str.indexOf(']');\n+\n+      if (endIdx == -1) {\n+        throw createBadPortException(str);\n+      }\n+\n+      final int port;\n+\n       try {\n-        String str = parts.nextToken();\n-        host = str.substring(0, str.indexOf('['));\n-        int idx = host.lastIndexOf('@');\n-        if (idx < 0) {\n-          idx = host.lastIndexOf(':');\n-        }\n-        String start = host.substring(0, idx > -1 ? idx : host.length());\n-        if (start.indexOf(':') >= 0) { // a single numeric ipv6 address\n-          idx = host.lastIndexOf('@');\n-        }\n-        if (idx >= 0) {\n-          host = host.substring(idx + 1, host.length());\n-        }\n-\n-        int startIdx = str.indexOf('[') + 1;\n-        int endIdx = str.indexOf(']');\n         port = Integer.parseInt(str.substring(startIdx, endIdx));\n-        if (port <= 0) {\n-          continue;\n-        }\n-        InetSocketAddress isa = new InetSocketAddress(host, port);\n-\n-        if (checkLoopback) {\n-          if (isLoopback && !isa.getAddress().isLoopbackAddress()) {\n-            throw new GemFireConfigException(\n-                \"This process is attempting to join with a loopback address (\" + bindAddress\n-                    + \") using a locator that does not have a local address (\" + isa\n-                    + \").  On Unix this usually means that /etc/hosts is misconfigured.\");\n-          }\n-        }\n-        HostAddress la = new HostAddress(isa, host);\n-        if (!inetAddresses.contains(isa)) {\n-          inetAddresses.add(isa);\n-          result.add(la);\n-        }\n       } catch (NumberFormatException e) {\n-        // this shouldn't happen because the config has already been parsed and\n-        // validated\n+        throw createBadPortException(str);\n+      }\n+\n+      final InetSocketAddress isa = new InetSocketAddress(host, port);\n+\n+      final InetAddress locatorAddress = isa.getAddress();\n+\n+      if (locatorAddress == null) {\n+        throw new GemFireConfigException(\"This process is attempting to use a locator\" +\n+            \" at an unknown address or FQDN: \" + host);\n+      }\n+\n+      if (checkLoopback && isLoopback && !locatorAddress.isLoopbackAddress()) {\n+        throw new GemFireConfigException(\n+            \"This process is attempting to join with a loopback address (\" + bindAddress\n+                + \") using a locator that does not have a local address (\" + isa\n+                + \").  On Unix this usually means that /etc/hosts is misconfigured.\");\n+      }\n+\n+      HostAddress la = new HostAddress(isa, host);\n+      if (!inetAddresses.contains(isa)) {\n+        inetAddresses.add(isa);\n+        result.add(la);\n       }\n     }\n \n     return result;\n   }\n \n+  private static GemFireConfigException createBadPortException(final String str) {\n+    return new GemFireConfigException(\"This process is attempting to use a locator\" +\n+        \" with a malformed port specification: \" + str);\n+  }\n+\n   /** Parses comma-separated-roles/groups into array of groups (strings). */\n   public static String[] parseGroups(String csvRoles, String csvGroups) {\n     List<String> groups = new ArrayList<String>();",
                "raw_url": "https://github.com/apache/geode/raw/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/membership/gms/GMSUtil.java",
                "sha": "7e79c74f1d819b0174851f0528952f8ec6d157c1",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/geode/blob/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java?ref=f30f9367bd7334a4e9f191d80568d7a1e0c13536",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "patch": "@@ -229,10 +229,10 @@ private void initializeServerSocket() throws IOException {\n         srv_sock = getSocketCreator().createServerSocket(port, BACKLOG, bind_address);\n       }\n       // GEODE-4176 - set the port from a wild-card bind so that handlers know the correct value\n+\n       if (this.port <= 0) {\n         this.port = srv_sock.getLocalPort();\n       }\n-\n       if (log.isInfoEnabled()) {\n         log.info(\"Locator was created at \" + new Date());\n         log.info(\"Listening on port \" + getPort() + \" bound on address \" + bind_address);",
                "raw_url": "https://github.com/apache/geode/raw/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/main/java/org/apache/geode/distributed/internal/tcpserver/TcpServer.java",
                "sha": "72625fdeef392fb660ed26b7d92cb3ae97591fe9",
                "status": "modified"
            },
            {
                "additions": 110,
                "blob_url": "https://github.com/apache/geode/blob/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/GMSUtilTest.java",
                "changes": 110,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/GMSUtilTest.java?ref=f30f9367bd7334a4e9f191d80568d7a1e0c13536",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/GMSUtilTest.java",
                "patch": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.distributed.internal.membership.gms;\n+\n+import static org.apache.geode.distributed.internal.membership.gms.GMSUtil.parseLocators;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.GemFireConfigException;\n+import org.apache.geode.distributed.internal.membership.gms.membership.HostAddress;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class GMSUtilTest {\n+\n+  static final int PORT = 1234; // any old port--no need to have anything actually bound here\n+\n+  static final String RESOLVEABLE_LOOPBACK_HOST = \"127.0.0.1\"; // loopback addy\n+\n+  static final String RESOLVEABLE_NON_LOOPBACK_HOST = \"1.1.1.1\";\n+\n+  static final String UNRESOLVEABLE_HOST = \"not-localhost-937c64aa\"; // some FQDN that does not\n+\n+\n+  @Test\n+  public void resolveableLoopBackAddress() {\n+    assertThat(\n+        parseLocators(RESOLVEABLE_LOOPBACK_HOST + \"[\" + PORT + \"]\",\n+            InetAddress.getLoopbackAddress()))\n+                .contains(\n+                    new HostAddress(new InetSocketAddress(RESOLVEABLE_LOOPBACK_HOST, PORT),\n+                        RESOLVEABLE_LOOPBACK_HOST));\n+  }\n+\n+  @Test\n+  public void resolveableNonLoopBackAddress() {\n+    assertThatThrownBy(\n+        () -> parseLocators(RESOLVEABLE_NON_LOOPBACK_HOST + \"[\" + PORT + \"]\",\n+            InetAddress.getLoopbackAddress()))\n+                .isInstanceOf(GemFireConfigException.class)\n+                .hasMessageContaining(\"does not have a local address\");\n+  }\n+\n+  @Test\n+  public void unresolveableAddress() {\n+    assertThatThrownBy(\n+        () -> parseLocators(UNRESOLVEABLE_HOST + \"[\" + PORT + \"]\",\n+            InetAddress.getLoopbackAddress()))\n+                .isInstanceOf(GemFireConfigException.class)\n+                .hasMessageContaining(\"unknown address or FQDN: \" + UNRESOLVEABLE_HOST);\n+  }\n+\n+  @Test\n+  @Parameters({\"1234\", \"0\"})\n+  public void validPortSpecified(final int validPort) {\n+    final String locatorsString = RESOLVEABLE_LOOPBACK_HOST + \"[\" + validPort + \"]\";\n+    assertThat(parseLocators(locatorsString, InetAddress.getLoopbackAddress()))\n+        .contains(\n+            new HostAddress(new InetSocketAddress(RESOLVEABLE_LOOPBACK_HOST, validPort),\n+                RESOLVEABLE_LOOPBACK_HOST));\n+  }\n+\n+  @Test\n+  @Parameters({\"[]\", \"1234]\", \"[1234\", \":1234\", \"\"})\n+  public void malformedPortSpecification(final String portSpecification) {\n+    final String locatorsString = RESOLVEABLE_LOOPBACK_HOST + portSpecification;\n+    assertThatThrownBy(\n+        () -> parseLocators(locatorsString, InetAddress.getLoopbackAddress()))\n+            .isInstanceOf(GemFireConfigException.class)\n+            .hasMessageContaining(\"malformed port specification: \" + locatorsString);\n+  }\n+\n+  @Test\n+  @Parameters({\"host@127.0.0.1[1234]\", \"host:127.0.0.1[1234]\"})\n+  public void validHostSpecified(final String locatorsString) {\n+    assertThat(parseLocators(locatorsString, (InetAddress) null))\n+        .contains(\n+            new HostAddress(new InetSocketAddress(\"127.0.0.1\", 1234), \"127.0.0.1\"));\n+  }\n+\n+  @Test\n+  @Parameters({\"server1@fdf0:76cf:a0ed:9449::5[12233]\", \"fdf0:76cf:a0ed:9449::5[12233]\"})\n+  public void validIPV6AddySpecified(final String locatorsString) {\n+    assertThat(parseLocators(locatorsString, (InetAddress) null))\n+        .contains(\n+            new HostAddress(new InetSocketAddress(\"fdf0:76cf:a0ed:9449::5\", 12233),\n+                \"fdf0:76cf:a0ed:9449::5\"));\n+  }\n+\n+}",
                "raw_url": "https://github.com/apache/geode/raw/f30f9367bd7334a4e9f191d80568d7a1e0c13536/geode-core/src/test/java/org/apache/geode/distributed/internal/membership/gms/GMSUtilTest.java",
                "sha": "bc047657bda54b597d86c55d96e1def6c2922c7f",
                "status": "added"
            }
        ],
        "message": "GEODE-7167: eliminate NPE when parsing locators property (#4018)",
        "parent": "https://github.com/apache/geode/commit/2104c9bba5cd2b57e41e5c9259d08de31fb8ea3b",
        "patched_files": [
            "GMSUtil.java",
            "TcpServer.java",
            "InternalLocator.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "MultipleCacheJUnitTest.java",
            "GMSUtilTest.java"
        ]
    },
    "geode_f6dd58f": {
        "bug_id": "geode_f6dd58f",
        "commit": "https://github.com/apache/geode/commit/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegionMap.java",
                "changes": 77,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegionMap.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 74,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegionMap.java",
                "patch": "@@ -14,7 +14,6 @@\n  */\n package org.apache.geode.internal.cache;\n \n-import java.io.IOException;\n import java.util.Collection;\n import java.util.HashSet;\n import java.util.Iterator;\n@@ -54,17 +53,12 @@\n import org.apache.geode.internal.cache.entries.OffHeapRegionEntry;\n import org.apache.geode.internal.cache.eviction.EvictableEntry;\n import org.apache.geode.internal.cache.eviction.EvictionController;\n-import org.apache.geode.internal.cache.ha.HAContainerWrapper;\n-import org.apache.geode.internal.cache.ha.HARegionQueue;\n import org.apache.geode.internal.cache.map.CacheModificationLock;\n import org.apache.geode.internal.cache.map.FocusedRegionMap;\n import org.apache.geode.internal.cache.map.RegionMapDestroy;\n import org.apache.geode.internal.cache.persistence.DiskRegionView;\n import org.apache.geode.internal.cache.region.entry.RegionEntryFactoryBuilder;\n-import org.apache.geode.internal.cache.tier.sockets.CacheClientNotifier;\n import org.apache.geode.internal.cache.tier.sockets.ClientProxyMembershipID;\n-import org.apache.geode.internal.cache.tier.sockets.ClientUpdateMessageImpl;\n-import org.apache.geode.internal.cache.tier.sockets.HAEventWrapper;\n import org.apache.geode.internal.cache.versions.ConcurrentCacheModificationException;\n import org.apache.geode.internal.cache.versions.RegionVersionVector;\n import org.apache.geode.internal.cache.versions.VersionHolder;\n@@ -86,7 +80,6 @@\n import org.apache.geode.internal.offheap.annotations.Unretained;\n import org.apache.geode.internal.sequencelog.EntryLogger;\n import org.apache.geode.internal.size.ReflectionSingleObjectSizer;\n-import org.apache.geode.internal.util.BlobHelper;\n import org.apache.geode.internal.util.concurrent.ConcurrentMapWithReusableEntries;\n import org.apache.geode.internal.util.concurrent.CustomEntryConcurrentHashMap;\n \n@@ -830,73 +823,9 @@ public boolean initialImagePut(final Object key, final long lastModified, Object\n     }\n \n     if (owner instanceof HARegion && newValue instanceof CachedDeserializable) {\n-      Object actualVal = null;\n-      CachedDeserializable newValueCd = (CachedDeserializable) newValue;\n-      try {\n-        actualVal = BlobHelper.deserializeBlob(newValueCd.getSerializedValue(),\n-            sender.getVersionObject(), null);\n-        newValue = new VMCachedDeserializable(actualVal, newValueCd.getSizeInBytes());\n-      } catch (IOException | ClassNotFoundException e) {\n-        throw new RuntimeException(\"Unable to deserialize HA event for region \" + owner);\n-      }\n-      if (actualVal instanceof HAEventWrapper) {\n-        HAEventWrapper haEventWrapper = (HAEventWrapper) actualVal;\n-        // Key was removed at sender side so not putting it into the HARegion\n-        if (haEventWrapper.getClientUpdateMessage() == null) {\n-          return false;\n-        }\n-        // Getting the instance from singleton CCN..This assumes only one bridge\n-        // server in the VM\n-        HAContainerWrapper haContainer =\n-            (HAContainerWrapper) CacheClientNotifier.getInstance().getHaContainer();\n-        if (haContainer == null) {\n-          return false;\n-        }\n-        HAEventWrapper original = null;\n-        // synchronized (haContainer) {\n-        do {\n-          ClientUpdateMessageImpl oldMsg = (ClientUpdateMessageImpl) haContainer\n-              .putIfAbsent(haEventWrapper, haEventWrapper.getClientUpdateMessage());\n-          if (oldMsg != null) {\n-            original = (HAEventWrapper) haContainer.getKey(haEventWrapper);\n-            if (original == null) {\n-              continue;\n-            }\n-            synchronized (original) {\n-              if ((HAEventWrapper) haContainer.getKey(original) != null) {\n-                original.incAndGetReferenceCount();\n-                HARegionQueue.addClientCQsAndInterestList(oldMsg, haEventWrapper, haContainer,\n-                    owner.getName());\n-                haEventWrapper.setClientUpdateMessage(null);\n-                newValue = new VMCachedDeserializable(original, newValueCd.getSizeInBytes());\n-              } else {\n-                original = null;\n-              }\n-            }\n-          } else { // putIfAbsent successful\n-            synchronized (haEventWrapper) {\n-              haEventWrapper.incAndGetReferenceCount();\n-              haEventWrapper.setHAContainer(haContainer);\n-              haEventWrapper.setClientUpdateMessage(null);\n-              haEventWrapper.setIsRefFromHAContainer(true);\n-            }\n-            break;\n-          }\n-          // try until we either get a reference to HAEventWrapper from\n-          // HAContainer or successfully put one into it.\n-        } while (original == null);\n-        /*\n-         * entry = (Map.Entry)haContainer.getEntry(haEventWrapper); if (entry != null) { original =\n-         * (HAEventWrapper)entry.getKey(); original.incAndGetReferenceCount(); } else {\n-         * haEventWrapper.incAndGetReferenceCount(); haEventWrapper.setHAContainer(haContainer);\n-         * haContainer.put(haEventWrapper, haEventWrapper .getClientUpdateMessage());\n-         * haEventWrapper.setClientUpdateMessage(null);\n-         * haEventWrapper.setIsRefFromHAContainer(true); } } if (entry != null) {\n-         * HARegionQueue.addClientCQsAndInterestList(entry, haEventWrapper, haContainer,\n-         * owner.getName()); haEventWrapper.setClientUpdateMessage(null); newValue =\n-         * CachedDeserializableFactory.create(original,\n-         * ((CachedDeserializable)newValue).getSizeInBytes()); }\n-         */\n+      newValue = ((HARegion) owner).updateHAEventWrapper(sender, (CachedDeserializable) newValue);\n+      if (newValue == null) {\n+        return false;\n       }\n     }\n ",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/AbstractRegionMap.java",
                "sha": "5b1f30932b9e231e785a0dc84906a4a72927210c",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/HARegion.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/HARegion.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 0,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/HARegion.java",
                "patch": "@@ -476,6 +476,10 @@ public boolean noPrimaryOrHasRegisteredInterest() {\n     return ((HARegionAdvisor) this.distAdvisor).noPrimaryOrHasRegisteredInterest();\n   }\n \n+  public Object updateHAEventWrapper(InternalDistributedMember sender,\n+      CachedDeserializable newValueCd) {\n+    return this.owningQueue.updateHAEventWrapper(sender, newValueCd, getName());\n+  }\n \n   /** HARegions have their own advisors so that interest registration state can be tracked */\n   public static class HARegionAdvisor extends CacheDistributionAdvisor {",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/HARegion.java",
                "sha": "03c7b7e2d333aded824deecbfa6d7f5f9cd8089d",
                "status": "modified"
            },
            {
                "additions": 82,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 1,
                "filename": "geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "patch": "@@ -79,11 +79,13 @@\n import org.apache.geode.internal.DataSerializableFixedID;\n import org.apache.geode.internal.Version;\n import org.apache.geode.internal.cache.CacheServerImpl;\n+import org.apache.geode.internal.cache.CachedDeserializable;\n import org.apache.geode.internal.cache.Conflatable;\n import org.apache.geode.internal.cache.EventID;\n import org.apache.geode.internal.cache.HARegion;\n import org.apache.geode.internal.cache.InternalCache;\n import org.apache.geode.internal.cache.RegionQueue;\n+import org.apache.geode.internal.cache.VMCachedDeserializable;\n import org.apache.geode.internal.cache.tier.sockets.CacheClientNotifier;\n import org.apache.geode.internal.cache.tier.sockets.ClientMarkerMessageImpl;\n import org.apache.geode.internal.cache.tier.sockets.ClientProxyMembershipID;\n@@ -96,6 +98,7 @@\n import org.apache.geode.internal.logging.LogService;\n import org.apache.geode.internal.logging.log4j.LocalizedMessage;\n import org.apache.geode.internal.logging.log4j.LogMarker;\n+import org.apache.geode.internal.util.BlobHelper;\n import org.apache.geode.internal.util.concurrent.StoppableCondition;\n import org.apache.geode.internal.util.concurrent.StoppableReentrantLock;\n import org.apache.geode.internal.util.concurrent.StoppableReentrantReadWriteLock;\n@@ -2070,6 +2073,84 @@ public void closeClientCq(ClientProxyMembershipID clientId, InternalCqQuery cqTo\n     }\n   }\n \n+  public Object updateHAEventWrapper(InternalDistributedMember sender,\n+      CachedDeserializable newValueCd, String regionName) {\n+    Object inputValue;\n+    try {\n+      inputValue = BlobHelper.deserializeBlob(newValueCd.getSerializedValue(),\n+          sender.getVersionObject(), null);\n+      newValueCd = new VMCachedDeserializable(inputValue, newValueCd.getSizeInBytes());\n+    } catch (IOException | ClassNotFoundException e) {\n+      throw new RuntimeException(\"Unable to deserialize HA event for region \" + regionName);\n+    }\n+    if (inputValue instanceof HAEventWrapper) {\n+      HAEventWrapper inputHaEventWrapper = (HAEventWrapper) inputValue;\n+      // Key was removed at sender side so not putting it into the HARegion\n+      if (inputHaEventWrapper.getClientUpdateMessage() == null) {\n+        return null;\n+      }\n+      // Getting the instance from singleton CCN..This assumes only one bridge\n+      // server in the VM\n+      HAContainerWrapper haContainer =\n+          (HAContainerWrapper) CacheClientNotifier.getInstance().getHaContainer();\n+      if (haContainer == null) {\n+        return null;\n+      }\n+      HAEventWrapper entryHaEventWrapper = null;\n+      // synchronized (haContainer) {\n+      do {\n+        ClientUpdateMessageImpl entryMessage = (ClientUpdateMessageImpl) haContainer\n+            .putIfAbsent(inputHaEventWrapper, inputHaEventWrapper.getClientUpdateMessage());\n+        if (entryMessage != null) {\n+          entryHaEventWrapper = (HAEventWrapper) haContainer.getKey(inputHaEventWrapper);\n+          if (entryHaEventWrapper == null) {\n+            continue;\n+          }\n+          synchronized (entryHaEventWrapper) {\n+            if (haContainer.getKey(entryHaEventWrapper) != null) {\n+              entryHaEventWrapper.incAndGetReferenceCount();\n+              // If the input and entry HAEventWrappers are not the same (which is the normal\n+              // case), add the CQs and interest list from the input to the entry and create a new\n+              // value from the entry.\n+              if (entryHaEventWrapper != inputHaEventWrapper) { // See GEODE-4957\n+                addClientCQsAndInterestList(entryMessage, inputHaEventWrapper, haContainer,\n+                    regionName);\n+                inputHaEventWrapper.setClientUpdateMessage(null);\n+                newValueCd =\n+                    new VMCachedDeserializable(entryHaEventWrapper, newValueCd.getSizeInBytes());\n+              }\n+            } else {\n+              entryHaEventWrapper = null;\n+            }\n+          }\n+        } else { // putIfAbsent successful\n+          entryHaEventWrapper = (HAEventWrapper) haContainer.getKey(inputHaEventWrapper);\n+          synchronized (entryHaEventWrapper) {\n+            entryHaEventWrapper.incAndGetReferenceCount();\n+            entryHaEventWrapper.setHAContainer(haContainer);\n+            // If the input and entry HAEventWrappers are not the same (which is not the normal\n+            // case), get the entry message, add the CQs and interest list from the input to the\n+            // entry and create a new value from the entry.\n+            if (entryHaEventWrapper != inputHaEventWrapper) { // See GEODE-4957\n+              entryMessage = (ClientUpdateMessageImpl) haContainer.get(inputHaEventWrapper);\n+              addClientCQsAndInterestList(entryMessage, inputHaEventWrapper, haContainer,\n+                  regionName);\n+              inputHaEventWrapper.setClientUpdateMessage(null);\n+              newValueCd =\n+                  new VMCachedDeserializable(entryHaEventWrapper, newValueCd.getSizeInBytes());\n+            }\n+            entryHaEventWrapper.setClientUpdateMessage(null);\n+            entryHaEventWrapper.setIsRefFromHAContainer(true);\n+          }\n+          break;\n+        }\n+        // try until we either get a reference to HAEventWrapper from\n+        // HAContainer or successfully put one into it.\n+      } while (entryHaEventWrapper == null);\n+    }\n+    return newValueCd;\n+  }\n+\n   /**\n    * This is an implementation of RegionQueue where peek() & take () are blocking operation and will\n    * not return unless it gets some legitimate value The Lock object used by this class is a\n@@ -3440,7 +3521,7 @@ protected void putEventInHARegion(Conflatable event, Long position) {\n     }\n   }\n \n-  public static void addClientCQsAndInterestList(ClientUpdateMessageImpl msg,\n+  private void addClientCQsAndInterestList(ClientUpdateMessageImpl msg,\n       HAEventWrapper haEventWrapper, Map haContainer, String regionName) {\n \n     ClientProxyMembershipID proxyID = ((HAContainerWrapper) haContainer).getProxyID(regionName);",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/main/java/org/apache/geode/internal/cache/ha/HARegionQueue.java",
                "sha": "e69a8af545486fb54a681a3189fb6b02b13ebd2f",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionDUnitTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionDUnitTest.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionDUnitTest.java",
                "patch": "@@ -15,11 +15,15 @@\n package org.apache.geode.internal.cache.ha;\n \n import static org.junit.Assert.*;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n \n import java.util.Properties;\n \n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n+import org.mockito.AdditionalAnswers;\n \n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.CacheFactory;\n@@ -213,7 +217,14 @@ public static void createRegion() throws Exception {\n     AttributesFactory factory = new AttributesFactory();\n     factory.setScope(Scope.DISTRIBUTED_ACK);\n     factory.setDataPolicy(DataPolicy.REPLICATE);\n-    HARegion.getInstance(REGION_NAME, (GemFireCacheImpl) cache, null, factory.create());\n+\n+    // Mock the HARegionQueue and answer the input CachedDeserializable when updateHAEventWrapper is\n+    // called\n+    HARegionQueue harq = mock(HARegionQueue.class);\n+    when(harq.updateHAEventWrapper(any(), any(), any()))\n+        .thenAnswer(AdditionalAnswers.returnsSecondArg());\n+\n+    HARegion.getInstance(REGION_NAME, (GemFireCacheImpl) cache, harq, factory.create());\n   }\n \n   private static HARegionQueue hrq = null;",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionDUnitTest.java",
                "sha": "000453924232209c29c12f307001f3725a7fa29d",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueDUnitTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueDUnitTest.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueDUnitTest.java",
                "patch": "@@ -15,6 +15,9 @@\n package org.apache.geode.internal.cache.ha;\n \n import static org.apache.geode.test.dunit.Assert.*;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n \n import java.util.Iterator;\n import java.util.List;\n@@ -27,6 +30,7 @@\n import org.junit.Ignore;\n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n+import org.mockito.AdditionalAnswers;\n \n import org.apache.geode.LogWriter;\n import org.apache.geode.cache.AttributesFactory;\n@@ -264,7 +268,14 @@ private static void createRegion() throws Exception {\n     AttributesFactory factory = new AttributesFactory();\n     factory.setScope(Scope.DISTRIBUTED_ACK);\n     factory.setDataPolicy(DataPolicy.REPLICATE);\n-    HARegion.getInstance(\"HARegionQueueDUnitTest_region\", (GemFireCacheImpl) cache, null,\n+\n+    // Mock the HARegionQueue and answer the input CachedDeserializable when updateHAEventWrapper is\n+    // called\n+    HARegionQueue harq = mock(HARegionQueue.class);\n+    when(harq.updateHAEventWrapper(any(), any(), any()))\n+        .thenAnswer(AdditionalAnswers.returnsSecondArg());\n+\n+    HARegion.getInstance(\"HARegionQueueDUnitTest_region\", (GemFireCacheImpl) cache, harq,\n         factory.create());\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueDUnitTest.java",
                "sha": "78db217cf65f50180896d14de6b7186f8ca044dc",
                "status": "modified"
            },
            {
                "additions": 286,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueIntegrationTest.java",
                "changes": 286,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueIntegrationTest.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 0,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueIntegrationTest.java",
                "patch": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache.ha;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.MCAST_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.Mockito.when;\n+import static org.powermock.api.mockito.PowerMockito.mock;\n+\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.mockito.MockitoAnnotations;\n+import org.powermock.api.mockito.PowerMockito;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import org.apache.geode.CancelCriterion;\n+import org.apache.geode.cache.AttributesFactory;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheFactory;\n+import org.apache.geode.cache.DataPolicy;\n+import org.apache.geode.cache.EvictionAction;\n+import org.apache.geode.cache.EvictionAttributes;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.Scope;\n+import org.apache.geode.distributed.internal.membership.InternalDistributedMember;\n+import org.apache.geode.internal.Version;\n+import org.apache.geode.internal.cache.CacheServerImpl;\n+import org.apache.geode.internal.cache.CachedDeserializable;\n+import org.apache.geode.internal.cache.EnumListenerEvent;\n+import org.apache.geode.internal.cache.EventID;\n+import org.apache.geode.internal.cache.GemFireCacheImpl;\n+import org.apache.geode.internal.cache.HARegion;\n+import org.apache.geode.internal.cache.InternalCache;\n+import org.apache.geode.internal.cache.InternalRegionArguments;\n+import org.apache.geode.internal.cache.LocalRegion;\n+import org.apache.geode.internal.cache.VMCachedDeserializable;\n+import org.apache.geode.internal.cache.tier.sockets.CacheClientNotifier;\n+import org.apache.geode.internal.cache.tier.sockets.ClientProxyMembershipID;\n+import org.apache.geode.internal.cache.tier.sockets.ClientUpdateMessage;\n+import org.apache.geode.internal.cache.tier.sockets.ClientUpdateMessageImpl;\n+import org.apache.geode.internal.cache.tier.sockets.HAEventWrapper;\n+import org.apache.geode.internal.util.BlobHelper;\n+import org.apache.geode.internal.util.concurrent.StoppableReentrantReadWriteLock;\n+import org.apache.geode.test.junit.categories.IntegrationTest;\n+\n+@RunWith(PowerMockRunner.class)\n+@PowerMockIgnore({\"javax.script.*\", \"javax.management.*\", \"org.springframework.shell.event.*\",\n+    \"org.springframework.shell.core.*\", \"*.IntegrationTest\"})\n+@PrepareForTest({CacheClientNotifier.class})\n+@Category(IntegrationTest.class)\n+public class HARegionQueueIntegrationTest {\n+\n+  private Cache cache;\n+\n+  private Region dataRegion;\n+\n+  private CacheClientNotifier ccn;\n+\n+  private InternalDistributedMember member;\n+\n+  private static final int NUM_QUEUES = 100;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    MockitoAnnotations.initMocks(this);\n+    cache = createCache();\n+    dataRegion = createDataRegion();\n+    ccn = createCacheClientNotifier();\n+    member = createMember();\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    cache.close();\n+  }\n+\n+  private Cache createCache() {\n+    return new CacheFactory().set(MCAST_PORT, \"0\").create();\n+  }\n+\n+  private Region createDataRegion() {\n+    return cache.createRegionFactory(RegionShortcut.REPLICATE).create(\"data\");\n+  }\n+\n+  private CacheClientNotifier createCacheClientNotifier() {\n+    // Create a mock CacheClientNotifier\n+    CacheClientNotifier ccn = mock(CacheClientNotifier.class);\n+    PowerMockito.mockStatic(CacheClientNotifier.class, Mockito.CALLS_REAL_METHODS);\n+    PowerMockito.when(CacheClientNotifier.getInstance()).thenReturn(ccn);\n+    return ccn;\n+  }\n+\n+  private InternalDistributedMember createMember() {\n+    // Create an InternalDistributedMember\n+    InternalDistributedMember member = mock(InternalDistributedMember.class);\n+    when(member.getVersionObject()).thenReturn(Version.CURRENT);\n+    return member;\n+  }\n+\n+  @Test\n+  public void verifySequentialUpdateHAEventWrapperWithMap() throws Exception {\n+    // Create a HAContainerMap to be used by the CacheClientNotifier\n+    HAContainerWrapper haContainerWrapper = new HAContainerMap(new ConcurrentHashMap());\n+    when(ccn.getHaContainer()).thenReturn(haContainerWrapper);\n+\n+    // Create a CachedDeserializable\n+    CachedDeserializable cd = createCachedDeserializable(haContainerWrapper);\n+\n+    // Create and update HARegionQueues\n+    createAndUpdateHARegionQueuesSequentially(haContainerWrapper, cd, NUM_QUEUES);\n+\n+    // Verify HAContainerWrapper\n+    verifyHAContainerWrapper(haContainerWrapper, cd, NUM_QUEUES);\n+  }\n+\n+  @Test\n+  public void verifySimultaneousUpdateHAEventWrapperWithMap() throws Exception {\n+    // Create a HAContainerMap to be used by the CacheClientNotifier\n+    HAContainerWrapper haContainerWrapper = new HAContainerMap(new ConcurrentHashMap());\n+    when(ccn.getHaContainer()).thenReturn(haContainerWrapper);\n+\n+    // Create a CachedDeserializable\n+    CachedDeserializable cd = createCachedDeserializable(haContainerWrapper);\n+\n+    // Create and update HARegionQueues\n+    createAndUpdateHARegionQueuesSimultaneously(haContainerWrapper, cd, NUM_QUEUES);\n+\n+    // Verify HAContainerWrapper\n+    verifyHAContainerWrapper(haContainerWrapper, cd, NUM_QUEUES);\n+  }\n+\n+  @Test\n+  public void verifySequentialUpdateHAEventWrapperWithRegion() throws Exception {\n+    // Create a HAContainerRegion to be used by the CacheClientNotifier\n+    HAContainerWrapper haContainerWrapper = createHAContainerRegion();\n+    when(ccn.getHaContainer()).thenReturn(haContainerWrapper);\n+\n+    // Create a CachedDeserializable\n+    CachedDeserializable cd = createCachedDeserializable(haContainerWrapper);\n+\n+    // Create and update HARegionQueues\n+    createAndUpdateHARegionQueuesSequentially(haContainerWrapper, cd, NUM_QUEUES);\n+\n+    // Verify HAContainerWrapper\n+    verifyHAContainerWrapper(haContainerWrapper, cd, NUM_QUEUES);\n+  }\n+\n+  @Test\n+  public void verifySimultaneousUpdateHAEventWrapperWithRegion() throws Exception {\n+    // Create a HAContainerRegion to be used by the CacheClientNotifier\n+    HAContainerWrapper haContainerWrapper = createHAContainerRegion();\n+    when(ccn.getHaContainer()).thenReturn(haContainerWrapper);\n+\n+    // Create a CachedDeserializable\n+    CachedDeserializable cd = createCachedDeserializable(haContainerWrapper);\n+\n+    // Create and update HARegionQueues\n+    createAndUpdateHARegionQueuesSimultaneously(haContainerWrapper, cd, NUM_QUEUES);\n+\n+    // Verify HAContainerWrapper\n+    verifyHAContainerWrapper(haContainerWrapper, cd, NUM_QUEUES);\n+  }\n+\n+  private HAContainerRegion createHAContainerRegion() throws Exception {\n+    // Create a Region to be used by the HAContainerRegion\n+    Region haContainerRegionRegion = createHAContainerRegionRegion();\n+\n+    // Create an HAContainerRegion\n+    HAContainerRegion haContainerRegion = new HAContainerRegion(haContainerRegionRegion);\n+\n+    return haContainerRegion;\n+  }\n+\n+  private Region createHAContainerRegionRegion() throws Exception {\n+    AttributesFactory factory = new AttributesFactory();\n+    factory.setScope(Scope.LOCAL);\n+    factory.setDiskStoreName(null);\n+    factory.setDiskSynchronous(true);\n+    factory.setDataPolicy(DataPolicy.NORMAL);\n+    factory.setStatisticsEnabled(true);\n+    factory.setEvictionAttributes(\n+        EvictionAttributes.createLIFOEntryAttributes(1000, EvictionAction.OVERFLOW_TO_DISK));\n+    Region region = ((GemFireCacheImpl) cache).createVMRegion(\n+        CacheServerImpl.generateNameForClientMsgsRegion(0), factory.create(),\n+        new InternalRegionArguments().setDestroyLockFlag(true).setRecreateFlag(false)\n+            .setSnapshotInputStream(null).setImageTarget(null).setIsUsedForMetaRegion(true));\n+    return region;\n+  }\n+\n+  private HARegionQueue createHARegionQueue(Map haContainer, int index) throws Exception {\n+    return new HARegionQueue(\"haRegion+\" + index, mock(HARegion.class), (InternalCache) cache,\n+        haContainer, null, (byte) 1, true, mock(HARegionQueueStats.class),\n+        mock(StoppableReentrantReadWriteLock.class), mock(StoppableReentrantReadWriteLock.class),\n+        mock(CancelCriterion.class), false);\n+  }\n+\n+  private CachedDeserializable createCachedDeserializable(HAContainerWrapper haContainerWrapper)\n+      throws Exception {\n+    // Create ClientUpdateMessage and HAEventWrapper\n+    ClientUpdateMessage message = new ClientUpdateMessageImpl(EnumListenerEvent.AFTER_UPDATE,\n+        (LocalRegion) dataRegion, \"key\", \"value\".getBytes(), (byte) 0x01, null,\n+        new ClientProxyMembershipID(), new EventID(cache.getDistributedSystem()));\n+    HAEventWrapper wrapper = new HAEventWrapper(message);\n+    wrapper.setHAContainer(haContainerWrapper);\n+\n+    // Create a CachedDeserializable\n+    // Note: The haContainerRegion must contain the wrapper and message to serialize it\n+    haContainerWrapper.putIfAbsent(wrapper, message);\n+    byte[] wrapperBytes = BlobHelper.serializeToBlob(wrapper);\n+    CachedDeserializable cd = new VMCachedDeserializable(wrapperBytes);\n+    haContainerWrapper.remove(wrapper);\n+    assertThat(haContainerWrapper.size()).isEqualTo(0);\n+    return cd;\n+  }\n+\n+  private void createAndUpdateHARegionQueuesSequentially(HAContainerWrapper haContainerWrapper,\n+      CachedDeserializable cd, int numQueues) throws Exception {\n+    // Create some HARegionQueues\n+    for (int i = 0; i < numQueues; i++) {\n+      HARegionQueue haRegionQueue = createHARegionQueue(haContainerWrapper, i);\n+      haRegionQueue.updateHAEventWrapper(member, cd, \"haRegion\");\n+    }\n+  }\n+\n+  private void createAndUpdateHARegionQueuesSimultaneously(HAContainerWrapper haContainerWrapper,\n+      CachedDeserializable cd, int numQueues) throws Exception {\n+    // Create some HARegionQueues\n+    HARegionQueue[] haRegionQueues = new HARegionQueue[numQueues];\n+    for (int i = 0; i < numQueues; i++) {\n+      haRegionQueues[i] = createHARegionQueue(haContainerWrapper, i);\n+    }\n+\n+    // Create threads to simultaneously update the HAEventWrapper\n+    int j = 0;\n+    Thread[] threads = new Thread[numQueues];\n+    for (HARegionQueue haRegionQueue : haRegionQueues) {\n+      threads[j] = new Thread(() -> {\n+        haRegionQueue.updateHAEventWrapper(member, cd, \"haRegion\");\n+      });\n+      j++;\n+    }\n+\n+    // Start the threads\n+    for (int i = 0; i < numQueues; i++) {\n+      threads[i].start();\n+    }\n+\n+    // Wait for the threads to complete\n+    for (int i = 0; i < numQueues; i++) {\n+      threads[i].join();\n+    }\n+  }\n+\n+  private void verifyHAContainerWrapper(HAContainerWrapper haContainerWrapper,\n+      CachedDeserializable cd, int numQueues) {\n+    // Verify HAContainerRegion size\n+    assertThat(haContainerWrapper.size()).isEqualTo(1);\n+\n+    // Verify the refCount is correct\n+    HAEventWrapper wrapperInContainer =\n+        (HAEventWrapper) haContainerWrapper.getKey(cd.getDeserializedForReading());\n+    assertThat(wrapperInContainer.getReferenceCount()).isEqualTo(numQueues);\n+  }\n+}",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/ha/HARegionQueueIntegrationTest.java",
                "sha": "6ce921e69151678847bc6988ad95b176ef5ea6b7",
                "status": "added"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/geode/blob/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/HABug36738DUnitTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/HABug36738DUnitTest.java?ref=f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3",
                "deletions": 1,
                "filename": "geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/HABug36738DUnitTest.java",
                "patch": "@@ -18,9 +18,13 @@\n import static org.awaitility.Awaitility.*;\n import static org.awaitility.Duration.*;\n import static org.junit.Assert.*;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n \n import org.junit.Test;\n import org.junit.experimental.categories.Category;\n+import org.mockito.AdditionalAnswers;\n \n import org.apache.geode.cache.AttributesFactory;\n import org.apache.geode.cache.Cache;\n@@ -35,6 +39,7 @@\n import org.apache.geode.internal.cache.HARegion;\n import org.apache.geode.internal.cache.LocalRegion;\n import org.apache.geode.internal.cache.ha.HAHelper;\n+import org.apache.geode.internal.cache.ha.HARegionQueue;\n import org.apache.geode.test.dunit.Host;\n import org.apache.geode.test.dunit.VM;\n import org.apache.geode.test.dunit.internal.JUnit4DistributedTestCase;\n@@ -113,7 +118,13 @@ private void createServerCacheWithHA() throws Exception {\n     factory.setMirrorType(MirrorType.KEYS_VALUES);\n     factory.setScope(Scope.DISTRIBUTED_ACK);\n \n-    haRegion = HARegion.getInstance(HAREGION_NAME, (GemFireCacheImpl) cache, null,\n+    // Mock the HARegionQueue and answer the input CachedDeserializable when updateHAEventWrapper is\n+    // called\n+    HARegionQueue harq = mock(HARegionQueue.class);\n+    when(harq.updateHAEventWrapper(any(), any(), any()))\n+        .thenAnswer(AdditionalAnswers.returnsSecondArg());\n+\n+    haRegion = HARegion.getInstance(HAREGION_NAME, (GemFireCacheImpl) cache, harq,\n         factory.createRegionAttributes());\n   }\n ",
                "raw_url": "https://github.com/apache/geode/raw/f6dd58f83528b32bb0fb1a44da9bb47ea29f5df3/geode-core/src/test/java/org/apache/geode/internal/cache/tier/sockets/HABug36738DUnitTest.java",
                "sha": "c76dd4a55370368f52f7222d24256df165704cb3",
                "status": "modified"
            }
        ],
        "message": "GEODE-4996: Addressed NPE by always using the region entry key",
        "parent": "https://github.com/apache/geode/commit/147c9d54dcc2d03704e6cb4ddfc2fa36fa70278f",
        "patched_files": [
            "HARegionQueue.java",
            "HARegion.java",
            "AbstractRegionMap.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "HABug36738DUnitTest.java",
            "HARegionDUnitTest.java",
            "HARegionQueueIntegrationTest.java",
            "AbstractRegionMapTest.java",
            "HARegionQueueTest.java",
            "HARegionQueueDUnitTest.java"
        ]
    },
    "geode_fcd0340": {
        "bug_id": "geode_fcd0340",
        "commit": "https://github.com/apache/geode/commit/fcd03406c13d8f22b0222b337c6309ab94fce69c",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/geode/blob/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/AbstractMapIndex.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/AbstractMapIndex.java?ref=fcd03406c13d8f22b0222b337c6309ab94fce69c",
                "deletions": 4,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/AbstractMapIndex.java",
                "patch": "@@ -319,10 +319,9 @@ public boolean isMapType()\n   void addMapping(Object key, Object value, RegionEntry entry)\n       throws IMQException\n   {\n-    if(key == QueryService.UNDEFINED) {\n+    if(key == QueryService.UNDEFINED || !(key instanceof Map)) {\n       return;\n     }\n-    assert key instanceof Map;\n     if (this.isAllKeys) {\n       Iterator<Map.Entry<?, ?>> entries = ((Map)key).entrySet().iterator();\n       while (entries.hasNext()) {\n@@ -346,10 +345,9 @@ void addMapping(Object key, Object value, RegionEntry entry)\n   void saveMapping(Object key, Object value, RegionEntry entry)\n       throws IMQException\n   {\n-    if(key == QueryService.UNDEFINED) {\n+    if(key == QueryService.UNDEFINED || !(key instanceof Map)) {\n       return;\n     }\n-    assert key instanceof Map;\n     if (this.isAllKeys) {\n       Iterator<Map.Entry<?, ?>> entries = ((Map)key).entrySet().iterator();\n       while (entries.hasNext()) {",
                "raw_url": "https://github.com/apache/geode/raw/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/AbstractMapIndex.java",
                "sha": "198b6aea71fe807557ebbc5d42f722d4066bbd6e",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/geode/blob/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/CompactMapRangeIndex.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/CompactMapRangeIndex.java?ref=fcd03406c13d8f22b0222b337c6309ab94fce69c",
                "deletions": 2,
                "filename": "gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/CompactMapRangeIndex.java",
                "patch": "@@ -90,10 +90,9 @@ protected void removeMapping(RegionEntry entry, int opCode) throws IMQException\n   void saveMapping(Object key, Object value, RegionEntry entry)\n       throws IMQException\n   {\n-    if(key == QueryService.UNDEFINED) {\n+    if(key == QueryService.UNDEFINED || !(key instanceof Map)) {\n       return;\n     }\n-    assert key instanceof Map;\n     if (this.isAllKeys) {\n       Iterator<Map.Entry<?, ?>> entries = ((Map)key).entrySet().iterator();\n       while (entries.hasNext()) {\n@@ -107,6 +106,7 @@ void saveMapping(Object key, Object value, RegionEntry entry)\n       for (Object mapKey : mapKeys) {\n         Object indexKey = ((Map)key).get(mapKey);\n         if (indexKey != null) {\n+          //Do not convert to IndexManager.NULL.  We are only interested in specific keys\n           this.saveIndexAddition(mapKey, indexKey, value, entry);\n         }\n       }\n@@ -156,6 +156,9 @@ protected void doIndexAddition(Object mapKey, Object indexKey, Object value,\n   protected void saveIndexAddition(Object mapKey, Object indexKey, Object value,\n       RegionEntry entry) throws IMQException\n   {\n+    if (indexKey == null) {\n+      indexKey = IndexManager.NULL;\n+    }\n     boolean isPr = this.region instanceof BucketRegion;\n     // Get RangeIndex for it or create it if absent\n     CompactRangeIndex rg = (CompactRangeIndex) this.mapKeyToValueIndex.get(mapKey);",
                "raw_url": "https://github.com/apache/geode/raw/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/main/java/com/gemstone/gemfire/cache/query/internal/index/CompactMapRangeIndex.java",
                "sha": "f8c574531e95771528766f5fd2cad0f5a59a621d",
                "status": "modified"
            },
            {
                "additions": 50,
                "blob_url": "https://github.com/apache/geode/blob/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/internal/index/MapRangeIndexMaintenanceJUnitTest.java",
                "changes": 50,
                "contents_url": "https://api.github.com/repos/apache/geode/contents/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/internal/index/MapRangeIndexMaintenanceJUnitTest.java?ref=fcd03406c13d8f22b0222b337c6309ab94fce69c",
                "deletions": 0,
                "filename": "gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/internal/index/MapRangeIndexMaintenanceJUnitTest.java",
                "patch": "@@ -23,11 +23,13 @@\n \n import com.gemstone.gemfire.cache.AttributesFactory;\n import com.gemstone.gemfire.cache.Region;\n+import com.gemstone.gemfire.cache.RegionShortcut;\n import com.gemstone.gemfire.cache.Scope;\n import com.gemstone.gemfire.cache.query.CacheUtils;\n import com.gemstone.gemfire.cache.query.Index;\n import com.gemstone.gemfire.cache.query.IndexMaintenanceException;\n import com.gemstone.gemfire.cache.query.QueryService;\n+import com.gemstone.gemfire.cache.query.SelectResults;\n import com.gemstone.gemfire.cache.query.data.Portfolio;\n import com.gemstone.gemfire.test.junit.categories.IntegrationTest;\n \n@@ -301,7 +303,55 @@ public void testUndefinedForCompactMapRangeIndex() throws Exception {\n     // recreate index to verify they get updated correctly\n     keyIndex1 = (IndexProtocol) qs.createIndex(INDEX_NAME, \"positions['SUN', 'IBM']\", \"/portfolio \");\n     assertTrue(\"Index should be a CompactMapRangeIndex \", keyIndex1 instanceof CompactMapRangeIndex);\n+  }\n+\n+  @Test\n+  public void testNullMapValuesInIndexOnLocalRegionForCompactMap() throws Exception{\n+    region = CacheUtils.getCache().createRegionFactory(RegionShortcut.REPLICATE).create(\"portfolio\");\n+    qs = CacheUtils.getQueryService();\n+    keyIndex1 = (IndexProtocol) qs.createIndex(INDEX_NAME, \"positions[*]\", \"/portfolio \");\n+\n+    Portfolio p = new Portfolio(1, 1);\n+    p.positions = new HashMap();\n+    region.put(1, p);\n+\n+    Portfolio p2 = new Portfolio(2, 2);\n+    p2.positions = null;\n+    region.put(2, p2);\n+\n+    Portfolio p3 = new Portfolio(3, 3);\n+    p3.positions = new HashMap();\n+    p3.positions.put(\"IBM\", \"something\");\n+    p3.positions.put(\"SUN\", null);\n+    region.put(3, p3);\n+    region.put(3, p3);\n+    \n+    SelectResults result = (SelectResults) qs.newQuery(\"select * from /portfolio p where p.positions['SUN'] = null\").execute();\n+    assertEquals(1, result.size());\n+  }\n+\n+  @Test\n+  public void testNullMapValuesInIndexOnLocalRegionForMap() throws Exception{\n+    IndexManager.TEST_RANGEINDEX_ONLY = true;\n+    region = CacheUtils.getCache().createRegionFactory(RegionShortcut.REPLICATE).create(\"portfolio\");\n+    qs = CacheUtils.getQueryService();\n+    keyIndex1 = (IndexProtocol) qs.createIndex(INDEX_NAME, \"positions[*]\", \"/portfolio \");\n+\n+    Portfolio p = new Portfolio(1, 1);\n+    p.positions = new HashMap();\n+    region.put(1, p);\n+\n+    Portfolio p2 = new Portfolio(2, 2);\n+    p2.positions = null;\n+    region.put(2, p2);\n+\n+    Portfolio p3 = new Portfolio(3, 3);\n+    p3.positions = new HashMap();\n+    p3.positions.put(\"SUN\", null);\n+    region.put(3, p3);\n     \n+    SelectResults result = (SelectResults) qs.newQuery(\"select * from /portfolio p where p.positions['SUN'] = null\").execute();\n+    assertEquals(1, result.size());\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/geode/raw/fcd03406c13d8f22b0222b337c6309ab94fce69c/gemfire-core/src/test/java/com/gemstone/gemfire/cache/query/internal/index/MapRangeIndexMaintenanceJUnitTest.java",
                "sha": "0bb92d3b4983fc1b88ecac744b405242b16ee519",
                "status": "modified"
            }
        ],
        "message": "GEODE-105: Null value in Map causes NPE with Map Indexes\n\nConvert null to NULL tokens when saving to the map indexes\nWe now ignore non map objects instead of throwing assertion errors.\nWe do not try to index them for map indexes.",
        "parent": "https://github.com/apache/geode/commit/18bbd9b8018d2332c073651dbaa99c07e2f6dba9",
        "patched_files": [
            "AbstractMapIndex.java",
            "CompactMapRangeIndex.java"
        ],
        "repo": "geode",
        "unit_tests": [
            "MapRangeIndexMaintenanceJUnitTest.java"
        ]
    }
}