[
    {
        "repo": "incubator-dolphinscheduler",
        "commit": "https://github.com/apache/incubator-dolphinscheduler/commit/1baa1f4279925f4eea8e07caedd6c67ab1284057",
        "bug_id": "incubator-dolphinscheduler_1baa1f4",
        "message": "merge from dev-db (#1386)\n\n* Worker group add IP format verification (#1131)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Increase the judgment of whether it is admin (#1136)\r\n\r\n* rename from DatasourceUserMapper to DataSourceUserMapper\r\n\r\n* add unit test in UserMapper and WorkerGroupMapper\r\n\r\n* change cn.escheduler to org.apache.dolphinscheduler\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* remove DatabaseConfiguration\r\n\r\n* add ConnectionFactoryTest\r\n\r\n* cal duration in processInstancesList\r\n\r\n* change desc to description\r\n\r\n* change table name in mysql ddl\r\n\r\n* change table name in mysql ddl\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* remove log4j-1.2-api and modify AlertMapperTest\r\n\r\n* remove log4j-1.2-api\r\n\r\n* Add alertDao to spring management\r\n\r\n* Add alertDao to spring management\r\n\r\n* get SqlSessionFactory from MybatisSqlSessionFactoryBean\r\n\r\n* get processDao by DaoFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* change get alertDao by spring to DaoFactory\r\n\r\n* add log4j to resolve #967\r\n\r\n* resole verify udf name error and delete udf error\r\n\r\n* Determine if principal is empty\r\n\r\n* Determine whether the logon user has the right to delete the project\r\n\r\n* Fixed an issue that produced attatch file named such as ATT00002.bin\r\n\r\n* fix too many connection in upgrade or create\r\n\r\n* fix NEED_FAULT_TOLERANCE and WAITTING_THREAD count fail\r\n\r\n* Added a judgment on whether the currently login user is an administrator\r\n\r\n* fix update udf database not change and create time is changed\r\n\r\n* add enterprise.wechat.enable to decide whether to send enterprise WeChat\r\n\r\n* change method check\r\n\r\n* Remove the administrator's judgment on query access token list\r\n\r\n* only admin can create worker group\r\n\r\n* delete alert group need delete the relation of user and alert group\r\n\r\n* add timeout in proxy when upload large resource\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* add postgre db performance monitor\r\n\r\n* add postgre performance monitor\r\n\r\n* update performance monitor\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add postgre performance monitor (#1137)\r\n\r\n* update english documents\r\n\r\n* refactor zk client\r\n\r\n* update documents\r\n\r\n* update zkclient\r\n\r\n* update zkclient\r\n\r\n* update documents\r\n\r\n* add architecture-design\r\n\r\n* change i18n\r\n\r\n* update i18n\r\n\r\n* update english documents\r\n\r\n* add architecture-design\r\n\r\n* update english documents\r\n\r\n* update en-US documents\r\n\r\n* add architecture-design\r\n\r\n* update demo site\r\n\r\n* add mybatis plus model\r\n\r\n* modify mybatisplus\r\n\r\n* modify mybatisplus\r\n\r\n* change interface by mybatisplus\r\n\r\n* add unit test\r\n\r\n* refactor dao interface.\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update some dao bugs\r\n\r\n* update for some bugs\r\n\r\n* update some bugs\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update\r\n\r\n* update\r\n\r\n* add multiply settings for application.yml\r\n\r\n* add multiply settings for application.yml\r\n\r\n* revert\r\n\r\n* update configuration settings in task record dao...\r\n\r\n* change application_master to application-master\r\n\r\n* change application_master to application-master\r\n\r\n* update application.yml to application.properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add properties\r\n\r\n* add properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add api start up..\r\nadd alert send try catch\r\n\r\n* update dao info level\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* merge from dev-db\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* fix bug: get process definition list failed.\r\n\r\n* fix bug: process instance interval is error\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* support stop submit success tasks\r\n\r\n* update kill process\r\n\r\n* update for stop process\r\n\r\n* update for stop process\r\n\r\n* add some logs for stop process\r\n\r\n* update for small bug.\r\n\r\n* add check strategy before submit task\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* update\r\n\r\n* revert\r\n\r\n* wait task instance exists if null.\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* add check user and definitions function when delete tenant\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* remove check resources when delete tenant\r\n\r\n* change desc to description.\r\n\r\n* change mybatisplus version to 3.2.0\r\n\r\n* update\r\n\r\n* change the notice to apache.\r\n\r\n* update\r\n\r\n* update postgre sql\r\n\r\n* fix bug: phone can be empty.\r\n\r\n* fix bug: postgre test error.\r\n\r\n* update create table for postgre quartz\r\n\r\n* fix some bugs about postgre.\r\n\r\n* update create table for postgre quartz\r\n\r\n* add postgre db performance monitor\r\n\r\n* add postgre performance monitor\r\n\r\n* update performance monitor\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* Modify MySQL page of monitoring center (#1138)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* fix bug: tasks queue length error\r\n\r\n* fix bug: tasks queue length error (#1139)\r\n\r\n* update english documents\r\n\r\n* refactor zk client\r\n\r\n* update documents\r\n\r\n* update zkclient\r\n\r\n* update zkclient\r\n\r\n* update documents\r\n\r\n* add architecture-design\r\n\r\n* change i18n\r\n\r\n* update i18n\r\n\r\n* update english documents\r\n\r\n* add architecture-design\r\n\r\n* update english documents\r\n\r\n* update en-US documents\r\n\r\n* add architecture-design\r\n\r\n* update demo site\r\n\r\n* add mybatis plus model\r\n\r\n* modify mybatisplus\r\n\r\n* modify mybatisplus\r\n\r\n* change interface by mybatisplus\r\n\r\n* add unit test\r\n\r\n* refactor dao interface.\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update some dao bugs\r\n\r\n* update for some bugs\r\n\r\n* update some bugs\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update\r\n\r\n* update\r\n\r\n* add multiply settings for application.yml\r\n\r\n* add multiply settings for application.yml\r\n\r\n* revert\r\n\r\n* update configuration settings in task record dao...\r\n\r\n* change application_master to application-master\r\n\r\n* change application_master to application-master\r\n\r\n* update application.yml to application.properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add properties\r\n\r\n* add properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add api start up..\r\nadd alert send try catch\r\n\r\n* update dao info level\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* merge from dev-db\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* fix bug: get process definition list failed.\r\n\r\n* fix bug: process instance interval is error\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* support stop submit success tasks\r\n\r\n* update kill process\r\n\r\n* update for stop process\r\n\r\n* update for stop process\r\n\r\n* add some logs for stop process\r\n\r\n* update for small bug.\r\n\r\n* add check strategy before submit task\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* update\r\n\r\n* revert\r\n\r\n* wait task instance exists if null.\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* add check user and definitions function when delete tenant\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* remove check resources when delete tenant\r\n\r\n* change desc to description.\r\n\r\n* change mybatisplus version to 3.2.0\r\n\r\n* update\r\n\r\n* change the notice to apache.\r\n\r\n* update\r\n\r\n* update postgre sql\r\n\r\n* fix bug: phone can be empty.\r\n\r\n* fix bug: postgre test error.\r\n\r\n* update create table for postgre quartz\r\n\r\n* fix some bugs about postgre.\r\n\r\n* update create table for postgre quartz\r\n\r\n* add postgre db performance monitor\r\n\r\n* add postgre performance monitor\r\n\r\n* update performance monitor\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* fix bug: tasks queue length error\r\n\r\n* DB page rename and background color modification (#1140)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code (#1142)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* the task is abnormal and task is running bug fix (#1143)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* Replace ans charts with source code (#1144)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils (#1148)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin (#1151)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin\r\n\r\n* update shutdownhook methods (#1149)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* owners and administrators can delete schedule (#1155)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* fix worker log bug (#1154)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* Release administrator delete function and select tenant not updated (#1156)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin\r\n\r\n* Release administrator delete function and select tenant not updated\r\n\r\n*  when delete access token add whether login user has perm to delete (#1159)\r\n\r\n* rename from DatasourceUserMapper to DataSourceUserMapper\r\n\r\n* add unit test in UserMapper and WorkerGroupMapper\r\n\r\n* change cn.escheduler to org.apache.dolphinscheduler\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* remove DatabaseConfiguration\r\n\r\n* add ConnectionFactoryTest\r\n\r\n* cal duration in processInstancesList\r\n\r\n* change desc to description\r\n\r\n* change table name in mysql ddl\r\n\r\n* change table name in mysql ddl\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* remove log4j-1.2-api and modify AlertMapperTest\r\n\r\n* remove log4j-1.2-api\r\n\r\n* Add alertDao to spring management\r\n\r\n* Add alertDao to spring management\r\n\r\n* get SqlSessionFactory from MybatisSqlSessionFactoryBean\r\n\r\n* get processDao by DaoFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* change get alertDao by spring to DaoFactory\r\n\r\n* add log4j to resolve #967\r\n\r\n* resole verify udf name error and delete udf error\r\n\r\n* Determine if principal is empty\r\n\r\n* Determine whether the logon user has the right to delete the project\r\n\r\n* Fixed an issue that produced attatch file named such as ATT00002.bin\r\n\r\n* fix too many connection in upgrade or create\r\n\r\n* fix NEED_FAULT_TOLERANCE and WAITTING_THREAD count fail\r\n\r\n* Added a judgment on whether the currently login user is an administrator\r\n\r\n* fix update udf database not change and create time is changed\r\n\r\n* add enterprise.wechat.enable to decide whether to send enterprise WeChat\r\n\r\n* change method check\r\n\r\n* Remove the administrator's judgment on query access token list\r\n\r\n* only admin can create worker group\r\n\r\n* delete alert group need delete the relation of user and alert group\r\n\r\n* add timeout in proxy when upload large resource\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* when delete access token add whether login user has perm to delete\r\n\r\n* change mysql-connector-java scope to test (#1161)\r\n\r\n* rename from DatasourceUserMapper to DataSourceUserMapper\r\n\r\n* add unit test in UserMapper and WorkerGroupMapper\r\n\r\n* change cn.escheduler to org.apache.dolphinscheduler\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* add unit test in UdfFuncMapperTest\r\n\r\n* remove DatabaseConfiguration\r\n\r\n* add ConnectionFactoryTest\r\n\r\n* cal duration in processInstancesList\r\n\r\n* change desc to description\r\n\r\n* change table name in mysql ddl\r\n\r\n* change table name in mysql ddl\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* change escheduler to dolphinscheduler\r\n\r\n* remove log4j-1.2-api and modify AlertMapperTest\r\n\r\n* remove log4j-1.2-api\r\n\r\n* Add alertDao to spring management\r\n\r\n* Add alertDao to spring management\r\n\r\n* get SqlSessionFactory from MybatisSqlSessionFactoryBean\r\n\r\n* get processDao by DaoFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* read druid properties in ConneciontFactory\r\n\r\n* change get alertDao by spring to DaoFactory\r\n\r\n* add log4j to resolve #967\r\n\r\n* resole verify udf name error and delete udf error\r\n\r\n* Determine if principal is empty\r\n\r\n* Determine whether the logon user has the right to delete the project\r\n\r\n* Fixed an issue that produced attatch file named such as ATT00002.bin\r\n\r\n* fix too many connection in upgrade or create\r\n\r\n* fix NEED_FAULT_TOLERANCE and WAITTING_THREAD count fail\r\n\r\n* Added a judgment on whether the currently login user is an administrator\r\n\r\n* fix update udf database not change and create time is changed\r\n\r\n* add enterprise.wechat.enable to decide whether to send enterprise WeChat\r\n\r\n* change method check\r\n\r\n* Remove the administrator's judgment on query access token list\r\n\r\n* only admin can create worker group\r\n\r\n* delete alert group need delete the relation of user and alert group\r\n\r\n* add timeout in proxy when upload large resource\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* add gets scheduled times by expect fire times\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* Increase the judgment of whether it is admin\r\n\r\n* when delete access token add whether login user has perm to delete\r\n\r\n* change mysql-connector-java scope to test\r\n\r\n* dockerfile optimization (#1165)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* remove datasource.properties\r\n\r\n* remove datasource.properties (#1168)\r\n\r\n* update english documents\r\n\r\n* refactor zk client\r\n\r\n* update documents\r\n\r\n* update zkclient\r\n\r\n* update zkclient\r\n\r\n* update documents\r\n\r\n* add architecture-design\r\n\r\n* change i18n\r\n\r\n* update i18n\r\n\r\n* update english documents\r\n\r\n* add architecture-design\r\n\r\n* update english documents\r\n\r\n* update en-US documents\r\n\r\n* add architecture-design\r\n\r\n* update demo site\r\n\r\n* add mybatis plus model\r\n\r\n* modify mybatisplus\r\n\r\n* modify mybatisplus\r\n\r\n* change interface by mybatisplus\r\n\r\n* add unit test\r\n\r\n* refactor dao interface.\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* add unit test for dao...\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ScheduleMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProcessInstanceMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/ProjectUserMapper.xml\r\n#\tescheduler-dao/src/main/resources/cn.escheduler.dao.mapper/QueueMapper.xml\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProcessInstanceMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ProjectUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/QueueMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ResourceUserMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/ScheduleMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/SessionMapperTest.java\r\n#\tescheduler-dao/src/test/java/cn/escheduler/dao/mapper/TenantMapperTest.java\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update some dao bugs\r\n\r\n* update for some bugs\r\n\r\n* update some bugs\r\n\r\n* Merge remote-tracking branch 'upstream/dev-db' into dev-db\r\n\r\n# Conflicts:\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml\r\n#\tdolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml\r\n\r\n* update\r\n\r\n* update\r\n\r\n* add multiply settings for application.yml\r\n\r\n* add multiply settings for application.yml\r\n\r\n* revert\r\n\r\n* update configuration settings in task record dao...\r\n\r\n* change application_master to application-master\r\n\r\n* change application_master to application-master\r\n\r\n* update application.yml to application.properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add properties\r\n\r\n* add properties\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* add api start up..\r\nadd alert send try catch\r\n\r\n* update dao info level\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* fix bug: task cannot submit when recovery failover\r\n\r\n* merge from dev-db\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* fix bug: get process definition list failed.\r\n\r\n* fix bug: process instance interval is error\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* support stop submit success tasks\r\n\r\n* update kill process\r\n\r\n* update for stop process\r\n\r\n* update for stop process\r\n\r\n* add some logs for stop process\r\n\r\n* update for small bug.\r\n\r\n* add check strategy before submit task\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* update\r\n\r\n* revert\r\n\r\n* wait task instance exists if null.\r\n\r\n* revert\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* add check user and definitions function when delete tenant\r\n\r\n* update\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* change desc to description.\r\n\r\n* remove check resources when delete tenant\r\n\r\n* change desc to description.\r\n\r\n* change mybatisplus version to 3.2.0\r\n\r\n* update\r\n\r\n* change the notice to apache.\r\n\r\n* update\r\n\r\n* update postgre sql\r\n\r\n* fix bug: phone can be empty.\r\n\r\n* fix bug: postgre test error.\r\n\r\n* update create table for postgre quartz\r\n\r\n* fix some bugs about postgre.\r\n\r\n* update create table for postgre quartz\r\n\r\n* add postgre db performance monitor\r\n\r\n* add postgre performance monitor\r\n\r\n* update performance monitor\r\n\r\n* revert\r\n\r\n* revert\r\n\r\n* fix bug: tasks queue length error\r\n\r\n* remove datasource.properties\r\n\r\n* remove application-alert.properties (#1167)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* remove application-alert.properties\r\n\r\n* fix api server debug mode bug (#1157)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* fix api server debug mode bug\r\n\r\n* upgrade zk version\r\n\r\n* task log print worker log bug fix (#1169)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* remove application-alert.properties\r\n\r\n* task log print worker log bug fix\r\n\r\n* The default timing is hourly (#1171)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin\r\n\r\n* Release administrator delete function and select tenant not updated\r\n\r\n* The default timing is hourly\r\n\r\n* remove .escheduler_env.sh (#1172)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* remove application-alert.properties\r\n\r\n* task log print worker log bug fix\r\n\r\n* remove .escheduler_env.sh\r\n\r\n* Resolve style conflict, recipient cannot tab and value verification (#1173)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin\r\n\r\n* Release administrator delete function and select tenant not updated\r\n\r\n* The default timing is hourly\r\n\r\n* Resolve style conflict, recipient cannot tab and value verification\r\n\r\n* change dockerfile email address (#1174)\r\n\r\n* add ConnectionFactoryTest and ConnectionFactory read datasource from appliction.yml\r\n\r\n* .escheduler_env.sh to dolphinscheduler_env.sh\r\n\r\n* dao yml assembly to conf directory\r\n\r\n* table name modify\r\n\r\n* entity title table  name modify\r\n\r\n* logback log name modify\r\n\r\n* running through the big process\r\n\r\n* running through the big process error modify\r\n\r\n* logback log name modify\r\n\r\n* data_source.properties rename\r\n\r\n* logback log name modify\r\n\r\n* install.sh optimization\r\n\r\n* install.sh optimization\r\n\r\n* command count modify\r\n\r\n* command state update\r\n\r\n* countCommandState sql update\r\n\r\n* countCommandState sql update\r\n\r\n* remove application.yml file\r\n\r\n* master.properties modify\r\n\r\n* install.sh modify\r\n\r\n* install.sh modify\r\n\r\n* api server startup modify\r\n\r\n* the current user quits and the session is completely emptied. bug fix\r\n\r\n* remove pom package resources\r\n\r\n* checkQueueNameExist method update\r\n\r\n* checkQueueExist\r\n\r\n* install.sh error output update\r\n\r\n* signOut error update\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* install.sh add mail.user\r\n\r\n* request url variables replace\r\n\r\n* process define import bug fix\r\n\r\n* process define import export bug fix\r\n\r\n* processdefine import export bug fix\r\n\r\n* down log suffix format modify\r\n\r\n* import export process define contains crontab error bug fix\r\n\r\n* add Flink local mode\r\n\r\n* ProcessDao is null bug fix\r\n\r\n* loadAverage display problem bug fix\r\n\r\n* MasterServer rename Server\r\n\r\n* rollback .env\r\n\r\n* rollback .env\r\n\r\n* MasterServer rename Server\r\n\r\n* the task is abnormal and task is running bug fix\r\n\r\n* owners and administrators can delete\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* dockerfile optimization\r\n\r\n* remove application-alert.properties\r\n\r\n* task log print worker log bug fix\r\n\r\n* remove .escheduler_env.sh\r\n\r\n* change dockerfile email address\r\n\r\n* Refresh task instance page regularly (#1175)\r\n\r\n* Dependency workflow add dependency correction value\r\n\r\n* Download workflow instance map width adjustment and change \"desc\" field to \"description\"\r\n\r\n* The third-party library that builds the dependency is recommended to be placed in 'devDependencies'\r\n\r\n* Tree chart and Gantt chart style modification\r\n\r\n* The workflow instance can be deleted only when its status is success, failure, stop and pause.\r\n\r\n* change desc to description\r\n\r\n* Maximum width of tooltip is set to 500px, note the copyright number of login page\r\n\r\n* Delete copyright number\r\n\r\n* No tenant in the list of selected tenants the default is default, and the status not shown in the repair page\r\n\r\n* repair\r\n\r\n* Repair security center module prompt\r\n\r\n* Remove blank character during verification\r\n\r\n* Remove blank character during verification\r\n\r\n* Non admin users cannot create users, tenants, alarm groups, queues and worker groups\r\n\r\n* Remove CI windows detection\r\n\r\n* The value of loadaverage should be two decimal places\r\n\r\n* Add license\r\n\r\n* delete docs\r\n\r\n* update package.json\r\n\r\n* delete LICENSE\r\n\r\n* Display icon when there is no data in process definition\r\n\r\n* Worker group add IP format verification\r\n\r\n* Modify MySQL page of monitoring center\r\n\r\n* DB page rename and background color modification\r\n\r\n* IO build replace with source code\r\n\r\n* Replace ans charts with source code\r\n\r\n* delete component-compiler-utils\r\n\r\n* delete progress-webpack-plugin\r\n\r\n* Release administrator delete function and select tenant not updated\r\n\r\n* The default timing is hourly\r\n\r\n* Resolve style conflict, recipient cannot tab and value verification\r\n\r\n* Refresh task instance page regularly\r\n\r\n* duplicate zk client close (#1176)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* fix api server debug mode bug\r\n\r\n* upgrade zk version\r\n\r\n* delete this line ,for zkClient.close() will do the whole thing\r\n\r\n* change package.xml\r\n\r\n* log view service grpc\r\n\r\n* log view service grpc\r\n\r\n* log view service grpc\r\n\r\n* log view service grpc\r\n\r\n* reset pgsql (#1178)\r\n\r\n+ 1\r\n\r\n* Ans UI upgrade to version 0.1.0 (#1181)\r\n\r\n+ 1\r\n\r\n* Administrators group prohibit deletion (#1182)\r\n\r\n* Ans UI upgrade to version 0.1.0\r\n\r\n* Administrators group prohibit deletion\r\n\r\n* fix master server shutdown error (#1177)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* fix api server debug mode bug\r\n\r\n* upgrade zk version\r\n\r\n* delete this line ,for zkClient.close() will do the whole thing\r\n\r\n* fix master server shutdown error\r\n\r\n* degrade zk version and add FourLetterWordMain class (#1183)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* fix api server debug mode bug\r\n\r\n* upgrade zk version\r\n\r\n* delete this line ,for zkClient.close() will do the whole thing\r\n\r\n* fix master server shutdown error\r\n\r\n* degrade zk version and add FourLetterWordMain class\r\n\r\n* fix ZKWorkerClient not close PathChildrenCache (#1185)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix the message\r\n\r\n* check processInstance state before delete tenant\r\n\r\n* check processInstance state before delete worker group\r\n\r\n* refactor\r\n\r\n* merge api constants into common constatns\r\n\r\n* update the resource perm\r\n\r\n* update the dataSource perm\r\n\r\n* fix CheckUtils.checkUserParams method\r\n\r\n* update AlertGroupService, extends from BaseService, remove duplicate methods\r\n\r\n* refactor\r\n\r\n* modify method name\r\n\r\n* add hasProjectAndPerm method\r\n\r\n* using checkProject instead of getResultStatus\r\n\r\n* delete checkAuth method, using hasProjectAndPerm instead.\r\n\r\n* correct spelling\r\n\r\n* add transactional for deleteWorkerGroupById\r\n\r\n* add Transactional for deleteProcessInstanceById method\r\n\r\n* change sqlSessionTemplate singleton\r\n\r\n* change sqlSessionTemplate singleton and reformat code\r\n\r\n* fix unsuitable error message\r\n\r\n* update shutdownhook methods\r\n\r\n* fix worker log bug\r\n\r\n* fix api server debug mode bug\r\n\r\n* upgrade zk version\r\n\r\n* delete this line ,for zkClient.close() will do the whole thing\r\n\r\n* fix master server shutdown error\r\n\r\n* degrade zk version and add FourLetterWordMain class\r\n\r\n* fix PathChildrenCache not close\r\n\r\n* add Transactional for createSession method (#1186)\r\n\r\n* move updateTaskState into try/catch block in case of exception\r\n\r\n* fix NPE\r\n\r\n* using conf.getInt instead of getString\r\n\r\n* for AbstractZKClient, remove the log, for it will print the same log message in createZNodePath.\r\nfor AlertDao, correct the spelling.\r\n\r\n* duplicate\r\n\r\n* refactor getTaskWorkerGroupId\r\n\r\n* add friendly log\r\n\r\n* update hearbeat thread num = 1\r\n\r\n* fix the bug when worker execute task using queue. and remove checking Tenant user anymore in TaskScheduleThread\r\n\r\n* 1. move verifyTaskInstanceIsNull after taskInstance\r\n2. keep verifyTenantIsNull/verifyTaskInstanceIsNull clean and readable\r\n\r\n* fix the message\r\n\r\n* delete before check to avoid KeeperException$NoNodeException\r\n\r\n* fix th\u2026",
        "parent": "https://github.com/apache/incubator-dolphinscheduler/commit/e2e340baf90d3ea424656b46010f2fa8744e79fa",
        "patched_files": [
            "ProcessInstanceMapMapper.xml",
            "instance-list.png",
            "sql-node.png",
            "\u540e\u7aef\u90e8\u7f72\u6587\u6863.md",
            "dependent_edit2.png",
            "task-log.png",
            "architecture.jpg",
            "worker1.png",
            "fault-tolerant_worker.png",
            "udf_edit.png",
            "LoginController.java",
            "file_create.png",
            "EnterpriseWeChatUtils.java",
            "AccessTokenMapper.xml",
            "lack_thread.png",
            "save-global-parameters.png",
            "master.properties",
            "useredit.png",
            "messages_en_US.properties",
            "run_config.conf",
            "worker_logback.xml",
            "TaskInstanceController.java",
            "ci_backend.yml",
            "ProjectController.java",
            "1.0.3-release.md",
            "dag4.png",
            "complement_data.png",
            "quartz.properties",
            "ProjectMapper.xml",
            "alert_mail_template.ftl",
            "task-log2.png",
            "save-definition.png",
            "TaskInstanceMapper.xml",
            "hive_edit2.png",
            "frontend-deployment.md",
            "AlertSender.java",
            "start_process.png",
            "\u5347\u7ea7\u6587\u6863.md",
            "spark_datesource.png",
            "dependent_edit.png",
            "sparksql_kerberos.png",
            "fault-tolerant.png",
            "JSONUtils.java",
            "UserMapper.xml",
            "combined_logback.xml",
            "default.conf",
            "\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1.md",
            "mysql-jk.png",
            "DISCLAIMER",
            "master2.png",
            "auth_user.png",
            "master_slave.png",
            "ApiApplicationServer.java",
            "addtenant.png",
            "1.0.4-release.md",
            "WorkerGroupMapper.xml",
            "process-list-stop.png",
            "mr_java.png",
            "master_worker_lack_res.png",
            "postgresql_edit.png",
            "TaskCountDto.java",
            "zoo.cfg",
            "backend-deployment.md",
            "gantt.png",
            "logo.png",
            ".escheduler_env.sh",
            "start-process.png",
            "task_list.png",
            "userinfo.png",
            "file_rename.png",
            "depend-node2.png",
            "file_upload.png",
            "master.png",
            "process-list.png",
            "Constants.java",
            "messages_zh_CN.properties",
            "postgressql_edit.png",
            "ScheduleMapper.xml",
            "data_source.properties",
            "python_edit.png",
            "master_logback.xml",
            "\u5feb\u901f\u4e0a\u624b.md",
            "\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md",
            "\u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1.md",
            "ExcelUtils.java",
            "create-queue.png",
            "AlertServer.java",
            "backend-development.md",
            "DefineUserDto.java",
            "ProcessDefinitionController.java",
            "PULL_REQUEST_TEMPLATE.md",
            "definition_edit.png",
            "depend-b-and-c.png",
            "CombinedApplicationServer.java",
            "zookeeper.properties",
            "README.md",
            "DataSourceController.java",
            "dag_examples_cn.jpg",
            "apiserver_logback.xml",
            "definition_create.png",
            "time-schedule2.png",
            "MailUtils.java",
            "useredit2.png",
            "file_detail.png",
            "cdh_hive_error.png",
            "worker2.png",
            "DataSourceMapper.xml",
            "TenantMapper.xml",
            "application-api.properties",
            "spark_edit.png",
            "sql-node2.png",
            "worker.properties",
            "ProjectUserMapper.xml",
            "UdfFuncMapper.xml",
            "project.png",
            "instance-detail.png",
            "time-schedule.png",
            "QueueController.java",
            "UsersController.java",
            "AppConfiguration.java",
            "push",
            "frontend-development.md",
            "AccessTokenController.java",
            "1.0.2-release.md",
            "messages.properties",
            "mysql_edit.png",
            "process-list3.png",
            "architecture-design.md",
            "FuncUtils.java",
            "EasyScheduler-FAQ.md",
            "BaseController.java",
            "timing.png",
            "EasyScheduler Proposal.md",
            "MonitorController.java",
            "SwaggerConfig.java",
            "application_master.properties",
            "CommandMapper.xml",
            "CommandStateCount.java",
            "ProcessInstanceMapper.xml",
            "hadoop.properties",
            "MsgManager.java",
            "startup.sh",
            "procedure_edit.png",
            "CONTRIBUTING.md",
            "DataAnalysisController.java",
            "worker.png",
            "TaskRecordController.java",
            "\u540e\u7aef\u5f00\u53d1\u6587\u6863.md",
            "TenantController.java",
            "\u524d\u7aef\u5f00\u53d1\u6587\u6863.md",
            "WorkerGroupController.java",
            "hive_kerberos.png",
            "AlertGroupMapper.xml",
            "NOTICE",
            "logout.png",
            "scheduler.png",
            "system-manual.md",
            "process_instance_edit.png",
            "application.properties",
            "shell_edit.png",
            "process-list-pause.png",
            "ci_frontend.yml",
            "PropertyUtils.java",
            "process-list-recovery-pause.png",
            "auth-project.png",
            "grpc.png",
            "favicon.ico",
            "ErrorCommandMapper.xml",
            "install_config.conf",
            "process_priority.png",
            "run-work.png",
            "variable_view.png",
            "zookeeper.png",
            "ProcessInstanceController.java",
            "1.0.1-release.md",
            "zk-jk.png",
            ".dolphinscheduler_env.sh",
            "Dockerfile",
            "AlertMapper.xml",
            ".gitignore",
            "distributed_lock_procss.png",
            "ServiceModelToSwagger2MapperImpl.java",
            "build",
            "UDFUserMapper.xml",
            "alert_logback.xml",
            "book.json",
            "worker-group.png",
            "dependent_edit3.png",
            "depend-node.png",
            "sql_edit.png",
            "start_from_current2.png",
            "task_log.png",
            "dag3.png",
            "ProcessDefinitionMapper.xml",
            "SchedulerController.java",
            "1.1.0-release.md",
            "LoggerController.java",
            "task_history.png",
            "dag2.png",
            "hive_edit.png",
            "project_edit.png",
            "ResourcesController.java",
            "process-list4.png",
            "website.css",
            "depend-week.png",
            "login.png",
            "subprocess_edit.png",
            "complement.png",
            "auth_project.png",
            "variable_view2.png",
            "quick-start.md",
            "AlertGroupController.java",
            "project_index.png",
            "global_parameter.png",
            "SessionMapper.xml",
            "QueueMapper.xml",
            "definition_list.png",
            "master-jk.png",
            "mysql.png",
            "SUMMARY.md",
            "mr_edit.png",
            "\u524d\u7aef\u90e8\u7f72\u6587\u6863.md",
            "UserAlertGroupMapper.xml",
            "README_zh_CN.md",
            "ScheduleParam.java",
            "ResourceMapper.xml",
            "dolphinscheduler.conf",
            "application-dao.properties",
            "decentralization.png",
            "mail_edit.png",
            "task-list.png",
            "file-manage.png",
            "EnterpriseWeChatManager.java",
            "ExecutorController.java",
            "DataSourceUserMapper.xml",
            "login.jpg",
            "EmailManager.java",
            "task_log2.png",
            "1.0.5-release.md",
            "tree_view.png",
            "start_from_current.png",
            "TaskStateCount.java",
            "ReleaseNotes.md",
            "dag_examples_en.jpg",
            "scheduler2.png",
            "depend-node3.png",
            "pom.xml",
            "gant-pic.png",
            "worker-jk.png",
            "upgrade.md",
            "task_priority.png",
            "alert.properties",
            "depend-last-tuesday.png",
            "distributed_lock.png",
            "common.properties",
            "process_instance.png",
            "fault-tolerant_master.png",
            "local_parameter.png",
            "dependent_edit4.png",
            "process-list2.png",
            "user_manager.png",
            "dag1.png",
            "ResourceUserMapper.xml"
        ],
        "file": [
            {
                "status": "added",
                "additions": 32,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/PULL_REQUEST_TEMPLATE.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/.github/PULL_REQUEST_TEMPLATE.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": ".github/PULL_REQUEST_TEMPLATE.md",
                "deletions": 0,
                "sha": "6235a6ce847372be7fe5c86e03489cb56b375e25",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/PULL_REQUEST_TEMPLATE.md",
                "patch": "@@ -0,0 +1,32 @@\n+## *Tips*\n+- *Thanks very much for contributing to Apache DolphinScheduler.*\n+- *Please review https://dolphinscheduler.apache.org/en-us/community/index.html before opening a pull request.*\n+\n+## What is the purpose of the pull request\n+\n+*(For example: This pull request adds checkstyle plugin.)*\n+\n+## Brief change log\n+\n+*(for example:)*\n+  - *Add maven-checkstyle-plugin to root pom.xml*\n+\n+## Verify this pull request\n+\n+*(Please pick either of the following options)*\n+\n+This pull request is code cleanup without any test coverage.\n+\n+*(or)*\n+\n+This pull request is already covered by existing tests, such as *(please describe tests)*.\n+\n+(or)\n+\n+This change added tests and can be verified as follows:\n+\n+*(example:)*\n+\n+  - *Added dolphinscheduler-dao tests for end-to-end.*\n+  - *Added CronUtilsTest to verify the change.*\n+  - *Manually verified the change by testing locally.*",
                "changes": 32
            },
            {
                "status": "added",
                "additions": 64,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/workflows/ci_backend.yml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/.github/workflows/ci_backend.yml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": ".github/workflows/ci_backend.yml",
                "deletions": 0,
                "sha": "e527c3c4a254a3d01d536080eb4e7a7dd4bc572a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/workflows/ci_backend.yml",
                "patch": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+name: Backend\n+\n+on:\n+  push:\n+    paths:\n+      - '.github/workflows/ci_backend.yml'\n+      - 'package.xml'\n+      - 'pom.xml'\n+      - 'dolphinscheduler-alert/**'\n+      - 'dolphinscheduler-api/**'\n+      - 'dolphinscheduler-common/**'\n+      - 'dolphinscheduler-dao/**'\n+      - 'dolphinscheduler-rpc/**'\n+      - 'dolphinscheduler-server/**'\n+  pull_request:\n+    paths:\n+      - '.github/workflows/ci_backend.yml'\n+      - 'package.xml'\n+      - 'pom.xml'\n+      - 'dolphinscheduler-alert/**'\n+      - 'dolphinscheduler-api/**'\n+      - 'dolphinscheduler-common/**'\n+      - 'dolphinscheduler-dao/**'\n+      - 'dolphinscheduler-rpc/**'\n+      - 'dolphinscheduler-server/**'\n+\n+jobs:\n+  Compile-check:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: actions/checkout@v1\n+      - name: Set up JDK 1.8\n+        uses: actions/setup-java@v1\n+        with:\n+          java-version: 1.8\n+      - name: Compile\n+        run: mvn -U -B -T 1C clean install -Prelease -Dmaven.compile.fork=true -Dmaven.test.skip=true\n+  License-check:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: actions/checkout@v1\n+      - name: Set up JDK 1.8\n+        uses: actions/setup-java@v1\n+        with:\n+          java-version: 1.8\n+      - name: Check\n+        run: mvn -B apache-rat:check",
                "changes": 64
            },
            {
                "status": "added",
                "additions": 58,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/workflows/ci_frontend.yml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/.github/workflows/ci_frontend.yml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": ".github/workflows/ci_frontend.yml",
                "deletions": 0,
                "sha": "fab75c634120976635118a977769559615214c3b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/.github/workflows/ci_frontend.yml",
                "patch": "@@ -0,0 +1,58 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+name: Frontend\n+\n+on:\n+  push:\n+    paths:\n+      - '.github/workflows/ci_frontend.yml'\n+      - 'dolphinscheduler-ui/**'\n+  pull_request:\n+    paths:\n+      - '.github/workflows/ci_frontend.yml'\n+      - 'dolphinscheduler-ui/**'\n+\n+jobs:\n+  Compile-check:\n+    runs-on: ${{ matrix.os }}\n+    strategy:\n+      matrix:\n+        os: [ubuntu-latest, macos-latest]\n+    steps:\n+      - uses: actions/checkout@v1\n+      - name: Set up Node.js\n+        uses: actions/setup-node@v1\n+        with:\n+          version: 8\n+      - name: Compile\n+        run: |\n+          cd dolphinscheduler-ui\n+          npm install node-sass --unsafe-perm\n+          npm install\n+          npm run build\n+\n+  License-check:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: actions/checkout@v1\n+      - name: Set up JDK 1.8\n+        uses: actions/setup-java@v1\n+        with:\n+          java-version: 1.8\n+      - name: Check\n+        run: mvn -B apache-rat:check",
                "changes": 58
            },
            {
                "status": "modified",
                "additions": 109,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/.gitignore",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/.gitignore?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": ".gitignore",
                "deletions": 109,
                "sha": "2ef5f5d1e66c57b409387343a43f674567586532",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/.gitignore",
                "patch": "@@ -35,112 +35,112 @@ config.gypi\n test/coverage\n /docs/zh_CN/\u4ecb\u7ecd\n /docs/zh_CN/\u8d21\u732e\u4ee3\u7801.md\n-/escheduler-common/src/main/resources/zookeeper.properties\n-escheduler-alert/logs/\n-escheduler-alert/src/main/resources/alert.properties_bak\n-escheduler-alert/src/main/resources/logback.xml\n-escheduler-server/src/main/resources/logback.xml\n-escheduler-ui/dist/css/common.16ac5d9.css\n-escheduler-ui/dist/css/home/index.b444b91.css\n-escheduler-ui/dist/css/login/index.5866c64.css\n-escheduler-ui/dist/js/0.ac94e5d.js\n-escheduler-ui/dist/js/0.ac94e5d.js.map\n-escheduler-ui/dist/js/1.0b043a3.js\n-escheduler-ui/dist/js/1.0b043a3.js.map\n-escheduler-ui/dist/js/10.1bce3dc.js\n-escheduler-ui/dist/js/10.1bce3dc.js.map\n-escheduler-ui/dist/js/11.79f04d8.js\n-escheduler-ui/dist/js/11.79f04d8.js.map\n-escheduler-ui/dist/js/12.420daa5.js\n-escheduler-ui/dist/js/12.420daa5.js.map\n-escheduler-ui/dist/js/13.e5bae1c.js\n-escheduler-ui/dist/js/13.e5bae1c.js.map\n-escheduler-ui/dist/js/14.f2a0dca.js\n-escheduler-ui/dist/js/14.f2a0dca.js.map\n-escheduler-ui/dist/js/15.45373e8.js\n-escheduler-ui/dist/js/15.45373e8.js.map\n-escheduler-ui/dist/js/16.fecb0fc.js\n-escheduler-ui/dist/js/16.fecb0fc.js.map\n-escheduler-ui/dist/js/17.84be279.js\n-escheduler-ui/dist/js/17.84be279.js.map\n-escheduler-ui/dist/js/18.307ea70.js\n-escheduler-ui/dist/js/18.307ea70.js.map\n-escheduler-ui/dist/js/19.144db9c.js\n-escheduler-ui/dist/js/19.144db9c.js.map\n-escheduler-ui/dist/js/2.8b4ef29.js\n-escheduler-ui/dist/js/2.8b4ef29.js.map\n-escheduler-ui/dist/js/20.4c527e9.js\n-escheduler-ui/dist/js/20.4c527e9.js.map\n-escheduler-ui/dist/js/21.831b2a2.js\n-escheduler-ui/dist/js/21.831b2a2.js.map\n-escheduler-ui/dist/js/22.2b4bb2a.js\n-escheduler-ui/dist/js/22.2b4bb2a.js.map\n-escheduler-ui/dist/js/23.81467ef.js\n-escheduler-ui/dist/js/23.81467ef.js.map\n-escheduler-ui/dist/js/24.54a00e4.js\n-escheduler-ui/dist/js/24.54a00e4.js.map\n-escheduler-ui/dist/js/25.8d7bd36.js\n-escheduler-ui/dist/js/25.8d7bd36.js.map\n-escheduler-ui/dist/js/26.2ec5e78.js\n-escheduler-ui/dist/js/26.2ec5e78.js.map\n-escheduler-ui/dist/js/27.3ab48c2.js\n-escheduler-ui/dist/js/27.3ab48c2.js.map\n-escheduler-ui/dist/js/28.363088a.js\n-escheduler-ui/dist/js/28.363088a.js.map\n-escheduler-ui/dist/js/29.6c5853a.js\n-escheduler-ui/dist/js/29.6c5853a.js.map\n-escheduler-ui/dist/js/3.a0edb5b.js\n-escheduler-ui/dist/js/3.a0edb5b.js.map\n-escheduler-ui/dist/js/30.940fdd3.js\n-escheduler-ui/dist/js/30.940fdd3.js.map\n-escheduler-ui/dist/js/31.168a460.js\n-escheduler-ui/dist/js/31.168a460.js.map\n-escheduler-ui/dist/js/32.8df6594.js\n-escheduler-ui/dist/js/32.8df6594.js.map\n-escheduler-ui/dist/js/33.4480bbe.js\n-escheduler-ui/dist/js/33.4480bbe.js.map\n-escheduler-ui/dist/js/34.b407fe1.js\n-escheduler-ui/dist/js/34.b407fe1.js.map\n-escheduler-ui/dist/js/35.f340b0a.js\n-escheduler-ui/dist/js/35.f340b0a.js.map\n-escheduler-ui/dist/js/36.8880c2d.js\n-escheduler-ui/dist/js/36.8880c2d.js.map\n-escheduler-ui/dist/js/37.ea2a25d.js\n-escheduler-ui/dist/js/37.ea2a25d.js.map\n-escheduler-ui/dist/js/38.98a59ee.js\n-escheduler-ui/dist/js/38.98a59ee.js.map\n-escheduler-ui/dist/js/39.a5e958a.js\n-escheduler-ui/dist/js/39.a5e958a.js.map\n-escheduler-ui/dist/js/4.4ca44db.js\n-escheduler-ui/dist/js/4.4ca44db.js.map\n-escheduler-ui/dist/js/40.e187b1e.js\n-escheduler-ui/dist/js/40.e187b1e.js.map\n-escheduler-ui/dist/js/41.0e89182.js\n-escheduler-ui/dist/js/41.0e89182.js.map\n-escheduler-ui/dist/js/42.341047c.js\n-escheduler-ui/dist/js/42.341047c.js.map\n-escheduler-ui/dist/js/43.27b8228.js\n-escheduler-ui/dist/js/43.27b8228.js.map\n-escheduler-ui/dist/js/44.e8869bc.js\n-escheduler-ui/dist/js/44.e8869bc.js.map\n-escheduler-ui/dist/js/45.8d54901.js\n-escheduler-ui/dist/js/45.8d54901.js.map\n-escheduler-ui/dist/js/5.e1ed7f3.js\n-escheduler-ui/dist/js/5.e1ed7f3.js.map\n-escheduler-ui/dist/js/6.241ba07.js\n-escheduler-ui/dist/js/6.241ba07.js.map\n-escheduler-ui/dist/js/7.ab2e297.js\n-escheduler-ui/dist/js/7.ab2e297.js.map\n-escheduler-ui/dist/js/8.83ff814.js\n-escheduler-ui/dist/js/8.83ff814.js.map\n-escheduler-ui/dist/js/9.39cb29f.js\n-escheduler-ui/dist/js/9.39cb29f.js.map\n-escheduler-ui/dist/js/common.733e342.js\n-escheduler-ui/dist/js/common.733e342.js.map\n-escheduler-ui/dist/js/home/index.78a5d12.js\n-escheduler-ui/dist/js/home/index.78a5d12.js.map\n-escheduler-ui/dist/js/login/index.291b8e3.js\n-escheduler-ui/dist/js/login/index.291b8e3.js.map\n-escheduler-ui/dist/lib/external/\n-escheduler-ui/src/js/conf/home/pages/projects/pages/taskInstance/index.vue\n-/escheduler-dao/src/main/resources/dao/data_source.properties\n+/dolphinscheduler-common/src/main/resources/zookeeper.properties\n+dolphinscheduler-alert/logs/\n+dolphinscheduler-alert/src/main/resources/alert.properties_bak\n+dolphinscheduler-alert/src/main/resources/logback.xml\n+dolphinscheduler-server/src/main/resources/logback.xml\n+dolphinscheduler-ui/dist/css/common.16ac5d9.css\n+dolphinscheduler-ui/dist/css/home/index.b444b91.css\n+dolphinscheduler-ui/dist/css/login/index.5866c64.css\n+dolphinscheduler-ui/dist/js/0.ac94e5d.js\n+dolphinscheduler-ui/dist/js/0.ac94e5d.js.map\n+dolphinscheduler-ui/dist/js/1.0b043a3.js\n+dolphinscheduler-ui/dist/js/1.0b043a3.js.map\n+dolphinscheduler-ui/dist/js/10.1bce3dc.js\n+dolphinscheduler-ui/dist/js/10.1bce3dc.js.map\n+dolphinscheduler-ui/dist/js/11.79f04d8.js\n+dolphinscheduler-ui/dist/js/11.79f04d8.js.map\n+dolphinscheduler-ui/dist/js/12.420daa5.js\n+dolphinscheduler-ui/dist/js/12.420daa5.js.map\n+dolphinscheduler-ui/dist/js/13.e5bae1c.js\n+dolphinscheduler-ui/dist/js/13.e5bae1c.js.map\n+dolphinscheduler-ui/dist/js/14.f2a0dca.js\n+dolphinscheduler-ui/dist/js/14.f2a0dca.js.map\n+dolphinscheduler-ui/dist/js/15.45373e8.js\n+dolphinscheduler-ui/dist/js/15.45373e8.js.map\n+dolphinscheduler-ui/dist/js/16.fecb0fc.js\n+dolphinscheduler-ui/dist/js/16.fecb0fc.js.map\n+dolphinscheduler-ui/dist/js/17.84be279.js\n+dolphinscheduler-ui/dist/js/17.84be279.js.map\n+dolphinscheduler-ui/dist/js/18.307ea70.js\n+dolphinscheduler-ui/dist/js/18.307ea70.js.map\n+dolphinscheduler-ui/dist/js/19.144db9c.js\n+dolphinscheduler-ui/dist/js/19.144db9c.js.map\n+dolphinscheduler-ui/dist/js/2.8b4ef29.js\n+dolphinscheduler-ui/dist/js/2.8b4ef29.js.map\n+dolphinscheduler-ui/dist/js/20.4c527e9.js\n+dolphinscheduler-ui/dist/js/20.4c527e9.js.map\n+dolphinscheduler-ui/dist/js/21.831b2a2.js\n+dolphinscheduler-ui/dist/js/21.831b2a2.js.map\n+dolphinscheduler-ui/dist/js/22.2b4bb2a.js\n+dolphinscheduler-ui/dist/js/22.2b4bb2a.js.map\n+dolphinscheduler-ui/dist/js/23.81467ef.js\n+dolphinscheduler-ui/dist/js/23.81467ef.js.map\n+dolphinscheduler-ui/dist/js/24.54a00e4.js\n+dolphinscheduler-ui/dist/js/24.54a00e4.js.map\n+dolphinscheduler-ui/dist/js/25.8d7bd36.js\n+dolphinscheduler-ui/dist/js/25.8d7bd36.js.map\n+dolphinscheduler-ui/dist/js/26.2ec5e78.js\n+dolphinscheduler-ui/dist/js/26.2ec5e78.js.map\n+dolphinscheduler-ui/dist/js/27.3ab48c2.js\n+dolphinscheduler-ui/dist/js/27.3ab48c2.js.map\n+dolphinscheduler-ui/dist/js/28.363088a.js\n+dolphinscheduler-ui/dist/js/28.363088a.js.map\n+dolphinscheduler-ui/dist/js/29.6c5853a.js\n+dolphinscheduler-ui/dist/js/29.6c5853a.js.map\n+dolphinscheduler-ui/dist/js/3.a0edb5b.js\n+dolphinscheduler-ui/dist/js/3.a0edb5b.js.map\n+dolphinscheduler-ui/dist/js/30.940fdd3.js\n+dolphinscheduler-ui/dist/js/30.940fdd3.js.map\n+dolphinscheduler-ui/dist/js/31.168a460.js\n+dolphinscheduler-ui/dist/js/31.168a460.js.map\n+dolphinscheduler-ui/dist/js/32.8df6594.js\n+dolphinscheduler-ui/dist/js/32.8df6594.js.map\n+dolphinscheduler-ui/dist/js/33.4480bbe.js\n+dolphinscheduler-ui/dist/js/33.4480bbe.js.map\n+dolphinscheduler-ui/dist/js/34.b407fe1.js\n+dolphinscheduler-ui/dist/js/34.b407fe1.js.map\n+dolphinscheduler-ui/dist/js/35.f340b0a.js\n+dolphinscheduler-ui/dist/js/35.f340b0a.js.map\n+dolphinscheduler-ui/dist/js/36.8880c2d.js\n+dolphinscheduler-ui/dist/js/36.8880c2d.js.map\n+dolphinscheduler-ui/dist/js/37.ea2a25d.js\n+dolphinscheduler-ui/dist/js/37.ea2a25d.js.map\n+dolphinscheduler-ui/dist/js/38.98a59ee.js\n+dolphinscheduler-ui/dist/js/38.98a59ee.js.map\n+dolphinscheduler-ui/dist/js/39.a5e958a.js\n+dolphinscheduler-ui/dist/js/39.a5e958a.js.map\n+dolphinscheduler-ui/dist/js/4.4ca44db.js\n+dolphinscheduler-ui/dist/js/4.4ca44db.js.map\n+dolphinscheduler-ui/dist/js/40.e187b1e.js\n+dolphinscheduler-ui/dist/js/40.e187b1e.js.map\n+dolphinscheduler-ui/dist/js/41.0e89182.js\n+dolphinscheduler-ui/dist/js/41.0e89182.js.map\n+dolphinscheduler-ui/dist/js/42.341047c.js\n+dolphinscheduler-ui/dist/js/42.341047c.js.map\n+dolphinscheduler-ui/dist/js/43.27b8228.js\n+dolphinscheduler-ui/dist/js/43.27b8228.js.map\n+dolphinscheduler-ui/dist/js/44.e8869bc.js\n+dolphinscheduler-ui/dist/js/44.e8869bc.js.map\n+dolphinscheduler-ui/dist/js/45.8d54901.js\n+dolphinscheduler-ui/dist/js/45.8d54901.js.map\n+dolphinscheduler-ui/dist/js/5.e1ed7f3.js\n+dolphinscheduler-ui/dist/js/5.e1ed7f3.js.map\n+dolphinscheduler-ui/dist/js/6.241ba07.js\n+dolphinscheduler-ui/dist/js/6.241ba07.js.map\n+dolphinscheduler-ui/dist/js/7.ab2e297.js\n+dolphinscheduler-ui/dist/js/7.ab2e297.js.map\n+dolphinscheduler-ui/dist/js/8.83ff814.js\n+dolphinscheduler-ui/dist/js/8.83ff814.js.map\n+dolphinscheduler-ui/dist/js/9.39cb29f.js\n+dolphinscheduler-ui/dist/js/9.39cb29f.js.map\n+dolphinscheduler-ui/dist/js/common.733e342.js\n+dolphinscheduler-ui/dist/js/common.733e342.js.map\n+dolphinscheduler-ui/dist/js/home/index.78a5d12.js\n+dolphinscheduler-ui/dist/js/home/index.78a5d12.js.map\n+dolphinscheduler-ui/dist/js/login/index.291b8e3.js\n+dolphinscheduler-ui/dist/js/login/index.291b8e3.js.map\n+dolphinscheduler-ui/dist/lib/external/\n+dolphinscheduler-ui/src/js/conf/home/pages/projects/pages/taskInstance/index.vue\n+/dolphinscheduler-dao/src/main/resources/dao/data_source.properties",
                "changes": 218
            },
            {
                "status": "modified",
                "additions": 3,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/CONTRIBUTING.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/CONTRIBUTING.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "CONTRIBUTING.md",
                "deletions": 71,
                "sha": "8ed9aac8975a682826ad9ded85140bd28f1e03ff",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/CONTRIBUTING.md",
                "patch": "@@ -1,4 +1,4 @@\n-* First from the remote repository *https://github.com/analysys/EasyScheduler.git* fork code to your own repository\n+* First from the remote repository *https://github.com/apache/incubator-dolphinscheduler.git* fork code to your own repository\n \n * there are three branches in the remote repository currently:\n      * master normal delivery branch\n@@ -7,17 +7,14 @@\n     * dev daily development branch\n             The daily development branch, the newly submitted code can pull requests to this branch.\n \n-    * branch-1.0.0 release version branch\n-            Release version branch, there will be 2.0 ... and other version branches, the version \n-            branch only changes the error, does not add new features.\n \n * Clone your own warehouse to your local\n \n-    `git clone https://github.com/analysys/EasyScheduler.git`\n+    `git clone https://github.com/apache/incubator-dolphinscheduler.git`\n \n * Add remote repository address, named upstream\n \n-   `git remote add upstream https://github.com/analysys/EasyScheduler.git`\n+   `git remote add upstream https://github.com/apache/incubator-dolphinscheduler.git`\n \n * View repository:\n \n@@ -63,71 +60,6 @@ git push --set-upstream origin dev1.0\n \n *  Next, the administrator is responsible for **merging** to complete the pull request\n \n----\n-\n-* \u9996\u5148\u4ece\u8fdc\u7aef\u4ed3\u5e93*https://github.com/analysys/EasyScheduler.git* fork\u4e00\u4efd\u4ee3\u7801\u5230\u81ea\u5df1\u7684\u4ed3\u5e93\u4e2d\n-\n-* \u8fdc\u7aef\u4ed3\u5e93\u4e2d\u76ee\u524d\u6709\u4e09\u4e2a\u5206\u652f\uff1a\n-    * master \u6b63\u5e38\u4ea4\u4ed8\u5206\u652f\n-\t   \u53d1\u5e03\u7a33\u5b9a\u7248\u672c\u4ee5\u540e\uff0c\u5c06\u7a33\u5b9a\u7248\u672c\u5206\u652f\u7684\u4ee3\u7801\u5408\u5e76\u5230master\u4e0a\u3002\n-    \n-\t* dev    \u65e5\u5e38\u5f00\u53d1\u5206\u652f\n-\t   \u65e5\u5e38dev\u5f00\u53d1\u5206\u652f\uff0c\u65b0\u63d0\u4ea4\u7684\u4ee3\u7801\u90fd\u53ef\u4ee5pull request\u5230\u8fd9\u4e2a\u5206\u652f\u4e0a\u3002\n-\t   \n-    * branch-1.0.0 \u53d1\u5e03\u7248\u672c\u5206\u652f\n-\t   \u53d1\u5e03\u7248\u672c\u5206\u652f\uff0c\u540e\u7eed\u4f1a\u67092.0...\u7b49\u7248\u672c\u5206\u652f\uff0c\u7248\u672c\u5206\u652f\u53ea\u4fee\u6539bug\uff0c\u4e0d\u589e\u52a0\u65b0\u529f\u80fd\u3002\n-\n-* \u628a\u81ea\u5df1\u4ed3\u5e93clone\u5230\u672c\u5730\n-  \n-    `git clone https://github.com/analysys/EasyScheduler.git`\n-\n-*  \u6dfb\u52a0\u8fdc\u7aef\u4ed3\u5e93\u5730\u5740\uff0c\u547d\u540d\u4e3aupstream\n-\n-    ` git remote add upstream https://github.com/analysys/EasyScheduler.git `\n-\n-*  \u67e5\u770b\u4ed3\u5e93\uff1a\n-\n-    ` git remote -v`\n-\n-> \u6b64\u65f6\u4f1a\u6709\u4e24\u4e2a\u4ed3\u5e93\uff1aorigin(\u81ea\u5df1\u7684\u4ed3\u5e93)\u548cupstream\uff08\u8fdc\u7aef\u4ed3\u5e93\uff09\n-\n-*  \u83b7\u53d6/\u66f4\u65b0\u8fdc\u7aef\u4ed3\u5e93\u4ee3\u7801\uff08\u5df2\u7ecf\u662f\u6700\u65b0\u4ee3\u7801\uff0c\u5c31\u8df3\u8fc7\uff09\n-  \n-    `git fetch upstream `\n-\n-\n-* \u540c\u6b65\u8fdc\u7aef\u4ed3\u5e93\u4ee3\u7801\u5230\u672c\u5730\u4ed3\u5e93\n-\n-```\n- git checkout origin/dev\n- git merge --no-ff upstream/dev\n-```\n-\n-\u5982\u679c\u8fdc\u7aef\u5206\u652f\u6709\u65b0\u52a0\u7684\u5206\u652f`dev-1.0`,\u9700\u8981\u540c\u6b65\u8fd9\u4e2a\u5206\u652f\u5230\u672c\u5730\u4ed3\u5e93\n-\n-```\n-git checkout -b dev-1.0 upstream/dev-1.0\n-git push --set-upstream origin dev1.0\n-```\n-\n-* \u5728\u672c\u5730\u4fee\u6539\u4ee3\u7801\u4ee5\u540e\uff0c\u63d0\u4ea4\u5230\u81ea\u5df1\u4ed3\u5e93\uff1a\n-  \n-    `git commit -m 'test commit'`\n-    `git push`\n-\n-* \u5c06\u4fee\u6539\u63d0\u4ea4\u5230\u8fdc\u7aef\u4ed3\u5e93\n-\n-\t* \u5728github\u9875\u9762\uff0c\u70b9\u51fbNew pull request.\n-\t\t<p align=\"center\">\n-\t   <img src=\"http://geek.analysys.cn/static/upload/221/2019-04-02/90f3abbf-70ef-4334-b8d6-9014c9cf4c7f.png\" width=\"60%\" />\n-\t </p>\n-\t \n-\t* \u9009\u62e9\u4fee\u6539\u5b8c\u7684\u672c\u5730\u5206\u652f\u548c\u8981\u5408\u5e76\u8fc7\u53bb\u7684\u5206\u652f\uff0cCreate pull request.\n-\t\t<p align=\"center\">\n-\t   <img src=\"http://geek.analysys.cn/static/upload/221/2019-04-02/fe7eecfe-2720-4736-951b-b3387cf1ae41.png\" width=\"60%\" />\n-\t </p>\n-\t\n-* \u63a5\u4e0b\u6765\u7531\u7ba1\u7406\u5458\u8d1f\u8d23\u5c06**Merge**\u5b8c\u6210\u6b64\u6b21pull request\n \n \n ",
                "changes": 74
            },
            {
                "status": "added",
                "additions": 5,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/DISCLAIMER",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/DISCLAIMER?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "DISCLAIMER",
                "deletions": 0,
                "sha": "1c269cd696ed2c0b964f51cea21124c023893cfb",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/DISCLAIMER",
                "patch": "@@ -0,0 +1,5 @@\n+Apache DolphinScheduler (incubating) is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator PMC.\n+Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, \n+communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. \n+While incubation status is not necessarily a reflection of the completeness or stability of the code, \n+it does indicate that the project has yet to be fully endorsed by the ASF.",
                "changes": 5
            },
            {
                "status": "modified",
                "additions": 3,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/NOTICE",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/NOTICE?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "NOTICE",
                "deletions": 5,
                "sha": "72b5f0632c6efeceb57b817cffbdcdc97a587c7a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/NOTICE",
                "patch": "@@ -1,7 +1,5 @@\n-Easy Scheduler\n-Copyright 2019 The Analysys Foundation\n+Apache DolphinScheduler (incubating)\n+Copyright 2019 The Apache Software Foundation\n \n This product includes software developed at\n-The Analysys Foundation (https://www.analysys.cn/).\n-\n-\n+The Apache Software Foundation (http://www.apache.org/).",
                "changes": 8
            },
            {
                "status": "modified",
                "additions": 22,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/README.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/README.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "README.md",
                "deletions": 8,
                "sha": "b4a7e5c7cd51bc490ac6fbfe20917c1b264b4984",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/README.md",
                "patch": "@@ -11,7 +11,7 @@ Dolphin Scheduler\n [![CN doc](https://img.shields.io/badge/\u6587\u6863-\u4e2d\u6587\u7248-blue.svg)](README_zh_CN.md)\n \n \n-### Design features: \n+### Design features:\n \n A distributed and easy-to-expand visual DAG workflow scheduling system. Dedicated to solving the complex dependencies in data processing, making the scheduling system `out of the box` for data processing.\n Its main objectives are as follows:\n@@ -36,8 +36,8 @@ Its main objectives are as follows:\n \n  Stability | Easy to use | Features | Scalability |\n  -- | -- | -- | --\n-Decentralized multi-master and multi-worker | Visualization process defines key information such as task status, task type, retry times, task running machine, visual variables and so on at a glance.\u00a0 | \u00a0Support pause, recover operation | support custom task types \n-HA is supported by itself | All process definition operations are visualized, dragging tasks to draw DAGs, configuring data sources and resources. At the same time, for third-party systems, the api mode operation is provided. | Users on DolphinScheduler can achieve many-to-one or one-to-one mapping relationship through tenants and Hadoop users, which is very important for scheduling large data jobs. \" | The scheduler uses distributed scheduling, and the overall scheduling capability will increase linearly with the scale of the cluster. Master and Worker support dynamic online and offline. \n+Decentralized multi-master and multi-worker | Visualization process defines key information such as task status, task type, retry times, task running machine, visual variables and so on at a glance.\u00a0 | \u00a0Support pause, recover operation | support custom task types\n+HA is supported by itself | All process definition operations are visualized, dragging tasks to draw DAGs, configuring data sources and resources. At the same time, for third-party systems, the api mode operation is provided. | Users on DolphinScheduler can achieve many-to-one or one-to-one mapping relationship through tenants and Hadoop users, which is very important for scheduling large data jobs. \" | The scheduler uses distributed scheduling, and the overall scheduling capability will increase linearly with the scale of the cluster. Master and Worker support dynamic online and offline.\n Overload processing: Task queue mechanism, the number of schedulable tasks on a single machine can be flexibly configured, when too many tasks will be cached in the task queue, will not cause machine jam. | One-click deployment | Supports traditional shell tasks, and also support big data platform task scheduling: MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Procedure, Sub_Process |  |\n \n \n@@ -58,11 +58,11 @@ Overload processing: Task queue mechanism, the number of schedulable tasks on a\n \n - <a href=\"https://dolphinscheduler.apache.org/en-us/docs/user_doc/frontend-deployment.html\" target=\"_blank\">Front-end deployment documentation</a>\n \n-- [**User manual**](https://dolphinscheduler.apache.org/en-us/docs/user_doc/system-manual.html?_blank \"System manual\") \n+- [**User manual**](https://dolphinscheduler.apache.org/en-us/docs/user_doc/system-manual.html?_blank \"System manual\")\n \n-- [**Upgrade document**](https://dolphinscheduler.apache.org/en-us/docs/release/upgrade.html?_blank \"Upgrade document\") \n+- [**Upgrade document**](https://dolphinscheduler.apache.org/en-us/docs/release/upgrade.html?_blank \"Upgrade document\")\n \n-- <a href=\"http://106.75.43.194:8888\" target=\"_blank\">Online Demo</a> \n+- <a href=\"http://106.75.43.194:8888\" target=\"_blank\">Online Demo</a>\n \n More documentation please refer to <a href=\"https://dolphinscheduler.apache.org/en-us/docs/user_doc/quick-start.html\" target=\"_blank\">[DolphinScheduler online documentation]</a>\n \n@@ -74,6 +74,20 @@ Work plan of Dolphin Scheduler: [R&D plan](https://github.com/apache/incubator-d\n Welcome to participate in contributing code, please refer to the process of submitting the code:\n [[How to contribute code](https://github.com/apache/incubator-dolphinscheduler/issues/310)]\n \n+### How to Build\n+\n+```bash\n+mvn clean install -Prelease\n+```\n+\n+Artifact:\n+\n+```\n+dolphinscheduler-dist/dolphinscheduler-backend/target/apache-dolphinscheduler-incubating-${latest.release.version}-dolphinscheduler-backend-bin.tar.gz: Binary package of DolphinScheduler-Backend\n+dolphinscheduler-dist/dolphinscheduler-front/target/apache-dolphinscheduler-incubating-${latest.release.version}-dolphinscheduler-front-bin.tar.gz: Binary package of DolphinScheduler-UI\n+dolphinscheduler-dist/dolphinscheduler-src/target/apache-dolphinscheduler-incubating-${latest.release.version}-src.zip: Source code package of DolphinScheduler\n+```\n+\n ### Thanks\n \n Dolphin Scheduler uses a lot of excellent open source projects, such as google guava, guice, grpc, netty, ali bonecp, quartz, and many open source projects of apache, etc.\n@@ -86,8 +100,8 @@ It is because of the shoulders of these open source projects that the birth of t\n \n ### License\n Please refer to [LICENSE](https://github.com/apache/incubator-dolphinscheduler/blob/dev/LICENSE) file.\n- \n- \n+\n+\n \n \n ",
                "changes": 30
            },
            {
                "status": "modified",
                "additions": 20,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/README_zh_CN.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/README_zh_CN.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "README_zh_CN.md",
                "deletions": 7,
                "sha": "6bdf7be183cb5a9f9880d33743ac0611e16a5224",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/README_zh_CN.md",
                "patch": "@@ -1,13 +1,13 @@\n Dolphin Scheduler\n ============\n [![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n-[![Total Lines](https://tokei.rs/b1/github/analysys/EasyScheduler?category=lines)](https://github.com/analysys/EasyScheduler)\n+[![Total Lines](https://tokei.rs/b1/github/apache/Incubator-DolphinScheduler?category=lines)](https://github.com/apache/Incubator-DolphinScheduler)\n \n > Dolphin Scheduler for Big Data\n \n \n \n-[![Stargazers over time](https://starchart.cc/analysys/EasyScheduler.svg)](https://starchart.cc/analysys/EasyScheduler)\n+[![Stargazers over time](https://starchart.cc/apache/incubator-dolphinscheduler.svg)](https://starchart.cc/apache/incubator-dolphinscheduler)\n \n [![CN doc](https://img.shields.io/badge/\u6587\u6863-\u4e2d\u6587\u7248-blue.svg)](README_zh_CN.md)\n [![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README.md)\n@@ -45,11 +45,11 @@ Dolphin Scheduler\n \n - <a href=\"https://dolphinscheduler.apache.org/zh-cn/docs/user_doc/frontend-deployment.html\" target=\"_blank\">\u524d\u7aef\u90e8\u7f72\u6587\u6863</a>\n \n-- [**\u4f7f\u7528\u624b\u518c**](https://dolphinscheduler.apache.org/zh-cn/docs/user_doc/system-manual.html?_blank \"\u7cfb\u7edf\u4f7f\u7528\u624b\u518c\") \n+- [**\u4f7f\u7528\u624b\u518c**](https://dolphinscheduler.apache.org/zh-cn/docs/user_doc/system-manual.html?_blank \"\u7cfb\u7edf\u4f7f\u7528\u624b\u518c\")\n \n-- [**\u5347\u7ea7\u6587\u6863**](https://dolphinscheduler.apache.org/zh-cn/docs/release/upgrade.html?_blank \"\u5347\u7ea7\u6587\u6863\") \n+- [**\u5347\u7ea7\u6587\u6863**](https://dolphinscheduler.apache.org/zh-cn/docs/release/upgrade.html?_blank \"\u5347\u7ea7\u6587\u6863\")\n \n-- <a href=\"http://106.75.43.194:8888\" target=\"_blank\">\u6211\u8981\u4f53\u9a8c</a> \n+- <a href=\"http://106.75.43.194:8888\" target=\"_blank\">\u6211\u8981\u4f53\u9a8c</a>\n \n \u66f4\u591a\u6587\u6863\u8bf7\u53c2\u8003 <a href=\"https://dolphinscheduler.apache.org/zh-cn/docs/user_doc/quick-start.html\" target=\"_blank\">DolphinScheduler\u4e2d\u6587\u5728\u7ebf\u6587\u6863</a>\n \n@@ -63,11 +63,24 @@ DolphinScheduler\u7684\u5de5\u4f5c\u8ba1\u5212\uff1a<a href=\"https://github.com/apache/incubator-d\n \u975e\u5e38\u6b22\u8fce\u5927\u5bb6\u6765\u53c2\u4e0e\u8d21\u732e\u4ee3\u7801\uff0c\u63d0\u4ea4\u4ee3\u7801\u6d41\u7a0b\u8bf7\u53c2\u8003\uff1a\n [[How to contribute code](https://github.com/apache/incubator-dolphinscheduler/issues/310)]\n \n+### How to Build\n+\n+```bash\n+mvn clean install -Prelease\n+```\n+\n+Artifact:\n+\n+```\n+dolphinscheduler-dist/dolphinscheduler-backend/target/apache-dolphinscheduler-incubating-${latest.release.version}-dolphinscheduler-backend-bin.tar.gz: Binary package of DolphinScheduler-Backend\n+dolphinscheduler-dist/dolphinscheduler-front/target/apache-dolphinscheduler-incubating-${latest.release.version}-dolphinscheduler-front-bin.tar.gz: Binary package of DolphinScheduler-UI\n+dolphinscheduler-dist/dolphinscheduler-src/target/apache-dolphinscheduler-incubating-${latest.release.version}-src.zip: Source code package of DolphinScheduler\n+```\n \n ### \u611f\u8c22\n \n Dolphin Scheduler\u4f7f\u7528\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u5f00\u6e90\u9879\u76ee\uff0c\u6bd4\u5982google\u7684guava\u3001guice\u3001grpc\uff0cnetty\uff0cali\u7684bonecp\uff0cquartz\uff0c\u4ee5\u53caapache\u7684\u4f17\u591a\u5f00\u6e90\u9879\u76ee\u7b49\u7b49\uff0c\n-\u6b63\u662f\u7531\u4e8e\u7ad9\u5728\u8fd9\u4e9b\u5f00\u6e90\u9879\u76ee\u7684\u80a9\u8180\u4e0a\uff0c\u624d\u6709Easy Scheduler\u7684\u8bde\u751f\u7684\u53ef\u80fd\u3002\u5bf9\u6b64\u6211\u4eec\u5bf9\u4f7f\u7528\u7684\u6240\u6709\u5f00\u6e90\u8f6f\u4ef6\u8868\u793a\u975e\u5e38\u7684\u611f\u8c22\uff01\u6211\u4eec\u4e5f\u5e0c\u671b\u81ea\u5df1\u4e0d\u4ec5\u662f\u5f00\u6e90\u7684\u53d7\u76ca\u8005\uff0c\u4e5f\u80fd\u6210\u4e3a\u5f00\u6e90\u7684\n+\u6b63\u662f\u7531\u4e8e\u7ad9\u5728\u8fd9\u4e9b\u5f00\u6e90\u9879\u76ee\u7684\u80a9\u8180\u4e0a\uff0c\u624d\u6709Dolphin Scheduler\u7684\u8bde\u751f\u7684\u53ef\u80fd\u3002\u5bf9\u6b64\u6211\u4eec\u5bf9\u4f7f\u7528\u7684\u6240\u6709\u5f00\u6e90\u8f6f\u4ef6\u8868\u793a\u975e\u5e38\u7684\u611f\u8c22\uff01\u6211\u4eec\u4e5f\u5e0c\u671b\u81ea\u5df1\u4e0d\u4ec5\u662f\u5f00\u6e90\u7684\u53d7\u76ca\u8005\uff0c\u4e5f\u80fd\u6210\u4e3a\u5f00\u6e90\u7684\n \u8d21\u732e\u8005\uff0c\u4e8e\u662f\u6211\u4eec\u51b3\u5b9a\u628a\u6613\u8c03\u5ea6\u8d21\u732e\u51fa\u6765\uff0c\u5e76\u627f\u8bfa\u957f\u671f\u7ef4\u62a4\u3002\u4e5f\u5e0c\u671b\u5bf9\u5f00\u6e90\u6709\u540c\u6837\u70ed\u60c5\u548c\u4fe1\u5ff5\u7684\u4f19\u4f34\u52a0\u5165\u8fdb\u6765\uff0c\u4e00\u8d77\u4e3a\u5f00\u6e90\u732e\u51fa\u4e00\u4efd\u529b\uff01\n \n \n@@ -78,7 +91,7 @@ Dolphin Scheduler\u4f7f\u7528\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u5f00\u6e90\u9879\u76ee\uff0c\u6bd4\u5982google\u7684guava\u3001g\n \n ### \u7248\u6743\n Please refer to [LICENSE](https://github.com/apache/incubator-dolphinscheduler/blob/dev/LICENSE) file.\n- \n+\n \n \n ",
                "changes": 27
            },
            {
                "status": "added",
                "additions": 55,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/ReleaseNotes.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/ReleaseNotes.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "ReleaseNotes.md",
                "deletions": 0,
                "sha": "8d837c465b8a4487dbe756fbd918009b0122ee01",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/ReleaseNotes.md",
                "patch": "@@ -0,0 +1,55 @@\n+## 1.2.0\n+\n+### New Feature\t\n+1. Support postgre sql\n+2. Change all Chinese names to English\n+3. Add flink and http task support\n+4. Cross project dependencies\n+5. Modify mybatis to mybatisplus, support multy databases.\n+6. Add export and import definition feaure\n+7. Github actions ci compile check\n+8. Add method and parameters comments\n+9. Add java doc for common module\n+\n+\t\n+### Enhancement\t\n+1. Add license and notice files\n+2. Move batchDelete Process Define/Instance Outside for transactional\n+3. Remove space before and after login user name\n+4. Dockerfile optimization\n+5. Change mysql-connector-java scope to test\n+6. Owners and administrators can delete schedule\n+7. DB page rename and background color modification\u00a0\n+8. Add postgre performance monitor\n+9. Resolve style conflict, recipient cannot tab and value verification\n+10. Checkbox change background color and env to Chinese\n+11. Change chinese sql to english\n+12. Change sqlSessionTemplate singleton and reformat code\u00a0\n+13. The value of loadaverage should be two decimal places\n+14. Delete alert group need delete the relation of user and alert group\n+15. Remove check resources when delete tenant\n+16. Check processInstance state before delete worker group\u00a0\n+17. Add check user and definitions function when delete tenant\n+18. Delete before check to avoid KeeperException$NoNodeException\n+\n+### Bug Fixes\n+1. Fix\u00a0#1245, make scanCommand transactional \n+2. Fix ZKWorkerClient not close PathChildrenCache\n+3. Data type convert error \uff0cemail send error bug fix\n+4. Catch exception transaction method does not take effect to modify\n+5. Fix the spring transaction not worker bug\n+6. Task log print worker log bug fix\n+7. Fix api server debug mode bug\n+8. The task is abnormal and task is running bug fix\n+9. Fix bug: tasks queue length error\n+10. Fix unsuitable error message\n+11. Fix bug: phone can be empty\n+12. Fix email error password\n+13. Fix CheckUtils.checkUserParams method\n+14. The process cannot be terminated while tasks in the status submit success\n+15. Fix too many connection in upgrade or create\u00a0\n+16. Fix the bug when worker execute task using queue. and remove checking\n+17. Resole verify udf name error and delete udf error\u00a0\n+18. Fix bug: task cannot submit when recovery failover\n+19. Fix bug: the administrator authorizes the project to ordinary users,but ordinary users cannot see the process definition created by the administrator\n+20. Fix bug: create dolphinscheduler sql failed\n\\ No newline at end of file",
                "changes": 55
            },
            {
                "status": "modified",
                "additions": 64,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/Dockerfile",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/Dockerfile?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/Dockerfile",
                "deletions": 74,
                "sha": "217b2c052f2738d9139d3a0fb1b626917699fece",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/Dockerfile",
                "patch": "@@ -1,13 +1,29 @@\n-FROM ubuntu:18.04\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n \n-MAINTAINER journey \"825193156@qq.com\"\n+FROM ubuntu:18.04\n \n ENV LANG=C.UTF-8\n+ENV DEBIAN_FRONTEND=noninteractive\n \n ARG version\n ARG tar_version\n \n-#1,\u5b89\u88c5jdk\n+#1,install jdk\n \n RUN apt-get update \\\n     && apt-get -y install openjdk-8-jdk \\\n@@ -17,17 +33,10 @@ ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64\n ENV PATH $JAVA_HOME/bin:$PATH\n \n \n-#\u5b89\u88c5wget\n+#install wget\n RUN apt-get update && \\\n         apt-get -y install wget\n-#2,\u5b89\u88c5ZK\n-#RUN cd /opt && \\\n-#    wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz && \\\n-#    tar -zxvf zookeeper-3.4.6.tar.gz && \\\n-#    mv zookeeper-3.4.6 zookeeper && \\\n-#    rm -rf ./zookeeper-*tar.gz && \\\n-#    mkdir -p /tmp/zookeeper && \\\n-#    rm -rf /opt/zookeeper/conf/zoo_sample.cfg\n+#2,install ZK\n \n RUN cd /opt && \\\n     wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz  && \\\n@@ -37,22 +46,22 @@ RUN cd /opt && \\\n     mkdir -p /tmp/zookeeper && \\\n     rm -rf /opt/zookeeper/conf/zoo_sample.cfg\n \n-ADD ./conf/zookeeper/zoo.cfg /opt/zookeeper/conf\n+ADD ./dockerfile/conf/zookeeper/zoo.cfg /opt/zookeeper/conf\n ENV ZK_HOME=/opt/zookeeper\n ENV PATH $PATH:$ZK_HOME/bin\n \n-#3,\u5b89\u88c5maven\n+#3,install maven\n RUN cd /opt && \\\n     wget http://apache-mirror.rbc.ru/pub/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz && \\\n     tar -zxvf apache-maven-3.3.9-bin.tar.gz && \\\n     mv apache-maven-3.3.9 maven && \\\n     rm -rf ./apache-maven-*tar.gz && \\\n     rm -rf /opt/maven/conf/settings.xml\n-ADD ./conf/maven/settings.xml /opt/maven/conf\n+ADD ./dockerfile/conf/maven/settings.xml /opt/maven/conf\n ENV MAVEN_HOME=/opt/maven\n ENV PATH $PATH:$MAVEN_HOME/bin\n \n-#4,\u5b89\u88c5node\n+#4,install node\n RUN cd /opt && \\\n     wget https://nodejs.org/download/release/v8.9.4/node-v8.9.4-linux-x64.tar.gz && \\\n     tar -zxvf node-v8.9.4-linux-x64.tar.gz && \\\n@@ -61,67 +70,19 @@ RUN cd /opt && \\\n ENV NODE_HOME=/opt/node\n ENV PATH $PATH:$NODE_HOME/bin\n \n-#5,\u4e0b\u8f7descheduler\n-RUN cd /opt && \\\n-    wget https://github.com/analysys/EasyScheduler/archive/${version}.tar.gz && \\\n-    tar -zxvf ${version}.tar.gz && \\\n-    mv EasyScheduler-${version} easyscheduler_source && \\\n-    rm -rf ./${version}.tar.gz\n-\n-#6,\u540e\u7aef\u7f16\u8bd1\n-RUN cd /opt/easyscheduler_source && \\\n-    mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n-\n-#7,\u524d\u7aef\u7f16\u8bd1\n-RUN chmod -R 777 /opt/easyscheduler_source/escheduler-ui && \\\n-    cd /opt/easyscheduler_source/escheduler-ui && \\\n-    rm -rf /opt/easyscheduler_source/escheduler-ui/node_modules && \\\n-    npm install node-sass --unsafe-perm && \\\n-    npm install && \\\n-    npm run build\n-#8,\u5b89\u88c5mysql\n-RUN echo \"deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse\" >> /etc/apt/sources.list\n-\n-RUN echo \"mysql-server mysql-server/root_password password root\" | debconf-set-selections\n-RUN echo \"mysql-server mysql-server/root_password_again password root\" | debconf-set-selections\n-\n+#5,install postgresql\n RUN apt-get update && \\\n-        apt-get -y install mysql-server-5.7 && \\\n-        mkdir -p /var/lib/mysql && \\\n-        mkdir -p /var/run/mysqld && \\\n-        mkdir -p /var/log/mysql && \\\n-        chown -R mysql:mysql /var/lib/mysql && \\\n-        chown -R mysql:mysql /var/run/mysqld && \\\n-        chown -R mysql:mysql /var/log/mysql\n-\n-\n-# UTF-8 and bind-address\n-RUN sed -i -e \"$ a [client]\\n\\n[mysql]\\n\\n[mysqld]\"  /etc/mysql/my.cnf && \\\n-        sed -i -e \"s/\\(\\[client\\]\\)/\\1\\ndefault-character-set = utf8/g\" /etc/mysql/my.cnf && \\\n-        sed -i -e \"s/\\(\\[mysql\\]\\)/\\1\\ndefault-character-set = utf8/g\" /etc/mysql/my.cnf && \\\n-        sed -i -e \"s/\\(\\[mysqld\\]\\)/\\1\\ninit_connect='SET NAMES utf8'\\ncharacter-set-server = utf8\\ncollation-server=utf8_general_ci\\nbind-address = 0.0.0.0/g\" /etc/mysql/my.cnf\n+    apt-get install -y postgresql postgresql-contrib sudo && \\\n+    sed -i 's/localhost/*/g' /etc/postgresql/10/main/postgresql.conf\n \n-\n-#9,\u5b89\u88c5nginx\n+#6,install nginx\n RUN apt-get update && \\\n   apt-get install -y nginx && \\\n   rm -rf /var/lib/apt/lists/* && \\\n   echo \"\\ndaemon off;\" >> /etc/nginx/nginx.conf && \\\n   chown -R www-data:www-data /var/lib/nginx\n \n-#10,\u4fee\u6539escheduler\u914d\u7f6e\u6587\u4ef6\n-#\u540e\u7aef\u914d\u7f6e\n-RUN mkdir -p /opt/escheduler && \\\n-    tar -zxvf /opt/easyscheduler_source/target/escheduler-${tar_version}.tar.gz -C /opt/escheduler && \\\n-    rm -rf /opt/escheduler/conf\n-ADD ./conf/escheduler/conf /opt/escheduler/conf\n-#\u524d\u7aefnginx\u914d\u7f6e\n-ADD ./conf/nginx/default.conf /etc/nginx/conf.d\n-\n-#11,\u5f00\u653e\u7aef\u53e3\n-EXPOSE 2181 2888 3888 3306 80 12345 8888\n-\n-#12,\u5b89\u88c5sudo,python,vim,ping\u548cssh\n+#7,install sudo,python,vim,ping and ssh command\n RUN apt-get update && \\\n   apt-get -y install sudo && \\\n   apt-get -y install python && \\\n@@ -132,15 +93,44 @@ RUN apt-get update && \\\n   apt-get -y install python-pip && \\\n   pip install kazoo\n \n-COPY ./startup.sh /root/startup.sh\n-#13,\u4fee\u6539\u6743\u9650\u548c\u8bbe\u7f6e\u8f6f\u8fde\n+#8,add dolphinscheduler source code to /opt/dolphinscheduler_source\n+ADD . /opt/dolphinscheduler_source\n+\n+\n+#9,backend compilation\n+RUN cd /opt/dolphinscheduler_source && \\\n+    mvn clean package -Prelease -Dmaven.test.skip=true\n+\n+#10,frontend compilation\n+RUN chmod -R 777 /opt/dolphinscheduler_source/dolphinscheduler-ui && \\\n+    cd /opt/dolphinscheduler_source/dolphinscheduler-ui && \\\n+    rm -rf /opt/dolphinscheduler_source/dolphinscheduler-ui/node_modules && \\\n+    npm install node-sass --unsafe-perm && \\\n+    npm install && \\\n+    npm run build\n+\n+#11,modify dolphinscheduler configuration file\n+#backend configuration\n+RUN tar -zxvf /opt/dolphinscheduler_source/dolphinscheduler-dist/dolphinscheduler-backend/target/apache-dolphinscheduler-incubating-${tar_version}-dolphinscheduler-backend-bin.tar.gz -C /opt && \\\n+    mv /opt/apache-dolphinscheduler-incubating-${tar_version}-dolphinscheduler-backend-bin /opt/dolphinscheduler && \\\n+    rm -rf /opt/dolphinscheduler/conf\n+\n+ADD ./dockerfile/conf/dolphinscheduler/conf /opt/dolphinscheduler/conf\n+#frontend nginx configuration\n+ADD ./dockerfile/conf/nginx/dolphinscheduler.conf /etc/nginx/conf.d\n+\n+#12,open port\n+EXPOSE 2181 2888 3888 3306 80 12345 8888\n+\n+COPY ./dockerfile/startup.sh /root/startup.sh\n+#13,modify permissions and set soft links\n RUN chmod +x /root/startup.sh && \\\n-  chmod +x /opt/escheduler/script/create_escheduler.sh && \\\n+  chmod +x /opt/dolphinscheduler/script/create-dolphinscheduler.sh && \\\n   chmod +x /opt/zookeeper/bin/zkServer.sh && \\\n-  chmod +x /opt/escheduler/bin/escheduler-daemon.sh && \\\n+  chmod +x /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh && \\\n   rm -rf /bin/sh && \\\n   ln -s /bin/bash /bin/sh && \\\n   mkdir -p /tmp/xls\n \n \n-ENTRYPOINT [\"/root/startup.sh\"]\n+ENTRYPOINT [\"/root/startup.sh\"]\n\\ No newline at end of file",
                "changes": 138
            },
            {
                "status": "added",
                "additions": 11,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/README.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/README.md?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/README.md",
                "deletions": 0,
                "sha": "33b58cacde257a0420e7ba23fc35bfebee5aa575",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/README.md",
                "patch": "@@ -0,0 +1,11 @@\n+## Build Image\n+```\n+  cd ..\n+  docker build -t dolphinscheduler --build-arg version=1.1.0 --build-arg tar_version=1.1.0-SNAPSHOT -f dockerfile/Dockerfile .\n+  docker run -p 12345:12345 -p 8888:8888 --rm --name dolphinscheduler -d dolphinscheduler\n+```\n+* Visit the url: http://127.0.0.1:8888\n+* UserName:admin Password:dolphinscheduler123\n+\n+## Note\n+* MacOS: The memory of docker needs to be set to 4G, default 2G. Steps: Preferences -> Advanced -> adjust resources -> Apply & Restart",
                "changes": 11
            },
            {
                "status": "added",
                "additions": 50,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/alert.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/alert.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/alert.properties",
                "deletions": 0,
                "sha": "276ef3132acdab8bafd2256c0909dd8e8fb41d5e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/alert.properties",
                "patch": "@@ -0,0 +1,50 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+#alert type is EMAIL/SMS\n+alert.type=EMAIL\n+\n+# mail server configuration\n+mail.protocol=SMTP\n+mail.server.host=smtp.126.com\n+mail.server.port=\n+mail.sender=dolphinscheduler@126.com\n+mail.user=dolphinscheduler@126.com\n+mail.passwd=escheduler123\n+\n+# TLS\n+mail.smtp.starttls.enable=false\n+# SSL\n+mail.smtp.ssl.enable=true\n+mail.smtp.ssl.trust=smtp.126.com\n+\n+#xls file path,need create if not exist\n+xls.file.path=/tmp/xls\n+\n+# Enterprise WeChat configuration\n+enterprise.wechat.enable=false\n+enterprise.wechat.corp.id=xxxxxxx\n+enterprise.wechat.secret=xxxxxxx\n+enterprise.wechat.agent.id=xxxxxxx\n+enterprise.wechat.users=xxxxxxx\n+enterprise.wechat.token.url=https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$corpId&corpsecret=$secret\n+enterprise.wechat.push.url=https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$token\n+enterprise.wechat.team.send.msg={\\\"toparty\\\":\\\"$toParty\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"$msg\\\"},\\\"safe\\\":\\\"0\\\"}\n+enterprise.wechat.user.send.msg={\\\"touser\\\":\\\"$toUser\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"markdown\\\",\\\"markdown\\\":{\\\"content\\\":\\\"$msg\\\"}}\n+\n+\n+",
                "changes": 50
            },
            {
                "status": "added",
                "additions": 49,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/alert_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/alert_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/alert_logback.xml",
                "deletions": 0,
                "sha": "35e19865b988da2dacd48f000fa3b9083d62c010",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/alert_logback.xml",
                "patch": "@@ -0,0 +1,49 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\"> <!--debug=\"true\" -->\n+\t<property name=\"log.base\" value=\"logs\" />\n+\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<appender name=\"ALERTLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+\t\t<file>${log.base}/dolphinscheduler-alert.log</file>\n+\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+\t\t\t<fileNamePattern>${log.base}/dolphinscheduler-alert.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+\t\t\t<maxHistory>20</maxHistory>\n+\t\t\t<maxFileSize>64MB</maxFileSize>\n+\t\t</rollingPolicy>\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<root level=\"INFO\">\n+\t\t<appender-ref ref=\"ALERTLOGFILE\"/>\n+\t</root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 49
            },
            {
                "status": "added",
                "additions": 60,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/apiserver_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/apiserver_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/apiserver_logback.xml",
                "deletions": 0,
                "sha": "36719671c92653b4635e8cb37ef811299f68d9e2",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/apiserver_logback.xml",
                "patch": "@@ -0,0 +1,60 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\">\n+\t<logger name=\"org.apache.zookeeper\" level=\"WARN\"/>\n+ \t<logger name=\"org.apache.hbase\" level=\"WARN\"/>\n+ \t<logger name=\"org.apache.hadoop\" level=\"WARN\"/>\n+\n+\t<property name=\"log.base\" value=\"logs\" />\n+\n+\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<appender name=\"APISERVERLOGFILE\"  class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+\t\t<!-- Log level filter -->\n+\t\t<filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n+\t\t\t<level>INFO</level>\n+\t\t</filter>\n+        <file>${log.base}/dolphinscheduler-api-server.log</file>\n+\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+\t\t\t<fileNamePattern>${log.base}/dolphinscheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+\t\t\t<maxHistory>168</maxHistory>\n+\t\t\t<maxFileSize>64MB</maxFileSize>\n+\t\t</rollingPolicy>\n+\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\n+\t</appender>\n+\n+\t<root level=\"INFO\">\n+\t\t<appender-ref ref=\"APISERVERLOGFILE\" />\n+\t</root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 60
            },
            {
                "status": "added",
                "additions": 40,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/application-api.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/application-api.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/application-api.properties",
                "deletions": 0,
                "sha": "ead8dd872e1a64d1bea89a5f142d0f31f96c0bcc",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/application-api.properties",
                "patch": "@@ -0,0 +1,40 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+logging.config=classpath:apiserver_logback.xml\n+\n+# server port\n+server.port=12345\n+\n+# session config\n+server.servlet.session.timeout=7200\n+\n+server.servlet.context-path=/dolphinscheduler/\n+\n+# file size limit for upload\n+spring.servlet.multipart.max-file-size=1024MB\n+spring.servlet.multipart.max-request-size=1024MB\n+\n+#post content\n+server.jetty.max-http-post-size=5000000\n+\n+spring.messages.encoding=UTF-8\n+\n+#i18n classpath folder , file prefix messages\uff0c if have many files, use \",\" seperator\n+spring.messages.basename=i18n/messages\n+\n+",
                "changes": 40
            },
            {
                "status": "added",
                "additions": 103,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/application-dao.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/application-dao.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/application-dao.properties",
                "deletions": 0,
                "sha": "166c36fbf0462644c1210da3c2818ede55667ac7",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/application-dao.properties",
                "patch": "@@ -0,0 +1,103 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# base spring data source configuration\n+spring.datasource.type=com.alibaba.druid.pool.DruidDataSource\n+# postgresql\n+spring.datasource.driver-class-name=org.postgresql.Driver\n+spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler\n+spring.datasource.username=root\n+spring.datasource.password=root@123\n+\n+# connection configuration\n+spring.datasource.initialSize=5\n+# min connection number\n+spring.datasource.minIdle=5\n+# max connection number\n+spring.datasource.maxActive=50\n+\n+# max wait time for get a connection in milliseconds. if configuring maxWait, fair locks are enabled by default and concurrency efficiency decreases.\n+# If necessary, unfair locks can be used by configuring the useUnfairLock attribute to true.\n+spring.datasource.maxWait=60000\n+\n+# milliseconds for check to close free connections\n+spring.datasource.timeBetweenEvictionRunsMillis=60000\n+\n+# the Destroy thread detects the connection interval and closes the physical connection in milliseconds if the connection idle time is greater than or equal to minEvictableIdleTimeMillis.\n+spring.datasource.timeBetweenConnectErrorMillis=60000\n+\n+# the longest time a connection remains idle without being evicted, in milliseconds\n+spring.datasource.minEvictableIdleTimeMillis=300000\n+\n+#the SQL used to check whether the connection is valid requires a query statement. If validation Query is null, testOnBorrow, testOnReturn, and testWhileIdle will not work.\n+spring.datasource.validationQuery=SELECT 1\n+\n+#check whether the connection is valid for timeout, in seconds\n+spring.datasource.validationQueryTimeout=3\n+\n+# when applying for a connection, if it is detected that the connection is idle longer than time Between Eviction Runs Millis,\n+# validation Query is performed to check whether the connection is valid\n+spring.datasource.testWhileIdle=true\n+\n+#execute validation to check if the connection is valid when applying for a connection\n+spring.datasource.testOnBorrow=true\n+#execute validation to check if the connection is valid when the connection is returned\n+spring.datasource.testOnReturn=false\n+spring.datasource.defaultAutoCommit=true\n+spring.datasource.keepAlive=true\n+\n+# open PSCache, specify count PSCache for every connection\n+spring.datasource.poolPreparedStatements=true\n+spring.datasource.maxPoolPreparedStatementPerConnectionSize=20\n+\n+spring.datasource.spring.datasource.filters=stat,wall,log4j\n+spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000\n+\n+#mybatis\n+mybatis-plus.mapper-locations=classpath*:/org.apache.dolphinscheduler.dao.mapper/*.xml\n+\n+mybatis-plus.typeEnumsPackage=org.apache.dolphinscheduler.*.enums\n+\n+#Entity scan, where multiple packages are separated by a comma or semicolon\n+mybatis-plus.typeAliasesPackage=org.apache.dolphinscheduler.dao.entity\n+\n+#Primary key type AUTO:\" database ID AUTO \", INPUT:\" user INPUT ID\", ID_WORKER:\" global unique ID (numeric type unique ID)\", UUID:\" global unique ID UUID\";\n+mybatis-plus.global-config.db-config.id-type=AUTO\n+\n+#Field policy IGNORED:\" ignore judgment \",NOT_NULL:\" not NULL judgment \"),NOT_EMPTY:\" not NULL judgment\"\n+mybatis-plus.global-config.db-config.field-strategy=NOT_NULL\n+\n+#The hump underline is converted\n+mybatis-plus.global-config.db-config.column-underline=true\n+mybatis-plus.global-config.db-config.logic-delete-value=-1\n+mybatis-plus.global-config.db-config.logic-not-delete-value=0\n+mybatis-plus.global-config.db-config.banner=false\n+#The original configuration\n+mybatis-plus.configuration.map-underscore-to-camel-case=true\n+mybatis-plus.configuration.cache-enabled=false\n+mybatis-plus.configuration.call-setters-on-nulls=true\n+mybatis-plus.configuration.jdbc-type-for-null=null\n+\n+# data quality analysis is not currently in use. please ignore the following configuration\n+# task record flag\n+task.record.flag=false\n+task.record.datasource.url=jdbc:mysql://192.168.xx.xx:3306/etl?characterEncoding=UTF-8\n+task.record.datasource.username=xx\n+task.record.datasource.password=xx\n+\n+# Logger Config\n+#logging.level.org.apache.dolphinscheduler.dao=debug",
                "changes": 103
            },
            {
                "status": "added",
                "additions": 80,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/combined_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/combined_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/combined_logback.xml",
                "deletions": 0,
                "sha": "6bdb97cf00f5b5d7732528cfad6e52559857f854",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/combined_logback.xml",
                "patch": "@@ -0,0 +1,80 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\">\n+    <property name=\"log.base\" value=\"logs\"/>\n+    <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+        <encoder>\n+            <pattern>\n+                %highlight([%level]) %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{10}:[%line] - %msg%n\n+            </pattern>\n+            <charset>UTF-8</charset>\n+        </encoder>\n+    </appender>\n+    <appender name=\"TASKLOGFILE\" class=\"ch.qos.logback.classic.sift.SiftingAppender\">\n+        <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n+            <level>INFO</level>\n+        </filter>\n+        <filter class=\"org.apache.dolphinscheduler.server.worker.log.TaskLogFilter\"></filter>\n+        <Discriminator class=\"org.apache.dolphinscheduler.server.worker.log.TaskLogDiscriminator\">\n+            <key>taskAppId</key>\n+            <logBase>${log.base}</logBase>\n+        </Discriminator>\n+        <sift>\n+            <appender name=\"FILE-${taskAppId}\" class=\"ch.qos.logback.core.FileAppender\">\n+                <file>${log.base}/${taskAppId}.log</file>\n+                <encoder>\n+                    <pattern>\n+                        [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+                    </pattern>\n+                    <charset>UTF-8</charset>\n+                </encoder>\n+                <append>true</append>\n+            </appender>\n+        </sift>\n+    </appender>\n+\n+    <appender name=\"COMBINEDLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+        <file>${log.base}/dolphinscheduler-combined.log</file>\n+        <filter class=\"org.apache.dolphinscheduler.server.worker.log.WorkerLogFilter\">\n+            <level>INFO</level>\n+        </filter>\n+\n+        <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+            <fileNamePattern>${log.base}/dolphinscheduler-combined.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+            <maxHistory>168</maxHistory>\n+            <maxFileSize>200MB</maxFileSize>\n+        </rollingPolicy>\n+        \u3000\u3000\u3000\u3000\u3000\n+        <encoder>\n+            <pattern>\n+                [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+            </pattern>\n+            <charset>UTF-8</charset>\n+        </encoder>\n+        \u3000\u3000\n+    </appender>\n+\n+\n+    <root level=\"INFO\">\n+        <appender-ref ref=\"STDOUT\"/>\n+        <appender-ref ref=\"TASKLOGFILE\"/>\n+        <appender-ref ref=\"COMBINEDLOGFILE\"/>\n+    </root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 80
            },
            {
                "status": "added",
                "additions": 59,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/common/common.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/common/common.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/common/common.properties",
                "deletions": 0,
                "sha": "5371c7665fbf97a5ff2c74eca97a1a5df3dba7aa",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/common/common.properties",
                "patch": "@@ -0,0 +1,59 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+#task queue implementation, default \"zookeeper\"\n+dolphinscheduler.queue.impl=zookeeper\n+\n+# user data directory path, self configuration, please make sure the directory exists and have read write permissions\n+data.basedir.path=/tmp/dolphinscheduler\n+\n+# directory path for user data download. self configuration, please make sure the directory exists and have read write permissions\n+data.download.basedir.path=/tmp/dolphinscheduler/download\n+\n+# process execute directory. self configuration, please make sure the directory exists and have read write permissions\n+process.exec.basepath=/tmp/dolphinscheduler/exec\n+\n+# Users who have permission to create directories under the HDFS root path\n+hdfs.root.user=hdfs\n+\n+# data base dir, resource file will store to this hadoop hdfs path, self configuration, please make sure the directory exists on hdfs and have read write permissions\u3002\"/dolphinscheduler\" is recommended\n+data.store2hdfs.basepath=/dolphinscheduler\n+\n+# resource upload startup type : HDFS,S3,NONE\n+res.upload.startup.type=NONE\n+\n+# whether kerberos starts\n+hadoop.security.authentication.startup.state=false\n+\n+# java.security.krb5.conf path\n+java.security.krb5.conf.path=/opt/krb5.conf\n+\n+# loginUserFromKeytab user\n+login.user.keytab.username=hdfs-mycluster@ESZ.COM\n+\n+# loginUserFromKeytab path\n+login.user.keytab.path=/opt/hdfs.headless.keytab\n+\n+# system env path. self configuration, please make sure the directory and file exists and have read write execute permissions\n+dolphinscheduler.env.path=/opt/dolphinscheduler/conf/env/.dolphinscheduler_env.sh\n+\n+#resource.view.suffixs\n+resource.view.suffixs=txt,log,sh,conf,cfg,py,java,sql,hql,xml\n+\n+# is development state? default \"false\"\n+development.state=true\n+",
                "changes": 59
            },
            {
                "status": "added",
                "additions": 35,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/common/hadoop/hadoop.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/common/hadoop/hadoop.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/common/hadoop/hadoop.properties",
                "deletions": 0,
                "sha": "2c19b4a52e115824a682222fa30d4662cecaf0b5",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/common/hadoop/hadoop.properties",
                "patch": "@@ -0,0 +1,35 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# ha or single namenode,If namenode ha needs to copy core-site.xml and hdfs-site.xml\n+# to the conf directory\uff0csupport s3\uff0cfor example : s3a://dolphinscheduler\n+fs.defaultFS=hdfs://mycluster:8020\n+\n+# s3 need\uff0cs3 endpoint\n+fs.s3a.endpoint=http://192.168.199.91:9010\n+\n+# s3 need\uff0cs3 access key\n+fs.s3a.access.key=A3DXS30FO22544RE\n+\n+# s3 need\uff0cs3 secret key\n+fs.s3a.secret.key=OloCLq3n+8+sdPHUhJ21XrSxTC+JK\n+\n+#resourcemanager ha note this need ips , this empty if single\n+yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx\n+\n+# If it is a single resourcemanager, you only need to configure one host name. If it is resourcemanager HA, the default configuration is fine\n+yarn.application.status.address=http://ark1:8088/ws/v1/cluster/apps/%s\n\\ No newline at end of file",
                "changes": 35
            },
            {
                "status": "added",
                "additions": 20,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/config/install_config.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/config/install_config.conf?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/config/install_config.conf",
                "deletions": 0,
                "sha": "196a78f49c67d004fb5fdb36a4e9b51a08569dab",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/config/install_config.conf",
                "patch": "@@ -0,0 +1,20 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+installPath=/data1_1T/dolphinscheduler\n+deployUser=dolphinscheduler\n+ips=ark0,ark1,ark2,ark3,ark4",
                "changes": 20
            },
            {
                "status": "added",
                "additions": 21,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/config/run_config.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/config/run_config.conf?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/config/run_config.conf",
                "deletions": 0,
                "sha": "69a28db4586d82f37e381f9a9bd21005b77b70a2",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/config/run_config.conf",
                "patch": "@@ -0,0 +1,21 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+masters=ark0,ark1\n+workers=ark2,ark3,ark4\n+alertServer=ark3\n+apiServers=ark1\n\\ No newline at end of file",
                "changes": 21
            },
            {
                "status": "added",
                "additions": 20,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/env/.dolphinscheduler_env.sh",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/env/.dolphinscheduler_env.sh?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/env/.dolphinscheduler_env.sh",
                "deletions": 0,
                "sha": "960d971dd870dc9c715157cd5797d5b68ac883e4",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/env/.dolphinscheduler_env.sh",
                "patch": "@@ -0,0 +1,20 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+export PYTHON_HOME=/usr/bin/python\n+export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+export PATH=$PYTHON_HOME:$JAVA_HOME/bin:$PATH",
                "changes": 20
            },
            {
                "status": "added",
                "additions": 20,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/env/.escheduler_env.sh",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/env/.escheduler_env.sh?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/env/.escheduler_env.sh",
                "deletions": 0,
                "sha": "5b85917fc2636bd4256e0d079abdc2408fc9e6ed",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/env/.escheduler_env.sh",
                "patch": "@@ -0,0 +1,20 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+export PYTHON_HOME=/usr/bin/python\n+export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+export PATH=$PYTHON_HOME:$JAVA_HOME/bin:$PATH\n\\ No newline at end of file",
                "changes": 20
            },
            {
                "status": "added",
                "additions": 252,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/i18n/messages.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/i18n/messages.properties",
                "deletions": 0,
                "sha": "be880ba26df4155aacc6c31f9b956ab948f544b2",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages.properties",
                "patch": "@@ -0,0 +1,252 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+QUERY_SCHEDULE_LIST_NOTES=query schedule list\n+EXECUTE_PROCESS_TAG=execute process related operation\n+PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n+RUN_PROCESS_INSTANCE_NOTES=run process instance \n+START_NODE_LIST=start node list\uff08node name\uff09\n+TASK_DEPEND_TYPE=task depend type\n+COMMAND_TYPE=command type\n+RUN_MODE=run mode\n+TIMEOUT=timeout\n+EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n+EXECUTE_TYPE=execute type\n+START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n+GET_RECEIVER_CC_NOTES=query receiver cc \n+DESC=description\n+GROUP_NAME=group name\n+GROUP_TYPE=group type\n+QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n+UPDATE_ALERT_GROUP_NOTES=update alert group \n+DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n+VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n+GRANT_ALERT_GROUP_NOTES=grant alert group \n+USER_IDS=user id list\n+ALERT_GROUP_TAG=alert group related operation\n+CREATE_ALERT_GROUP_NOTES=create alert group \n+WORKER_GROUP_TAG=worker group related operation\n+SAVE_WORKER_GROUP_NOTES=create worker group\n+WORKER_GROUP_NAME=worker group name\n+WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n+QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n+QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n+DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n+DATA_ANALYSIS_TAG=analysis related operation of task state\n+COUNT_TASK_STATE_NOTES=count task state \n+COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n+COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n+COUNT_COMMAND_STATE_NOTES=count command state \n+COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n+\n+ACCESS_TOKEN_TAG=access token related operation\n+MONITOR_TAG=monitor related operation\n+MASTER_LIST_NOTES=master server list\n+WORKER_LIST_NOTES=worker server list\n+QUERY_DATABASE_STATE_NOTES=query database state \n+QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n+TASK_STATE=task instance state\n+SOURCE_TABLE=SOURCE TABLE\n+DEST_TABLE=dest table\n+TASK_DATE=task date\n+QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=query history task record list paging\n+DATA_SOURCE_TAG=data source related operation\n+CREATE_DATA_SOURCE_NOTES=create data source\n+DATA_SOURCE_NAME=data source name\n+DATA_SOURCE_NOTE=data source desc\n+DB_TYPE=database type\n+DATA_SOURCE_HOST=DATA SOURCE HOST\n+DATA_SOURCE_PORT=data source port\n+DATABASE_NAME=database name\n+QUEUE_TAG=queue related operation\n+QUERY_QUEUE_LIST_NOTES=query queue list \n+QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n+CREATE_QUEUE_NOTES=create queue\n+YARN_QUEUE_NAME=yarn(hadoop) queue name\n+QUEUE_ID=queue id\n+TENANT_DESC=tenant desc\n+QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n+QUERY_TENANT_LIST_NOTES=query tenant list \n+UPDATE_TENANT_NOTES=update tenant \n+DELETE_TENANT_NOTES=delete tenant \n+RESOURCES_TAG=resource center related operation\n+CREATE_RESOURCE_NOTES=create resource \n+RESOURCE_TYPE=resource file type\n+RESOURCE_NAME=resource name\n+RESOURCE_DESC=resource file desc\n+RESOURCE_FILE=resource file\n+RESOURCE_ID=resource id\n+QUERY_RESOURCE_LIST_NOTES=query resource list\n+DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n+VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n+ONLINE_CREATE_RESOURCE_NOTES=online create resource \n+SUFFIX=resource file suffix\n+CONTENT=resource file content\n+UPDATE_RESOURCE_NOTES=edit resource file online\n+DOWNLOAD_RESOURCE_NOTES=download resource file\n+CREATE_UDF_FUNCTION_NOTES=create udf function \n+UDF_TYPE=UDF type\n+FUNC_NAME=function name\n+CLASS_NAME=package and class name\n+ARG_TYPES=arguments\n+UDF_DESC=udf desc\n+VIEW_UDF_FUNCTION_NOTES=view udf function \n+UPDATE_UDF_FUNCTION_NOTES=update udf function \n+QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n+VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n+DELETE_UDF_FUNCTION_NOTES=delete udf function \n+AUTHORIZED_FILE_NOTES=authorized file \n+UNAUTHORIZED_FILE_NOTES=unauthorized file \n+AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n+UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n+VERIFY_QUEUE_NOTES=verify queue \n+TENANT_TAG=tenant related operation\n+CREATE_TENANT_NOTES=create tenant \n+TENANT_CODE=tenant code\n+TENANT_NAME=tenant name\n+QUEUE_NAME=queue name\n+PASSWORD=password\n+DATA_SOURCE_OTHER=jdbc connection params, format:{\"key1\":\"value1\",...}\n+PROJECT_TAG=project related operation\n+CREATE_PROJECT_NOTES=create project \n+PROJECT_DESC=project description\n+UPDATE_PROJECT_NOTES=update project \n+PROJECT_ID=project id\n+QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n+QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n+DELETE_PROJECT_BY_ID_NOTES=delete project by id \n+QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n+QUERY_ALL_PROJECT_LIST_NOTES=query all project list\n+QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n+TASK_RECORD_TAG=task record related operation\n+QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n+CREATE_TOKEN_NOTES=create token \uff0cnote: please login first\n+QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n+SCHEDULE=schedule\n+WARNING_TYPE=warning type(sending strategy)\n+WARNING_GROUP_ID=warning group id\n+FAILURE_STRATEGY=failure strategy\n+RECEIVERS=receivers\n+RECEIVERS_CC=receivers cc\n+WORKER_GROUP_ID=worker server group id\n+PROCESS_INSTANCE_PRIORITY=process instance priority\n+UPDATE_SCHEDULE_NOTES=update schedule \n+SCHEDULE_ID=schedule id\n+ONLINE_SCHEDULE_NOTES=online schedule\n+OFFLINE_SCHEDULE_NOTES=offline schedule \n+QUERY_SCHEDULE_NOTES=query schedule \n+QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n+LOGIN_TAG=User login related operations\n+USER_NAME=user name\n+PROJECT_NAME=project name\n+CREATE_PROCESS_DEFINITION_NOTES=create process definition\n+PROCESS_DEFINITION_NAME=process definition name\n+PROCESS_DEFINITION_JSON=process definition detail info (json format)\n+PROCESS_DEFINITION_LOCATIONS=process definition node locations info (json format)\n+PROCESS_INSTANCE_LOCATIONS=process instance node locations info (json format)\n+PROCESS_DEFINITION_CONNECTS=process definition node connects info (json format)\n+PROCESS_INSTANCE_CONNECTS=process instance node connects info (json format)\n+PROCESS_DEFINITION_DESC=process definition desc\n+PROCESS_DEFINITION_TAG=process definition related opertation\n+SIGNOUT_NOTES=logout\n+USER_PASSWORD=user password\n+UPDATE_PROCESS_INSTANCE_NOTES=update process instance\n+QUERY_PROCESS_INSTANCE_LIST_NOTES=query process instance list\n+VERIFY_PROCCESS_DEFINITION_NAME_NOTES=verify proccess definition name\n+LOGIN_NOTES=user login\n+UPDATE_PROCCESS_DEFINITION_NOTES=update proccess definition\n+PROCESS_DEFINITION_ID=process definition id\n+PROCESS_DEFINITION_IDS=process definition ids\n+RELEASE_PROCCESS_DEFINITION_NOTES=release proccess definition\n+QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=query proccess definition by id\n+QUERY_PROCCESS_DEFINITION_LIST_NOTES=query proccess definition list\n+QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=query proccess definition list paging\n+QUERY_ALL_DEFINITION_LIST_NOTES=query all definition list\n+PAGE_NO=page no\n+PROCESS_INSTANCE_ID=process instance id\n+PROCESS_INSTANCE_JSON=process instance info(json format)\n+SCHEDULE_TIME=schedule time\n+SYNC_DEFINE=update the information of the process instance to the process definition\\\n+\n+RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n+SEARCH_VAL=search val\n+USER_ID=user id\n+PAGE_SIZE=page size\n+LIMIT=limit\n+VIEW_TREE_NOTES=view tree\n+GET_NODE_LIST_BY_DEFINITION_ID_NOTES=get task node list by process definition id\n+PROCESS_DEFINITION_ID_LIST=process definition id list\n+QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=query proccess definition all by project id\n+DELETE_PROCESS_DEFINITION_BY_ID_NOTES=delete process definition by process definition id\n+BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=batch delete process definition by process definition ids\n+QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n+DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n+TASK_ID=task instance id\n+SKIP_LINE_NUM=skip line num\n+QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n+DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n+USERS_TAG=users related operation\n+SCHEDULER_TAG=scheduler related operation\n+CREATE_SCHEDULE_NOTES=create schedule \n+CREATE_USER_NOTES=create user\n+TENANT_ID=tenant id\n+QUEUE=queue\n+EMAIL=email\n+PHONE=phone\n+QUERY_USER_LIST_NOTES=query user list \n+UPDATE_USER_NOTES=update user\n+DELETE_USER_BY_ID_NOTES=delete user by id\n+GRANT_PROJECT_NOTES=GRANT PROJECT \n+PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n+GRANT_RESOURCE_NOTES=grant resource file\n+RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n+GET_USER_INFO_NOTES=get user info \n+LIST_USER_NOTES=list user\n+VERIFY_USER_NAME_NOTES=verify user name\n+UNAUTHORIZED_USER_NOTES=cancel authorization\n+ALERT_GROUP_ID=alert group id\n+AUTHORIZED_USER_NOTES=authorized user\n+GRANT_UDF_FUNC_NOTES=grant udf function\n+UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n+GRANT_DATASOURCE_NOTES=grant datasource \n+DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n+QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n+QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n+QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n+VIEW_GANTT_NOTES=view gantt \n+SUB_PROCESS_INSTANCE_ID=sub process instance id\n+TASK_NAME=task instance name\n+TASK_INSTANCE_TAG=task instance related operation\n+LOGGER_TAG=log related operation\n+PROCESS_INSTANCE_TAG=process instance related operation\n+EXECUTION_STATUS=runing status for workflow and task nodes\n+HOST=ip address of running task\n+START_DATE=start date\n+END_DATE=end date\n+QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=query task list by process instance id\n+UPDATE_DATA_SOURCE_NOTES=update data source\n+DATA_SOURCE_ID=DATA SOURCE ID\n+QUERY_DATA_SOURCE_NOTES=query data source by id\n+QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n+QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n+CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n+CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n+DELETE_DATA_SOURCE_NOTES=delete data source \n+VERIFY_DATA_SOURCE_NOTES=verify data source\n+UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n+AUTHORIZED_DATA_SOURCE_NOTES=authorized data source\n+DELETE_SCHEDULER_BY_ID_NOTES=delete scheduler by id",
                "changes": 252
            },
            {
                "status": "added",
                "additions": 252,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages_en_US.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/i18n/messages_en_US.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/i18n/messages_en_US.properties",
                "deletions": 0,
                "sha": "24c0843c109cfcdef4506cc9df93358910a3fb0e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages_en_US.properties",
                "patch": "@@ -0,0 +1,252 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+QUERY_SCHEDULE_LIST_NOTES=query schedule list\n+EXECUTE_PROCESS_TAG=execute process related operation\n+PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n+RUN_PROCESS_INSTANCE_NOTES=run process instance \n+START_NODE_LIST=start node list\uff08node name\uff09\n+TASK_DEPEND_TYPE=task depend type\n+COMMAND_TYPE=command type\n+RUN_MODE=run mode\n+TIMEOUT=timeout\n+EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n+EXECUTE_TYPE=execute type\n+START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n+GET_RECEIVER_CC_NOTES=query receiver cc \n+DESC=description\n+GROUP_NAME=group name\n+GROUP_TYPE=group type\n+QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n+UPDATE_ALERT_GROUP_NOTES=update alert group \n+DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n+VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n+GRANT_ALERT_GROUP_NOTES=grant alert group \n+USER_IDS=user id list\n+ALERT_GROUP_TAG=alert group related operation\n+CREATE_ALERT_GROUP_NOTES=create alert group \n+WORKER_GROUP_TAG=worker group related operation\n+SAVE_WORKER_GROUP_NOTES=create worker group\n+WORKER_GROUP_NAME=worker group name\n+WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n+QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n+QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n+DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n+DATA_ANALYSIS_TAG=analysis related operation of task state\n+COUNT_TASK_STATE_NOTES=count task state \n+COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n+COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n+COUNT_COMMAND_STATE_NOTES=count command state \n+COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n+\n+ACCESS_TOKEN_TAG=access token related operation\n+MONITOR_TAG=monitor related operation\n+MASTER_LIST_NOTES=master server list\n+WORKER_LIST_NOTES=worker server list\n+QUERY_DATABASE_STATE_NOTES=query database state \n+QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n+TASK_STATE=task instance state\n+SOURCE_TABLE=SOURCE TABLE\n+DEST_TABLE=dest table\n+TASK_DATE=task date\n+QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=query history task record list paging\n+DATA_SOURCE_TAG=data source related operation\n+CREATE_DATA_SOURCE_NOTES=create data source\n+DATA_SOURCE_NAME=data source name\n+DATA_SOURCE_NOTE=data source desc\n+DB_TYPE=database type\n+DATA_SOURCE_HOST=DATA SOURCE HOST\n+DATA_SOURCE_PORT=data source port\n+DATABASE_NAME=database name\n+QUEUE_TAG=queue related operation\n+QUERY_QUEUE_LIST_NOTES=query queue list \n+QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n+CREATE_QUEUE_NOTES=create queue\n+YARN_QUEUE_NAME=yarn(hadoop) queue name\n+QUEUE_ID=queue id\n+TENANT_DESC=tenant desc\n+QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n+QUERY_TENANT_LIST_NOTES=query tenant list \n+UPDATE_TENANT_NOTES=update tenant \n+DELETE_TENANT_NOTES=delete tenant \n+RESOURCES_TAG=resource center related operation\n+CREATE_RESOURCE_NOTES=create resource \n+RESOURCE_TYPE=resource file type\n+RESOURCE_NAME=resource name\n+RESOURCE_DESC=resource file desc\n+RESOURCE_FILE=resource file\n+RESOURCE_ID=resource id\n+QUERY_RESOURCE_LIST_NOTES=query resource list\n+DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n+VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n+ONLINE_CREATE_RESOURCE_NOTES=online create resource \n+SUFFIX=resource file suffix\n+CONTENT=resource file content\n+UPDATE_RESOURCE_NOTES=edit resource file online\n+DOWNLOAD_RESOURCE_NOTES=download resource file\n+CREATE_UDF_FUNCTION_NOTES=create udf function \n+UDF_TYPE=UDF type\n+FUNC_NAME=function name\n+CLASS_NAME=package and class name\n+ARG_TYPES=arguments\n+UDF_DESC=udf desc\n+VIEW_UDF_FUNCTION_NOTES=view udf function \n+UPDATE_UDF_FUNCTION_NOTES=update udf function \n+QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n+VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n+DELETE_UDF_FUNCTION_NOTES=delete udf function \n+AUTHORIZED_FILE_NOTES=authorized file \n+UNAUTHORIZED_FILE_NOTES=unauthorized file \n+AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n+UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n+VERIFY_QUEUE_NOTES=verify queue \n+TENANT_TAG=tenant related operation\n+CREATE_TENANT_NOTES=create tenant \n+TENANT_CODE=tenant code\n+TENANT_NAME=tenant name\n+QUEUE_NAME=queue name\n+PASSWORD=password\n+DATA_SOURCE_OTHER=jdbc connection params, format:{\"key1\":\"value1\",...}\n+PROJECT_TAG=project related operation\n+CREATE_PROJECT_NOTES=create project \n+PROJECT_DESC=project description\n+UPDATE_PROJECT_NOTES=update project \n+PROJECT_ID=project id\n+QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n+QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n+QUERY_ALL_PROJECT_LIST_NOTES=query all project list\n+DELETE_PROJECT_BY_ID_NOTES=delete project by id \n+QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n+QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n+TASK_RECORD_TAG=task record related operation\n+QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n+CREATE_TOKEN_NOTES=create token \uff0cnote: please login first\n+QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n+SCHEDULE=schedule\n+WARNING_TYPE=warning type(sending strategy)\n+WARNING_GROUP_ID=warning group id\n+FAILURE_STRATEGY=failure strategy\n+RECEIVERS=receivers\n+RECEIVERS_CC=receivers cc\n+WORKER_GROUP_ID=worker server group id\n+PROCESS_INSTANCE_PRIORITY=process instance priority\n+UPDATE_SCHEDULE_NOTES=update schedule \n+SCHEDULE_ID=schedule id\n+ONLINE_SCHEDULE_NOTES=online schedule\n+OFFLINE_SCHEDULE_NOTES=offline schedule \n+QUERY_SCHEDULE_NOTES=query schedule \n+QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n+LOGIN_TAG=User login related operations\n+USER_NAME=user name\n+PROJECT_NAME=project name\n+CREATE_PROCESS_DEFINITION_NOTES=create process definition\n+PROCESS_DEFINITION_NAME=process definition name\n+PROCESS_DEFINITION_JSON=process definition detail info (json format)\n+PROCESS_DEFINITION_LOCATIONS=process definition node locations info (json format)\n+PROCESS_INSTANCE_LOCATIONS=process instance node locations info (json format)\n+PROCESS_DEFINITION_CONNECTS=process definition node connects info (json format)\n+PROCESS_INSTANCE_CONNECTS=process instance node connects info (json format)\n+PROCESS_DEFINITION_DESC=process definition desc\n+PROCESS_DEFINITION_TAG=process definition related opertation\n+SIGNOUT_NOTES=logout\n+USER_PASSWORD=user password\n+UPDATE_PROCESS_INSTANCE_NOTES=update process instance\n+QUERY_PROCESS_INSTANCE_LIST_NOTES=query process instance list\n+VERIFY_PROCCESS_DEFINITION_NAME_NOTES=verify proccess definition name\n+LOGIN_NOTES=user login\n+UPDATE_PROCCESS_DEFINITION_NOTES=update proccess definition\n+PROCESS_DEFINITION_ID=process definition id\n+PROCESS_DEFINITION_IDS=process definition ids\n+RELEASE_PROCCESS_DEFINITION_NOTES=release proccess definition\n+QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=query proccess definition by id\n+QUERY_PROCCESS_DEFINITION_LIST_NOTES=query proccess definition list\n+QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=query proccess definition list paging\n+QUERY_ALL_DEFINITION_LIST_NOTES=query all definition list\n+PAGE_NO=page no\n+PROCESS_INSTANCE_ID=process instance id\n+PROCESS_INSTANCE_JSON=process instance info(json format)\n+SCHEDULE_TIME=schedule time\n+SYNC_DEFINE=update the information of the process instance to the process definition\\\n+\n+RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n+SEARCH_VAL=search val\n+USER_ID=user id\n+PAGE_SIZE=page size\n+LIMIT=limit\n+VIEW_TREE_NOTES=view tree\n+GET_NODE_LIST_BY_DEFINITION_ID_NOTES=get task node list by process definition id\n+PROCESS_DEFINITION_ID_LIST=process definition id list\n+QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=query proccess definition all by project id\n+DELETE_PROCESS_DEFINITION_BY_ID_NOTES=delete process definition by process definition id\n+BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=batch delete process definition by process definition ids\n+QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n+DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n+TASK_ID=task instance id\n+SKIP_LINE_NUM=skip line num\n+QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n+DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n+USERS_TAG=users related operation\n+SCHEDULER_TAG=scheduler related operation\n+CREATE_SCHEDULE_NOTES=create schedule \n+CREATE_USER_NOTES=create user\n+TENANT_ID=tenant id\n+QUEUE=queue\n+EMAIL=email\n+PHONE=phone\n+QUERY_USER_LIST_NOTES=query user list \n+UPDATE_USER_NOTES=update user\n+DELETE_USER_BY_ID_NOTES=delete user by id\n+GRANT_PROJECT_NOTES=GRANT PROJECT \n+PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n+GRANT_RESOURCE_NOTES=grant resource file\n+RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n+GET_USER_INFO_NOTES=get user info \n+LIST_USER_NOTES=list user\n+VERIFY_USER_NAME_NOTES=verify user name\n+UNAUTHORIZED_USER_NOTES=cancel authorization\n+ALERT_GROUP_ID=alert group id\n+AUTHORIZED_USER_NOTES=authorized user\n+GRANT_UDF_FUNC_NOTES=grant udf function\n+UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n+GRANT_DATASOURCE_NOTES=grant datasource \n+DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n+QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n+QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n+QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n+VIEW_GANTT_NOTES=view gantt \n+SUB_PROCESS_INSTANCE_ID=sub process instance id\n+TASK_NAME=task instance name\n+TASK_INSTANCE_TAG=task instance related operation\n+LOGGER_TAG=log related operation\n+PROCESS_INSTANCE_TAG=process instance related operation\n+EXECUTION_STATUS=runing status for workflow and task nodes\n+HOST=ip address of running task\n+START_DATE=start date\n+END_DATE=end date\n+QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=query task list by process instance id\n+UPDATE_DATA_SOURCE_NOTES=update data source\n+DATA_SOURCE_ID=DATA SOURCE ID\n+QUERY_DATA_SOURCE_NOTES=query data source by id\n+QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n+QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n+CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n+CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n+DELETE_DATA_SOURCE_NOTES=delete data source \n+VERIFY_DATA_SOURCE_NOTES=verify data source\n+UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n+AUTHORIZED_DATA_SOURCE_NOTES=authorized data source\n+DELETE_SCHEDULER_BY_ID_NOTES=delete scheduler by id",
                "changes": 252
            },
            {
                "status": "added",
                "additions": 250,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages_zh_CN.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/i18n/messages_zh_CN.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/i18n/messages_zh_CN.properties",
                "deletions": 0,
                "sha": "5f24a6fedda8b24bca900ea3ba30345c8f0dd562",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/i18n/messages_zh_CN.properties",
                "patch": "@@ -0,0 +1,250 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+QUERY_SCHEDULE_LIST_NOTES=\u67e5\u8be2\u5b9a\u65f6\u5217\u8868\n+PROCESS_INSTANCE_EXECUTOR_TAG=\u6d41\u7a0b\u5b9e\u4f8b\u6267\u884c\u76f8\u5173\u64cd\u4f5c\n+RUN_PROCESS_INSTANCE_NOTES=\u8fd0\u884c\u6d41\u7a0b\u5b9e\u4f8b\n+START_NODE_LIST=\u5f00\u59cb\u8282\u70b9\u5217\u8868(\u8282\u70b9name)\n+TASK_DEPEND_TYPE=\u4efb\u52a1\u4f9d\u8d56\u7c7b\u578b\n+COMMAND_TYPE=\u6307\u4ee4\u7c7b\u578b\n+RUN_MODE=\u8fd0\u884c\u6a21\u5f0f\n+TIMEOUT=\u8d85\u65f6\u65f6\u95f4\n+EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=\u6267\u884c\u6d41\u7a0b\u5b9e\u4f8b\u7684\u5404\u79cd\u64cd\u4f5c(\u6682\u505c\u3001\u505c\u6b62\u3001\u91cd\u8dd1\u3001\u6062\u590d\u7b49)\n+EXECUTE_TYPE=\u6267\u884c\u7c7b\u578b\n+START_CHECK_PROCESS_DEFINITION_NOTES=\u68c0\u67e5\u6d41\u7a0b\u5b9a\u4e49\n+DESC=\u5907\u6ce8(\u63cf\u8ff0)\n+GROUP_NAME=\u7ec4\u540d\u79f0\n+GROUP_TYPE=\u7ec4\u7c7b\u578b\n+QUERY_ALERT_GROUP_LIST_NOTES=\u544a\u8b66\u7ec4\u5217\u8868\\\n+\n+UPDATE_ALERT_GROUP_NOTES=\u7f16\u8f91(\u66f4\u65b0)\u544a\u8b66\u7ec4\n+DELETE_ALERT_GROUP_BY_ID_NOTES=\u5220\u9664\u544a\u8b66\u7ec4\u901a\u8fc7ID\n+VERIFY_ALERT_GROUP_NAME_NOTES=\u68c0\u67e5\u544a\u8b66\u7ec4\u662f\u5426\u5b58\u5728\n+GRANT_ALERT_GROUP_NOTES=\u6388\u6743\u544a\u8b66\u7ec4\n+USER_IDS=\u7528\u6237ID\u5217\u8868\n+ALERT_GROUP_TAG=\u544a\u8b66\u7ec4\u76f8\u5173\u64cd\u4f5c\n+WORKER_GROUP_TAG=Worker\u5206\u7ec4\u7ba1\u7406\n+SAVE_WORKER_GROUP_NOTES=\u521b\u5efaWorker\u5206\u7ec4\\\n+\n+WORKER_GROUP_NAME=Worker\u5206\u7ec4\u540d\u79f0\n+WORKER_IP_LIST=Worker ip\u5217\u8868\uff0c\u6ce8\u610f\uff1a\u591a\u4e2aIP\u5730\u5740\u4ee5\u9017\u53f7\u5206\u5272\\\n+\n+QUERY_WORKER_GROUP_PAGING_NOTES=Worker\u5206\u7ec4\u7ba1\u7406\n+QUERY_WORKER_GROUP_LIST_NOTES=\u67e5\u8be2worker group\u5206\u7ec4\n+DELETE_WORKER_GROUP_BY_ID_NOTES=\u5220\u9664worker group\u901a\u8fc7ID\n+DATA_ANALYSIS_TAG=\u4efb\u52a1\u72b6\u6001\u5206\u6790\u76f8\u5173\u64cd\u4f5c\n+COUNT_TASK_STATE_NOTES=\u4efb\u52a1\u72b6\u6001\u7edf\u8ba1\n+COUNT_PROCESS_INSTANCE_NOTES=\u7edf\u8ba1\u6d41\u7a0b\u5b9e\u4f8b\u72b6\u6001\n+COUNT_PROCESS_DEFINITION_BY_USER_NOTES=\u7edf\u8ba1\u7528\u6237\u521b\u5efa\u7684\u6d41\u7a0b\u5b9a\u4e49\n+COUNT_COMMAND_STATE_NOTES=\u7edf\u8ba1\u547d\u4ee4\u72b6\u6001\n+COUNT_QUEUE_STATE_NOTES=\u7edf\u8ba1\u961f\u5217\u91cc\u4efb\u52a1\u72b6\u6001\n+ACCESS_TOKEN_TAG=access token\u76f8\u5173\u64cd\u4f5c\uff0c\u9700\u8981\u5148\u767b\u5f55\n+MONITOR_TAG=\u76d1\u63a7\u76f8\u5173\u64cd\u4f5c\n+MASTER_LIST_NOTES=master\u670d\u52a1\u5217\u8868\n+WORKER_LIST_NOTES=worker\u670d\u52a1\u5217\u8868\n+QUERY_DATABASE_STATE_NOTES=\u67e5\u8be2\u6570\u636e\u5e93\u72b6\u6001\n+QUERY_ZOOKEEPER_STATE_NOTES=\u67e5\u8be2Zookeeper\u72b6\u6001\n+TASK_STATE=\u4efb\u52a1\u5b9e\u4f8b\u72b6\u6001\n+SOURCE_TABLE=\u6e90\u8868\n+DEST_TABLE=\u76ee\u6807\u8868\n+TASK_DATE=\u4efb\u52a1\u65f6\u95f4\n+QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u5386\u53f2\u4efb\u52a1\u8bb0\u5f55\u5217\u8868\n+DATA_SOURCE_TAG=\u6570\u636e\u6e90\u76f8\u5173\u64cd\u4f5c\n+CREATE_DATA_SOURCE_NOTES=\u521b\u5efa\u6570\u636e\u6e90\n+DATA_SOURCE_NAME=\u6570\u636e\u6e90\u540d\u79f0\n+DATA_SOURCE_NOTE=\u6570\u636e\u6e90\u63cf\u8ff0\n+DB_TYPE=\u6570\u636e\u6e90\u7c7b\u578b\n+DATA_SOURCE_HOST=IP\u4e3b\u673a\u540d\n+DATA_SOURCE_PORT=\u6570\u636e\u6e90\u7aef\u53e3\n+DATABASE_NAME=\u6570\u636e\u5e93\u540d\n+QUEUE_TAG=\u961f\u5217\u76f8\u5173\u64cd\u4f5c\n+QUERY_QUEUE_LIST_NOTES=\u67e5\u8be2\u961f\u5217\u5217\u8868\n+QUERY_QUEUE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u961f\u5217\u5217\u8868\n+CREATE_QUEUE_NOTES=\u521b\u5efa\u961f\u5217\n+YARN_QUEUE_NAME=hadoop yarn\u961f\u5217\u540d\n+QUEUE_ID=\u961f\u5217ID\n+TENANT_DESC=\u79df\u6237\u63cf\u8ff0\n+QUERY_TENANT_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u79df\u6237\u5217\u8868\n+QUERY_TENANT_LIST_NOTES=\u67e5\u8be2\u79df\u6237\u5217\u8868\n+UPDATE_TENANT_NOTES=\u66f4\u65b0\u79df\u6237\n+DELETE_TENANT_NOTES=\u5220\u9664\u79df\u6237\n+RESOURCES_TAG=\u8d44\u6e90\u4e2d\u5fc3\u76f8\u5173\u64cd\u4f5c\n+CREATE_RESOURCE_NOTES=\u521b\u5efa\u8d44\u6e90\n+RESOURCE_TYPE=\u8d44\u6e90\u6587\u4ef6\u7c7b\u578b\n+RESOURCE_NAME=\u8d44\u6e90\u6587\u4ef6\u540d\u79f0\n+RESOURCE_DESC=\u8d44\u6e90\u6587\u4ef6\u63cf\u8ff0\n+RESOURCE_FILE=\u8d44\u6e90\u6587\u4ef6\n+RESOURCE_ID=\u8d44\u6e90ID\n+QUERY_RESOURCE_LIST_NOTES=\u67e5\u8be2\u8d44\u6e90\u5217\u8868\n+DELETE_RESOURCE_BY_ID_NOTES=\u5220\u9664\u8d44\u6e90\u901a\u8fc7ID\n+VIEW_RESOURCE_BY_ID_NOTES=\u6d4f\u89c8\u8d44\u6e90\u901a\u901a\u8fc7ID\n+ONLINE_CREATE_RESOURCE_NOTES=\u5728\u7ebf\u521b\u5efa\u8d44\u6e90\n+SUFFIX=\u8d44\u6e90\u6587\u4ef6\u540e\u7f00\n+CONTENT=\u8d44\u6e90\u6587\u4ef6\u5185\u5bb9\n+UPDATE_RESOURCE_NOTES=\u5728\u7ebf\u66f4\u65b0\u8d44\u6e90\u6587\u4ef6\n+DOWNLOAD_RESOURCE_NOTES=\u4e0b\u8f7d\u8d44\u6e90\u6587\u4ef6\n+CREATE_UDF_FUNCTION_NOTES=\u521b\u5efaUDF\u51fd\u6570\n+UDF_TYPE=UDF\u7c7b\u578b\n+FUNC_NAME=\u51fd\u6570\u540d\u79f0\n+CLASS_NAME=\u5305\u540d\u7c7b\u540d\n+ARG_TYPES=\u53c2\u6570\n+UDF_DESC=udf\u63cf\u8ff0\uff0c\u4f7f\u7528\u8bf4\u660e\n+VIEW_UDF_FUNCTION_NOTES=\u67e5\u770budf\u51fd\u6570\n+UPDATE_UDF_FUNCTION_NOTES=\u66f4\u65b0udf\u51fd\u6570\n+QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2udf\u51fd\u6570\u5217\u8868\n+VERIFY_UDF_FUNCTION_NAME_NOTES=\u9a8c\u8bc1udf\u51fd\u6570\u540d\n+DELETE_UDF_FUNCTION_NOTES=\u5220\u9664UDF\u51fd\u6570\n+AUTHORIZED_FILE_NOTES=\u6388\u6743\u6587\u4ef6\n+UNAUTHORIZED_FILE_NOTES=\u53d6\u6d88\u6388\u6743\u6587\u4ef6\n+AUTHORIZED_UDF_FUNC_NOTES=\u6388\u6743udf\u51fd\u6570\n+UNAUTHORIZED_UDF_FUNC_NOTES=\u53d6\u6d88udf\u51fd\u6570\u6388\u6743\n+VERIFY_QUEUE_NOTES=\u9a8c\u8bc1\u961f\u5217\n+TENANT_TAG=\u79df\u6237\u76f8\u5173\u64cd\u4f5c\n+CREATE_TENANT_NOTES=\u521b\u5efa\u79df\u6237\n+TENANT_CODE=\u79df\u6237\u7f16\u7801\n+TENANT_NAME=\u79df\u6237\u540d\u79f0\n+QUEUE_NAME=\u961f\u5217\u540d\n+PASSWORD=\u5bc6\u7801\n+DATA_SOURCE_OTHER=jdbc\u8fde\u63a5\u53c2\u6570\uff0c\u683c\u5f0f\u4e3a:{\"key1\":\"value1\",...}\n+PROJECT_TAG=\u9879\u76ee\u76f8\u5173\u64cd\u4f5c\n+CREATE_PROJECT_NOTES=\u521b\u5efa\u9879\u76ee\n+PROJECT_DESC=\u9879\u76ee\u63cf\u8ff0\n+UPDATE_PROJECT_NOTES=\u66f4\u65b0\u9879\u76ee\n+PROJECT_ID=\u9879\u76eeID\n+QUERY_PROJECT_BY_ID_NOTES=\u901a\u8fc7\u9879\u76eeID\u67e5\u8be2\u9879\u76ee\u4fe1\u606f\n+QUERY_PROJECT_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u9879\u76ee\u5217\u8868\n+QUERY_ALL_PROJECT_LIST_NOTES=\u67e5\u8be2\u6240\u6709\u9879\u76ee\n+DELETE_PROJECT_BY_ID_NOTES=\u5220\u9664\u9879\u76ee\u901a\u8fc7ID\n+QUERY_UNAUTHORIZED_PROJECT_NOTES=\u67e5\u8be2\u672a\u6388\u6743\u7684\u9879\u76ee\n+QUERY_AUTHORIZED_PROJECT_NOTES=\u67e5\u8be2\u6388\u6743\u9879\u76ee\n+TASK_RECORD_TAG=\u4efb\u52a1\u8bb0\u5f55\u76f8\u5173\u64cd\u4f5c\n+QUERY_TASK_RECORD_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u4efb\u52a1\u8bb0\u5f55\u5217\u8868\n+CREATE_TOKEN_NOTES=\u521b\u5efatoken\uff0c\u6ce8\u610f\u9700\u8981\u5148\u767b\u5f55\n+QUERY_ACCESS_TOKEN_LIST_NOTES=\u5206\u9875\u67e5\u8be2access token\u5217\u8868\n+SCHEDULE=\u5b9a\u65f6\n+WARNING_TYPE=\u53d1\u9001\u7b56\u7565\n+WARNING_GROUP_ID=\u53d1\u9001\u7ec4ID\n+FAILURE_STRATEGY=\u5931\u8d25\u7b56\u7565\n+RECEIVERS=\u6536\u4ef6\u4eba\n+RECEIVERS_CC=\u6536\u4ef6\u4eba(\u6284\u9001)\n+WORKER_GROUP_ID=Worker Server\u5206\u7ec4ID\n+PROCESS_INSTANCE_PRIORITY=\u6d41\u7a0b\u5b9e\u4f8b\u4f18\u5148\u7ea7\n+UPDATE_SCHEDULE_NOTES=\u66f4\u65b0\u5b9a\u65f6\n+SCHEDULE_ID=\u5b9a\u65f6ID\n+ONLINE_SCHEDULE_NOTES=\u5b9a\u65f6\u4e0a\u7ebf\n+OFFLINE_SCHEDULE_NOTES=\u5b9a\u65f6\u4e0b\u7ebf\n+QUERY_SCHEDULE_NOTES=\u67e5\u8be2\u5b9a\u65f6\n+QUERY_SCHEDULE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u5b9a\u65f6\n+LOGIN_TAG=\u7528\u6237\u767b\u5f55\u76f8\u5173\u64cd\u4f5c\n+USER_NAME=\u7528\u6237\u540d\n+PROJECT_NAME=\u9879\u76ee\u540d\u79f0\n+CREATE_PROCESS_DEFINITION_NOTES=\u521b\u5efa\u6d41\u7a0b\u5b9a\u4e49\n+PROCESS_DEFINITION_NAME=\u6d41\u7a0b\u5b9a\u4e49\u540d\u79f0\n+PROCESS_DEFINITION_JSON=\u6d41\u7a0b\u5b9a\u4e49\u8be6\u7ec6\u4fe1\u606f(json\u683c\u5f0f)\n+PROCESS_DEFINITION_LOCATIONS=\u6d41\u7a0b\u5b9a\u4e49\u8282\u70b9\u5750\u6807\u4f4d\u7f6e\u4fe1\u606f(json\u683c\u5f0f)\n+PROCESS_INSTANCE_LOCATIONS=\u6d41\u7a0b\u5b9e\u4f8b\u8282\u70b9\u5750\u6807\u4f4d\u7f6e\u4fe1\u606f(json\u683c\u5f0f)\n+PROCESS_DEFINITION_CONNECTS=\u6d41\u7a0b\u5b9a\u4e49\u8282\u70b9\u56fe\u6807\u8fde\u63a5\u4fe1\u606f(json\u683c\u5f0f)\n+PROCESS_INSTANCE_CONNECTS=\u6d41\u7a0b\u5b9e\u4f8b\u8282\u70b9\u56fe\u6807\u8fde\u63a5\u4fe1\u606f(json\u683c\u5f0f)\n+PROCESS_DEFINITION_DESC=\u6d41\u7a0b\u5b9a\u4e49\u63cf\u8ff0\u4fe1\u606f\n+PROCESS_DEFINITION_TAG=\u6d41\u7a0b\u5b9a\u4e49\u76f8\u5173\u64cd\u4f5c\n+SIGNOUT_NOTES=\u9000\u51fa\u767b\u5f55\n+USER_PASSWORD=\u7528\u6237\u5bc6\u7801\n+UPDATE_PROCESS_INSTANCE_NOTES=\u66f4\u65b0\u6d41\u7a0b\u5b9e\u4f8b\n+QUERY_PROCESS_INSTANCE_LIST_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u5217\u8868\n+VERIFY_PROCCESS_DEFINITION_NAME_NOTES=\u9a8c\u8bc1\u6d41\u7a0b\u5b9a\u4e49\u540d\u5b57\n+LOGIN_NOTES=\u7528\u6237\u767b\u5f55\n+UPDATE_PROCCESS_DEFINITION_NOTES=\u66f4\u65b0\u6d41\u7a0b\u5b9a\u4e49\n+PROCESS_DEFINITION_ID=\u6d41\u7a0b\u5b9a\u4e49ID\n+RELEASE_PROCCESS_DEFINITION_NOTES=\u53d1\u5e03\u6d41\u7a0b\u5b9a\u4e49\n+QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n+QUERY_PROCCESS_DEFINITION_LIST_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\n+QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\n+QUERY_ALL_DEFINITION_LIST_NOTES=\u67e5\u8be2\u6240\u6709\u6d41\u7a0b\u5b9a\u4e49\n+PAGE_NO=\u9875\u7801\u53f7\n+PROCESS_INSTANCE_ID=\u6d41\u7a0b\u5b9e\u4f8bID\n+PROCESS_INSTANCE_IDS=\u6d41\u7a0b\u5b9e\u4f8bID\u96c6\u5408\n+PROCESS_INSTANCE_JSON=\u6d41\u7a0b\u5b9e\u4f8b\u4fe1\u606f(json\u683c\u5f0f)\n+SCHEDULE_TIME=\u5b9a\u65f6\u65f6\u95f4\n+SYNC_DEFINE=\u66f4\u65b0\u6d41\u7a0b\u5b9e\u4f8b\u7684\u4fe1\u606f\u662f\u5426\u540c\u6b65\u5230\u6d41\u7a0b\u5b9a\u4e49\n+RECOVERY_PROCESS_INSTANCE_FLAG=\u662f\u5426\u6062\u590d\u6d41\u7a0b\u5b9e\u4f8b\n+SEARCH_VAL=\u641c\u7d22\u503c\n+USER_ID=\u7528\u6237ID\n+PAGE_SIZE=\u9875\u5927\u5c0f\n+LIMIT=\u663e\u793a\u591a\u5c11\u6761\n+VIEW_TREE_NOTES=\u6811\u72b6\u56fe\n+GET_NODE_LIST_BY_DEFINITION_ID_NOTES=\u83b7\u5f97\u4efb\u52a1\u8282\u70b9\u5217\u8868\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n+PROCESS_DEFINITION_ID_LIST=\u6d41\u7a0b\u5b9a\u4e49id\u5217\u8868\n+QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u9879\u76eeID\n+BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=\u6279\u91cf\u5220\u9664\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\u96c6\u5408\n+DELETE_PROCESS_DEFINITION_BY_ID_NOTES=\u5220\u9664\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n+QUERY_PROCESS_INSTANCE_BY_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\n+DELETE_PROCESS_INSTANCE_BY_ID_NOTES=\u5220\u9664\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\n+TASK_ID=\u4efb\u52a1\u5b9e\u4f8bID\n+SKIP_LINE_NUM=\u5ffd\u7565\u884c\u6570\n+QUERY_TASK_INSTANCE_LOG_NOTES=\u67e5\u8be2\u4efb\u52a1\u5b9e\u4f8b\u65e5\u5fd7\n+DOWNLOAD_TASK_INSTANCE_LOG_NOTES=\u4e0b\u8f7d\u4efb\u52a1\u5b9e\u4f8b\u65e5\u5fd7\n+USERS_TAG=\u7528\u6237\u76f8\u5173\u64cd\u4f5c\n+SCHEDULER_TAG=\u5b9a\u65f6\u76f8\u5173\u64cd\u4f5c\n+CREATE_SCHEDULE_NOTES=\u521b\u5efa\u5b9a\u65f6\n+CREATE_USER_NOTES=\u521b\u5efa\u7528\u6237\n+TENANT_ID=\u79df\u6237ID\n+QUEUE=\u4f7f\u7528\u7684\u961f\u5217\n+EMAIL=\u90ae\u7bb1\n+PHONE=\u624b\u673a\u53f7\n+QUERY_USER_LIST_NOTES=\u67e5\u8be2\u7528\u6237\u5217\u8868\n+UPDATE_USER_NOTES=\u66f4\u65b0\u7528\u6237\n+DELETE_USER_BY_ID_NOTES=\u5220\u9664\u7528\u6237\u901a\u8fc7ID\n+GRANT_PROJECT_NOTES=\u6388\u6743\u9879\u76ee\n+PROJECT_IDS=\u9879\u76eeIDS(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u9879\u76ee\u4ee5\",\"\u5206\u5272)\n+GRANT_RESOURCE_NOTES=\u6388\u6743\u8d44\u6e90\u6587\u4ef6\n+RESOURCE_IDS=\u8d44\u6e90ID\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u8d44\u6e90ID\u4ee5\",\"\u5206\u5272)\n+GET_USER_INFO_NOTES=\u83b7\u53d6\u7528\u6237\u4fe1\u606f\n+LIST_USER_NOTES=\u7528\u6237\u5217\u8868\n+VERIFY_USER_NAME_NOTES=\u9a8c\u8bc1\u7528\u6237\u540d\n+UNAUTHORIZED_USER_NOTES=\u53d6\u6d88\u6388\u6743\n+ALERT_GROUP_ID=\u62a5\u8b66\u7ec4ID\n+AUTHORIZED_USER_NOTES=\u6388\u6743\u7528\u6237\n+GRANT_UDF_FUNC_NOTES=\u6388\u6743udf\u51fd\u6570\n+UDF_IDS=udf\u51fd\u6570id\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2audf\u51fd\u6570ID\u4ee5\",\"\u5206\u5272)\n+GRANT_DATASOURCE_NOTES=\u6388\u6743\u6570\u636e\u6e90\n+DATASOURCE_IDS=\u6570\u636e\u6e90ID\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u6570\u636e\u6e90ID\u4ee5\",\"\u5206\u5272)\n+QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=\u67e5\u8be2\u5b50\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u4efb\u52a1\u5b9e\u4f8bID\n+QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=\u67e5\u8be2\u7236\u6d41\u7a0b\u5b9e\u4f8b\u4fe1\u606f\u901a\u8fc7\u5b50\u6d41\u7a0b\u5b9e\u4f8bID\n+QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u5168\u5c40\u53d8\u91cf\u548c\u5c40\u90e8\u53d8\u91cf\n+VIEW_GANTT_NOTES=\u6d4f\u89c8Gantt\u56fe\n+SUB_PROCESS_INSTANCE_ID=\u5b50\u6d41\u7a0b\u662f\u54a7ID\n+TASK_NAME=\u4efb\u52a1\u5b9e\u4f8b\u540d\n+TASK_INSTANCE_TAG=\u4efb\u52a1\u5b9e\u4f8b\u76f8\u5173\u64cd\u4f5c\n+LOGGER_TAG=\u65e5\u5fd7\u76f8\u5173\u64cd\u4f5c\n+PROCESS_INSTANCE_TAG=\u6d41\u7a0b\u5b9e\u4f8b\u76f8\u5173\u64cd\u4f5c\n+EXECUTION_STATUS=\u5de5\u4f5c\u6d41\u548c\u4efb\u52a1\u8282\u70b9\u7684\u8fd0\u884c\u72b6\u6001\n+HOST=\u8fd0\u884c\u4efb\u52a1\u7684\u4e3b\u673aIP\u5730\u5740\n+START_DATE=\u5f00\u59cb\u65f6\u95f4\n+END_DATE=\u7ed3\u675f\u65f6\u95f4\n+QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\u67e5\u8be2\u4efb\u52a1\u5217\u8868\n+UPDATE_DATA_SOURCE_NOTES=\u66f4\u65b0\u6570\u636e\u6e90\n+DATA_SOURCE_ID=\u6570\u636e\u6e90ID\n+QUERY_DATA_SOURCE_NOTES=\u67e5\u8be2\u6570\u636e\u6e90\u901a\u8fc7ID\n+QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=\u67e5\u8be2\u6570\u636e\u6e90\u5217\u8868\u901a\u8fc7\u6570\u636e\u6e90\u7c7b\u578b\n+QUERY_DATA_SOURCE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u6570\u636e\u6e90\u5217\u8868\n+CONNECT_DATA_SOURCE_NOTES=\u8fde\u63a5\u6570\u636e\u6e90\n+CONNECT_DATA_SOURCE_TEST_NOTES=\u8fde\u63a5\u6570\u636e\u6e90\u6d4b\u8bd5\n+DELETE_DATA_SOURCE_NOTES=\u5220\u9664\u6570\u636e\u6e90\n+VERIFY_DATA_SOURCE_NOTES=\u9a8c\u8bc1\u6570\u636e\u6e90\n+UNAUTHORIZED_DATA_SOURCE_NOTES=\u672a\u6388\u6743\u7684\u6570\u636e\u6e90\n+AUTHORIZED_DATA_SOURCE_NOTES=\u6388\u6743\u7684\u6570\u636e\u6e90\n+DELETE_SCHEDULER_BY_ID_NOTES=\u6839\u636e\u5b9a\u65f6id\u5220\u9664\u5b9a\u65f6\u6570\u636e",
                "changes": 250
            },
            {
                "status": "added",
                "additions": 17,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/mail_templates/alert_mail_template.ftl",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/mail_templates/alert_mail_template.ftl?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/mail_templates/alert_mail_template.ftl",
                "deletions": 0,
                "sha": "c63860909065211ffc15cb230ba02b7ce4ff3b7c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/mail_templates/alert_mail_template.ftl",
                "patch": "@@ -0,0 +1,17 @@\n+<#--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+-->\n+<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'><html><head><title> dolphinscheduler</title><meta name='Keywords' content=''><meta name='Description' content=''><style type=\"text/css\">table {            margin-top:0px;            padding-top:0px;            border:1px solid;            font-size: 14px;            color: #333333;            border-width: 1px;            border-color: #666666;            border-collapse: collapse;        }        table th {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #dedede;        }        table td {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #ffffff;        }</style></head><body style=\"margin:0;padding:0\"><table border=\"1px\" cellpadding=\"5px\" cellspacing=\"-10px\"><thead><#if title??> ${title}</#if></thead><#if content??> ${content}</#if></table></body></html>\n\\ No newline at end of file",
                "changes": 17
            },
            {
                "status": "added",
                "additions": 38,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/master.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/master.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/master.properties",
                "deletions": 0,
                "sha": "73c29a2db223e2ba9e81cc0a83eaa6fb18e35729",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/master.properties",
                "patch": "@@ -0,0 +1,38 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# master execute thread num\n+master.exec.threads=100\n+\n+# master execute task number in parallel\n+master.exec.task.number=20\n+\n+# master heartbeat interval\n+master.heartbeat.interval=10\n+\n+# master commit task retry times\n+master.task.commit.retryTimes=5\n+\n+# master commit task interval\n+master.task.commit.interval=100\n+\n+\n+# only less than cpu avg load, master server can work. default value : the number of cpu cores * 2\n+#master.max.cpuload.avg=100\n+\n+# only larger than reserved memory, master server can work. default value : physical memory * 1/10, unit is G.\n+master.reserved.memory=0.1",
                "changes": 38
            },
            {
                "status": "added",
                "additions": 52,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/master_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/master_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/master_logback.xml",
                "deletions": 0,
                "sha": "12bcd658e141d90b01ede8ec3b31b74653a4269c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/master_logback.xml",
                "patch": "@@ -0,0 +1,52 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\"> <!--debug=\"true\" -->\n+\t<property name=\"log.base\" value=\"logs\" />\n+\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<appender name=\"MASTERLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+\t\t<file>${log.base}/dolphinscheduler-master.log</file>\n+\t\t<filter class=\"org.apache.dolphinscheduler.server.master.log.MasterLogFilter\">\n+\t\t\t<level>INFO</level>\n+\t\t</filter>\n+\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+\t\t\t<fileNamePattern>${log.base}/dolphinscheduler-master.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+\t\t\t<maxHistory>168</maxHistory>\n+\t\t\t<maxFileSize>200MB</maxFileSize>\n+\t\t</rollingPolicy>\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<root level=\"INFO\">\n+\t\t<appender-ref ref=\"MASTERLOGFILE\"/>\n+\t</root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 52
            },
            {
                "status": "added",
                "additions": 33,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml",
                "deletions": 0,
                "sha": "29c8dfa5a3583f5d943040bfeee7e20871af42ff",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml",
                "patch": "@@ -0,0 +1,33 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper\">\n+    <select id=\"selectAccessTokenPage\" resultType=\"org.apache.dolphinscheduler.dao.entity.AccessToken\">\n+        select * from t_ds_access_token t\n+        left join t_ds_user u on t.user_id = u.id\n+        where 1 = 1\n+        <if test=\"userName != null and userName != ''\">\n+            and u.user_name like concat ('%', #{userName}, '%')\n+        </if>\n+        <if test=\"userId != 0\">\n+            and t.user_id = #{userId}\n+        </if>\n+        order by t.update_time desc\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 33
            },
            {
                "status": "added",
                "additions": 47,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml",
                "deletions": 0,
                "sha": "8ee335b6ff3d9e94bfd3751fdefab99eae46e87f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml",
                "patch": "@@ -0,0 +1,47 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.AlertGroupMapper\">\n+    <select id=\"queryAlertGroupPage\" resultType=\"org.apache.dolphinscheduler.dao.entity.AlertGroup\">\n+        select * from t_ds_alertgroup\n+        where 1 = 1\n+        <if test=\"groupName != null and groupName != ''\">\n+            and group_name like concat('%', #{groupName}, '%')\n+        </if>\n+        order by update_time desc\n+    </select>\n+    <select id=\"queryByGroupName\" resultType=\"org.apache.dolphinscheduler.dao.entity.AlertGroup\">\n+        select * from t_ds_alertgroup\n+        where group_name=#{groupName}\n+    </select>\n+    <select id=\"queryByUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.AlertGroup\">\n+        select * from t_ds_alertgroup t\n+        left join t_ds_relation_user_alertgroup r on t.id=r.alertgroup_id\n+        where r.user_id=#{userId}\n+    </select>\n+    <select id=\"queryByAlertType\" resultType=\"org.apache.dolphinscheduler.dao.entity.AlertGroup\">\n+        select * from t_ds_alertgroup\n+        where group_type=#{alertType}\n+    </select>\n+    <select id=\"queryAllGroupList\" resultType=\"org.apache.dolphinscheduler.dao.entity.AlertGroup\">\n+        select *\n+        from t_ds_alertgroup\n+        order by update_time desc\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 47
            },
            {
                "status": "added",
                "additions": 26,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml",
                "deletions": 0,
                "sha": "703b6851570ae10ee2a5e22ad6df00f17c6b878a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml",
                "patch": "@@ -0,0 +1,26 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.AlertMapper\">\n+    <select id=\"listAlertByStatus\" resultType=\"org.apache.dolphinscheduler.dao.entity.Alert\">\n+        select *\n+        from t_ds_alert\n+        where alert_status = #{alertStatus}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 26
            },
            {
                "status": "added",
                "additions": 43,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml",
                "deletions": 0,
                "sha": "66e6c3edd377f84c48a116a43a4ffe0f16118aec",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml",
                "patch": "@@ -0,0 +1,43 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.CommandMapper\">\n+    <select id=\"getOneToRun\" resultType=\"org.apache.dolphinscheduler.dao.entity.Command\">\n+        select command.* from t_ds_command command\n+        join t_ds_process_definition definition on command.process_definition_id = definition.id\n+        where definition.release_state = 1 AND definition.flag = 1\n+        order by command.update_time asc\n+        limit 1\n+    </select>\n+    <select id=\"countCommandState\" resultType=\"org.apache.dolphinscheduler.dao.entity.CommandCount\">\n+        select cmd.command_type as command_type, count(1) as count\n+        from t_ds_command cmd, t_ds_process_definition process\n+        where cmd.process_definition_id = process.id\n+        <if test=\"projectIdArray != null and projectIdArray.length != 0\">\n+            and process.project_id in \n+            <foreach collection=\"projectIdArray\" index=\"index\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"startTime != null and endTime != null\">\n+            and cmd.start_time <![CDATA[ >= ]]> #{startTime} and cmd.update_time <![CDATA[ <= ]]> #{endTime}\n+        </if>\n+        group by cmd.command_type\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 43
            },
            {
                "status": "added",
                "additions": 79,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml",
                "deletions": 0,
                "sha": "b296d5fc3eb370ecc21f44b03a0f30c0f8dcb167",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml",
                "patch": "@@ -0,0 +1,79 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.DataSourceMapper\">\n+    <select id=\"queryDataSourceByType\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select *\n+        from t_ds_datasource\n+        where type=#{type}\n+        <if test=\"userId != 0\">\n+        and id in\n+          (select datasource_id\n+          from t_ds_relation_datasource_user\n+          where user_id=#{userId}\n+          union select id as datasource_id\n+                from t_ds_datasource\n+                where user_id=#{userId}\n+         )\n+        </if>\n+\n+    </select>\n+\n+    <select id=\"selectPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select *\n+        from t_ds_datasource\n+        where 1 =1\n+        <if test=\"userId != 0\">\n+         and id in\n+          (select datasource_id\n+            from t_ds_relation_datasource_user\n+            where user_id=#{userId}\n+            union select id as datasource_id\n+            from t_ds_datasource\n+            where user_id=#{userId}\n+            )\n+        </if>\n+        <if test=\"name != null and name != ''\">\n+             and name like concat ('%', #{name}, '%')\n+         </if>\n+         order by update_time desc\n+    </select>\n+    <select id=\"queryDataSourceByName\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select *\n+        from t_ds_datasource\n+        where name=#{name}\n+    </select>\n+    <select id=\"queryAuthedDatasource\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select datasource.*\n+        from t_ds_datasource datasource, t_ds_relation_datasource_user rel\n+        where datasource.id = rel.datasource_id AND rel.user_id = #{userId}\n+    </select>\n+    <select id=\"queryDatasourceExceptUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select *\n+        from t_ds_datasource\n+        where user_id <![CDATA[ <> ]]> #{userId}\n+    </select>\n+    <select id=\"listAllDataSourceByType\" resultType=\"org.apache.dolphinscheduler.dao.entity.DataSource\">\n+        select *\n+        from t_ds_datasource\n+        where type = #{type}\n+    </select>\n+\n+\n+</mapper>\n\\ No newline at end of file",
                "changes": 79
            },
            {
                "status": "added",
                "additions": 30,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml",
                "deletions": 0,
                "sha": "a43cbeca91f5f2c88660216cff9c2867fe66b26d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml",
                "patch": "@@ -0,0 +1,30 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.DataSourceUserMapper\">\n+    <delete id=\"deleteByUserId\">\n+        delete from t_ds_relation_datasource_user\n+        where user_id = #{userId}\n+\n+    </delete>\n+    <delete id=\"deleteByDatasourceId\">\n+        delete from t_ds_relation_datasource_user\n+        where datasource_id = #{datasourceId}\n+    </delete>\n+</mapper>\n\\ No newline at end of file",
                "changes": 30
            },
            {
                "status": "added",
                "additions": 36,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml",
                "deletions": 0,
                "sha": "2f5ae7104ae85156d2f874b3693cd8c7b1feb0e8",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml",
                "patch": "@@ -0,0 +1,36 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ErrorCommandMapper\">\n+    <select id=\"countCommandState\" resultType=\"org.apache.dolphinscheduler.dao.entity.CommandCount\">\n+        select cmd.command_type as command_type, count(1) as count\n+        from t_ds_error_command cmd, t_ds_process_definition process\n+        where cmd.process_definition_id = process.id\n+        <if test=\"projectIdArray != null and projectIdArray.length != 0\">\n+            and process.project_id in\n+            <foreach collection=\"projectIdArray\" index=\"index\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"startTime != null and endTime != null\">\n+            and cmd.startTime <![CDATA[ >= ]]> #{startTime} and cmd.update_time <![CDATA[ <= ]]> #{endTime}\n+        </if>\n+        group by cmd.command_type\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 36
            },
            {
                "status": "added",
                "additions": 96,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml",
                "deletions": 0,
                "sha": "1b97c07676114ce59d90e1f7352553cba97c552d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml",
                "patch": "@@ -0,0 +1,96 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ProcessDefinitionMapper\">\n+    <select id=\"queryByDefineName\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        select pd.*,u.user_name,p.name as project_name,t.tenant_code,t.tenant_name,q.queue,q.queue_name\n+        from t_ds_process_definition pd\n+        JOIN t_ds_user u ON pd.user_id = u.id\n+        JOIN  t_ds_project p ON pd.project_id = p.id\n+        JOIN  t_ds_tenant t ON t.id = u.tenant_id\n+        JOIN t_ds_queue q ON t.queue_id = q.id\n+        WHERE p.id = #{projectId}\n+        and pd.name = #{processDefinitionName}\n+    </select>\n+    <select id=\"queryDefineListPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        SELECT td.*,sc.schedule_release_state,tu.user_name\n+        FROM t_ds_process_definition td\n+        left join (select process_definition_id,release_state as schedule_release_state from t_ds_schedules group by process_definition_id,release_state) sc on sc.process_definition_id = td.id\n+        left join t_ds_user tu on  td.user_id = tu.id\n+        where td.project_id = #{projectId}\n+        <if test=\" isAdmin == false \">\n+            and tu.user_type=1\n+        </if>\n+        <if test=\" searchVal != null and searchVal != ''\">\n+            and td.name like concat('%', #{searchVal}, '%')\n+        </if>\n+        <if test=\" userId != 0\">\n+            and td.user_id = #{userId}\n+        </if>\n+        order by sc.schedule_release_state desc,td.update_time desc\n+    </select>\n+\n+    <select id=\"queryAllDefinitionList\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        select *\n+        from t_ds_process_definition\n+        where project_id = #{projectId}\n+        order by create_time desc\n+    </select>\n+    <select id=\"queryDefinitionListByTenant\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        select *\n+        from t_ds_process_definition\n+        where tenant_id = #{tenantId}\n+    </select>\n+    <select id=\"queryDefinitionListByIdList\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        select *\n+        from t_ds_process_definition\n+        where id in\n+        <foreach collection=\"ids\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+            #{i}\n+        </foreach>\n+    </select>\n+    <select id=\"countDefinitionGroupByUser\" resultType=\"org.apache.dolphinscheduler.dao.entity.DefinitionGroupByUser\">\n+        SELECT td.user_id as user_id, tu.user_name as user_name, count(0) as count\n+        FROM t_ds_process_definition td\n+        JOIN t_ds_user tu on tu.id=td.user_id\n+        where 1 = 1\n+        <if test=\" isAdmin == false \">\n+            and tu.user_type=1\n+        </if>\n+        <if test=\"projectIds != null and projectIds.length != 0\">\n+            and td.project_id in\n+            <foreach collection=\"projectIds\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        group by td.user_id,tu.user_name\n+    </select>\n+    <select id=\"queryByDefineId\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessDefinition\">\n+        SELECT\n+            pd.*, u.user_name,\n+            p.name AS project_name\n+        FROM\n+            t_ds_process_definition pd,\n+            t_ds_user u,\n+            t_ds_project p\n+        WHERE\n+            pd.user_id = u.id AND pd.project_id = p.id\n+        AND pd.id = #{processDefineId}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 96
            },
            {
                "status": "added",
                "additions": 43,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml",
                "deletions": 0,
                "sha": "d217665eab7a9ad17e476ecc6cc98214ce4d6c93",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml",
                "patch": "@@ -0,0 +1,43 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapMapper\">\n+    <delete id=\"deleteByParentProcessId\">\n+        delete\n+        from t_ds_relation_process_instance\n+        where parent_process_instance_id=#{parentProcessId}\n+\n+    </delete>\n+    <select id=\"queryByParentId\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstanceMap\">\n+        select *\n+        from t_ds_relation_process_instance\n+        where parent_process_instance_id = #{parentProcessId}\n+        and parent_task_instance_id = #{parentTaskId}\n+    </select>\n+    <select id=\"queryBySubProcessId\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstanceMap\">\n+        select *\n+        from t_ds_relation_process_instance\n+        where process_instance_id = #{subProcessId}\n+    </select>\n+    <select id=\"querySubIdListByParentId\" resultType=\"java.lang.Integer\">\n+        select process_instance_id\n+        from t_ds_relation_process_instance\n+        where parent_process_instance_id = #{parentInstanceId}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 43
            },
            {
                "status": "added",
                "additions": 182,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml",
                "deletions": 0,
                "sha": "2e63867d3346b0a81d6fe0fb8246d28c31866eba",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml",
                "patch": "@@ -0,0 +1,182 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapper\">\n+    <select id=\"queryDetailById\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select inst.*\n+        from t_ds_process_instance inst\n+        where inst.id = #{processId}\n+    </select>\n+    <select id=\"queryByHostAndStatus\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where 1=1\n+        <if test=\"host != null and host != ''\">\n+            and host=#{host}\n+        </if>\n+        and state in\n+        <foreach collection=\"states\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+            #{i}\n+        </foreach>\n+        order by id asc\n+    </select>\n+\n+    <select id=\"queryByTenantIdAndStatus\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where 1=1\n+        <if test=\"tenantId != -1\">\n+            and tenant_id =#{tenantId}\n+        </if>\n+        and state in\n+        <foreach collection=\"states\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+            #{i}\n+        </foreach>\n+        order by id asc\n+    </select>\n+\n+    <select id=\"queryByWorkerGroupIdAndStatus\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where 1=1\n+        <if test=\"workerGroupId != -1\">\n+            and worker_group_id =#{workerGroupId}\n+        </if>\n+        and state in\n+        <foreach collection=\"states\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+            #{i}\n+        </foreach>\n+        order by id asc\n+    </select>\n+\n+    <select id=\"queryProcessInstanceListPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select instance.*\n+        from t_ds_process_instance instance\n+        join t_ds_process_definition define ON instance.process_definition_id = define.id\n+        where 1=1\n+        and instance.is_sub_process=0\n+        and define.project_id = #{projectId}\n+        <if test=\"processDefinitionId != 0\">\n+            and instance.process_definition_id = #{processDefinitionId}\n+        </if>\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and  instance.name like concat('%', #{searchVal}, '%')\n+        </if>\n+        <if test=\"startTime != null \">\n+            and instance.start_time > #{startTime} and instance.start_time <![CDATA[ <=]]> #{endTime}\n+        </if>\n+        <if test=\"states != null and states != ''\">\n+            and instance.state in\n+            <foreach collection=\"states\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"host != null and host != ''\">\n+            and instance.host like concat('%', #{host}, '%')\n+        </if>\n+        order by instance.start_time desc\n+    </select>\n+    <update id=\"setFailoverByHostAndStateArray\">\n+        update t_ds_process_instance\n+        set host=null\n+        where host =#{host} and state in\n+        <foreach collection=\"states\" index=\"index\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+            #{i}\n+        </foreach>\n+    </update>\n+    <update id=\"updateProcessInstanceByState\">\n+        update t_ds_process_instance\n+        set state = #{destState}\n+        where state = #{originState}\n+    </update>\n+\n+    <update id=\"updateProcessInstanceByTenantId\">\n+        update t_ds_process_instance\n+        set tenant_id = #{destTenantId}\n+        where tenant_id = #{originTenantId}\n+    </update>\n+\n+    <update id=\"updateProcessInstanceByWorkerGroupId\">\n+        update t_ds_process_instance\n+        set worker_group_id = #{destWorkerGroupId}\n+        where worker_group_id = #{originWorkerGroupId}\n+    </update>\n+\n+    <select id=\"countInstanceStateByUser\" resultType=\"org.apache.dolphinscheduler.dao.entity.ExecuteStatusCount\">\n+        select t.state, count(0) as count\n+        from t_ds_process_instance t\n+        join t_ds_process_definition d on d.id=t.process_definition_id\n+        join t_ds_project p on p.id=d.project_id\n+        where 1 = 1\n+        and t.is_sub_process = 0\n+        <if test=\"startTime != null and endTime != null\">\n+            and  t.start_time >= #{startTime} and t.start_time <![CDATA[ <= ]]> #{endTime}\n+        </if>\n+        <if test=\"projectIds != null and projectIds.length != 0\">\n+            and p.id in\n+            <foreach collection=\"projectIds\" index=\"index\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        group by t.state\n+    </select>\n+    <select id=\"queryByProcessDefineId\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where process_definition_id=#{processDefinitionId}\n+        order by start_time desc limit #{size}\n+    </select>\n+    <select id=\"queryLastSchedulerProcess\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where process_definition_id=#{processDefinitionId}\n+        <if test=\"startTime!=null and endTime != null \">\n+            and schedule_time between #{startTime} and #{endTime}\n+        </if>\n+        order by end_time desc limit 1\n+    </select>\n+    <select id=\"queryLastRunningProcess\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where 1=1\n+        <if test=\"states !=null and states.length != 0\">\n+            and state in\n+            <foreach collection=\"states\" item=\"i\" index=\"index\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"startTime!=null and endTime != null \">\n+            and process_definition_id=#{processDefinitionId}\n+            and (schedule_time between #{startTime} and #{endTime} or start_time between #{startTime} and #{endTime})\n+        </if>\n+        order by start_time desc limit 1\n+    </select>\n+    <select id=\"queryLastManualProcess\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProcessInstance\">\n+        select *\n+        from t_ds_process_instance\n+        where process_definition_id=#{processDefinitionId}\n+        and schedule_time is null\n+        <if test=\"startTime!=null and endTime != null \">\n+            and start_time between #{startTime} and #{endTime}\n+        </if>\n+        order by end_time desc limit 1\n+    </select>\n+\n+\n+</mapper>\n\\ No newline at end of file",
                "changes": 182
            },
            {
                "status": "added",
                "additions": 68,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml",
                "deletions": 0,
                "sha": "5ab0756250fe3ad324754b26f76f68ecee043881",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml",
                "patch": "@@ -0,0 +1,68 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ProjectMapper\">\n+    <select id=\"queryDetailById\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select p.*,u.user_name as user_name\n+        from t_ds_project p\n+        join t_ds_user u on p.user_id = u.id\n+        where p.id = #{projectId}\n+    </select>\n+    <select id=\"queryByName\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select p.*,u.user_name as user_name\n+        from t_ds_project p\n+        join t_ds_user u on p.user_id = u.id\n+        where p.name = #{projectName}\n+        limit 1\n+    </select>\n+    <select id=\"queryProjectListPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select p.*,u.user_name as user_name,\n+        (SELECT COUNT(*) FROM t_ds_process_definition AS def WHERE def.project_id = p.id) AS def_count,\n+        (SELECT COUNT(*) FROM t_ds_process_definition def, t_ds_process_instance inst WHERE def.id = inst.process_definition_id AND def.project_id = p.id AND inst.state=1 ) as inst_running_count\n+        from t_ds_project p\n+        join t_ds_user u on u.id=p.user_id\n+        where 1=1\n+        <if test=\"userId != 0\">\n+            and p.id in\n+            (select project_id from t_ds_relation_project_user  where user_id=#{userId}\n+            union select id as project_id  from t_ds_project where user_id=#{userId}\n+            )\n+        </if>\n+        <if test=\"searchName!=null and searchName != ''\">\n+            and p.name like concat('%', #{searchName}, '%')\n+        </if>\n+        order by p.create_time desc\n+    </select>\n+    <select id=\"queryAuthedProjectListByUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select p.*\n+        from t_ds_project p,t_ds_relation_project_user rel\n+        where p.id = rel.project_id and rel.user_id= #{userId}\n+    </select>\n+    <select id=\"queryProjectExceptUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select *\n+        from t_ds_project\n+        where user_id <![CDATA[ <> ]]> #{userId}\n+    </select>\n+    <select id=\"queryProjectCreatedByUser\" resultType=\"org.apache.dolphinscheduler.dao.entity.Project\">\n+        select *\n+        from t_ds_project\n+        where user_id = #{userId}\n+    </select>\n+\n+</mapper>\n\\ No newline at end of file",
                "changes": 68
            },
            {
                "status": "added",
                "additions": 36,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml",
                "deletions": 0,
                "sha": "006cf080eb083bf56beba9ecc75c6b8ca6e09030",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml",
                "patch": "@@ -0,0 +1,36 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ProjectUserMapper\">\n+    <delete id=\"deleteProjectRelation\">\n+        delete from t_ds_relation_project_user\n+        where 1=1\n+        and user_id = #{userId}\n+        <if test=\"projectId != 0 \">\n+            and project_id = #{projectId}\n+        </if>\n+    </delete>\n+    <select id=\"queryProjectRelation\" resultType=\"org.apache.dolphinscheduler.dao.entity.ProjectUser\">\n+      select *\n+      from t_ds_relation_project_user\n+      where project_id = #{projectId}\n+      and user_id = #{userId}\n+      limit 1\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 36
            },
            {
                "status": "added",
                "additions": 42,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml",
                "deletions": 0,
                "sha": "423b0dd04d480071bddb1d0e7aafc292be89b926",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml",
                "patch": "@@ -0,0 +1,42 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.QueueMapper\">\n+    <select id=\"queryQueuePaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.Queue\">\n+        select *\n+        from t_ds_queue\n+        where  1= 1\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and queue_name like concat('%', #{searchVal}, '%')\n+        </if>\n+        order by  update_time desc\n+    </select>\n+    <select id=\"queryAllQueueList\" resultType=\"org.apache.dolphinscheduler.dao.entity.Queue\">\n+        select *\n+        from t_ds_queue\n+        where  1=1\n+        <if test=\"queue != null and queue != ''\">\n+            and queue = #{queue}\n+        </if>\n+        <if test=\"queueName != null and queueName != ''\">\n+            and queue_name =#{queueName}\n+        </if>\n+    </select>\n+\n+</mapper>\n\\ No newline at end of file",
                "changes": 42
            },
            {
                "status": "added",
                "additions": 74,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml",
                "deletions": 0,
                "sha": "146daa0632b52e654ec84a05a34f45abb6aeddf0",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml",
                "patch": "@@ -0,0 +1,74 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ResourceMapper\">\n+    <select id=\"queryResourceList\" resultType=\"org.apache.dolphinscheduler.dao.entity.Resource\">\n+        select *\n+        from t_ds_resources\n+        where 1= 1\n+        <if test=\"alias != null and alias != ''\">\n+            and alias = #{alias}\n+        </if>\n+        <if test=\"type != -1\">\n+            and type = #{type}\n+        </if>\n+        <if test=\"userId != 0\">\n+            and user_id = #{userId}\n+        </if>\n+    </select>\n+    <select id=\"queryResourceListAuthored\" resultType=\"org.apache.dolphinscheduler.dao.entity.Resource\">\n+        select *\n+        from t_ds_resources\n+        where 1 = 1\n+        <if test=\"type != -1\">\n+            and type=#{type}\n+        </if>\n+        and id in (select resources_id from  t_ds_relation_resources_user where user_id=#{userId}\n+                  union select id as resources_id  from t_ds_resources where user_id=#{userId})\n+    </select>\n+    <select id=\"queryResourcePaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.Resource\">\n+        select *\n+        from t_ds_resources\n+        where type=#{type}\n+        <if test=\"userId != 0\">\n+            and id in (select resources_id from  t_ds_relation_resources_user where user_id=#{userId}\n+            union select id as resources_id  from t_ds_resources where user_id=#{userId})\n+        </if>\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and  alias like concat('%', #{searchVal}, '%')\n+        </if>\n+        order by update_time desc\n+    </select>\n+    <select id=\"queryAuthorizedResourceList\" resultType=\"org.apache.dolphinscheduler.dao.entity.Resource\">\n+        select r.*\n+        from  t_ds_resources r,t_ds_relation_resources_user rel\n+        where r.id = rel.resources_id AND rel.user_id = #{userId}\n+    </select>\n+    <select id=\"queryResourceExceptUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.Resource\">\n+        select *\n+        from  t_ds_resources\n+        where user_id <![CDATA[ <> ]]> #{userId}\n+    </select>\n+    <select id=\"queryTenantCodeByResourceName\" resultType=\"java.lang.String\">\n+        select tenant_code\n+        from t_ds_tenant t, t_ds_user u, t_ds_resources res\n+        where t.id = u.tenant_id and u.id = res.user_id and res.type=0\n+        and res.alias= #{resName}\n+    </select>\n+</mapper>",
                "changes": 74
            },
            {
                "status": "added",
                "additions": 32,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml",
                "deletions": 0,
                "sha": "6a89e47c2f86bc1a7797110b0d8ed93beb415e53",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml",
                "patch": "@@ -0,0 +1,32 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ResourceUserMapper\">\n+    <delete id=\"deleteResourceUser\">\n+        delete\n+        from t_ds_relation_resources_user\n+        where 1 = 1\n+        <if test=\"userId != 0\">\n+            and user_id = #{userId}\n+        </if>\n+        <if test=\"resourceId != 0\">\n+            and resources_id = #{resourceId}\n+        </if>\n+    </delete>\n+</mapper>\n\\ No newline at end of file",
                "changes": 32
            },
            {
                "status": "added",
                "additions": 58,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml",
                "deletions": 0,
                "sha": "402c8642517163c2a5d7a010b72e5a4115aa7e9c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml",
                "patch": "@@ -0,0 +1,58 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.ScheduleMapper\">\n+    <select id=\"queryByProcessDefineIdPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.Schedule\">\n+        select p_f.name as process_definition_name, p.name as project_name,u.user_name,s.*\n+        from t_ds_schedules s\n+        join t_ds_process_definition p_f on s.process_definition_id = p_f.id\n+        join t_ds_project as p on p_f.project_id = p.id\n+        join t_ds_user as u on s.user_id = u.id\n+        where 1=1\n+        <if test=\"processDefinitionId!= 0\">\n+            and s.process_definition_id = #{processDefinitionId}\n+        </if>\n+        order by s.update_time desc\n+    </select>\n+    <select id=\"querySchedulerListByProjectName\" resultType=\"org.apache.dolphinscheduler.dao.entity.Schedule\">\n+        select p_f.name as process_definition_name, p_f.description as definition_description, p.name as project_name,u.user_name,s.*\n+        from t_ds_schedules s\n+        join t_ds_process_definition p_f on s.process_definition_id = p_f.id\n+        join t_ds_project as p on p_f.project_id = p.id\n+        join t_ds_user as u on s.user_id = u.id\n+        where p.name = #{projectName}\n+    </select>\n+    <select id=\"selectAllByProcessDefineArray\" resultType=\"org.apache.dolphinscheduler.dao.entity.Schedule\">\n+        select *\n+        from t_ds_schedules\n+        where  1= 1\n+        <if test=\"processDefineIds != null and processDefineIds.length != 0 \">\n+            and process_definition_id in\n+            <foreach collection=\"processDefineIds\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        and release_state = 1\n+    </select>\n+    <select id=\"queryByProcessDefinitionId\" resultType=\"org.apache.dolphinscheduler.dao.entity.Schedule\">\n+        select *\n+        from t_ds_schedules\n+        where process_definition_id =#{processDefinitionId}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 58
            },
            {
                "status": "added",
                "additions": 32,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml",
                "deletions": 0,
                "sha": "4fa7f309dc0a5c8fe71319f4ee7a906fc46052f9",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml",
                "patch": "@@ -0,0 +1,32 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.SessionMapper\">\n+    <select id=\"queryByUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.Session\">\n+        select *\n+        from t_ds_session\n+        where user_id = #{userId}\n+    </select>\n+\n+    <select id=\"queryByUserIdAndIp\" resultType=\"org.apache.dolphinscheduler.dao.entity.Session\">\n+        select *\n+        from t_ds_session\n+        where user_id = #{userId} AND ip = #{ip}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 32
            },
            {
                "status": "added",
                "additions": 129,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml",
                "deletions": 0,
                "sha": "3a1fddd2885a04bbfe2cab66f6c09086bd36858d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml",
                "patch": "@@ -0,0 +1,129 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper\">\n+    <update id=\"setFailoverByHostAndStateArray\">\n+        update t_ds_task_instance\n+        set state = #{destStatus}\n+        where host = #{host}\n+        and state in\n+        <foreach collection=\"states\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+            #{i}\n+        </foreach>\n+    </update>\n+    <select id=\"queryTaskByProcessIdAndState\" resultType=\"java.lang.Integer\">\n+        select id\n+        from t_ds_task_instance\n+        WHERE  process_instance_id = #{processInstanceId}\n+        and state = #{state}\n+        and flag = 1\n+    </select>\n+    <select id=\"findValidTaskListByProcessId\" resultType=\"org.apache.dolphinscheduler.dao.entity.TaskInstance\">\n+        select *\n+        from t_ds_task_instance\n+        WHERE  process_instance_id = #{processInstanceId}\n+        and flag = #{flag}\n+        order by start_time desc\n+    </select>\n+    <select id=\"queryByHostAndStatus\" resultType=\"org.apache.dolphinscheduler.dao.entity.TaskInstance\">\n+        select *\n+        from t_ds_task_instance\n+        where 1 = 1\n+        <if test=\"host != null and host != ''\">\n+            and host = #{host}\n+        </if>\n+        <if test=\"states != null and states.length != 0\">\n+            and state in\n+            <foreach collection=\"states\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+    </select>\n+    <select id=\"countTaskInstanceStateByUser\" resultType=\"org.apache.dolphinscheduler.dao.entity.ExecuteStatusCount\">\n+        select  state, count(0) as count\n+        from t_ds_task_instance t\n+        left join t_ds_process_definition  d on d.id=t.process_definition_id\n+        left join t_ds_project p on p.id=d.project_id\n+        where 1=1\n+        <if test=\"projectIds != null and projectIds.length != 0\">\n+            and d.project_id in\n+            <foreach collection=\"projectIds\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"startTime != null and endTime != null\">\n+            and t.start_time > #{startTime} and t.start_time <![CDATA[ <= ]]> #{endTime}\n+        </if>\n+        group by t.state\n+    </select>\n+    <select id=\"queryByInstanceIdAndName\" resultType=\"org.apache.dolphinscheduler.dao.entity.TaskInstance\">\n+        select  *\n+        from t_ds_task_instance\n+        where process_instance_id = #{processInstanceId}\n+        and name = #{name}\n+        and flag = 1\n+        limit 1\n+    </select>\n+    <select id=\"countTask\" resultType=\"java.lang.Integer\">\n+        select count(1) as count\n+        from t_ds_task_instance task,t_ds_process_definition process\n+        where task.process_definition_id=process.id\n+        <if test=\"projectIds != null and projectIds.length != 0\">\n+            and process.project_id in\n+            <foreach collection=\"projectIds\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"taskIds != null and taskIds.length != 0\">\n+            and task.id in\n+            <foreach collection=\"taskIds\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+    </select>\n+    <select id=\"queryTaskInstanceListPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.TaskInstance\">\n+        select instance.*,process.name as process_instance_name\n+        from t_ds_task_instance instance\n+        join t_ds_process_definition define ON instance.process_definition_id = define.id\n+        join  t_ds_process_instance process on process.id=instance.process_instance_id\n+        where define.project_id = #{projectId}\n+        <if test=\"startTime != null\">\n+            and instance.start_time > #{startTime} and instance.start_time <![CDATA[ <=]]> #{endTime}\n+        </if>\n+        <if test=\"processInstanceId != 0\">\n+            and instance.process_instance_id = #{processInstanceId}\n+        </if>\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and  instance.name like concat('%', #{searchVal}, '%')\n+        </if>\n+        <if test=\"taskName != null and taskName != ''\">\n+            and instance.name=#{taskName}\n+        </if>\n+        <if test=\"states != null and states.length != 0\">\n+            and instance.state in \n+            <foreach collection=\"states\" index=\"index\" item=\"i\" open=\"(\" separator=\",\" close=\")\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"host != null and host != ''\">\n+            and instance.host like concat('%', #{host}, '%')\n+        </if>\n+        order by instance.start_time desc\n+    </select>\n+</mapper>",
                "changes": 129
            },
            {
                "status": "added",
                "additions": 41,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml",
                "deletions": 0,
                "sha": "fc9219ce869fdc29e003f16c5841ecee402999f1",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml",
                "patch": "@@ -0,0 +1,41 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.TenantMapper\">\n+    <select id=\"queryById\" resultType=\"org.apache.dolphinscheduler.dao.entity.Tenant\">\n+            SELECT t.*,q.queue_name,q.queue\n+            FROM t_ds_tenant t,t_ds_queue q\n+            WHERE t.queue_id = q.id\n+            and t.id = #{tenantId}\n+    </select>\n+    <select id=\"queryByTenantCode\" resultType=\"org.apache.dolphinscheduler.dao.entity.Tenant\">\n+      select *\n+      from t_ds_tenant\n+      where tenant_code = #{tenantCode}\n+    </select>\n+    <select id=\"queryTenantPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.Tenant\">\n+        SELECT t.*,q.queue_name\n+        FROM t_ds_tenant t,t_ds_queue q\n+        WHERE t.queue_id = q.id\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and  t.tenant_name like concat('%', #{searchVal}, '%')\n+        </if>\n+        order by  t.update_time desc\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 41
            },
            {
                "status": "added",
                "additions": 29,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml",
                "deletions": 0,
                "sha": "61b4e2c3727ebffff9215a6eda1d8c622b21abde",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml",
                "patch": "@@ -0,0 +1,29 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.UDFUserMapper\">\n+    <delete id=\"deleteByUserId\">\n+        delete from t_ds_relation_udfs_user\n+        where user_id = #{userId}\n+    </delete>\n+    <delete id=\"deleteByUdfFuncId\">\n+        delete from t_ds_relation_udfs_user\n+        where udf_id = #{udfFuncId}\n+    </delete>\n+</mapper>\n\\ No newline at end of file",
                "changes": 29
            },
            {
                "status": "added",
                "additions": 71,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml",
                "deletions": 0,
                "sha": "04926d132e7ee30e813c578daaf8b691473f3a4e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml",
                "patch": "@@ -0,0 +1,71 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.UdfFuncMapper\">\n+    <select id=\"queryUdfByIdStr\" resultType=\"org.apache.dolphinscheduler.dao.entity.UdfFunc\">\n+        select *\n+        from t_ds_udfs\n+        where 1 = 1\n+        <if test=\"ids != null and ids != ''\">\n+            and id in\n+            <foreach collection=\"ids\" item=\"i\" open=\"(\" close=\")\" separator=\",\">\n+                #{i}\n+            </foreach>\n+        </if>\n+        <if test=\"funcNames != null and funcNames != ''\">\n+            and func_name = #{funcNames}\n+        </if>\n+        order by id asc\n+    </select>\n+    <select id=\"queryUdfFuncPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.UdfFunc\">\n+        select *\n+        from t_ds_udfs\n+        where 1=1\n+        <if test=\"searchVal!= null and searchVal != ''\">\n+            and func_name like concat('%', #{searchVal}, '%')\n+        </if>\n+        <if test=\"userId != 0\">\n+            and id in (\n+              select udf_id from t_ds_relation_udfs_user where user_id=#{userId}\n+              union select id as udf_id  from t_ds_udfs where user_id=#{userId})\n+        </if>\n+        order by create_time desc\n+    </select>\n+    <select id=\"getUdfFuncByType\" resultType=\"org.apache.dolphinscheduler.dao.entity.UdfFunc\">\n+        select *\n+        from t_ds_udfs\n+        where type=#{type}\n+        <if test=\"userId != 0\">\n+            and id in (\n+            select udf_id from t_ds_relation_udfs_user where user_id=#{userId}\n+            union select id as udf_id  from t_ds_udfs where user_id=#{userId})\n+        </if>\n+    </select>\n+    <select id=\"queryUdfFuncExceptUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.UdfFunc\">\n+        select *\n+        from t_ds_udfs\n+        where user_id <![CDATA[ <> ]]> #{userId}\n+    </select>\n+    <select id=\"queryAuthedUdfFunc\" resultType=\"org.apache.dolphinscheduler.dao.entity.UdfFunc\">\n+        SELECT u.*\n+        from t_ds_udfs u,t_ds_relation_udfs_user rel\n+        WHERE u.id = rel.udf_id\n+        AND rel.user_id = #{userId}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 71
            },
            {
                "status": "added",
                "additions": 31,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml",
                "deletions": 0,
                "sha": "cbb448275cec5bfdda7fbe4fb1735773c8e90644",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml",
                "patch": "@@ -0,0 +1,31 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.UserAlertGroupMapper\">\n+    <delete id=\"deleteByAlertgroupId\">\n+        delete from t_ds_relation_user_alertgroup\n+        where alertgroup_id = #{alertgroupId}\n+    </delete>\n+    <select id=\"listUserByAlertgroupId\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+           SELECT u.*\n+           FROM t_ds_relation_user_alertgroup g_u\n+           JOIN t_ds_user u on g_u.user_id = u.id\n+           WHERE g_u.alertgroup_id = #{alertgroupId}\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 31
            },
            {
                "status": "added",
                "additions": 72,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml",
                "deletions": 0,
                "sha": "6046ad22ebe0d519bebea707acf81e700acb9c0b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml",
                "patch": "@@ -0,0 +1,72 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.UserMapper\">\n+    <select id=\"queryAllGeneralUser\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select * from t_ds_user\n+        where user_type=1;\n+    </select>\n+    <select id=\"queryByUserNameAccurately\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select * from t_ds_user\n+        where user_name=#{userName}\n+    </select>\n+    <select id=\"queryUserByNamePassword\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select * from t_ds_user\n+        where user_name=#{userName} and user_password = #{password}\n+    </select>\n+    <select id=\"queryUserPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select u.id,u.user_name,u.user_password,u.user_type,u.email,u.phone,u.tenant_id,u.create_time,\n+        u.update_time,t.tenant_name,\n+        case when u.queue  <![CDATA[ <> ]]> '' then u.queue else q.queue_name end as queue, q.queue_name\n+        from t_ds_user u\n+        left join t_ds_tenant t on u.tenant_id=t.id\n+        left join t_ds_queue q on t.queue_id = q.id\n+        where 1=1\n+        <if test=\"userName!=null and userName != ''\" >\n+             and u.user_name like concat ('%', #{userName}, '%')\n+        </if>\n+        order by u.update_time desc\n+    </select>\n+    <select id=\"queryDetailsById\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select u.*, t.tenant_name,\n+        case when u.queue <![CDATA[ <> ]]>  '' then u.queue else q.queue_name end as queue_name\n+        from t_ds_user u,t_ds_tenant t,t_ds_queue q\n+        WHERE u.tenant_id = t.id and t.queue_id = q.id and u.id = #{userId}\n+    </select>\n+    <select id=\"queryUserListByAlertGroupId\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+      select u.*\n+      from t_ds_user u, t_ds_relation_user_alertgroup rel\n+      where u.id = rel.user_id AND rel.alertgroup_id = #{alertgroupId}\n+    </select>\n+    <select id=\"queryUserListByTenant\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+      select *\n+      from t_ds_user\n+      where tenant_id = #{tenantId}\n+    </select>\n+    <select id=\"queryTenantCodeByUserId\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        SELECT  u.*,t.tenant_code\n+        FROM  t_ds_user u, t_ds_tenant t\n+        WHERE u.tenant_id = t.id AND u.id = #{userId}\n+    </select>\n+    <select id=\"queryUserByToken\" resultType=\"org.apache.dolphinscheduler.dao.entity.User\">\n+        select u.*\n+        from t_ds_user u ,t_ds_access_token t\n+        where u.id = t.user_id and token=#{token} and t.expire_time > NOW()\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 72
            },
            {
                "status": "added",
                "additions": 40,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml",
                "deletions": 0,
                "sha": "84dd4db88d77b4b4d63cc39ef9fc3ee9c3da1372",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml",
                "patch": "@@ -0,0 +1,40 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n+<mapper namespace=\"org.apache.dolphinscheduler.dao.mapper.WorkerGroupMapper\">\n+    <select id=\"queryAllWorkerGroup\" resultType=\"org.apache.dolphinscheduler.dao.entity.WorkerGroup\">\n+        select *\n+        from t_ds_worker_group\n+        order by update_time desc\n+    </select>\n+    <select id=\"queryWorkerGroupByName\" resultType=\"org.apache.dolphinscheduler.dao.entity.WorkerGroup\">\n+        select *\n+        from t_ds_worker_group\n+        where name = #{name}\n+    </select>\n+    <select id=\"queryListPaging\" resultType=\"org.apache.dolphinscheduler.dao.entity.WorkerGroup\">\n+        select *\n+        from t_ds_worker_group\n+        where 1 = 1\n+        <if test=\"searchVal != null and searchVal != ''\">\n+            and  name like concat('%', #{searchVal}, '%')\n+        </if>\n+        order by  update_time desc\n+    </select>\n+</mapper>\n\\ No newline at end of file",
                "changes": 40
            },
            {
                "status": "added",
                "additions": 56,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/quartz.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/quartz.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/quartz.properties",
                "deletions": 0,
                "sha": "21ebd5e29d3eb5c0a075723a6ead66babb3a4d95",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/quartz.properties",
                "patch": "@@ -0,0 +1,56 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+#============================================================================\n+# Configure Main Scheduler Properties\n+#============================================================================\n+org.quartz.scheduler.instanceName = DolphinScheduler\n+org.quartz.scheduler.instanceId = AUTO\n+org.quartz.scheduler.makeSchedulerThreadDaemon = true\n+org.quartz.jobStore.useProperties = false\n+\n+#============================================================================\n+# Configure ThreadPool\n+#============================================================================\n+\n+org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool\n+org.quartz.threadPool.makeThreadsDaemons = true\n+org.quartz.threadPool.threadCount = 25\n+org.quartz.threadPool.threadPriority = 5\n+\n+#============================================================================\n+# Configure JobStore\n+#============================================================================\n+\n+org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX\n+org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.PostgreSQLDelegate\n+org.quartz.jobStore.tablePrefix = QRTZ_\n+org.quartz.jobStore.isClustered = true\n+org.quartz.jobStore.misfireThreshold = 60000\n+org.quartz.jobStore.clusterCheckinInterval = 5000\n+org.quartz.jobStore.dataSource = myDs\n+\n+#============================================================================\n+# Configure Datasources\n+#============================================================================\n+org.quartz.dataSource.myDs.connectionProvider.class = org.apache.dolphinscheduler.server.quartz.DruidConnectionProvider\n+org.quartz.dataSource.myDs.driver = org.postgresql.Driver\n+org.quartz.dataSource.myDs.URL=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler\n+org.quartz.dataSource.myDs.user=root\n+org.quartz.dataSource.myDs.password=root@123\n+org.quartz.dataSource.myDs.maxConnections = 10\n+org.quartz.dataSource.myDs.validationQuery = select 1",
                "changes": 56
            },
            {
                "status": "added",
                "additions": 32,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/worker.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/worker.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/worker.properties",
                "deletions": 0,
                "sha": "582bb953f082fbca72c2722db2d3c388445e022b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/worker.properties",
                "patch": "@@ -0,0 +1,32 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# worker execute thread num\n+worker.exec.threads=100\n+\n+# worker heartbeat interval\n+worker.heartbeat.interval=10\n+\n+# submit the number of tasks at a time\n+worker.fetch.task.num = 3\n+\n+\n+# only less than cpu avg load, worker server can work. default value : the number of cpu cores * 2\n+#worker.max.cpuload.avg=10\n+\n+# only larger than reserved memory, worker server can work. default value : physical memory * 1/6, unit is G.\n+worker.reserved.memory=1\n\\ No newline at end of file",
                "changes": 32
            },
            {
                "status": "added",
                "additions": 79,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/worker_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/worker_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/worker_logback.xml",
                "deletions": 0,
                "sha": "9bbd9615c40966f73ba466a741cd4288f554997c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/worker_logback.xml",
                "patch": "@@ -0,0 +1,79 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\">\n+    <property name=\"log.base\" value=\"logs\"/>\n+    <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+        <encoder>\n+            <pattern>\n+                [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+            </pattern>\n+            <charset>UTF-8</charset>\n+        </encoder>\n+    </appender>\n+    <appender name=\"TASKLOGFILE\" class=\"ch.qos.logback.classic.sift.SiftingAppender\">\n+        <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n+            <level>INFO</level>\n+        </filter>\n+        <filter class=\"org.apache.dolphinscheduler.server.worker.log.TaskLogFilter\"></filter>\n+        <Discriminator class=\"org.apache.dolphinscheduler.server.worker.log.TaskLogDiscriminator\">\n+            <key>taskAppId</key>\n+            <logBase>${log.base}</logBase>\n+        </Discriminator>\n+        <sift>\n+            <appender name=\"FILE-${taskAppId}\" class=\"ch.qos.logback.core.FileAppender\">\n+                <file>${log.base}/${taskAppId}.log</file>\n+                <encoder>\n+                    <pattern>\n+                        [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+                    </pattern>\n+                    <charset>UTF-8</charset>\n+                </encoder>\n+                <append>true</append>\n+            </appender>\n+        </sift>\n+    </appender>\n+\n+    <appender name=\"WORKERLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+        <file>${log.base}/dolphinscheduler-worker.log</file>\n+        <filter class=\"org.apache.dolphinscheduler.server.worker.log.WorkerLogFilter\">\n+            <level>INFO</level>\n+        </filter>\n+\n+        <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+            <fileNamePattern>${log.base}/dolphinscheduler-worker.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+            <maxHistory>168</maxHistory>\n+            <maxFileSize>200MB</maxFileSize>\n+        </rollingPolicy>\n+        \u3000\u3000\u3000\u3000\u3000\n+        <encoder>\n+            <pattern>\n+                [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+            </pattern>\n+            <charset>UTF-8</charset>\n+        </encoder>\n+        \u3000\u3000\n+    </appender>\n+\n+\n+    <root level=\"INFO\">\n+        <appender-ref ref=\"TASKLOGFILE\"/>\n+        <appender-ref ref=\"WORKERLOGFILE\"/>\n+    </root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 79
            },
            {
                "status": "added",
                "additions": 42,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/zookeeper.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/dolphinscheduler/conf/zookeeper.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/dolphinscheduler/conf/zookeeper.properties",
                "deletions": 0,
                "sha": "5e9df1c86382dc04fa1ba5f98eabf98024d48fee",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/dolphinscheduler/conf/zookeeper.properties",
                "patch": "@@ -0,0 +1,42 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+#zookeeper cluster\n+zookeeper.quorum=127.0.0.1:2181\n+\n+#dolphinscheduler root directory\n+zookeeper.dolphinscheduler.root=/dolphinscheduler\n+\n+#zookeeper server dirctory\n+zookeeper.dolphinscheduler.dead.servers=/dolphinscheduler/dead-servers\n+zookeeper.dolphinscheduler.masters=/dolphinscheduler/masters\n+zookeeper.dolphinscheduler.workers=/dolphinscheduler/workers\n+\n+#zookeeper lock dirctory\n+zookeeper.dolphinscheduler.lock.masters=/dolphinscheduler/lock/masters\n+zookeeper.dolphinscheduler.lock.workers=/dolphinscheduler/lock/workers\n+\n+#dolphinscheduler failover directory\n+zookeeper.dolphinscheduler.lock.failover.masters=/dolphinscheduler/lock/failover/masters\n+zookeeper.dolphinscheduler.lock.failover.workers=/dolphinscheduler/lock/failover/workers\n+zookeeper.dolphinscheduler.lock.failover.startup.masters=/dolphinscheduler/lock/failover/startup-masters\n+\n+#dolphinscheduler failover directory\n+zookeeper.session.timeout=300\n+zookeeper.connection.timeout=300\n+zookeeper.retry.sleep=1000\n+zookeeper.retry.maxtime=5\n\\ No newline at end of file",
                "changes": 42
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/alert.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/alert.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/alert.properties",
                "deletions": 30,
                "sha": "df7d8372d759d177a2ae3f33ee47c9a435b144cc",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/alert.properties",
                "patch": "@@ -1,30 +0,0 @@\n-#alert type is EMAIL/SMS\n-alert.type=EMAIL\n-\n-# mail server configuration\n-mail.protocol=SMTP\n-mail.server.host=smtp.office365.com\n-mail.server.port=587\n-mail.sender=qiaozhanwei@outlook.com\n-mail.passwd=eschedulerBJEG\n-\n-# TLS\n-mail.smtp.starttls.enable=true\n-# SSL\n-mail.smtp.ssl.enable=false\n-\n-#xls file path,need create if not exist\n-xls.file.path=/tmp/xls\n-\n-# Enterprise WeChat configuration\n-enterprise.wechat.corp.id=xxxxxxx\n-enterprise.wechat.secret=xxxxxxx\n-enterprise.wechat.agent.id=xxxxxxx\n-enterprise.wechat.users=xxxxxxx\n-enterprise.wechat.token.url=https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$corpId&corpsecret=$secret\n-enterprise.wechat.push.url=https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$token\n-enterprise.wechat.team.send.msg={\\\"toparty\\\":\\\"$toParty\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"$msg\\\"},\\\"safe\\\":\\\"0\\\"}\n-enterprise.wechat.user.send.msg={\\\"touser\\\":\\\"$toUser\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"markdown\\\",\\\"markdown\\\":{\\\"content\\\":\\\"$msg\\\"}}\n-\n-\n-",
                "changes": 30
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/alert_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/alert_logback.xml?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/alert_logback.xml",
                "deletions": 31,
                "sha": "c4ca8e9d1fed3ea581b6d6059d6513d4cdf71345",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/alert_logback.xml",
                "patch": "@@ -1,31 +0,0 @@\n-<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n-<configuration scan=\"true\" scanPeriod=\"120 seconds\"> <!--debug=\"true\" -->\n-\t<property name=\"log.base\" value=\"logs\" />\n-\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\t</appender>\n-\n-\t<appender name=\"ALERTLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n-\t\t<file>${log.base}/escheduler-alert.log</file>\n-\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n-\t\t\t<fileNamePattern>${log.base}/escheduler-alert.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n-\t\t\t<maxHistory>20</maxHistory>\n-\t\t\t<maxFileSize>64MB</maxFileSize>\n-\t\t</rollingPolicy>\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\t</appender>\n-\n-\t<root level=\"INFO\">\n-\t\t<appender-ref ref=\"ALERTLOGFILE\"/>\n-\t</root>\n-</configuration>\n\\ No newline at end of file",
                "changes": 31
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/apiserver_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/apiserver_logback.xml?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/apiserver_logback.xml",
                "deletions": 42,
                "sha": "43e6af951a8fdb88e225d7a8039c803ed6a190ba",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/apiserver_logback.xml",
                "patch": "@@ -1,42 +0,0 @@\n-<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n-<configuration scan=\"true\" scanPeriod=\"120 seconds\">\n-\t<logger name=\"org.apache.zookeeper\" level=\"WARN\"/>\n- \t<logger name=\"org.apache.hbase\" level=\"WARN\"/>\n- \t<logger name=\"org.apache.hadoop\" level=\"WARN\"/>\n-\n-\t<property name=\"log.base\" value=\"logs\" />\n-\n-\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\t</appender>\n-\n-\t<appender name=\"APISERVERLOGFILE\"  class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n-\t\t<!-- Log level filter -->\n-\t\t<filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n-\t\t\t<level>INFO</level>\n-\t\t</filter>\n-        <file>${log.base}/escheduler-api-server.log</file>\n-\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n-\t\t\t<fileNamePattern>${log.base}/escheduler-api-server.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n-\t\t\t<maxHistory>168</maxHistory>\n-\t\t\t<maxFileSize>64MB</maxFileSize>\n-\t\t</rollingPolicy>\n-\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\n-\t</appender>\n-\n-\t<root level=\"INFO\">\n-\t\t<appender-ref ref=\"APISERVERLOGFILE\" />\n-\t</root>\n-</configuration>\n\\ No newline at end of file",
                "changes": 42
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/application.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/application.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/application.properties",
                "deletions": 19,
                "sha": "b817c18a4adecef1da4c915061ed11784a69b53b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/application.properties",
                "patch": "@@ -1,19 +0,0 @@\n-# server port\n-server.port=12345\n-\n-# session config\n-server.servlet.session.timeout=7200\n-\n-server.servlet.context-path=/escheduler/\n-\n-# file size limit for upload\n-spring.servlet.multipart.max-file-size=1024MB\n-spring.servlet.multipart.max-request-size=1024MB\n-\n-#post content\n-server.jetty.max-http-post-size=5000000\n-\n-spring.messages.encoding=UTF-8\n-\n-#i18n classpath folder , file prefix messages\uff0c if have many files, use \",\" seperator\n-spring.messages.basename=i18n/messages",
                "changes": 19
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/application_master.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/application_master.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/application_master.properties",
                "deletions": 1,
                "sha": "cc4774ae94907fad28e3f3c2f69c0006dc833b5d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/application_master.properties",
                "patch": "@@ -1 +0,0 @@\n-logging.config=classpath:master_logback.xml",
                "changes": 1
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/common/common.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/common/common.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/common/common.properties",
                "deletions": 42,
                "sha": "15af2845972fc1b523e9bcfc416f543fd35c64ff",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/common/common.properties",
                "patch": "@@ -1,42 +0,0 @@\n-#task queue implementation, default \"zookeeper\"\n-escheduler.queue.impl=zookeeper\n-\n-# user data directory path, self configuration, please make sure the directory exists and have read write permissions\n-data.basedir.path=/tmp/escheduler\n-\n-# directory path for user data download. self configuration, please make sure the directory exists and have read write permissions\n-data.download.basedir.path=/tmp/escheduler/download\n-\n-# process execute directory. self configuration, please make sure the directory exists and have read write permissions\n-process.exec.basepath=/tmp/escheduler/exec\n-\n-# Users who have permission to create directories under the HDFS root path\n-hdfs.root.user=hdfs\n-\n-# data base dir, resource file will store to this hadoop hdfs path, self configuration, please make sure the directory exists on hdfs and have read write permissions\u3002\"/escheduler\" is recommended\n-data.store2hdfs.basepath=/escheduler\n-\n-# resource upload startup type : HDFS,S3,NONE\n-res.upload.startup.type=NONE\n-\n-# whether kerberos starts\n-hadoop.security.authentication.startup.state=false\n-\n-# java.security.krb5.conf path\n-java.security.krb5.conf.path=/opt/krb5.conf\n-\n-# loginUserFromKeytab user\n-login.user.keytab.username=hdfs-mycluster@ESZ.COM\n-\n-# loginUserFromKeytab path\n-login.user.keytab.path=/opt/hdfs.headless.keytab\n-\n-# system env path. self configuration, please make sure the directory and file exists and have read write execute permissions\n-escheduler.env.path=/opt/escheduler/conf/env/.escheduler_env.sh\n-\n-#resource.view.suffixs\n-resource.view.suffixs=txt,log,sh,conf,cfg,py,java,sql,hql,xml\n-\n-# is development state? default \"false\"\n-development.state=true\n-",
                "changes": 42
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/common/hadoop/hadoop.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/common/hadoop/hadoop.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/common/hadoop/hadoop.properties",
                "deletions": 18,
                "sha": "81452a83a28818494eb801ffa700886f366952e3",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/common/hadoop/hadoop.properties",
                "patch": "@@ -1,18 +0,0 @@\n-# ha or single namenode,If namenode ha needs to copy core-site.xml and hdfs-site.xml\n-# to the conf directory\uff0csupport s3\uff0cfor example : s3a://escheduler\n-fs.defaultFS=hdfs://mycluster:8020\n-\n-# s3 need\uff0cs3 endpoint\n-fs.s3a.endpoint=http://192.168.199.91:9010\n-\n-# s3 need\uff0cs3 access key\n-fs.s3a.access.key=A3DXS30FO22544RE\n-\n-# s3 need\uff0cs3 secret key\n-fs.s3a.secret.key=OloCLq3n+8+sdPHUhJ21XrSxTC+JK\n-\n-#resourcemanager ha note this need ips , this empty if single\n-yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx\n-\n-# If it is a single resourcemanager, you only need to configure one host name. If it is resourcemanager HA, the default configuration is fine\n-yarn.application.status.address=http://ark1:8088/ws/v1/cluster/apps/%s\n\\ No newline at end of file",
                "changes": 18
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/config/install_config.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/config/install_config.conf?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/config/install_config.conf",
                "deletions": 3,
                "sha": "43b955d4f1652c89c2de1d7409937d965048fe52",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/config/install_config.conf",
                "patch": "@@ -1,3 +0,0 @@\n-installPath=/data1_1T/escheduler\n-deployUser=escheduler\n-ips=ark0,ark1,ark2,ark3,ark4",
                "changes": 3
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/config/run_config.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/config/run_config.conf?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/config/run_config.conf",
                "deletions": 4,
                "sha": "f4cfd832c4a49b21f78f0be4e789bcce01d1baa6",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/config/run_config.conf",
                "patch": "@@ -1,4 +0,0 @@\n-masters=ark0,ark1\n-workers=ark2,ark3,ark4\n-alertServer=ark3\n-apiServers=ark1\n\\ No newline at end of file",
                "changes": 4
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/dao/data_source.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/dao/data_source.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/dao/data_source.properties",
                "deletions": 53,
                "sha": "0dce2943e41cbf8e179340fb157c326177909e03",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/dao/data_source.properties",
                "patch": "@@ -1,53 +0,0 @@\n-# base spring data source configuration\n-spring.datasource.type=com.alibaba.druid.pool.DruidDataSource\n-spring.datasource.driver-class-name=com.mysql.jdbc.Driver\n-spring.datasource.url=jdbc:mysql://127.0.0.1:3306/escheduler?characterEncoding=UTF-8\n-spring.datasource.username=root\n-spring.datasource.password=root@123\n-\n-# connection configuration\n-spring.datasource.initialSize=5\n-# min connection number\n-spring.datasource.minIdle=5\n-# max connection number\n-spring.datasource.maxActive=50\n-\n-# max wait time for get a connection in milliseconds. if configuring maxWait, fair locks are enabled by default and concurrency efficiency decreases.\n-# If necessary, unfair locks can be used by configuring the useUnfairLock attribute to true.\n-spring.datasource.maxWait=60000\n-\n-# milliseconds for check to close free connections\n-spring.datasource.timeBetweenEvictionRunsMillis=60000\n-\n-# the Destroy thread detects the connection interval and closes the physical connection in milliseconds if the connection idle time is greater than or equal to minEvictableIdleTimeMillis.\n-spring.datasource.timeBetweenConnectErrorMillis=60000\n-\n-# the longest time a connection remains idle without being evicted, in milliseconds\n-spring.datasource.minEvictableIdleTimeMillis=300000\n-\n-#the SQL used to check whether the connection is valid requires a query statement. If validation Query is null, testOnBorrow, testOnReturn, and testWhileIdle will not work.\n-spring.datasource.validationQuery=SELECT 1\n-#check whether the connection is valid for timeout, in seconds\n-spring.datasource.validationQueryTimeout=3\n-\n-# when applying for a connection, if it is detected that the connection is idle longer than time Between Eviction Runs Millis,\n-# validation Query is performed to check whether the connection is valid\n-spring.datasource.testWhileIdle=true\n-\n-#execute validation to check if the connection is valid when applying for a connection\n-spring.datasource.testOnBorrow=true\n-#execute validation to check if the connection is valid when the connection is returned\n-spring.datasource.testOnReturn=false\n-spring.datasource.defaultAutoCommit=true\n-spring.datasource.keepAlive=true\n-\n-# open PSCache, specify count PSCache for every connection\n-spring.datasource.poolPreparedStatements=true\n-spring.datasource.maxPoolPreparedStatementPerConnectionSize=20\n-\n-# data quality analysis is not currently in use. please ignore the following configuration\n-# task record flag\n-task.record.flag=false\n-task.record.datasource.url=jdbc:mysql://192.168.xx.xx:3306/etl?characterEncoding=UTF-8\n-task.record.datasource.username=xx\n-task.record.datasource.password=xx",
                "changes": 53
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/env/.escheduler_env.sh",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/env/.escheduler_env.sh?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/env/.escheduler_env.sh",
                "deletions": 3,
                "sha": "75362d494d7d84404ae99f99eaa928a757b0f900",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/env/.escheduler_env.sh",
                "patch": "@@ -1,3 +0,0 @@\n-export PYTHON_HOME=/usr/bin/python\n-export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n-export PATH=$PYTHON_HOME:$JAVA_HOME/bin:$PATH\n\\ No newline at end of file",
                "changes": 3
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/i18n/messages.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/i18n/messages.properties",
                "deletions": 235,
                "sha": "88509558a99dc9954bcfe2c231bfd8081103cf32",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages.properties",
                "patch": "@@ -1,235 +0,0 @@\n-QUERY_SCHEDULE_LIST_NOTES=query schedule list\n-EXECUTE_PROCESS_TAG=execute process related operation\n-PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n-RUN_PROCESS_INSTANCE_NOTES=run process instance \n-START_NODE_LIST=start node list\uff08node name\uff09\n-TASK_DEPEND_TYPE=task depend type\n-COMMAND_TYPE=command type\n-RUN_MODE=run mode\n-TIMEOUT=timeout\n-EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n-EXECUTE_TYPE=execute type\n-START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n-GET_RECEIVER_CC_NOTES=query receiver cc \n-DESC=description\n-GROUP_NAME=group name\n-GROUP_TYPE=group type\n-QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n-UPDATE_ALERT_GROUP_NOTES=update alert group \n-DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n-VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n-GRANT_ALERT_GROUP_NOTES=grant alert group \n-USER_IDS=user id list\n-ALERT_GROUP_TAG=alert group related operation\n-CREATE_ALERT_GROUP_NOTES=create alert group \n-WORKER_GROUP_TAG=worker group related operation\n-SAVE_WORKER_GROUP_NOTES=create worker group\n-WORKER_GROUP_NAME=worker group name\n-WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n-QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n-QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n-DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n-DATA_ANALYSIS_TAG=analysis related operation of task state\n-COUNT_TASK_STATE_NOTES=count task state \n-COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n-COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n-COUNT_COMMAND_STATE_NOTES=count command state \n-COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n-\n-ACCESS_TOKEN_TAG=access token related operation\n-MONITOR_TAG=monitor related operation\n-MASTER_LIST_NOTES=master server list\n-WORKER_LIST_NOTES=worker server list\n-QUERY_DATABASE_STATE_NOTES=query database state \n-QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n-TASK_STATE=task instance state\n-SOURCE_TABLE=SOURCE TABLE\n-DEST_TABLE=dest table\n-TASK_DATE=task date\n-QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=query history task record list paging\n-DATA_SOURCE_TAG=data source related operation\n-CREATE_DATA_SOURCE_NOTES=create data source\n-DATA_SOURCE_NAME=data source name\n-DATA_SOURCE_NOTE=data source desc\n-DB_TYPE=database type\n-DATA_SOURCE_HOST=DATA SOURCE HOST\n-DATA_SOURCE_PORT=data source port\n-DATABASE_NAME=database name\n-QUEUE_TAG=queue related operation\n-QUERY_QUEUE_LIST_NOTES=query queue list \n-QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n-CREATE_QUEUE_NOTES=create queue\n-YARN_QUEUE_NAME=yarn(hadoop) queue name\n-QUEUE_ID=queue id\n-TENANT_DESC=tenant desc\n-QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n-QUERY_TENANT_LIST_NOTES=query tenant list \n-UPDATE_TENANT_NOTES=update tenant \n-DELETE_TENANT_NOTES=delete tenant \n-RESOURCES_TAG=resource center related operation\n-CREATE_RESOURCE_NOTES=create resource \n-RESOURCE_TYPE=resource file type\n-RESOURCE_NAME=resource name\n-RESOURCE_DESC=resource file desc\n-RESOURCE_FILE=resource file\n-RESOURCE_ID=resource id\n-QUERY_RESOURCE_LIST_NOTES=query resource list\n-DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n-VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n-ONLINE_CREATE_RESOURCE_NOTES=online create resource \n-SUFFIX=resource file suffix\n-CONTENT=resource file content\n-UPDATE_RESOURCE_NOTES=edit resource file online\n-DOWNLOAD_RESOURCE_NOTES=download resource file\n-CREATE_UDF_FUNCTION_NOTES=create udf function \n-UDF_TYPE=UDF type\n-FUNC_NAME=function name\n-CLASS_NAME=package and class name\n-ARG_TYPES=arguments\n-UDF_DESC=udf desc\n-VIEW_UDF_FUNCTION_NOTES=view udf function \n-UPDATE_UDF_FUNCTION_NOTES=update udf function \n-QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n-VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n-DELETE_UDF_FUNCTION_NOTES=delete udf function \n-AUTHORIZED_FILE_NOTES=authorized file \n-UNAUTHORIZED_FILE_NOTES=unauthorized file \n-AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n-UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n-VERIFY_QUEUE_NOTES=verify queue \n-TENANT_TAG=tenant related operation\n-CREATE_TENANT_NOTES=create tenant \n-TENANT_CODE=tenant code\n-TENANT_NAME=tenant name\n-QUEUE_NAME=queue name\n-PASSWORD=password\n-DATA_SOURCE_OTHER=jdbc connection params, format:{\"key1\":\"value1\",...}\n-PROJECT_TAG=project related operation\n-CREATE_PROJECT_NOTES=create project \n-PROJECT_DESC=project description\n-UPDATE_PROJECT_NOTES=update project \n-PROJECT_ID=project id\n-QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n-QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n-QUERY_ALL_PROJECT_LIST_NOTES=query all project list \n-DELETE_PROJECT_BY_ID_NOTES=delete project by id \n-QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n-QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n-TASK_RECORD_TAG=task record related operation\n-QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n-CREATE_TOKEN_NOTES=create token \uff0cnote: please login first\n-QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n-SCHEDULE=schedule\n-WARNING_TYPE=warning type(sending strategy)\n-WARNING_GROUP_ID=warning group id\n-FAILURE_STRATEGY=failure strategy\n-RECEIVERS=receivers\n-RECEIVERS_CC=receivers cc\n-WORKER_GROUP_ID=worker server group id\n-PROCESS_INSTANCE_PRIORITY=process instance priority\n-UPDATE_SCHEDULE_NOTES=update schedule \n-SCHEDULE_ID=schedule id\n-ONLINE_SCHEDULE_NOTES=online schedule\n-OFFLINE_SCHEDULE_NOTES=offline schedule \n-QUERY_SCHEDULE_NOTES=query schedule \n-QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n-LOGIN_TAG=User login related operations\n-USER_NAME=user name\n-PROJECT_NAME=project name\n-CREATE_PROCESS_DEFINITION_NOTES=create process definition\n-PROCESS_DEFINITION_NAME=process definition name\n-PROCESS_DEFINITION_JSON=process definition detail info (json format)\n-PROCESS_DEFINITION_LOCATIONS=process definition node locations info (json format)\n-PROCESS_INSTANCE_LOCATIONS=process instance node locations info (json format)\n-PROCESS_DEFINITION_CONNECTS=process definition node connects info (json format)\n-PROCESS_INSTANCE_CONNECTS=process instance node connects info (json format)\n-PROCESS_DEFINITION_DESC=process definition desc\n-PROCESS_DEFINITION_TAG=process definition related opertation\n-SIGNOUT_NOTES=logout\n-USER_PASSWORD=user password\n-UPDATE_PROCESS_INSTANCE_NOTES=update process instance\n-QUERY_PROCESS_INSTANCE_LIST_NOTES=query process instance list\n-VERIFY_PROCCESS_DEFINITION_NAME_NOTES=verify proccess definition name\n-LOGIN_NOTES=user login\n-UPDATE_PROCCESS_DEFINITION_NOTES=update proccess definition\n-PROCESS_DEFINITION_ID=process definition id\n-PROCESS_DEFINITION_IDS=process definition ids\n-RELEASE_PROCCESS_DEFINITION_NOTES=release proccess definition\n-QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=query proccess definition by id\n-QUERY_PROCCESS_DEFINITION_LIST_NOTES=query proccess definition list\n-QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=query proccess definition list paging\n-QUERY_ALL_DEFINITION_LIST_NOTES=query all definition list\n-PAGE_NO=page no\n-PROCESS_INSTANCE_ID=process instance id\n-PROCESS_INSTANCE_JSON=process instance info(json format)\n-SCHEDULE_TIME=schedule time\n-SYNC_DEFINE=update the information of the process instance to the process definition\\\n-\n-RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n-SEARCH_VAL=search val\n-USER_ID=user id\n-PAGE_SIZE=page size\n-LIMIT=limit\n-VIEW_TREE_NOTES=view tree\n-GET_NODE_LIST_BY_DEFINITION_ID_NOTES=get task node list by process definition id\n-PROCESS_DEFINITION_ID_LIST=process definition id list\n-QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=query proccess definition all by project id\n-DELETE_PROCESS_DEFINITION_BY_ID_NOTES=delete process definition by process definition id\n-BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=batch delete process definition by process definition ids\n-QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n-DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n-TASK_ID=task instance id\n-SKIP_LINE_NUM=skip line num\n-QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n-DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n-USERS_TAG=users related operation\n-SCHEDULER_TAG=scheduler related operation\n-CREATE_SCHEDULE_NOTES=create schedule \n-CREATE_USER_NOTES=create user\n-TENANT_ID=tenant id\n-QUEUE=queue\n-EMAIL=email\n-PHONE=phone\n-QUERY_USER_LIST_NOTES=query user list \n-UPDATE_USER_NOTES=update user\n-DELETE_USER_BY_ID_NOTES=delete user by id\n-GRANT_PROJECT_NOTES=GRANT PROJECT \n-PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n-GRANT_RESOURCE_NOTES=grant resource file\n-RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n-GET_USER_INFO_NOTES=get user info \n-LIST_USER_NOTES=list user\n-VERIFY_USER_NAME_NOTES=verify user name\n-UNAUTHORIZED_USER_NOTES=cancel authorization\n-ALERT_GROUP_ID=alert group id\n-AUTHORIZED_USER_NOTES=authorized user\n-GRANT_UDF_FUNC_NOTES=grant udf function\n-UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n-GRANT_DATASOURCE_NOTES=grant datasource \n-DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n-QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n-QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n-QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n-VIEW_GANTT_NOTES=view gantt \n-SUB_PROCESS_INSTANCE_ID=sub process instance id\n-TASK_NAME=task instance name\n-TASK_INSTANCE_TAG=task instance related operation\n-LOGGER_TAG=log related operation\n-PROCESS_INSTANCE_TAG=process instance related operation\n-EXECUTION_STATUS=runing status for workflow and task nodes\n-HOST=ip address of running task\n-START_DATE=start date\n-END_DATE=end date\n-QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=query task list by process instance id\n-UPDATE_DATA_SOURCE_NOTES=update data source\n-DATA_SOURCE_ID=DATA SOURCE ID\n-QUERY_DATA_SOURCE_NOTES=query data source by id\n-QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n-QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n-CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n-CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n-DELETE_DATA_SOURCE_NOTES=delete data source \n-VERIFY_DATA_SOURCE_NOTES=verify data source\n-UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n-AUTHORIZED_DATA_SOURCE_NOTES=authorized data source\n-DELETE_SCHEDULER_BY_ID_NOTES=delete scheduler by id",
                "changes": 235
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages_en_US.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/i18n/messages_en_US.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/i18n/messages_en_US.properties",
                "deletions": 235,
                "sha": "d06b83fed5d39373b39afdc4875533c297d9a6bf",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages_en_US.properties",
                "patch": "@@ -1,235 +0,0 @@\n-QUERY_SCHEDULE_LIST_NOTES=query schedule list\n-EXECUTE_PROCESS_TAG=execute process related operation\n-PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n-RUN_PROCESS_INSTANCE_NOTES=run process instance \n-START_NODE_LIST=start node list\uff08node name\uff09\n-TASK_DEPEND_TYPE=task depend type\n-COMMAND_TYPE=command type\n-RUN_MODE=run mode\n-TIMEOUT=timeout\n-EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n-EXECUTE_TYPE=execute type\n-START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n-GET_RECEIVER_CC_NOTES=query receiver cc \n-DESC=description\n-GROUP_NAME=group name\n-GROUP_TYPE=group type\n-QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n-UPDATE_ALERT_GROUP_NOTES=update alert group \n-DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n-VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n-GRANT_ALERT_GROUP_NOTES=grant alert group \n-USER_IDS=user id list\n-ALERT_GROUP_TAG=alert group related operation\n-CREATE_ALERT_GROUP_NOTES=create alert group \n-WORKER_GROUP_TAG=worker group related operation\n-SAVE_WORKER_GROUP_NOTES=create worker group\n-WORKER_GROUP_NAME=worker group name\n-WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n-QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n-QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n-DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n-DATA_ANALYSIS_TAG=analysis related operation of task state\n-COUNT_TASK_STATE_NOTES=count task state \n-COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n-COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n-COUNT_COMMAND_STATE_NOTES=count command state \n-COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n-\n-ACCESS_TOKEN_TAG=access token related operation\n-MONITOR_TAG=monitor related operation\n-MASTER_LIST_NOTES=master server list\n-WORKER_LIST_NOTES=worker server list\n-QUERY_DATABASE_STATE_NOTES=query database state \n-QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n-TASK_STATE=task instance state\n-SOURCE_TABLE=SOURCE TABLE\n-DEST_TABLE=dest table\n-TASK_DATE=task date\n-QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=query history task record list paging\n-DATA_SOURCE_TAG=data source related operation\n-CREATE_DATA_SOURCE_NOTES=create data source\n-DATA_SOURCE_NAME=data source name\n-DATA_SOURCE_NOTE=data source desc\n-DB_TYPE=database type\n-DATA_SOURCE_HOST=DATA SOURCE HOST\n-DATA_SOURCE_PORT=data source port\n-DATABASE_NAME=database name\n-QUEUE_TAG=queue related operation\n-QUERY_QUEUE_LIST_NOTES=query queue list \n-QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n-CREATE_QUEUE_NOTES=create queue\n-YARN_QUEUE_NAME=yarn(hadoop) queue name\n-QUEUE_ID=queue id\n-TENANT_DESC=tenant desc\n-QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n-QUERY_TENANT_LIST_NOTES=query tenant list \n-UPDATE_TENANT_NOTES=update tenant \n-DELETE_TENANT_NOTES=delete tenant \n-RESOURCES_TAG=resource center related operation\n-CREATE_RESOURCE_NOTES=create resource \n-RESOURCE_TYPE=resource file type\n-RESOURCE_NAME=resource name\n-RESOURCE_DESC=resource file desc\n-RESOURCE_FILE=resource file\n-RESOURCE_ID=resource id\n-QUERY_RESOURCE_LIST_NOTES=query resource list\n-DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n-VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n-ONLINE_CREATE_RESOURCE_NOTES=online create resource \n-SUFFIX=resource file suffix\n-CONTENT=resource file content\n-UPDATE_RESOURCE_NOTES=edit resource file online\n-DOWNLOAD_RESOURCE_NOTES=download resource file\n-CREATE_UDF_FUNCTION_NOTES=create udf function \n-UDF_TYPE=UDF type\n-FUNC_NAME=function name\n-CLASS_NAME=package and class name\n-ARG_TYPES=arguments\n-UDF_DESC=udf desc\n-VIEW_UDF_FUNCTION_NOTES=view udf function \n-UPDATE_UDF_FUNCTION_NOTES=update udf function \n-QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n-VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n-DELETE_UDF_FUNCTION_NOTES=delete udf function \n-AUTHORIZED_FILE_NOTES=authorized file \n-UNAUTHORIZED_FILE_NOTES=unauthorized file \n-AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n-UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n-VERIFY_QUEUE_NOTES=verify queue \n-TENANT_TAG=tenant related operation\n-CREATE_TENANT_NOTES=create tenant \n-TENANT_CODE=tenant code\n-TENANT_NAME=tenant name\n-QUEUE_NAME=queue name\n-PASSWORD=password\n-DATA_SOURCE_OTHER=jdbc connection params, format:{\"key1\":\"value1\",...}\n-PROJECT_TAG=project related operation\n-CREATE_PROJECT_NOTES=create project \n-PROJECT_DESC=project description\n-UPDATE_PROJECT_NOTES=update project \n-PROJECT_ID=project id\n-QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n-QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n-QUERY_ALL_PROJECT_LIST_NOTES=query all project list\n-DELETE_PROJECT_BY_ID_NOTES=delete project by id \n-QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n-QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n-TASK_RECORD_TAG=task record related operation\n-QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n-CREATE_TOKEN_NOTES=create token \uff0cnote: please login first\n-QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n-SCHEDULE=schedule\n-WARNING_TYPE=warning type(sending strategy)\n-WARNING_GROUP_ID=warning group id\n-FAILURE_STRATEGY=failure strategy\n-RECEIVERS=receivers\n-RECEIVERS_CC=receivers cc\n-WORKER_GROUP_ID=worker server group id\n-PROCESS_INSTANCE_PRIORITY=process instance priority\n-UPDATE_SCHEDULE_NOTES=update schedule \n-SCHEDULE_ID=schedule id\n-ONLINE_SCHEDULE_NOTES=online schedule\n-OFFLINE_SCHEDULE_NOTES=offline schedule \n-QUERY_SCHEDULE_NOTES=query schedule \n-QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n-LOGIN_TAG=User login related operations\n-USER_NAME=user name\n-PROJECT_NAME=project name\n-CREATE_PROCESS_DEFINITION_NOTES=create process definition\n-PROCESS_DEFINITION_NAME=process definition name\n-PROCESS_DEFINITION_JSON=process definition detail info (json format)\n-PROCESS_DEFINITION_LOCATIONS=process definition node locations info (json format)\n-PROCESS_INSTANCE_LOCATIONS=process instance node locations info (json format)\n-PROCESS_DEFINITION_CONNECTS=process definition node connects info (json format)\n-PROCESS_INSTANCE_CONNECTS=process instance node connects info (json format)\n-PROCESS_DEFINITION_DESC=process definition desc\n-PROCESS_DEFINITION_TAG=process definition related opertation\n-SIGNOUT_NOTES=logout\n-USER_PASSWORD=user password\n-UPDATE_PROCESS_INSTANCE_NOTES=update process instance\n-QUERY_PROCESS_INSTANCE_LIST_NOTES=query process instance list\n-VERIFY_PROCCESS_DEFINITION_NAME_NOTES=verify proccess definition name\n-LOGIN_NOTES=user login\n-UPDATE_PROCCESS_DEFINITION_NOTES=update proccess definition\n-PROCESS_DEFINITION_ID=process definition id\n-PROCESS_DEFINITION_IDS=process definition ids\n-RELEASE_PROCCESS_DEFINITION_NOTES=release proccess definition\n-QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=query proccess definition by id\n-QUERY_PROCCESS_DEFINITION_LIST_NOTES=query proccess definition list\n-QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=query proccess definition list paging\n-QUERY_ALL_DEFINITION_LIST_NOTES=query all definition list\n-PAGE_NO=page no\n-PROCESS_INSTANCE_ID=process instance id\n-PROCESS_INSTANCE_JSON=process instance info(json format)\n-SCHEDULE_TIME=schedule time\n-SYNC_DEFINE=update the information of the process instance to the process definition\\\n-\n-RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n-SEARCH_VAL=search val\n-USER_ID=user id\n-PAGE_SIZE=page size\n-LIMIT=limit\n-VIEW_TREE_NOTES=view tree\n-GET_NODE_LIST_BY_DEFINITION_ID_NOTES=get task node list by process definition id\n-PROCESS_DEFINITION_ID_LIST=process definition id list\n-QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=query proccess definition all by project id\n-DELETE_PROCESS_DEFINITION_BY_ID_NOTES=delete process definition by process definition id\n-BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=batch delete process definition by process definition ids\n-QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n-DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n-TASK_ID=task instance id\n-SKIP_LINE_NUM=skip line num\n-QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n-DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n-USERS_TAG=users related operation\n-SCHEDULER_TAG=scheduler related operation\n-CREATE_SCHEDULE_NOTES=create schedule \n-CREATE_USER_NOTES=create user\n-TENANT_ID=tenant id\n-QUEUE=queue\n-EMAIL=email\n-PHONE=phone\n-QUERY_USER_LIST_NOTES=query user list \n-UPDATE_USER_NOTES=update user\n-DELETE_USER_BY_ID_NOTES=delete user by id\n-GRANT_PROJECT_NOTES=GRANT PROJECT \n-PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n-GRANT_RESOURCE_NOTES=grant resource file\n-RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n-GET_USER_INFO_NOTES=get user info \n-LIST_USER_NOTES=list user\n-VERIFY_USER_NAME_NOTES=verify user name\n-UNAUTHORIZED_USER_NOTES=cancel authorization\n-ALERT_GROUP_ID=alert group id\n-AUTHORIZED_USER_NOTES=authorized user\n-GRANT_UDF_FUNC_NOTES=grant udf function\n-UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n-GRANT_DATASOURCE_NOTES=grant datasource \n-DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n-QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n-QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n-QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n-VIEW_GANTT_NOTES=view gantt \n-SUB_PROCESS_INSTANCE_ID=sub process instance id\n-TASK_NAME=task instance name\n-TASK_INSTANCE_TAG=task instance related operation\n-LOGGER_TAG=log related operation\n-PROCESS_INSTANCE_TAG=process instance related operation\n-EXECUTION_STATUS=runing status for workflow and task nodes\n-HOST=ip address of running task\n-START_DATE=start date\n-END_DATE=end date\n-QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=query task list by process instance id\n-UPDATE_DATA_SOURCE_NOTES=update data source\n-DATA_SOURCE_ID=DATA SOURCE ID\n-QUERY_DATA_SOURCE_NOTES=query data source by id\n-QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n-QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n-CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n-CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n-DELETE_DATA_SOURCE_NOTES=delete data source \n-VERIFY_DATA_SOURCE_NOTES=verify data source\n-UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n-AUTHORIZED_DATA_SOURCE_NOTES=authorized data source\n-DELETE_SCHEDULER_BY_ID_NOTES=delete scheduler by id",
                "changes": 235
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages_zh_CN.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/i18n/messages_zh_CN.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/i18n/messages_zh_CN.properties",
                "deletions": 233,
                "sha": "f23e6b7e36dbcb32065edb1824ca6abf59ebff07",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/i18n/messages_zh_CN.properties",
                "patch": "@@ -1,233 +0,0 @@\n-QUERY_SCHEDULE_LIST_NOTES=\u67e5\u8be2\u5b9a\u65f6\u5217\u8868\n-PROCESS_INSTANCE_EXECUTOR_TAG=\u6d41\u7a0b\u5b9e\u4f8b\u6267\u884c\u76f8\u5173\u64cd\u4f5c\n-RUN_PROCESS_INSTANCE_NOTES=\u8fd0\u884c\u6d41\u7a0b\u5b9e\u4f8b\n-START_NODE_LIST=\u5f00\u59cb\u8282\u70b9\u5217\u8868(\u8282\u70b9name)\n-TASK_DEPEND_TYPE=\u4efb\u52a1\u4f9d\u8d56\u7c7b\u578b\n-COMMAND_TYPE=\u6307\u4ee4\u7c7b\u578b\n-RUN_MODE=\u8fd0\u884c\u6a21\u5f0f\n-TIMEOUT=\u8d85\u65f6\u65f6\u95f4\n-EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=\u6267\u884c\u6d41\u7a0b\u5b9e\u4f8b\u7684\u5404\u79cd\u64cd\u4f5c(\u6682\u505c\u3001\u505c\u6b62\u3001\u91cd\u8dd1\u3001\u6062\u590d\u7b49)\n-EXECUTE_TYPE=\u6267\u884c\u7c7b\u578b\n-START_CHECK_PROCESS_DEFINITION_NOTES=\u68c0\u67e5\u6d41\u7a0b\u5b9a\u4e49\n-DESC=\u5907\u6ce8(\u63cf\u8ff0)\n-GROUP_NAME=\u7ec4\u540d\u79f0\n-GROUP_TYPE=\u7ec4\u7c7b\u578b\n-QUERY_ALERT_GROUP_LIST_NOTES=\u544a\u8b66\u7ec4\u5217\u8868\\\n-\n-UPDATE_ALERT_GROUP_NOTES=\u7f16\u8f91(\u66f4\u65b0)\u544a\u8b66\u7ec4\n-DELETE_ALERT_GROUP_BY_ID_NOTES=\u5220\u9664\u544a\u8b66\u7ec4\u901a\u8fc7ID\n-VERIFY_ALERT_GROUP_NAME_NOTES=\u68c0\u67e5\u544a\u8b66\u7ec4\u662f\u5426\u5b58\u5728\n-GRANT_ALERT_GROUP_NOTES=\u6388\u6743\u544a\u8b66\u7ec4\n-USER_IDS=\u7528\u6237ID\u5217\u8868\n-ALERT_GROUP_TAG=\u544a\u8b66\u7ec4\u76f8\u5173\u64cd\u4f5c\n-WORKER_GROUP_TAG=Worker\u5206\u7ec4\u7ba1\u7406\n-SAVE_WORKER_GROUP_NOTES=\u521b\u5efaWorker\u5206\u7ec4\\\n-\n-WORKER_GROUP_NAME=Worker\u5206\u7ec4\u540d\u79f0\n-WORKER_IP_LIST=Worker ip\u5217\u8868\uff0c\u6ce8\u610f\uff1a\u591a\u4e2aIP\u5730\u5740\u4ee5\u9017\u53f7\u5206\u5272\\\n-\n-QUERY_WORKER_GROUP_PAGING_NOTES=Worker\u5206\u7ec4\u7ba1\u7406\n-QUERY_WORKER_GROUP_LIST_NOTES=\u67e5\u8be2worker group\u5206\u7ec4\n-DELETE_WORKER_GROUP_BY_ID_NOTES=\u5220\u9664worker group\u901a\u8fc7ID\n-DATA_ANALYSIS_TAG=\u4efb\u52a1\u72b6\u6001\u5206\u6790\u76f8\u5173\u64cd\u4f5c\n-COUNT_TASK_STATE_NOTES=\u4efb\u52a1\u72b6\u6001\u7edf\u8ba1\n-COUNT_PROCESS_INSTANCE_NOTES=\u7edf\u8ba1\u6d41\u7a0b\u5b9e\u4f8b\u72b6\u6001\n-COUNT_PROCESS_DEFINITION_BY_USER_NOTES=\u7edf\u8ba1\u7528\u6237\u521b\u5efa\u7684\u6d41\u7a0b\u5b9a\u4e49\n-COUNT_COMMAND_STATE_NOTES=\u7edf\u8ba1\u547d\u4ee4\u72b6\u6001\n-COUNT_QUEUE_STATE_NOTES=\u7edf\u8ba1\u961f\u5217\u91cc\u4efb\u52a1\u72b6\u6001\n-ACCESS_TOKEN_TAG=access token\u76f8\u5173\u64cd\u4f5c\uff0c\u9700\u8981\u5148\u767b\u5f55\n-MONITOR_TAG=\u76d1\u63a7\u76f8\u5173\u64cd\u4f5c\n-MASTER_LIST_NOTES=master\u670d\u52a1\u5217\u8868\n-WORKER_LIST_NOTES=worker\u670d\u52a1\u5217\u8868\n-QUERY_DATABASE_STATE_NOTES=\u67e5\u8be2\u6570\u636e\u5e93\u72b6\u6001\n-QUERY_ZOOKEEPER_STATE_NOTES=\u67e5\u8be2Zookeeper\u72b6\u6001\n-TASK_STATE=\u4efb\u52a1\u5b9e\u4f8b\u72b6\u6001\n-SOURCE_TABLE=\u6e90\u8868\n-DEST_TABLE=\u76ee\u6807\u8868\n-TASK_DATE=\u4efb\u52a1\u65f6\u95f4\n-QUERY_HISTORY_TASK_RECORD_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u5386\u53f2\u4efb\u52a1\u8bb0\u5f55\u5217\u8868\n-DATA_SOURCE_TAG=\u6570\u636e\u6e90\u76f8\u5173\u64cd\u4f5c\n-CREATE_DATA_SOURCE_NOTES=\u521b\u5efa\u6570\u636e\u6e90\n-DATA_SOURCE_NAME=\u6570\u636e\u6e90\u540d\u79f0\n-DATA_SOURCE_NOTE=\u6570\u636e\u6e90\u63cf\u8ff0\n-DB_TYPE=\u6570\u636e\u6e90\u7c7b\u578b\n-DATA_SOURCE_HOST=IP\u4e3b\u673a\u540d\n-DATA_SOURCE_PORT=\u6570\u636e\u6e90\u7aef\u53e3\n-DATABASE_NAME=\u6570\u636e\u5e93\u540d\n-QUEUE_TAG=\u961f\u5217\u76f8\u5173\u64cd\u4f5c\n-QUERY_QUEUE_LIST_NOTES=\u67e5\u8be2\u961f\u5217\u5217\u8868\n-QUERY_QUEUE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u961f\u5217\u5217\u8868\n-CREATE_QUEUE_NOTES=\u521b\u5efa\u961f\u5217\n-YARN_QUEUE_NAME=hadoop yarn\u961f\u5217\u540d\n-QUEUE_ID=\u961f\u5217ID\n-TENANT_DESC=\u79df\u6237\u63cf\u8ff0\n-QUERY_TENANT_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u79df\u6237\u5217\u8868\n-QUERY_TENANT_LIST_NOTES=\u67e5\u8be2\u79df\u6237\u5217\u8868\n-UPDATE_TENANT_NOTES=\u66f4\u65b0\u79df\u6237\n-DELETE_TENANT_NOTES=\u5220\u9664\u79df\u6237\n-RESOURCES_TAG=\u8d44\u6e90\u4e2d\u5fc3\u76f8\u5173\u64cd\u4f5c\n-CREATE_RESOURCE_NOTES=\u521b\u5efa\u8d44\u6e90\n-RESOURCE_TYPE=\u8d44\u6e90\u6587\u4ef6\u7c7b\u578b\n-RESOURCE_NAME=\u8d44\u6e90\u6587\u4ef6\u540d\u79f0\n-RESOURCE_DESC=\u8d44\u6e90\u6587\u4ef6\u63cf\u8ff0\n-RESOURCE_FILE=\u8d44\u6e90\u6587\u4ef6\n-RESOURCE_ID=\u8d44\u6e90ID\n-QUERY_RESOURCE_LIST_NOTES=\u67e5\u8be2\u8d44\u6e90\u5217\u8868\n-DELETE_RESOURCE_BY_ID_NOTES=\u5220\u9664\u8d44\u6e90\u901a\u8fc7ID\n-VIEW_RESOURCE_BY_ID_NOTES=\u6d4f\u89c8\u8d44\u6e90\u901a\u901a\u8fc7ID\n-ONLINE_CREATE_RESOURCE_NOTES=\u5728\u7ebf\u521b\u5efa\u8d44\u6e90\n-SUFFIX=\u8d44\u6e90\u6587\u4ef6\u540e\u7f00\n-CONTENT=\u8d44\u6e90\u6587\u4ef6\u5185\u5bb9\n-UPDATE_RESOURCE_NOTES=\u5728\u7ebf\u66f4\u65b0\u8d44\u6e90\u6587\u4ef6\n-DOWNLOAD_RESOURCE_NOTES=\u4e0b\u8f7d\u8d44\u6e90\u6587\u4ef6\n-CREATE_UDF_FUNCTION_NOTES=\u521b\u5efaUDF\u51fd\u6570\n-UDF_TYPE=UDF\u7c7b\u578b\n-FUNC_NAME=\u51fd\u6570\u540d\u79f0\n-CLASS_NAME=\u5305\u540d\u7c7b\u540d\n-ARG_TYPES=\u53c2\u6570\n-UDF_DESC=udf\u63cf\u8ff0\uff0c\u4f7f\u7528\u8bf4\u660e\n-VIEW_UDF_FUNCTION_NOTES=\u67e5\u770budf\u51fd\u6570\n-UPDATE_UDF_FUNCTION_NOTES=\u66f4\u65b0udf\u51fd\u6570\n-QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2udf\u51fd\u6570\u5217\u8868\n-VERIFY_UDF_FUNCTION_NAME_NOTES=\u9a8c\u8bc1udf\u51fd\u6570\u540d\n-DELETE_UDF_FUNCTION_NOTES=\u5220\u9664UDF\u51fd\u6570\n-AUTHORIZED_FILE_NOTES=\u6388\u6743\u6587\u4ef6\n-UNAUTHORIZED_FILE_NOTES=\u53d6\u6d88\u6388\u6743\u6587\u4ef6\n-AUTHORIZED_UDF_FUNC_NOTES=\u6388\u6743udf\u51fd\u6570\n-UNAUTHORIZED_UDF_FUNC_NOTES=\u53d6\u6d88udf\u51fd\u6570\u6388\u6743\n-VERIFY_QUEUE_NOTES=\u9a8c\u8bc1\u961f\u5217\n-TENANT_TAG=\u79df\u6237\u76f8\u5173\u64cd\u4f5c\n-CREATE_TENANT_NOTES=\u521b\u5efa\u79df\u6237\n-TENANT_CODE=\u79df\u6237\u7f16\u7801\n-TENANT_NAME=\u79df\u6237\u540d\u79f0\n-QUEUE_NAME=\u961f\u5217\u540d\n-PASSWORD=\u5bc6\u7801\n-DATA_SOURCE_OTHER=jdbc\u8fde\u63a5\u53c2\u6570\uff0c\u683c\u5f0f\u4e3a:{\"key1\":\"value1\",...}\n-PROJECT_TAG=\u9879\u76ee\u76f8\u5173\u64cd\u4f5c\n-CREATE_PROJECT_NOTES=\u521b\u5efa\u9879\u76ee\n-PROJECT_DESC=\u9879\u76ee\u63cf\u8ff0\n-UPDATE_PROJECT_NOTES=\u66f4\u65b0\u9879\u76ee\n-PROJECT_ID=\u9879\u76eeID\n-QUERY_PROJECT_BY_ID_NOTES=\u901a\u8fc7\u9879\u76eeID\u67e5\u8be2\u9879\u76ee\u4fe1\u606f\n-QUERY_PROJECT_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u9879\u76ee\u5217\u8868\n-QUERY_ALL_PROJECT_LIST_NOTES=\u67e5\u8be2\u6240\u6709\u9879\u76ee\n-DELETE_PROJECT_BY_ID_NOTES=\u5220\u9664\u9879\u76ee\u901a\u8fc7ID\n-QUERY_UNAUTHORIZED_PROJECT_NOTES=\u67e5\u8be2\u672a\u6388\u6743\u7684\u9879\u76ee\n-QUERY_AUTHORIZED_PROJECT_NOTES=\u67e5\u8be2\u6388\u6743\u9879\u76ee\n-TASK_RECORD_TAG=\u4efb\u52a1\u8bb0\u5f55\u76f8\u5173\u64cd\u4f5c\n-QUERY_TASK_RECORD_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u4efb\u52a1\u8bb0\u5f55\u5217\u8868\n-CREATE_TOKEN_NOTES=\u521b\u5efatoken\uff0c\u6ce8\u610f\u9700\u8981\u5148\u767b\u5f55\n-QUERY_ACCESS_TOKEN_LIST_NOTES=\u5206\u9875\u67e5\u8be2access token\u5217\u8868\n-SCHEDULE=\u5b9a\u65f6\n-WARNING_TYPE=\u53d1\u9001\u7b56\u7565\n-WARNING_GROUP_ID=\u53d1\u9001\u7ec4ID\n-FAILURE_STRATEGY=\u5931\u8d25\u7b56\u7565\n-RECEIVERS=\u6536\u4ef6\u4eba\n-RECEIVERS_CC=\u6536\u4ef6\u4eba(\u6284\u9001)\n-WORKER_GROUP_ID=Worker Server\u5206\u7ec4ID\n-PROCESS_INSTANCE_PRIORITY=\u6d41\u7a0b\u5b9e\u4f8b\u4f18\u5148\u7ea7\n-UPDATE_SCHEDULE_NOTES=\u66f4\u65b0\u5b9a\u65f6\n-SCHEDULE_ID=\u5b9a\u65f6ID\n-ONLINE_SCHEDULE_NOTES=\u5b9a\u65f6\u4e0a\u7ebf\n-OFFLINE_SCHEDULE_NOTES=\u5b9a\u65f6\u4e0b\u7ebf\n-QUERY_SCHEDULE_NOTES=\u67e5\u8be2\u5b9a\u65f6\n-QUERY_SCHEDULE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u5b9a\u65f6\n-LOGIN_TAG=\u7528\u6237\u767b\u5f55\u76f8\u5173\u64cd\u4f5c\n-USER_NAME=\u7528\u6237\u540d\n-PROJECT_NAME=\u9879\u76ee\u540d\u79f0\n-CREATE_PROCESS_DEFINITION_NOTES=\u521b\u5efa\u6d41\u7a0b\u5b9a\u4e49\n-PROCESS_DEFINITION_NAME=\u6d41\u7a0b\u5b9a\u4e49\u540d\u79f0\n-PROCESS_DEFINITION_JSON=\u6d41\u7a0b\u5b9a\u4e49\u8be6\u7ec6\u4fe1\u606f(json\u683c\u5f0f)\n-PROCESS_DEFINITION_LOCATIONS=\u6d41\u7a0b\u5b9a\u4e49\u8282\u70b9\u5750\u6807\u4f4d\u7f6e\u4fe1\u606f(json\u683c\u5f0f)\n-PROCESS_INSTANCE_LOCATIONS=\u6d41\u7a0b\u5b9e\u4f8b\u8282\u70b9\u5750\u6807\u4f4d\u7f6e\u4fe1\u606f(json\u683c\u5f0f)\n-PROCESS_DEFINITION_CONNECTS=\u6d41\u7a0b\u5b9a\u4e49\u8282\u70b9\u56fe\u6807\u8fde\u63a5\u4fe1\u606f(json\u683c\u5f0f)\n-PROCESS_INSTANCE_CONNECTS=\u6d41\u7a0b\u5b9e\u4f8b\u8282\u70b9\u56fe\u6807\u8fde\u63a5\u4fe1\u606f(json\u683c\u5f0f)\n-PROCESS_DEFINITION_DESC=\u6d41\u7a0b\u5b9a\u4e49\u63cf\u8ff0\u4fe1\u606f\n-PROCESS_DEFINITION_TAG=\u6d41\u7a0b\u5b9a\u4e49\u76f8\u5173\u64cd\u4f5c\n-SIGNOUT_NOTES=\u9000\u51fa\u767b\u5f55\n-USER_PASSWORD=\u7528\u6237\u5bc6\u7801\n-UPDATE_PROCESS_INSTANCE_NOTES=\u66f4\u65b0\u6d41\u7a0b\u5b9e\u4f8b\n-QUERY_PROCESS_INSTANCE_LIST_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u5217\u8868\n-VERIFY_PROCCESS_DEFINITION_NAME_NOTES=\u9a8c\u8bc1\u6d41\u7a0b\u5b9a\u4e49\u540d\u5b57\n-LOGIN_NOTES=\u7528\u6237\u767b\u5f55\n-UPDATE_PROCCESS_DEFINITION_NOTES=\u66f4\u65b0\u6d41\u7a0b\u5b9a\u4e49\n-PROCESS_DEFINITION_ID=\u6d41\u7a0b\u5b9a\u4e49ID\n-RELEASE_PROCCESS_DEFINITION_NOTES=\u53d1\u5e03\u6d41\u7a0b\u5b9a\u4e49\n-QUERY_PROCCESS_DEFINITION_BY_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n-QUERY_PROCCESS_DEFINITION_LIST_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\n-QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\n-QUERY_ALL_DEFINITION_LIST_NOTES=\u67e5\u8be2\u6240\u6709\u6d41\u7a0b\u5b9a\u4e49\n-PAGE_NO=\u9875\u7801\u53f7\n-PROCESS_INSTANCE_ID=\u6d41\u7a0b\u5b9e\u4f8bID\n-PROCESS_INSTANCE_IDS=\u6d41\u7a0b\u5b9e\u4f8bID\u96c6\u5408\n-PROCESS_INSTANCE_JSON=\u6d41\u7a0b\u5b9e\u4f8b\u4fe1\u606f(json\u683c\u5f0f)\n-SCHEDULE_TIME=\u5b9a\u65f6\u65f6\u95f4\n-SYNC_DEFINE=\u66f4\u65b0\u6d41\u7a0b\u5b9e\u4f8b\u7684\u4fe1\u606f\u662f\u5426\u540c\u6b65\u5230\u6d41\u7a0b\u5b9a\u4e49\n-RECOVERY_PROCESS_INSTANCE_FLAG=\u662f\u5426\u6062\u590d\u6d41\u7a0b\u5b9e\u4f8b\n-SEARCH_VAL=\u641c\u7d22\u503c\n-USER_ID=\u7528\u6237ID\n-PAGE_SIZE=\u9875\u5927\u5c0f\n-LIMIT=\u663e\u793a\u591a\u5c11\u6761\n-VIEW_TREE_NOTES=\u6811\u72b6\u56fe\n-GET_NODE_LIST_BY_DEFINITION_ID_NOTES=\u83b7\u5f97\u4efb\u52a1\u8282\u70b9\u5217\u8868\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n-PROCESS_DEFINITION_ID_LIST=\u6d41\u7a0b\u5b9a\u4e49id\u5217\u8868\n-QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u9879\u76eeID\n-DELETE_PROCESS_DEFINITION_BY_ID_NOTES=\u5220\u9664\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\n-BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES=\u6279\u91cf\u5220\u9664\u6d41\u7a0b\u5b9a\u4e49\u901a\u8fc7\u6d41\u7a0b\u5b9a\u4e49ID\u96c6\u5408\n-QUERY_PROCESS_INSTANCE_BY_ID_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\n-DELETE_PROCESS_INSTANCE_BY_ID_NOTES=\u5220\u9664\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\n-TASK_ID=\u4efb\u52a1\u5b9e\u4f8bID\n-SKIP_LINE_NUM=\u5ffd\u7565\u884c\u6570\n-QUERY_TASK_INSTANCE_LOG_NOTES=\u67e5\u8be2\u4efb\u52a1\u5b9e\u4f8b\u65e5\u5fd7\n-DOWNLOAD_TASK_INSTANCE_LOG_NOTES=\u4e0b\u8f7d\u4efb\u52a1\u5b9e\u4f8b\u65e5\u5fd7\n-USERS_TAG=\u7528\u6237\u76f8\u5173\u64cd\u4f5c\n-SCHEDULER_TAG=\u5b9a\u65f6\u76f8\u5173\u64cd\u4f5c\n-CREATE_SCHEDULE_NOTES=\u521b\u5efa\u5b9a\u65f6\n-CREATE_USER_NOTES=\u521b\u5efa\u7528\u6237\n-TENANT_ID=\u79df\u6237ID\n-QUEUE=\u4f7f\u7528\u7684\u961f\u5217\n-EMAIL=\u90ae\u7bb1\n-PHONE=\u624b\u673a\u53f7\n-QUERY_USER_LIST_NOTES=\u67e5\u8be2\u7528\u6237\u5217\u8868\n-UPDATE_USER_NOTES=\u66f4\u65b0\u7528\u6237\n-DELETE_USER_BY_ID_NOTES=\u5220\u9664\u7528\u6237\u901a\u8fc7ID\n-GRANT_PROJECT_NOTES=\u6388\u6743\u9879\u76ee\n-PROJECT_IDS=\u9879\u76eeIDS(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u9879\u76ee\u4ee5\",\"\u5206\u5272)\n-GRANT_RESOURCE_NOTES=\u6388\u6743\u8d44\u6e90\u6587\u4ef6\n-RESOURCE_IDS=\u8d44\u6e90ID\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u8d44\u6e90ID\u4ee5\",\"\u5206\u5272)\n-GET_USER_INFO_NOTES=\u83b7\u53d6\u7528\u6237\u4fe1\u606f\n-LIST_USER_NOTES=\u7528\u6237\u5217\u8868\n-VERIFY_USER_NAME_NOTES=\u9a8c\u8bc1\u7528\u6237\u540d\n-UNAUTHORIZED_USER_NOTES=\u53d6\u6d88\u6388\u6743\n-ALERT_GROUP_ID=\u62a5\u8b66\u7ec4ID\n-AUTHORIZED_USER_NOTES=\u6388\u6743\u7528\u6237\n-GRANT_UDF_FUNC_NOTES=\u6388\u6743udf\u51fd\u6570\n-UDF_IDS=udf\u51fd\u6570id\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2audf\u51fd\u6570ID\u4ee5\",\"\u5206\u5272)\n-GRANT_DATASOURCE_NOTES=\u6388\u6743\u6570\u636e\u6e90\n-DATASOURCE_IDS=\u6570\u636e\u6e90ID\u5217\u8868(\u5b57\u7b26\u4e32\u683c\u5f0f\uff0c\u591a\u4e2a\u6570\u636e\u6e90ID\u4ee5\",\"\u5206\u5272)\n-QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=\u67e5\u8be2\u5b50\u6d41\u7a0b\u5b9e\u4f8b\u901a\u8fc7\u4efb\u52a1\u5b9e\u4f8bID\n-QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=\u67e5\u8be2\u7236\u6d41\u7a0b\u5b9e\u4f8b\u4fe1\u606f\u901a\u8fc7\u5b50\u6d41\u7a0b\u5b9e\u4f8bID\n-QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=\u67e5\u8be2\u6d41\u7a0b\u5b9e\u4f8b\u5168\u5c40\u53d8\u91cf\u548c\u5c40\u90e8\u53d8\u91cf\n-VIEW_GANTT_NOTES=\u6d4f\u89c8Gantt\u56fe\n-SUB_PROCESS_INSTANCE_ID=\u5b50\u6d41\u7a0b\u662f\u54a7ID\n-TASK_NAME=\u4efb\u52a1\u5b9e\u4f8b\u540d\n-TASK_INSTANCE_TAG=\u4efb\u52a1\u5b9e\u4f8b\u76f8\u5173\u64cd\u4f5c\n-LOGGER_TAG=\u65e5\u5fd7\u76f8\u5173\u64cd\u4f5c\n-PROCESS_INSTANCE_TAG=\u6d41\u7a0b\u5b9e\u4f8b\u76f8\u5173\u64cd\u4f5c\n-EXECUTION_STATUS=\u5de5\u4f5c\u6d41\u548c\u4efb\u52a1\u8282\u70b9\u7684\u8fd0\u884c\u72b6\u6001\n-HOST=\u8fd0\u884c\u4efb\u52a1\u7684\u4e3b\u673aIP\u5730\u5740\n-START_DATE=\u5f00\u59cb\u65f6\u95f4\n-END_DATE=\u7ed3\u675f\u65f6\u95f4\n-QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES=\u901a\u8fc7\u6d41\u7a0b\u5b9e\u4f8bID\u67e5\u8be2\u4efb\u52a1\u5217\u8868\n-UPDATE_DATA_SOURCE_NOTES=\u66f4\u65b0\u6570\u636e\u6e90\n-DATA_SOURCE_ID=\u6570\u636e\u6e90ID\n-QUERY_DATA_SOURCE_NOTES=\u67e5\u8be2\u6570\u636e\u6e90\u901a\u8fc7ID\n-QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=\u67e5\u8be2\u6570\u636e\u6e90\u5217\u8868\u901a\u8fc7\u6570\u636e\u6e90\u7c7b\u578b\n-QUERY_DATA_SOURCE_LIST_PAGING_NOTES=\u5206\u9875\u67e5\u8be2\u6570\u636e\u6e90\u5217\u8868\n-CONNECT_DATA_SOURCE_NOTES=\u8fde\u63a5\u6570\u636e\u6e90\n-CONNECT_DATA_SOURCE_TEST_NOTES=\u8fde\u63a5\u6570\u636e\u6e90\u6d4b\u8bd5\n-DELETE_DATA_SOURCE_NOTES=\u5220\u9664\u6570\u636e\u6e90\n-VERIFY_DATA_SOURCE_NOTES=\u9a8c\u8bc1\u6570\u636e\u6e90\n-UNAUTHORIZED_DATA_SOURCE_NOTES=\u672a\u6388\u6743\u7684\u6570\u636e\u6e90\n-AUTHORIZED_DATA_SOURCE_NOTES=\u6388\u6743\u7684\u6570\u636e\u6e90\n-DELETE_SCHEDULER_BY_ID_NOTES=\u6839\u636e\u5b9a\u65f6id\u5220\u9664\u5b9a\u65f6\u6570\u636e",
                "changes": 233
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/mail_templates/alert_mail_template.ftl",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/mail_templates/alert_mail_template.ftl?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/mail_templates/alert_mail_template.ftl",
                "deletions": 1,
                "sha": "0ff763fa28d69ce722fbb10db1128d107f507912",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/mail_templates/alert_mail_template.ftl",
                "patch": "@@ -1 +0,0 @@\n-<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'><html><head><title> easyscheduler</title><meta name='Keywords' content=''><meta name='Description' content=''><style type=\"text/css\">table {            margin-top:0px;            padding-top:0px;            border:1px solid;            font-size: 14px;            color: #333333;            border-width: 1px;            border-color: #666666;            border-collapse: collapse;        }        table th {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #dedede;        }        table td {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #ffffff;        }</style></head><body style=\"margin:0;padding:0\"><table border=\"1px\" cellpadding=\"5px\" cellspacing=\"-10px\"><thead><#if title??> ${title}</#if></thead><#if content??> ${content}</#if></table></body></html>\n\\ No newline at end of file",
                "changes": 1
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/master.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/master.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/master.properties",
                "deletions": 21,
                "sha": "9080defc7b57480e2aafd4b3141d55eb92f10244",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/master.properties",
                "patch": "@@ -1,21 +0,0 @@\n-# master execute thread num\n-master.exec.threads=100\n-\n-# master execute task number in parallel\n-master.exec.task.number=20\n-\n-# master heartbeat interval\n-master.heartbeat.interval=10\n-\n-# master commit task retry times\n-master.task.commit.retryTimes=5\n-\n-# master commit task interval\n-master.task.commit.interval=100\n-\n-\n-# only less than cpu avg load, master server can work. default value : the number of cpu cores * 2\n-master.max.cpuload.avg=10\n-\n-# only larger than reserved memory, master server can work. default value : physical memory * 1/10, unit is G.\n-master.reserved.memory=1",
                "changes": 21
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/master_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/master_logback.xml?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/master_logback.xml",
                "deletions": 34,
                "sha": "d93878218e05cc19b6de10fffa3fdc5925471c91",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/master_logback.xml",
                "patch": "@@ -1,34 +0,0 @@\n-<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n-<configuration scan=\"true\" scanPeriod=\"120 seconds\"> <!--debug=\"true\" -->\n-\t<property name=\"log.base\" value=\"logs\" />\n-\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\t</appender>\n-\n-\t<appender name=\"MASTERLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n-\t\t<file>${log.base}/escheduler-master.log</file>\n-\t\t<filter class=\"cn.escheduler.server.master.log.MasterLogFilter\">\n-\t\t\t<level>INFO</level>\n-\t\t</filter>\n-\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n-\t\t\t<fileNamePattern>${log.base}/escheduler-master.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n-\t\t\t<maxHistory>168</maxHistory>\n-\t\t\t<maxFileSize>200MB</maxFileSize>\n-\t\t</rollingPolicy>\n-\t\t<encoder>\n-\t\t\t<pattern>\n-\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-\t\t\t</pattern>\n-\t\t\t<charset>UTF-8</charset>\n-\t\t</encoder>\n-\t</appender>\n-\n-\t<root level=\"INFO\">\n-\t\t<appender-ref ref=\"MASTERLOGFILE\"/>\n-\t</root>\n-</configuration>\n\\ No newline at end of file",
                "changes": 34
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/quartz.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/quartz.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/quartz.properties",
                "deletions": 39,
                "sha": "21c5feb321b30101a1678edd30fff18d5c5e82cc",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/quartz.properties",
                "patch": "@@ -1,39 +0,0 @@\n-#============================================================================\n-# Configure Main Scheduler Properties\n-#============================================================================\n-org.quartz.scheduler.instanceName = EasyScheduler\n-org.quartz.scheduler.instanceId = AUTO\n-org.quartz.scheduler.makeSchedulerThreadDaemon = true\n-org.quartz.jobStore.useProperties = false\n-\n-#============================================================================\n-# Configure ThreadPool\n-#============================================================================\n-\n-org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool\n-org.quartz.threadPool.makeThreadsDaemons = true\n-org.quartz.threadPool.threadCount = 25\n-org.quartz.threadPool.threadPriority = 5\n-\n-#============================================================================\n-# Configure JobStore\n-#============================================================================\n- \n-org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX\n-org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate\n-org.quartz.jobStore.tablePrefix = QRTZ_\n-org.quartz.jobStore.isClustered = true\n-org.quartz.jobStore.misfireThreshold = 60000\n-org.quartz.jobStore.clusterCheckinInterval = 5000\n-org.quartz.jobStore.dataSource = myDs\n-\n-#============================================================================\n-# Configure Datasources  \n-#============================================================================\n- \n-org.quartz.dataSource.myDs.driver = com.mysql.jdbc.Driver\n-org.quartz.dataSource.myDs.URL=jdbc:mysql://127.0.0.1:3306/escheduler?characterEncoding=utf8\n-org.quartz.dataSource.myDs.user=root\n-org.quartz.dataSource.myDs.password=root@123\n-org.quartz.dataSource.myDs.maxConnections = 10\n-org.quartz.dataSource.myDs.validationQuery = select 1\n\\ No newline at end of file",
                "changes": 39
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/worker.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/worker.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/worker.properties",
                "deletions": 15,
                "sha": "e58bd86dcf3797c410aedd2607867f7a1df8d2c5",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/worker.properties",
                "patch": "@@ -1,15 +0,0 @@\n-# worker execute thread num\n-worker.exec.threads=100\n-\n-# worker heartbeat interval\n-worker.heartbeat.interval=10\n-\n-# submit the number of tasks at a time\n-worker.fetch.task.num = 3\n-\n-\n-# only less than cpu avg load, worker server can work. default value : the number of cpu cores * 2\n-#worker.max.cpuload.avg=10\n-\n-# only larger than reserved memory, worker server can work. default value : physical memory * 1/6, unit is G.\n-worker.reserved.memory=1\n\\ No newline at end of file",
                "changes": 15
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/worker_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/worker_logback.xml?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/worker_logback.xml",
                "deletions": 60,
                "sha": "f630559da98f775c63b48abce2a29642a4d36f13",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/worker_logback.xml",
                "patch": "@@ -1,60 +0,0 @@\n-<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n-<configuration scan=\"true\" scanPeriod=\"120 seconds\">\n-    <property name=\"log.base\" value=\"logs\"/>\n-    <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n-        <encoder>\n-            <pattern>\n-                [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-            </pattern>\n-            <charset>UTF-8</charset>\n-        </encoder>\n-    </appender>\n-    <appender name=\"TASKLOGFILE\" class=\"ch.qos.logback.classic.sift.SiftingAppender\">\n-        <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\n-            <level>INFO</level>\n-        </filter>\n-        <filter class=\"cn.escheduler.server.worker.log.TaskLogFilter\"></filter>\n-        <Discriminator class=\"cn.escheduler.server.worker.log.TaskLogDiscriminator\">\n-            <key>taskAppId</key>\n-        </Discriminator>\n-        <sift>\n-            <appender name=\"FILE-${taskAppId}\" class=\"ch.qos.logback.core.FileAppender\">\n-                <file>${log.base}/${taskAppId}.log</file>\n-                <encoder>\n-                    <pattern>\n-                        [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-                    </pattern>\n-                    <charset>UTF-8</charset>\n-                </encoder>\n-                <append>true</append>\n-            </appender>\n-        </sift>\n-    </appender>\n-\n-    <appender name=\"WORKERLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n-        <file>${log.base}/escheduler-worker.log</file>\n-        <filter class=\"cn.escheduler.server.worker.log.WorkerLogFilter\">\n-            <level>INFO</level>\n-        </filter>\n-\n-        <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n-            <fileNamePattern>${log.base}/escheduler-worker.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n-            <maxHistory>168</maxHistory>\n-            <maxFileSize>200MB</maxFileSize>\n-        </rollingPolicy>\n-        \u3000\u3000\u3000\u3000\u3000\n-        <encoder>\n-            <pattern>\n-                [%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n-            </pattern>\n-            <charset>UTF-8</charset>\n-        </encoder>\n-        \u3000\u3000\n-    </appender>\n-\n-\n-    <root level=\"INFO\">\n-        <appender-ref ref=\"TASKLOGFILE\"/>\n-        <appender-ref ref=\"WORKERLOGFILE\"/>\n-    </root>\n-</configuration>\n\\ No newline at end of file",
                "changes": 60
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/zookeeper.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/escheduler/conf/zookeeper.properties?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/escheduler/conf/zookeeper.properties",
                "deletions": 25,
                "sha": "5f14df49b794f36c61487b9c6a941b4a846313e2",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/escheduler/conf/zookeeper.properties",
                "patch": "@@ -1,25 +0,0 @@\n-#zookeeper cluster\n-zookeeper.quorum=127.0.0.1:2181\n-\n-#escheduler root directory\n-zookeeper.escheduler.root=/escheduler\n-\n-#zookeeper server dirctory\n-zookeeper.escheduler.dead.servers=/escheduler/dead-servers\n-zookeeper.escheduler.masters=/escheduler/masters\n-zookeeper.escheduler.workers=/escheduler/workers\n-\n-#zookeeper lock dirctory\n-zookeeper.escheduler.lock.masters=/escheduler/lock/masters\n-zookeeper.escheduler.lock.workers=/escheduler/lock/workers\n-\n-#escheduler failover directory\n-zookeeper.escheduler.lock.failover.masters=/escheduler/lock/failover/masters\n-zookeeper.escheduler.lock.failover.workers=/escheduler/lock/failover/workers\n-zookeeper.escheduler.lock.failover.startup.masters=/escheduler/lock/failover/startup-masters\n-\n-#escheduler failover directory\n-zookeeper.session.timeout=300\n-zookeeper.connection.timeout=300\n-zookeeper.retry.sleep=1000\n-zookeeper.retry.maxtime=5\n\\ No newline at end of file",
                "changes": 25
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/nginx/default.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/nginx/default.conf?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "dockerfile/conf/nginx/default.conf",
                "deletions": 31,
                "sha": "2d43c32b630c04095e57385a879476c010c21bba",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/dockerfile/conf/nginx/default.conf",
                "patch": "@@ -1,31 +0,0 @@\n-server {\n-    listen       8888;\n-    server_name  localhost;\n-    #charset koi8-r;\n-    #access_log  /var/log/nginx/host.access.log  main;\n-    location / {\n-        root   /opt/easyscheduler_source/escheduler-ui/dist;\n-        index  index.html index.html;\n-    }\n-    location /escheduler {\n-        proxy_pass http://127.0.0.1:12345;\n-        proxy_set_header Host $host;\n-        proxy_set_header X-Real-IP $remote_addr;\n-        proxy_set_header x_real_ipP $remote_addr;\n-        proxy_set_header remote_addr $remote_addr;\n-        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n-        proxy_http_version 1.1;\n-        proxy_connect_timeout 300s;\n-        proxy_read_timeout 300s;\n-        proxy_send_timeout 300s;\n-        proxy_set_header Upgrade $http_upgrade;\n-        proxy_set_header Connection \"upgrade\";\n-    }\n-    #error_page  404              /404.html;\n-    # redirect server error pages to the static page /50x.html\n-    #\n-    error_page   500 502 503 504  /50x.html;\n-    location = /50x.html {\n-        root   /usr/share/nginx/html;\n-    }\n-}",
                "changes": 31
            },
            {
                "status": "added",
                "additions": 48,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/nginx/dolphinscheduler.conf",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/nginx/dolphinscheduler.conf?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/nginx/dolphinscheduler.conf",
                "deletions": 0,
                "sha": "03f87e6b5281d5b235e0f02f91351a363d1e8a57",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/nginx/dolphinscheduler.conf",
                "patch": "@@ -0,0 +1,48 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+server {\n+    listen       8888;\n+    server_name  localhost;\n+    #charset koi8-r;\n+    #access_log  /var/log/nginx/host.access.log  main;\n+    location / {\n+        root   /opt/dolphinscheduler_source/dolphinscheduler-ui/dist;\n+        index  index.html index.html;\n+    }\n+    location /dolphinscheduler {\n+        proxy_pass http://127.0.0.1:12345;\n+        proxy_set_header Host $host;\n+        proxy_set_header X-Real-IP $remote_addr;\n+        proxy_set_header x_real_ipP $remote_addr;\n+        proxy_set_header remote_addr $remote_addr;\n+        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n+        proxy_http_version 1.1;\n+        proxy_connect_timeout 300s;\n+        proxy_read_timeout 300s;\n+        proxy_send_timeout 300s;\n+        proxy_set_header Upgrade $http_upgrade;\n+        proxy_set_header Connection \"upgrade\";\n+    }\n+    #error_page  404              /404.html;\n+    # redirect server error pages to the static page /50x.html\n+    #\n+    error_page   500 502 503 504  /50x.html;\n+    location = /50x.html {\n+        root   /usr/share/nginx/html;\n+    }\n+}",
                "changes": 48
            },
            {
                "status": "modified",
                "additions": 17,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/zookeeper/zoo.cfg",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/conf/zookeeper/zoo.cfg?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/conf/zookeeper/zoo.cfg",
                "deletions": 0,
                "sha": "7980d37ae927b09be3bbfd4fc68a26af3560d9d0",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/conf/zookeeper/zoo.cfg",
                "patch": "@@ -1,3 +1,20 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n # The number of milliseconds of each tick\n tickTime=2000\n # The number of ticks that the initial ",
                "changes": 17
            },
            {
                "status": "modified",
                "additions": 18,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/hooks/build",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/hooks/build?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/hooks/build",
                "deletions": 2,
                "sha": "8b7d5329dcbbfce1bf55f48ac3b57bf00ecc07b8",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/hooks/build",
                "patch": "@@ -1,8 +1,24 @@\n #!/bin/bash\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n \n-echo \"------ escheduler start - build -------\"\n+echo \"------ dolphinscheduler start - build -------\"\n printenv\n \n docker build --build-arg version=$version --build-arg tar_version=$tar_version  -t $DOCKER_REPO:$version .\n \n-echo \"------ escheduler end   - build -------\"\n+echo \"------ dolphinscheduler end   - build -------\"",
                "changes": 20
            },
            {
                "status": "modified",
                "additions": 16,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/hooks/push",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/hooks/push?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/hooks/push",
                "deletions": 0,
                "sha": "6146727d456ad48abbb0f30f1cd6392029f6310f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/hooks/push",
                "patch": "@@ -1,4 +1,20 @@\n #!/bin/bash\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n \n echo \"------ push start -------\"\n printenv",
                "changes": 16
            },
            {
                "status": "modified",
                "additions": 49,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/startup.sh",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dockerfile/startup.sh?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dockerfile/startup.sh",
                "deletions": 55,
                "sha": "cc98d07e5706af79ae678aaf2a8e7d24132a22cf",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dockerfile/startup.sh",
                "patch": "@@ -1,78 +1,72 @@\n-#! /bin/bash\n+#!/bin/bash\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n \n set -e\n-if [ `netstat -anop|grep mysql|wc -l` -gt 0 ];then\n-                echo \"MySQL is Running.\"\n-else\n-\tMYSQL_ROOT_PWD=\"root@123\"\n-        ESZ_DB=\"escheduler\"\n-\techo \"\u542f\u52a8mysql\u670d\u52a1\"\n-\tchown -R mysql:mysql /var/lib/mysql /var/run/mysqld\n-\tfind /var/lib/mysql -type f -exec touch {} \\; && service mysql restart $ sleep 10\n-\tif [ ! -f /nohup.out ];then\n-\t\techo \"\u8bbe\u7f6emysql\u5bc6\u7801\"\n-\t\tmysql --user=root --password=root -e \"UPDATE mysql.user set authentication_string=password('$MYSQL_ROOT_PWD') where user='root'; FLUSH PRIVILEGES;\"\n-\n-\t\techo \"\u8bbe\u7f6emysql\u6743\u9650\"\n-\t\tmysql --user=root --password=$MYSQL_ROOT_PWD -e \"GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '$MYSQL_ROOT_PWD' WITH GRANT OPTION; FLUSH PRIVILEGES;\"\n-\t\techo \"\u521b\u5efaescheduler\u6570\u636e\u5e93\"\n-\t\tmysql --user=root --password=$MYSQL_ROOT_PWD -e \"CREATE DATABASE IF NOT EXISTS \\`$ESZ_DB\\` CHARACTER SET utf8 COLLATE utf8_general_ci; FLUSH PRIVILEGES;\"\n-\t\techo \"\u5bfc\u5165mysql\u6570\u636e\"\n-\t\tnohup /opt/escheduler/script/create_escheduler.sh &\n-\t\tsleep 90\n-\tfi\n-\t\n-\tif [ `mysql --user=root --password=$MYSQL_ROOT_PWD -s -r -e  \"SELECT count(TABLE_NAME) FROM information_schema.TABLES WHERE TABLE_SCHEMA='escheduler';\" | grep -v count` -eq 38 ];then\n-\t\techo \"\\`$ESZ_DB\\` \u8868\u4e2a\u6570\u6b63\u786e\"\n-\telse\n-\t\techo \"\\`$ESZ_DB\\` \u8868\u4e2a\u6570\u4e0d\u6b63\u786e\"\n-\t\tmysql --user=root --password=$MYSQL_ROOT_PWD  -e \"DROP DATABASE \\`$ESZ_DB\\`;\"\n-\t\techo \"\u521b\u5efaescheduler\u6570\u636e\u5e93\"\n-                mysql --user=root --password=$MYSQL_ROOT_PWD -e \"CREATE DATABASE IF NOT EXISTS \\`$ESZ_DB\\` CHARACTER SET utf8 COLLATE utf8_general_ci; FLUSH PRIVILEGES;\"\n-                echo \"\u5bfc\u5165mysql\u6570\u636e\"\n-                nohup /opt/escheduler/script/create_escheduler.sh &\n-                sleep 90\n-\tfi\n-fi\n-\n-/opt/zookeeper/bin/zkServer.sh restart \n+\techo \"start postgresql service\"\n+    /etc/init.d/postgresql restart\n+    echo \"create user and init db\"\n+    sudo -u postgres psql <<'ENDSSH'\n+create user root with password 'root@123';\n+create database dolphinscheduler owner root;\n+grant all privileges on database dolphinscheduler to root;\n+\\q\n+ENDSSH\n+    echo \"import sql data\"\n+    /opt/dolphinscheduler/script/create-dolphinscheduler.sh\n+\n+/opt/zookeeper/bin/zkServer.sh restart\n \n sleep 90\n \n-echo \"\u542f\u52a8api-server\"\n-/opt/escheduler/bin/escheduler-daemon.sh stop api-server\n-/opt/escheduler/bin/escheduler-daemon.sh start api-server\n+echo \"start api-server\"\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop api-server\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start api-server\n \n \n \n-echo \"\u542f\u52a8master-server\"\n-/opt/escheduler/bin/escheduler-daemon.sh stop master-server\n-python /opt/escheduler/script/del_zk_node.py 127.0.0.1 /escheduler/masters\n-/opt/escheduler/bin/escheduler-daemon.sh start master-server\n+echo \"start master-server\"\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop master-server\n+python /opt/dolphinscheduler/script/del-zk-node.py 127.0.0.1 /dolphinscheduler/masters\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start master-server\n \n-echo \"\u542f\u52a8worker-server\"\n-/opt/escheduler/bin/escheduler-daemon.sh stop worker-server\n-python /opt/escheduler/script/del_zk_node.py 127.0.0.1 /escheduler/workers\n-/opt/escheduler/bin/escheduler-daemon.sh start worker-server\n+echo \"start worker-server\"\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop worker-server\n+python /opt/dolphinscheduler/script/del-zk-node.py 127.0.0.1 /dolphinscheduler/workers\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start worker-server\n \n \n-echo \"\u542f\u52a8logger-server\"\n-/opt/escheduler/bin/escheduler-daemon.sh stop logger-server\n-/opt/escheduler/bin/escheduler-daemon.sh start logger-server\n+echo \"start logger-server\"\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop logger-server\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start logger-server\n \n \n-echo \"\u542f\u52a8alert-server\"\n-/opt/escheduler/bin/escheduler-daemon.sh stop alert-server\n-/opt/escheduler/bin/escheduler-daemon.sh start alert-server\n+echo \"start alert-server\"\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop alert-server\n+/opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start alert-server\n \n \n \n \n \n-echo \"\u542f\u52a8nginx\"\n+echo \"start nginx\"\n /etc/init.d/nginx stop\n nginx &\n-\t\n+\n \n while true\n do",
                "changes": 104
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.1-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.0.1-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.0.1-release.md",
                "deletions": 16,
                "sha": "8613d9352eb5fb5bce6e4c20f01ebd143f39db88",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.1-release.md",
                "patch": "@@ -1,16 +0,0 @@\n-Easy Scheduler Release 1.0.1\n-===\n-Easy Scheduler 1.0.1 is the second version in the 1.x series. The update is as follows:\n-\n-- 1,outlook TSL email support\n-- 2,servlet and protobuf jar conflict resolution\n-- 3,create a tenant and establish a Linux user at the same time\n-- 4,the re-run time is negative\n-- 5,stand-alone and cluster can be deployed with one click of install.sh\n-- 6,queue support interface added\n-- 7,escheduler.t_escheduler_queue added create_time and update_time fields\n-\n-\n-\n-\n-",
                "changes": 16
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.2-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.0.2-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.0.2-release.md",
                "deletions": 49,
                "sha": "502dbf8f9b2920368ae38ee58647b6938c83a48b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.2-release.md",
                "patch": "@@ -1,49 +0,0 @@\n-Easy Scheduler Release 1.0.2\n-===\n-Easy Scheduler 1.0.2 is the third version in the 1.x series. This version adds scheduling open interfaces, worker grouping (the machine group for which the specified task runs), task flow and service monitoring, and support for oracle, clickhouse, etc., as follows:\n-\n-New features:\n-===\n-- [[EasyScheduler-79](https://github.com/analysys/EasyScheduler/issues/79)] scheduling the open interface through the token mode, which can be operated through the api.\n-- [[EasyScheduler-138](https://github.com/analysys/EasyScheduler/issues/138)] can specify the machine (group) where the task runs.\n-- [[EasyScheduler-139](https://github.com/analysys/EasyScheduler/issues/139)] task Process Monitoring and Master, Worker, Zookeeper Operation Status Monitoring\n-- [[EasyScheduler-140](https://github.com/analysys/EasyScheduler/issues/140)] workflow Definition - Increase Process Timeout Alarm\n-- [[EasyScheduler-134](https://github.com/analysys/EasyScheduler/issues/134)] task type supports Oracle, CLICKHOUSE, SQLSERVER, IMPALA\n-- [[EasyScheduler-136](https://github.com/analysys/EasyScheduler/issues/136)]  sql task node can independently select CC mail users\n-- [[EasyScheduler-141](https://github.com/analysys/EasyScheduler/issues/141)] user Management\u2014Users can bind queues. The user queue level is higher than the tenant queue level. If the user queue is empty, look for the tenant queue.\n-\n-\n-\n-Enhanced\uff1a\n-===\n-- [[EasyScheduler-154](https://github.com/analysys/EasyScheduler/issues/154)] Tenant code allows encoding of pure numbers or underscores\n-\n-\n-Repair:\n-===\n-- [[EasyScheduler-135](https://github.com/analysys/EasyScheduler/issues/135)] Python task can specify python version\n-\n-- [[EasyScheduler-125](https://github.com/analysys/EasyScheduler/issues/125)] The mobile phone number in the user account does not recognize the opening of Unicom's latest number 166\n-\n-- [[EasyScheduler-178](https://github.com/analysys/EasyScheduler/issues/178)] Fix subtle spelling mistakes in ProcessDao\n-\n-- [[EasyScheduler-129](https://github.com/analysys/EasyScheduler/issues/129)] Tenant code, underlined and other special characters cannot pass the check.\n-\n-\n-Thank:\n-===\n-Last but not least, no new version was born without the contributions of the following partners:\n-\n-Baoqi , chubbyjiang , coreychen , chgxtony, cmdares , datuzi , dingchao, fanguanqun , \u98ce\u6e05\u626c, gaojun416 , googlechorme, hyperknob , hujiang75277381 , huanzui , kinssun, ivivi727 ,jimmy, jiangzhx , kevin5210 , lidongdai , lshmouse , lenboo, lyf198972 , lgcareer , lzy305 ,  moranrr ,  millionfor , mazhong8808, programlief, qiaozhanwei , roy110 , swxchappy , sherlock111 , samz406 , swxchappy, qq389401879 , lzy305,  vkingnew, William-GuoWei , woniulinux, yyl861, zhangxin1988, yangjiajun2014, yangqinlong, yangjiajun2014, zhzhenqin, zhangluck, zhanghaicheng1, zhuyizhizhi  \n-\n-And many enthusiastic partners in the WeChat group! Thank you very much!\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-",
                "changes": 49
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.3-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.0.3-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.0.3-release.md",
                "deletions": 30,
                "sha": "b87f8940117e85184f4f20b772a6446532169b5e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.3-release.md",
                "patch": "@@ -1,30 +0,0 @@\n-Easy Scheduler Release 1.0.3\n-===\n-Easy Scheduler 1.0.3 is the fourth version in the 1.x series.\n-\n-Enhanced\uff1a\n-===\n--  [[EasyScheduler-482]](https://github.com/analysys/EasyScheduler/issues/482)sql task mail header added support for custom variables\n--  [[EasyScheduler-483]](https://github.com/analysys/EasyScheduler/issues/483)sql task failed to send mail, then this sql task is failed\n--  [[EasyScheduler-484]](https://github.com/analysys/EasyScheduler/issues/484)modify the replacement rule of the custom variable in the sql task, and support the replacement of multiple single quotes and double quotes.\n--   [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/485)when creating a resource file, increase the verification that the resource file already exists on hdfs\n-\n-Repair:\n-===\n--  [[EasyScheduler-198]](https://github.com/analysys/EasyScheduler/issues/198) the process definition list is sorted according to the timing status and update time\n--  [[EasyScheduler-419]](https://github.com/analysys/EasyScheduler/issues/419)  fixes online creation of files, hdfs file is not created, but returns successfully\n--  [[EasyScheduler-481] ](https://github.com/analysys/EasyScheduler/issues/481)fixes the problem that the job does not exist at the same time.\n--  [[EasyScheduler-425]](https://github.com/analysys/EasyScheduler/issues/425) kills the kill of its child process when killing the task\n--  [[EasyScheduler-422]](https://github.com/analysys/EasyScheduler/issues/422) fixed an issue where the update time and size were not updated when updating resource files\n--  [[EasyScheduler-431]](https://github.com/analysys/EasyScheduler/issues/431) fixed an issue where deleting a tenant failed if hdfs was not started when the tenant was deleted\n--  [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/486) the shell process exits, the yarn state is not final and waits for judgment.\n-\n-Thank:\n-===\n-Last but not least, no new version was born without the contributions of the following partners:\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, \n-feloxx, coding-now, hymzcn, nysyxxg, chgxtony \n-\n-And many enthusiastic partners in the WeChat group! Thank you very much!\n-",
                "changes": 30
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.4-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.0.4-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.0.4-release.md",
                "deletions": 2,
                "sha": "f7b1089cc93c232d4a2c14fb64b153a570de7e72",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.4-release.md",
                "patch": "@@ -1,2 +0,0 @@\n-# 1.0.4 release\n-",
                "changes": 2
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.5-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.0.5-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.0.5-release.md",
                "deletions": 2,
                "sha": "ce945e28b1689d5deeb6d77583e5e8edb116b5c4",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.0.5-release.md",
                "patch": "@@ -1,2 +0,0 @@\n-# 1.0.5 release\n-",
                "changes": 2
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.1.0-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/1.1.0-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/1.1.0-release.md",
                "deletions": 55,
                "sha": "c9ebe71503e75b657e9f77f2b6255b8007e42a4d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/1.1.0-release.md",
                "patch": "@@ -1,55 +0,0 @@\n-Easy Scheduler Release 1.1.0\n-===\n-Easy Scheduler 1.1.0 is the first release in the 1.1.x series.\n-\n-New features:\n-===\n-- [[EasyScheduler-391](https://github.com/analysys/EasyScheduler/issues/391)] run a process under a specified tenement user\n-- [[EasyScheduler-288](https://github.com/analysys/EasyScheduler/issues/288)] feature/qiye_weixin\n-- [[EasyScheduler-189](https://github.com/analysys/EasyScheduler/issues/189)] security support such as Kerberos\n-- [[EasyScheduler-398](https://github.com/analysys/EasyScheduler/issues/398)]dministrator, with tenants (install.sh set default tenant), can create resources, projects and data sources (limited to one administrator)\n-- [[EasyScheduler-293](https://github.com/analysys/EasyScheduler/issues/293)]click on the parameter selected when running the process, there is no place to view, no save\n-- [[EasyScheduler-401](https://github.com/analysys/EasyScheduler/issues/401)]timing is easy to time every second. After the timing is completed, you can display the next trigger time on the page.\n-- [[EasyScheduler-493](https://github.com/analysys/EasyScheduler/pull/493)]add datasource kerberos auth and FAQ modify and add resource upload s3\n-\n-\n-Enhanced\uff1a\n-===\n-- [[EasyScheduler-227](https://github.com/analysys/EasyScheduler/issues/227)] upgrade spring-boot to 2.1.x and spring to 5.x\n-- [[EasyScheduler-434](https://github.com/analysys/EasyScheduler/issues/434)] number of worker nodes zk and mysql are inconsistent\n-- [[EasyScheduler-435](https://github.com/analysys/EasyScheduler/issues/435)]authentication of the mailbox format\n-- [[EasyScheduler-441](https://github.com/analysys/EasyScheduler/issues/441)] prohibits running nodes from joining completed node detection\n-- [[EasyScheduler-400](https://github.com/analysys/EasyScheduler/issues/400)] Home page, queue statistics are not harmonious, command statistics have no data\n-- [[EasyScheduler-395](https://github.com/analysys/EasyScheduler/issues/395)] For fault-tolerant recovery processes, the status cannot be ** is running\n-- [[EasyScheduler-529](https://github.com/analysys/EasyScheduler/issues/529)] optimize poll task from zookeeper\n-- [[EasyScheduler-242](https://github.com/analysys/EasyScheduler/issues/242)]worker-server node gets task performance problem\n-- [[EasyScheduler-352](https://github.com/analysys/EasyScheduler/issues/352)]worker grouping, queue consumption problem\n-- [[EasyScheduler-461](https://github.com/analysys/EasyScheduler/issues/461)]view data source parameters, need to encrypt account password information\n-- [[EasyScheduler-396](https://github.com/analysys/EasyScheduler/issues/396)]Dockerfile optimization, and associated Dockerfile and github to achieve automatic mirroring\n-- [[EasyScheduler-389](https://github.com/analysys/EasyScheduler/issues/389)]service monitor cannot find the change of master/worker\n-- [[EasyScheduler-511](https://github.com/analysys/EasyScheduler/issues/511)]support recovery process from stop/kill nodes.\n-- [[EasyScheduler-399](https://github.com/analysys/EasyScheduler/issues/399)]HadoopUtils specifies user actions instead of **Deploying users\n-\n-Repair:\n-===\n-- [[EasyScheduler-394](https://github.com/analysys/EasyScheduler/issues/394)] When the master&worker is deployed on the same machine, if the master&worker service is restarted, the previously scheduled tasks cannot be scheduled.\n-- [[EasyScheduler-469](https://github.com/analysys/EasyScheduler/issues/469)]Fix naming errors,monitor page\n-- [[EasyScheduler-392](https://github.com/analysys/EasyScheduler/issues/392)]Feature request: fix email regex check\n-- [[EasyScheduler-405](https://github.com/analysys/EasyScheduler/issues/405)]timed modification/addition page, start time and end time cannot be the same\n-- [[EasyScheduler-517](https://github.com/analysys/EasyScheduler/issues/517)]complement - subworkflow - time parameter \n-- [[EasyScheduler-532](https://github.com/analysys/EasyScheduler/issues/532)] python node does not execute the problem\n-- [[EasyScheduler-543](https://github.com/analysys/EasyScheduler/issues/543)]optimize datasource connection params safety\n-- [[EasyScheduler-569](https://github.com/analysys/EasyScheduler/issues/569)] timed tasks can't really stop\n-- [[EasyScheduler-463](https://github.com/analysys/EasyScheduler/issues/463)]mailbox verification does not support very suffixed mailboxes\n-\n-\n-\n-\n-Thank:\n-===\n-Last but not least, no new version was born without the contributions of the following partners:\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, chgxtony, Stanfan, lfyee, thisnew, hujiang75277381, sunnyingit, lgbo-ustc, ivivi, lzy305, JackIllkid, telltime, lipengbo2018, wuchunfu, telltime\n-\n-And many enthusiastic partners in the WeChat group! Thank you very much!\n-",
                "changes": 55
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/EasyScheduler%20Proposal.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/EasyScheduler%20Proposal.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/EasyScheduler Proposal.md",
                "deletions": 299,
                "sha": "6bcea73540e884eeaf08e034320bbd0132902616",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/EasyScheduler%20Proposal.md",
                "patch": "@@ -1,299 +0,0 @@\n-# EasyScheduler Proposal\n-\n-## Abstract\n-\n-EasyScheduler is a distributed ETL scheduling engine with powerful DAG visualization interface. EasyScheduler focuses on solving the problem of 'complex task dependencies & triggers ' in data processing. Just like its name, we dedicated to making the scheduling system `out of the box`. \n-\n-## Proposal\n-\n-EasyScheduler provides many easy-to-use features to accelerate the engineer efficiency on data ETL workflow job. We propose a new concept of 'instance of process' and 'instance of task' to let developers to tuning their jobs on the running state of workflow instead of changing the task's template. Its main objectives are as follows:\n-\n-- Define the complex tasks' dependencies & triggers  in a DAG graph by dragging and dropping.\n-- Support cluster HA.\n-- Support multi-tenant and parallel or serial backfilling data.\n-- Support automatical failure job retry and recovery.\n-- Support many data task types and process priority, task priority and relative task timeout alarm.\n-\n-For now, EasyScheduler has a fairly huge community in China. \n-It is also widely adopted by many [companies and organizations](https://github.com/analysys/EasyScheduler/issues/57) as its ETL scheduling tool. \n-\n-We believe that bringing EasyScheduler into ASF could advance development of a much more stronger and more diverse open source community.\n-\n-Analysys submits this proposal to donate EasyScheduler's source codes and all related documentations to Apache Software Foundation. \n-The codes are already under Apache License Version 2.0.\n-\n-- Code base: https://www.github.com/analysys/easyscheduler\n-- English Documentations: <https://analysys.github.io/easyscheduler_docs>\n-- Chinese Documentations: <https://analysys.github.io/easyscheduler_docs_cn>\n-\n-## Background\n-\n-We want to find a data processing tool with the following features:\n-\n-- Easy to use\uff0cdevelopers can build a ETL process with a very simple drag and drop operation. not only for ETL developers\uff0cpeople who can't write code also can use this tool for ETL operation such as system administrator.\n-- Solving the problem of \"complex  task dependencies\" , and it can monitor the ETL running status. \n-- Support multi-tenant.\n-- Support many task types: Shell, MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Sub_Process, Procedure, etc.\n-- Support HA and linear scalability.\n-\n-For the above reasons, we realized that no existing product met our requirements, so we decided to develop this tool ourselves. We designed EasyScheduler at the end of 2017. The first internal use version was completed in May 2018. We then iterated several internal versions and the system gradually became stabilized. \n-\n-Then we open the source code of EasyScheduler on March 2019. It soon gained lot's of ETL developers interest and stars on github. \n-\n-## Rationale\n-\n-Many organizations (>30) (refer to [Who is using EasyScheduler](https://github.com/analysys/EasyScheduler/issues/57) ) already benefit from running EasyScheduler to make data process pipelines more easier. More than 100  [feature ideas](https://github.com/analysys/EasyScheduler/projects/1) come from EasyScheduler community.   Some 3rd-party projects also plan to integrate with EasyScheduler through task plugin, such as [Scriptis](https://github.com/WeBankFinTech/Scriptis), [waterdrop](https://github.com/InterestingLab/waterdrop). These will strengthen the features of EasyScheduler.   \n-\n-## Current Status\n-\n-### Meritocracy\n-\n-EasyScheduler was incubated at Analysys in 2017 and open sourced on GitHub in March 2019.  Once open sourced, we have been quickly adopted by multiple organizations\uff0cEasyScheduler has contributors and users from many companies; we have set up the Committer Team. New contributors are guided and reviewed by existed committer members. \n-Contributions are always welcomed and highly valued. \n-\n-### Community\n-\n-Now we have set development teams for EasyScheduler in Analysys, and we already have external developers who contributed the code.  We already have a user group of more than 1,000 people. \n-We hope to grow the base of contributors by inviting all those who offer contributions through The Apache Way. \n-Right now, we make use of github as code hosting as well as gitter for community communication.\n-\n-### Core Developers\n-\n-The core developers, including experienced senior developers, are often guided by mentors.\n-\n-## Known Risks\n-\n-### Orphaned products\n-\n-EasyScheduler is widely adopted in China by many [companies and organizations](https://github.com/analysys/EasyScheduler/issues/57). The core developers of EasyScheduler team plan to work full time on this project. Currently there are 10 use cases with more that 1000 activity tasks per day using EasyScheduler in the user's production environment. There is very little risk of EasyScheduler getting orphaned as at least two large companies (xueqiu\u3001fengjr) are widely using it in their production, and developers from these companies have also joined Easy Scheduler's team of contributors, EasyScheduler has eight major releases so far, and and received 373 pull requests from contributors, which further demonstrates EasyScheduler as a very active project. We also plan to extend and diversify this community further through Apache.\n-\n-Thus, it is very unlikely that EasyScheduler becomes orphaned.\n-\n-### Inexperience with Open Source\n-\n-EasyScheduler's core developers have been running it as a community-oriented open source project for some time, several of them already have experience working with open source communities, they are also active in presto, alluxio and other projects. At the same time, we will learn more open source experiences by following the Apache way in our incubator journey.\n-\n-### Homogeneous Developers\n-\n-The current developers work across a variety of organizations including Analysys, guandata and hydee; \n-some individual developers are accepted as developers of EasyScheduler as well. \n-Considering that fengjr and sefonsoft have shown great interests in EasyScheduler, we plan to encourage them to contribute and invite them as contributors to work together.\n-\n-### Reliance on Salaried Developers\n-\n-At present, eight of the core developers are paid by their employer to contribute to EasyScheduler project. \n-we also have some other developers and researchers taking part in the project, and we will make efforts to increase the diversity of the contributors and actively lobby for Domain experts in the workflow space to contribute. \n-\n-### Relationships with Other Apache Products\n-\n-EasyScheduler integrates Apache Zookeeper as one of the service registration/discovery mechanisms. EasyScheduler is deeply integrated with Apache products. It currently support many task types like  Apache Hive, Apache Spark, Apache Hadoop, and so on\n-\n-### A Excessive Fascination with the Apache Brand\n-\n-We recognize the value and reputation that the Apache brand will bring to EasyScheduler.\n-However, we prefer that the community provided by the Apache Software Foundation will enable the project to achieve long-term stable development. so EasyScheduler is proposing to enter incubation at Apache in order to help efforts to diversify the community, not so much to capitalize on the Apache brand.\n-\n-## Documentation\n-\n-A complete set of EasyScheduler documentations is provided on github in both English and Simplified Chinese.\n-\n-- [English](https://github.com/analysys/easyscheduler_docs)\n-- [Chinese](https://github.com/analysys/easyscheduler_docs_cn)\n-\n-## Initial Source\n-\n-The project consists of three distinct codebases: core and document. The address of two existed git repositories are as follows:\n-\n-- <https://github.com/analysys/easyscheduler>\n-- <https://github.com/analysys/easyscheduler_docs> \n-- <https://github.com/analysys/easyscheduler_docs_cn> \n-\n-## Source and Intellectual Property Submission Plan\n-\n-As soon as EasyScheduler is approved to join Apache Incubator, Analysys will provide the Software Grant Agreement(SGA) and initial committers will submit ICLA(s). The code is already licensed under the Apache Software License, version 2.0. \n-\n-## External Dependencies\n-\n-As all backend code dependencies are managed using Apache Maven, none of the external libraries need to be packaged in a source distribution. \n-\n-Most of dependencies have Apache compatible licenses\uff0cand the core dependencies are as follows:\n-\n-### Backend Dependency\n-\n-| Dependency                                             | License                                                      | Comments      |\n-| ------------------------------------------------------ | ------------------------------------------------------------ | ------------- |\n-| bonecp-0.8.0.RELEASE.jar                               | Apache v2.0                                                  |               |\n-| byte-buddy-1.9.10.jar                                  | Apache V2.0                                                  |               |\n-| c3p0-0.9.1.1.jar                                       | GNU LESSER GENERAL   PUBLIC LICENSE                          | will   remove |\n-| curator-*-2.12.0.jar                                   | Apache V2.0                                                  |               |\n-| druid-1.1.14.jar                                       | Apache V2.0                                                  |               |\n-| fastjson-1.2.29.jar                                    | Apache V2.0                                                  |               |\n-| fastutil-6.5.6.jar                                     | Apache V2.0                                                  |               |\n-| grpc-*-1.9.0.jar                                       | Apache V2.0                                                  |               |\n-| gson-2.8.5.jar                                         | Apache V2.0                                                  |               |\n-| guava-20.0.jar                                         | Apache V2.0                                                  |               |\n-| guice-*3.0.jar                                         | Apache V2.0                                                  |               |\n-| hadoop-*-2.7.3.jar                                     | Apache V2.0                                                  |               |\n-| hbase-*-1.1.1.jar                                      | Apache V2.0                                                  |               |\n-| hive-*-2.1.0.jar                                       | Apache V2.0                                                  |               |\n-| instrumentation-api-0.4.3.jar                          | Apache V2.0                                                  |               |\n-| jackson-*-2.9.8.jar                                    | Apache V2.0                                                  |               |\n-| jackson-jaxrs-1.8.3.jar                                | LGPL Version 2.1    Apache V2.0                              | will   remove |\n-| jackson-xc-1.8.3.jar                                   | LGPL Version 2.1    Apache V2.0                              | will   remove |\n-| javax.activation-api-1.2.0.jar                         | CDDL/GPLv2+CE                                                | will   remove |\n-| javax.annotation-api-1.3.2.jar                         | CDDL + GPLv2 with   classpath exception                      | will   remove |\n-| javax.servlet-api-3.1.0.jar                            | CDDL + GPLv2 with   classpath exception                      | will   remove |\n-| jaxb-*.jar                                             | (CDDL 1.1) (GPL2 w/   CPE)                                   | will   remove |\n-| jersey-*-1.9.jar                                       | CDDL+GPLv2                                                   | will   remove |\n-| jetty-*-9.4.14.v20181114.jar                           | Apache V2.0\uff0cEPL 1.0                                         |               |\n-| jna-4.5.2.jar                                          | Apache V2.0\uff0cLGPL 2.1                                        | will   remove |\n-| jna-platform-4.5.2.jar                                 | Apache V2.0\uff0cLGPL 2.1                                        | will   remove |\n-| jsp-api-2.x.jar                                        | CDDL\uff0cGPL 2.0                                                | will   remove |\n-| log4j-1.2.17.jar                                       | Apache V2.0                                                  |               |\n-| log4j-*-2.11.2.jar                                     | Apache V2.0                                                  |               |\n-| logback-x.jar                                          | dual-license      EPL 1.0,LGPL 2.1                           |               |\n-| mail-1.4.5.jar                                         | CDDL+GPLv2                                                   | will   remove |\n-| mybatis-3.5.1.jar                                      | Apache V2.0                                                  |               |\n-| mybatis-spring-*2.0.1.jar                              | Apache V2.0                                                  |               |\n-| mysql-connector-java-5.1.34.jar                        | GPL 2.0                                                      | will   remove |\n-| netty-*-4.1.33.Final.jar                               | Apache V2.0                                                  |               |\n-| oshi-core-3.5.0.jar                                    | EPL 1.0                                                      |               |\n-| parquet-hadoop-bundle-1.8.1.jar                        | Apache V2.0                                                  |               |\n-| postgresql-42.1.4.jar                                  | BSD 2-clause                                                 |               |\n-| protobuf-java-*3.5.1.jar                               | BSD 3-clause                                                 |               |\n-| quartz-2.2.3.jar                                       | Apache V2.0                                                  |               |\n-| quartz-jobs-2.2.3.jar                                  | Apache V2.0                                                  |               |\n-| slf4j-api-1.7.5.jar                                    | MIT                                                          |               |\n-| spring-*-5.1.5.RELEASE.jar                             | Apache V2.0                                                  |               |\n-| spring-beans-5.1.5.RELEASE.jar                         | Apache V2.0                                                  |               |\n-| spring-boot-*2.1.3.RELEASE.jar                         | Apache V2.0                                                  |               |\n-| springfox-*-2.9.2.jar                                  | Apache V2.0                                                  |               |\n-| stringtemplate-3.2.1.jar                               | BSD                                                          |               |\n-| swagger-annotations-1.5.20.jar                         | Apache V2.0                                                  |               |\n-| swagger-bootstrap-ui-1.9.3.jar                         | Apache V2.0                                                  |               |\n-| swagger-models-1.5.20.jar                              | Apache V2.0                                                  |               |\n-| zookeeper-3.4.8.jar                                    | Apache                                                       |               |\n-\n-\n-\n-\n-The front-end UI currently relies on many components, and the core dependencies are as follows:\n-\n-### UI Dependency\n-\n-| Dependency                                              | License                              | Comments    |\n-| ------------------------------------------------------- | ------------------------------------ | ----------- |\n-| autoprefixer                                            | MIT                                  |             |\n-| babel-core                                              | MIT                                  |             |\n-| babel-eslint                                            | MIT                                  |             |\n-| babel-helper-*                                          | MIT                                  |             |\n-| babel-helpers                                           | MIT                                  |             |\n-| babel-loader                                            | MIT                                  |             |\n-| babel-plugin-syntax-*                                   | MIT                                  |             |\n-| babel-plugin-transform-*                                | MIT                                  |             |\n-| babel-preset-env                                        | MIT                                  |             |\n-| babel-runtime                                           | MIT                                  |             |\n-| bootstrap                                               | MIT                                  |             |\n-| canvg                                                   | MIT                                  |             |\n-| clipboard                                               | MIT                                  |             |\n-| codemirror                                              | MIT                                  |             |\n-| copy-webpack-plugin                                     | MIT                                  |             |\n-| cross-env                                               | MIT                                  |             |\n-| css-loader                                              | MIT                                  |             |\n-| cssnano                                                 | MIT                                  |             |\n-| cyclist                                                 | MIT                                  |             |\n-| d3                                                      | BSD-3-Clause                         |             |\n-| dayjs                                                   | MIT                                  |             |\n-| echarts                                                 | Apache V2.0                          |             |\n-| env-parse                                               | ISC                                  |             |\n-| extract-text-webpack-plugin                             | MIT                                  |             |\n-| file-loader                                             | MIT                                  |             |\n-| globby                                                  | MIT                                  |             |\n-| html-loader                                             | MIT                                  |             |\n-| html-webpack-ext-plugin                                 | MIT                                  |             |\n-| html-webpack-plugin                                     | MIT                                  |             |\n-| html2canvas                                             | MIT                                  |             |\n-| jsplumb                                                 | (MIT OR GPL-2.0)                     |             |\n-| lodash                                                  | MIT                                  |             |\n-| node-sass                                               | MIT                                  |             |\n-| optimize-css-assets-webpack-plugin                      | MIT                                  |             |\n-| postcss-loader                                          | MIT                                  |             |\n-| rimraf                                                  | ISC                                  |             |\n-| sass-loader                                             | MIT                                  |             |\n-| uglifyjs-webpack-plugin                                 | MIT                                  |             |\n-| url-loader                                              | MIT                                  |             |\n-| util.promisify                                          | MIT                                  |             |\n-| vue                                                     | MIT                                  |             |\n-| vue-loader                                              | MIT                                  |             |\n-| vue-style-loader                                        | MIT                                  |             |\n-| vue-template-compiler                                   | MIT                                  |             |\n-| vuex-router-sync                                        | MIT                                  |             |\n-| watchpack                                               | MIT                                  |             |\n-| webpack                                                 | MIT                                  |             |\n-| webpack-dev-server                                      | MIT                                  |             |\n-| webpack-merge                                           | MIT                                  |             |\n-| xmldom                                                  | MIT,LGPL                             | will remove |\n-\n-\n-## Required Resources\n-\n-### Git Repositories\n-\n-- <https://github.com/analysys/EasyScheduler.git>\n-- <https://github.com/analysys/easyscheduler_docs.git>\n-- <https://github.com/analysys/easyscheduler_docs_cn.git>\n-\n-### Issue Tracking\n-\n-The community would like to continue using GitHub Issues.\n-\n-### Continuous Integration tool\n-\n-Jenkins\n-\n-### Mailing Lists\n-\n-- EasyScheduler-dev: for development discussions\n-- EasyScheduler-private: for PPMC discussions\n-- EasyScheduler-notifications: for users notifications\n-\n-## Initial Committers\n-\n-- William-GuoWei(guowei20m@outlook.com)\n-- Lidong Dai(lidong.dai@outlook.com)\n-- Zhanwei Qiao(qiaozhanwei@outlook.com)\n-- Liang Bao(baoliang.leon@gmail.com)\n-- Gang Li(lgcareer2019@outlook.com)\n-- Zijian Gong(quanquansy@gmail.com)\n-- Jun Gao(gaojun2048@gmail.com)\n-- Baoqi Wu(wubaoqi@gmail.com)\n-\n-## Affiliations\n-\n-- Analysys Inc: William-GuoWei\uff0cZhanwei Qiao\uff0cLiang Bao\uff0cGang Li\uff0cJun Gao\uff0cLidong Dai\n-\n-- Hydee Inc: Zijian Gong\n-\n-- Guandata Inc: Baoqi Wu\n-\n-  \n-\n-## Sponsors\n-\n-### Champion\n-\n-- Sheng Wu ( Apache Incubator PMC, [wusheng@apache.org](mailto:wusheng@apache.org))\n-\n-### Mentors\n-\n-- Sheng Wu ( Apache Incubator PMC,  [wusheng@apache.org](mailto:wusheng@apache.org))\n-\n-- ShaoFeng Shi  ( Apache Incubator PMC,  [shaofengshi@apache.org](mailto:wusheng@apache.org))\n-\n-- Liang Chen ( Apache Software Foundation Member,  [chenliang613@apache.org](mailto:chenliang613@apache.org))\n-\n-  \n-\n-### Sponsoring Entity\n-\n-We are expecting the Apache Incubator could sponsor this project.",
                "changes": 299
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/EasyScheduler-FAQ.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/EasyScheduler-FAQ.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/EasyScheduler-FAQ.md",
                "deletions": 284,
                "sha": "b55b0e2413925c3b37acc0bf408515d782c0042e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/EasyScheduler-FAQ.md",
                "patch": "@@ -1,284 +0,0 @@\n-## Q: EasyScheduler service introduction and recommended running memory\n-\n-A: EasyScheduler consists of 5 services, MasterServer, WorkerServer, ApiServer, AlertServer, LoggerServer and UI.\n-\n-| Service                   | Description                                                  |\n-| ------------------------- | ------------------------------------------------------------ |\n-| MasterServer              | Mainly responsible for DAG segmentation and task status monitoring |\n-| WorkerServer/LoggerServer | Mainly responsible for the submission, execution and update of task status. LoggerServer is used for Rest Api to view logs through RPC |\n-| ApiServer                 | Provides the Rest Api service for the UI to call             |\n-| AlertServer               | Provide alarm service                                        |\n-| UI                        | Front page display                                           |\n-\n-Note\uff1a**Due to the large number of services, it is recommended that the single-machine deployment is preferably 4 cores and 16G or more.**\n-\n----\n-\n-## Q: Why can't an administrator create a project?\n-\n-A: The administrator is currently \"**pure management**\". There is no tenant, that is, there is no corresponding user on linux, so there is no execution permission, **so there is no project, resource and data source,** so there is no permission to create. **But there are all viewing permissions**. If you need to create a business operation such as a project, **use the administrator to create a tenant and a normal user, and then use the normal user login to operate**. We will release the administrator's creation and execution permissions in version 1.1.0, and the administrator will have all permissions.\n-\n----\n-\n-## Q: Which mailboxes does the system support?\n-\n-A: Support most mailboxes, qq, 163, 126, 139, outlook, aliyun, etc. are supported. Support TLS and SSL protocols, optionally configured in alert.properties\n-\n----\n-\n-## Q: What are the common system variable time parameters and how do I use them?\n-\n-A: Please refer to 'System parameter' in the system-manual \n-\n----\n-\n-## Q: pip install kazoo This installation gives an error. Is it necessary to install?\n-\n-A: This is the python connection zookeeper needs to use, must be installed\n-\n----\n-\n-## Q: How to specify the machine running task\n-\n-A: Use **the administrator** to create a Worker group, **specify the Worker group** when the **process definition starts**, or **specify the Worker group on the task node**. If not specified, use Default, **Default is to select one of all the workers in the cluster to use for task submission and execution.**\n-\n----\n-\n-## Q: Priority of the task\n-\n-A: We also support **the priority of processes and tasks**. Priority We have five levels of **HIGHEST, HIGH, MEDIUM, LOW and LOWEST**. **You can set the priority between different process instances, or you can set the priority of different task instances in the same process instance.** For details, please refer to the task priority design in the architecture-design.\n-\n-----\n-\n-## Q: Escheduler-grpc gives an error\n-\n-A: Execute in the root directory: mvn -U clean package assembly:assembly -Dmaven.test.skip=true , then refresh the entire project\n-\n-----\n-\n-## Q: Does EasyScheduler support running on windows?\n-\n-A: In theory, **only the Worker needs to run on Linux**. Other services can run normally on Windows. But it is still recommended to deploy on Linux.\n-\n------\n-\n-## Q: UI compiles node-sass prompt in linux: Error: EACCESS: permission denied, mkdir xxxx\n-\n-A: Install **npm install node-sass --unsafe-perm** separately, then **npm install**\n-\n----\n-\n-## Q: UI cannot log in normally.\n-\n-A: 1, if it is node startup, check whether the .env API_BASE configuration under escheduler-ui is the Api Server service address.\n-\n-    2, If it is nginx booted and installed via **install-escheduler-ui.sh**, check if the proxy_pass configuration in **/etc/nginx/conf.d/escheduler.conf** is the Api Server service. address\n-    \n-    \u00a03, if the above configuration is correct, then please check if the Api Server service is normal, curl http://192.168.xx.xx:12345/escheduler/users/get-user-info, check the Api Server log, if Prompt cn.escheduler.api.interceptor.LoginHandlerInterceptor:[76] - session info is null, which proves that the Api Server service is normal.\n-    \n-    4, if there is no problem above, you need to check if **server.context-path and server.port configuration** in **application.properties** is correct\n-\n----\n-\n-## Q: After the process definition is manually started or scheduled, no process instance is generated.\n-\n-A:   1, first **check whether the MasterServer service exists through jps**, or directly check whether there is a master service in zk from the service monitoring.\n-\n-\u200b       2,If there is a master service, check **the command status statistics** or whether new records are added in **t_escheduler_error_command**. If it is added, **please check the message field.**\n-\n----\n-\n-## Q : The task status is always in the successful submission status.\n-\n-A:   1, **first check whether the WorkerServer service exists through jps**, or directly check whether there is a worker service in zk from the service monitoring.\n-\n-\u200b       2,If the **WorkerServer** service is normal, you need to **check whether the MasterServer puts the task task in the zk queue. You need to check whether the task is blocked in the MasterServer log and the zk queue.**\n-\n-\u200b       3, if there is no problem above, you need to locate whether the Worker group is specified, but **the machine grouped by the worker is not online**.**\n-\n----\n-\n-## Q: Is there a Docker image and a Dockerfile?\n-\n-A: Provide Docker image and Dockerfile.\n-\n-Docker image address: https://hub.docker.com/r/escheduler/escheduler_images\n-\n-Dockerfile address: https://github.com/qiaozhanwei/escheduler_dockerfile/tree/master/docker_escheduler\n-\n-------\n-\n-## Q : Need to pay attention to the problem in install.sh\n-\n-A:   1, if the replacement variable contains special characters, **use the \\ transfer character to transfer**\n-\n-\u200b       2, installPath=\"/data1_1T/escheduler\", **this directory can not be the same as the install.sh directory currently installed with one click.**\n-\n-\u200b       3, deployUser = \"escheduler\", **the deployment user must have sudo privileges**, because the worker is executed by sudo -u tenant sh xxx.command\n-\n-\u200b       4, monitorServerState = \"false\", whether the service monitoring script is started, the default is not to start the service monitoring script. **If the service monitoring script is started, the master and worker services are monitored every 5 minutes, and if the machine is down, it will automatically restart.**\n-\n-\u200b       5, hdfsStartupSate=\"false\", whether to enable HDFS resource upload function. The default is not enabled. **If it is not enabled, the resource center cannot be used.** If enabled, you need to configure the configuration of fs.defaultFS and yarn in conf/common/hadoop/hadoop.properties. If you use namenode HA, you need to copy core-site.xml and hdfs-site.xml to the conf root directory.\n-\n-\u200b    Note: **The 1.0.x version does not automatically create the hdfs root directory, you need to create it yourself, and you need to deploy the user with hdfs operation permission.**\n-\n----\n-\n-## Q : Process definition and process instance offline exception\n-\n-A : For **versions prior to 1.0.4**, modify the code under the escheduler-api cn.escheduler.api.quartz package.\n-\n-```\n-public boolean deleteJob(String jobName, String jobGroupName) {\n-    lock.writeLock().lock();\n-    try {\n-      JobKey jobKey = new JobKey(jobName,jobGroupName);\n-      if(scheduler.checkExists(jobKey)){\n-        logger.info(\"try to delete job, job name: {}, job group name: {},\", jobName, jobGroupName);\n-        return scheduler.deleteJob(jobKey);\n-      }else {\n-        return true;\n-      }\n-\n-    } catch (SchedulerException e) {\n-      logger.error(String.format(\"delete job : %s failed\",jobName), e);\n-    } finally {\n-      lock.writeLock().unlock();\n-    }\n-    return false;\n-  }\n-```\n-\n----\n-\n-## Q: Can the tenant created before the HDFS startup use the resource center normally?\n-\n-A: No. Because the tenant created by HDFS is not started, the tenant directory will not be registered in HDFS. So the last resource will report an error.\n-\n-## Q: In the multi-master and multi-worker state, the service is lost, how to be fault-tolerant\n-\n-A: **Note:** **Master monitors Master and Worker services.**\n-\n-\u200b    1\uff0cIf the Master service is lost, other Masters will take over the process of the hanged Master and continue to monitor the Worker task status.\n-\n-\u200b    2\uff0cIf the Worker service is lost, the Master will monitor that the Worker service is gone. If there is a Yarn task, the Kill Yarn task will be retried.\n-\n-Please see the fault-tolerant design in the architecture for details.\n-\n----\n-\n-## Q : Fault tolerance for a machine distributed by Master and Worker\n-\n-A: The 1.0.3 version only implements the fault tolerance of the Master startup process, and does not take the Worker Fault Tolerance. That is to say, if the Worker hangs, no Master exists. There will be problems with this process. We will add Master and Worker startup fault tolerance in version **1.1.0** to fix this problem. If you want to manually modify this problem, you need to **modify the running task for the running worker task that is running the process across the restart and has been dropped. The running process is set to the failed state across the restart**. Then resume the process from the failed node.\n-\n----\n-\n-## Q : Timing is easy to set to execute every second\n-\n-A : Note when setting the timing. If the first digit (* * * * * ? *) is set to *, it means execution every second. **We will add a list of recently scheduled times in version 1.1.0.** You can see the last 5 running times online at http://cron.qqe2.com/\n-\n-\n-\n-## Q: Is there a valid time range for timing?\n-\n-A: Yes, **if the timing start and end time is the same time, then this timing will be invalid timing. If the end time of the start and end time is smaller than the current time, it is very likely that the timing will be automatically deleted.**\n-\n-\n-\n-## Q : There are several implementations of task dependencies\n-\n-A\uff1a\t1, the task dependency between **DAG**, is **from the zero degree** of the DAG segmentation\n-\n-\u200b\t2, there are **task dependent nodes**, you can achieve cross-process tasks or process dependencies, please refer to the (DEPENDENT) node design in the system-manual. \n-\n-\u200b\tNote: **Cross-project processes or task dependencies are not supported**\n-\n-## Q: There are several ways to start the process definition.\n-\n-A:   1, in **the process definition list**, click the **Start** button.\n-\n-\u200b       2, **the process definition list adds a timer**, scheduling start process definition.\n-\n-\u200b       3, process definition **view or edit** the DAG page, any **task node right click** Start process definition.\n-\n-\u200b       4, you can define DAG editing for the process, set the running flag of some tasks to **prohibit running**, when the process definition is started, the connection of the node will be removed from the DAG.\n-\n-\n-\n-## Q : Python task setting Python version\n-\n-A\uff1a  1\uff0c**for the version after 1.0.3** only need to modify PYTHON_HOME in conf/env/.escheduler_env.sh\n-\n-```\n-export PYTHON_HOME=/bin/python\n-```\n-\n-Note: This is **PYTHON_HOME** , which is the absolute path of the python command, not the simple PYTHON_HOME. Also note that when exporting the PATH, you need to directly\n-\n-```\n-export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH\n-```\n-\n-\u200b\t2\uff0cFor versions prior to 1.0.3, the Python task only supports the Python version of the system. It does not support specifying the Python version.\n-\n-## Q\uff1aWorker Task will generate a child process through sudo -u tenant sh xxx.command, will kill when kill\n-\n-A\uff1a  We will add the kill task in 1.0.4 and kill all the various child processes generated by the task.\n-\n-\n-\n-## Q \uff1a How to use the queue in EasyScheduler, what does the user queue and tenant queue mean?\n-\n-A \uff1a The queue in the EasyScheduler can be configured on the user or the tenant. **The priority of the queue specified by the user is higher than the priority of the tenant queue.** For example, to specify a queue for an MR task, the queue is specified by mapreduce.job.queuename.\n-\n-Note: When using the above method to specify the queue, the MR uses the following methods:\n-\n-```\n-\tConfiguration conf = new Configuration();\n-        GenericOptionsParser optionParser = new GenericOptionsParser(conf, args);\n-        String[] remainingArgs = optionParser.getRemainingArgs();\n-```\n-\n-\n-\n-If it is a Spark task --queue mode specifies the queue\n-\n-\n-\n-## Q : Master or Worker reports the following alarm\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/master_worker_lack_res.png\" width=\"60%\" />\n- </p>\n-\n-\n-\n-A \uff1a Change the value of master.properties **master.reserved.memory** under conf to a smaller value, say 0.1 or the value of worker.properties **worker.reserved.memory** is a smaller value, say 0.1\n-\n-## Q: The hive version is 1.1.0+cdh5.15.0, and the SQL hive task connection is reported incorrectly.\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/cdh_hive_error.png\" width=\"60%\" />\n- </p>\n-\n-\n-A \uff1a Will hive pom\n-\n-```\n-<dependency>\n-    <groupId>org.apache.hive</groupId>\n-    <artifactId>hive-jdbc</artifactId>\n-    <version>2.1.0</version>\n-</dependency>\n-```\n-\n-change into\n-\n-```\n-<dependency>\n-    <groupId>org.apache.hive</groupId>\n-    <artifactId>hive-jdbc</artifactId>\n-    <version>1.1.0</version>\n-</dependency>\n-```\n-",
                "changes": 284
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/README.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/README.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/README.md",
                "deletions": 96,
                "sha": "05380d0212c93bd9499aaaa02f3f8b81b3e51e0e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/README.md",
                "patch": "@@ -1,96 +0,0 @@\n-Easy Scheduler\n-============\n-[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n-[![Total Lines](https://tokei.rs/b1/github/analysys/EasyScheduler?category=lines)](https://github.com/analysys/EasyScheduler)\n-\n-> Easy Scheduler for Big Data\n-\n-\n-[![Stargazers over time](https://starchart.cc/analysys/EasyScheduler.svg)](https://starchart.cc/analysys/EasyScheduler)\n-\n-[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README.md)\n-[![CN doc](https://img.shields.io/badge/\u6587\u6863-\u4e2d\u6587\u7248-blue.svg)](README_zh_CN.md)\n-\n-\n-### Design features: \n-\n-A distributed and easy-to-expand visual DAG workflow scheduling system. Dedicated to solving the complex dependencies in data processing, making the scheduling system `out of the box` for data processing.\n-Its main objectives are as follows:\n-\n- - Associate the Tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of task in real time.\n- - Support for many task types: Shell, MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Sub_Process, Procedure, etc.\n- - Support process scheduling, dependency scheduling, manual scheduling, manual pause/stop/recovery, support for failed retry/alarm, recovery from specified nodes, Kill task, etc.\n- - Support process priority, task priority and task failover and task timeout alarm/failure\n- - Support process global parameters and node custom parameter settings\n- - Support online upload/download of resource files, management, etc. Support online file creation and editing\n- - Support task log online viewing and scrolling, online download log, etc.\n- - Implement cluster HA, decentralize Master cluster and Worker cluster through Zookeeper\n- - Support online viewing of `Master/Worker` cpu load, memory\n- - Support process running history tree/gantt chart display, support task status statistics, process status statistics\n- - Support backfilling data\n- - Support multi-tenant\n- - Support internationalization\n- - There are more waiting partners to explore\n-\n-\n-### What's in Easy Scheduler\n-\n- Stability | Easy to use | Features | Scalability |\n- -- | -- | -- | --\n-Decentralized multi-master and multi-worker | Visualization process defines key information such as task status, task type, retry times, task running machine, visual variables and so on at a glance.\u00a0 | \u00a0Support pause, recover operation | support custom task types \n-HA is supported by itself | All process definition operations are visualized, dragging tasks to draw DAGs, configuring data sources and resources. At the same time, for third-party systems, the api mode operation is provided. | Users on easyscheduler can achieve many-to-one or one-to-one mapping relationship through tenants and Hadoop users, which is very important for scheduling large data jobs. | The scheduler uses distributed scheduling, and the overall scheduling capability will increase linearly with the scale of the cluster. Master and Worker support dynamic online and offline. \n-Overload processing: Task queue mechanism, the number of schedulable tasks on a single machine can be flexibly configured, when too many tasks will be cached in the task queue, will not cause machine jam. | One-click deployment | Supports traditional shell tasks, and also support big data platform task scheduling: MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Procedure, Sub_Process |  |\n-\n-\n-\n-\n-### System partial screenshot\n-\n-![image](https://user-images.githubusercontent.com/48329107/61368744-1f5f3b00-a8c1-11e9-9cf1-10f8557a6b3b.png)\n-\n-![image](https://user-images.githubusercontent.com/48329107/61368966-9dbbdd00-a8c1-11e9-8dcc-a9469d33583e.png)\n-\n-![image](https://user-images.githubusercontent.com/48329107/61372146-f347b800-a8c8-11e9-8882-66e8934ada23.png)\n-\n-\n-### Document\n-\n-- <a href=\"https://analysys.github.io/easyscheduler_docs/backend-deployment.html\" target=\"_blank\">Backend deployment documentation</a>\n-\n-- <a href=\"https://analysys.github.io/easyscheduler_docs/frontend-deployment.html\" target=\"_blank\">Front-end deployment documentation</a>\n-\n-- [**User manual**](https://analysys.github.io/easyscheduler_docs/system-manual.html?_blank \"User manual\") \n-\n-- [**Upgrade document**](https://analysys.github.io/easyscheduler_docs/upgrade.html?_blank \"Upgrade document\") \n-\n-- <a href=\"http://52.82.13.76:8888\" target=\"_blank\">Online Demo</a> \n-\n-More documentation please refer to <a href=\"https://analysys.github.io/easyscheduler_docs/\" target=\"_blank\">[EasyScheduler online documentation]</a>\n-\n-### Recent R&D plan\n-Work plan of Easy Scheduler: [R&D plan](https://github.com/analysys/EasyScheduler/projects/1), where `In Develop` card is the features of 1.1.0 version , TODO card is to be done (including feature ideas)\n-\n-### How to contribute code\n-\n-Welcome to participate in contributing code, please refer to the process of submitting the code:\n-[[How to contribute code](https://github.com/analysys/EasyScheduler/issues/310)]\n-\n-### Thanks\n-\n-Easy Scheduler uses a lot of excellent open source projects, such as google guava, guice, grpc, netty, ali bonecp, quartz, and many open source projects of apache, etc.\n-It is because of the shoulders of these open source projects that the birth of the Easy Scheduler is possible. We are very grateful for all the open source software used! We also hope that we will not only be the beneficiaries of open source, but also be open source contributors, so we decided to contribute to easy scheduling and promised long-term updates. We also hope that partners who have the same passion and conviction for open source will join in and contribute to open source!\n-\n-### Get Help\n-The fastest way to get response from our developers is to submit issues,  or add our wechat : 510570367\n-\n-### License\n-Please refer to [LICENSE](https://github.com/analysys/EasyScheduler/blob/dev/LICENSE) file.\n- \n- \n-\n-\n-\n-\n-\n-\n-",
                "changes": 96
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/SUMMARY.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/SUMMARY.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/SUMMARY.md",
                "deletions": 50,
                "sha": "397a4a110ca275cbc284205052308dddab4e5440",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/SUMMARY.md",
                "patch": "@@ -1,50 +0,0 @@\n-# Summary\n-\n-* [Instruction](README.md)\n-\n-* Frontend Deployment\n-    * [Preparations](frontend-deployment.md#Preparations)\n-    * [Deployment](frontend-deployment.md#Deployment)\n-    * [FAQ](frontend-deployment.md#FAQ)\n-    \n-* Backend Deployment\n-    * [Preparations](backend-deployment.md#Preparations)\n-    * [Deployment](backend-deployment.md#Deployment)\n-    \n-* [Quick Start](quick-start.md#Quick Start)\n-\n-* System Use Manual\n-    * [Operational Guidelines](system-manual.md#Operational Guidelines)\n-    * [Security](system-manual.md#Security)\n-    * [Monitor center](system-manual.md#Monitor center)\n-    * [Task Node Type and Parameter Setting](system-manual.md#Task Node Type and Parameter Setting)\n-    * [System parameter](system-manual.md#System parameter)\n-    \n-* [Architecture Design](architecture-design.md)\n-\n-* Front-end development\n-    * [Development environment](frontend-development.md#Development environment)\n-    * [Project directory structure](frontend-development.md#Project directory structure)\n-    * [System function module](frontend-development.md#System function module)\n-    * [Routing and state management](frontend-development.md#Routing and state management)\n-    * [specification](frontend-development.md#specification)\n-    * [interface](frontend-development.md#interface)\n-    * [Extended development](frontend-development.md#Extended development)\n-    \n-* Backend development documentation\n-    * [Environmental requirements](backend-development.md#Environmental requirements)\n-    * [Project compilation](backend-development.md#Project compilation)\n-* [Interface documentation](http://52.82.13.76:8888/escheduler/doc.html?language=en_US&lang=en)\n-* FAQ\n-    * [FAQ](EasyScheduler-FAQ.md)\n-* EasyScheduler upgrade documentation\n-    * [upgrade documentation](upgrade.md)\n-* History release notes\n-    * [1.1.0 release](1.1.0-release.md)\n-    * [1.0.5 release](1.0.5-release.md)\n-    * [1.0.4 release](1.0.4-release.md)\n-    * [1.0.3 release](1.0.3-release.md)\n-    * [1.0.2 release](1.0.2-release.md)\n-    * [1.0.1 release](1.0.1-release.md)\n-    * [1.0.0 release]\n-",
                "changes": 50
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/architecture-design.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/architecture-design.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/architecture-design.md",
                "deletions": 316,
                "sha": "0587993d0577530e292249b9e40fc27b9d5afc7a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/architecture-design.md",
                "patch": "@@ -1,316 +0,0 @@\n-## Architecture Design\n-Before explaining the architecture of the schedule system, let us first understand the common nouns of the schedule system.\n-\n-### 1.Noun Interpretation\n-\n-**DAG\uff1a** Full name Directed Acyclic Graph\uff0creferred to as DAG\u3002Tasks in the workflow are assembled in the form of directed acyclic graphs, which are topologically traversed from nodes with zero indegrees of ingress until there are no successor nodes. For example, the following picture:\n-\n-<p align=\"center\">\n-  <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag_examples_cn.jpg\" alt=\"dag\u793a\u4f8b\"  width=\"60%\" />\n-  <p align=\"center\">\n-        <em>dag example</em>\n-  </p>\n-</p>\n-\n-**Process definition**: Visualization **DAG** by dragging task nodes and establishing associations of task nodes \n-\n-**Process instance**: A process instance is an instantiation of a process definition, which can be generated by manual startup or  scheduling. The process definition runs once, a new process instance is generated\n-\n-**Task instance**: A task instance is the instantiation of a specific task node when a process instance runs, which indicates the specific task execution status\n-\n-**Task type**: Currently supports SHELL, SQL, SUB_PROCESS (sub-process), PROCEDURE, MR, SPARK, PYTHON, DEPENDENT (dependency), and plans to support dynamic plug-in extension, note: the sub-**SUB_PROCESS** is also A separate process definition that can be launched separately\n-\n-**Schedule mode** :  The system supports timing schedule and manual schedule based on cron expressions. Command type support: start workflow, start execution from current node, resume fault-tolerant workflow, resume pause process, start execution from failed node, complement, timer, rerun, pause, stop, resume waiting thread. Where **recovers the fault-tolerant workflow** and **restores the waiting thread** The two command types are used by the scheduling internal control and cannot be called externally\n-\n-**Timed schedule**: The system uses **quartz** distributed scheduler and supports the generation of cron expression visualization\n-\n-**Dependency**: The system does not only support **DAG** Simple dependencies between predecessors and successor nodes, but also provides **task dependencies** nodes, support for custom task dependencies between processes**\n-\n-**Priority**: Supports the priority of process instances and task instances. If the process instance and task instance priority are not set, the default is first in, first out.\n-\n-**Mail Alert**: Support **SQL Task** Query Result Email Send, Process Instance Run Result Email Alert and Fault Tolerant Alert Notification\n-\n-**Failure policy**: For tasks running in parallel, if there are tasks that fail, two failure policy processing methods are provided. **Continue** means that the status of the task is run in parallel until the end of the process failure. **End** means that once a failed task is found, Kill also drops the running parallel task and the process ends.\n-\n-**Complement**: Complement historical data, support ** interval parallel and serial ** two complement methods\n-\n-\n-\n-### 2.System architecture\n-\n-#### 2.1 System Architecture Diagram\n-<p align=\"center\">\n-  <img src=\"https://user-images.githubusercontent.com/48329107/62609545-8f973480-b934-11e9-9a58-d8133222f14d.png\" alt=\"System Architecture Diagram\"  />\n-  <p align=\"center\">\n-        <em>System Architecture Diagram</em>\n-  </p>\n-</p>\n-\n-\n-\n-#### 2.2 Architectural description\n-\n-* **MasterServer** \n-\n-    MasterServer adopts the distributed non-central design concept. MasterServer is mainly responsible for DAG task split, task submission monitoring, and monitoring the health status of other MasterServer and WorkerServer.\n-    When the MasterServer service starts, it registers a temporary node with Zookeeper, and listens to the Zookeeper temporary node state change for fault tolerance processing.\n-\n-    \n-\n-    ##### The service mainly contains:\n-\n-    - **Distributed Quartz** distributed scheduling component, mainly responsible for the start and stop operation of the scheduled task. When the quartz picks up the task, the master internally has a thread pool to be responsible for the subsequent operations of the task.\n-\n-    - **MasterSchedulerThread** is a scan thread that periodically scans the **command** table in the database for different business operations based on different ** command types**\n-\n-    - **MasterExecThread** is mainly responsible for DAG task segmentation, task submission monitoring, logic processing of various command types\n-\n-    - **MasterTaskExecThread** is mainly responsible for task persistence\n-\n-      \n-\n-* **WorkerServer** \n-\n-     - WorkerServer also adopts a distributed, non-central design concept. WorkerServer is mainly responsible for task execution and providing log services. When the WorkerServer service starts, it registers the temporary node with Zookeeper and maintains the heartbeat.\n-\n-       ##### This service contains:\n-\n-       - **FetchTaskThread** is mainly responsible for continuously receiving tasks from **Task Queue** and calling **TaskScheduleThread** corresponding executors according to different task types.\n-       - **LoggerServer** is an RPC service that provides functions such as log fragment viewing, refresh and download.\n-\n-     - **ZooKeeper**\n-\n-       The ZooKeeper service, the MasterServer and the WorkerServer nodes in the system all use the ZooKeeper for cluster management and fault tolerance. In addition, the system also performs event monitoring and distributed locking based on ZooKeeper.\n-       We have also implemented queues based on Redis, but we hope that EasyScheduler relies on as few components as possible, so we finally removed the Redis implementation.\n-\n-     - **Task Queue**\n-\n-       The task queue operation is provided. Currently, the queue is also implemented based on Zookeeper. Since there is less information stored in the queue, there is no need to worry about too much data in the queue. In fact, we have over-measured a million-level data storage queue, which has no effect on system stability and performance.\n-\n-     - **Alert**\n-\n-       Provides alarm-related interfaces. The interfaces mainly include **Alarms**. The storage, query, and notification functions of the two types of alarm data. The notification function has two types: **mail notification** and **SNMP (not yet implemented)**.\n-\n-     - **API**\n-\n-       The API interface layer is mainly responsible for processing requests from the front-end UI layer. The service provides a RESTful api to provide request services externally.\n-       Interfaces include workflow creation, definition, query, modification, release, offline, manual start, stop, pause, resume, start execution from this node, and more.\n-\n-     - **UI**\n-\n-       The front-end page of the system provides various visual operation interfaces of the system. For details, see the **[System User Manual] (System User Manual.md)** section.\n-\n-     \n-\n-#### 2.3 Architectural Design Ideas\n-\n-##### I. Decentralized vs centralization\n-\n-###### Centralization Thought\n-\n-The centralized design concept is relatively simple. The nodes in the distributed cluster are divided into two roles according to their roles:\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/master_slave.png\" alt=\"master-slave role\" width=\"50%\" />\n- </p>\n-\n-- The role of Master is mainly responsible for task distribution and supervising the health status of Slave. It can dynamically balance the task to Slave, so that the Slave node will not be \"busy\" or \"free\".\n-- The role of the Worker is mainly responsible for the execution of the task and maintains the heartbeat with the Master so that the Master can assign tasks to the Slave.\n-\n-Problems in the design of centralized :\n-\n-- Once the Master has a problem, the group has no leader and the entire cluster will crash. In order to solve this problem, most Master/Slave architecture modes adopt the design scheme of the master and backup masters, which can be hot standby or cold standby, automatic switching or manual switching, and more and more new systems are available. Automatically elects the ability to switch masters to improve system availability.\n-- Another problem is that if the Scheduler is on the Master, although it can support different tasks in one DAG running on different machines, it will generate overload of the Master. If the Scheduler is on the Slave, all tasks in a DAG can only be submitted on one machine. If there are more parallel tasks, the pressure on the Slave may be larger.\n-\n-###### Decentralization\n-\n- <p align=\"center\"\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/decentralization.png\" alt=\"decentralized\" width=\"50%\" />\n- </p>\n-\n-- In the decentralized design, there is usually no Master/Slave concept, all roles are the same, the status is equal, the global Internet is a typical decentralized distributed system, networked arbitrary node equipment down machine , all will only affect a small range of features.\n-- The core design of decentralized design is that there is no \"manager\" that is different from other nodes in the entire distributed system, so there is no single point of failure problem. However, since there is no \"manager\" node, each node needs to communicate with other nodes to get the necessary machine information, and the unreliable line of distributed system communication greatly increases the difficulty of implementing the above functions.\n-- In fact, truly decentralized distributed systems are rare. Instead, dynamic centralized distributed systems are constantly emerging. Under this architecture, the managers in the cluster are dynamically selected, rather than preset, and when the cluster fails, the nodes of the cluster will spontaneously hold \"meetings\" to elect new \"managers\". Go to preside over the work. The most typical case is the Etcd implemented in ZooKeeper and Go.\n-\n-- Decentralization of EasyScheduler is the registration of Master/Worker to ZooKeeper. The Master Cluster and the Worker Cluster are not centered, and the Zookeeper distributed lock is used to elect one Master or Worker as the \u201cmanager\u201d to perform the task.\n-\n-#####  \u4e8c\u3001Distributed lock practice\n-\n-EasyScheduler uses ZooKeeper distributed locks to implement only one Master to execute the Scheduler at the same time, or only one Worker to perform task submission.\n-\n-1. The core process algorithm for obtaining distributed locks is as follows\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/distributed_lock.png\" alt=\"Get Distributed Lock Process\" width=\"50%\" />\n- </p>\n-\n-2. Scheduler thread distributed lock implementation flow chart in EasyScheduler:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/distributed_lock_procss.png\" alt=\"Get Distributed Lock Process\" width=\"50%\" />\n- </p>\n-\n-##### Third, the thread is insufficient loop waiting problem\n-\n-- If there is no subprocess in a DAG, if the number of data in the Command is greater than the threshold set by the thread pool, the direct process waits or fails.\n-- If a large number of sub-processes are nested in a large DAG, the following figure will result in a \"dead\" state:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/lack_thread.png\" alt=\"Thread is not enough to wait for loop\" width=\"50%\" />\n- </p>\n-\n-In the above figure, MainFlowThread waits for SubFlowThread1 to end, SubFlowThread1 waits for SubFlowThread2 to end, SubFlowThread2 waits for SubFlowThread3 to end, and SubFlowThread3 waits for a new thread in the thread pool, then the entire DAG process cannot end, and thus the thread cannot be released. This forms the state of the child parent process loop waiting. At this point, the scheduling cluster will no longer be available unless a new Master is started to add threads to break such a \"stuck.\"\n-\n-It seems a bit unsatisfactory to start a new Master to break the deadlock, so we proposed the following three options to reduce this risk:\n-\n-1. Calculate the sum of the threads of all Masters, and then calculate the number of threads required for each DAG, that is, pre-calculate before the DAG process is executed. Because it is a multi-master thread pool, the total number of threads is unlikely to be obtained in real time.\n-2. Judge the single master thread pool. If the thread pool is full, let the thread fail directly.\n-3. Add a Command type with insufficient resources. If the thread pool is insufficient, the main process will be suspended. This way, the thread pool has a new thread, which can make the process with insufficient resources hang up and wake up again.\n-\n-Note: The Master Scheduler thread is FIFO-enabled when it gets the Command.\n-\n-So we chose the third way to solve the problem of insufficient threads.\n-\n-##### IV. Fault Tolerant Design\n-\n-Fault tolerance is divided into service fault tolerance and task retry. Service fault tolerance is divided into two types: Master Fault Tolerance and Worker Fault Tolerance.\n-\n-###### 1. Downtime fault tolerance\n-\n-Service fault tolerance design relies on ZooKeeper's Watcher mechanism. The implementation principle is as follows:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant.png\" alt=\"EasyScheduler Fault Tolerant Design\" width=\"40%\" />\n- </p>\n-\n-The Master monitors the directories of other Masters and Workers. If the remove event is detected, the process instance is fault-tolerant or the task instance is fault-tolerant according to the specific business logic.\n-\n-\n-\n-- Master fault tolerance flow chart:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant_master.png\" alt=\"Master Fault Tolerance Flowchart\" width=\"40%\" />\n- </p>\n-\n-After the ZooKeeper Master is fault-tolerant, it is rescheduled by the Scheduler thread in EasyScheduler. It traverses the DAG to find the \"Running\" and \"Submit Successful\" tasks, and monitors the status of its task instance for the \"Running\" task. You need to determine whether the Task Queue already exists. If it exists, monitor the status of the task instance. If it does not exist, resubmit the task instance.\n-\n-\n-\n-- Worker fault tolerance flow chart:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant_worker.png\" alt=\"Worker Fault Tolerance Flowchart\" width=\"40%\" />\n- </p>\n-\n-Once the Master Scheduler thread finds the task instance as \"need to be fault tolerant\", it takes over the task and resubmits.\n-\n- Note: Because the \"network jitter\" may cause the node to lose the heartbeat of ZooKeeper in a short time, the node's remove event occurs. In this case, we use the easiest way, that is, once the node has timeout connection with ZooKeeper, it will directly stop the Master or Worker service.\n-\n-###### 2. Task failure retry\n-\n-Here we must first distinguish between the concept of task failure retry, process failure recovery, and process failure rerun:\n-\n-- Task failure Retry is task level, which is automatically performed by the scheduling system. For example, if a shell task sets the number of retries to 3 times, then the shell task will try to run up to 3 times after failing to run.\n-- Process failure recovery is process level, is done manually, recovery can only be performed from the failed node ** or ** from the current node **\n-- Process failure rerun is also process level, is done manually, rerun is from the start node\n-\n-\n-\n-Next, let's talk about the topic, we divided the task nodes in the workflow into two types.\n-\n-- One is a business node, which corresponds to an actual script or processing statement, such as a Shell node, an MR node, a Spark node, a dependent node, and so on.\n-- There is also a logical node, which does not do the actual script or statement processing, but the logical processing of the entire process flow, such as sub-flow sections.\n-\n-Each ** service node** can configure the number of failed retries. When the task node fails, it will automatically retry until it succeeds or exceeds the configured number of retries. **Logical node** does not support failed retry. But the tasks in the logical nodes support retry.\n-\n-If there is a task failure in the workflow that reaches the maximum number of retries, the workflow will fail to stop, and the failed workflow can be manually rerun or process resumed.\n-\n-\n-\n-##### V. Task priority design\n-\n-In the early scheduling design, if there is no priority design and fair scheduling design, it will encounter the situation that the task submitted first may be completed simultaneously with the task submitted subsequently, but the priority of the process or task cannot be set. We have redesigned this, and we are currently designing it as follows:\n-\n-- According to ** different process instance priority ** prioritizes ** same process instance priority ** prioritizes ** task priority within the same process ** takes precedence over ** same process ** commit order from high Go to low for task processing.\n-\n-  - The specific implementation is to resolve the priority according to the json of the task instance, and then save the ** process instance priority _ process instance id_task priority _ task id** information in the ZooKeeper task queue, when obtained from the task queue, Through string comparison, you can get the task that needs to be executed first.\n-\n-    - The priority of the process definition is that some processes need to be processed before other processes. This can be configured at the start of the process or at the time of scheduled start. There are 5 levels, followed by HIGHEST, HIGH, MEDIUM, LOW, and LOWEST. As shown below\n-\n-      <p align=\"center\">\n-         <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/process_priority.png\" alt=\"Process Priority Configuration\" width=\"40%\" />\n-       </p>\n-\n-    - The priority of the task is also divided into 5 levels, followed by HIGHEST, HIGH, MEDIUM, LOW, and LOWEST. As shown below\n-\n-      <p align=\"center\">\n-         <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task_priority.png\" alt=\"task priority configuration\" width=\"35%\" />\n-       </p>\n-\n-##### VI. Logback and gRPC implement log access\n-\n-- Since the Web (UI) and Worker are not necessarily on the same machine, viewing the log is not as it is for querying local files. There are two options:\n-  - Put the logs on the ES search engine\n-  - Obtain remote log information through gRPC communication\n-- Considering the lightweightness of EasyScheduler as much as possible, gRPC was chosen to implement remote access log information.\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/grpc.png\" alt=\"grpc remote access\" width=\"50%\" />\n- </p>\n-\n-- We use a custom Logback FileAppender and Filter function to generate a log file for each task instance.\n-- The main implementation of FileAppender is as follows:\n-\n-```java\n- /**\n-  * task log appender\n-  */\n- Public class TaskLogAppender extends FileAppender<ILoggingEvent> {\n- \n-     ...\n-\n-    @Override\n-    Protected void append(ILoggingEvent event) {\n-\n-        If (currentlyActiveFile == null){\n-            currentlyActiveFile = getFile();\n-        }\n-        String activeFile = currentlyActiveFile;\n-        // thread name: taskThreadName-processDefineId_processInstanceId_taskInstanceId\n-        String threadName = event.getThreadName();\n-        String[] threadNameArr = threadName.split(\"-\");\n-        // logId = processDefineId_processInstanceId_taskInstanceId\n-        String logId = threadNameArr[1];\n-        ...\n-        super.subAppend(event);\n-    }\n-}\n-```\n-\n-Generate a log in the form of /process definition id/process instance id/task instance id.log\n-\n-- Filter matches the thread name starting with TaskLogInfo:\n-- TaskLogFilter is implemented as follows:\n-\n-```java\n- /**\n- * task log filter\n- */\n-Public class TaskLogFilter extends Filter<ILoggingEvent> {\n-\n-    @Override\n-    Public FilterReply decide(ILoggingEvent event) {\n-        If (event.getThreadName().startsWith(\"TaskLogInfo-\")){\n-            Return FilterReply.ACCEPT;\n-        }\n-        Return FilterReply.DENY;\n-    }\n-}\n-```\n-\n-\n-\n-### summary\n-\n-Starting from the scheduling, this paper introduces the architecture principle and implementation ideas of the big data distributed workflow scheduling system-EasyScheduler. To be continued",
                "changes": 316
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/backend-deployment.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/backend-deployment.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/backend-deployment.md",
                "deletions": 207,
                "sha": "934a005f6bf272e674c57833b5a1c1447af8db72",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/backend-deployment.md",
                "patch": "@@ -1,207 +0,0 @@\n-# Backend Deployment Document\n-\n-There are two deployment modes for the backend: \n-\n-- automatic deployment  \n-- source code compile and then deployment\n-\n-## Preparations\n-\n-Download the latest version of the installation package, download address\uff1a [gitee download](https://gitee.com/easyscheduler/EasyScheduler/attach_files/) or [github download](https://github.com/analysys/EasyScheduler/releases), download escheduler-backend-x.x.x.tar.gz(back-end referred to as escheduler-backend),escheduler-ui-x.x.x.tar.gz(front-end referred to as escheduler-ui)\n-\n-\n-\n-#### Preparations 1: Installation of basic software (self-installation of required items)\n-\n- * [Mysql](http://geek.analysys.cn/topic/124) (5.5+) :  Mandatory\n- * [JDK](https://www.oracle.com/technetwork/java/javase/downloads/index.html) (1.8+) :  Mandatory\n- * [ZooKeeper](https://www.jianshu.com/p/de90172ea680)(3.4.6+) \uff1aMandatory\n- * [Hadoop](https://blog.csdn.net/Evankaka/article/details/51612437)(2.6+) \uff1aOptionally, if you need to use the resource upload function, MapReduce task submission needs to configure Hadoop (uploaded resource files are currently stored on Hdfs)\n- * [Hive](https://staroon.pro/2017/12/09/HiveInstall/)(1.2.1) :   Optional, hive task submission needs to be installed\n- * Spark(1.x,2.x) :  Optional, Spark task submission needs to be installed\n- * PostgreSQL(8.2.15+) : Optional, PostgreSQL PostgreSQL stored procedures need to be installed\n-\n-```\n- Note: Easy Scheduler itself does not rely on Hadoop, Hive, Spark, PostgreSQL, but only calls their Client to run the corresponding tasks.\n-```\n-\n-#### Preparations 2: Create deployment users\n-\n-- Deployment users are created on all machines that require deployment scheduling, because the worker service executes jobs in `sudo-u {linux-user}`, so deployment users need sudo privileges and are confidential.\n-\n-```\n-vi /etc/sudoers\n-\n-# For example, the deployment user is an escheduler account\n-escheduler  ALL=(ALL)       NOPASSWD: NOPASSWD: ALL\n-\n-# And you need to comment out the Default requiretty line\n-#Default requiretty\n-```\n-\n-#### Preparations 3: SSH Secret-Free Configuration\n-Configure SSH secret-free login on deployment machines and other installation machines. If you want to install easyscheduler on deployment machines, you need to configure native password-free login itself.\n-\n-- [Connect the host and other machines SSH](http://geek.analysys.cn/topic/113)\n-\n-#### Preparations 4: database initialization\n-\n-* Create databases and accounts\n-\n-    Execute the following command to create database and account\n-    \n-    ```\n-    CREATE DATABASE escheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;\n-    GRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}';\n-    GRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'localhost' IDENTIFIED BY '{password}';\n-    flush privileges;\n-    ```\n-\n-* creates tables and imports basic data\n-    Modify the following attributes in ./conf/dao/data_source.properties\n-\n-    ```\n-        spring.datasource.url\n-        spring.datasource.username\n-        spring.datasource.password\n-    ```\n-    \n-    Execute scripts for creating tables and importing basic data\n-    \n-    ```\n-    sh ./script/create-escheduler.sh\n-    ```\n-\n-#### Preparations 5: Modify the deployment directory permissions and operation parameters\n-\n-     instruction of escheduler-backend directory \n-\n-```directory\n-bin : Basic service startup script\n-conf : Project Profile\n-lib : The project relies on jar packages, including individual module jars and third-party jars\n-script :  Cluster Start, Stop and Service Monitor Start and Stop scripts\n-sql : The project relies on SQL files\n-install.sh :  One-click deployment script\n-```\n-\n-- Modify permissions (please modify the 'deployUser' to the corresponding deployment user) so that the deployment user has operational privileges on the escheduler-backend directory\n-\n-    `sudo chown -R deployUser:deployUser escheduler-backend`\n-\n-- Modify the `.escheduler_env.sh` environment variable in the conf/env/directory\n-\n-- Modify deployment parameters (depending on your server and business situation):\n-\n- - Modify the parameters in **install.sh** to replace the values required by your business\n-   - MonitorServerState switch variable, added in version 1.0.3, controls whether to start the self-start script (monitor master, worker status, if off-line will start automatically). The default value of \"false\" means that the self-start script is not started, and if it needs to start, it is changed to \"true\".\n-   - 'hdfsStartupSate' switch variable controls whether to start hdfs\n-      The default value of \"false\" means not to start hdfs\n-      Change the variable to 'true' if you want to use hdfs, you also need to create the hdfs root path by yourself, that 'hdfsPath' in install.sh.\n-\n- - If you use hdfs-related functions, you need to copy**hdfs-site.xml** and **core-site.xml** to the conf directory\n-\n-\n-## Deployment\n-Automated deployment is recommended, and experienced partners can use source deployment as well.\n-\n-### Automated Deployment\n-\n-- Install zookeeper tools\n-\n-   `pip install kazoo`\n-\n-- Switch to deployment user, one-click deployment\n-\n-    `sh install.sh` \n-\n-- Use the `jps` command to check if the services are started (`jps` comes from `Java JDK`)\n-\n-```aidl\n-    MasterServer         ----- Master Service\n-    WorkerServer         ----- Worker Service\n-    LoggerServer         ----- Logger Service\n-    ApiApplicationServer ----- API Service\n-    AlertServer          ----- Alert Service\n-```\n-\n-If all services are normal, the automatic deployment is successful\n-\n-\n-After successful deployment, the log can be viewed and stored in a specified folder.\n-\n-```logPath\n- logs/\n-    \u251c\u2500\u2500 escheduler-alert-server.log\n-    \u251c\u2500\u2500 escheduler-master-server.log\n-    |\u2014\u2014 escheduler-worker-server.log\n-    |\u2014\u2014 escheduler-api-server.log\n-    |\u2014\u2014 escheduler-logger-server.log\n-```\n-\n-### Compile source code to deploy\n-\n-After downloading the release version of the source package, unzip it into the root directory\n-\n-* Execute the compilation command\uff1a\n-\n-```\n- mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n-```\n-\n-* View directory\n-\n-After normal compilation, ./target/escheduler-{version}/ is generated in the current directory\n-\n-\n-### Start-and-stop services commonly used in systems (for service purposes, please refer to System Architecture Design for details)\n-\n-* stop all services in the cluster\n-  \n-   ` sh ./bin/stop-all.sh`\n-   \n-* start all services in the cluster\n-  \n-   ` sh ./bin/start-all.sh`\n-\n-* start and stop one master server\n-\n-```master\n-sh ./bin/escheduler-daemon.sh start master-server\n-sh ./bin/escheduler-daemon.sh stop master-server\n-```\n-\n-* start and stop one worker server\n-\n-```worker\n-sh ./bin/escheduler-daemon.sh start worker-server\n-sh ./bin/escheduler-daemon.sh stop worker-server\n-```\n-\n-* start and stop api server\n-\n-```Api\n-sh ./bin/escheduler-daemon.sh start api-server\n-sh ./bin/escheduler-daemon.sh stop api-server\n-```\n-* start and stop logger server\n-\n-```Logger\n-sh ./bin/escheduler-daemon.sh start logger-server\n-sh ./bin/escheduler-daemon.sh stop logger-server\n-```\n-* start and stop alert server\n-\n-```Alert\n-sh ./bin/escheduler-daemon.sh start alert-server\n-sh ./bin/escheduler-daemon.sh stop alert-server\n-```\n-\n-## Database Upgrade\n-Database upgrade is a function added in version 1.0.2. The database can be upgraded automatically by executing the following command:\n-\n-```upgrade\n-sh ./script/upgrade-escheduler.sh\n-```\n-\n-",
                "changes": 207
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/backend-development.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/backend-development.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/backend-development.md",
                "deletions": 48,
                "sha": "10f7ba47f6a0e12199449786808a72a9f44475ae",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/backend-development.md",
                "patch": "@@ -1,48 +0,0 @@\n-# Backend development documentation\n-\n-## Environmental requirements\n-\n- * [Mysql](http://geek.analysys.cn/topic/124) (5.5+) :  Must be installed\n- * [JDK](https://www.oracle.com/technetwork/java/javase/downloads/index.html) (1.8+) :  Must be installed\n- * [ZooKeeper](https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper)(3.4.6+) \uff1aMust be installed\n- * [Maven](http://maven.apache.org/download.cgi)(3.3+) \uff1aMust be installed\n-\n-Because the escheduler-rpc module in EasyScheduler uses Grpc, you need to use Maven to compile the generated classes.\n-For those who are not familiar with maven, please refer to: [maven in five minutes](http://maven.apache.org/guides/getting-started/maven-in-five-minutes.html)(3.3+)\n-\n-http://maven.apache.org/install.html\n-\n-## Project compilation\n-After importing the EasyScheduler source code into the development tools such as Idea, first convert to the Maven project (right click and select \"Add Framework Support\")\n-\n-* Execute the compile command:\n-\n-```\n- mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n-```\n-\n-* View directory\n-\n-After normal compilation, it will generate ./target/escheduler-{version}/ in the current directory.\n-\n-```\n-    bin\n-    conf\n-    lib\n-    script\n-    sql\n-    install.sh\n-```\n-\n-- Description\n-\n-```\n-bin : basic service startup script\n-conf : project configuration file\n-lib : the project depends on the jar package, including the various module jars and third-party jars\n-script : cluster start, stop, and service monitoring start and stop scripts\n-sql : project depends on sql file\n-install.sh : one-click deployment script\n-```\n-\n-   ",
                "changes": 48
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/book.json",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/book.json?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/book.json",
                "deletions": 23,
                "sha": "c05811289d4fbcfe562e6abb0e2bf2fe0dcaaf3d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/book.json",
                "patch": "@@ -1,23 +0,0 @@\n-{\n-  \"title\": \"EasyScheduler\",\n-  \"author\": \"\",\n-  \"description\": \"Scheduler\",\n-  \"language\": \"en-US\",\n-  \"gitbook\": \"3.2.3\",\n-  \"styles\": {\n-    \"website\": \"./styles/website.css\"\n-  },\n-  \"structure\": {\n-    \"readme\": \"README.md\"\n-  },\n-  \"plugins\":[\n-    \"expandable-chapters\",\n-    \"insert-logo-link\"\n-  ],\n-  \"pluginsConfig\": {\n-    \"insert-logo-link\": {\n-      \"src\": \"http://geek.analysys.cn/static/upload/236/2019-03-29/379450b4-7919-4707-877c-4d33300377d4.png\",\n-      \"url\": \"https://github.com/analysys/EasyScheduler\"\n-    }\n-  }\n-}\n\\ No newline at end of file",
                "changes": 23
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/frontend-deployment.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/frontend-deployment.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/frontend-deployment.md",
                "deletions": 115,
                "sha": "919caf148531a221a7d6aa2aeb60cac96e552e0c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/frontend-deployment.md",
                "patch": "@@ -1,115 +0,0 @@\n-# frontend-deployment\n-\n-The front-end has three deployment modes: automated deployment, manual deployment and compiled source deployment.\n-\n-\n-\n-## Preparations\n-\n-#### Download the installation package\n-\n-Please download the latest version of the installation package, download address\uff1a [gitee](https://gitee.com/easyscheduler/EasyScheduler/attach_files/)\n-\n-After downloading escheduler-ui-x.x.x.tar.gz\uff0cdecompress`tar -zxvf escheduler-ui-x.x.x.tar.gz ./`and enter the`escheduler-ui`directory\n-\n-\n-\n-\n-## Deployment\n-\n-Automated deployment is recommended for either of the following two ways\n-\n-### Automated Deployment\n-\n-Edit the installation file`vi install-escheduler-ui.sh` in the` escheduler-ui` directory\n-\n-Change the front-end access port and the back-end proxy interface address\n-\n-```\n-# Configure the front-end access port\n-esc_proxy=\"8888\"\n-\n-# Configure proxy back-end interface\n-esc_proxy_port=\"http://192.168.xx.xx:12345\"\n-```\n-\n->Front-end automatic deployment based on Linux system `yum` operation, before deployment, please install and update`yum`\n-\n-under this directory, execute`./install-escheduler-ui.sh` \n-\n-\n-### Manual Deployment\n-\n-Install epel source `yum install epel-release -y`\n-\n-Install Nginx `yum install nginx -y`\n-\n-\n-> ####  Nginx configuration file address\n-\n-```\n-/etc/nginx/conf.d/default.conf\n-```\n-\n-> ####  Configuration information (self-modifying)\n-\n-```\n-server {\n-    listen       8888;# access port\n-    server_name  localhost;\n-    #charset koi8-r;\n-    #access_log  /var/log/nginx/host.access.log  main;\n-    location / {\n-        root   /xx/dist; # the dist directory address decompressed by the front end above (self-modifying)\n-        index  index.html index.html;\n-    }\n-    location /escheduler {\n-        proxy_pass http://192.168.xx.xx:12345; # interface address (self-modifying)\n-        proxy_set_header Host $host;\n-        proxy_set_header X-Real-IP $remote_addr;\n-        proxy_set_header x_real_ipP $remote_addr;\n-        proxy_set_header remote_addr $remote_addr;\n-        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n-        proxy_http_version 1.1;\n-        proxy_connect_timeout 4s;\n-        proxy_read_timeout 30s;\n-        proxy_send_timeout 12s;\n-        proxy_set_header Upgrade $http_upgrade;\n-        proxy_set_header Connection \"upgrade\";\n-    }\n-    #error_page  404              /404.html;\n-    # redirect server error pages to the static page /50x.html\n-    #\n-    error_page   500 502 503 504  /50x.html;\n-    location = /50x.html {\n-        root   /usr/share/nginx/html;\n-    }\n-}\n-```\n-\n-> ####  Restart the Nginx service\n-\n-```\n-systemctl restart nginx\n-```\n-\n-#### nginx command\n-\n-- enable `systemctl enable nginx`\n-\n-- restart `systemctl restart nginx`\n-\n-- status `systemctl status nginx`\n-\n-\n-## FAQ\n-#### Upload file size limit\n-\n-Edit the configuration file `vi /etc/nginx/nginx.conf`\n-\n-```\n-# change upload size\n-client_max_body_size 1024m\n-```\n-\n-",
                "changes": 115
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/frontend-development.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/frontend-development.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/frontend-development.md",
                "deletions": 650,
                "sha": "286c598dbcad35254ecc28e7bc69354096e24e92",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/frontend-development.md",
                "patch": "@@ -1,650 +0,0 @@\n-# Front-end development documentation\n-\n-### Technical selection\n-```\n-Vue mvvm framework\n-\n-Es6 ECMAScript 6.0\n-\n-Ans-ui Analysys-ui\n-\n-D3  Visual Library Chart Library\n-\n-Jsplumb connection plugin library\n-\n-Lodash high performance JavaScript utility library\n-```\n-\n-\n-### Development environment\n-\n-- #### Node installation\n-Node package download (note version 8.9.4) `https://nodejs.org/download/release/v8.9.4/` \n-\n-\n-- #### Front-end project construction\n-Use the command line mode `cd`  enter the `escheduler-ui` project directory and execute `npm install` to pull the project dependency package.\n-\n-> If `npm install` is very slow\n-\n-> You can enter the Taobao image command line to enter `npm install -g cnpm --registry=https://registry.npm.taobao.org`\n-\n-> Run `cnpm install` \n-\n-\n-- Create a new `.env`  file or the interface that interacts with the backend\n-\n-Create a new` .env` file in the `escheduler-ui `directory, add the ip address and port of the backend service to the file, and use it to interact with the backend. The contents of the` .env` file are as follows:\n-```\n-# Proxy interface address (modified by yourself)\n-API_BASE = http://192.168.xx.xx:12345\n-\n-# If you need to access the project with ip, you can remove the \"#\" (example)\n-#DEV_HOST = 192.168.xx.xx\n-```\n-\n-> #####  ! ! ! Special attention here. If the project reports a \"node-sass error\" error while pulling the dependency package, execute the following command again after execution.\n-```\n-npm install node-sass --unsafe-perm //\u5355\u72ec\u5b89\u88c5node-sass\u4f9d\u8d56\n-```\n-\n-- #### Development environment operation\n-- `npm start` project development environment (after startup address http://localhost:8888/#/)\n-\n-\n-#### Front-end project release\n-\n-- `npm run build` project packaging (after packaging, the root directory will create a folder called dist for publishing Nginx online)\n-\n-Run the `npm run build` command to generate a package file (dist) package\n-\n-Copy it to the corresponding directory of the server (front-end service static page storage directory)\n-\n-Visit address` http://localhost:8888/#/`\n-\n-\n-#### Start with node and daemon under Linux\n-\n-Install pm2 `npm install -g pm2`\n-\n-Execute `pm2 start npm -- run dev` to start the project in the project `escheduler-ui `root directory\n-\n-#### command\n-\n-- Start `pm2 start npm -- run dev`\n-\n-- Stop `pm2 stop npm`\n-\n-- delete `pm2 delete npm`\n-\n-- Status  `pm2 list`\n-\n-```\n-\n-[root@localhost escheduler-ui]# pm2 start npm -- run dev\n-[PM2] Applying action restartProcessId on app [npm](ids: 0)\n-[PM2] [npm](0) \u2713\n-[PM2] Process successfully started\n-\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n-\u2502 App name \u2502 id \u2502 version \u2502 mode \u2502 pid  \u2502 status \u2502 restart \u2502 uptime \u2502 cpu \u2502 mem      \u2502 user \u2502 watching \u2502\n-\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n-\u2502 npm      \u2502 0  \u2502 N/A     \u2502 fork \u2502 6168 \u2502 online \u2502 31      \u2502 0s     \u2502 0%  \u2502 5.6 MB   \u2502 root \u2502 disabled \u2502\n-\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n- Use `pm2 show <id|name>` to get more details about an app\n-\n-```\n-\n-\n-### Project directory structure\n-\n-`build` some webpack configurations for packaging and development environment projects\n-\n-`node_modules` development environment node dependency package\n-\n-`src` project required documents\n-\n-`src => combo` project third-party resource localization `npm run combo` specific view `build/combo.js`\n-\n-`src => font` Font icon library can be added by visiting https://www.iconfont.cn Note: The font library uses its own secondary development to reintroduce its own library `src/sass/common/_font.scss`\n-\n-`src => images` public image storage\n-\n-`src => js` js/vue\n-\n-`src => lib` internal components of the company (company component library can be deleted after open source)\n-\n-`src => sass` sass file One page corresponds to a sass file\n-\n-`src => view` page file One page corresponds to an html file\n-\n-```\n-> Projects are developed using vue single page application (SPA)\n-- All page entry files are in the `src/js/conf/${ corresponding page filename => home} index.js` entry file\n-- The corresponding sass file is in `src/sass/conf/${corresponding page filename => home}/index.scss`\n-- The corresponding html file is in `src/view/${corresponding page filename => home}/index.html`\n-```\n-\n-Public module and utill `src/js/module`\n-\n-`components` => internal project common components\n-\n-`download` => download component\n-\n-`echarts` => chart component\n-\n-`filter` => filter and vue pipeline\n-\n-`i18n` => internationalization\n-\n-`io` => io request encapsulation based on axios\n-\n-`mixin` => vue mixin public part for disabled operation\n-\n-`permissions` => permission operation\n-\n-`util` => tool\n-\n-\n-### System function module\n-\n-Home  => `http://localhost:8888/#/home`\n-\n-Project Management => `http://localhost:8888/#/projects/list`\n-```\n-| Project Home\n-| Workflow\n-  - Workflow definition\n-  - Workflow instance\n-  - Task instance\n-```\n-\n-Resource Management => `http://localhost:8888/#/resource/file`\n-```\n-| File Management\n-| udf Management\n-  - Resource Management\n-  - Function management\n-\n-\n-\n-```\n-\n-Data Source Management => `http://localhost:8888/#/datasource/list`\n-\n-Security Center => `http://localhost:8888/#/security/tenant`\n-```\n-| Tenant Management\n-| User Management\n-| Alarm Group Management\n-  - master\n-  - worker\n-```\n-\n-User Center => `http://localhost:8888/#/user/account`\n-\n-\n-## Routing and state management\n-\n-The project `src/js/conf/home` is divided into\n-\n-`pages` => route to page directory\n-```\n- The page file corresponding to the routing address\n-```\n-\n-`router` => route management\n-```\n-vue router, the entry file index.js in each page will be registered. Specific operations: https://router.vuejs.org/zh/\n-```\n-\n-`store` => status management\n-```\n-The page corresponding to each route has a state management file divided into:\n-\n-actions => mapActions => Details\uff1ahttps://vuex.vuejs.org/zh/guide/actions.html\n-\n-getters => mapGetters => Details\uff1ahttps://vuex.vuejs.org/zh/guide/getters.html\n-\n-index => entrance\n-mutations => mapMutations => Details\uff1ahttps://vuex.vuejs.org/zh/guide/mutations.html\n-\n-state => mapState => Details\uff1ahttps://vuex.vuejs.org/zh/guide/state.html\n-\n-Specific action\uff1ahttps://vuex.vuejs.org/zh/\n-\n-```\n-\n-\n-## specification\n-## Vue specification\n-##### 1.Component name\n-The component is named multiple words and is connected with a wire (-) to avoid conflicts with HTML tags and a clearer structure.\n-```\n-// positive example\n-export default {\n-    name: 'page-article-item'\n-}\n-```\n-\n-##### 2.Component files\n-The internal common component of the `src/js/module/components` project writes the folder name with the same name as the file name. The subcomponents and util tools that are split inside the common component are placed in the internal `_source` folder of the component.\n-```\n-\u2514\u2500\u2500 components\n-    \u251c\u2500\u2500 header\n-        \u251c\u2500\u2500 header.vue\n-        \u2514\u2500\u2500 _source\n-            \u2514\u2500\u2500 nav.vue\n-            \u2514\u2500\u2500 util.js\n-    \u251c\u2500\u2500 conditions\n-        \u251c\u2500\u2500 conditions.vue\n-        \u2514\u2500\u2500 _source\n-            \u2514\u2500\u2500 search.vue\n-            \u2514\u2500\u2500 util.js\n-```\n-\n-##### 3.Prop\n-When you define Prop, you should always name it in camel format (camelCase) and use the connection line (-) when assigning values to the parent component.This follows the characteristics of each language, because it is case-insensitive in HTML tags, and the use of links is more friendly; in JavaScript, the more natural is the hump name.\n-\n-```\n-// Vue\n-props: {\n-    articleStatus: Boolean\n-}\n-// HTML\n-<article-item :article-status=\"true\"></article-item>\n-```\n-\n-The definition of Prop should specify its type, defaults, and validation as much as possible.\n-\n-Example\uff1a\n-\n-```\n-props: {\n-    attrM: Number,\n-    attrA: {\n-        type: String,\n-        required: true\n-    },\n-    attrZ: {\n-        type: Object,\n-        //  The default value of the array/object should be returned by a factory function\n-        default: function () {\n-            return {\n-                msg: 'achieve you and me'\n-            }\n-        }\n-    },\n-    attrE: {\n-        type: String,\n-        validator: function (v) {\n-            return !(['success', 'fail'].indexOf(v) === -1) \n-        }\n-    }\n-}\n-```\n-\n-##### 4.v-for\n-When performing v-for traversal, you should always bring a key value to make rendering more efficient when updating the DOM.\n-```\n-<ul>\n-    <li v-for=\"item in list\" :key=\"item.id\">\n-        {{ item.title }}\n-    </li>\n-</ul>\n-```\n-\n-v-for should be avoided on the same element as v-if (`for example: <li>`) because v-for has a higher priority than v-if. To avoid invalid calculations and rendering, you should try to use v-if Put it on top of the container's parent element.\n-```\n-<ul v-if=\"showList\">\n-    <li v-for=\"item in list\" :key=\"item.id\">\n-        {{ item.title }}\n-    </li>\n-</ul>\n-```\n-\n-##### 5.v-if / v-else-if / v-else\n-If the elements in the same set of v-if logic control are logically identical, Vue reuses the same part for more efficient element switching, `such as: value`. In order to avoid the unreasonable effect of multiplexing, you should add key to the same element for identification.\n-```\n-<div v-if=\"hasData\" key=\"mazey-data\">\n-    <span>{{ mazeyData }}</span>\n-</div>\n-<div v-else key=\"mazey-none\">\n-    <span>no data</span>\n-</div>\n-```\n-\n-##### 6.Instruction abbreviation\n-In order to unify the specification, the instruction abbreviation is always used. Using `v-bind`, `v-on` is not bad. Here is only a unified specification.\n-```\n-<input :value=\"mazeyUser\" @click=\"verifyUser\">\n-```\n-\n-##### 7.Top-level element order of single file components\n-Styles are packaged in a file, all the styles defined in a single vue file, the same name in other files will also take effect. All will have a top class name before creating a component.\n-Note: The sass plugin has been added to the project, and the sas syntax can be written directly in a single vue file.\n-For uniformity and ease of reading, they should be placed in the order of  `<template>`\u3001`<script>`\u3001`<style>`.\n-\n-```\n-<template>\n-  <div class=\"test-model\">\n-    test\n-  </div>\n-</template>\n-<script>\n-  export default {\n-    name: \"test\",\n-    data() {\n-      return {}\n-    },\n-    props: {},\n-    methods: {},\n-    watch: {},\n-    beforeCreate() {\n-    },\n-    created() {\n-    },\n-    beforeMount() {\n-    },\n-    mounted() {\n-    },\n-    beforeUpdate() {\n-    },\n-    updated() {\n-    },\n-    beforeDestroy() {\n-    },\n-    destroyed() {\n-    },\n-    computed: {},\n-    components: {},\n-  }\n-</script>\n-\n-<style lang=\"scss\" rel=\"stylesheet/scss\">\n-  .test-model {\n-\n-  }\n-</style>\n-\n-```\n-\n-\n-## JavaScript specification\n-\n-##### 1.var / let / const\n-It is recommended to no longer use var, but use let / const, prefer const. The use of any variable must be declared in advance, except that the function defined by function can be placed anywhere.\n-\n-##### 2.quotes\n-```\n-const foo = 'after division'\n-const bar = `${foo}\uff0cront-end engineer`\n-```\n-\n-##### 3.function\n-Anonymous functions use the arrow function uniformly. When multiple parameters/return values are used, the object's structure assignment is used first.\n-```\n-function getPersonInfo ({name, sex}) {\n-    // ...\n-    return {name, gender}\n-}\n-```\n-The function name is uniformly named with a camel name. The beginning of the capital letter is a constructor. The lowercase letters start with ordinary functions, and the new operator should not be used to operate ordinary functions.\n-\n-##### 4.object\n-```\n-const foo = {a: 0, b: 1}\n-const bar = JSON.parse(JSON.stringify(foo))\n-\n-const foo = {a: 0, b: 1}\n-const bar = {...foo, c: 2}\n-\n-const foo = {a: 3}\n-Object.assign(foo, {b: 4})\n-\n-const myMap = new Map([])\n-for (let [key, value] of myMap.entries()) {\n-    // ...\n-}\n-```\n-\n-##### 5.module\n-Unified management of project modules using import / export.\n-```\n-// lib.js\n-export default {}\n-\n-// app.js\n-import app from './lib'\n-```\n-\n-Import is placed at the top of the file.\n-\n-If the module has only one output value, use `export default`\uff0cotherwise no.\n-\n-## HTML / CSS\n-\n-##### 1.Label\n-\n-Do not write the type attribute when referencing external CSS or JavaScript. The HTML5 default type is the text/css and text/javascript properties, so there is no need to specify them.\n-```\n-<link rel=\"stylesheet\" href=\"//www.test.com/css/test.css\">\n-<script src=\"//www.test.com/js/test.js\"></script>\n-```\n-\n-##### 2.Naming\n-The naming of Class and ID should be semantic, and you can see what you are doing by looking at the name; multiple words are connected by a link.\n-```\n-// positive example\n-.test-header{\n-    font-size: 20px;\n-}\n-```\n-\n-##### 3.Attribute abbreviation\n-CSS attributes use abbreviations as much as possible to improve the efficiency and ease of understanding of the code.\n-\n-```\n-// counter example\n-border-width: 1px;\n-border-style: solid;\n-border-color: #ccc;\n-\n-// positive example\n-border: 1px solid #ccc;\n-```\n-\n-##### 4.Document type\n-\n-The HTML5 standard should always be used.\n-\n-```\n-<!DOCTYPE html>\n-```\n-\n-##### 5.Notes\n-A block comment should be written to a module file.\n-```\n-/**\n-* @module mazey/api\n-* @author Mazey <mazey@mazey.net>\n-* @description test.\n-* */\n-```\n-\n-\n-## interface\n-\n-##### All interfaces are returned as Promise \n-Note that non-zero is wrong for catching catch\n-\n-```\n-const test = () => {\n-  return new Promise((resolve, reject) => {\n-    resolve({\n-      a:1\n-    })\n-  })\n-}\n-\n-// transfer\n-test.then(res => {\n-  console.log(res)\n-  // {a:1}\n-})\n-```\n-\n-Normal return\n-```\n-{\n-  code:0,\n-  data:{}\n-  msg:'success'\n-}\n-```\n-\n-\u9519\u8bef\u8fd4\u56de\n-```\n-{\n-  code:10000, \n-  data:{}\n-  msg:'failed'\n-}\n-```\n-\n-##### Related interface path\n-\n-dag related interface `src/js/conf/home/store/dag/actions.js`\n-\n-Data Source Center Related Interfaces  `src/js/conf/home/store/datasource/actions.js`\n-\n-Project Management Related Interfaces `src/js/conf/home/store/projects/actions.js`\n-\n-Resource Center Related Interfaces `src/js/conf/home/store/resource/actions.js`\n-\n-Security Center Related Interfaces `src/js/conf/home/store/security/actions.js`\n-\n-User Center Related Interfaces `src/js/conf/home/store/user/actions.js`\n-\n-\n-\n-## Extended development\n-\n-##### 1.Add node\n-\n-(1) First place the icon icon of the node in the `src/js/conf/home/pages/dag/img `folder, and note the English name of the node defined by the `toolbar_${in the background. For example: SHELL}.png`\n-\n-(2)  Find the `tasksType` object in `src/js/conf/home/pages/dag/_source/config.js` and add it to it.\n-```\n-'DEPENDENT': {  //  The background definition node type English name is used as the key value\n-  desc: 'DEPENDENT',  // tooltip desc\n-  color: '#2FBFD8'  // The color represented is mainly used for tree and gantt\n-}\n-```\n-\n-(3)  Add a `${node type (lowercase)}`.vue file in `src/js/conf/home/pages/dag/_source/formModel/tasks`. The contents of the components related to the current node are written here. Must belong to a node component must have a function _verification () After the verification is successful, the relevant data of the current component is thrown to the parent component.\n-```\n-/**\n- * Verification\n-*/\n-  _verification () {\n-    // datasource subcomponent verification\n-    if (!this.$refs.refDs._verifDatasource()) {\n-      return false\n-    }\n-\n-    // verification function\n-    if (!this.method) {\n-      this.$message.warning(`${i18n.$t('Please enter method')}`)\n-      return false\n-    }\n-\n-    // localParams subcomponent validation\n-    if (!this.$refs.refLocalParams._verifProp()) {\n-      return false\n-    }\n-    // store\n-    this.$emit('on-params', {\n-      type: this.type,\n-      datasource: this.datasource,\n-      method: this.method,\n-      localParams: this.localParams\n-    })\n-    return true\n-  }\n-```\n-\n-(4) Common components used inside the node component are under` _source`, and `commcon.js` is used to configure public data.\n-\n-##### 2.Increase the status type\n-\n-(1) Find the `tasksState` object in `src/js/conf/home/pages/dag/_source/config.js` and add it to it.\n-\n-```\n- 'WAITTING_DEPEND': {  // 'WAITTING_DEPEND': {  //\u540e\u7aef\u5b9a\u4e49\u72b6\u6001\u7c7b\u578b \u524d\u7aef\u7528\u4f5ckey\u503c\n-  id: 11,  // front-end definition id is used as a sort\n-  desc: `${i18n.$t('waiting for dependency')}`,  // tooltip desc\n-  color: '#5101be',  // The color represented is mainly used for tree and gantt\n-  icoUnicode: '&#xe68c;',  // font icon\n-  isSpin: false  // whether to rotate (requires code judgment)\n-}\n-```\n-\n-##### 3.Add the action bar tool\n-(1)  Find the `toolOper` object in `src/js/conf/home/pages/dag/_source/config.js` and add it to it.\n-```\n-{\n-  code: 'pointer',  // tool identifier\n-  icon: '&#xe781;',  // tool icon\n-  disable: disable,  // disable\n-  desc: `${i18n.$t('Drag node and selected item')}`  // tooltip desc\n-}\n-```\n-\n-(2) Tool classes are returned as a constructor  `src/js/conf/home/pages/dag/_source/plugIn`\n-\n-`downChart.js`  =>  dag image download processing\n-\n-`dragZoom.js`  =>  mouse zoom effect processing\n-\n-`jsPlumbHandle.js`  =>  drag and drop line processing\n-\n-`util.js`  =>   belongs to the `plugIn` tool class\n-\n-\n-The operation is handled in the `src/js/conf/home/pages/dag/_source/dag.js` => `toolbarEvent` event.\n-\n-\n-##### 3.Add a routing page\n-\n-(1) First add a routing address`src/js/conf/home/router/index.js` in route management\n-```\n-routing address{\n-  path: '/test',  // routing address\n-  name: 'test',  // alias\n-  component: resolve => require(['../pages/test/index'], resolve),  // route corresponding component entry file\n-  meta: {\n-    title: `${i18n.$t('test')} - EasyScheduler`  // title display\n-  }\n-},\n-```\n-\n-(2)Create a `test` folder in `src/js/conf/home/pages` and create an `index.vue `entry file in the folder.\n-\n-    This will give you direct access to`http://localhost:8888/#/test`\n-\n-\n-##### 4.Increase the preset mailbox\n-\n-Find the `src/lib/localData/email.js` startup and timed email address input to automatically pull down the match.\n-```\n-export default [\"test@analysys.com.cn\",\"test1@analysys.com.cn\",\"test3@analysys.com.cn\"]\n-```\n-\n-##### 5.Authority management and disabled state processing\n-\n-The permission gives the userType according to the backUser interface `getUserInfo` interface: `\"ADMIN_USER/GENERAL_USER\" `permission to control whether the page operation button is `disabled`.\n-\n-specific operation\uff1a`src/js/module/permissions/index.js`\n-\n-disabled processing\uff1a`src/js/module/mixin/disabledState.js`\n-",
                "changes": 650
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/auth-project.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/auth-project.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/auth-project.png",
                "deletions": 0,
                "sha": "40c6fecb0e06952e802b182dab037c4e19a5b211",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/auth-project.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/complement.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/complement.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/complement.png",
                "deletions": 0,
                "sha": "f5d87ab57ac651ff0e0a4b4ca3f2097396567014",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/complement.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-b-and-c.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/depend-b-and-c.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/depend-b-and-c.png",
                "deletions": 0,
                "sha": "693725d30fa69232a265a00496180336ac16eda8",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-b-and-c.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-last-tuesday.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/depend-last-tuesday.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/depend-last-tuesday.png",
                "deletions": 0,
                "sha": "53fc99f5fb97039369701b0d97babe8d313ab907",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-last-tuesday.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-week.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/depend-week.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/depend-week.png",
                "deletions": 0,
                "sha": "567648168c1d0417537194fc97be016b5a8e13fd",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/depend-week.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/save-definition.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/save-definition.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/save-definition.png",
                "deletions": 0,
                "sha": "ffde6b474267240e39e829e66baff6d95e5017d9",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/save-definition.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/save-global-parameters.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/save-global-parameters.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/save-global-parameters.png",
                "deletions": 0,
                "sha": "33454b6b644add45d1e03592f776ead04b0b6753",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/save-global-parameters.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/start-process.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/start-process.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/start-process.png",
                "deletions": 0,
                "sha": "3d535f393786102d213cda39d6bae6d4bbfd6273",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/start-process.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/timing.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/images/timing.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/images/timing.png",
                "deletions": 0,
                "sha": "a1642b73d1804057af6833ec61a49e367d9755f7",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/images/timing.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/quick-start.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/quick-start.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/quick-start.md",
                "deletions": 53,
                "sha": "a1dc255345f383bb52cfdd6edd5b49a08847282f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/quick-start.md",
                "patch": "@@ -1,53 +0,0 @@\n-# Quick Start\n-\n-* Administrator user login\n-\n-  > Address\uff1a192.168.xx.xx:8888  Username and password\uff1aadmin/escheduler123\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/48329107/61701549-ee738000-ad70-11e9-8d75-87ce04a0152f.png\" width=\"60%\" />\n- </p>\n-\n-* Create queue\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/48329107/61701943-896c5a00-ad71-11e9-99b8-a279762f1bc8.png\" width=\"60%\" />\n- </p>\n-\n-  * Create tenant\n-      <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/48329107/61702051-bb7dbc00-ad71-11e9-86e1-1c328cafe916.png\" width=\"60%\" />\n-  </p>\n-\n-  * Creating Ordinary Users\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61704402-3517a900-ad76-11e9-865a-6325041d97e2.png\" width=\"60%\" />\n- </p>\n-\n-  * Create an alarm group\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61704553-845dd980-ad76-11e9-85f1-05f33111409e.png\" width=\"60%\" />\n-  </p>\n-\n-  * Log in with regular users\n-  > Click on the user name in the upper right corner to \"exit\" and re-use the normal user login.\n-\n-  * Project Management - > Create Project - > Click on Project Name\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61704688-dd2d7200-ad76-11e9-82ee-0833b16bd88f.png\" width=\"60%\" />\n- </p>\n-\n-  * Click Workflow Definition - > Create Workflow Definition - > Online Process Definition\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61705638-c425c080-ad78-11e9-8619-6c21b61a24c9.png\" width=\"60%\" />\n- </p>\n-\n-  * Running Process Definition - > Click Workflow Instance - > Click Process Instance Name - > Double-click Task Node - > View Task Execution Log\n-\n- <p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61705356-34801200-ad78-11e9-8d60-9b7494231028.png\" width=\"60%\" />\n-</p>\n-\n-",
                "changes": 53
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/system-manual.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/system-manual.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/system-manual.md",
                "deletions": 699,
                "sha": "d571e1d66f865b2a660358e586761d90251b5ea2",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/system-manual.md",
                "patch": "@@ -1,699 +0,0 @@\n-# System Use Manual\n-\n-## Operational Guidelines\n-\n-### Create a project\n-\n-  - Click \"Project - > Create Project\", enter project name,  description, and click \"Submit\" to create a new project.\n-  - Click on the project name to enter the project home page.\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61776719-2ee50380-ae2e-11e9-9d11-41de8907efb5.png\" width=\"60%\" />\n- </p>\n-\n-> Project Home Page contains task status statistics, process status statistics.\n-\n- - Task State Statistics: It refers to the statistics of the number of tasks to be run, failed, running, completed and succeeded in a given time frame.\n- - Process State Statistics: It refers to the statistics of the number of waiting, failing, running, completing and succeeding process instances in a specified time range.\n- - Process Definition Statistics: The process definition created by the user and the process definition granted by the administrator to the user are counted.\n-\n-\n-### Creating Process definitions\n-  - Go to the project home page, click \"Process definitions\" and enter the list page of process definition.\n-  - Click \"Create process\" to create a new process definition.\n-  - Drag the \"SHELL\" node to the canvas and add a shell task.\n-  - Fill in the Node Name, Description, and Script fields.\n-  - Selecting \"task priority\" will give priority to high-level tasks in the execution queue. Tasks with the same priority will be executed in the first-in-first-out order.\n-  - Timeout alarm. Fill in \"Overtime Time\". When the task execution time exceeds the overtime, it can alarm and fail over time.\n-  - Fill in \"Custom Parameters\" and refer to [Custom Parameters](#Custom Parameters)\n-    <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61778402-42459e00-ae31-11e9-96c6-8fd7fed8fed2.png\" width=\"60%\" />\n-      </p>\n-  - Increase the order of execution between nodes: click \"line connection\". As shown, task 1 and task 3 are executed in parallel. When task 1 is executed, task 2 and task 3 are executed simultaneously.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61778247-f98de500-ae30-11e9-8f11-cce0530c3ff2.png\" width=\"60%\" />\n- </p>\n-\n-  - Delete dependencies: Click on the arrow icon to \"drag nodes and select items\", select the connection line, click on the delete icon to delete dependencies between nodes.\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61778800-052ddb80-ae32-11e9-8ac0-4f13466d3515.png\" width=\"60%\" />\n- </p>\n-\n-  - Click \"Save\", enter the name of the process definition, the description of the process definition, and set the global parameters.\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/save-definition.png\" width=\"60%\" />\n- </p>\n-\n-  - For other types of nodes, refer to [task node types and parameter settings](#task node types and parameter settings)\n-\n-### Execution process definition\n-  - **The process definition of the off-line state can be edited, but not run**, so the on-line workflow is the first step.\n-  > Click on the Process definition, return to the list of process definitions, click on the icon \"online\", online process definition.\n-\n-  > Before setting workflow offline, the timed tasks in timed management should be offline, so that the definition of workflow can be set offline successfully. \n-\n-  - Click \"Run\" to execute the process. Description of operation parameters\uff1a\n-    * Failure strategy\uff1a**When a task node fails to execute, other parallel task nodes need to execute the strategy**\u3002\u201dContinue \"Representation: Other task nodes perform normally\", \"End\" Representation: Terminate all ongoing tasks and terminate the entire process.\n-    * Notification strategy\uff1aWhen the process is over, send process execution information notification mail according to the process status.\n-    * Process priority: The priority of process running is divided into five levels:the highest, the high, the medium, the low, and the lowest . High-level processes are executed first in the execution queue, and processes with the same priority are executed first in first out order.\n-    * Worker group: This process can only be executed in a specified machine group. Default, by default, can be executed on any worker.\n-    * Notification group: When the process ends or fault tolerance occurs, process information is sent to all members of the notification group by mail.\n-    * Recipient: Enter the mailbox and press Enter key to save. When the process ends and fault tolerance occurs, an alert message is sent to the recipient list.\n-    * Cc: Enter the mailbox and press Enter key to save. When the process is over and fault-tolerant occurs, alarm messages are copied to the copier list.\n-    \n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/start-process.png\" width=\"60%\" />\n- </p>\n-\n-  * Complement: To implement the workflow definition of a specified date, you can select the time range of the complement (currently only support for continuous days), such as the data from May 1 to May 10, as shown in the figure:\n-  \n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/complement.png\" width=\"60%\" />\n- </p>\n-\n-> Complement execution mode includes serial execution and parallel execution. In serial mode, the complement will be executed sequentially from May 1 to May 10. In parallel mode, the tasks from May 1 to May 10 will be executed simultaneously.\n-\n-### Timing Process Definition\n-  - Create Timing: \"Process Definition - > Timing\"\n-  - Choose start-stop time, in the start-stop time range, regular normal work, beyond the scope, will not continue to produce timed workflow instances.\n-  \n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/timing.png\" width=\"60%\" />\n- </p>\n-\n-  - Add a timer to be executed once a day at 5:00 a.m. as shown below:\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61781968-d9adef80-ae37-11e9-9e90-3d9f0b3eb998.png\" width=\"60%\" />\n- </p>\n-\n-  - Timely online\uff0c**the newly created timer is offline. You need to click \"Timing Management - >online\" to work properly.**\n-\n-### View process instances\n-  > Click on \"Process Instances\" to view the list of process instances.\n-\n-  > Click on the process name to see the status of task execution.\n-\n-  <p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61855837-6ff31b80-aef3-11e9-8464-2fb5773709df.png\" width=\"60%\" />\n- </p>\n-\n-  > Click on the task node, click \"View Log\" to view the task execution log.\n-\n-  <p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783070-bdab4d80-ae39-11e9-9ada-355614fbb7f7.png\" width=\"60%\" />\n- </p>\n-\n- > Click on the task instance node, click **View History** to view the list of task instances that the process instance runs.\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61783240-05ca7000-ae3a-11e9-8c10-591a7635834a.png\" width=\"60%\" />\n-  </p>\n-\n-\n-  > Operations on workflow instances:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783291-21357b00-ae3a-11e9-837c-fc3d85404410.png\" width=\"60%\" />\n-</p>\n-\n-  * Editor: You can edit the terminated process. When you save it after editing, you can choose whether to update the process definition or not.\n-  * Rerun: A process that has been terminated can be re-executed.\n-  * Recovery failure: For a failed process, a recovery failure operation can be performed, starting at the failed node.\n-  * Stop: Stop the running process, the background will `kill` he worker process first, then `kill -9` operation.\n-  * Pause\uff1aThe running process can be **suspended**, the system state becomes **waiting to be executed**, waiting for the end of the task being executed, and suspending the next task to be executed.\n-  * Restore pause: **The suspended process** can be restored and run directly from the suspended node\n-  * Delete: Delete process instances and task instances under process instances\n-  * Gantt diagram: The vertical axis of Gantt diagram is the topological ordering of task instances under a process instance, and the horizontal axis is the running time of task instances, as shown in the figure:\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61783596-aa4cb200-ae3a-11e9-9798-e795f80dae96.png\" width=\"60%\" />\n-</p>\n-\n-### View task instances\n-  > Click on \"Task Instance\" to enter the Task List page and query the performance of the task.\n-  >\n-  >\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783544-91dc9780-ae3a-11e9-9dca-dfd901f1fe83.png\" width=\"60%\" />\n-</p>\n-\n-  > Click \"View Log\" in the action column to view the log of task execution.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783441-60fc6280-ae3a-11e9-8631-963dcf78467b.png\" width=\"60%\" />\n-</p>\n-\n-### Create data source\n-  > Data Source Center supports MySQL, POSTGRESQL, HIVE and Spark data sources.\n-\n-#### Create and edit MySQL data source\n-\n-  - Click on \"Datasource - > Create Datasources\" to create different types of datasources according to requirements.\n-- Datasource: Select MYSQL\n-- Datasource Name: Name of Input Datasource\n-- Description: Description of input datasources\n-- IP: Enter the IP to connect to MySQL\n-- Port: Enter the port to connect MySQL\n-- User name: Set the username to connect to MySQL\n-- Password: Set the password to connect to MySQL\n-- Database name: Enter the name of the database connecting MySQL\n-- Jdbc connection parameters: parameter settings for MySQL connections, filled in as JSON\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783812-129b9380-ae3b-11e9-9b9c-77870371c5f3.png\" width=\"60%\" />\n- </p>\n-\n-  > Click \"Test Connect\" to test whether the data source can be successfully connected.\n-  >\n-  >\n-\n-#### Create and edit POSTGRESQL data source\n-\n-- Datasource: Select POSTGRESQL\n-- Datasource Name: Name of Input Data Source\n-- Description: Description of input data sources\n-- IP: Enter IP to connect to POSTGRESQL\n-- Port: Input port to connect POSTGRESQL\n-- Username: Set the username to connect to POSTGRESQL\n-- Password: Set the password to connect to POSTGRESQL\n-- Database name: Enter the name of the database connecting to POSTGRESQL\n-- Jdbc connection parameters: parameter settings for POSTGRESQL connections, filled in as JSON\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61783968-60180080-ae3b-11e9-91b7-36d49246a205.png\" width=\"60%\" />\n- </p>\n-\n-#### Create and edit HIVE data source\n-\n-1.Connect with HiveServer 2\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61784129-b9802f80-ae3b-11e9-8a27-7be23e0953be.png\" width=\"60%\" />\n-  </p>\n-\n-  - Datasource: Select HIVE\n-- Datasource Name: Name of Input Datasource\n-- Description: Description of input datasources\n-- IP: Enter IP to connect to HIVE\n-- Port: Input port to connect to HIVE\n-- Username: Set the username to connect to HIVE\n-- Password: Set the password to connect to HIVE\n-- Database Name: Enter the name of the database connecting to HIVE\n-- Jdbc connection parameters: parameter settings for HIVE connections, filled in in as JSON\n-\n-2.Connect using Hive Server 2 HA Zookeeper mode\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61784420-3dd2b280-ae3c-11e9-894a-5b896863d37a.png\" width=\"60%\" />\n-  </p>\n-\n-\n-Note: If **kerberos** is turned on, you need to fill in **Principal**\n-<p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61784847-0adcee80-ae3d-11e9-8ac7-ba8a13aef90c.png\" width=\"60%\" />\n-  </p>\n-\n-\n-\n-\n-#### Create and Edit Datasource\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/48329107/61853431-7af77d00-aeee-11e9-8e2e-95ba6cea43c8.png\" width=\"60%\" />\n- </p>\n-\n-- Datasource: Select Spark\n-- Datasource Name: Name of Input Datasource\n-- Description: Description of input datasources\n-- IP: Enter the IP to connect to Spark\n-- Port: Input port to connect Spark\n-- Username: Set the username to connect to Spark\n-- Password: Set the password to connect to Spark\n-- Database name: Enter the name of the database connecting to Spark\n-- Jdbc Connection Parameters: Parameter settings for Spark Connections, filled in as JSON\n-\n-\n-\n-Note: If **kerberos** If Kerberos is turned on, you need to fill in  **Principal**\n-\n-<p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/48329107/61853668-0709a480-aeef-11e9-8960-92107dd1a9ca.png\" width=\"60%\" />\n-  </p>\n-\n-### Upload Resources\n-  - Upload resource files and udf functions, all uploaded files and resources will be stored on hdfs, so the following configuration items are required:\n-\n-```\n-conf/common/common.properties\n-    -- hdfs.startup.state=true\n-conf/common/hadoop.properties  \n-    -- fs.defaultFS=hdfs://xxxx:8020  \n-    -- yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx\n-    -- yarn.application.status.address=http://xxxx:8088/ws/v1/cluster/apps/%s\n-```\n-\n-#### File Manage\n-\n-  > It is the management of various resource files, including creating basic txt/log/sh/conf files, uploading jar packages and other types of files, editing, downloading, deleting and other operations.\n-  >\n-  >\n-  > <p align=\"center\">\n-  >  <img src=\"https://user-images.githubusercontent.com/53217792/61785274-ed5c5480-ae3d-11e9-8461-2178f49b228d.png\" width=\"60%\" />\n-  > </p>\n-\n-  * Create file\n- > File formats support the following types\uff1atxt\u3001log\u3001sh\u3001conf\u3001cfg\u3001py\u3001java\u3001sql\u3001xml\u3001hql\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61841049-f133b980-aec5-11e9-8ac8-db97cdccc599.png\" width=\"60%\" />\n- </p>\n-\n-  * Upload Files\n-\n-> Upload Files: Click the Upload button to upload, drag the file to the upload area, and the file name will automatically complete the uploaded file name.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61841179-73bc7900-aec6-11e9-8780-28756e684754.png\" width=\"60%\" />\n- </p>\n-\n-\n-  * File View\n-\n-> For viewable file types, click on the file name to view file details\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61841247-9cdd0980-aec6-11e9-9f6f-0a7dd145f865.png\" width=\"60%\" />\n- </p>\n-\n-  * Download files\n-\n-> You can download a file by clicking the download button in the top right corner of the file details, or by downloading the file under the download button after the file list.\n-\n-  * File rename\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61841322-f47b7500-aec6-11e9-93b1-b00328e7b69e.png\" width=\"60%\" />\n- </p>\n-\n-#### Delete\n->  File List - > Click the Delete button to delete the specified file\n-\n-#### Resource management\n-  > Resource management and file management functions are similar. The difference is that resource management is the UDF function of uploading, and file management uploads user programs, scripts and configuration files.\n-\n-  * Upload UDF resources\n-  > The same as uploading files.\n-\n-#### Function management\n-\n-  * Create UDF Functions\n-  > Click \"Create UDF Function\", enter parameters of udf function, select UDF resources, and click \"Submit\" to create udf function.\n-  >\n-  >\n-  >\n-  > Currently only temporary udf functions for HIVE are supported\n-  >\n-  > \n-  >\n-  > - UDF function name: name when entering UDF Function\n-  > - Package Name: Full Path of Input UDF Function\n-  > - Parameter: Input parameters used to annotate functions\n-  > - Database Name: Reserved Field for Creating Permanent UDF Functions\n-  > - UDF Resources: Set up the resource files corresponding to the created UDF\n-  >\n-  > \n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61841562-c6e2fb80-aec7-11e9-9481-4202d63dab6f.png\" width=\"60%\" />\n- </p>\n-\n-## Security\n-\n-  - The security has the functions of queue management, tenant management, user management, warning group management, worker group manager, token manage and other functions. It can also authorize resources, data sources, projects, etc.\n-- Administrator login, default username password: admin/escheduler 123\n-\n-\n-\n-### Create queues\n-\n-\n-\n-  - Queues are used to execute spark, mapreduce and other programs, which require the use of \"queue\" parameters.\n-- \"Security\" - > \"Queue Manage\" - > \"Create Queue\" \n-     <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61841945-078f4480-aec9-11e9-92fb-05b6f42f07d6.png\" width=\"60%\" />\n-  </p>\n-\n-\n-### Create Tenants\n-  - The tenant corresponds to the account of Linux, which is used by the worker server to submit jobs. If Linux does not have this user, the worker would create the account when executing the task.\n-  - Tenant Code\uff1a**the tenant code is the only account on Linux that can't be duplicated.**\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61842372-8042d080-aeca-11e9-8c54-e3dee583eeff.png\" width=\"60%\" />\n-  </p>\n-\n-### Create Ordinary Users\n-  -  User types are **ordinary users** and **administrator users**..\n-    * Administrators have **authorization and user management** privileges, and no privileges to **create project and process-defined operations**.\n-    * Ordinary users can **create projects and create, edit, and execute process definitions**.\n-    * Note: **If the user switches the tenant, all resources under the tenant will be copied to the switched new tenant.**\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61842461-da439600-aeca-11e9-98e3-f8327dbafa60.png\" width=\"60%\" />\n- </p>\n-\n-### Create alarm group\n-  * The alarm group is a parameter set at start-up. After the process is finished, the status of the process and other information will be sent to the alarm group by mail.\n-  * New and Editorial Warning Group\n-    <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61842553-34445b80-aecb-11e9-84a8-3cc66b6c6135.png\" width=\"60%\" />\n-    </p>\n-\n-### Create Worker Group\n-  - Worker group provides a mechanism for tasks to run on a specified worker. Administrators create worker groups, which can be specified in task nodes and operation parameters. If the specified grouping is deleted or no grouping is specified, the task will run on any worker.\n-- Multiple IP addresses within a worker group (**aliases can not be written**), separated by **commas in English**\n-\n-  <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61842630-6b1a7180-aecb-11e9-8988-b4444de16b36.png\" width=\"60%\" />\n-  </p>\n-\n-### Token manage\n-  - Because the back-end interface has login check and token management, it provides a way to operate the system by calling the interface.\n-- Call examples:\n-\n-```\u4ee4\u724c\u8c03\u7528\u793a\u4f8b\n-    /**\n-     * test token\n-     */\n-    public  void doPOSTParam()throws Exception{\n-        // create HttpClient\n-        CloseableHttpClient httpclient = HttpClients.createDefault();\n-\n-        // create http post request\n-        HttpPost httpPost = new HttpPost(\"http://127.0.0.1:12345/escheduler/projects/create\");\n-        httpPost.setHeader(\"token\", \"123\");\n-        // set parameters\n-        List<NameValuePair> parameters = new ArrayList<NameValuePair>();\n-        parameters.add(new BasicNameValuePair(\"projectName\", \"qzw\"));\n-        parameters.add(new BasicNameValuePair(\"desc\", \"qzw\"));\n-        UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(parameters);\n-        httpPost.setEntity(formEntity);\n-        CloseableHttpResponse response = null;\n-        try {\n-            // execute\n-            response = httpclient.execute(httpPost);\n-            // response status code 200\n-            if (response.getStatusLine().getStatusCode() == 200) {\n-                String content = EntityUtils.toString(response.getEntity(), \"UTF-8\");\n-                System.out.println(content);\n-            }\n-        } finally {\n-            if (response != null) {\n-                response.close();\n-            }\n-            httpclient.close();\n-        }\n-    }\n-```\n-\n-### Grant authority\n-  - Granting permissions includes project permissions, resource permissions, datasource permissions, UDF Function permissions.\n-> Administrators can authorize projects, resources, data sources and UDF Functions that are not created by ordinary users. Because project, resource, data source and UDF Function are all authorized in the same way, the project authorization is introduced as an example.\n-\n-> Note\uff1aFor projects created by the user himself, the user has all the permissions. The list of items and the list of selected items will not be reflected\n-\n-  - 1.Click on the authorization button of the designated person as follows:\n-    <p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61843204-71a9e880-aecd-11e9-83ad-365d7bf99375.png\" width=\"60%\" />\n- </p>\n-\n-- 2.Select the project button to authorize the project\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/auth-project.png\" width=\"60%\" />\n- </p>\n-\n-### Monitor center\n-  - Service management is mainly to monitor and display the health status and basic information of each service in the system.\n-\n-#### Master monitor\n-  - Mainly related information about master.\n-<p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61843245-8edeb700-aecd-11e9-9916-ea50080e7d08.png\" width=\"60%\" />\n- </p>\n-\n-#### Worker monitor\n-  - Mainly related information of worker.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61843277-ae75df80-aecd-11e9-9667-b9f1615b6f3b.png\" width=\"60%\" />\n- </p>\n-\n-#### Zookeeper monitor\n-  - Mainly the configuration information of each worker and master in zookpeeper.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61843323-c64d6380-aecd-11e9-8392-1ca9b84cd794.png\" width=\"60%\" />\n- </p>\n-\n-#### Mysql monitor\n-  - Mainly the health status of mysql\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61843358-e11fd800-aecd-11e9-86d1-9490e48dc955.png\" width=\"60%\" />\n- </p>\n-\n-## Task Node Type and Parameter Setting\n-\n-### Shell\n-\n-  - The shell node, when the worker executes, generates a temporary shell script, which is executed by a Linux user with the same name as the tenant.\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_SHELL.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61843728-6788e980-aecf-11e9-8006-241a7ec5024b.png\" width=\"60%\" />\n- </p>`\n-\n-- Node name: The node name in a process definition is unique\n-- Run flag: Identify whether the node can be scheduled properly, and if it does not need to be executed, you can turn on the forbidden execution switch.\n-- Description : Describes the function of the node\n-- Number of failed retries: Number of failed task submissions, support drop-down and manual filling\n-- Failure Retry Interval: Interval between tasks that fail to resubmit tasks, support drop-down and manual filling\n-- Script: User-developed SHELL program\n-- Resources: A list of resource files that need to be invoked in a script\n-- Custom parameters: User-defined parameters that are part of SHELL replace the contents of scripts with ${variables}\n-\n-### SUB_PROCESS\n-  - The sub-process node is to execute an external workflow definition as an task node.\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_SUB_PROCESS.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61843799-adde4880-aecf-11e9-846e-f1696107029f.png\" width=\"60%\" />\n- </p>\n-\n-- Node name: The node name in a process definition is unique\n-- Run flag: Identify whether the node is scheduled properly\n-- Description: Describes the function of the node\n-- Sub-node: The process definition of the selected sub-process is selected, and the process definition of the selected sub-process can be jumped to by entering the sub-node in the upper right corner.\n-\n-### DEPENDENT\n-\n-  - Dependent nodes are **dependent checking nodes**. For example, process A depends on the successful execution of process B yesterday, and the dependent node checks whether process B has a successful execution instance yesterday.\n-\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_DEPENDENT.png) ask node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61844369-be8fbe00-aed1-11e9-965d-ddb9aeeba9db.png\" width=\"60%\" />\n- </p>\n-\n-  > Dependent nodes provide logical judgment functions, such as checking whether yesterday's B process was successful or whether the C process was successfully executed.\n-\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/depend-b-and-c.png\" width=\"80%\" />\n- </p>\n-\n-  > For example, process A is a weekly task and process B and C are daily tasks. Task A requires that task B and C be successfully executed every day of the last week, as shown in the figure:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/depend-week.png\" width=\"80%\" />\n- </p>\n-\n-  > If weekly A also needs to be implemented successfully on Tuesday:\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/depend-last-tuesday.png\" width=\"80%\" />\n- </p>\n-\n-###  PROCEDURE\n-  - The procedure is executed according to the selected data source.\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_PROCEDURE.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61844464-1af2dd80-aed2-11e9-9486-6cf1b8585aa5.png\" width=\"60%\" />\n- </p>\n-\n-- Datasource: The data source type of stored procedure supports MySQL and POSTGRESQL, and chooses the corresponding data source.\n-- Method: The method name of the stored procedure\n-- Custom parameters: Custom parameter types of stored procedures support IN and OUT, and data types support nine data types: VARCHAR, INTEGER, LONG, FLOAT, DOUBLE, DATE, TIME, TIMESTAMP and BOOLEAN.\n-\n-### SQL\n-  - Execute non-query SQL functionality\n-    <p align=\"center\">\n-      <img src=\"https://user-images.githubusercontent.com/53217792/61850397-d7569e80-aee6-11e9-9da0-c4d96deaa8a1.png\" width=\"60%\" />\n- </p>\n-\n-  - Executing the query SQL function, you can choose to send mail in the form of tables and attachments to the designated recipients.\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_SQL.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61850594-4d5b0580-aee7-11e9-9c9e-1934c91962b9.png\" width=\"60%\" />\n- </p>\n-\n-- Datasource: Select the corresponding datasource\n-- sql type: support query and non-query, query is select type query, there is a result set returned, you can specify mail notification as table, attachment or table attachment three templates. Non-query is not returned by result set, and is for update, delete, insert three types of operations\n-- sql parameter: input parameter format is key1 = value1; key2 = value2...\n-- sql statement: SQL statement\n-- UDF function: For HIVE type data sources, you can refer to UDF functions created in the resource center, other types of data sources do not support UDF functions for the time being.\n-- Custom parameters: SQL task type, and stored procedure is to customize the order of parameters to set values for methods. Custom parameter type and data type are the same as stored procedure task type. The difference is that the custom parameter of the SQL task type replaces the ${variable} in the SQL statement.\n-\n-\n-\n-### SPARK \n-\n-  - Through SPARK node, SPARK program can be directly executed. For spark node, worker will use `spark-submit` mode to submit tasks.\n-\n-> Drag the   ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_SPARK.png)  task node in the toolbar onto the palette and double-click the task node as follows:\n->\n-> \n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/48329107/61852935-3d462480-aeed-11e9-8241-415314bfc2e5.png\" width=\"60%\" />\n- </p>\n-\n-- Program Type: Support JAVA, Scala and Python\n-- Class of the main function: The full path of Main Class, the entry to the Spark program\n-- Master jar package: It's Spark's jar package\n-- Deployment: support three modes: yarn-cluster, yarn-client, and local\n-- Driver Kernel Number: Driver Kernel Number and Memory Number can be set\n-- Executor Number: Executor Number, Executor Memory Number and Executor Kernel Number can be set\n-- Command Line Parameters: Setting the input parameters of Spark program to support the replacement of custom parameter variables.\n-- Other parameters: support - jars, - files, - archives, - conf format\n-- Resource: If a resource file is referenced in other parameters, you need to select the specified resource.\n-- Custom parameters: User-defined parameters in MR locality that replace the contents in scripts with ${variables}\n-\n-Note: JAVA and Scala are just used for identification, no difference. If it's a Spark developed by Python, there's no class of the main function, and everything else is the same.\n-\n-### MapReduce(MR)\n-  - Using MR nodes, MR programs can be executed directly. For Mr nodes, worker submits tasks using `hadoop jar`\n-\n-\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_MR.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n- 1. JAVA program\n-\n- <p align=\"center\">\n-    <img src=\"https://user-images.githubusercontent.com/53217792/61851102-91023f00-aee8-11e9-9ac0-dbe588d860c2.png\" width=\"60%\" />\n-  </p>\n-\n-- Class of the main function: The full path of the MR program's entry Main Class\n-- Program Type: Select JAVA Language\n-- Master jar package: MR jar package\n-- Command Line Parameters: Setting the input parameters of MR program to support the replacement of custom parameter variables\n-- Other parameters: support - D, - files, - libjars, - archives format\n-- Resource: If a resource file is referenced in other parameters, you need to select the specified resource.\n-- Custom parameters: User-defined parameters in MR locality that replace the contents in scripts with ${variables}\n-\n-2. Python program\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61851224-f3f3d600-aee8-11e9-8862-435220bbda93.png\" width=\"60%\" />\n- </p>\n-\n-- Program Type: Select Python Language\n-- Main jar package: Python jar package running MR\n-- Other parameters: support - D, - mapper, - reducer, - input - output format, where user-defined parameters can be set, such as:\n-- mapper \"mapper.py 1\" - file mapper.py-reducer reducer.py-file reducer.py-input/journey/words.txt-output/journey/out/mr/${current TimeMillis}\n-- Among them, mapper. py 1 after - mapper is two parameters, the first parameter is mapper. py, and the second parameter is 1.\n-- Resource: If a resource file is referenced in other parameters, you need to select the specified resource.\n-- Custom parameters: User-defined parameters in MR locality that replace the contents in scripts with ${variables}\n-\n-### Python\n-  - With Python nodes, Python scripts can be executed directly. For Python nodes, worker will use `python ** `to submit tasks.\n-\n-\n-\n-\n-> Drag the ![PNG](https://analysys.github.io/easyscheduler_docs/images/toolbar_PYTHON.png) task node in the toolbar onto the palette and double-click the task node as follows:\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61851959-daec2480-aeea-11e9-83fd-3e00a030cb84.png\" width=\"60%\" />\n- </p>\n-\n-- Script: User-developed Python program\n-- Resource: A list of resource files that need to be invoked in a script\n-- Custom parameters: User-defined parameters that are part of Python that replace the contents in the script with ${variables}\n-\n-### System parameter\n-\n-<table>\n-    <tr><th>variable</th><th>meaning</th></tr>\n-    <tr>\n-        <td>${system.biz.date}</td>\n-        <td>The timing time of routine dispatching instance is one day before, in yyyyyMMdd format. When data is supplemented, the date + 1</td>\n-    </tr>\n-    <tr>\n-        <td>${system.biz.curdate}</td>\n-        <td> Daily scheduling example timing time, format is yyyyyMMdd, when supplementing data, the date + 1</td>\n-    </tr>\n-    <tr>\n-        <td>${system.datetime}</td>\n-        <td>Daily scheduling example timing time, format is yyyyyMMddHmmss, when supplementing data, the date + 1</td>\n-    </tr>\n-</table>\n-\n-\n-### Time Customization Parameters\n-\n-> Support code to customize the variable name, declaration: ${variable name}. It can refer to \"system parameters\" or specify \"constants\".\n-\n-> When we define this benchmark variable as $[...]\uff0c [yyyyMMddHHmmss] can be decomposed and combined arbitrarily, such as:$[yyyyMMdd], $[HHmmss], $[yyyy-MM-dd] ,etc.\n-\n-> Can also do this\uff1a\n->\n-> \n-\n-- Later N years: $[add_months (yyyyyyMMdd, 12*N)]\n-- The previous N years: $[add_months (yyyyyyMMdd, -12*N)]\n-- Later N months: $[add_months (yyyyyMMdd, N)]\n-- The first N months: $[add_months (yyyyyyMMdd, -N)]\n-- Later N weeks: $[yyyyyyMMdd + 7*N]\n-- The first N weeks: $[yyyyyMMdd-7*N]\n-- The day after that: $[yyyyyyMMdd + N]\n-- The day before yesterday: $[yyyyyMMdd-N]\n-- Later N hours: $[HHmmss + N/24]\n-- First N hours: $[HHmmss-N/24]\n-- After N minutes: $[HHmmss + N/24/60]\n-- First N minutes: $[HHmmss-N/24/60]\n-\n-\n-\n-### User-defined parameters\n-\n-> User-defined parameters are divided into global parameters and local parameters. Global parameters are the global parameters passed when the process definition and process instance are saved. Global parameters can be referenced by local parameters of any task node in the whole process.\n-\n-> For example:\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs/images/save-global-parameters.png\" width=\"60%\" />\n- </p>\n-\n-> global_bizdate is a global parameter, referring to system parameters.\n-\n-<p align=\"center\">\n-   <img src=\"https://user-images.githubusercontent.com/53217792/61857313-78992100-aef6-11e9-9ba3-521c6ca33ce3.png\" width=\"60%\" />\n- </p>\n-\n-> In tasks, local_param_bizdate refers to global parameters by  ${global_bizdate} for scripts, the value of variable local_param_bizdate can be referenced by${local_param_bizdate}, or the value of local_param_bizdate can be set directly by JDBC.\n-\n-\n-",
                "changes": 699
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/upgrade.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/en_US/upgrade.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/en_US/upgrade.md",
                "deletions": 39,
                "sha": "b5c743fd84e3783393e5d84b536a5f8b562702a9",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/en_US/upgrade.md",
                "patch": "@@ -1,39 +0,0 @@\n-\n-# EasyScheduler upgrade documentation\n-\n-## 1. Back up the previous version of the files and database\n-\n-## 2. Stop all services of escheduler\n-\n- `sh ./script/stop-all.sh`\n-\n-## 3. Download the new version of the installation package\n-\n-- [gitee](https://gitee.com/easyscheduler/EasyScheduler/attach_files), download the latest version of the front and back installation packages (backend referred to as escheduler-backend, front end referred to as escheduler-ui)\n-- The following upgrade operations need to be performed in the new version of the directory\n-\n-## 4. Database upgrade\n-- Modify the following properties in conf/dao/data_source.properties\n-\n-```\n-    spring.datasource.url\n-    spring.datasource.username\n-    spring.datasource.password\n-```\n-\n-- Execute database upgrade script\n-\n-`sh ./script/upgrade-escheduler.sh`\n-\n-## 5. Backend service upgrade\n-\n-- Modify the content of the install.sh configuration and execute the upgrade script\n-  \n-  `sh install.sh`\n-\n-## 6. Frontend service upgrade\n-\n-- Overwrite the previous version of the dist directory\n-- Restart the nginx service\n-  \n-    `systemctl restart nginx`\n\\ No newline at end of file",
                "changes": 39
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.1-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.0.1-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.0.1-release.md",
                "deletions": 16,
                "sha": "1902fbb04aae1d4d0e810fdb724cc79d335f1e8a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.1-release.md",
                "patch": "@@ -1,16 +0,0 @@\n-Easy Scheduler Release 1.0.1\n-===\n-Easy Scheduler 1.0.2\u662f1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u4e8c\u4e2a\u7248\u672c\u3002\u66f4\u65b0\u5185\u5bb9\u5177\u4f53\u5982\u4e0b\uff1a\n-\n-- 1,outlook TSL \u53d1\u90ae\u4ef6\u652f\u6301\n-- 2,servlet \u548c protobuf jar\u51b2\u7a81\u89e3\u51b3\n-- 3,\u521b\u5efa\u79df\u6237\u540c\u65f6\u5efa\u7acblinux\u7528\u6237\n-- 4,\u91cd\u8dd1\u65f6\u95f4\u8d1f\u6570\n-- 5,\u5355\u673a\u548c\u96c6\u7fa4\u90fd\u53ef\u4ee5\u4f7f\u7528install.sh\u4e00\u952e\u90e8\u7f72\n-- 6,\u961f\u5217\u652f\u6301\u754c\u9762\u6dfb\u52a0\n-- 7,escheduler.t_escheduler_queue \u589e\u52a0\u4e86create_time\u548cupdate_time\u5b57\u6bb5\n-\n-\n-\n-\n-",
                "changes": 16
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.2-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.0.2-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.0.2-release.md",
                "deletions": 49,
                "sha": "c3bacc29c9b50299dd03c13a01aab93fbe7a7494",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.2-release.md",
                "patch": "@@ -1,49 +0,0 @@\n-Easy Scheduler Release 1.0.2\n-===\n-Easy Scheduler 1.0.2\u662f1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u4e09\u4e2a\u7248\u672c\u3002\u6b64\u7248\u672c\u589e\u52a0\u4e86\u8c03\u5ea6\u5f00\u653e\u63a5\u53e3\u3001worker\u5206\u7ec4(\u6307\u5b9a\u4efb\u52a1\u8fd0\u884c\u7684\u673a\u5668\u7ec4)\u3001\u4efb\u52a1\u6d41\u7a0b\u53ca\u670d\u52a1\u76d1\u63a7\u4ee5\u53ca\u5bf9oracle\u3001clickhouse\u7b49\u652f\u6301\uff0c\u5177\u4f53\u5982\u4e0b\uff1a\n-\n-\u65b0\u7279\u6027\uff1a\n-===\n-- [[EasyScheduler-79](https://github.com/analysys/EasyScheduler/issues/79)] \u8c03\u5ea6\u901a\u8fc7token\u65b9\u5f0f\u5bf9\u5916\u5f00\u653e\u63a5\u53e3\uff0c\u53ef\u4ee5\u901a\u8fc7api\u8fdb\u884c\u64cd\u4f5c\n-- [[EasyScheduler-138](https://github.com/analysys/EasyScheduler/issues/138)] \u53ef\u4ee5\u6307\u5b9a\u4efb\u52a1\u8fd0\u884c\u7684\u673a\u5668(\u7ec4)\n-- [[EasyScheduler-139](https://github.com/analysys/EasyScheduler/issues/139)] \u4efb\u52a1\u6d41\u7a0b\u76d1\u63a7\u53caMaster\u3001Worker\u3001Zookeeper\u8fd0\u884c\u72b6\u6001\u76d1\u63a7\n-- [[EasyScheduler-140](https://github.com/analysys/EasyScheduler/issues/140)] \u5de5\u4f5c\u6d41\u5b9a\u4e49\u2014\u589e\u52a0\u6d41\u7a0b\u8d85\u65f6\u62a5\u8b66\n-- [[EasyScheduler-134](https://github.com/analysys/EasyScheduler/issues/134)] \u4efb\u52a1\u7c7b\u578b\u652f\u6301Oracle\u3001CLICKHOUSE\u3001SQLSERVER\u3001IMPALA\n-- [[EasyScheduler-136](https://github.com/analysys/EasyScheduler/issues/136)] Sql\u4efb\u52a1\u8282\u70b9\u53ef\u4ee5\u72ec\u7acb\u9009\u53d6\u6284\u9001\u90ae\u4ef6\u7528\u6237 \n-- [[EasyScheduler-141](https://github.com/analysys/EasyScheduler/issues/141)] \u7528\u6237\u7ba1\u7406\u2014\u7528\u6237\u53ef\u4ee5\u7ed1\u5b9a\u961f\u5217,\u7528\u6237\u961f\u5217\u7ea7\u522b\u9ad8\u4e8e\u79df\u6237\u961f\u5217\u7ea7\u522b\uff0c\u5982\u679c\u7528\u6237\u961f\u5217\u4e3a\u7a7a\uff0c\u5219\u5bfb\u627e\u79df\u6237\u961f\u5217 \n-\n-\n-\n-\u589e\u5f3a\uff1a\n-===\n-- [[EasyScheduler-154](https://github.com/analysys/EasyScheduler/issues/154)] \u79df\u6237\u7f16\u7801\u5141\u8bb8\u7eaf\u6570\u5b57\u6216\u8005\u4e0b\u5212\u7ebf\u8fd9\u79cd\u7684\u7f16\u7801\n-\n-\n-\u4fee\u590d\uff1a\n-===\n-- [[EasyScheduler-135](https://github.com/analysys/EasyScheduler/issues/135)] Python\u4efb\u52a1\u53ef\u4ee5\u6307\u5b9apython\u7248\u672c\n-\n-- [[EasyScheduler-125](https://github.com/analysys/EasyScheduler/issues/125)] \u7528\u6237\u8d26\u53f7\u4e2d\u624b\u673a\u53f7\u65e0\u6cd5\u8bc6\u522b\u8054\u901a\u6700\u65b0\u53f7\u7801166\u5f00\u5934\n-\n-- [[EasyScheduler-178](https://github.com/analysys/EasyScheduler/issues/178)] \u4fee\u590dProcessDao\u91cc\u7ec6\u5fae\u7684\u62fc\u5199\u9519\u8bef \n-\n-- [[EasyScheduler-129](https://github.com/analysys/EasyScheduler/issues/129)] \u79df\u6237\u7ba1\u7406\u4e2d\uff0c\u79df\u6237\u7f16\u7801\u5e26\u4e0b\u5212\u7ebf\u7b49\u7279\u6b8a\u5b57\u7b26\u65e0\u6cd5\u901a\u8fc7\u6821\u9a8c \n-\n-\n-\u611f\u8c22\uff1a\n-===\n-\u6700\u540e\u4f46\u6700\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u4ee5\u4e0b\u4f19\u4f34\u7684\u8d21\u732e\u5c31\u6ca1\u6709\u65b0\u7248\u672c\u7684\u8bde\u751f\uff1a\n-\n-Baoqi , chubbyjiang , coreychen , chgxtony, cmdares , datuzi , dingchao, fanguanqun , \u98ce\u6e05\u626c, gaojun416 , googlechorme, hyperknob , hujiang75277381 , huanzui , kinssun, ivivi727 ,jimmy, jiangzhx , kevin5210 , lidongdai , lshmouse , lenboo, lyf198972 , lgcareer , lzy305 ,  moranrr ,  millionfor , mazhong8808, programlief, qiaozhanwei , roy110 , swxchappy , sherlock111 , samz406 , swxchappy, qq389401879 , lzy305,  vkingnew, William-GuoWei , woniulinux, yyl861, zhangxin1988, yangjiajun2014, yangqinlong, yangjiajun2014, zhzhenqin, zhangluck, zhanghaicheng1, zhuyizhizhi  \n-\n-\u4ee5\u53ca\u5fae\u4fe1\u7fa4\u91cc\u4f17\u591a\u7684\u70ed\u5fc3\u4f19\u4f34\uff01\u5728\u6b64\u975e\u5e38\u611f\u8c22\uff01\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-",
                "changes": 49
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.3-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.0.3-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.0.3-release.md",
                "deletions": 30,
                "sha": "d89e05dd9099ea7c55822adb939b3bbc1ee7acc1",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.3-release.md",
                "patch": "@@ -1,30 +0,0 @@\n-Easy Scheduler Release 1.0.3\n-===\n-Easy Scheduler 1.0.3\u662f1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u56db\u4e2a\u7248\u672c\u3002\n-\n-\u589e\u5f3a\uff1a\n-===\n--  [[EasyScheduler-482]](https://github.com/analysys/EasyScheduler/issues/482)sql\u4efb\u52a1\u4e2d\u7684\u90ae\u4ef6\u6807\u9898\u589e\u52a0\u4e86\u5bf9\u81ea\u5b9a\u4e49\u53d8\u91cf\u7684\u652f\u6301\n--  [[EasyScheduler-483]](https://github.com/analysys/EasyScheduler/issues/483)sql\u4efb\u52a1\u4e2d\u7684\u53d1\u90ae\u4ef6\u5931\u8d25,\u5219\u6b64sql\u4efb\u52a1\u4e3a\u5931\u8d25\n--  [[EasyScheduler-484]](https://github.com/analysys/EasyScheduler/issues/484)\u4fee\u6539sql\u4efb\u52a1\u4e2d\u81ea\u5b9a\u4e49\u53d8\u91cf\u7684\u66ff\u6362\u89c4\u5219,\u652f\u6301\u591a\u4e2a\u5355\u5f15\u53f7\u548c\u53cc\u5f15\u53f7\u7684\u66ff\u6362\n--  [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/485)\u521b\u5efa\u8d44\u6e90\u6587\u4ef6\u65f6\uff0c\u589e\u52a0\u5bf9\u8be5\u8d44\u6e90\u6587\u4ef6\u662f\u5426\u5728hdfs\u4e0a\u5df2\u5b58\u5728\u7684\u9a8c\u8bc1\n-\n-\u4fee\u590d\uff1a\n-===\n--  [[EasyScheduler-198]](https://github.com/analysys/EasyScheduler/issues/198) \u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\u6839\u636e\u5b9a\u65f6\u72b6\u6001\u548c\u66f4\u65b0\u65f6\u95f4\u8fdb\u884c\u6392\u5e8f\n--  [[EasyScheduler-419]](https://github.com/analysys/EasyScheduler/issues/419) \u4fee\u590d\u5728\u7ebf\u521b\u5efa\u6587\u4ef6\uff0chdfs\u6587\u4ef6\u672a\u521b\u5efa\uff0c\u5374\u8fd4\u56de\u6210\u529f\n--  [[EasyScheduler-481]](https://github.com/analysys/EasyScheduler/issues/481)\u4fee\u590djob\u4e0d\u5b58\u5728\u5b9a\u65f6\u65e0\u6cd5\u4e0b\u7ebf\u7684\u95ee\u9898\n--  [[EasyScheduler-425]](https://github.com/analysys/EasyScheduler/issues/425) kill\u4efb\u52a1\u65f6\u589e\u52a0\u5bf9\u5176\u5b50\u8fdb\u7a0b\u7684kill\n--  [[EasyScheduler-422]](https://github.com/analysys/EasyScheduler/issues/422) \u4fee\u590d\u66f4\u65b0\u8d44\u6e90\u6587\u4ef6\u65f6\u66f4\u65b0\u65f6\u95f4\u548c\u5927\u5c0f\u672a\u66f4\u65b0\u7684\u95ee\u9898\n--  [[EasyScheduler-431]](https://github.com/analysys/EasyScheduler/issues/431) \u4fee\u590d\u5220\u9664\u79df\u6237\u65f6,\u5982\u679c\u672a\u542f\u52a8hdfs,\u5219\u5220\u9664\u79df\u6237\u5931\u8d25\u7684\u95ee\u9898\n--  [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/486) shell\u8fdb\u7a0b\u9000\u51fa\uff0cyarn\u72b6\u6001\u975e\u7ec8\u6001\u7b49\u5f85\u5224\u65ad\n-\n-\u611f\u8c22\uff1a\n-===\n-\u6700\u540e\u4f46\u6700\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u4ee5\u4e0b\u4f19\u4f34\u7684\u8d21\u732e\u5c31\u6ca1\u6709\u65b0\u7248\u672c\u7684\u8bde\u751f\uff1a\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, \n-feloxx, coding-now, hymzcn, nysyxxg, chgxtony \n-\n-\u4ee5\u53ca\u5fae\u4fe1\u7fa4\u91cc\u4f17\u591a\u7684\u70ed\u5fc3\u4f19\u4f34\uff01\u5728\u6b64\u975e\u5e38\u611f\u8c22\uff01\n-",
                "changes": 30
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.4-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.0.4-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.0.4-release.md",
                "deletions": 28,
                "sha": "5df1027e08f5038acc2fbb4b3488c564e25bfebd",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.4-release.md",
                "patch": "@@ -1,28 +0,0 @@\n-Easy Scheduler Release 1.0.4\n-===\n-Easy Scheduler 1.0.4\u662f1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u4e94\u4e2a\u7248\u672c\u3002\n-\n-**\u4fee\u590d**\uff1a\n--  [[EasyScheduler-198]](https://github.com/analysys/EasyScheduler/issues/198) \u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\u6839\u636e\u5b9a\u65f6\u72b6\u6001\u548c\u66f4\u65b0\u65f6\u95f4\u8fdb\u884c\u6392\u5e8f\n--  [[EasyScheduler-419]](https://github.com/analysys/EasyScheduler/issues/419) \u4fee\u590d\u5728\u7ebf\u521b\u5efa\u6587\u4ef6\uff0chdfs\u6587\u4ef6\u672a\u521b\u5efa\uff0c\u5374\u8fd4\u56de\u6210\u529f\n--  [[EasyScheduler-481]](https://github.com/analysys/EasyScheduler/issues/481)\u4fee\u590djob\u4e0d\u5b58\u5728\u5b9a\u65f6\u65e0\u6cd5\u4e0b\u7ebf\u7684\u95ee\u9898\n--  [[EasyScheduler-425]](https://github.com/analysys/EasyScheduler/issues/425) kill\u4efb\u52a1\u65f6\u589e\u52a0\u5bf9\u5176\u5b50\u8fdb\u7a0b\u7684kill\n--  [[EasyScheduler-422]](https://github.com/analysys/EasyScheduler/issues/422) \u4fee\u590d\u66f4\u65b0\u8d44\u6e90\u6587\u4ef6\u65f6\u66f4\u65b0\u65f6\u95f4\u548c\u5927\u5c0f\u672a\u66f4\u65b0\u7684\u95ee\u9898\n--  [[EasyScheduler-431]](https://github.com/analysys/EasyScheduler/issues/431) \u4fee\u590d\u5220\u9664\u79df\u6237\u65f6,\u5982\u679c\u672a\u542f\u52a8hdfs,\u5219\u5220\u9664\u79df\u6237\u5931\u8d25\u7684\u95ee\u9898\n--  [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/486) shell\u8fdb\u7a0b\u9000\u51fa\uff0cyarn\u72b6\u6001\u975e\u7ec8\u6001\u7b49\u5f85\u5224\u65ad\n-\n-**\u589e\u5f3a**:\n--  [[EasyScheduler-482]](https://github.com/analysys/EasyScheduler/issues/482)sql\u4efb\u52a1\u4e2d\u7684\u90ae\u4ef6\u6807\u9898\u589e\u52a0\u4e86\u5bf9\u81ea\u5b9a\u4e49\u53d8\u91cf\u7684\u652f\u6301\n--  [[EasyScheduler-483]](https://github.com/analysys/EasyScheduler/issues/483)sql\u4efb\u52a1\u4e2d\u7684\u53d1\u90ae\u4ef6\u5931\u8d25,\u5219\u6b64sql\u4efb\u52a1\u4e3a\u5931\u8d25\n--  [[EasyScheduler-484]](https://github.com/analysys/EasyScheduler/issues/484)\u4fee\u6539sql\u4efb\u52a1\u4e2d\u81ea\u5b9a\u4e49\u53d8\u91cf\u7684\u66ff\u6362\u89c4\u5219,\u652f\u6301\u591a\u4e2a\u5355\u5f15\u53f7\u548c\u53cc\u5f15\u53f7\u7684\u66ff\u6362\n--  [[EasyScheduler-485]](https://github.com/analysys/EasyScheduler/issues/485)\u521b\u5efa\u8d44\u6e90\u6587\u4ef6\u65f6\uff0c\u589e\u52a0\u5bf9\u8be5\u8d44\u6e90\u6587\u4ef6\u662f\u5426\u5728hdfs\u4e0a\u5df2\u5b58\u5728\u7684\u9a8c\u8bc1\n-\n-\n-\u611f\u8c22\uff1a\n-===\n-\u6700\u540e\u4f46\u6700\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u4ee5\u4e0b\u4f19\u4f34\u7684\u8d21\u732e\u5c31\u6ca1\u6709\u65b0\u7248\u672c\u7684\u8bde\u751f(\u6392\u540d\u4e0d\u5206\u5148\u540e)\uff1a\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, \n-feloxx, coding-now, hymzcn, nysyxxg, chgxtony, lfyee, Crossoverrr, gj-zhang, sunnyingit, xianhu, zhengqiangtan\n-\n-\u4ee5\u53ca\u5fae\u4fe1\u7fa4/\u9489\u9489\u7fa4\u91cc\u4f17\u591a\u7684\u70ed\u5fc3\u4f19\u4f34\uff01\u5728\u6b64\u975e\u5e38\u611f\u8c22\uff01\n\\ No newline at end of file",
                "changes": 28
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.5-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.0.5-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.0.5-release.md",
                "deletions": 23,
                "sha": "da86c6b207caa837b37ac759676a6a439a4ba95f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.0.5-release.md",
                "patch": "@@ -1,23 +0,0 @@\n-Easy Scheduler Release 1.0.5\n-===\n-Easy Scheduler 1.0.5\u662f1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u516d\u4e2a\u7248\u672c\u3002\n-\n-\u589e\u5f3a\uff1a\n-===\n-- [[EasyScheduler-597]](https://github.com/analysys/EasyScheduler/issues/597)child process cannot extend father's receivers and cc\n-\n-\u4fee\u590d\n-===\n-- [[EasyScheduler-516]](https://github.com/analysys/EasyScheduler/issues/516)The task instance of MR cannot stop in some cases\n-- [[EasyScheduler-594]](https://github.com/analysys/EasyScheduler/issues/594)soft kill task \u540e \u8fdb\u7a0b\u4f9d\u65e7\u5b58\u5728(\u7236\u8fdb\u7a0b \u5b50\u8fdb\u7a0b) \n-\n-\n-\u611f\u8c22\uff1a\n-===\n-\u6700\u540e\u4f46\u6700\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u4ee5\u4e0b\u4f19\u4f34\u7684\u8d21\u732e\u5c31\u6ca1\u6709\u65b0\u7248\u672c\u7684\u8bde\u751f\uff1a\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, feloxx, coding-now, hymzcn, nysyxxg, chgxtony, gj-zhang, xianhu, sunnyingit,\n-zhengqiangtan, chinashenkai\n-\n-\u4ee5\u53ca\u5fae\u4fe1\u7fa4\u91cc\u4f17\u591a\u7684\u70ed\u5fc3\u4f19\u4f34\uff01\u5728\u6b64\u975e\u5e38\u611f\u8c22\uff01\n-",
                "changes": 23
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.1.0-release.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/1.1.0-release.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/1.1.0-release.md",
                "deletions": 63,
                "sha": "b603180708499bb63a7e596895fbb3bf271db420",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/1.1.0-release.md",
                "patch": "@@ -1,63 +0,0 @@\n-Easy Scheduler Release 1.1.0\n-===\n-Easy Scheduler 1.1.0\u662f1.1.x\u7cfb\u5217\u4e2d\u7684\u7b2c\u4e00\u4e2a\u7248\u672c\u3002\n-\n-\u65b0\u7279\u6027\uff1a\n-===\n-- [[EasyScheduler-391](https://github.com/analysys/EasyScheduler/issues/391)] run a process under a specified tenement user\n-- [[EasyScheduler-288](https://github.com/analysys/EasyScheduler/issues/288)] Feature/qiye_weixin\n-- [[EasyScheduler-189](https://github.com/analysys/EasyScheduler/issues/189)] Kerberos\u7b49\u5b89\u5168\u652f\u6301\n-- [[EasyScheduler-398](https://github.com/analysys/EasyScheduler/issues/398)]\u7ba1\u7406\u5458\uff0c\u6709\u79df\u6237\uff08install.sh\u8bbe\u7f6e\u9ed8\u8ba4\u79df\u6237\uff09\uff0c\u53ef\u4ee5\u521b\u5efa\u8d44\u6e90\u3001\u9879\u76ee\u548c\u6570\u636e\u6e90\uff08\u9650\u5236\u6709\u4e00\u4e2a\u7ba1\u7406\u5458\uff09\n-- [[EasyScheduler-293](https://github.com/analysys/EasyScheduler/issues/293)]\u70b9\u51fb\u8fd0\u884c\u6d41\u7a0b\u65f6\u5019\u9009\u62e9\u7684\u53c2\u6570\uff0c\u6ca1\u6709\u5730\u65b9\u53ef\u67e5\u770b\uff0c\u4e5f\u6ca1\u6709\u4fdd\u5b58\n-- [[EasyScheduler-401](https://github.com/analysys/EasyScheduler/issues/401)]\u5b9a\u65f6\u5f88\u5bb9\u6613\u5b9a\u65f6\u6bcf\u79d2\u4e00\u6b21\uff0c\u5b9a\u65f6\u5b8c\u6210\u4ee5\u540e\u53ef\u4ee5\u5728\u9875\u9762\u663e\u793a\u4e00\u4e0b\u4e0b\u6b21\u89e6\u53d1\u65f6\u95f4\n-- [[EasyScheduler-493](https://github.com/analysys/EasyScheduler/pull/493)]add datasource kerberos auth and FAQ modify and add resource upload s3\n-\n-\n-\u589e\u5f3a\uff1a\n-===\n-- [[EasyScheduler-227](https://github.com/analysys/EasyScheduler/issues/227)] upgrade spring-boot to 2.1.x and spring to 5.x\n-- [[EasyScheduler-434](https://github.com/analysys/EasyScheduler/issues/434)] worker\u8282\u70b9\u6570\u91cf zk\u548cmysql\u4e2d\u4e0d\u4e00\u81f4\n-- [[EasyScheduler-435](https://github.com/analysys/EasyScheduler/issues/435)]\u90ae\u7bb1\u683c\u5f0f\u7684\u9a8c\u8bc1\n-- [[EasyScheduler-441](https://github.com/analysys/EasyScheduler/issues/441)] \u7981\u6b62\u8fd0\u884c\u8282\u70b9\u52a0\u5165\u5df2\u5b8c\u6210\u8282\u70b9\u68c0\u6d4b\n-- [[EasyScheduler-400](https://github.com/analysys/EasyScheduler/issues/400)] \u9996\u9875\u9875\u9762\uff0c\u961f\u5217\u7edf\u8ba1\u4e0d\u548c\u8c10\uff0c\u547d\u4ee4\u7edf\u8ba1\u65e0\u6570\u636e\n-- [[EasyScheduler-395](https://github.com/analysys/EasyScheduler/issues/395)] \u5bf9\u4e8e\u5bb9\u9519\u6062\u590d\u7684\u6d41\u7a0b\uff0c\u72b6\u6001\u4e0d\u80fd\u4e3a **\u6b63\u5728\u8fd0\u884c\n-- [[EasyScheduler-529](https://github.com/analysys/EasyScheduler/issues/529)] optimize poll task from zookeeper\n-- [[EasyScheduler-242](https://github.com/analysys/EasyScheduler/issues/242)]worker-server\u8282\u70b9\u83b7\u53d6\u4efb\u52a1\u6027\u80fd\u95ee\u9898\n-- [[EasyScheduler-352](https://github.com/analysys/EasyScheduler/issues/352)]worker \u5206\u7ec4, \u961f\u5217\u6d88\u8d39\u95ee\u9898\n-- [[EasyScheduler-461](https://github.com/analysys/EasyScheduler/issues/461)]\u67e5\u770b\u6570\u636e\u6e90\u53c2\u6570\uff0c\u9700\u8981\u52a0\u5bc6\u8d26\u53f7\u5bc6\u7801\u4fe1\u606f\n-- [[EasyScheduler-396](https://github.com/analysys/EasyScheduler/issues/396)]Dockerfile\u4f18\u5316\uff0c\u5e76\u5173\u8054Dockerfile\u548cgithub\u5b9e\u73b0\u81ea\u52a8\u6253\u955c\u50cf\n-- [[EasyScheduler-389](https://github.com/analysys/EasyScheduler/issues/389)]service monitor cannot find the change of master/worker\n-- [[EasyScheduler-511](https://github.com/analysys/EasyScheduler/issues/511)]support recovery process from stop/kill nodes.\n-- [[EasyScheduler-399](https://github.com/analysys/EasyScheduler/issues/399)]HadoopUtils\u6307\u5b9a\u7528\u6237\u64cd\u4f5c\uff0c\u800c\u4e0d\u662f **\u90e8\u7f72\u7528\u6237\n-- [[EasyScheduler-378](https://github.com/analysys/EasyScheduler/issues/378)]Mailbox regular match\n-- [[EasyScheduler-625](https://github.com/analysys/EasyScheduler/issues/625)]EasyScheduler call shell \"task instance not set host\"\n-- [[EasyScheduler-622](https://github.com/analysys/EasyScheduler/issues/622)]Front-end interface deployment k8s, background deployment big data cluster session error\n-\n-\u4fee\u590d\uff1a\n-===\n-- [[EasyScheduler-394](https://github.com/analysys/EasyScheduler/issues/394)] master&worker\u90e8\u7f72\u5728\u540c\u4e00\u53f0\u673a\u5668\u4e0a\u65f6\uff0c\u5982\u679c\u91cd\u542fmaster&worker\u670d\u52a1\uff0c\u4f1a\u5bfc\u81f4\u4e4b\u524d\u8c03\u5ea6\u7684\u4efb\u52a1\u65e0\u6cd5\u7ee7\u7eed\u8c03\u5ea6\n-- [[EasyScheduler-469](https://github.com/analysys/EasyScheduler/issues/469)]Fix naming errors,monitor page\n-- [[EasyScheduler-392](https://github.com/analysys/EasyScheduler/issues/392)]Feature request: fix email regex check\n-- [[EasyScheduler-405](https://github.com/analysys/EasyScheduler/issues/405)]\u5b9a\u65f6\u4fee\u6539/\u6dfb\u52a0\u9875\u9762\uff0c\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\u4e0d\u80fd\u76f8\u540c\n-- [[EasyScheduler-517](https://github.com/analysys/EasyScheduler/issues/517)]\u8865\u6570 - \u5b50\u5de5\u4f5c\u6d41 - \u65f6\u95f4\u53c2\u6570 \n-- [[EasyScheduler-532](https://github.com/analysys/EasyScheduler/issues/532)]python\u8282\u70b9\u4e0d\u6267\u884c\u7684\u95ee\u9898 \n-- [[EasyScheduler-543](https://github.com/analysys/EasyScheduler/issues/543)]optimize datasource connection params safety\n-- [[EasyScheduler-569](https://github.com/analysys/EasyScheduler/issues/569)]\u5b9a\u65f6\u4efb\u52a1\u65e0\u6cd5\u771f\u6b63\u505c\u6b62\n-- [[EasyScheduler-463](https://github.com/analysys/EasyScheduler/issues/463)]\u90ae\u7bb1\u9a8c\u8bc1\u4e0d\u652f\u6301\u975e\u5e38\u89c1\u540e\u7f00\u90ae\u7bb1\n-- [[EasyScheduler-650](https://github.com/analysys/EasyScheduler/issues/650)]Creating a hive data source without a principal will cause the connection to fail\n-- [[EasyScheduler-641](https://github.com/analysys/EasyScheduler/issues/641)]The cellphone is not supported for 199 telecom segment when create a user\n-- [[EasyScheduler-627](https://github.com/analysys/EasyScheduler/issues/627)]Different sql node task logs in parallel in the same workflow will be mixed\n-- [[EasyScheduler-655](https://github.com/analysys/EasyScheduler/issues/655)]when deploy a spark task,the tentant queue not empty,set with a empty queue name \n-- [[EasyScheduler-667](https://github.com/analysys/EasyScheduler/issues/667)]HivePreparedStatement can't print the actual SQL executed \n-\n-\n-\n-\n-\u611f\u8c22\uff1a\n-===\n-\u6700\u540e\u4f46\u6700\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u4ee5\u4e0b\u4f19\u4f34\u7684\u8d21\u732e\u5c31\u6ca1\u6709\u65b0\u7248\u672c\u7684\u8bde\u751f\uff1a\n-\n-Baoqi, jimmy201602, samz406, petersear, millionfor, hyperknob, fanguanqun, yangqinlong, qq389401879, chgxtony, Stanfan, lfyee, thisnew, hujiang75277381, sunnyingit, lgbo-ustc, ivivi, lzy305, JackIllkid, telltime, lipengbo2018, wuchunfu, telltime, chenyuan9028, zhangzhipeng621, thisnew, 307526982,  crazycarry\n-\n-\u4ee5\u53ca\u5fae\u4fe1\u7fa4\u91cc\u4f17\u591a\u7684\u70ed\u5fc3\u4f19\u4f34\uff01\u5728\u6b64\u975e\u5e38\u611f\u8c22\uff01\n-",
                "changes": 63
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/EasyScheduler-FAQ.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/EasyScheduler-FAQ.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/EasyScheduler-FAQ.md",
                "deletions": 287,
                "sha": "360565a4ee560071f6d70df6f0a56957be7f3e15",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/EasyScheduler-FAQ.md",
                "patch": "@@ -1,287 +0,0 @@\n-## Q\uff1aEasyScheduler\u670d\u52a1\u4ecb\u7ecd\u53ca\u5efa\u8bae\u8fd0\u884c\u5185\u5b58\n-\n-A\uff1a EasyScheduler\u75315\u4e2a\u670d\u52a1\u7ec4\u6210\uff0cMasterServer\u3001WorkerServer\u3001ApiServer\u3001AlertServer\u3001LoggerServer\u548cUI\u3002\n-\n-| \u670d\u52a1                      | \u8bf4\u660e                                                         |\n-| ------------------------- | ------------------------------------------------------------ |\n-| MasterServer              | \u4e3b\u8981\u8d1f\u8d23 **DAG** \u7684\u5207\u5206\u548c\u4efb\u52a1\u72b6\u6001\u7684\u76d1\u63a7                      |\n-| WorkerServer/LoggerServer | \u4e3b\u8981\u8d1f\u8d23\u4efb\u52a1\u7684\u63d0\u4ea4\u3001\u6267\u884c\u548c\u4efb\u52a1\u72b6\u6001\u7684\u66f4\u65b0\u3002LoggerServer\u7528\u4e8eRest Api\u901a\u8fc7 **RPC** \u67e5\u770b\u65e5\u5fd7 |\n-| ApiServer                 | \u63d0\u4f9bRest Api\u670d\u52a1\uff0c\u4f9bUI\u8fdb\u884c\u8c03\u7528                               |\n-| AlertServer               | \u63d0\u4f9b\u544a\u8b66\u670d\u52a1                                                 |\n-| UI                        | \u524d\u7aef\u9875\u9762\u5c55\u793a                                                 |\n-\n-\u6ce8\u610f\uff1a**\u7531\u4e8e\u670d\u52a1\u6bd4\u8f83\u591a\uff0c\u5efa\u8bae\u5355\u673a\u90e8\u7f72\u6700\u597d\u662f4\u683816G\u4ee5\u4e0a**\n-\n----\n-\n-## Q\uff1a \u7ba1\u7406\u5458\u4e3a\u4ec0\u4e48\u4e0d\u80fd\u521b\u5efa\u9879\u76ee\n-\n-A\uff1a\u7ba1\u7406\u5458\u76ee\u524d\u5c5e\u4e8e\"**\u7eaf\u7ba1\u7406**\", \u6ca1\u6709\u79df\u6237\uff0c\u5373\u6ca1\u6709linux\u4e0a\u5bf9\u5e94\u7684\u7528\u6237\uff0c\u6240\u4ee5\u6ca1\u6709\u6267\u884c\u6743\u9650,  **\u6545\u6ca1\u6709\u6240\u5c5e\u7684\u9879\u76ee\u3001\u8d44\u6e90\u53ca\u6570\u636e\u6e90**\uff0c\u6240\u4ee5\u6ca1\u6709\u521b\u5efa\u6743\u9650\u3002**\u4f46\u662f\u6709\u6240\u6709\u7684\u67e5\u770b\u6743\u9650**\u3002\u5982\u679c\u9700\u8981\u521b\u5efa\u9879\u76ee\u7b49\u4e1a\u52a1\u64cd\u4f5c\uff0c**\u8bf7\u4f7f\u7528\u7ba1\u7406\u5458\u521b\u5efa\u79df\u6237\u548c\u666e\u901a\u7528\u6237\uff0c\u7136\u540e\u4f7f\u7528\u666e\u901a\u7528\u6237\u767b\u5f55\u8fdb\u884c\u64cd\u4f5c**\u3002\u6211\u4eec\u5c06\u4f1a\u57281.1.0\u7248\u672c\u4e2d\u5c06\u7ba1\u7406\u5458\u7684\u521b\u5efa\u548c\u6267\u884c\u6743\u9650\u653e\u5f00\uff0c\u7ba1\u7406\u5458\u5c06\u4f1a\u6709\u6240\u6709\u7684\u6743\u9650\n-\n----\n-\n-## Q\uff1a\u7cfb\u7edf\u652f\u6301\u54ea\u4e9b\u90ae\u7bb1\uff1f\n-\n-A\uff1a\u652f\u6301\u7edd\u5927\u591a\u6570\u90ae\u7bb1\uff0cqq\u3001163\u3001126\u3001139\u3001outlook\u3001aliyun\u7b49\u7686\u652f\u6301\u3002\u652f\u6301**TLS\u548cSSL**\u534f\u8bae\uff0c\u53ef\u4ee5\u5728alert.properties\u4e2d\u9009\u62e9\u6027\u914d\u7f6e\n-\n----\n-\n-## Q\uff1a\u5e38\u7528\u7684\u7cfb\u7edf\u53d8\u91cf\u65f6\u95f4\u53c2\u6570\u6709\u54ea\u4e9b\uff0c\u5982\u4f55\u4f7f\u7528\uff1f\n-\n-A\uff1a\u8bf7\u53c2\u8003 https://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.html#%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0\n-\n----\n-\n-## Q\uff1apip install kazoo \u8fd9\u4e2a\u5b89\u88c5\u62a5\u9519\u3002\u662f\u5fc5\u987b\u5b89\u88c5\u7684\u5417\uff1f\n-\n-A\uff1a \u8fd9\u4e2a\u662fpython\u8fde\u63a5zookeeper\u9700\u8981\u4f7f\u7528\u5230\u7684\uff0c\u5fc5\u987b\u8981\u5b89\u88c5\n-\n----\n-\n-## Q: \u600e\u4e48\u6307\u5b9a\u673a\u5668\u8fd0\u884c\u4efb\u52a1\n-\n-A\uff1a\u4f7f\u7528 **\u7ba1\u7406\u5458** \u521b\u5efaWorker\u5206\u7ec4\uff0c\u5728 **\u6d41\u7a0b\u5b9a\u4e49\u542f\u52a8** \u7684\u65f6\u5019\u53ef**\u6307\u5b9aWorker\u5206\u7ec4**\u6216\u8005\u5728**\u4efb\u52a1\u8282\u70b9\u4e0a\u6307\u5b9aWorker\u5206\u7ec4**\u3002\u5982\u679c\u4e0d\u6307\u5b9a\uff0c\u5219\u4f7f\u7528Default\uff0c**Default\u9ed8\u8ba4\u662f\u4f7f\u7528\u7684\u96c6\u7fa4\u91cc\u6240\u6709\u7684Worker\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u53f0\u6765\u8fdb\u884c\u4efb\u52a1\u63d0\u4ea4\u3001\u6267\u884c**\n-\n----\n-\n-## Q\uff1a\u4efb\u52a1\u7684\u4f18\u5148\u7ea7\n-\n-A\uff1a\u6211\u4eec\u540c\u65f6 **\u652f\u6301\u6d41\u7a0b\u548c\u4efb\u52a1\u7684\u4f18\u5148\u7ea7**\u3002\u4f18\u5148\u7ea7\u6211\u4eec\u6709 **HIGHEST\u3001HIGH\u3001MEDIUM\u3001LOW\u548cLOWEST** \u4e94\u79cd\u7ea7\u522b\u3002**\u53ef\u4ee5\u8bbe\u7f6e\u4e0d\u540c\u6d41\u7a0b\u5b9e\u4f8b\u4e4b\u95f4\u7684\u4f18\u5148\u7ea7\uff0c\u4e5f\u53ef\u4ee5\u8bbe\u7f6e\u540c\u4e00\u4e2a\u6d41\u7a0b\u5b9e\u4f8b\u4e2d\u4e0d\u540c\u4efb\u52a1\u5b9e\u4f8b\u7684\u4f18\u5148\u7ea7**\u3002\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u4efb\u52a1\u4f18\u5148\u7ea7\u8bbe\u8ba1 https://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\n-\n-----\n-\n-## Q\uff1aescheduler-grpc\u62a5\u9519\n-\n-A\uff1a\u5728\u6839\u76ee\u5f55\u4e0b\u6267\u884c\uff1amvn -U clean package assembly:assembly -Dmaven.test.skip=true \uff0c \u7136\u540e\u5237\u65b0\u4e0b\u6574\u4e2a\u9879\u76ee\n-\n-----\n-\n-## Q\uff1aEasyScheduler\u652f\u6301windows\u4e0a\u8fd0\u884c\u4e48\n-\n-A\uff1a \u7406\u8bba\u4e0a\u53ea\u6709**Worker\u662f\u9700\u8981\u5728Linux\u4e0a\u8fd0\u884c\u7684**\uff0c\u5176\u5b83\u7684\u670d\u52a1\u90fd\u662f\u53ef\u4ee5\u5728windows\u4e0a\u6b63\u5e38\u8fd0\u884c\u7684\u3002\u4f46\u662f\u8fd8\u662f\u5efa\u8bae\u6700\u597d\u80fd\u5728linux\u4e0a\u90e8\u7f72\u4f7f\u7528\n-\n------\n-\n-## Q\uff1aUI \u5728 linux \u7f16\u8bd1node-sass\u63d0\u793a\uff1aError\uff1aEACCESS:permission denied\uff0cmkdir xxxx\n-\n-A\uff1a\u5355\u72ec\u5b89\u88c5 **npm install node-sass --unsafe-perm**\uff0c\u4e4b\u540e\u518d **npm install**\n-\n----\n-\n-## Q\uff1aUI \u4e0d\u80fd\u6b63\u5e38\u767b\u9646\u8bbf\u95ee\n-\n-A\uff1a 1\uff0c\u5982\u679c\u662fnode\u542f\u52a8\u7684\u67e5\u770bescheduler-ui\u4e0b\u7684.env API_BASE\u914d\u7f6e\u662f\u5426\u662fApi Server\u670d\u52a1\u5730\u5740\n-\n-    2\uff0c\u5982\u679c\u662fnginx\u542f\u52a8\u7684\u5e76\u4e14\u662f\u901a\u8fc7 **install-escheduler-ui.sh** \u5b89\u88c5\u7684\uff0c\u67e5\u770b             \t\t\t\t\t\t\t\t\t\t\t**/etc/nginx/conf.d/escheduler.conf** \u4e2d\u7684proxy_pass\u914d\u7f6e\u662f\u5426\u662fApi Server\u670d\u52a1\u5730\u5740\n-\n-    3\uff0c\u5982\u679c\u4ee5\u4e0a\u914d\u7f6e\u90fd\u662f\u6b63\u786e\u7684\uff0c\u90a3\u4e48\u8bf7\u67e5\u770bApi Server\u670d\u52a1\u662f\u5426\u662f\u6b63\u5e38\u7684\uff0ccurl http://192.168.xx.xx:12345/escheduler/users/get-user-info\uff0c\u67e5\u770bApi Server\u65e5\u5fd7\uff0c\u5982\u679c\u63d0\u793a cn.escheduler.api.interceptor.LoginHandlerInterceptor:[76] - session info is null\uff0c\u5219\u8bc1\u660eApi Server\u670d\u52a1\u662f\u6b63\u5e38\u7684\n-\n-    4\uff0c\u5982\u679c\u4ee5\u4e0a\u90fd\u6ca1\u6709\u95ee\u9898\uff0c\u9700\u8981\u67e5\u770b\u4e00\u4e0b **application.properties** \u4e2d\u7684 **server.context-path \u548c server.port \u914d\u7f6e**\u662f\u5426\u6b63\u786e\n-\n----\n-\n-## Q\uff1a \u6d41\u7a0b\u5b9a\u4e49\u624b\u52a8\u542f\u52a8\u6216\u8c03\u5ea6\u542f\u52a8\u4e4b\u540e\uff0c\u6ca1\u6709\u6d41\u7a0b\u5b9e\u4f8b\u751f\u6210\n-\n-A\uff1a 1\uff0c\u9996\u5148\u901a\u8fc7**jps \u67e5\u770bMasterServer\u670d\u52a1\u662f\u5426\u5b58\u5728**\uff0c\u6216\u8005\u4ece\u670d\u52a1\u76d1\u63a7\u76f4\u63a5\u67e5\u770bzk\u4e2d\u662f\u5426\u5b58\u5728master\u670d\u52a1\n-\n-\u200b\t2\uff0c\u5982\u679c\u5b58\u5728master\u670d\u52a1\uff0c\u67e5\u770b **\u547d\u4ee4\u72b6\u6001\u7edf\u8ba1** \u6216\u8005 **t_escheduler_error_command** \u4e2d\u662f\u5426\u589e\u52a0\u7684\u65b0\u8bb0\u5f55\uff0c\u5982\u679c\u589e\u52a0\u4e86\uff0c**\u8bf7\u67e5\u770b message \u5b57\u6bb5\u5b9a\u4f4d\u542f\u52a8\u5f02\u5e38\u539f\u56e0**\n-\n----\n-\n-## Q \uff1a \u4efb\u52a1\u72b6\u6001\u4e00\u76f4\u5904\u4e8e\u63d0\u4ea4\u6210\u529f\u72b6\u6001\n-\n-A\uff1a 1\uff0c\u9996\u5148\u901a\u8fc7**jps \u67e5\u770bWorkerServer\u670d\u52a1\u662f\u5426\u5b58\u5728**\uff0c\u6216\u8005\u4ece\u670d\u52a1\u76d1\u63a7\u76f4\u63a5\u67e5\u770bzk\u4e2d\u662f\u5426\u5b58\u5728worker\u670d\u52a1\n-\n-\u200b       2\uff0c\u5982\u679c **WorkerServer** \u670d\u52a1\u6b63\u5e38\uff0c\u9700\u8981 **\u67e5\u770bMasterServer\u662f\u5426\u628atask\u4efb\u52a1\u653e\u5230zk\u961f\u5217\u4e2d** \uff0c**\u9700\u8981\u67e5\u770bMasterServer\u65e5\u5fd7\u53cazk\u961f\u5217\u4e2d\u662f\u5426\u6709\u4efb\u52a1\u963b\u585e**\n-\n-\u200b\t3\uff0c\u5982\u679c\u4ee5\u4e0a\u90fd\u6ca1\u6709\u95ee\u9898\uff0c\u9700\u8981\u5b9a\u4f4d\u662f\u5426\u6307\u5b9a\u4e86Worker\u5206\u7ec4\uff0c\u4f46\u662f **Worker\u5206\u7ec4\u7684\u673a\u5668\u4e0d\u662f\u5728\u7ebf\u72b6\u6001**\n-\n----\n-\n-## Q\uff1a \u662f\u5426\u63d0\u4f9bDocker\u955c\u50cf\u53caDockerfile\n-\n-A\uff1a \u63d0\u4f9bDocker\u955c\u50cf\u53caDockerfile\u3002\n-\n-Docker\u955c\u50cf\u5730\u5740\uff1ahttps://hub.docker.com/r/escheduler/escheduler_images\n-\n-Dockerfile\u5730\u5740\uff1ahttps://github.com/qiaozhanwei/escheduler_dockerfile/tree/master/docker_escheduler\n-\n----\n-\n-## Q \uff1a install.sh \u4e2d\u9700\u8981\u6ce8\u610f\u95ee\u9898\n-\n-A\uff1a  1\uff0c\u5982\u679c\u66ff\u6362\u53d8\u91cf\u4e2d\u5305\u542b\u7279\u6b8a\u5b57\u7b26\uff0c**\u8bf7\u7528 \\ \u8f6c\u79fb\u7b26\u8fdb\u884c\u8f6c\u79fb**\n-\n-\u200b\t2\uff0cinstallPath=\"/data1_1T/escheduler\"\uff0c**\u8fd9\u4e2a\u76ee\u5f55\u4e0d\u80fd\u548c\u5f53\u524d\u8981\u4e00\u952e\u5b89\u88c5\u7684install.sh\u76ee\u5f55\u662f\u4e00\u6837\u7684**\n-\n-\u200b\t3\uff0cdeployUser=\"escheduler\"\uff0c**\u90e8\u7f72\u7528\u6237\u5fc5\u987b\u5177\u6709sudo\u6743\u9650**\uff0c\u56e0\u4e3aworker\u662f\u901a\u8fc7sudo -u \u79df\u6237 sh xxx.command\u8fdb\u884c\u6267\u884c\u7684\n-\n-\u200b\t4\uff0cmonitorServerState=\"false\"\uff0c\u670d\u52a1\u76d1\u63a7\u811a\u672c\u662f\u5426\u542f\u52a8\uff0c\u9ed8\u8ba4\u662f\u4e0d\u542f\u52a8\u670d\u52a1\u76d1\u63a7\u811a\u672c\u7684\u3002**\u5982\u679c\u542f\u52a8\u670d\u52a1\u76d1\u63a7\u811a\u672c\uff0c\u5219\u6bcf5\u5206\u949f\u5b9a\u65f6\u6765\u76d1\u63a7master\u548cworker\u7684\u670d\u52a1\u662f\u5426down\u673a\uff0c\u5982\u679cdown\u673a\u5219\u4f1a\u81ea\u52a8\u91cd\u542f**\n-\n-\u200b\t5\uff0chdfsStartupSate=\"false\"\uff0c\u662f\u5426\u5f00\u542fHDFS\u8d44\u6e90\u4e0a\u4f20\u529f\u80fd\u3002\u9ed8\u8ba4\u662f\u4e0d\u5f00\u542f\u7684\uff0c**\u5982\u679c\u4e0d\u5f00\u542f\u5219\u8d44\u6e90\u4e2d\u5fc3\u662f\u4e0d\u80fd\u4f7f\u7528\u7684**\u3002\u5982\u679c\u5f00\u542f\uff0c\u9700\u8981conf/common/hadoop/hadoop.properties\u4e2d\u914d\u7f6efs.defaultFS\u548cyarn\u7684\u76f8\u5173\u914d\u7f6e\uff0c\u5982\u679c\u4f7f\u7528namenode HA\uff0c\u9700\u8981\u5c06core-site.xml\u548chdfs-site.xml\u590d\u5236\u5230conf\u6839\u76ee\u5f55\u4e0b\n-\n-\u200b\t\u6ce8\u610f\uff1a**1.0.x\u7248\u672c\u662f\u4e0d\u4f1a\u81ea\u52a8\u521b\u5efahdfs\u6839\u76ee\u5f55\u7684\uff0c\u9700\u8981\u81ea\u884c\u521b\u5efa\uff0c\u5e76\u4e14\u9700\u8981\u90e8\u7f72\u7528\u6237\u6709hdfs\u7684\u64cd\u4f5c\u6743\u9650**\n-\n----\n-\n-## Q \uff1a \u6d41\u7a0b\u5b9a\u4e49\u548c\u6d41\u7a0b\u5b9e\u4f8b\u4e0b\u7ebf\u5f02\u5e38\n-\n-A \uff1a \u5bf9\u4e8e **1.0.4 \u4ee5\u524d\u7684\u7248\u672c\u4e2d**\uff0c\u4fee\u6539escheduler-api cn.escheduler.api.quartz\u5305\u4e0b\u7684\u4ee3\u7801\u5373\u53ef\n-\n-```\n-public boolean deleteJob(String jobName, String jobGroupName) {\n-    lock.writeLock().lock();\n-    try {\n-      JobKey jobKey = new JobKey(jobName,jobGroupName);\n-      if(scheduler.checkExists(jobKey)){\n-        logger.info(\"try to delete job, job name: {}, job group name: {},\", jobName, jobGroupName);\n-        return scheduler.deleteJob(jobKey);\n-      }else {\n-        return true;\n-      }\n-\n-    } catch (SchedulerException e) {\n-      logger.error(String.format(\"delete job : %s failed\",jobName), e);\n-    } finally {\n-      lock.writeLock().unlock();\n-    }\n-    return false;\n-  }\n-```\n-\n----\n-\n-## Q \uff1a HDFS\u542f\u52a8\u4e4b\u524d\u521b\u5efa\u7684\u79df\u6237\uff0c\u80fd\u6b63\u5e38\u4f7f\u7528\u8d44\u6e90\u4e2d\u5fc3\u5417\n-\n-A\uff1a \u4e0d\u80fd\u3002\u56e0\u4e3a\u5728\u672a\u542f\u52a8HDFS\u521b\u5efa\u7684\u79df\u6237\uff0c\u4e0d\u4f1a\u5728HDFS\u4e2d\u6ce8\u518c\u79df\u6237\u76ee\u5f55\u3002\u6240\u4ee5\u4e0a\u6b21\u8d44\u6e90\u4f1a\u62a5\u9519\n-\n-## Q :  \u591aMaster\u548c\u591aWorker\u72b6\u6001\u4e0b\uff0c\u670d\u52a1\u6389\u4e86\uff0c\u600e\u4e48\u5bb9\u9519\n-\n-A\uff1a  **\u6ce8\u610f\uff1aMaster\u76d1\u63a7Master\u53caWorker\u670d\u52a1\u3002**\n-\n-\u200b\t1\uff0c\u5982\u679cMaster\u670d\u52a1\u6389\u4e86\uff0c\u5176\u5b83\u7684Master\u4f1a\u63a5\u7ba1\u6302\u6389\u7684Master\u7684\u6d41\u7a0b\uff0c\u7ee7\u7eed\u76d1\u63a7Worker task\u72b6\u6001\n-\n-\u200b\t2\uff0c\u5982\u679cWorker\u670d\u52a1\u6389\uff0cMaster\u4f1a\u76d1\u63a7\u5230Worker\u670d\u52a1\u6389\u4e86\uff0c\u5982\u679c\u5b58\u5728Yarn\u4efb\u52a1\uff0cKill Yarn\u4efb\u52a1\u4e4b\u540e\u8d70\u91cd\u8bd5\n-\n-\u5177\u4f53\u8bf7\u770b\u5bb9\u9519\u8bbe\u8ba1\uff1ahttps://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.html#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\n-\n----\n-\n-## Q \uff1a \u5bf9\u4e8eMaster\u548cWorker\u4e00\u53f0\u673a\u5668\u4f2a\u5206\u5e03\u5f0f\u4e0b\u7684\u5bb9\u9519\n-\n-A \uff1a 1.0.3 \u7248\u672c\u53ea\u5b9e\u73b0\u4e86Master\u542f\u52a8\u6d41\u7a0b\u5bb9\u9519\uff0c\u4e0d\u8d70Worker\u5bb9\u9519\u3002\u4e5f\u5c31\u662f\u8bf4\u5982\u679cWorker\u6302\u6389\u7684\u65f6\u5019\uff0c\u6ca1\u6709Master\u5b58\u5728\u3002\u8fd9\u6d41\u7a0b\u5c06\u4f1a\u51fa\u73b0\u95ee\u9898\u3002\u6211\u4eec\u4f1a\u5728 **1.1.0** \u7248\u672c\u4e2d\u589e\u52a0Master\u548cWorker\u542f\u52a8\u81ea\u5bb9\u9519\uff0c\u4fee\u590d\u8fd9\u4e2a\u95ee\u9898\u3002\u5982\u679c\u60f3\u624b\u52a8\u4fee\u6539\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u9488\u5bf9 **\u8de8\u91cd\u542f\u6b63\u5728\u8fd0\u884c\u6d41\u7a0b** **\u5e76\u4e14\u5df2\u7ecf\u6389\u7684\u6b63\u5728\u8fd0\u884c\u7684Worker\u4efb\u52a1\uff0c\u9700\u8981\u4fee\u6539\u4e3a\u5931\u8d25**\uff0c**\u540c\u65f6\u8de8\u91cd\u542f\u6b63\u5728\u8fd0\u884c\u6d41\u7a0b\u8bbe\u7f6e\u4e3a\u5931\u8d25\u72b6\u6001**\u3002\u7136\u540e\u4ece\u5931\u8d25\u8282\u70b9\u8fdb\u884c\u6d41\u7a0b\u6062\u590d\u5373\u53ef\n-\n----\n-\n-## Q \uff1a \u5b9a\u65f6\u5bb9\u6613\u8bbe\u7f6e\u6210\u6bcf\u79d2\u6267\u884c\n-\n-A \uff1a \u8bbe\u7f6e\u5b9a\u65f6\u7684\u65f6\u5019\u9700\u8981\u6ce8\u610f\uff0c\u5982\u679c\u7b2c\u4e00\u4f4d\uff08* * * * * ? *\uff09\u8bbe\u7f6e\u6210 \\* \uff0c\u5219\u8868\u793a\u6bcf\u79d2\u6267\u884c\u3002**\u6211\u4eec\u5c06\u4f1a\u57281.1.0\u7248\u672c\u4e2d\u52a0\u5165\u663e\u793a\u6700\u8fd1\u8c03\u5ea6\u7684\u65f6\u95f4\u5217\u8868** \uff0c\u4f7f\u7528http://cron.qqe2.com/ \u53ef\u4ee5\u5728\u7ebf\u770b\u8fd15\u6b21\u8fd0\u884c\u65f6\u95f4\n-\n-\n-\n-## Q\uff1a \u5b9a\u65f6\u6709\u6709\u6548\u65f6\u95f4\u8303\u56f4\u5417\n-\n-A\uff1a\u6709\u7684\uff0c**\u5982\u679c\u5b9a\u65f6\u7684\u8d77\u6b62\u65f6\u95f4\u662f\u540c\u4e00\u4e2a\u65f6\u95f4\uff0c\u90a3\u4e48\u6b64\u5b9a\u65f6\u5c06\u662f\u65e0\u6548\u7684\u5b9a\u65f6**\u3002**\u5982\u679c\u8d77\u6b62\u65f6\u95f4\u7684\u7ed3\u675f\u65f6\u95f4\u6bd4\u5f53\u524d\u7684\u65f6\u95f4\u5c0f\uff0c\u5f88\u6709\u53ef\u80fd\u5b9a\u65f6\u4f1a\u88ab\u81ea\u52a8\u5220\u9664**\n-\n-\n-\n-## Q \uff1a \u4efb\u52a1\u4f9d\u8d56\u6709\u51e0\u79cd\u5b9e\u73b0\n-\n-A\uff1a\t1\uff0c**DAG** \u4e4b\u95f4\u7684\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\uff0c\u662f\u4ece **\u5165\u5ea6\u4e3a\u96f6** \u8fdb\u884cDAG\u5207\u5206\u7684\n-\n-\u200b\t2\uff0c\u6709 **\u4efb\u52a1\u4f9d\u8d56\u8282\u70b9** \uff0c\u53ef\u4ee5\u5b9e\u73b0\u8de8\u6d41\u7a0b\u7684\u4efb\u52a1\u6216\u8005\u6d41\u7a0b\u4f9d\u8d56\uff0c\u5177\u4f53\u8bf7\u53c2\u8003 \u4f9d\u8d56(DEPENDENT)\u8282\u70b9\uff1ahttps://analysys.github.io/easyscheduler_docs_cn/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.html#%E4%BB%BB%E5%8A%A1%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\n-\n-\u200b\t\u6ce8\u610f\uff1a**\u4e0d\u652f\u6301\u8de8\u9879\u76ee\u7684\u6d41\u7a0b\u6216\u4efb\u52a1\u4f9d\u8d56**\n-\n-## Q\uff1a \u6d41\u7a0b\u5b9a\u4e49\u6709\u51e0\u79cd\u542f\u52a8\u65b9\u5f0f\n-\n-A\uff1a 1\uff0c\u5728 **\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868**\uff0c\u70b9\u51fb **\u542f\u52a8** \u6309\u94ae\n-\n-\u200b\t2\uff0c**\u6d41\u7a0b\u5b9a\u4e49\u5217\u8868\u6dfb\u52a0\u5b9a\u65f6\u5668**\uff0c\u8c03\u5ea6\u542f\u52a8\u6d41\u7a0b\u5b9a\u4e49\n-\n-\u200b\t3\uff0c\u6d41\u7a0b\u5b9a\u4e49 **\u67e5\u770b\u6216\u7f16\u8f91** DAG \u9875\u9762\uff0c\u4efb\u610f **\u4efb\u52a1\u8282\u70b9\u53f3\u51fb** \u542f\u52a8\u6d41\u7a0b\u5b9a\u4e49\n-\n-\u200b\t4\uff0c\u53ef\u4ee5\u5bf9\u6d41\u7a0b\u5b9a\u4e49 DAG \u7f16\u8f91\uff0c\u8bbe\u7f6e\u67d0\u4e9b\u4efb\u52a1\u7684\u8fd0\u884c\u6807\u5fd7\u4f4d **\u7981\u6b62\u8fd0\u884c**\uff0c\u5219\u5728\u542f\u52a8\u6d41\u7a0b\u5b9a\u4e49\u7684\u65f6\u5019\uff0c\u5c06\u8be5\u8282\u70b9\u7684\u8fde\u7ebf\u5c06\u4eceDAG\u4e2d\u53bb\u6389\n-\n-## Q \uff1a Python\u4efb\u52a1\u8bbe\u7f6ePython\u7248\u672c\n-\n-A\uff1a  1\uff0c\u5bf9\u4e8e1**.0.3\u4e4b\u540e\u7684\u7248\u672c**\u53ea\u9700\u8981\u4fee\u6539 conf/env/.escheduler_env.sh\u4e2d\u7684PYTHON_HOME\n-\n-```\n-export PYTHON_HOME=/bin/python\n-```\n-\n-\u6ce8\u610f\uff1a\u8fd9\u4e86 **PYTHON_HOME** \uff0c\u662fpython\u547d\u4ee4\u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u800c\u4e0d\u662f\u5355\u7eaf\u7684 PYTHON_HOME\uff0c\u8fd8\u9700\u8981\u6ce8\u610f\u7684\u662f export PATH \u7684\u65f6\u5019\uff0c\u9700\u8981\u76f4\u63a5\n-\n-```\n-export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH\n-```\n-\n-\u200b\t2\uff0c\u5bf9 1.0.3 \u4e4b\u524d\u7684\u7248\u672c\uff0cPython\u4efb\u52a1\u53ea\u80fd\u652f\u6301\u7cfb\u7edf\u7684Python\u7248\u672c\uff0c\u4e0d\u652f\u6301\u6307\u5b9aPython\u7248\u672c\n-\n-## Q\uff1a Worker Task \u901a\u8fc7sudo -u \u79df\u6237 sh xxx.command\u4f1a\u4ea7\u751f\u5b50\u8fdb\u7a0b\uff0c\u5728kill\u7684\u65f6\u5019\uff0c\u662f\u5426\u4f1a\u6740\u6389\n-\n-A\uff1a \u6211\u4eec\u4f1a\u57281.0.4\u4e2d\u589e\u52a0kill\u4efb\u52a1\u540c\u65f6\uff0ckill\u6389\u4efb\u52a1\u4ea7\u751f\u7684\u5404\u79cd\u6240\u6709\u5b50\u8fdb\u7a0b\n-\n-\n-\n-## Q \uff1a EasyScheduler\u4e2d\u7684\u961f\u5217\u600e\u4e48\u7528\uff0c\u7528\u6237\u961f\u5217\u548c\u79df\u6237\u961f\u5217\u662f\u4ec0\u4e48\u610f\u601d\n-\n-A \uff1a EasyScheduler \u4e2d\u7684\u961f\u5217\u53ef\u4ee5\u5728\u7528\u6237\u6216\u8005\u79df\u6237\u4e0a\u6307\u5b9a\u961f\u5217\uff0c**\u7528\u6237\u6307\u5b9a\u7684\u961f\u5217\u4f18\u5148\u7ea7\u662f\u9ad8\u4e8e\u79df\u6237\u961f\u5217\u7684\u4f18\u5148\u7ea7\u7684\u3002**\uff0c\u4f8b\u5982\uff1a\u5bf9MR\u4efb\u52a1\u6307\u5b9a\u961f\u5217\uff0c\u662f\u901a\u8fc7 mapreduce.job.queuename \u6765\u6307\u5b9a\u961f\u5217\u7684\u3002\n-\n-\u6ce8\u610f\uff1aMR\u5728\u7528\u4ee5\u4e0a\u65b9\u6cd5\u6307\u5b9a\u961f\u5217\u7684\u65f6\u5019\uff0c\u4f20\u9012\u53c2\u6570\u8bf7\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\uff1a\n-\n-```\n-\tConfiguration conf = new Configuration();\n-        GenericOptionsParser optionParser = new GenericOptionsParser(conf, args);\n-        String[] remainingArgs = optionParser.getRemainingArgs();\n-```\n-\n-\n-\n-\u5982\u679c\u662fSpark\u4efb\u52a1 --queue \u65b9\u5f0f\u6307\u5b9a\u961f\u5217\n-\n-\n-\n-## Q : Master \u6216\u8005 Worker\u62a5\u5982\u4e0b\u544a\u8b66\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/master_worker_lack_res.png\" width=\"60%\" />\n- </p>\n-\n-\n-\n-A \uff1a \u4fee\u6539conf\u4e0b\u7684 master.properties **master.reserved.memory** \u7684\u503c\u4e3a\u66f4\u5c0f\u7684\u503c\uff0c\u6bd4\u5982\u8bf40.1 \u6216\u8005\n-\n-worker.properties **worker.reserved.memory** \u7684\u503c\u4e3a\u66f4\u5c0f\u7684\u503c\uff0c\u6bd4\u5982\u8bf40.1\n-\n-\n-\n-## Q : hive\u7248\u672c\u662f1.1.0+cdh5.15.0\uff0cSQL hive\u4efb\u52a1\u8fde\u63a5\u62a5\u9519\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/cdh_hive_error.png\" width=\"60%\" />\n- </p>\n-\n-\n-\n-A \uff1a \u5c06 hive pom\n-\n-```\n-<dependency>\n-    <groupId>org.apache.hive</groupId>\n-    <artifactId>hive-jdbc</artifactId>\n-    <version>2.1.0</version>\n-</dependency>\n-```\n-\n-\u4fee\u6539\u4e3a\n-\n-```\n-<dependency>\n-    <groupId>org.apache.hive</groupId>\n-    <artifactId>hive-jdbc</artifactId>\n-    <version>1.1.0</version>\n-</dependency>\n-```\n-",
                "changes": 287
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/README.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/README.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/README.md",
                "deletions": 66,
                "sha": "5337e585cd876883b8325809eb0fdef07c7141e5",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/README.md",
                "patch": "@@ -1,66 +0,0 @@\n-Easy Scheduler\n-============\n-[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n-\n-> Easy Scheduler for Big Data\n-\n-**\u8bbe\u8ba1\u7279\u70b9\uff1a** \u4e00\u4e2a\u5206\u5e03\u5f0f\u6613\u6269\u5c55\u7684\u53ef\u89c6\u5316DAG\u5de5\u4f5c\u6d41\u4efb\u52a1\u8c03\u5ea6\u7cfb\u7edf\u3002\u81f4\u529b\u4e8e\u89e3\u51b3\u6570\u636e\u5904\u7406\u6d41\u7a0b\u4e2d\u9519\u7efc\u590d\u6742\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u8c03\u5ea6\u7cfb\u7edf\u5728\u6570\u636e\u5904\u7406\u6d41\u7a0b\u4e2d`\u5f00\u7bb1\u5373\u7528`\u3002\n-\u5176\u4e3b\u8981\u76ee\u6807\u5982\u4e0b\uff1a\n- - \u4ee5DAG\u56fe\u7684\u65b9\u5f0f\u5c06Task\u6309\u7167\u4efb\u52a1\u7684\u4f9d\u8d56\u5173\u7cfb\u5173\u8054\u8d77\u6765\uff0c\u53ef\u5b9e\u65f6\u53ef\u89c6\u5316\u76d1\u63a7\u4efb\u52a1\u7684\u8fd0\u884c\u72b6\u6001\n- - \u652f\u6301\u4e30\u5bcc\u7684\u4efb\u52a1\u7c7b\u578b\uff1aShell\u3001MR\u3001Spark\u3001SQL(mysql\u3001postgresql\u3001hive\u3001sparksql),Python,Sub_Process\u3001Procedure\u7b49\n- - \u652f\u6301\u5de5\u4f5c\u6d41\u5b9a\u65f6\u8c03\u5ea6\u3001\u4f9d\u8d56\u8c03\u5ea6\u3001\u624b\u52a8\u8c03\u5ea6\u3001\u624b\u52a8\u6682\u505c/\u505c\u6b62/\u6062\u590d\uff0c\u540c\u65f6\u652f\u6301\u5931\u8d25\u91cd\u8bd5/\u544a\u8b66\u3001\u4ece\u6307\u5b9a\u8282\u70b9\u6062\u590d\u5931\u8d25\u3001Kill\u4efb\u52a1\u7b49\u64cd\u4f5c\n- - \u652f\u6301\u5de5\u4f5c\u6d41\u4f18\u5148\u7ea7\u3001\u4efb\u52a1\u4f18\u5148\u7ea7\u53ca\u4efb\u52a1\u7684\u6545\u969c\u8f6c\u79fb\u53ca\u4efb\u52a1\u8d85\u65f6\u544a\u8b66/\u5931\u8d25\n- - \u652f\u6301\u5de5\u4f5c\u6d41\u5168\u5c40\u53c2\u6570\u53ca\u8282\u70b9\u81ea\u5b9a\u4e49\u53c2\u6570\u8bbe\u7f6e\n- - \u652f\u6301\u8d44\u6e90\u6587\u4ef6\u7684\u5728\u7ebf\u4e0a\u4f20/\u4e0b\u8f7d\uff0c\u7ba1\u7406\u7b49\uff0c\u652f\u6301\u5728\u7ebf\u6587\u4ef6\u521b\u5efa\u3001\u7f16\u8f91\n- - \u652f\u6301\u4efb\u52a1\u65e5\u5fd7\u5728\u7ebf\u67e5\u770b\u53ca\u6eda\u52a8\u3001\u5728\u7ebf\u4e0b\u8f7d\u65e5\u5fd7\u7b49\n- - \u5b9e\u73b0\u96c6\u7fa4HA\uff0c\u901a\u8fc7Zookeeper\u5b9e\u73b0Master\u96c6\u7fa4\u548cWorker\u96c6\u7fa4\u53bb\u4e2d\u5fc3\u5316\n- - \u652f\u6301\u5bf9`Master/Worker` cpu load\uff0cmemory\uff0ccpu\u5728\u7ebf\u67e5\u770b\n- - \u652f\u6301\u5de5\u4f5c\u6d41\u8fd0\u884c\u5386\u53f2\u6811\u5f62/\u7518\u7279\u56fe\u5c55\u793a\u3001\u652f\u6301\u4efb\u52a1\u72b6\u6001\u7edf\u8ba1\u3001\u6d41\u7a0b\u72b6\u6001\u7edf\u8ba1\n- - \u652f\u6301\u8865\u6570\n- - \u652f\u6301\u591a\u79df\u6237\n- - \u652f\u6301\u56fd\u9645\u5316\n- - \u8fd8\u6709\u66f4\u591a\u7b49\u5f85\u4f19\u4f34\u4eec\u63a2\u7d22\n-\n-### \u4e0e\u540c\u7c7b\u8c03\u5ea6\u7cfb\u7edf\u7684\u5bf9\u6bd4\n-\n-![\u8c03\u5ea6\u7cfb\u7edf\u5bf9\u6bd4](http://geek.analysys.cn/static/upload/47/2019-03-01/9609ca82-cf8b-4d91-8dc0-0e2805194747.jpeg)\n-\n-### \u7cfb\u7edf\u90e8\u5206\u622a\u56fe\n-\n-![](http://geek.analysys.cn/static/upload/221/2019-03-29/0a9dea80-fb02-4fa5-a812-633b67035ffc.jpeg)\n-\n-![](http://geek.analysys.cn/static/upload/221/2019-04-01/83686def-a54f-4169-8cae-77b1f8300cc1.png)\n-\n-![](http://geek.analysys.cn/static/upload/221/2019-03-29/83c937c7-1793-4d7a-aa28-b98460329fe0.jpeg)\n-\n-### \u6587\u6863\n-\n-- <a href=\"https://analysys.github.io/easyscheduler_docs_cn/\u540e\u7aef\u90e8\u7f72\u6587\u6863.html\" target=\"_blank\">\u540e\u7aef\u90e8\u7f72\u6587\u6863</a>\n-\n-- <a href=\"https://analysys.github.io/easyscheduler_docs_cn/\u524d\u7aef\u90e8\u7f72\u6587\u6863.html\" target=\"_blank\">\u524d\u7aef\u90e8\u7f72\u6587\u6863</a>\n-\n-- [**\u4f7f\u7528\u624b\u518c**](https://analysys.github.io/easyscheduler_docs_cn/\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.html?_blank \"\u7cfb\u7edf\u4f7f\u7528\u624b\u518c\") \n-\n-- [**\u5347\u7ea7\u6587\u6863**](https://analysys.github.io/easyscheduler_docs_cn/\u5347\u7ea7\u6587\u6863.html?_blank \"\u5347\u7ea7\u6587\u6863\") \n-\n-- <a href=\"http://52.82.13.76:8888\" target=\"_blank\">\u6211\u8981\u4f53\u9a8c</a> \n-\n-\u66f4\u591a\u6587\u6863\u8bf7\u53c2\u8003 <a href=\"https://analysys.github.io/easyscheduler_docs_cn/\" target=\"_blank\">easyscheduler\u4e2d\u6587\u5728\u7ebf\u6587\u6863</a>\n-\n-### \u611f\u8c22\n-\n-- Easy Scheduler\u4f7f\u7528\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u5f00\u6e90\u9879\u76ee\uff0c\u6bd4\u5982google\u7684guava\u3001guice\u3001grpc\uff0cnetty\uff0cali\u7684bonecp\uff0cquartz\uff0c\u4ee5\u53caapache\u7684\u4f17\u591a\u5f00\u6e90\u9879\u76ee\u7b49\u7b49\uff0c\n-\u6b63\u662f\u7531\u4e8e\u7ad9\u5728\u8fd9\u4e9b\u5f00\u6e90\u9879\u76ee\u7684\u80a9\u8180\u4e0a\uff0c\u624d\u6709Easy Scheduler\u7684\u8bde\u751f\u7684\u53ef\u80fd\u3002\u5bf9\u6b64\u6211\u4eec\u5bf9\u4f7f\u7528\u7684\u6240\u6709\u5f00\u6e90\u8f6f\u4ef6\u8868\u793a\u975e\u5e38\u7684\u611f\u8c22\uff01\u6211\u4eec\u4e5f\u5e0c\u671b\u81ea\u5df1\u4e0d\u4ec5\u662f\u5f00\u6e90\u7684\u53d7\u76ca\u8005\uff0c\u4e5f\u80fd\u6210\u4e3a\u5f00\u6e90\u7684\n-\u8d21\u732e\u8005\uff0c\u4e8e\u662f\u6211\u4eec\u51b3\u5b9a\u628a\u6613\u8c03\u5ea6\u8d21\u732e\u51fa\u6765\uff0c\u5e76\u627f\u8bfa\u957f\u671f\u7ef4\u62a4\u3002\u4e5f\u5e0c\u671b\u5bf9\u5f00\u6e90\u6709\u540c\u6837\u70ed\u60c5\u548c\u4fe1\u5ff5\u7684\u4f19\u4f34\u52a0\u5165\u8fdb\u6765\uff0c\u4e00\u8d77\u4e3a\u5f00\u6e90\u732e\u51fa\u4e00\u4efd\u529b\uff01\n-\n-### \u5e2e\u52a9\n-The fastest way to get response from our developers is to submit issues,   or add our wechat : 510570367\n- \n- \n-\n-\n-\n-\n-\n-\n-",
                "changes": 66
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/SUMMARY.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/SUMMARY.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/SUMMARY.md",
                "deletions": 47,
                "sha": "2b153b60c5910cf57ce8fd9be473e51a1ac84647",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/SUMMARY.md",
                "patch": "@@ -1,47 +0,0 @@\n-# Summary\n-\n-* [Easyscheduler\u7b80\u4ecb](README.md)\n-* \u524d\u7aef\u90e8\u7f72\u6587\u6863\n-    * [\u51c6\u5907\u5de5\u4f5c](\u524d\u7aef\u90e8\u7f72\u6587\u6863.md#1\u3001\u51c6\u5907\u5de5\u4f5c)\n-    * [\u90e8\u7f72](\u524d\u7aef\u90e8\u7f72\u6587\u6863.md#2\u3001\u90e8\u7f72)\n-    * [\u5e38\u89c1\u95ee\u9898](\u524d\u7aef\u90e8\u7f72\u6587\u6863.md#\u524d\u7aef\u5e38\u89c1\u95ee\u9898)\n-* \u540e\u7aef\u90e8\u7f72\u6587\u6863\n-    * [\u51c6\u5907\u5de5\u4f5c](\u540e\u7aef\u90e8\u7f72\u6587\u6863.md#1\u3001\u51c6\u5907\u5de5\u4f5c)  \n-    * [\u90e8\u7f72](\u540e\u7aef\u90e8\u7f72\u6587\u6863.md#2\u3001\u90e8\u7f72)  \n-* [\u5feb\u901f\u4e0a\u624b](\u5feb\u901f\u4e0a\u624b.md#\u5feb\u901f\u4e0a\u624b)\n-* \u7cfb\u7edf\u4f7f\u7528\u624b\u518c\n-    * [\u5feb\u901f\u4e0a\u624b](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u5feb\u901f\u4e0a\u624b)\n-    * [\u64cd\u4f5c\u6307\u5357](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u64cd\u4f5c\u6307\u5357)\n-    * [\u5b89\u5168\u4e2d\u5fc3\uff08\u6743\u9650\u7cfb\u7edf\uff09](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u5b89\u5168\u4e2d\u5fc3\uff08\u6743\u9650\u7cfb\u7edf\uff09)\n-    * [\u76d1\u63a7\u4e2d\u5fc3](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u76d1\u63a7\u4e2d\u5fc3)\n-    * [\u4efb\u52a1\u8282\u70b9\u7c7b\u578b\u548c\u53c2\u6570\u8bbe\u7f6e](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u4efb\u52a1\u8282\u70b9\u7c7b\u578b\u548c\u53c2\u6570\u8bbe\u7f6e)\n-    * [\u7cfb\u7edf\u53c2\u6570](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md#\u7cfb\u7edf\u53c2\u6570)\n-* [\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1](\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1.md#\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1)\n-* \u524d\u7aef\u5f00\u53d1\u6587\u6863\n-    * [\u5f00\u53d1\u73af\u5883\u642d\u5efa](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u5f00\u53d1\u73af\u5883\u642d\u5efa)\n-    * [\u9879\u76ee\u76ee\u5f55\u7ed3\u6784](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u9879\u76ee\u76ee\u5f55\u7ed3\u6784)\n-    * [\u7cfb\u7edf\u529f\u80fd\u6a21\u5757](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u7cfb\u7edf\u529f\u80fd\u6a21\u5757)\n-    * [\u8def\u7531\u548c\u72b6\u6001\u7ba1\u7406](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u8def\u7531\u548c\u72b6\u6001\u7ba1\u7406)\n-    * [\u89c4\u8303](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u89c4\u8303)\n-    * [\u63a5\u53e3](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u63a5\u53e3)\n-    * [\u6269\u5c55\u5f00\u53d1](\u524d\u7aef\u5f00\u53d1\u6587\u6863.md#\u6269\u5c55\u5f00\u53d1)   \n-* \u540e\u7aef\u5f00\u53d1\u6587\u6863\n-    * [\u5f00\u53d1\u73af\u5883\u642d\u5efa](\u540e\u7aef\u5f00\u53d1\u6587\u6863.md#\u9879\u76ee\u7f16\u8bd1)\n-    * [\u81ea\u5b9a\u4e49\u4efb\u52a1\u63d2\u4ef6\u6587\u6863](\u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1.md#\u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1)\n-    \n-* [\u63a5\u53e3\u6587\u6863](http://52.82.13.76:8888/escheduler/doc.html?language=zh_CN&lang=cn)\n-* FAQ\n-    * [FAQ](EasyScheduler-FAQ.md)\n-* \u7cfb\u7edf\u7248\u672c\u5347\u7ea7\u6587\u6863\n-    * [\u7248\u672c\u5347\u7ea7](\u5347\u7ea7\u6587\u6863.md)\n-* \u5386\u6b21\u7248\u672c\u53d1\u5e03\u5185\u5bb9\n-    * [1.1.0 release](1.1.0-release.md)\n-    * [1.0.5 release](1.0.5-release.md)\n-    * [1.0.4 release](1.0.4-release.md)\n-    * [1.0.3 release](1.0.3-release.md)\n-    * [1.0.2 release](1.0.2-release.md)\n-    * [1.0.1 release](1.0.1-release.md)\n-    * [1.0.0 release \u6b63\u5f0f\u5f00\u6e90]\n-    \n-    \n-    \n\\ No newline at end of file",
                "changes": 47
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/book.json",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/book.json?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/book.json",
                "deletions": 23,
                "sha": "5857eb9138aae762e4349e4ec03a29b4ae4b5872",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/book.json",
                "patch": "@@ -1,23 +0,0 @@\n-{\n-  \"title\": \"\u8c03\u5ea6\u7cfb\u7edf-EasyScheduler\",\n-  \"author\": \"\",\n-  \"description\": \"\u8c03\u5ea6\u7cfb\u7edf\",\n-  \"language\": \"zh-hans\",\n-  \"gitbook\": \"3.2.3\",\n-  \"styles\": {\n-    \"website\": \"./styles/website.css\"\n-  },\n-  \"structure\": {\n-    \"readme\": \"README.md\"\n-  },\n-  \"plugins\":[\n-    \"expandable-chapters\",\n-    \"insert-logo-link\"\n-  ],\n-  \"pluginsConfig\": {\n-    \"insert-logo-link\": {\n-      \"src\": \"http://geek.analysys.cn/static/upload/236/2019-03-29/379450b4-7919-4707-877c-4d33300377d4.png\",\n-      \"url\": \"https://github.com/analysys/EasyScheduler\"\n-    }\n-  }\n-}\n\\ No newline at end of file",
                "changes": 23
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/addtenant.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/addtenant.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/addtenant.png",
                "deletions": 0,
                "sha": "c3909ec994e13be70e8a0eb471cf08e35c604766",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/addtenant.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/architecture.jpg",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/architecture.jpg?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/architecture.jpg",
                "deletions": 0,
                "sha": "380962594078eb3c73b1c8ff0f200501f61fa0a0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/architecture.jpg"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/auth_project.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/auth_project.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/auth_project.png",
                "deletions": 0,
                "sha": "96c05d81e13de9be40d2915c9cbf28d4b06c5e6b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/auth_project.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/auth_user.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/auth_user.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/auth_user.png",
                "deletions": 0,
                "sha": "e03f00ca14be64da62fe1807730d40184b51ba6b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/auth_user.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/cdh_hive_error.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/cdh_hive_error.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/cdh_hive_error.png",
                "deletions": 0,
                "sha": "ad1db4c2b44b184dc8367383e2e36305ce3b1043",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/cdh_hive_error.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/complement.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/complement.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/complement.png",
                "deletions": 0,
                "sha": "058311f43c0936ce6caa56952eaeb345802fe29e",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/complement.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/complement_data.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/complement_data.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/complement_data.png",
                "deletions": 0,
                "sha": "a71c8a21c65e23be363ab6fa57c4b02f93cfb896",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/complement_data.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/create-queue.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/create-queue.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/create-queue.png",
                "deletions": 0,
                "sha": "1f23cac08b1445f78f5f671d0b46fa3010d95769",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/create-queue.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag1.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag1.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag1.png",
                "deletions": 0,
                "sha": "eacd1a4bd846b424aae0021b65537cdd5ad88810",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag1.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag2.png",
                "deletions": 0,
                "sha": "12b5ace0ccb5099192081679a67fffa15f38a82c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag3.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag3.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag3.png",
                "deletions": 0,
                "sha": "a4ce3340140de10a7d7188f5556238e6077a4f1e",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag3.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag4.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag4.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag4.png",
                "deletions": 0,
                "sha": "b3ec5a897a2df89631c1eca52e1070d7c6b7712f",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag4.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag_examples_cn.jpg",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag_examples_cn.jpg?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag_examples_cn.jpg",
                "deletions": 0,
                "sha": "31ae54f9bffc9a57f45f5bd0070a63c1b1a81de9",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag_examples_cn.jpg"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag_examples_en.jpg",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dag_examples_en.jpg?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dag_examples_en.jpg",
                "deletions": 0,
                "sha": "1fef8461fdba4c9f366195dbca74840b8cdb89ea",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dag_examples_en.jpg"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/decentralization.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/decentralization.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/decentralization.png",
                "deletions": 0,
                "sha": "c7c69ef435bd6bbf0033abefcf1f206e6dedafa8",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/decentralization.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_create.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/definition_create.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/definition_create.png",
                "deletions": 0,
                "sha": "90257fd47881a46f3e4087443747afb20b308bd0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_create.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/definition_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/definition_edit.png",
                "deletions": 0,
                "sha": "9611922353dc2b47dd84c9c6c68d9732fedf200a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_list.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/definition_list.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/definition_list.png",
                "deletions": 0,
                "sha": "581b75c572994bb13180638cad788a1d0ca5384c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/definition_list.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/depend-node.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/depend-node.png",
                "deletions": 0,
                "sha": "1f26973a9dbe6bf72d42aa5ce20c81e9cde6335c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/depend-node2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/depend-node2.png",
                "deletions": 0,
                "sha": "1ca11d0e2bd0ab6f699b387d6a26c78a3ce3eeb2",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node3.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/depend-node3.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/depend-node3.png",
                "deletions": 0,
                "sha": "dc57aaa174905ce0c037ee097d9b9565f422fb7a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/depend-node3.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dependent_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dependent_edit.png",
                "deletions": 0,
                "sha": "b007cacee66bac90a74c53eccdbe7fd0dede5970",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dependent_edit2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dependent_edit2.png",
                "deletions": 0,
                "sha": "af929b80c3bdcb8e625bedcbd8eff37ad4794779",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit3.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dependent_edit3.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dependent_edit3.png",
                "deletions": 0,
                "sha": "b0b9d99c4fab6f66493f038b607d727aebcaebf0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit3.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit4.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/dependent_edit4.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/dependent_edit4.png",
                "deletions": 0,
                "sha": "033ad1766a55231bfac05c3bc75d4c7102cf9c49",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/dependent_edit4.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/distributed_lock.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/distributed_lock.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/distributed_lock.png",
                "deletions": 0,
                "sha": "2f048435c94fda336bd10a316f618192f5d4dc1a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/distributed_lock.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/distributed_lock_procss.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/distributed_lock_procss.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/distributed_lock_procss.png",
                "deletions": 0,
                "sha": "eb07136c1b76af7771db4a77b91e5ab5d1c3450c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/distributed_lock_procss.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/fault-tolerant.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/fault-tolerant.png",
                "deletions": 0,
                "sha": "a53881ca1658489886ab543c1cddb7776d1d2065",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant_master.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/fault-tolerant_master.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/fault-tolerant_master.png",
                "deletions": 0,
                "sha": "4adacc4b2a65e453f8a7e2568a92d1db352d341d",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant_master.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant_worker.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/fault-tolerant_worker.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/fault-tolerant_worker.png",
                "deletions": 0,
                "sha": "4962e880280938a0f726a77c626df040934c807a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/fault-tolerant_worker.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/favicon.ico",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/favicon.ico?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/favicon.ico",
                "deletions": 0,
                "sha": "b041d11f5090f3d8d53e2025e8f66ddfadb603da",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/favicon.ico"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file-manage.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/file-manage.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/file-manage.png",
                "deletions": 0,
                "sha": "e53a81722ddd0e6db76a4f15a09bb0240fbefd3c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file-manage.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_create.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/file_create.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/file_create.png",
                "deletions": 0,
                "sha": "464b179beed3c24541cc789e14c54573e48d8965",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_create.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_detail.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/file_detail.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/file_detail.png",
                "deletions": 0,
                "sha": "726f9bf2fe39fc16e22b053cb5ec0c134396d518",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_detail.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_rename.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/file_rename.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/file_rename.png",
                "deletions": 0,
                "sha": "bcbc6dae2b7519a20624497a9b15cfc7dffd20d1",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_rename.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_upload.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/file_upload.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/file_upload.png",
                "deletions": 0,
                "sha": "b2f36ea0ee4e42d8c1e7b7989206316d5c80c305",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/file_upload.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/gant-pic.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/gant-pic.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/gant-pic.png",
                "deletions": 0,
                "sha": "fe29e595e779f6f5eef1f88083fa340cfcf944c8",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/gant-pic.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/gantt.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/gantt.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/gantt.png",
                "deletions": 0,
                "sha": "7555d6f1b2b43a2333fd16e2ee9c76cf727561e5",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/gantt.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/global_parameter.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/global_parameter.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/global_parameter.png",
                "deletions": 0,
                "sha": "9fb415c126f2e7193df5b898f18a270ffff9cbf6",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/global_parameter.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/grpc.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/grpc.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/grpc.png",
                "deletions": 0,
                "sha": "c96f22d1c33d77eb108508c4311bd99b20bb8780",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/grpc.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/hive_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/hive_edit.png",
                "deletions": 0,
                "sha": "50d0eedeeea614f5bfc517ede5f22e7bdd44f2b2",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_edit2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/hive_edit2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/hive_edit2.png",
                "deletions": 0,
                "sha": "789d65fb9a730369c5e42dd6f0c45cbe7d3cd749",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_edit2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_kerberos.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/hive_kerberos.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/hive_kerberos.png",
                "deletions": 0,
                "sha": "1532934f928d6b3d0d74c330523343878b5ed7c6",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/hive_kerberos.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/instance-detail.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/instance-detail.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/instance-detail.png",
                "deletions": 0,
                "sha": "a09d147de097328b18b43f10c9ab3ceeeeb0faa1",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/instance-detail.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/instance-list.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/instance-list.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/instance-list.png",
                "deletions": 0,
                "sha": "be3a75d2bf9b6a45afa5a349dac5076846c9220a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/instance-list.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/lack_thread.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/lack_thread.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/lack_thread.png",
                "deletions": 0,
                "sha": "bea5337b5a25d1ceab66679c5453a746f86e5233",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/lack_thread.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/local_parameter.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/local_parameter.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/local_parameter.png",
                "deletions": 0,
                "sha": "1eac919addfd6b142b6b5db1b4eb8f17e1612b43",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/local_parameter.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/login.jpg",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/login.jpg?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/login.jpg",
                "deletions": 0,
                "sha": "b6574e1d0c078119bb18ecb75e739e6e1459e200",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/login.jpg"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/login.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/login.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/login.png",
                "deletions": 0,
                "sha": "2ba0822ec9cd2b9bd9599734e92c4c55c826fbae",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/login.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/logo.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/logo.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/logo.png",
                "deletions": 0,
                "sha": "eb58aebaf1ec3cb1b7e2e1fbca3854da77a2a56f",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/logo.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/logout.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/logout.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/logout.png",
                "deletions": 0,
                "sha": "b2ee2411dbb36f1bda0ee857462768a8c141f554",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/logout.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mail_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mail_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mail_edit.png",
                "deletions": 0,
                "sha": "a7ca3f7835b2b82df0f4b2bcc245c236771a0a66",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mail_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master-jk.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/master-jk.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/master-jk.png",
                "deletions": 0,
                "sha": "4fb1f4521b245c1228ba358581bb8cb1e091ca40",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master-jk.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/master.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/master.png",
                "deletions": 0,
                "sha": "612841d2415571d73d54d87e41eecd0438118203",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/master2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/master2.png",
                "deletions": 0,
                "sha": "b99d1403df150ad9cee74aba1a317a256bd48dab",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master_slave.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/master_slave.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/master_slave.png",
                "deletions": 0,
                "sha": "a47ebf3870cb31fc5d60031c4514e66ab4fb25b2",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master_slave.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master_worker_lack_res.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/master_worker_lack_res.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/master_worker_lack_res.png",
                "deletions": 0,
                "sha": "1b26714cfbdcf2dd6126a02f143238f6c452f7b7",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/master_worker_lack_res.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mr_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mr_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mr_edit.png",
                "deletions": 0,
                "sha": "1fa85495b365e0e2f1b37750d8bb7e48c41dabc4",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mr_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mr_java.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mr_java.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mr_java.png",
                "deletions": 0,
                "sha": "9321049e1459c924f7dbcd28617b4e69366e5d59",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mr_java.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql-jk.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mysql-jk.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mysql-jk.png",
                "deletions": 0,
                "sha": "89cec305f021fa7af255f17042528b080413926c",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql-jk.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mysql.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mysql.png",
                "deletions": 0,
                "sha": "476a3d9902fd4299cc99ca46a0dfe1630eb48d8f",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/mysql_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/mysql_edit.png",
                "deletions": 0,
                "sha": "1ae75cbef5f298bc2f3ee0968e0cdc87568bfc44",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/mysql_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/postgresql_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/postgresql_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/postgresql_edit.png",
                "deletions": 0,
                "sha": "79c1eec0666b11f762eccc4c9eaa9096c612c385",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/postgresql_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/postgressql_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/postgressql_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/postgressql_edit.png",
                "deletions": 0,
                "sha": "b95f3539ceadd96c6bf1fd161d9bcd83fa8796cc",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/postgressql_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/procedure_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/procedure_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/procedure_edit.png",
                "deletions": 0,
                "sha": "e6d31ab7bda5954cc7da3dbc140c441be310f669",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/procedure_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-pause.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list-pause.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list-pause.png",
                "deletions": 0,
                "sha": "c61fcd3edae42a703cacaeda126d3f9b33c8f23f",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-pause.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-recovery-pause.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list-recovery-pause.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list-recovery-pause.png",
                "deletions": 0,
                "sha": "097a4f214bd0c1e1f2d37273432b9b0547c02949",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-recovery-pause.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-stop.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list-stop.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list-stop.png",
                "deletions": 0,
                "sha": "d74613f3e761dce8010758685e9692aca19035fe",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list-stop.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list.png",
                "deletions": 0,
                "sha": "e1c52d07f9a04fbc10d45783f711d6ac03eff47e",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list2.png",
                "deletions": 0,
                "sha": "5ed86b9df785814dbc139d91e24d919edb829333",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list3.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list3.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list3.png",
                "deletions": 0,
                "sha": "8f61df94d6188e7b89086769271d6aae02bc9c9b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list3.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list4.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process-list4.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process-list4.png",
                "deletions": 0,
                "sha": "71bb7d83c9b4802f60c9ecab88694c44aed9d973",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process-list4.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_instance.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process_instance.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process_instance.png",
                "deletions": 0,
                "sha": "0c87ade46b41add6e439adfe0d4aa307e2141534",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_instance.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_instance_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process_instance_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process_instance_edit.png",
                "deletions": 0,
                "sha": "8b9e6e7e149cdc3a6935be00cf42de2f25d1ecdb",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_instance_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_priority.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/process_priority.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/process_priority.png",
                "deletions": 0,
                "sha": "efe49a2c5e239d90a2e09ee91befc3ca88af077d",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/process_priority.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/project.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/project.png",
                "deletions": 0,
                "sha": "558f601c7382cd95b1a576ecd544f0d7c7c2db34",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/project_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/project_edit.png",
                "deletions": 0,
                "sha": "1b6479839d3569b02e1fd03edbdbc58ec0f11116",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project_index.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/project_index.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/project_index.png",
                "deletions": 0,
                "sha": "502418f9ff59b4274f1856e401bac50abca51a02",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/project_index.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/python_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/python_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/python_edit.png",
                "deletions": 0,
                "sha": "e2f6380f8c52a58bab229038e31b71db37513fde",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/python_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/run-work.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/run-work.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/run-work.png",
                "deletions": 0,
                "sha": "f06994220feb880b619bf7b7f6b7c26b7ded3584",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/run-work.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/scheduler.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/scheduler.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/scheduler.png",
                "deletions": 0,
                "sha": "30d8bb8184ee49fd969feee97889f03595ad5577",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/scheduler.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/scheduler2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/scheduler2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/scheduler2.png",
                "deletions": 0,
                "sha": "bbd3a64a994f9c99c959fa5e2d168d220b750e3f",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/scheduler2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/shell_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/shell_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/shell_edit.png",
                "deletions": 0,
                "sha": "1fe8870b78123fa25e4a52c6d87a64ab29de75e1",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/shell_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/spark_datesource.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/spark_datesource.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/spark_datesource.png",
                "deletions": 0,
                "sha": "ac30d9f52c5abf218f72a394a114928cd4387c5b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/spark_datesource.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/spark_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/spark_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/spark_edit.png",
                "deletions": 0,
                "sha": "b7c232115753ed31d72cf869dff8859ca717ddf9",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/spark_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sparksql_kerberos.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/sparksql_kerberos.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/sparksql_kerberos.png",
                "deletions": 0,
                "sha": "761279b3013d94a0a58fe9a24f907806ded274fb",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sparksql_kerberos.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql-node.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/sql-node.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/sql-node.png",
                "deletions": 0,
                "sha": "3fedae2cb0f6f11c42614e82cf929ae3a6504d10",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql-node.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql-node2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/sql-node2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/sql-node2.png",
                "deletions": 0,
                "sha": "4d11e4d710c732441dc16a26e901c01e0772f2b0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql-node2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/sql_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/sql_edit.png",
                "deletions": 0,
                "sha": "546261c42b407fdaca2832c153298fa7f6330948",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/sql_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_from_current.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/start_from_current.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/start_from_current.png",
                "deletions": 0,
                "sha": "557e704435c350c3fcda66946a6409ceca5468aa",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_from_current.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_from_current2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/start_from_current2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/start_from_current2.png",
                "deletions": 0,
                "sha": "004619988d497f1831a4a0f683665c058cb9a622",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_from_current2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_process.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/start_process.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/start_process.png",
                "deletions": 0,
                "sha": "c97c439e50bbdf4e24b78e0b096f3103f50c615a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/start_process.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/subprocess_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/subprocess_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/subprocess_edit.png",
                "deletions": 0,
                "sha": "6a2152a59fb29d1b0da1fe0bcf495b6079483161",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/subprocess_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-list.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task-list.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task-list.png",
                "deletions": 0,
                "sha": "d35662ddbd5010b41278d3710d2ae291e25e31f0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-list.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-log.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task-log.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task-log.png",
                "deletions": 0,
                "sha": "73e91beb7f86f1f2843fd0cb8b5d0763d6a08dea",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-log.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-log2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task-log2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task-log2.png",
                "deletions": 0,
                "sha": "3ea00a5d9ab0f4fa162589f734d957399dc27260",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task-log2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_history.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task_history.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task_history.png",
                "deletions": 0,
                "sha": "69573e3c70fb7a9e02f49a2bc1312a66e0554d11",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_history.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_list.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task_list.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task_list.png",
                "deletions": 0,
                "sha": "9b5bdca96a821f30e99a8673305a6763ff7a1358",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_list.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_log.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task_log.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task_log.png",
                "deletions": 0,
                "sha": "54aa9d69fcf66c027f1d8935609d7fafd05c0c63",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_log.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_log2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task_log2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task_log2.png",
                "deletions": 0,
                "sha": "ce86c4e4153593426802b18e1670cfbc4429484d",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_log2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_priority.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/task_priority.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/task_priority.png",
                "deletions": 0,
                "sha": "c7c34926e1d5bc0292d9d19742d46a46e8be7fca",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/task_priority.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/time-schedule.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/time-schedule.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/time-schedule.png",
                "deletions": 0,
                "sha": "0a6d6baafc1e9feda82102ad72f12cdff98f9e20",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/time-schedule.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/time-schedule2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/time-schedule2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/time-schedule2.png",
                "deletions": 0,
                "sha": "fdfc5be738820f91dd36fd153bbd004fbc09a657",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/time-schedule2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/tree_view.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/tree_view.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/tree_view.png",
                "deletions": 0,
                "sha": "2f553bd79d6442fa15df9e82f2bc6188f5075d4d",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/tree_view.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/udf_edit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/udf_edit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/udf_edit.png",
                "deletions": 0,
                "sha": "eb5df0416d677c8d5d001d70a63ea8ee3f6d2582",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/udf_edit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/user_manager.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/user_manager.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/user_manager.png",
                "deletions": 0,
                "sha": "865302783637adfc78cf435cf79141a6a3950cca",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/user_manager.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/useredit.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/useredit.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/useredit.png",
                "deletions": 0,
                "sha": "af83dc053d05d70e90ebd935386651927c133ab0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/useredit.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/useredit2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/useredit2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/useredit2.png",
                "deletions": 0,
                "sha": "0e9f5d71cebd6fad28673873542c19d216df8458",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/useredit2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/userinfo.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/userinfo.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/userinfo.png",
                "deletions": 0,
                "sha": "7ba9da756f855920ad8014202b1b214a16ad1a07",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/userinfo.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/variable_view.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/variable_view.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/variable_view.png",
                "deletions": 0,
                "sha": "2676d3788a3eca76f1a997de0dadef51f484faee",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/variable_view.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/variable_view2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/variable_view2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/variable_view2.png",
                "deletions": 0,
                "sha": "7badb6ca2d613c3ba38c2bf15b7e554807a0f4b8",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/variable_view2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker-group.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/worker-group.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/worker-group.png",
                "deletions": 0,
                "sha": "d35c17ec259bd4070d0ba883bc5b65553f641fd4",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker-group.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker-jk.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/worker-jk.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/worker-jk.png",
                "deletions": 0,
                "sha": "c953d9619bde31d4622c2db143e1c30860af75b5",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker-jk.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/worker.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/worker.png",
                "deletions": 0,
                "sha": "1e591f58c4fe4c5ac79ef693bac6116199ef3ba0",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker1.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/worker1.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/worker1.png",
                "deletions": 0,
                "sha": "e29aca7d6f2dff0a847107dae9963c2db3f24d7e",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker1.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker2.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/worker2.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/worker2.png",
                "deletions": 0,
                "sha": "a3efa85378a0602346c50f18fedb642bcf0c7d6b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/worker2.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/zk-jk.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/zk-jk.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/zk-jk.png",
                "deletions": 0,
                "sha": "cb503271b98fbe7e969d78501818b23d79406d6e",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/zk-jk.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/zookeeper.png",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/images/zookeeper.png?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/images/zookeeper.png",
                "deletions": 0,
                "sha": "05df9ff96f45c3f9c264b5e4ac0329fbb60a281b",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/images/zookeeper.png"
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/styles/website.css",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/styles/website.css?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/styles/website.css",
                "deletions": 22,
                "sha": "670448661038ff44c9789eea77a212500611ebeb",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/styles/website.css",
                "patch": "@@ -1,22 +0,0 @@\n-.gitbook-link {\n-  display: none !important;\n-}\n-.book.font-family-0 {\n-  font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n-}\n-\n-.body-inner .i18n {\n-  position: absolute;\n-  right: 140px;\n-  top: 0;\n-  height: 50px;\n-  line-height: 50px;\n-  padding: 0 10px;\n-  color: #ccc;\n-  font-size: 14px;\n-  display: inline-block;\n-}\n-\n-.body-inner .i18n:hover {\n-  color: #999;\n-}",
                "changes": 22
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E4%BB%BB%E5%8A%A1%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E4%BB%BB%E5%8A%A1%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1.md",
                "deletions": 54,
                "sha": "5e733b954092a33973fa41c1561c377ece55ee9b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E4%BB%BB%E5%8A%A1%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91.md",
                "patch": "@@ -1,54 +0,0 @@\n-## \u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1\n-\n-\u63d0\u9192:\u76ee\u524d\u4efb\u52a1\u63d2\u4ef6\u5f00\u53d1\u6682\u4e0d\u652f\u6301\u70ed\u90e8\u7f72\n-\n-### \u57fa\u4e8eSHELL\u7684\u4efb\u52a1\n-\n-#### \u57fa\u4e8eYARN\u7684\u8ba1\u7b97\uff08\u53c2\u89c1MapReduceTask\uff09\n-\n-- \u9700\u8981\u5728 **cn.escheduler.server.worker.task** \u4e0b\u7684 **TaskManager** \u7c7b\u4e2d\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1(\u4e5f\u9700\u5728TaskType\u6ce8\u518c\u5bf9\u5e94\u7684\u4efb\u52a1\u7c7b\u578b)\n-- \u9700\u8981\u7ee7\u627f**cn.escheduler.server.worker.task** \u4e0b\u7684 **AbstractYarnTask**\n-- \u6784\u9020\u65b9\u6cd5\u8c03\u5ea6 **AbstractYarnTask** \u6784\u9020\u65b9\u6cd5\n-- \u7ee7\u627f **AbstractParameters** \u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570\u5b9e\u4f53\n-- \u91cd\u5199 **AbstractTask** \u7684 **init** \u65b9\u6cd5\u4e2d\u89e3\u6790**\u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570**\n-- \u91cd\u5199 **buildCommand** \u5c01\u88c5command\n-\n-\n-\n-#### \u57fa\u4e8e\u975eYARN\u7684\u8ba1\u7b97\uff08\u53c2\u89c1ShellTask\uff09\n-- \u9700\u8981\u5728 **cn.escheduler.server.worker.task** \u4e0b\u7684 **TaskManager** \u4e2d\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1\n-\n-- \u9700\u8981\u7ee7\u627f**cn.escheduler.server.worker.task** \u4e0b\u7684 **AbstractTask**\n-\n-- \u6784\u9020\u65b9\u6cd5\u4e2d\u5b9e\u4f8b\u5316 **ShellCommandExecutor**\n-\n-  ```\n-  public ShellTask(TaskProps props, Logger logger) {\n-    super(props, logger);\n-  \n-    this.taskDir = props.getTaskDir();\n-  \n-    this.processTask = new ShellCommandExecutor(this::logHandle,\n-        props.getTaskDir(), props.getTaskAppId(),\n-        props.getTenantCode(), props.getEnvFile(), props.getTaskStartTime(),\n-        props.getTaskTimeout(), logger);\n-    this.processDao = DaoFactory.getDaoInstance(ProcessDao.class);\n-  }\n-  ```\n-\n-  \u4f20\u5165\u81ea\u5b9a\u4e49\u4efb\u52a1\u7684 **TaskProps**\u548c\u81ea\u5b9a\u4e49**Logger**\uff0cTaskProps \u5c01\u88c5\u4e86\u4efb\u52a1\u7684\u4fe1\u606f\uff0cLogger\u5206\u88c5\u4e86\u81ea\u5b9a\u4e49\u65e5\u5fd7\u4fe1\u606f\n-\n-- \u7ee7\u627f **AbstractParameters** \u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570\u5b9e\u4f53\n-\n-- \u91cd\u5199 **AbstractTask** \u7684 **init** \u65b9\u6cd5\u4e2d\u89e3\u6790**\u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570\u5b9e\u4f53**\n-\n-- \u91cd\u5199 **handle** \u65b9\u6cd5\uff0c\u8c03\u7528 **ShellCommandExecutor** \u7684 **run** \u65b9\u6cd5\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u4f20\u5165\u81ea\u5df1\u7684**command**\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4f20\u5165 ProcessDao\uff0c\u8bbe\u7f6e\u76f8\u5e94\u7684 **exitStatusCode**\n-\n-### \u57fa\u4e8e\u975eSHELL\u7684\u4efb\u52a1\uff08\u53c2\u89c1SqlTask\uff09\n-\n-- \u9700\u8981\u5728 **cn.escheduler.server.worker.task** \u4e0b\u7684 **TaskManager** \u4e2d\u521b\u5efa\u81ea\u5b9a\u4e49\u4efb\u52a1\n-- \u9700\u8981\u7ee7\u627f**cn.escheduler.server.worker.task** \u4e0b\u7684 **AbstractTask**\n-- \u7ee7\u627f **AbstractParameters** \u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570\u5b9e\u4f53\n-- \u6784\u9020\u65b9\u6cd5\u6216\u8005\u91cd\u5199 **AbstractTask** \u7684 **init** \u65b9\u6cd5\u4e2d\uff0c\u89e3\u6790\u81ea\u5b9a\u4e49\u4efb\u52a1\u53c2\u6570\u5b9e\u4f53\n-- \u91cd\u5199 **handle** \u65b9\u6cd5\u5b9e\u73b0\u4e1a\u52a1\u903b\u8f91\u5e76\u8bbe\u7f6e\u76f8\u5e94\u7684**exitStatusCode**\n-",
                "changes": 54
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u524d\u7aef\u5f00\u53d1\u6587\u6863.md",
                "deletions": 644,
                "sha": "f805f5ed8ca332442529bf719959a86dc940d7af",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md",
                "patch": "@@ -1,644 +0,0 @@\n-# \u524d\u7aef\u5f00\u53d1\u6587\u6863\n-\n-### \u6280\u672f\u9009\u578b\n-```\n-Vue mvvm\u6846\u67b6\n-\n-Es6 ECMAScript 6.0\n-\n-Ans-ui Analysys-ui\n-\n-D3 \u53ef\u89c6\u5316\u5e93\u56fe\u8868\u5e93\n-\n-Jsplumb \u8fde\u7ebf\u63d2\u4ef6\u5e93\n-\n-Lodash \u9ad8\u6027\u80fd\u7684 JavaScript \u5b9e\u7528\u5de5\u5177\u5e93\n-```\n-\n-\n-### \u5f00\u53d1\u73af\u5883\u642d\u5efa\n-   \n-- #### Node\u5b89\u88c5\n-Node\u5305\u4e0b\u8f7d (\u6ce8\u610f\u7248\u672c 8.9.4) `https://nodejs.org/download/release/v8.9.4/` \n-\n-\n-- #### \u524d\u7aef\u9879\u76ee\u6784\u5efa\n-\u7528\u547d\u4ee4\u884c\u6a21\u5f0f `cd`  \u8fdb\u5165 `escheduler-ui`\u9879\u76ee\u76ee\u5f55\u5e76\u6267\u884c `npm install` \u62c9\u53d6\u9879\u76ee\u4f9d\u8d56\u5305\n-\n-> \u5982\u679c `npm install` \u901f\u5ea6\u975e\u5e38\u6162 \n-\n-> \u53ef\u4ee5\u8f6c\u6dd8\u5b9d\u955c\u50cf\u547d\u4ee4\u884c\u8f93\u5165 `npm install -g cnpm --registry=https://registry.npm.taobao.org`\n-\n-> \u8fd0\u884c `cnpm install` \n-\n-\n-- \u65b0\u5efa\u4e00\u4e2a`.env`\u6587\u4ef6\uff0c\u7528\u4e8e\u8ddf\u540e\u7aef\u4ea4\u4e92\u7684\u63a5\u53e3\n-\n-\u5728`escheduler-ui`\u76ee\u5f55\u4e0b\u65b0\u5efa\u4e00\u4e2a`.env`\u6587\u4ef6\uff0c\u5728\u6587\u4ef6\u91cc\u6dfb\u52a0\u540e\u7aef\u670d\u52a1\u7684ip\u5730\u5740\u548c\u7aef\u53e3\uff0c\u7528\u4e8e\u8ddf\u540e\u7aef\u4ea4\u4e92\uff0c`.env`\u6587\u4ef6\u5185\u5bb9\u5982\u4e0b\uff1a\n-```\n-# \u4ee3\u7406\u7684\u63a5\u53e3\u5730\u5740\uff08\u81ea\u884c\u4fee\u6539\uff09\n-API_BASE = http://192.168.xx.xx:12345\n-\n-# \u5982\u679c\u60a8\u9700\u8981\u7528ip\u8bbf\u95ee\u9879\u76ee\u53ef\u4ee5\u628a \"#\" \u53f7\u53bb\u6389\uff08\u4f8b\uff09\n-#DEV_HOST = 192.168.xx.xx\n-```\n-\n-> #####  \uff01\uff01\uff01\u8fd9\u91cc\u7279\u522b\u6ce8\u610f \u9879\u76ee\u5982\u679c\u5728\u62c9\u53d6\u4f9d\u8d56\u5305\u7684\u8fc7\u7a0b\u4e2d\u62a5 \" node-sass error \" \u9519\u8bef\uff0c\u8bf7\u5728\u6267\u884c\u5b8c\u540e\u518d\u6b21\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\n-```\n-npm install node-sass --unsafe-perm //\u5355\u72ec\u5b89\u88c5node-sass\u4f9d\u8d56\n-```\n-\n-- #### \u5f00\u53d1\u73af\u5883\u8fd0\u884c\n-- `npm start` \u9879\u76ee\u5f00\u53d1\u73af\u5883 (\u542f\u52a8\u540e\u8bbf\u95ee\u5730\u5740 http://localhost:8888/#/)\n-\n-\n-#### \u524d\u7aef\u9879\u76ee\u53d1\u5e03\n-\n-- `npm run build` \u9879\u76ee\u6253\u5305 (\u6253\u5305\u540e\u6839\u76ee\u5f55\u4f1a\u521b\u5efa\u4e00\u4e2a\u540d\u4e3adist\u6587\u4ef6\u5939\uff0c\u7528\u4e8e\u53d1\u5e03\u7ebf\u4e0aNginx)\n-\n-\u8fd0\u884c `npm run build` \u547d\u4ee4\uff0c\u751f\u6210\u6253\u5305\u6587\u4ef6\uff08dist\uff09\u5305\n-\n-\u518d\u62f7\u8d1d\u5230\u670d\u52a1\u5668\u5bf9\u5e94\u7684\u76ee\u5f55\u4e0b\uff08\u524d\u7aef\u670d\u52a1\u9759\u6001\u9875\u9762\u5b58\u653e\u76ee\u5f55\uff09\n-\n-\n-\u8bbf\u95ee\u5730\u5740 `http://localhost:8888/#/` \n-\n-\n-#### Linux\u4e0b\u4f7f\u7528node\u542f\u52a8\u5e76\u4e14\u5b88\u62a4\u8fdb\u7a0b\n-\n-\u5b89\u88c5pm2 `npm install -g pm2`\n-\n-\u5728\u9879\u76ee`escheduler-ui`\u6839\u76ee\u5f55\u6267\u884c `pm2 start npm -- run dev` \u542f\u52a8\u9879\u76ee\n-\n-#### \u547d\u4ee4\n-\n-- \u542f\u7528 `pm2 start npm -- run dev`\n-\n-- \u505c\u6b62 `pm2 stop npm`\n-\n-- \u5220\u9664 `pm2 delete npm`\n-\n-- \u72b6\u6001 `pm2 list`\n-\n-```\n-\n-[root@localhost escheduler-ui]# pm2 start npm -- run dev\n-[PM2] Applying action restartProcessId on app [npm](ids: 0)\n-[PM2] [npm](0) \u2713\n-[PM2] Process successfully started\n-\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n-\u2502 App name \u2502 id \u2502 version \u2502 mode \u2502 pid  \u2502 status \u2502 restart \u2502 uptime \u2502 cpu \u2502 mem      \u2502 user \u2502 watching \u2502\n-\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n-\u2502 npm      \u2502 0  \u2502 N/A     \u2502 fork \u2502 6168 \u2502 online \u2502 31      \u2502 0s     \u2502 0%  \u2502 5.6 MB   \u2502 root \u2502 disabled \u2502\n-\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n- Use `pm2 show <id|name>` to get more details about an app\n-\n-```\n-\n-\n-### \u9879\u76ee\u76ee\u5f55\u7ed3\u6784\n-\n-`build` \u6253\u5305\u53ca\u5f00\u53d1\u73af\u5883\u9879\u76ee\u7684\u4e00\u4e9bwebpack\u914d\u7f6e\n-\n-`node_modules` \u5f00\u53d1\u73af\u5883node\u4f9d\u8d56\u5305\n-\n-`src` \u9879\u76ee\u6240\u9700\u6587\u4ef6\n-\n-`src => combo` \u9879\u76ee\u7b2c\u4e09\u65b9\u8d44\u6e90\u672c\u5730\u5316 `npm run combo`\u5177\u4f53\u67e5\u770b`build/combo.js`\n-\n-`src => font` \u5b57\u4f53\u56fe\u6807\u5e93\u53ef\u8bbf\u95ee `https://www.iconfont.cn` \u8fdb\u884c\u6dfb\u52a0 \u6ce8\u610f\uff1a\u5b57\u4f53\u5e93\u7528\u7684\u81ea\u5df1\u7684 \u4e8c\u6b21\u5f00\u53d1\u9700\u8981\u91cd\u65b0\u5f15\u5165\u81ea\u5df1\u7684\u5e93 `src/sass/common/_font.scss`\n-\n-`src => images` \u516c\u5171\u56fe\u7247\u5b58\u653e\n-\n-`src => js` js/vue\n-\n-`src => lib` \u516c\u53f8\u5185\u90e8\u7ec4\u4ef6\uff08\u516c\u53f8\u7ec4\u4ef6\u5e93\u5f00\u6e90\u540e\u53ef\u5220\u6389\uff09\n-\n-`src => sass` sass\u6587\u4ef6 \u4e00\u4e2a\u9875\u9762\u5bf9\u5e94\u4e00\u4e2asass\u6587\u4ef6\n-\n-`src => view` \u9875\u9762\u6587\u4ef6 \u4e00\u4e2a\u9875\u9762\u5bf9\u5e94\u4e00\u4e2ahtml\u6587\u4ef6\n-\n-```\n-> \u9879\u76ee\u91c7\u7528vue\u5355\u9875\u9762\u5e94\u7528(SPA)\u5f00\u53d1\n-- \u6240\u6709\u9875\u9762\u5165\u53e3\u6587\u4ef6\u5728 `src/js/conf/${\u5bf9\u5e94\u9875\u9762\u6587\u4ef6\u540d => home}` \u7684 `index.js` \u5165\u53e3\u6587\u4ef6\n-- \u5bf9\u5e94\u7684sass\u6587\u4ef6\u5219\u5728 `src/sass/conf/${\u5bf9\u5e94\u9875\u9762\u6587\u4ef6\u540d => home}/index.scss`\n-- \u5bf9\u5e94\u7684html\u6587\u4ef6\u5219\u5728 `src/view/${\u5bf9\u5e94\u9875\u9762\u6587\u4ef6\u540d => home}/index.html`\n-```\n-\n-\u516c\u5171\u6a21\u5757\u53cautil `src/js/module`\n-\n-`components` => \u5185\u90e8\u9879\u76ee\u516c\u5171\u7ec4\u4ef6\n-\n-`download` => \u4e0b\u8f7d\u7ec4\u4ef6\n-\n-`echarts` => \u56fe\u8868\u7ec4\u4ef6\n-\n-`filter` => \u8fc7\u6ee4\u5668\u548cvue\u7ba1\u9053\n-\n-`i18n` => \u56fd\u9645\u5316\n-\n-`io` => io\u8bf7\u6c42\u5c01\u88c5 \u57fa\u4e8eaxios\n-\n-`mixin` => vue mixin \u516c\u5171\u90e8\u5206 \u7528\u4e8edisabled\u64cd\u4f5c\n-\n-`permissions` => \u6743\u9650\u64cd\u4f5c\n-\n-`util` => \u5de5\u5177\n-\n-\n-### \u7cfb\u7edf\u529f\u80fd\u6a21\u5757\n-\n-\u9996\u9875 => `http://localhost:8888/#/home`\n-\n-\u9879\u76ee\u7ba1\u7406 => `http://localhost:8888/#/projects/list`\n-```\n-| \u9879\u76ee\u9996\u9875\n-| \u5de5\u4f5c\u6d41\n-  - \u5de5\u4f5c\u6d41\u5b9a\u4e49\n-  - \u5de5\u4f5c\u6d41\u5b9e\u4f8b\n-  - \u4efb\u52a1\u5b9e\u4f8b\n-```\n- \n-\u8d44\u6e90\u7ba1\u7406 => `http://localhost:8888/#/resource/file`\n-```\n-| \u6587\u4ef6\u7ba1\u7406\n-| UDF\u7ba1\u7406\n-  - \u8d44\u6e90\u7ba1\u7406\n-  - \u51fd\u6570\u7ba1\u7406\n-```\n-\n-\u6570\u636e\u6e90\u7ba1\u7406 => `http://localhost:8888/#/datasource/list`\n-\n-\u5b89\u5168\u4e2d\u5fc3 => `http://localhost:8888/#/security/tenant`\n-```\n-| \u79df\u6237\u7ba1\u7406\n-| \u7528\u6237\u7ba1\u7406\n-| \u544a\u8b66\u7ec4\u7ba1\u7406\n-  - master\n-  - worker\n-```\n-\n-\u7528\u6237\u4e2d\u5fc3 => `http://localhost:8888/#/user/account`\n-\n-\n-## \u8def\u7531\u548c\u72b6\u6001\u7ba1\u7406\n-\n-\u9879\u76ee `src/js/conf/home` \u4e0b\u5206\u4e3a\n-\n-`pages` => \u8def\u7531\u6307\u5411\u9875\u9762\u76ee\u5f55\n-```\n- \u8def\u7531\u5730\u5740\u5bf9\u5e94\u7684\u9875\u9762\u6587\u4ef6\n-```\n-\n-`router` => \u8def\u7531\u7ba1\u7406\n-```\n-vue\u7684\u8def\u7531\u5668\uff0c\u5728\u6bcf\u4e2a\u9875\u9762\u7684\u5165\u53e3\u6587\u4ef6index.js \u90fd\u4f1a\u6ce8\u518c\u8fdb\u6765 \u5177\u4f53\u64cd\u4f5c\uff1ahttps://router.vuejs.org/zh/\n-```\n-\n-`store` => \u72b6\u6001\u7ba1\u7406\n-```\n-\u6bcf\u4e2a\u8def\u7531\u5bf9\u5e94\u7684\u9875\u9762\u90fd\u6709\u4e00\u4e2a\u72b6\u6001\u7ba1\u7406\u7684\u6587\u4ef6 \u5206\u4e3a\uff1a\n-\n-actions => mapActions => \u8be6\u60c5\uff1ahttps://vuex.vuejs.org/zh/guide/actions.html\n-\n-getters => mapGetters => \u8be6\u60c5\uff1ahttps://vuex.vuejs.org/zh/guide/getters.html\n-\n-index => \u5165\u53e3\n-\n-mutations => mapMutations => \u8be6\u60c5\uff1ahttps://vuex.vuejs.org/zh/guide/mutations.html\n-\n-state => mapState => \u8be6\u60c5\uff1ahttps://vuex.vuejs.org/zh/guide/state.html\n-\n-\u5177\u4f53\u64cd\u4f5c\uff1ahttps://vuex.vuejs.org/zh/\n-\n-```\n-\n-\n-## \u89c4\u8303\n-## Vue\u89c4\u8303\n-##### 1.\u7ec4\u4ef6\u540d\n-\u7ec4\u4ef6\u540d\u4e3a\u591a\u4e2a\u5355\u8bcd\uff0c\u5e76\u4e14\u7528\u8fde\u63a5\u7ebf\uff08-\uff09\u8fde\u63a5\uff0c\u907f\u514d\u4e0e HTML \u6807\u7b7e\u51b2\u7a81\uff0c\u5e76\u4e14\u7ed3\u6784\u66f4\u52a0\u6e05\u6670\u3002\n-```\n-// \u6b63\u4f8b\n-export default {\n-    name: 'page-article-item'\n-}\n-```\n-\n-##### 2.\u7ec4\u4ef6\u6587\u4ef6\n-`src/js/module/components`\u9879\u76ee\u5185\u90e8\u516c\u5171\u7ec4\u4ef6\u4e66\u5199\u6587\u4ef6\u5939\u540d\u4e0e\u6587\u4ef6\u540d\u540c\u540d,\u516c\u5171\u7ec4\u4ef6\u5185\u90e8\u6240\u62c6\u5206\u7684\u5b50\u7ec4\u4ef6\u4e0eutil\u5de5\u5177\u90fd\u653e\u7f6e\u7ec4\u4ef6\u5185\u90e8 `_source`\u6587\u4ef6\u5939\u91cc\u3002\n-```\n-\u2514\u2500\u2500 components\n-    \u251c\u2500\u2500 header\n-        \u251c\u2500\u2500 header.vue\n-        \u2514\u2500\u2500 _source\n-            \u2514\u2500\u2500 nav.vue\n-            \u2514\u2500\u2500 util.js\n-    \u251c\u2500\u2500 conditions\n-        \u251c\u2500\u2500 conditions.vue\n-        \u2514\u2500\u2500 _source\n-            \u2514\u2500\u2500 search.vue\n-            \u2514\u2500\u2500 util.js\n-```\n-\n-##### 3.Prop\n-\u5b9a\u4e49 Prop \u7684\u65f6\u5019\u5e94\u8be5\u59cb\u7ec8\u4ee5\u9a7c\u5cf0\u683c\u5f0f\uff08camelCase\uff09\u547d\u540d\uff0c\u5728\u7236\u7ec4\u4ef6\u8d4b\u503c\u7684\u65f6\u5019\u4f7f\u7528\u8fde\u63a5\u7ebf\uff08-\uff09\u3002\n-\u8fd9\u91cc\u9075\u5faa\u6bcf\u4e2a\u8bed\u8a00\u7684\u7279\u6027\uff0c\u56e0\u4e3a\u5728 HTML \u6807\u8bb0\u4e2d\u5bf9\u5927\u5c0f\u5199\u662f\u4e0d\u654f\u611f\u7684\uff0c\u4f7f\u7528\u8fde\u63a5\u7ebf\u66f4\u52a0\u53cb\u597d\uff1b\u800c\u5728 JavaScript \u4e2d\u66f4\u81ea\u7136\u7684\u662f\u9a7c\u5cf0\u547d\u540d\u3002\n-```\n-// Vue\n-props: {\n-    articleStatus: Boolean\n-}\n-// HTML\n-<article-item :article-status=\"true\"></article-item>\n-```\n-\n-Prop \u7684\u5b9a\u4e49\u5e94\u8be5\u5c3d\u91cf\u8be6\u7ec6\u7684\u6307\u5b9a\u5176\u7c7b\u578b\u3001\u9ed8\u8ba4\u503c\u548c\u9a8c\u8bc1\u3002\n-\n-\u793a\u4f8b\uff1a\n-\n-```\n-props: {\n-    attrM: Number,\n-    attrA: {\n-        type: String,\n-        required: true\n-    },\n-    attrZ: {\n-        type: Object,\n-        // \u6570\u7ec4/\u5bf9\u8c61\u7684\u9ed8\u8ba4\u503c\u5e94\u8be5\u7531\u4e00\u4e2a\u5de5\u5382\u51fd\u6570\u8fd4\u56de\n-        default: function () {\n-            return {\n-                msg: '\u6210\u5c31\u4f60\u6211'\n-            }\n-        }\n-    },\n-    attrE: {\n-        type: String,\n-        validator: function (v) {\n-            return !(['success', 'fail'].indexOf(v) === -1) \n-        }\n-    }\n-}\n-```\n-\n-##### 4.v-for\n-\u5728\u6267\u884c v-for \u904d\u5386\u7684\u65f6\u5019\uff0c\u603b\u662f\u5e94\u8be5\u5e26\u4e0a key \u503c\u4f7f\u66f4\u65b0 DOM \u65f6\u6e32\u67d3\u6548\u7387\u66f4\u9ad8\u3002\n-```\n-<ul>\n-    <li v-for=\"item in list\" :key=\"item.id\">\n-        {{ item.title }}\n-    </li>\n-</ul>\n-```\n-\n-v-for \u5e94\u8be5\u907f\u514d\u4e0e v-if \u5728\u540c\u4e00\u4e2a\u5143\u7d20\uff08`\u4f8b\u5982\uff1a<li>`\uff09\u4e0a\u4f7f\u7528\uff0c\u56e0\u4e3a v-for \u7684\u4f18\u5148\u7ea7\u6bd4 v-if \u66f4\u9ad8\uff0c\u4e3a\u4e86\u907f\u514d\u65e0\u6548\u8ba1\u7b97\u548c\u6e32\u67d3\uff0c\u5e94\u8be5\u5c3d\u91cf\u5c06 v-if \u653e\u5230\u5bb9\u5668\u7684\u7236\u5143\u7d20\u4e4b\u4e0a\u3002\n-```\n-<ul v-if=\"showList\">\n-    <li v-for=\"item in list\" :key=\"item.id\">\n-        {{ item.title }}\n-    </li>\n-</ul>\n-```\n-\n-##### 5.v-if / v-else-if / v-else\n-\u82e5\u540c\u4e00\u7ec4 v-if \u903b\u8f91\u63a7\u5236\u4e2d\u7684\u5143\u7d20\u903b\u8f91\u76f8\u540c\uff0cVue \u4e3a\u4e86\u66f4\u9ad8\u6548\u7684\u5143\u7d20\u5207\u6362\uff0c\u4f1a\u590d\u7528\u76f8\u540c\u7684\u90e8\u5206\uff0c`\u4f8b\u5982\uff1avalue`\u3002\u4e3a\u4e86\u907f\u514d\u590d\u7528\u5e26\u6765\u7684\u4e0d\u5408\u7406\u6548\u679c\uff0c\u5e94\u8be5\u5728\u540c\u79cd\u5143\u7d20\u4e0a\u52a0\u4e0a key \u505a\u6807\u8bc6\u3002\n-```\n-<div v-if=\"hasData\" key=\"mazey-data\">\n-    <span>{{ mazeyData }}</span>\n-</div>\n-<div v-else key=\"mazey-none\">\n-    <span>\u65e0\u6570\u636e</span>\n-</div>\n-```\n-\n-##### 6.\u6307\u4ee4\u7f29\u5199\n-\u4e3a\u4e86\u7edf\u4e00\u89c4\u8303\u59cb\u7ec8\u4f7f\u7528\u6307\u4ee4\u7f29\u5199\uff0c\u4f7f\u7528`v-bind`\uff0c`v-on`\u5e76\u6ca1\u6709\u4ec0\u4e48\u4e0d\u597d\uff0c\u8fd9\u91cc\u4ec5\u4e3a\u4e86\u7edf\u4e00\u89c4\u8303\u3002\n-```\n-<input :value=\"mazeyUser\" @click=\"verifyUser\">\n-```\n-\n-##### 7.\u5355\u6587\u4ef6\u7ec4\u4ef6\u7684\u9876\u7ea7\u5143\u7d20\u987a\u5e8f\n-\u6837\u5f0f\u540e\u7eed\u90fd\u662f\u6253\u5305\u5728\u4e00\u4e2a\u6587\u4ef6\u91cc\uff0c\u6240\u6709\u5728\u5355\u4e2avue\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u6837\u5f0f\uff0c\u5728\u522b\u7684\u6587\u4ef6\u91cc\u540c\u7c7b\u540d\u7684\u6837\u5f0f\u4e5f\u662f\u4f1a\u751f\u6548\u7684\u6240\u6709\u5728\u521b\u5efa\u4e00\u4e2a\u7ec4\u4ef6\u524d\u90fd\u4f1a\u6709\u4e2a\u9876\u7ea7\u7c7b\u540d\n-\u6ce8\u610f\uff1a\u9879\u76ee\u5185\u5df2\u7ecf\u589e\u52a0\u4e86sass\u63d2\u4ef6\uff0c\u5355\u4e2avue\u6587\u4ef6\u91cc\u53ef\u4ee5\u76f4\u63a5\u4e66\u5199sass\u8bed\u6cd5\n-\u4e3a\u4e86\u7edf\u4e00\u548c\u4fbf\u4e8e\u9605\u8bfb\uff0c\u5e94\u8be5\u6309 `<template>`\u3001`<script>`\u3001`<style>`\u7684\u987a\u5e8f\u653e\u7f6e\u3002\n-\n-```\n-<template>\n-  <div class=\"test-model\">\n-    test\n-  </div>\n-</template>\n-<script>\n-  export default {\n-    name: \"test\",\n-    data() {\n-      return {}\n-    },\n-    props: {},\n-    methods: {},\n-    watch: {},\n-    beforeCreate() {\n-    },\n-    created() {\n-    },\n-    beforeMount() {\n-    },\n-    mounted() {\n-    },\n-    beforeUpdate() {\n-    },\n-    updated() {\n-    },\n-    beforeDestroy() {\n-    },\n-    destroyed() {\n-    },\n-    computed: {},\n-    components: {},\n-  }\n-</script>\n-\n-<style lang=\"scss\" rel=\"stylesheet/scss\">\n-  .test-model {\n-\n-  }\n-</style>\n-\n-```\n-\n-\n-## JavaScript\u89c4\u8303\n-\n-##### 1.var / let / const\n-\u5efa\u8bae\u4e0d\u518d\u4f7f\u7528 var\uff0c\u800c\u4f7f\u7528 let / const\uff0c\u4f18\u5148\u4f7f\u7528 const\u3002\u4efb\u4f55\u4e00\u4e2a\u53d8\u91cf\u7684\u4f7f\u7528\u90fd\u8981\u63d0\u524d\u7533\u660e\uff0c\u9664\u4e86 function \u5b9a\u4e49\u7684\u51fd\u6570\u53ef\u4ee5\u968f\u4fbf\u653e\u5728\u4efb\u4f55\u4f4d\u7f6e\u3002\n-\n-##### 2.\u5f15\u53f7\n-```\n-const foo = '\u540e\u9664'\n-const bar = `${foo}\uff0c\u524d\u7aef\u5de5\u7a0b\u5e08`\n-```\n-\n-##### 3.\u51fd\u6570\n-\u533f\u540d\u51fd\u6570\u7edf\u4e00\u4f7f\u7528\u7bad\u5934\u51fd\u6570\uff0c\u591a\u4e2a\u53c2\u6570/\u8fd4\u56de\u503c\u65f6\u4f18\u5148\u4f7f\u7528\u5bf9\u8c61\u7684\u7ed3\u6784\u8d4b\u503c\u3002\n-```\n-function getPersonInfo ({name, sex}) {\n-    // ...\n-    return {name, gender}\n-}\n-```\n-\u51fd\u6570\u540d\u7edf\u4e00\u4f7f\u7528\u9a7c\u5cf0\u547d\u540d\uff0c\u4ee5\u5927\u5199\u5b57\u6bcd\u5f00\u5934\u7533\u660e\u7684\u90fd\u662f\u6784\u9020\u51fd\u6570\uff0c\u4f7f\u7528\u5c0f\u5199\u5b57\u6bcd\u5f00\u5934\u7684\u90fd\u662f\u666e\u901a\u51fd\u6570\uff0c\u4e5f\u4e0d\u8be5\u4f7f\u7528 new \u64cd\u4f5c\u7b26\u53bb\u64cd\u4f5c\u666e\u901a\u51fd\u6570\u3002\n-\n-##### 4.\u5bf9\u8c61\n-```\n-const foo = {a: 0, b: 1}\n-const bar = JSON.parse(JSON.stringify(foo))\n-\n-const foo = {a: 0, b: 1}\n-const bar = {...foo, c: 2}\n-\n-const foo = {a: 3}\n-Object.assign(foo, {b: 4})\n-\n-const myMap = new Map([])\n-for (let [key, value] of myMap.entries()) {\n-    // ...\n-}\n-```\n-\n-##### 5.\u6a21\u5757\n-\u7edf\u4e00\u4f7f\u7528 import / export \u7684\u65b9\u5f0f\u7ba1\u7406\u9879\u76ee\u7684\u6a21\u5757\u3002\n-```\n-// lib.js\n-export default {}\n-\n-// app.js\n-import app from './lib'\n-```\n-\n-import \u7edf\u4e00\u653e\u5728\u6587\u4ef6\u9876\u90e8\u3002\n-\n-\u5982\u679c\u6a21\u5757\u53ea\u6709\u4e00\u4e2a\u8f93\u51fa\u503c\uff0c\u4f7f\u7528 `export default`\uff0c\u5426\u5219\u4e0d\u7528\u3002\n-\n-\n-## HTML / CSS\n-\n-###### 1.\u6807\u7b7e\n-\u5728\u5f15\u7528\u5916\u90e8 CSS \u6216 JavaScript \u65f6\u4e0d\u5199 type \u5c5e\u6027\u3002HTML5 \u9ed8\u8ba4 type \u4e3a `text/css` \u548c `text/javascript` \u5c5e\u6027\uff0c\u6240\u4ee5\u6ca1\u5fc5\u8981\u6307\u5b9a\u3002\n-```\n-<link rel=\"stylesheet\" href=\"//www.test.com/css/test.css\">\n-<script src=\"//www.test.com/js/test.js\"></script>\n-```\n-\n-##### 2.\u547d\u540d\n-Class \u548c ID \u7684\u547d\u540d\u5e94\u8be5\u8bed\u4e49\u5316\uff0c\u901a\u8fc7\u770b\u540d\u5b57\u5c31\u77e5\u9053\u662f\u5e72\u561b\u7684\uff1b\u591a\u4e2a\u5355\u8bcd\u7528\u8fde\u63a5\u7ebf - \u8fde\u63a5\u3002\n-```\n-// \u6b63\u4f8b\n-.test-header{\n-    font-size: 20px;\n-}\n-```\n-\n-##### 3.\u5c5e\u6027\u7f29\u5199\n-CSS \u5c5e\u6027\u5c3d\u91cf\u4f7f\u7528\u7f29\u5199\uff0c\u63d0\u9ad8\u4ee3\u7801\u7684\u6548\u7387\u548c\u65b9\u4fbf\u7406\u89e3\u3002\n-\n-```\n-// \u53cd\u4f8b\n-border-width: 1px;\n-border-style: solid;\n-border-color: #ccc;\n-\n-// \u6b63\u4f8b\n-border: 1px solid #ccc;\n-```\n-\n-##### 4.\u6587\u6863\u7c7b\u578b\n-\u5e94\u8be5\u603b\u662f\u4f7f\u7528 HTML5 \u6807\u51c6\u3002\n-```\n-<!DOCTYPE html>\n-```\n-\n-##### 5.\u6ce8\u91ca\n-\u5e94\u8be5\u7ed9\u4e00\u4e2a\u6a21\u5757\u6587\u4ef6\u5199\u4e00\u4e2a\u533a\u5757\u6ce8\u91ca\u3002\n-```\n-/**\n-* @module mazey/api\n-* @author Mazey <mazey@mazey.net>\n-* @description test.\n-* */\n-```\n-\n-\n-## \u63a5\u53e3\n-\n-##### \u6240\u6709\u7684\u63a5\u53e3\u90fd\u4ee5 Promise \u5f62\u5f0f\u8fd4\u56de \n-\u6ce8\u610f\u975e0\u90fd\u4e3a\u9519\u8bef\u8d70catch\n-\n-```\n-const test = () => {\n-  return new Promise((resolve, reject) => {\n-    resolve({\n-      a:1\n-    })\n-  })\n-}\n-\n-// \u8c03\u7528\n-test.then(res => {\n-  console.log(res)\n-  // {a:1}\n-})\n-```\n-\n-\u6b63\u5e38\u8fd4\u56de\n-```\n-{\n-  code:0,\n-  data:{}\n-  msg:'\u6210\u529f'\n-}\n-```\n-\n-\u9519\u8bef\u8fd4\u56de\n-```\n-{\n-  code:10000, \n-  data:{}\n-  msg:'\u5931\u8d25'\n-}\n-```\n-\n-##### \u76f8\u5173\u63a5\u53e3\u8def\u5f84\n-\n-dag \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/dag/actions.js`\n-\n-\u6570\u636e\u6e90\u4e2d\u5fc3 \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/datasource/actions.js`\n-\n-\u9879\u76ee\u7ba1\u7406 \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/projects/actions.js`\n-\n-\u8d44\u6e90\u4e2d\u5fc3 \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/resource/actions.js`\n-\n-\u5b89\u5168\u4e2d\u5fc3 \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/security/actions.js`\n-\n-\u7528\u6237\u4e2d\u5fc3 \u76f8\u5173\u63a5\u53e3 `src/js/conf/home/store/user/actions.js`\n-\n-\n-\n-## \u6269\u5c55\u5f00\u53d1\n-\n-##### 1.\u589e\u52a0\u8282\u70b9\n-\n-(1) \u5148\u5c06\u8282\u70b9\u7684icon\u5c0f\u56fe\u6807\u653e\u7f6e`src/js/conf/home/pages/dag/img`\u6587\u4ef6\u5939\u5185\uff0c\u6ce8\u610f `toolbar_${\u540e\u53f0\u5b9a\u4e49\u7684\u8282\u70b9\u7684\u82f1\u6587\u540d\u79f0 \u4f8b\u5982:SHELL}.png`\n-(2) \u627e\u5230 `src/js/conf/home/pages/dag/_source/config.js` \u91cc\u7684 `tasksType` \u5bf9\u8c61\uff0c\u5f80\u91cc\u589e\u52a0\n-```\n-'DEPENDENT': {  // \u540e\u53f0\u5b9a\u4e49\u8282\u70b9\u7c7b\u578b\u82f1\u6587\u540d\u79f0\u7528\u4f5ckey\u503c\n-  desc: 'DEPENDENT',  // tooltip desc\n-  color: '#2FBFD8'  // \u4ee3\u8868\u7684\u989c\u8272\u4e3b\u8981\u7528\u4e8e tree\u548cgantt \u4e24\u5f20\u56fe\n-}\n-```\n-\n-(3) \u5728 `src/js/conf/home/pages/dag/_source/formModel/tasks` \u589e\u52a0\u4e00\u4e2a `${\u8282\u70b9\u7c7b\u578b\uff08\u5c0f\u5199\uff09}`.vue \u6587\u4ef6\uff0c\u8ddf\u5f53\u524d\u8282\u70b9\u76f8\u5173\u7684\u7ec4\u4ef6\u5185\u5bb9\u90fd\u5728\u8fd9\u91cc\u5199\u3002 \u5c5e\u4e8e\u8282\u70b9\u7ec4\u4ef6\u5185\u7684\u5fc5\u987b\u62e5\u6709\u4e00\u4e2a\u51fd\u6570 `_verification()` \u9a8c\u8bc1\u6210\u529f\u540e\u8bb2\u5f53\u524d\u7ec4\u4ef6\u7684\u76f8\u5173\u6570\u636e\u5f80\u7236\u7ec4\u4ef6\u629b\u3002\n-```\n-/**\n- * \u9a8c\u8bc1\n-*/\n-  _verification () {\n-    // datasource \u5b50\u7ec4\u4ef6\u9a8c\u8bc1\n-    if (!this.$refs.refDs._verifDatasource()) {\n-      return false\n-    }\n-\n-    // \u9a8c\u8bc1\u51fd\u6570\n-    if (!this.method) {\n-      this.$message.warning(`${i18n.$t('\u8bf7\u8f93\u5165\u65b9\u6cd5')}`)\n-      return false\n-    }\n-\n-    // localParams \u5b50\u7ec4\u4ef6\u9a8c\u8bc1\n-    if (!this.$refs.refLocalParams._verifProp()) {\n-      return false\n-    }\n-    // \u5b58\u50a8\n-    this.$emit('on-params', {\n-      type: this.type,\n-      datasource: this.datasource,\n-      method: this.method,\n-      localParams: this.localParams\n-    })\n-    return true\n-  }\n-``` \n-\n-(4) \u8282\u70b9\u7ec4\u4ef6\u5185\u90e8\u6240\u7528\u5230\u516c\u5171\u7684\u7ec4\u4ef6\u90fd\u5728`_source`\u4e0b\uff0c`commcon.js`\u7528\u4e0e\u914d\u7f6e\u516c\u5171\u6570\u636e\n-\n-##### 2.\u589e\u52a0\u72b6\u6001\u7c7b\u578b\n-(1) \u627e\u5230 `src/js/conf/home/pages/dag/_source/config.js` \u91cc\u7684 `tasksState` \u5bf9\u8c61\uff0c\u5f80\u91cc\u589e\u52a0\n-```\n-'WAITTING_DEPEND': {  //\u540e\u7aef\u5b9a\u4e49\u72b6\u6001\u7c7b\u578b \u524d\u7aef\u7528\u4f5ckey\u503c\n-  id: 11,  // \u524d\u7aef\u5b9a\u4e49id \u540e\u7eed\u7528\u4f5c\u6392\u5e8f\n-  desc: `${i18n.$t('\u7b49\u5f85\u4f9d\u8d56')}`,  // tooltip desc\n-  color: '#5101be',  // \u4ee3\u8868\u7684\u989c\u8272\u4e3b\u8981\u7528\u4e8e tree\u548cgantt \u4e24\u5f20\u56fe\n-  icoUnicode: '&#xe68c;',  // \u5b57\u4f53\u56fe\u6807 \n-  isSpin: false  // \u662f\u5426\u65cb\u8f6c\uff08\u9700\u4ee3\u7801\u5224\u65ad\uff09\n-}\n-```\n-\n-##### 3.\u589e\u52a0\u64cd\u4f5c\u680f\u5de5\u5177\n-(1) \u627e\u5230 `src/js/conf/home/pages/dag/_source/config.js` \u91cc\u7684 `toolOper` \u5bf9\u8c61\uff0c\u5f80\u91cc\u589e\u52a0\n-```\n-{\n-  code: 'pointer',  // \u5de5\u5177\u6807\u8bc6\n-  icon: '&#xe781;',  // \u5de5\u5177\u56fe\u6807 \n-  disable: disable,  // \u662f\u5426\u7981\u7528\n-  desc: `${i18n.$t('\u62d6\u52a8\u8282\u70b9\u548c\u9009\u4e2d\u9879')}`  // tooltip desc\n-}\n-```\n-\n-(2) \u5de5\u5177\u7c7b\u90fd\u4ee5\u4e00\u4e2a\u6784\u9020\u51fd\u6570\u8fd4\u56de `src/js/conf/home/pages/dag/_source/plugIn`\n-\n-`downChart.js`  =>  dag \u56fe\u7247\u4e0b\u8f7d\u5904\u7406 \n-\n-`dragZoom.js`  =>  \u9f20\u6807\u7f29\u653e\u6548\u679c\u5904\u7406 \n-\n-`jsPlumbHandle.js`  =>  \u62d6\u62fd\u7ebf\u6761\u5904\u7406 \n-\n-`util.js`  =>   \u5c5e\u4e8e `plugIn` \u5de5\u5177\u7c7b\n-\n-\n-\u64cd\u4f5c\u5219\u5728 `src/js/conf/home/pages/dag/_source/dag.js` => `toolbarEvent` \u4e8b\u4ef6\u4e2d\u5904\u7406\u3002\n-\n-\n-##### 3.\u589e\u52a0\u4e00\u4e2a\u8def\u7531\u9875\u9762\n-\n-(1) \u9996\u5148\u5728\u8def\u7531\u7ba1\u7406\u589e\u52a0\u4e00\u4e2a\u8def\u7531\u5730\u5740`src/js/conf/home/router/index.js`\n-```\n-{\n-  path: '/test',  // \u8def\u7531\u5730\u5740 \n-  name: 'test',  // \u522b\u540d\n-  component: resolve => require(['../pages/test/index'], resolve),  // \u8def\u7531\u5bf9\u5e94\u7ec4\u4ef6\u5165\u53e3\u6587\u4ef6\n-  meta: {\n-    title: `${i18n.$t('test')} - EasyScheduler`  // title \u663e\u793a\n-  }\n-},\n-```\n-\n-(2) \u5728`src/js/conf/home/pages` \u5efa\u4e00\u4e2a `test` \u6587\u4ef6\u5939\uff0c\u5728\u6587\u4ef6\u5939\u91cc\u5efa\u4e00\u4e2a`index.vue`\u5165\u53e3\u6587\u4ef6\u3002\n-\n-    \u8fd9\u6837\u5c31\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee `http://localhost:8888/#/test`\n-\n-\n-##### 4.\u589e\u52a0\u9884\u7f6e\u90ae\u7bb1\n-\n-\u627e\u5230`src/lib/localData/email.js`\u542f\u52a8\u548c\u5b9a\u65f6\u90ae\u7bb1\u5730\u5740\u8f93\u5165\u53ef\u4ee5\u81ea\u52a8\u4e0b\u62c9\u5339\u914d\u3002\n-```\n-export default [\"test@analysys.com.cn\",\"test1@analysys.com.cn\",\"test3@analysys.com.cn\"]\n-```\n-\n-##### 5.\u6743\u9650\u7ba1\u7406\u53cadisabled\u72b6\u6001\u5904\u7406\n-\n-\u6743\u9650\u6839\u636e\u540e\u7aef\u63a5\u53e3`getUserInfo`\u63a5\u53e3\u7ed9\u51fa`userType: \"ADMIN_USER/GENERAL_USER\"`\u6743\u9650\u63a7\u5236\u9875\u9762\u64cd\u4f5c\u6309\u94ae\u662f\u5426`disabled`\n-\n-\u5177\u4f53\u64cd\u4f5c\uff1a`src/js/module/permissions/index.js`\n-\n-disabled\u5904\u7406\uff1a`src/js/module/mixin/disabledState.js`\n-",
                "changes": 644
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%89%8D%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%89%8D%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u524d\u7aef\u90e8\u7f72\u6587\u6863.md",
                "deletions": 101,
                "sha": "dc9cf612167e10c13d76b0d4c9a42d123fec347b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%89%8D%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md",
                "patch": "@@ -1,101 +0,0 @@\n-# \u524d\u7aef\u90e8\u7f72\u6587\u6863\n-\n-\u524d\u7aef\u67093\u79cd\u90e8\u7f72\u65b9\u5f0f\uff0c\u5206\u522b\u4e3a\u81ea\u52a8\u5316\u90e8\u7f72\uff0c\u624b\u52a8\u90e8\u7f72\u548c\u7f16\u8bd1\u6e90\u7801\u90e8\u7f72\n-\n-## 1\u3001\u51c6\u5907\u5de5\u4f5c\n-#### \u4e0b\u8f7d\u5b89\u88c5\u5305\n-\n-\u8bf7\u4e0b\u8f7d\u6700\u65b0\u7248\u672c\u7684\u5b89\u88c5\u5305\uff0c\u4e0b\u8f7d\u5730\u5740\uff1a [\u7801\u4e91\u4e0b\u8f7d](https://gitee.com/easyscheduler/EasyScheduler/attach_files/) \u6216\u8005 [github\u4e0b\u8f7d](https://github.com/analysys/EasyScheduler/releases)\n-\n-\u4e0b\u8f7d escheduler-ui-x.x.x.tar.gz \u540e\uff0c\u89e3\u538b`tar -zxvf escheduler-ui-x.x.x.tar.gz ./`\u540e\uff0c\u8fdb\u5165`escheduler-ui`\u76ee\u5f55\n- \n-\n-\n-\n-## 2\u3001\u90e8\u7f72\n-\u4ee5\u4e0b\u4e24\u79cd\u65b9\u5f0f\u4efb\u9009\u5176\u4e00\u90e8\u7f72\u5373\u53ef\uff0c\u63a8\u8350\u81ea\u52a8\u5316\u90e8\u7f72\n-### 2.1 \u81ea\u52a8\u5316\u90e8\u7f72\n-\n-\u5728`escheduler-ui`\u76ee\u5f55\u4e0b\u7f16\u8f91\u5b89\u88c5\u6587\u4ef6`vi install-escheduler-ui.sh`\n-\n-\u66f4\u6539\u524d\u7aef\u8bbf\u95ee\u7aef\u53e3\u548c\u540e\u7aef\u4ee3\u7406\u63a5\u53e3\u5730\u5740\n-\n-```\n-# \u914d\u7f6e\u524d\u7aef\u8bbf\u95ee\u7aef\u53e3\n-esc_proxy=\"8888\"\n-\n-# \u914d\u7f6e\u4ee3\u7406\u540e\u7aef\u63a5\u53e3\n-esc_proxy_port=\"http://192.168.xx.xx:12345\"\n-```\n-\n->\u524d\u7aef\u81ea\u52a8\u90e8\u7f72\u57fa\u4e8elinux\u7cfb\u7edf`yum`\u64cd\u4f5c\uff0c\u90e8\u7f72\u4e4b\u524d\u8bf7\u5148\u5b89\u88c5\u66f4\u65b0`yum`\n-\n-\u5728\u8be5\u76ee\u5f55\u4e0b\u6267\u884c`./install-escheduler-ui.sh`\n-\n-\n-### 2.2 \u624b\u52a8\u90e8\u7f72\n-\n-\u5b89\u88c5epel\u6e90 `yum install epel-release -y`\n-\n-\u5b89\u88c5Nginx `yum install nginx -y`\n-\n-\n-> ####  nginx\u914d\u7f6e\u6587\u4ef6\u5730\u5740\n-```\n-/etc/nginx/conf.d/default.conf\n-```\n-> ####  \u914d\u7f6e\u4fe1\u606f(\u81ea\u884c\u4fee\u6539)\n-```\n-server {\n-    listen       8888;# \u8bbf\u95ee\u7aef\u53e3\n-    server_name  localhost;\n-    #charset koi8-r;\n-    #access_log  /var/log/nginx/host.access.log  main;\n-    location / {\n-        root   /xx/dist; # \u4e0a\u9762\u524d\u7aef\u89e3\u538b\u7684dist\u76ee\u5f55\u5730\u5740(\u81ea\u884c\u4fee\u6539)\n-        index  index.html index.html;\n-    }\n-    location /escheduler {\n-        proxy_pass http://192.168.xx.xx:12345; # \u63a5\u53e3\u5730\u5740(\u81ea\u884c\u4fee\u6539)\n-        proxy_set_header Host $host;\n-        proxy_set_header X-Real-IP $remote_addr;\n-        proxy_set_header x_real_ipP $remote_addr;\n-        proxy_set_header remote_addr $remote_addr;\n-        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n-        proxy_http_version 1.1;\n-        proxy_connect_timeout 4s;\n-        proxy_read_timeout 30s;\n-        proxy_send_timeout 12s;\n-        proxy_set_header Upgrade $http_upgrade;\n-        proxy_set_header Connection \"upgrade\";\n-    }\n-    #error_page  404              /404.html;\n-    # redirect server error pages to the static page /50x.html\n-    #\n-    error_page   500 502 503 504  /50x.html;\n-    location = /50x.html {\n-        root   /usr/share/nginx/html;\n-    }\n-}\n-```\n-> ####  \u91cd\u542fNginx\u670d\u52a1\n-```\n-systemctl restart nginx\n-```\n-\n-#### nginx\u547d\u4ee4\n-\n-- \u542f\u7528 `systemctl enable nginx`\n-\n-- \u91cd\u542f `systemctl restart nginx`\n-\n-- \u72b6\u6001 `systemctl status nginx`\n-\n-\n-## \u524d\u7aef\u5e38\u89c1\u95ee\u9898\n-####  1. \u4e0a\u4f20\u6587\u4ef6\u5927\u5c0f\u9650\u5236\n-\u7f16\u8f91\u914d\u7f6e\u6587\u4ef6 `vi /etc/nginx/nginx.conf`\n-```\n-# \u66f4\u6539\u4e0a\u4f20\u5927\u5c0f\n-client_max_body_size 1024m\n-```",
                "changes": 101
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%8D%87%E7%BA%A7%E6%96%87%E6%A1%A3.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%8D%87%E7%BA%A7%E6%96%87%E6%A1%A3.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u5347\u7ea7\u6587\u6863.md",
                "deletions": 38,
                "sha": "83166971fc2f2c59fae5ca67bffbe82a2d546042",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%8D%87%E7%BA%A7%E6%96%87%E6%A1%A3.md",
                "patch": "@@ -1,38 +0,0 @@\n-\n-# EasyScheduler\u5347\u7ea7\u6587\u6863\n-\n-## 1. \u5907\u4efd\u4e0a\u4e00\u7248\u672c\u6587\u4ef6\u548c\u6570\u636e\u5e93\n-\n-## 2. \u505c\u6b62escheduler\u6240\u6709\u670d\u52a1\n-\n- `sh ./script/stop-all.sh`\n-\n-## 3. \u4e0b\u8f7d\u65b0\u7248\u672c\u7684\u5b89\u88c5\u5305\n-\n-- [\u7801\u4e91\u4e0b\u8f7d](https://gitee.com/easyscheduler/EasyScheduler/attach_files), \u4e0b\u8f7d\u6700\u65b0\u7248\u672c\u7684\u524d\u540e\u7aef\u5b89\u88c5\u5305(\u540e\u7aef\u7b80\u79f0escheduler-backend\u3001\u524d\u7aef\u7b80\u79f0escheduler-ui)\n-- \u4ee5\u4e0b\u5347\u7ea7\u64cd\u4f5c\u90fd\u9700\u8981\u5728\u65b0\u7248\u672c\u7684\u76ee\u5f55\u8fdb\u884c\n-\n-## 4. \u6570\u636e\u5e93\u5347\u7ea7\n-- \u4fee\u6539conf/dao/data_source.properties\u4e2d\u7684\u4e0b\u5217\u5c5e\u6027\n-\n-```\n-    spring.datasource.url\n-    spring.datasource.username\n-    spring.datasource.password\n-```\n-\n-- \u6267\u884c\u6570\u636e\u5e93\u5347\u7ea7\u811a\u672c\n-\n-`sh ./script/upgrade-escheduler.sh`\n-\n-## 5. \u540e\u7aef\u670d\u52a1\u5347\u7ea7\n-\n-- \u4fee\u6539install.sh\u914d\u7f6e\u5185\u5bb9\uff0c\u6267\u884c\u5347\u7ea7\u811a\u672c\n-  \n-  `sh install.sh`\n-\n-## 6. \u524d\u7aef\u670d\u52a1\u5347\u7ea7\n-- \u8986\u76d6\u4e0a\u4e00\u7248\u672cdist\u76ee\u5f55\n-- \u91cd\u542fnginx\u670d\u52a1\n-  \n-    `systemctl restart nginx`\n\\ No newline at end of file",
                "changes": 38
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u540e\u7aef\u5f00\u53d1\u6587\u6863.md",
                "deletions": 48,
                "sha": "7d2d34a0a016ceec33a769045db7cc7fb28cdb8f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3.md",
                "patch": "@@ -1,48 +0,0 @@\n-# \u540e\u7aef\u5f00\u53d1\u6587\u6863\n-\n-## \u73af\u5883\u8981\u6c42\n-\n- * [Mysql](http://geek.analysys.cn/topic/124) (5.5+) :  \u5fc5\u88c5\n- * [JDK](https://www.oracle.com/technetwork/java/javase/downloads/index.html) (1.8+) :  \u5fc5\u88c5\n- * [ZooKeeper](https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper)(3.4.6+) \uff1a\u5fc5\u88c5 \n- * [Maven](http://maven.apache.org/download.cgi)(3.3+) \uff1a\u5fc5\u88c5 \n-\n-\u56e0EasyScheduler\u4e2descheduler-rpc\u6a21\u5757\u4f7f\u7528\u5230Grpc\uff0c\u9700\u8981\u7528\u5230Maven\u7f16\u8bd1\u751f\u6210\u6240\u9700\u8981\u7684\u7c7b\n-\u5bf9maven\u4e0d\u719f\u7684\u4f19\u4f34\u8bf7\u53c2\u8003: [maven in five minutes](http://maven.apache.org/guides/getting-started/maven-in-five-minutes.html)(3.3+)\n-\n-http://maven.apache.org/install.html\n-\n-## \u9879\u76ee\u7f16\u8bd1\n-\u5c06EasyScheduler\u6e90\u7801\u4e0b\u8f7d\u5bfc\u5165Idea\u5f00\u53d1\u5de5\u5177\u540e\uff0c\u9996\u5148\u8f6c\u4e3aMaven\u9879\u76ee(\u53f3\u952e\u70b9\u51fb\u540e\u9009\u62e9\"Add Framework Support\")\n-\n-* \u6267\u884c\u7f16\u8bd1\u547d\u4ee4\uff1a\n-\n-```\n- mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n-```\n-\n-* \u67e5\u770b\u76ee\u5f55\n-\n-\u6b63\u5e38\u7f16\u8bd1\u5b8c\u540e\uff0c\u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u751f\u6210 ./target/escheduler-{version}/\n-\n-```\n-    bin\n-    conf\n-    lib\n-    script\n-    sql\n-    install.sh\n-```\n-\n-- \u8bf4\u660e\n-\n-```\n-bin : \u57fa\u7840\u670d\u52a1\u542f\u52a8\u811a\u672c\n-conf : \u9879\u76ee\u914d\u7f6e\u6587\u4ef6\n-lib : \u9879\u76ee\u4f9d\u8d56jar\u5305\uff0c\u5305\u62ec\u5404\u4e2a\u6a21\u5757jar\u548c\u7b2c\u4e09\u65b9jar\n-script : \u96c6\u7fa4\u542f\u52a8\u3001\u505c\u6b62\u548c\u670d\u52a1\u76d1\u63a7\u542f\u505c\u811a\u672c\n-sql : \u9879\u76ee\u4f9d\u8d56sql\u6587\u4ef6\n-install.sh : \u4e00\u952e\u90e8\u7f72\u811a\u672c\n-```\n-\n-   ",
                "changes": 48
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%90%8E%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%90%8E%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u540e\u7aef\u90e8\u7f72\u6587\u6863.md",
                "deletions": 210,
                "sha": "bf217880a5c7e09303016242930a78bb7faabfba",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%90%8E%E7%AB%AF%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3.md",
                "patch": "@@ -1,210 +0,0 @@\n-# \u540e\u7aef\u90e8\u7f72\u6587\u6863\n-\n-\u540e\u7aef\u67092\u79cd\u90e8\u7f72\u65b9\u5f0f\uff0c\u5206\u522b\u4e3a\u81ea\u52a8\u5316\u90e8\u7f72\u548c\u7f16\u8bd1\u6e90\u7801\u90e8\u7f72\n-\n-## 1\u3001\u51c6\u5907\u5de5\u4f5c\n-\n-\u8bf7\u4e0b\u8f7d\u6700\u65b0\u7248\u672c\u7684\u5b89\u88c5\u5305\uff0c\u4e0b\u8f7d\u5730\u5740\uff1a [\u7801\u4e91\u4e0b\u8f7d](https://gitee.com/easyscheduler/EasyScheduler/attach_files/)\u6216\u8005[github\u4e0b\u8f7d](https://github.com/analysys/EasyScheduler/releases) \uff0c\u4e0b\u8f7descheduler-backend-x.x.x.tar.gz(\u540e\u7aef\u7b80\u79f0escheduler-backend),escheduler-ui-x.x.x.tar.gz(\u524d\u7aef\u7b80\u79f0escheduler-ui)\n-\n-#### \u51c6\u5907\u4e00: \u57fa\u7840\u8f6f\u4ef6\u5b89\u88c5(\u5fc5\u88c5\u9879\u8bf7\u81ea\u884c\u5b89\u88c5)\n-\n- * [Mysql](http://geek.analysys.cn/topic/124) (5.5+) :  \u5fc5\u88c5\n- * [JDK](https://www.oracle.com/technetwork/java/javase/downloads/index.html) (1.8+) :  \u5fc5\u88c5\n- * [ZooKeeper](https://www.jianshu.com/p/de90172ea680)(3.4.6+) \uff1a\u5fc5\u88c5 \n- * [Hadoop](https://blog.csdn.net/Evankaka/article/details/51612437)(2.6+) \uff1a\u9009\u88c5\uff0c \u5982\u679c\u9700\u8981\u4f7f\u7528\u5230\u8d44\u6e90\u4e0a\u4f20\u529f\u80fd\uff0cMapReduce\u4efb\u52a1\u63d0\u4ea4\u5219\u9700\u8981\u914d\u7f6eHadoop(\u4e0a\u4f20\u7684\u8d44\u6e90\u6587\u4ef6\u76ee\u524d\u4fdd\u5b58\u5728Hdfs\u4e0a)\n- * [Hive](https://staroon.pro/2017/12/09/HiveInstall/)(1.2.1) :  \u9009\u88c5\uff0chive\u4efb\u52a1\u63d0\u4ea4\u9700\u8981\u5b89\u88c5\n- * Spark(1.x,2.x) : \u9009\u88c5\uff0cSpark\u4efb\u52a1\u63d0\u4ea4\u9700\u8981\u5b89\u88c5\n- * PostgreSQL(8.2.15+) : \u9009\u88c5\uff0cPostgreSQL PostgreSQL\u5b58\u50a8\u8fc7\u7a0b\u9700\u8981\u5b89\u88c5\n- \n-```\n- \u6ce8\u610f\uff1aEasyScheduler\u672c\u8eab\u4e0d\u4f9d\u8d56Hadoop\u3001Hive\u3001Spark\u3001PostgreSQL,\u4ec5\u662f\u4f1a\u8c03\u7528\u4ed6\u4eec\u7684Client\uff0c\u7528\u4e8e\u5bf9\u5e94\u4efb\u52a1\u7684\u8fd0\u884c\u3002\n-```\n-\n-#### \u51c6\u5907\u4e8c: \u521b\u5efa\u90e8\u7f72\u7528\u6237\n-\n-- \u5728\u6240\u6709\u9700\u8981\u90e8\u7f72\u8c03\u5ea6\u7684\u673a\u5668\u4e0a\u521b\u5efa\u90e8\u7f72\u7528\u6237\uff0c\u56e0\u4e3aworker\u670d\u52a1\u662f\u4ee5 sudo -u {linux-user} \u65b9\u5f0f\u6765\u6267\u884c\u4f5c\u4e1a\uff0c\u6240\u4ee5\u90e8\u7f72\u7528\u6237\u9700\u8981\u6709 sudo \u6743\u9650\uff0c\u800c\u4e14\u662f\u514d\u5bc6\u7684\u3002\n-\n-```\u90e8\u7f72\u8d26\u53f7\n-vi /etc/sudoers\n-\n-# \u4f8b\u5982\u90e8\u7f72\u7528\u6237\u662fescheduler\u8d26\u53f7\n-escheduler  ALL=(ALL)       NOPASSWD: NOPASSWD: ALL\n-\n-# \u5e76\u4e14\u9700\u8981\u6ce8\u91ca\u6389 Default requiretty \u4e00\u884c\n-#Default requiretty\n-```\n-\n-#### \u51c6\u5907\u4e09: ssh\u514d\u5bc6\u914d\u7f6e\n- \u5728\u90e8\u7f72\u673a\u5668\u548c\u5176\u4ed6\u5b89\u88c5\u673a\u5668\u4e0a\u914d\u7f6essh\u514d\u5bc6\u767b\u5f55\uff0c\u5982\u679c\u8981\u5728\u90e8\u7f72\u673a\u4e0a\u5b89\u88c5\u8c03\u5ea6\uff0c\u9700\u8981\u914d\u7f6e\u672c\u673a\u514d\u5bc6\u767b\u5f55\u81ea\u5df1\n- \n-- [\u5c06 **\u4e3b\u673a\u5668** \u548c\u5404\u4e2a\u5176\u5b83\u673a\u5668SSH\u6253\u901a](http://geek.analysys.cn/topic/113)\n-\n-\n-#### \u51c6\u5907\u56db\uff1a\u6570\u636e\u5e93\u521d\u59cb\u5316\n-\n-* \u521b\u5efadatabase\u548c\u8d26\u53f7\n-    \n-    \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u521b\u5efadatabase\u548c\u8d26\u53f7\n-    \n-    ```sql \n-    CREATE DATABASE escheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;\n-    GRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}';\n-    GRANT ALL PRIVILEGES ON escheduler.* TO '{user}'@'localhost' IDENTIFIED BY '{password}';\n-    flush privileges;\n-    ```\n-\n-* \u521b\u5efa\u8868\u548c\u5bfc\u5165\u57fa\u7840\u6570\u636e\n-    \u4fee\u6539./conf/dao/data_source.properties\u4e2d\u7684\u4e0b\u5217\u5c5e\u6027\n-\n-    ```\n-        spring.datasource.url\n-        spring.datasource.username\n-        spring.datasource.password\n-    ```\n-    \u6267\u884c\u521b\u5efa\u8868\u548c\u5bfc\u5165\u57fa\u7840\u6570\u636e\u811a\u672c\n-    ```\n-    sh ./script/create-escheduler.sh\n-    ```\n-\n-#### \u51c6\u5907\u4e94: \u4fee\u6539\u90e8\u7f72\u76ee\u5f55\u6743\u9650\u53ca\u8fd0\u884c\u53c2\u6570\n-\n-    escheduler-backend\u76ee\u5f55\u4ecb\u7ecd\n-\n-```\n-bin : \u57fa\u7840\u670d\u52a1\u542f\u52a8\u811a\u672c\n-conf : \u9879\u76ee\u914d\u7f6e\u6587\u4ef6\n-lib : \u9879\u76ee\u4f9d\u8d56jar\u5305\uff0c\u5305\u62ec\u5404\u4e2a\u6a21\u5757jar\u548c\u7b2c\u4e09\u65b9jar\n-script : \u96c6\u7fa4\u542f\u52a8\u3001\u505c\u6b62\u548c\u670d\u52a1\u76d1\u63a7\u542f\u505c\u811a\u672c\n-sql : \u9879\u76ee\u4f9d\u8d56sql\u6587\u4ef6\n-install.sh : \u4e00\u952e\u90e8\u7f72\u811a\u672c\n-```\n-\n-- \u4fee\u6539\u6743\u9650(\u8bf7\u5c06'deployUser'\u5b57\u6bb5\u4fee\u6539\u4e3a\u5bf9\u5e94\u90e8\u7f72\u7528\u6237)\uff0c\u4f7f\u5f97\u90e8\u7f72\u7528\u6237\u5bf9escheduler-backend\u76ee\u5f55\u6709\u64cd\u4f5c\u6743\u9650\n-    \n-    `sudo chown -R deployUser:deployUser escheduler-backend`\n-\n-- \u4fee\u6539conf/env/\u76ee\u5f55\u4e0b\u7684 `.escheduler_env.sh` \u73af\u5883\u53d8\u91cf\n-\n-- \u4fee\u6539\u90e8\u7f72\u53c2\u6570(\u6839\u636e\u81ea\u5df1\u670d\u52a1\u5668\u53ca\u4e1a\u52a1\u60c5\u51b5):\n-\n- - \u4fee\u6539 **install.sh**\u4e2d\u7684\u5404\u53c2\u6570\uff0c\u66ff\u6362\u6210\u81ea\u8eab\u4e1a\u52a1\u6240\u9700\u7684\u503c\n-   - monitorServerState \u5f00\u5173\u53d8\u91cf,\u57281.0.3\u7248\u672c\u4e2d\u589e\u52a0\uff0c\u63a7\u5236\u662f\u5426\u542f\u52a8\u81ea\u542f\u52a8\u811a\u672c(\u76d1\u63a7master,worker\u72b6\u6001,\u5982\u679c\u6389\u7ebf\u4f1a\u81ea\u52a8\u542f\u52a8)\n-   \u9ed8\u8ba4\u503c\u4e3a\"false\"\u8868\u793a\u4e0d\u542f\u52a8\u81ea\u542f\u52a8\u811a\u672c,\u5982\u679c\u9700\u8981\u542f\u52a8\u6539\u4e3a\"true\"\n-\n-   - hdfsStartupSate \u5f00\u5173\u53d8\u91cf\uff0c\u63a7\u5236\u662f\u5426\u542f\u52a8hdfs\n-      \u9ed8\u8ba4\u503c\u4e3a\"false\"\u8868\u793a\u4e0d\u542f\u52a8hdfs\n-      \u5982\u679c\u9700\u8981\u542f\u52a8\u6539\u4e3a\"true\",\u542f\u52a8hdfs\u9700\u8981\u81ea\u884c\u521b\u5efahdfs\u6839\u8def\u5f84\uff0c\u4e5f\u5c31\u662finstall.sh\u4e2d\u7684 hdfsPath\n-\n- - \u5982\u679c\u4f7f\u7528hdfs\u76f8\u5173\u529f\u80fd\uff0c\u9700\u8981\u62f7\u8d1d**hdfs-site.xml**\u548c**core-site.xml**\u5230conf\u76ee\u5f55\u4e0b\n-\n-\n-## 2\u3001\u90e8\u7f72\n-\u63a8\u8350\u81ea\u52a8\u5316\u90e8\u7f72\uff0c\u6709\u7ecf\u9a8c\u7684\u5c0f\u4f19\u4f34\u4e5f\u53ef\u4ee5\u4f7f\u7528\u6e90\u7801\u90e8\u7f72\n-\n-### 2.1 \u81ea\u52a8\u90e8\u7f72\n-\n-- \u5b89\u88c5zookeeper\u5de5\u5177 \n-\n-   `pip install kazoo`\n-\n-- \u5207\u6362\u5230\u90e8\u7f72\u7528\u6237\uff0c\u4e00\u952e\u90e8\u7f72\n-\n-    `sh install.sh` \n-\n-- \u4f7f\u7528`jps`\u547d\u4ee4\u67e5\u770b\u670d\u52a1\u662f\u5426\u542f\u52a8(`jps`\u4e3a`java JDK`\u81ea\u5e26)\n-\n-```aidl\n-    MasterServer         ----- master\u670d\u52a1\n-    WorkerServer         ----- worker\u670d\u52a1\n-    LoggerServer         ----- logger\u670d\u52a1\n-    ApiApplicationServer ----- api\u670d\u52a1\n-    AlertServer          ----- alert\u670d\u52a1\n-```\n-\u5982\u679c\u4ee5\u4e0a\u670d\u52a1\u90fd\u6b63\u5e38\u542f\u52a8\uff0c\u8bf4\u660e\u81ea\u52a8\u90e8\u7f72\u6210\u529f\n-\n-\n-\u90e8\u7f72\u6210\u529f\u540e\uff0c\u53ef\u4ee5\u8fdb\u884c\u65e5\u5fd7\u67e5\u770b\uff0c\u65e5\u5fd7\u7edf\u4e00\u5b58\u653e\u4e8e\u6307\u5b9a\u6587\u4ef6\u5939\u5185\n-\n-```\u65e5\u5fd7\u8def\u5f84\n- logs/\n-    \u251c\u2500\u2500 escheduler-alert-server.log\n-    \u251c\u2500\u2500 escheduler-master-server.log\n-    |\u2014\u2014 escheduler-worker-server.log\n-    |\u2014\u2014 escheduler-api-server.log\n-    |\u2014\u2014 escheduler-logger-server.log\n-```\n-\n-### 2.2 \u7f16\u8bd1\u6e90\u7801\u6765\u90e8\u7f72\n-\n-\u5c06\u6e90\u7801\u5305release\u7248\u672c\u4e0b\u8f7d\u540e\uff0c\u89e3\u538b\u8fdb\u5165\u6839\u76ee\u5f55\n-\n-* \u6267\u884c\u7f16\u8bd1\u547d\u4ee4\uff1a\n-\n-```\n- mvn -U clean package assembly:assembly -Dmaven.test.skip=true\n-```\n-\n-* \u67e5\u770b\u76ee\u5f55\n-\n-\u6b63\u5e38\u7f16\u8bd1\u5b8c\u540e\uff0c\u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u751f\u6210 `./target/escheduler-{version}/`\n-\n-```\u67e5\u770b\u76ee\u5f55\n- ../\n-    \u251c\u2500\u2500 bin\n-    \u251c\u2500\u2500 conf\n-    |\u2014\u2014 install.sh\n-    |\u2014\u2014 lib\n-    |\u2014\u2014 logs\n-    |\u2014\u2014 script\n-    |\u2014\u2014 sql\n-```\n-\n-\n-### 2.3 \u7cfb\u7edf\u5e38\u7528\u542f\u505c\u670d\u52a1(\u670d\u52a1\u7528\u9014\u8bf7\u5177\u4f53\u53c2\u89c1\u300a\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u300b\u5c0f\u8282)\n-\n-* \u4e00\u952e\u505c\u6b62\u96c6\u7fa4\u6240\u6709\u670d\u52a1\n-   \n-   ` sh ./bin/stop-all.sh`\n-   \n-* \u4e00\u952e\u5f00\u542f\u96c6\u7fa4\u6240\u6709\u670d\u52a1\n-   \n-   ` sh ./bin/start-all.sh`\n-\n-* \u542f\u505cMaster\n-\n-```\u542f\u52a8master\n-sh ./bin/escheduler-daemon.sh start master-server\n-sh ./bin/escheduler-daemon.sh stop master-server\n-```\n-\n-* \u542f\u505cWorker\n-\n-```\n-sh ./bin/escheduler-daemon.sh start worker-server\n-sh ./bin/escheduler-daemon.sh stop worker-server\n-```\n-\n-* \u542f\u505cApi\n-\n-```\n-sh ./bin/escheduler-daemon.sh start api-server\n-sh ./bin/escheduler-daemon.sh stop api-server\n-```\n-* \u542f\u505cLogger\n-\n-```\n-sh ./bin/escheduler-daemon.sh start logger-server\n-sh ./bin/escheduler-daemon.sh stop logger-server\n-```\n-* \u542f\u505cAlert\n-\n-```\n-sh ./bin/escheduler-daemon.sh start alert-server\n-sh ./bin/escheduler-daemon.sh stop alert-server\n-```\n-\n-## 3\u3001\u6570\u636e\u5e93\u5347\u7ea7\n-\u6570\u636e\u5e93\u5347\u7ea7\u662f\u57281.0.2\u7248\u672c\u589e\u52a0\u7684\u529f\u80fd,\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5373\u53ef\u81ea\u52a8\u5347\u7ea7\u6570\u636e\u5e93\n-```\n-sh ./script/upgrade-escheduler.sh\n-```",
                "changes": 210
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u5feb\u901f\u4e0a\u624b.md",
                "deletions": 50,
                "sha": "966ef88e846c0ccbdc0b8c8f37274f2b4b703b63",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md",
                "patch": "@@ -1,50 +0,0 @@\n-# \u5feb\u901f\u4e0a\u624b\n-\n-* \u7ba1\u7406\u5458\u7528\u6237\u767b\u5f55\n-  >\u5730\u5740\uff1a192.168.xx.xx:8888 \u7528\u6237\u540d\u5bc6\u7801\uff1aadmin/escheduler123\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/login.jpg\" width=\"60%\" />\n- </p>\n-\n-* \u521b\u5efa\u961f\u5217\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/create-queue.png\" width=\"60%\" />\n- </p>\n-\n-  * \u521b\u5efa\u79df\u6237\n-   <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/addtenant.png\" width=\"60%\" />\n-  </p>\n-\n-  * \u521b\u5efa\u666e\u901a\u7528\u6237\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/useredit2.png\" width=\"60%\" />\n- </p>\n-\n-  * \u521b\u5efa\u544a\u8b66\u7ec4\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mail_edit.png\" width=\"60%\" />\n-  </p>\n-\n-  * \u4f7f\u7528\u666e\u901a\u7528\u6237\u767b\u5f55\n-  > \u70b9\u51fb\u53f3\u4e0a\u89d2\u7528\u6237\u540d\u201c\u9000\u51fa\u201d\uff0c\u91cd\u65b0\u4f7f\u7528\u666e\u901a\u7528\u6237\u767b\u5f55\u3002\n-\n-  * \u9879\u76ee\u7ba1\u7406->\u521b\u5efa\u9879\u76ee->\u70b9\u51fb\u9879\u76ee\u540d\u79f0\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/project.png\" width=\"60%\" />\n- </p>\n-\n-  * \u70b9\u51fb\u5de5\u4f5c\u6d41\u5b9a\u4e49->\u521b\u5efa\u5de5\u4f5c\u6d41\u5b9a\u4e49->\u4e0a\u7ebf\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag1.png\" width=\"60%\" />\n- </p>\n-\n-  * \u8fd0\u884c\u5de5\u4f5c\u6d41\u5b9a\u4e49->\u70b9\u51fb\u5de5\u4f5c\u6d41\u5b9e\u4f8b->\u70b9\u51fb\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u540d\u79f0->\u53cc\u51fb\u4efb\u52a1\u8282\u70b9->\u67e5\u770b\u4efb\u52a1\u6267\u884c\u65e5\u5fd7\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task-log.png\" width=\"60%\" />\n-</p>\n\\ No newline at end of file",
                "changes": 50
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md",
                "deletions": 675,
                "sha": "348cc2b36a8ae4e0bf22781464d20551f92dab90",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md",
                "patch": "@@ -1,675 +0,0 @@\n-# \u7cfb\u7edf\u4f7f\u7528\u624b\u518c\n-\n-\n-## \u5feb\u901f\u4e0a\u624b\n-\n-  > \u8bf7\u53c2\u7167[\u5feb\u901f\u4e0a\u624b](\u5feb\u901f\u4e0a\u624b.md)\n-\n-## \u64cd\u4f5c\u6307\u5357\n-\n-### \u521b\u5efa\u9879\u76ee\n-\n-  - \u70b9\u51fb\u201c\u9879\u76ee\u7ba1\u7406->\u521b\u5efa\u9879\u76ee\u201d\uff0c\u8f93\u5165\u9879\u76ee\u540d\u79f0\uff0c\u9879\u76ee\u63cf\u8ff0\uff0c\u70b9\u51fb\u201c\u63d0\u4ea4\u201d\uff0c\u521b\u5efa\u65b0\u7684\u9879\u76ee\u3002\n-  - \u70b9\u51fb\u9879\u76ee\u540d\u79f0\uff0c\u8fdb\u5165\u9879\u76ee\u9996\u9875\u3002\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/project.png\" width=\"60%\" />\n- </p>\n-\n-> \u9879\u76ee\u9996\u9875\u5176\u4e2d\u5305\u542b\u4efb\u52a1\u72b6\u6001\u7edf\u8ba1\uff0c\u6d41\u7a0b\u72b6\u6001\u7edf\u8ba1\u3001\u5de5\u4f5c\u6d41\u5b9a\u4e49\u7edf\u8ba1\n-\n- - \u4efb\u52a1\u72b6\u6001\u7edf\u8ba1\uff1a\u662f\u6307\u5728\u6307\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u7edf\u8ba1\u4efb\u52a1\u5b9e\u4f8b\u4e2d\u7684\u5f85\u8fd0\u884c\u3001\u5931\u8d25\u3001\u8fd0\u884c\u4e2d\u3001\u5b8c\u6210\u3001\u6210\u529f\u7684\u4e2a\u6570\n- - \u6d41\u7a0b\u72b6\u6001\u7edf\u8ba1\uff1a\u662f\u6307\u5728\u6307\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u7edf\u8ba1\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u4e2d\u7684\u5f85\u8fd0\u884c\u3001\u5931\u8d25\u3001\u8fd0\u884c\u4e2d\u3001\u5b8c\u6210\u3001\u6210\u529f\u7684\u4e2a\u6570\n- - \u5de5\u4f5c\u6d41\u5b9a\u4e49\u7edf\u8ba1\uff1a\u662f\u7edf\u8ba1\u8be5\u7528\u6237\u521b\u5efa\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\u53ca\u7ba1\u7406\u5458\u6388\u4e88\u8be5\u7528\u6237\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-\n-\n-### \u521b\u5efa\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-  - \u8fdb\u5165\u9879\u76ee\u9996\u9875\uff0c\u70b9\u51fb\u201c\u5de5\u4f5c\u6d41\u5b9a\u4e49\u201d\uff0c\u8fdb\u5165\u5de5\u4f5c\u6d41\u5b9a\u4e49\u5217\u8868\u9875\u3002\n-  - \u70b9\u51fb\u201c\u521b\u5efa\u5de5\u4f5c\u6d41\u201d,\u521b\u5efa\u65b0\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\u3002\n-  - \u62d6\u62fd\u201cSHELL\"\u8282\u70b9\u5230\u753b\u5e03\uff0c\u65b0\u589e\u4e00\u4e2aShell\u4efb\u52a1\u3002\n-  - \u586b\u5199\u201d\u8282\u70b9\u540d\u79f0\u201c\uff0c\u201d\u63cf\u8ff0\u201c\uff0c\u201d\u811a\u672c\u201c\u5b57\u6bb5\u3002\n-  - \u9009\u62e9\u201c\u4efb\u52a1\u4f18\u5148\u7ea7\u201d\uff0c\u7ea7\u522b\u9ad8\u7684\u4efb\u52a1\u5728\u6267\u884c\u961f\u5217\u4e2d\u4f1a\u4f18\u5148\u6267\u884c\uff0c\u76f8\u540c\u4f18\u5148\u7ea7\u7684\u4efb\u52a1\u6309\u7167\u5148\u8fdb\u5148\u51fa\u7684\u987a\u5e8f\u6267\u884c\u3002\n-  - \u8d85\u65f6\u544a\u8b66\uff0c \u586b\u5199\u201d\u8d85\u65f6\u65f6\u957f\u201c\uff0c\u5f53\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u8d85\u8fc7**\u8d85\u65f6\u65f6\u957f**\u53ef\u4ee5\u544a\u8b66\u5e76\u4e14\u8d85\u65f6\u5931\u8d25\u3002\n-  - \u586b\u5199\"\u81ea\u5b9a\u4e49\u53c2\u6570\",\u53c2\u8003[\u81ea\u5b9a\u4e49\u53c2\u6570](#\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570)\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag1.png\" width=\"60%\" />\n- </p>\n-\n-  - \u589e\u52a0\u8282\u70b9\u4e4b\u95f4\u6267\u884c\u7684\u5148\u540e\u987a\u5e8f\uff1a \u70b9\u51fb\u201d\u7ebf\u6761\u8fde\u63a5\u201c\uff1b\u5982\u56fe\u793a\uff0c\u4efb\u52a11\u548c\u4efb\u52a13\u5e76\u884c\u6267\u884c\uff0c\u5f53\u4efb\u52a11\u6267\u884c\u5b8c\uff0c\u4efb\u52a12\u30013\u4f1a\u540c\u65f6\u6267\u884c\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag2.png\" width=\"60%\" />\n- </p>\n-\n-  - \u5220\u9664\u4f9d\u8d56\u5173\u7cfb\uff1a \u70b9\u51fb\u7bad\u5934\u56fe\u6807\u201d\u62d6\u52a8\u8282\u70b9\u548c\u9009\u4e2d\u9879\u201c\uff0c\u9009\u4e2d\u8fde\u63a5\u7ebf\uff0c\u70b9\u51fb\u5220\u9664\u56fe\u6807\uff0c\u5220\u9664\u8282\u70b9\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag3.png\" width=\"60%\" />\n- </p>\n-\n-  - \u70b9\u51fb\u201d\u4fdd\u5b58\u201c\uff0c\u8f93\u5165\u5de5\u4f5c\u6d41\u5b9a\u4e49\u540d\u79f0\uff0c\u5de5\u4f5c\u6d41\u5b9a\u4e49\u63cf\u8ff0\uff0c\u8bbe\u7f6e\u5168\u5c40\u53c2\u6570,\u53c2\u8003[\u81ea\u5b9a\u4e49\u53c2\u6570](#\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570)\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag4.png\" width=\"60%\" />\n- </p>\n-\n-  - \u5176\u4ed6\u7c7b\u578b\u8282\u70b9\uff0c\u8bf7\u53c2\u8003 [\u4efb\u52a1\u8282\u70b9\u7c7b\u578b\u548c\u53c2\u6570\u8bbe\u7f6e](#\u4efb\u52a1\u8282\u70b9\u7c7b\u578b\u548c\u53c2\u6570\u8bbe\u7f6e)\n-\n-### \u6267\u884c\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-  - **\u672a\u4e0a\u7ebf\u72b6\u6001\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\u53ef\u4ee5\u7f16\u8f91\uff0c\u4f46\u662f\u4e0d\u53ef\u4ee5\u8fd0\u884c**\uff0c\u6240\u4ee5\u5148\u4e0a\u7ebf\u5de5\u4f5c\u6d41\n-  > \u70b9\u51fb\u5de5\u4f5c\u6d41\u5b9a\u4e49\uff0c\u8fd4\u56de\u5de5\u4f5c\u6d41\u5b9a\u4e49\u5217\u8868\uff0c\u70b9\u51fb\u201d\u4e0a\u7ebf\u201c\u56fe\u6807\uff0c\u4e0a\u7ebf\u5de5\u4f5c\u6d41\u5b9a\u4e49\u3002\n-\n-  > \u4e0b\u7ebf\u5de5\u4f5c\u6d41\u5b9a\u4e49\u7684\u65f6\u5019\uff0c\u8981\u5148\u5c06\u5b9a\u65f6\u7ba1\u7406\u4e2d\u7684\u5b9a\u65f6\u4efb\u52a1\u4e0b\u7ebf\uff0c\u8fd9\u6837\u624d\u80fd\u6210\u529f\u4e0b\u7ebf\u5de5\u4f5c\u6d41\u5b9a\u4e49  \n-\n-  - \u70b9\u51fb\u201d\u8fd0\u884c\u201c\uff0c\u6267\u884c\u5de5\u4f5c\u6d41\u3002\u8fd0\u884c\u53c2\u6570\u8bf4\u660e\uff1a\n-    * \u5931\u8d25\u7b56\u7565\uff1a**\u5f53\u67d0\u4e00\u4e2a\u4efb\u52a1\u8282\u70b9\u6267\u884c\u5931\u8d25\u65f6\uff0c\u5176\u4ed6\u5e76\u884c\u7684\u4efb\u52a1\u8282\u70b9\u9700\u8981\u6267\u884c\u7684\u7b56\u7565**\u3002\u201d\u7ee7\u7eed\u201c\u8868\u793a\uff1a\u5176\u4ed6\u4efb\u52a1\u8282\u70b9\u6b63\u5e38\u6267\u884c\uff0c\u201d\u7ed3\u675f\u201c\u8868\u793a\uff1a\u7ec8\u6b62\u6240\u6709\u6b63\u5728\u6267\u884c\u7684\u4efb\u52a1\uff0c\u5e76\u7ec8\u6b62\u6574\u4e2a\u6d41\u7a0b\u3002\n-    * \u901a\u77e5\u7b56\u7565\uff1a\u5f53\u6d41\u7a0b\u7ed3\u675f\uff0c\u6839\u636e\u6d41\u7a0b\u72b6\u6001\u53d1\u9001\u6d41\u7a0b\u6267\u884c\u4fe1\u606f\u901a\u77e5\u90ae\u4ef6\u3002\n-    * \u6d41\u7a0b\u4f18\u5148\u7ea7\uff1a\u6d41\u7a0b\u8fd0\u884c\u7684\u4f18\u5148\u7ea7\uff0c\u5206\u4e94\u4e2a\u7b49\u7ea7\uff1a\u6700\u9ad8\uff08HIGHEST\uff09\uff0c\u9ad8(HIGH),\u4e2d\uff08MEDIUM\uff09,\u4f4e\uff08LOW\uff09\uff0c\u6700\u4f4e\uff08LOWEST\uff09\u3002\u7ea7\u522b\u9ad8\u7684\u6d41\u7a0b\u5728\u6267\u884c\u961f\u5217\u4e2d\u4f1a\u4f18\u5148\u6267\u884c\uff0c\u76f8\u540c\u4f18\u5148\u7ea7\u7684\u6d41\u7a0b\u6309\u7167\u5148\u8fdb\u5148\u51fa\u7684\u987a\u5e8f\u6267\u884c\u3002\n-    * worker\u5206\u7ec4\uff1a \u8fd9\u4e2a\u6d41\u7a0b\u53ea\u80fd\u5728\u6307\u5b9a\u7684\u673a\u5668\u7ec4\u91cc\u6267\u884c\u3002\u9ed8\u8ba4\u662fDefault\uff0c\u53ef\u4ee5\u5728\u4efb\u4e00worker\u4e0a\u6267\u884c\u3002\n-    * \u901a\u77e5\u7ec4\uff1a \u5f53\u6d41\u7a0b\u7ed3\u675f\uff0c\u6216\u8005\u53d1\u751f\u5bb9\u9519\u65f6\uff0c\u4f1a\u53d1\u9001\u6d41\u7a0b\u4fe1\u606f\u90ae\u4ef6\u5230\u901a\u77e5\u7ec4\u91cc\u6240\u6709\u6210\u5458\u3002\n-    * \u6536\u4ef6\u4eba\uff1a\u8f93\u5165\u90ae\u7bb1\u540e\u6309\u56de\u8f66\u952e\u4fdd\u5b58\u3002\u5f53\u6d41\u7a0b\u7ed3\u675f\u3001\u53d1\u751f\u5bb9\u9519\u65f6\uff0c\u4f1a\u53d1\u9001\u544a\u8b66\u90ae\u4ef6\u5230\u6536\u4ef6\u4eba\u5217\u8868\u3002\n-    * \u6284\u9001\u4eba\uff1a\u8f93\u5165\u90ae\u7bb1\u540e\u6309\u56de\u8f66\u952e\u4fdd\u5b58\u3002\u5f53\u6d41\u7a0b\u7ed3\u675f\u3001\u53d1\u751f\u5bb9\u9519\u65f6\uff0c\u4f1a\u6284\u9001\u544a\u8b66\u90ae\u4ef6\u5230\u6284\u9001\u4eba\u5217\u8868\u3002\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/run-work.png\" width=\"60%\" />\n- </p>\n-\n-  * \u8865\u6570\uff1a \u6267\u884c\u6307\u5b9a\u65e5\u671f\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\uff0c\u53ef\u4ee5\u9009\u62e9\u8865\u6570\u65f6\u95f4\u8303\u56f4\uff08\u76ee\u524d\u53ea\u652f\u6301\u9488\u5bf9\u8fde\u7eed\u7684\u5929\u8fdb\u884c\u8865\u6570)\uff0c\u6bd4\u5982\u8981\u88655\u67081\u53f7\u52305\u670810\u53f7\u7684\u6570\u636e\uff0c\u5982\u56fe\u793a\uff1a \n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/complement.png\" width=\"60%\" />\n- </p>\n-\n-> \u8865\u6570\u6267\u884c\u6a21\u5f0f\u6709**\u4e32\u884c\u6267\u884c\u3001\u5e76\u884c\u6267\u884c**\uff0c\u4e32\u884c\u6a21\u5f0f\u4e0b\uff0c\u8865\u6570\u4f1a\u4ece5\u67081\u53f7\u52305\u670810\u53f7\u4f9d\u6b21\u6267\u884c\uff1b\u5e76\u884c\u6a21\u5f0f\u4e0b\uff0c\u4f1a\u540c\u65f6\u6267\u884c5\u67081\u53f7\u52305\u670810\u53f7\u7684\u4efb\u52a1\u3002\n-\n-### \u5b9a\u65f6\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-  - \u521b\u5efa\u5b9a\u65f6\uff1a\"\u5de5\u4f5c\u6d41\u5b9a\u4e49->\u5b9a\u65f6\u201d\n-  - \u9009\u62e9\u8d77\u6b62\u65f6\u95f4\uff0c\u5728\u8d77\u6b62\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u5b9a\u65f6\u6b63\u5e38\u5de5\u4f5c\uff0c\u8d85\u8fc7\u8303\u56f4\uff0c\u5c31\u4e0d\u4f1a\u518d\u7ee7\u7eed\u4ea7\u751f\u5b9a\u65f6\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u4e86\u3002\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/time-schedule.png\" width=\"60%\" />\n- </p>\n-\n-  - \u6dfb\u52a0\u4e00\u4e2a\u6bcf\u5929\u51cc\u66685\u70b9\u6267\u884c\u4e00\u6b21\u7684\u5b9a\u65f6\uff0c\u5982\u56fe\u793a\uff1a\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/time-schedule2.png\" width=\"60%\" />\n- </p>\n-\n-  - \u5b9a\u65f6\u4e0a\u7ebf\uff0c**\u65b0\u521b\u5efa\u7684\u5b9a\u65f6\u662f\u4e0b\u7ebf\u72b6\u6001\uff0c\u9700\u8981\u70b9\u51fb\u201c\u5b9a\u65f6\u7ba1\u7406->\u4e0a\u7ebf\u201d\uff0c\u5b9a\u65f6\u624d\u80fd\u6b63\u5e38\u5de5\u4f5c**\u3002\n-\n-### \u67e5\u770b\u5de5\u4f5c\u6d41\u5b9e\u4f8b\n-  > \u70b9\u51fb\u201c\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u201d\uff0c\u67e5\u770b\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u5217\u8868\u3002\n-\n-  > \u70b9\u51fb\u5de5\u4f5c\u6d41\u540d\u79f0\uff0c\u67e5\u770b\u4efb\u52a1\u6267\u884c\u72b6\u6001\u3002\n-\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/instance-detail.png\" width=\"60%\" />\n- </p>\n-\n-  > \u70b9\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u70b9\u51fb\u201c\u67e5\u770b\u65e5\u5fd7\u201d\uff0c\u67e5\u770b\u4efb\u52a1\u6267\u884c\u65e5\u5fd7\u3002\n-\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task-log.png\" width=\"60%\" />\n- </p>\n-\n- > \u70b9\u51fb\u4efb\u52a1\u5b9e\u4f8b\u8282\u70b9\uff0c\u70b9\u51fb**\u67e5\u770b\u5386\u53f2**\uff0c\u53ef\u4ee5\u67e5\u770b\u8be5\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u8fd0\u884c\u7684\u8be5\u4efb\u52a1\u5b9e\u4f8b\u5217\u8868\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task_history.png\" width=\"60%\" />\n-  </p>\n- \n-\n-  > \u5bf9\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u7684\u64cd\u4f5c\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/instance-list.png\" width=\"60%\" />\n-</p>\n-\n-  * \u7f16\u8f91\uff1a\u53ef\u4ee5\u5bf9\u5df2\u7ecf\u7ec8\u6b62\u7684\u6d41\u7a0b\u8fdb\u884c\u7f16\u8f91\uff0c\u7f16\u8f91\u540e\u4fdd\u5b58\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u9009\u62e9\u662f\u5426\u66f4\u65b0\u5230\u5de5\u4f5c\u6d41\u5b9a\u4e49\u3002\n-  * \u91cd\u8dd1\uff1a\u53ef\u4ee5\u5bf9\u5df2\u7ecf\u7ec8\u6b62\u7684\u6d41\u7a0b\u8fdb\u884c\u91cd\u65b0\u6267\u884c\u3002\n-  * \u6062\u590d\u5931\u8d25\uff1a\u9488\u5bf9\u5931\u8d25\u7684\u6d41\u7a0b\uff0c\u53ef\u4ee5\u6267\u884c\u6062\u590d\u5931\u8d25\u64cd\u4f5c\uff0c\u4ece\u5931\u8d25\u7684\u8282\u70b9\u5f00\u59cb\u6267\u884c\u3002\n-  * \u505c\u6b62\uff1a\u5bf9\u6b63\u5728\u8fd0\u884c\u7684\u6d41\u7a0b\u8fdb\u884c**\u505c\u6b62**\u64cd\u4f5c\uff0c\u540e\u53f0\u4f1a\u5148\u5bf9worker\u8fdb\u7a0b`kill`,\u518d\u6267\u884c`kill -9`\u64cd\u4f5c\n-  * \u6682\u505c\uff1a\u53ef\u4ee5\u5bf9\u6b63\u5728\u8fd0\u884c\u7684\u6d41\u7a0b\u8fdb\u884c**\u6682\u505c**\u64cd\u4f5c\uff0c\u7cfb\u7edf\u72b6\u6001\u53d8\u4e3a**\u7b49\u5f85\u6267\u884c**\uff0c\u4f1a\u7b49\u5f85\u6b63\u5728\u6267\u884c\u7684\u4efb\u52a1\u7ed3\u675f\uff0c\u6682\u505c\u4e0b\u4e00\u4e2a\u8981\u6267\u884c\u7684\u4efb\u52a1\u3002\n-  * \u6062\u590d\u6682\u505c\uff1a\u53ef\u4ee5\u5bf9\u6682\u505c\u7684\u6d41\u7a0b\u6062\u590d\uff0c\u76f4\u63a5\u4ece**\u6682\u505c\u7684\u8282\u70b9**\u5f00\u59cb\u8fd0\u884c\n-  * \u5220\u9664\uff1a\u5220\u9664\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u53ca\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u4e0b\u7684\u4efb\u52a1\u5b9e\u4f8b\n-  * \u7518\u7279\u56fe\uff1aGantt\u56fe\u7eb5\u8f74\u662f\u67d0\u4e2a\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u4e0b\u7684\u4efb\u52a1\u5b9e\u4f8b\u7684\u62d3\u6251\u6392\u5e8f\uff0c\u6a2a\u8f74\u662f\u4efb\u52a1\u5b9e\u4f8b\u7684\u8fd0\u884c\u65f6\u95f4,\u5982\u56fe\u793a\uff1a\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/gant-pic.png\" width=\"60%\" />\n-</p>\n-\n-### \u67e5\u770b\u4efb\u52a1\u5b9e\u4f8b\n-  > \u70b9\u51fb\u201c\u4efb\u52a1\u5b9e\u4f8b\u201d\uff0c\u8fdb\u5165\u4efb\u52a1\u5217\u8868\u9875\uff0c\u67e5\u8be2\u4efb\u52a1\u6267\u884c\u60c5\u51b5\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task-list.png\" width=\"60%\" />\n-</p>\n-\n-  > \u70b9\u51fb\u64cd\u4f5c\u5217\u4e2d\u7684\u201c\u67e5\u770b\u65e5\u5fd7\u201d\uff0c\u53ef\u4ee5\u67e5\u770b\u4efb\u52a1\u6267\u884c\u7684\u65e5\u5fd7\u60c5\u51b5\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task-log2.png\" width=\"60%\" />\n-</p>\n-\n-### \u521b\u5efa\u6570\u636e\u6e90\n-  > \u6570\u636e\u6e90\u4e2d\u5fc3\u652f\u6301MySQL\u3001POSTGRESQL\u3001HIVE\u53caSpark\u7b49\u6570\u636e\u6e90\n-\n-#### \u521b\u5efa\u3001\u7f16\u8f91MySQL\u6570\u636e\u6e90\n-\n-  - \u70b9\u51fb\u201c\u6570\u636e\u6e90\u4e2d\u5fc3->\u521b\u5efa\u6570\u636e\u6e90\u201d\uff0c\u6839\u636e\u9700\u6c42\u521b\u5efa\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u6e90\u3002\n-\n-  - \u6570\u636e\u6e90\uff1a\u9009\u62e9MYSQL\n-  - \u6570\u636e\u6e90\u540d\u79f0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u540d\u79f0\n-  - \u63cf\u8ff0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u63cf\u8ff0\n-  - IP/\u4e3b\u673a\u540d\uff1a\u8f93\u5165\u8fde\u63a5MySQL\u7684IP\n-  - \u7aef\u53e3\uff1a\u8f93\u5165\u8fde\u63a5MySQL\u7684\u7aef\u53e3\n-  - \u7528\u6237\u540d\uff1a\u8bbe\u7f6e\u8fde\u63a5MySQL\u7684\u7528\u6237\u540d\n-  - \u5bc6\u7801\uff1a\u8bbe\u7f6e\u8fde\u63a5MySQL\u7684\u5bc6\u7801\n-  - \u6570\u636e\u5e93\u540d\uff1a\u8f93\u5165\u8fde\u63a5MySQL\u7684\u6570\u636e\u5e93\u540d\u79f0\n-  - Jdbc\u8fde\u63a5\u53c2\u6570\uff1a\u7528\u4e8eMySQL\u8fde\u63a5\u7684\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5JSON\u5f62\u5f0f\u586b\u5199\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mysql_edit.png\" width=\"60%\" />\n- </p>\n-\n-  > \u70b9\u51fb\u201c\u6d4b\u8bd5\u8fde\u63a5\u201d\uff0c\u6d4b\u8bd5\u6570\u636e\u6e90\u662f\u5426\u53ef\u4ee5\u8fde\u63a5\u6210\u529f\u3002\n-\n-#### \u521b\u5efa\u3001\u7f16\u8f91POSTGRESQL\u6570\u636e\u6e90\n-\n-- \u6570\u636e\u6e90\uff1a\u9009\u62e9POSTGRESQL\n-- \u6570\u636e\u6e90\u540d\u79f0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u540d\u79f0\n-- \u63cf\u8ff0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u63cf\u8ff0\n-- IP/\u4e3b\u673a\u540d\uff1a\u8f93\u5165\u8fde\u63a5POSTGRESQL\u7684IP\n-- \u7aef\u53e3\uff1a\u8f93\u5165\u8fde\u63a5POSTGRESQL\u7684\u7aef\u53e3\n-- \u7528\u6237\u540d\uff1a\u8bbe\u7f6e\u8fde\u63a5POSTGRESQL\u7684\u7528\u6237\u540d\n-- \u5bc6\u7801\uff1a\u8bbe\u7f6e\u8fde\u63a5POSTGRESQL\u7684\u5bc6\u7801\n-- \u6570\u636e\u5e93\u540d\uff1a\u8f93\u5165\u8fde\u63a5POSTGRESQL\u7684\u6570\u636e\u5e93\u540d\u79f0\n-- Jdbc\u8fde\u63a5\u53c2\u6570\uff1a\u7528\u4e8ePOSTGRESQL\u8fde\u63a5\u7684\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5JSON\u5f62\u5f0f\u586b\u5199\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/postgresql_edit.png\" width=\"60%\" />\n- </p>\n-\n-#### \u521b\u5efa\u3001\u7f16\u8f91HIVE\u6570\u636e\u6e90\n-\n-1.\u4f7f\u7528HiveServer2\u65b9\u5f0f\u8fde\u63a5\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/hive_edit.png\" width=\"60%\" />\n-  </p>\n-\n-  - \u6570\u636e\u6e90\uff1a\u9009\u62e9HIVE\n-  - \u6570\u636e\u6e90\u540d\u79f0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u540d\u79f0\n-  - \u63cf\u8ff0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u63cf\u8ff0\n-  - IP/\u4e3b\u673a\u540d\uff1a\u8f93\u5165\u8fde\u63a5HIVE\u7684IP\n-  - \u7aef\u53e3\uff1a\u8f93\u5165\u8fde\u63a5HIVE\u7684\u7aef\u53e3\n-  - \u7528\u6237\u540d\uff1a\u8bbe\u7f6e\u8fde\u63a5HIVE\u7684\u7528\u6237\u540d\n-  - \u5bc6\u7801\uff1a\u8bbe\u7f6e\u8fde\u63a5HIVE\u7684\u5bc6\u7801\n-  - \u6570\u636e\u5e93\u540d\uff1a\u8f93\u5165\u8fde\u63a5HIVE\u7684\u6570\u636e\u5e93\u540d\u79f0\n-  - Jdbc\u8fde\u63a5\u53c2\u6570\uff1a\u7528\u4e8eHIVE\u8fde\u63a5\u7684\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5JSON\u5f62\u5f0f\u586b\u5199\n-\n-2.\u4f7f\u7528HiveServer2 HA Zookeeper\u65b9\u5f0f\u8fde\u63a5\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/hive_edit2.png\" width=\"60%\" />\n-  </p>\n-\n-\n-\u6ce8\u610f\uff1a\u5982\u679c\u5f00\u542f\u4e86**kerberos**\uff0c\u5219\u9700\u8981\u586b\u5199 **Principal**\n-<p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/hive_kerberos.png\" width=\"60%\" />\n-  </p>\n-\n-\n-\n-\n-#### \u521b\u5efa\u3001\u7f16\u8f91Spark\u6570\u636e\u6e90\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/spark_datesource.png\" width=\"60%\" />\n- </p>\n-\n-- \u6570\u636e\u6e90\uff1a\u9009\u62e9Spark\n-- \u6570\u636e\u6e90\u540d\u79f0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u540d\u79f0\n-- \u63cf\u8ff0\uff1a\u8f93\u5165\u6570\u636e\u6e90\u7684\u63cf\u8ff0\n-- IP/\u4e3b\u673a\u540d\uff1a\u8f93\u5165\u8fde\u63a5Spark\u7684IP\n-- \u7aef\u53e3\uff1a\u8f93\u5165\u8fde\u63a5Spark\u7684\u7aef\u53e3\n-- \u7528\u6237\u540d\uff1a\u8bbe\u7f6e\u8fde\u63a5Spark\u7684\u7528\u6237\u540d\n-- \u5bc6\u7801\uff1a\u8bbe\u7f6e\u8fde\u63a5Spark\u7684\u5bc6\u7801\n-- \u6570\u636e\u5e93\u540d\uff1a\u8f93\u5165\u8fde\u63a5Spark\u7684\u6570\u636e\u5e93\u540d\u79f0\n-- Jdbc\u8fde\u63a5\u53c2\u6570\uff1a\u7528\u4e8eSpark\u8fde\u63a5\u7684\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5JSON\u5f62\u5f0f\u586b\u5199\n-\n-\n-\n-\u6ce8\u610f\uff1a\u5982\u679c\u5f00\u542f\u4e86**kerberos**\uff0c\u5219\u9700\u8981\u586b\u5199 **Principal**\n-\n-<p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/sparksql_kerberos.png\" width=\"60%\" />\n-  </p>\n-\n-### \u4e0a\u4f20\u8d44\u6e90\n-  - \u4e0a\u4f20\u8d44\u6e90\u6587\u4ef6\u548cudf\u51fd\u6570\uff0c\u6240\u6709\u4e0a\u4f20\u7684\u6587\u4ef6\u548c\u8d44\u6e90\u90fd\u4f1a\u88ab\u5b58\u50a8\u5230hdfs\u4e0a\uff0c\u6240\u4ee5\u9700\u8981\u4ee5\u4e0b\u914d\u7f6e\u9879\uff1a\n-\n-```\n-conf/common/common.properties\n-    -- hdfs.startup.state=true\n-conf/common/hadoop.properties  \n-    -- fs.defaultFS=hdfs://xxxx:8020  \n-    -- yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx\n-    -- yarn.application.status.address=http://xxxx:8088/ws/v1/cluster/apps/%s\n-```\n-\n-#### \u6587\u4ef6\u7ba1\u7406\n-\n-  > \u662f\u5bf9\u5404\u79cd\u8d44\u6e90\u6587\u4ef6\u7684\u7ba1\u7406\uff0c\u5305\u62ec\u521b\u5efa\u57fa\u672c\u7684txt/log/sh/conf\u7b49\u6587\u4ef6\u3001\u4e0a\u4f20jar\u5305\u7b49\u5404\u79cd\u7c7b\u578b\u6587\u4ef6\uff0c\u4ee5\u53ca\u7f16\u8f91\u3001\u4e0b\u8f7d\u3001\u5220\u9664\u7b49\u64cd\u4f5c\u3002\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/file-manage.png\" width=\"60%\" />\n- </p>\n-\n-  * \u521b\u5efa\u6587\u4ef6\n- > \u6587\u4ef6\u683c\u5f0f\u652f\u6301\u4ee5\u4e0b\u51e0\u79cd\u7c7b\u578b\uff1atxt\u3001log\u3001sh\u3001conf\u3001cfg\u3001py\u3001java\u3001sql\u3001xml\u3001hql\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/file_create.png\" width=\"60%\" />\n- </p>\n-\n-  * \u4e0a\u4f20\u6587\u4ef6\n-\n-> \u4e0a\u4f20\u6587\u4ef6\uff1a\u70b9\u51fb\u4e0a\u4f20\u6309\u94ae\u8fdb\u884c\u4e0a\u4f20\uff0c\u5c06\u6587\u4ef6\u62d6\u62fd\u5230\u4e0a\u4f20\u533a\u57df\uff0c\u6587\u4ef6\u540d\u4f1a\u81ea\u52a8\u4ee5\u4e0a\u4f20\u7684\u6587\u4ef6\u540d\u79f0\u8865\u5168\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/file_upload.png\" width=\"60%\" />\n- </p>\n-\n-\n-  * \u6587\u4ef6\u67e5\u770b\n-\n-> \u5bf9\u53ef\u67e5\u770b\u7684\u6587\u4ef6\u7c7b\u578b\uff0c\u70b9\u51fb \u6587\u4ef6\u540d\u79f0 \u53ef\u4ee5\u67e5\u770b\u6587\u4ef6\u8be6\u60c5\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/file_detail.png\" width=\"60%\" />\n- </p>\n-\n-  * \u4e0b\u8f7d\u6587\u4ef6\n-\n-> \u53ef\u4ee5\u5728 \u6587\u4ef6\u8be6\u60c5 \u4e2d\u70b9\u51fb\u53f3\u4e0a\u89d2\u4e0b\u8f7d\u6309\u94ae\u4e0b\u8f7d\u6587\u4ef6\uff0c\u6216\u8005\u5728\u6587\u4ef6\u5217\u8868\u540e\u7684\u4e0b\u8f7d\u6309\u94ae\u4e0b\u8f7d\u6587\u4ef6\n-\n-  * \u6587\u4ef6\u91cd\u547d\u540d\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/file_rename.png\" width=\"60%\" />\n- </p>\n-\n-#### \u5220\u9664\n->  \u6587\u4ef6\u5217\u8868->\u70b9\u51fb\"\u5220\u9664\"\u6309\u94ae\uff0c\u5220\u9664\u6307\u5b9a\u6587\u4ef6\n-\n-#### \u8d44\u6e90\u7ba1\u7406\n-  > \u8d44\u6e90\u7ba1\u7406\u548c\u6587\u4ef6\u7ba1\u7406\u529f\u80fd\u7c7b\u4f3c\uff0c\u4e0d\u540c\u4e4b\u5904\u662f\u8d44\u6e90\u7ba1\u7406\u662f\u4e0a\u4f20\u7684UDF\u51fd\u6570\uff0c\u6587\u4ef6\u7ba1\u7406\u4e0a\u4f20\u7684\u662f\u7528\u6237\u7a0b\u5e8f\uff0c\u811a\u672c\u53ca\u914d\u7f6e\u6587\u4ef6\n-\n-  * \u4e0a\u4f20udf\u8d44\u6e90\n-  > \u548c\u4e0a\u4f20\u6587\u4ef6\u76f8\u540c\u3002\n-\n-#### \u51fd\u6570\u7ba1\u7406\n-\n-  * \u521b\u5efaudf\u51fd\u6570\n-  > \u70b9\u51fb\u201c\u521b\u5efaUDF\u51fd\u6570\u201d\uff0c\u8f93\u5165udf\u51fd\u6570\u53c2\u6570\uff0c\u9009\u62e9udf\u8d44\u6e90\uff0c\u70b9\u51fb\u201c\u63d0\u4ea4\u201d\uff0c\u521b\u5efaudf\u51fd\u6570\u3002\n-\n- > \u76ee\u524d\u53ea\u652f\u6301HIVE\u7684\u4e34\u65f6UDF\u51fd\u6570\n-\n-  - UDF\u51fd\u6570\u540d\u79f0\uff1a\u8f93\u5165UDF\u51fd\u6570\u65f6\u7684\u540d\u79f0\n-  - \u5305\u540d\u7c7b\u540d\uff1a\u8f93\u5165UDF\u51fd\u6570\u7684\u5168\u8def\u5f84\n-  - \u53c2\u6570\uff1a\u7528\u6765\u6807\u6ce8\u51fd\u6570\u7684\u8f93\u5165\u53c2\u6570\n-  - \u6570\u636e\u5e93\u540d\uff1a\u9884\u7559\u5b57\u6bb5\uff0c\u7528\u4e8e\u521b\u5efa\u6c38\u4e45UDF\u51fd\u6570\n-  - UDF\u8d44\u6e90\uff1a\u8bbe\u7f6e\u521b\u5efa\u7684UDF\u5bf9\u5e94\u7684\u8d44\u6e90\u6587\u4ef6\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/udf_edit.png\" width=\"60%\" />\n- </p>\n-\n-## \u5b89\u5168\u4e2d\u5fc3\uff08\u6743\u9650\u7cfb\u7edf\uff09\n-\n-  - \u5b89\u5168\u4e2d\u5fc3\u662f\u53ea\u6709\u7ba1\u7406\u5458\u8d26\u6237\u624d\u6709\u6743\u9650\u7684\u529f\u80fd\uff0c\u6709\u961f\u5217\u7ba1\u7406\u3001\u79df\u6237\u7ba1\u7406\u3001\u7528\u6237\u7ba1\u7406\u3001\u544a\u8b66\u7ec4\u7ba1\u7406\u3001worker\u5206\u7ec4\u3001\u4ee4\u724c\u7ba1\u7406\u7b49\u529f\u80fd\uff0c\u8fd8\u53ef\u4ee5\u5bf9\u8d44\u6e90\u3001\u6570\u636e\u6e90\u3001\u9879\u76ee\u7b49\u6388\u6743\n-  - \u7ba1\u7406\u5458\u767b\u5f55\uff0c\u9ed8\u8ba4\u7528\u6237\u540d\u5bc6\u7801\uff1aadmin/escheduler123\n-\n-### \u521b\u5efa\u961f\u5217\n-  - \u961f\u5217\u662f\u5728\u6267\u884cspark\u3001mapreduce\u7b49\u7a0b\u5e8f\uff0c\u9700\u8981\u7528\u5230\u201c\u961f\u5217\u201d\u53c2\u6570\u65f6\u4f7f\u7528\u7684\u3002\n-  - \u201c\u5b89\u5168\u4e2d\u5fc3\u201d->\u201c\u961f\u5217\u7ba1\u7406\u201d->\u201c\u521b\u5efa\u961f\u5217\u201d\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/create-queue.png\" width=\"60%\" />\n-  </p>\n-\n-\n-### \u6dfb\u52a0\u79df\u6237\n-  - \u79df\u6237\u5bf9\u5e94\u7684\u662fLinux\u7684\u7528\u6237\uff0c\u7528\u4e8eworker\u63d0\u4ea4\u4f5c\u4e1a\u6240\u4f7f\u7528\u7684\u7528\u6237\u3002\u5982\u679clinux\u6ca1\u6709\u8fd9\u4e2a\u7528\u6237\uff0cworker\u4f1a\u5728\u6267\u884c\u811a\u672c\u7684\u65f6\u5019\u521b\u5efa\u8fd9\u4e2a\u7528\u6237\u3002\n-  - \u79df\u6237\u7f16\u7801\uff1a**\u79df\u6237\u7f16\u7801\u662fLinux\u4e0a\u7684\u7528\u6237\uff0c\u552f\u4e00\uff0c\u4e0d\u80fd\u91cd\u590d**\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/addtenant.png\" width=\"60%\" />\n-  </p>\n-\n-### \u521b\u5efa\u666e\u901a\u7528\u6237\n-  -  \u7528\u6237\u5206\u4e3a**\u7ba1\u7406\u5458\u7528\u6237**\u548c**\u666e\u901a\u7528\u6237**\n-    * \u7ba1\u7406\u5458\u6709**\u6388\u6743\u548c\u7528\u6237\u7ba1\u7406**\u7b49\u6743\u9650\uff0c\u6ca1\u6709**\u521b\u5efa\u9879\u76ee\u548c\u5de5\u4f5c\u6d41\u5b9a\u4e49**\u7684\u64cd\u4f5c\u7684\u6743\u9650\n-    * \u666e\u901a\u7528\u6237\u53ef\u4ee5**\u521b\u5efa\u9879\u76ee\u548c\u5bf9\u5de5\u4f5c\u6d41\u5b9a\u4e49\u7684\u521b\u5efa\uff0c\u7f16\u8f91\uff0c\u6267\u884c**\u7b49\u64cd\u4f5c\u3002\n-    * \u6ce8\u610f\uff1a**\u5982\u679c\u8be5\u7528\u6237\u5207\u6362\u4e86\u79df\u6237\uff0c\u5219\u8be5\u7528\u6237\u6240\u5728\u79df\u6237\u4e0b\u6240\u6709\u8d44\u6e90\u5c06\u590d\u5236\u5230\u5207\u6362\u7684\u65b0\u79df\u6237\u4e0b**\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/useredit2.png\" width=\"60%\" />\n- </p>\n-\n-### \u521b\u5efa\u544a\u8b66\u7ec4\n-  * \u544a\u8b66\u7ec4\u662f\u5728\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684\u53c2\u6570\uff0c\u5728\u6d41\u7a0b\u7ed3\u675f\u4ee5\u540e\u4f1a\u5c06\u6d41\u7a0b\u7684\u72b6\u6001\u548c\u5176\u4ed6\u4fe1\u606f\u4ee5\u90ae\u4ef6\u5f62\u5f0f\u53d1\u9001\u7ed9\u544a\u8b66\u7ec4\u3002\n-  - \u65b0\u5efa\u3001\u7f16\u8f91\u544a\u8b66\u7ec4\n-\n-  <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mail_edit.png\" width=\"60%\" />\n-  </p>\n-\n-### \u521b\u5efaworker\u5206\u7ec4\n-  - worker\u5206\u7ec4\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba9\u4efb\u52a1\u5728\u6307\u5b9a\u7684worker\u4e0a\u8fd0\u884c\u7684\u673a\u5236\u3002\u7ba1\u7406\u5458\u521b\u5efaworker\u5206\u7ec4\uff0c\u5728\u4efb\u52a1\u8282\u70b9\u548c\u8fd0\u884c\u53c2\u6570\u4e2d\u8bbe\u7f6e\u4e2d\u53ef\u4ee5\u6307\u5b9a\u8be5\u4efb\u52a1\u8fd0\u884c\u7684worker\u5206\u7ec4\uff0c\u5982\u679c\u6307\u5b9a\u7684\u5206\u7ec4\u88ab\u5220\u9664\u6216\u8005\u6ca1\u6709\u6307\u5b9a\u5206\u7ec4\uff0c\u5219\u8be5\u4efb\u52a1\u4f1a\u5728\u4efb\u4e00worker\u4e0a\u8fd0\u884c\u3002\n-  - worker\u5206\u7ec4\u5185\u591a\u4e2aip\u5730\u5740\uff08**\u4e0d\u80fd\u5199\u522b\u540d**\uff09\uff0c\u4ee5**\u82f1\u6587\u9017\u53f7**\u5206\u9694\n-\n-  <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/worker1.png\" width=\"60%\" />\n-  </p>\n-\n-### \u4ee4\u724c\u7ba1\u7406\n-  - \u7531\u4e8e\u540e\u7aef\u63a5\u53e3\u6709\u767b\u5f55\u68c0\u67e5\uff0c\u4ee4\u724c\u7ba1\u7406\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u63a5\u53e3\u7684\u65b9\u5f0f\u5bf9\u7cfb\u7edf\u8fdb\u884c\u5404\u79cd\u64cd\u4f5c\u3002\n-  - \u8c03\u7528\u793a\u4f8b\uff1a\n-\n-```\u4ee4\u724c\u8c03\u7528\u793a\u4f8b\n-    /**\n-     * test token\n-     */\n-    public  void doPOSTParam()throws Exception{\n-        // create HttpClient\n-        CloseableHttpClient httpclient = HttpClients.createDefault();\n-\n-        // create http post request\n-        HttpPost httpPost = new HttpPost(\"http://127.0.0.1:12345/escheduler/projects/create\");\n-        httpPost.setHeader(\"token\", \"123\");\n-        // set parameters\n-        List<NameValuePair> parameters = new ArrayList<NameValuePair>();\n-        parameters.add(new BasicNameValuePair(\"projectName\", \"qzw\"));\n-        parameters.add(new BasicNameValuePair(\"desc\", \"qzw\"));\n-        UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(parameters);\n-        httpPost.setEntity(formEntity);\n-        CloseableHttpResponse response = null;\n-        try {\n-            // execute\n-            response = httpclient.execute(httpPost);\n-            // response status code 200\n-            if (response.getStatusLine().getStatusCode() == 200) {\n-                String content = EntityUtils.toString(response.getEntity(), \"UTF-8\");\n-                System.out.println(content);\n-            }\n-        } finally {\n-            if (response != null) {\n-                response.close();\n-            }\n-            httpclient.close();\n-        }\n-    }\n-```\n-\n-### \u6388\u4e88\u6743\u9650\n-  - \u6388\u4e88\u6743\u9650\u5305\u62ec\u9879\u76ee\u6743\u9650\uff0c\u8d44\u6e90\u6743\u9650\uff0c\u6570\u636e\u6e90\u6743\u9650\uff0cUDF\u51fd\u6570\u6743\u9650\u3002\n-> \u7ba1\u7406\u5458\u53ef\u4ee5\u5bf9\u666e\u901a\u7528\u6237\u8fdb\u884c\u975e\u5176\u521b\u5efa\u7684\u9879\u76ee\u3001\u8d44\u6e90\u3001\u6570\u636e\u6e90\u548cUDF\u51fd\u6570\u8fdb\u884c\u6388\u6743\u3002\u56e0\u4e3a\u9879\u76ee\u3001\u8d44\u6e90\u3001\u6570\u636e\u6e90\u548cUDF\u51fd\u6570\u6388\u6743\u65b9\u5f0f\u90fd\u662f\u4e00\u6837\u7684\uff0c\u6240\u4ee5\u4ee5\u9879\u76ee\u6388\u6743\u4e3a\u4f8b\u4ecb\u7ecd\u3002\n-\n-> \u6ce8\u610f\uff1a**\u5bf9\u4e8e\u7528\u6237\u81ea\u5df1\u521b\u5efa\u7684\u9879\u76ee\uff0c\u8be5\u7528\u6237\u62e5\u6709\u6240\u6709\u7684\u6743\u9650\u3002\u5219\u9879\u76ee\u5217\u8868\u548c\u5df2\u9009\u9879\u76ee\u5217\u8868\u4e2d\u4e0d\u4f1a\u4f53\u73b0**\n-\n-  - 1.\u70b9\u51fb\u6307\u5b9a\u4eba\u7684\u6388\u6743\u6309\u94ae\uff0c\u5982\u4e0b\u56fe\uff1a\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/auth_user.png\" width=\"60%\" />\n- </p>\n-\n-- 2.\u9009\u4e2d\u9879\u76ee\u6309\u94ae\uff0c\u8fdb\u884c\u9879\u76ee\u6388\u6743\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/auth_project.png\" width=\"60%\" />\n- </p>\n-\n-\n-## \u76d1\u63a7\u4e2d\u5fc3\n-\n-### \u670d\u52a1\u7ba1\u7406\n-  - \u670d\u52a1\u7ba1\u7406\u4e3b\u8981\u662f\u5bf9\u7cfb\u7edf\u4e2d\u7684\u5404\u4e2a\u670d\u52a1\u7684\u5065\u5eb7\u72b6\u51b5\u548c\u57fa\u672c\u4fe1\u606f\u7684\u76d1\u63a7\u548c\u663e\u793a\n-\n-#### master\u76d1\u63a7\n-  - \u4e3b\u8981\u662fmaster\u7684\u76f8\u5173\u4fe1\u606f\u3002\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/master-jk.png\" width=\"60%\" />\n- </p>\n-\n-#### worker\u76d1\u63a7\n-  - \u4e3b\u8981\u662fworker\u7684\u76f8\u5173\u4fe1\u606f\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/worker-jk.png\" width=\"60%\" />\n- </p>\n-\n-#### Zookeeper\u76d1\u63a7\n-  - \u4e3b\u8981\u662fzookpeeper\u4e2d\u5404\u4e2aworker\u548cmaster\u7684\u76f8\u5173\u914d\u7f6e\u4fe1\u606f\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/zk-jk.png\" width=\"60%\" />\n- </p>\n-\n-#### Mysql\u76d1\u63a7\n-  - \u4e3b\u8981\u662fmysql\u7684\u5065\u5eb7\u72b6\u51b5\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mysql-jk.png\" width=\"60%\" />\n- </p>\n-\n-## \u4efb\u52a1\u8282\u70b9\u7c7b\u578b\u548c\u53c2\u6570\u8bbe\u7f6e\n-\n-### Shell\u8282\u70b9\n-  - shell\u8282\u70b9\uff0c\u5728worker\u6267\u884c\u7684\u65f6\u5019\uff0c\u4f1a\u751f\u6210\u4e00\u4e2a\u4e34\u65f6shell\u811a\u672c\uff0c\u4f7f\u7528\u79df\u6237\u540c\u540d\u7684linux\u7528\u6237\u6267\u884c\u8fd9\u4e2a\u811a\u672c\u3002\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_SHELL.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/shell_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u8282\u70b9\u540d\u79f0\uff1a\u4e00\u4e2a\u5de5\u4f5c\u6d41\u5b9a\u4e49\u4e2d\u7684\u8282\u70b9\u540d\u79f0\u662f\u552f\u4e00\u7684\n-- \u8fd0\u884c\u6807\u5fd7\uff1a\u6807\u8bc6\u8fd9\u4e2a\u8282\u70b9\u662f\u5426\u80fd\u6b63\u5e38\u8c03\u5ea6,\u5982\u679c\u4e0d\u9700\u8981\u6267\u884c\uff0c\u53ef\u4ee5\u6253\u5f00\u7981\u6b62\u6267\u884c\u5f00\u5173\u3002\n-- \u63cf\u8ff0\u4fe1\u606f\uff1a\u63cf\u8ff0\u8be5\u8282\u70b9\u7684\u529f\u80fd\n-- \u5931\u8d25\u91cd\u8bd5\u6b21\u6570\uff1a\u4efb\u52a1\u5931\u8d25\u91cd\u65b0\u63d0\u4ea4\u7684\u6b21\u6570\uff0c\u652f\u6301\u4e0b\u62c9\u548c\u624b\u586b\n-- \u5931\u8d25\u91cd\u8bd5\u95f4\u9694\uff1a\u4efb\u52a1\u5931\u8d25\u91cd\u65b0\u63d0\u4ea4\u4efb\u52a1\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u652f\u6301\u4e0b\u62c9\u548c\u624b\u586b\n-- \u811a\u672c\uff1a\u7528\u6237\u5f00\u53d1\u7684SHELL\u7a0b\u5e8f\n-- \u8d44\u6e90\uff1a\u662f\u6307\u811a\u672c\u4e2d\u9700\u8981\u8c03\u7528\u7684\u8d44\u6e90\u6587\u4ef6\u5217\u8868\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u662fSHELL\u5c40\u90e8\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\uff0c\u4f1a\u66ff\u6362\u811a\u672c\u4e2d\u4ee5${\u53d8\u91cf}\u7684\u5185\u5bb9\n-\n-### \u5b50\u6d41\u7a0b\u8282\u70b9\n-  - \u5b50\u6d41\u7a0b\u8282\u70b9\uff0c\u5c31\u662f\u628a\u5916\u90e8\u7684\u67d0\u4e2a\u5de5\u4f5c\u6d41\u5b9a\u4e49\u5f53\u505a\u4e00\u4e2a\u4efb\u52a1\u8282\u70b9\u53bb\u6267\u884c\u3002\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_SUB_PROCESS.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/subprocess_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u8282\u70b9\u540d\u79f0\uff1a\u4e00\u4e2a\u5de5\u4f5c\u6d41\u5b9a\u4e49\u4e2d\u7684\u8282\u70b9\u540d\u79f0\u662f\u552f\u4e00\u7684\n-- \u8fd0\u884c\u6807\u5fd7\uff1a\u6807\u8bc6\u8fd9\u4e2a\u8282\u70b9\u662f\u5426\u80fd\u6b63\u5e38\u8c03\u5ea6\n-- \u63cf\u8ff0\u4fe1\u606f\uff1a\u63cf\u8ff0\u8be5\u8282\u70b9\u7684\u529f\u80fd\n-- \u5b50\u8282\u70b9\uff1a\u662f\u9009\u62e9\u5b50\u6d41\u7a0b\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\uff0c\u53f3\u4e0a\u89d2\u8fdb\u5165\u8be5\u5b50\u8282\u70b9\u53ef\u4ee5\u8df3\u8f6c\u5230\u6240\u9009\u5b50\u6d41\u7a0b\u7684\u5de5\u4f5c\u6d41\u5b9a\u4e49\n-\n-### \u4f9d\u8d56(DEPENDENT)\u8282\u70b9\n-  - \u4f9d\u8d56\u8282\u70b9\uff0c\u5c31\u662f**\u4f9d\u8d56\u68c0\u67e5\u8282\u70b9**\u3002\u6bd4\u5982A\u6d41\u7a0b\u4f9d\u8d56\u6628\u5929\u7684B\u6d41\u7a0b\u6267\u884c\u6210\u529f\uff0c\u4f9d\u8d56\u8282\u70b9\u4f1a\u53bb\u68c0\u67e5B\u6d41\u7a0b\u5728\u6628\u5929\u662f\u5426\u6709\u6267\u884c\u6210\u529f\u7684\u5b9e\u4f8b\u3002\n-\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_DEPENDENT.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dependent_edit.png\" width=\"60%\" />\n- </p>\n-\n-  > \u4f9d\u8d56\u8282\u70b9\u63d0\u4f9b\u4e86\u903b\u8f91\u5224\u65ad\u529f\u80fd\uff0c\u6bd4\u5982\u68c0\u67e5\u6628\u5929\u7684B\u6d41\u7a0b\u662f\u5426\u6210\u529f\uff0c\u6216\u8005C\u6d41\u7a0b\u662f\u5426\u6267\u884c\u6210\u529f\u3002\n-\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/depend-node.png\" width=\"80%\" />\n- </p>\n-\n-  > \u4f8b\u5982\uff0cA\u6d41\u7a0b\u4e3a\u5468\u62a5\u4efb\u52a1\uff0cB\u3001C\u6d41\u7a0b\u4e3a\u5929\u4efb\u52a1\uff0cA\u4efb\u52a1\u9700\u8981B\u3001C\u4efb\u52a1\u5728\u4e0a\u5468\u7684\u6bcf\u4e00\u5929\u90fd\u6267\u884c\u6210\u529f\uff0c\u5982\u56fe\u793a\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/depend-node2.png\" width=\"80%\" />\n- </p>\n-\n-  > \u5047\u5982\uff0c\u5468\u62a5A\u540c\u65f6\u8fd8\u9700\u8981\u81ea\u8eab\u5728\u4e0a\u5468\u4e8c\u6267\u884c\u6210\u529f\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/depend-node3.png\" width=\"80%\" />\n- </p>\n-\n-### \u5b58\u50a8\u8fc7\u7a0b\u8282\u70b9\n-  - \u6839\u636e\u9009\u62e9\u7684\u6570\u636e\u6e90\uff0c\u6267\u884c\u5b58\u50a8\u8fc7\u7a0b\u3002\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_PROCEDURE.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/procedure_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u6570\u636e\u6e90\uff1a\u5b58\u50a8\u8fc7\u7a0b\u7684\u6570\u636e\u6e90\u7c7b\u578b\u652f\u6301MySQL\u548cPOSTGRESQL\u4e24\u79cd\uff0c\u9009\u62e9\u5bf9\u5e94\u7684\u6570\u636e\u6e90\n-- \u65b9\u6cd5\uff1a\u662f\u5b58\u50a8\u8fc7\u7a0b\u7684\u65b9\u6cd5\u540d\u79f0\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u5b58\u50a8\u8fc7\u7a0b\u7684\u81ea\u5b9a\u4e49\u53c2\u6570\u7c7b\u578b\u652f\u6301IN\u3001OUT\u4e24\u79cd\uff0c\u6570\u636e\u7c7b\u578b\u652f\u6301VARCHAR\u3001INTEGER\u3001LONG\u3001FLOAT\u3001DOUBLE\u3001DATE\u3001TIME\u3001TIMESTAMP\u3001BOOLEAN\u4e5d\u79cd\u6570\u636e\u7c7b\u578b\n-\n-### SQL\u8282\u70b9\n-  - \u6267\u884c\u975e\u67e5\u8be2SQL\u529f\u80fd\n-  <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/sql-node.png\" width=\"60%\" />\n- </p>\n-\n-  - \u6267\u884c\u67e5\u8be2SQL\u529f\u80fd\uff0c\u53ef\u4ee5\u9009\u62e9\u901a\u8fc7\u8868\u683c\u548c\u9644\u4ef6\u5f62\u5f0f\u53d1\u9001\u90ae\u4ef6\u5230\u6307\u5b9a\u7684\u6536\u4ef6\u4eba\u3002\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_SQL.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/sql-node2.png\" width=\"60%\" />\n- </p>\n-\n-- \u6570\u636e\u6e90\uff1a\u9009\u62e9\u5bf9\u5e94\u7684\u6570\u636e\u6e90\n-- sql\u7c7b\u578b\uff1a\u652f\u6301\u67e5\u8be2\u548c\u975e\u67e5\u8be2\u4e24\u79cd\uff0c\u67e5\u8be2\u662fselect\u7c7b\u578b\u7684\u67e5\u8be2\uff0c\u662f\u6709\u7ed3\u679c\u96c6\u8fd4\u56de\u7684\uff0c\u53ef\u4ee5\u6307\u5b9a\u90ae\u4ef6\u901a\u77e5\u4e3a\u8868\u683c\u3001\u9644\u4ef6\u6216\u8868\u683c\u9644\u4ef6\u4e09\u79cd\u6a21\u677f\u3002\u975e\u67e5\u8be2\u662f\u6ca1\u6709\u7ed3\u679c\u96c6\u8fd4\u56de\u7684\uff0c\u662f\u9488\u5bf9update\u3001delete\u3001insert\u4e09\u79cd\u7c7b\u578b\u7684\u64cd\u4f5c\n-- sql\u53c2\u6570\uff1a\u8f93\u5165\u53c2\u6570\u683c\u5f0f\u4e3akey1=value1;key2=value2\u2026\n-- sql\u8bed\u53e5\uff1aSQL\u8bed\u53e5\n-- UDF\u51fd\u6570\uff1a\u5bf9\u4e8eHIVE\u7c7b\u578b\u7684\u6570\u636e\u6e90\uff0c\u53ef\u4ee5\u5f15\u7528\u8d44\u6e90\u4e2d\u5fc3\u4e2d\u521b\u5efa\u7684UDF\u51fd\u6570,\u5176\u4ed6\u7c7b\u578b\u7684\u6570\u636e\u6e90\u6682\u4e0d\u652f\u6301UDF\u51fd\u6570\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1aSQL\u4efb\u52a1\u7c7b\u578b\uff0c\u800c\u5b58\u50a8\u8fc7\u7a0b\u662f\u81ea\u5b9a\u4e49\u53c2\u6570\u987a\u5e8f\u7684\u7ed9\u65b9\u6cd5\u8bbe\u7f6e\u503c\u81ea\u5b9a\u4e49\u53c2\u6570\u7c7b\u578b\u548c\u6570\u636e\u7c7b\u578b\u540c\u5b58\u50a8\u8fc7\u7a0b\u4efb\u52a1\u7c7b\u578b\u4e00\u6837\u3002\u533a\u522b\u5728\u4e8eSQL\u4efb\u52a1\u7c7b\u578b\u81ea\u5b9a\u4e49\u53c2\u6570\u4f1a\u66ff\u6362sql\u8bed\u53e5\u4e2d${\u53d8\u91cf}\n-\n-### SPARK\u8282\u70b9\n-  - \u901a\u8fc7SPARK\u8282\u70b9\uff0c\u53ef\u4ee5\u76f4\u63a5\u76f4\u63a5\u6267\u884cSPARK\u7a0b\u5e8f\uff0c\u5bf9\u4e8espark\u8282\u70b9\uff0cworker\u4f1a\u4f7f\u7528`spark-submit`\u65b9\u5f0f\u63d0\u4ea4\u4efb\u52a1\n-\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_SPARK.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/spark_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u7a0b\u5e8f\u7c7b\u578b\uff1a\u652f\u6301JAVA\u3001Scala\u548cPython\u4e09\u79cd\u8bed\u8a00\n-- \u4e3b\u51fd\u6570\u7684class\uff1a\u662fSpark\u7a0b\u5e8f\u7684\u5165\u53e3Main Class\u7684\u5168\u8def\u5f84\n-- \u4e3bjar\u5305\uff1a\u662fSpark\u7684jar\u5305\n-- \u90e8\u7f72\u65b9\u5f0f\uff1a\u652f\u6301yarn-cluster\u3001yarn-client\u3001\u548clocal\u4e09\u79cd\u6a21\u5f0f\n-- Driver\u5185\u6838\u6570\uff1a\u53ef\u4ee5\u8bbe\u7f6eDriver\u5185\u6838\u6570\u53ca\u5185\u5b58\u6570\n-- Executor\u6570\u91cf\uff1a\u53ef\u4ee5\u8bbe\u7f6eExecutor\u6570\u91cf\u3001Executor\u5185\u5b58\u6570\u548cExecutor\u5185\u6838\u6570\n-- \u547d\u4ee4\u884c\u53c2\u6570\uff1a\u662f\u8bbe\u7f6eSpark\u7a0b\u5e8f\u7684\u8f93\u5165\u53c2\u6570\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u53c2\u6570\u53d8\u91cf\u7684\u66ff\u6362\u3002\n-- \u5176\u4ed6\u53c2\u6570\uff1a\u652f\u6301 --jars\u3001--files\u3001--archives\u3001--conf\u683c\u5f0f\n-- \u8d44\u6e90\uff1a\u5982\u679c\u5176\u4ed6\u53c2\u6570\u4e2d\u5f15\u7528\u4e86\u8d44\u6e90\u6587\u4ef6\uff0c\u9700\u8981\u5728\u8d44\u6e90\u4e2d\u9009\u62e9\u6307\u5b9a\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u662fMR\u5c40\u90e8\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\uff0c\u4f1a\u66ff\u6362\u811a\u672c\u4e2d\u4ee5${\u53d8\u91cf}\u7684\u5185\u5bb9\n-\n- \u6ce8\u610f\uff1aJAVA\u548cScala\u53ea\u662f\u7528\u6765\u6807\u8bc6\uff0c\u6ca1\u6709\u533a\u522b\uff0c\u5982\u679c\u662fPython\u5f00\u53d1\u7684Spark\u5219\u6ca1\u6709\u4e3b\u51fd\u6570\u7684class\uff0c\u5176\u4ed6\u90fd\u662f\u4e00\u6837\n-\n-### MapReduce(MR)\u8282\u70b9\n-  - \u4f7f\u7528MR\u8282\u70b9\uff0c\u53ef\u4ee5\u76f4\u63a5\u6267\u884cMR\u7a0b\u5e8f\u3002\u5bf9\u4e8emr\u8282\u70b9\uff0cworker\u4f1a\u4f7f\u7528`hadoop jar`\u65b9\u5f0f\u63d0\u4ea4\u4efb\u52a1\n-\n-\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_MR.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n- 1. JAVA\u7a0b\u5e8f\n-\n- <p align=\"center\">\n-    <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mr_java.png\" width=\"60%\" />\n-  </p>\n-\n-- \u4e3b\u51fd\u6570\u7684class\uff1a\u662fMR\u7a0b\u5e8f\u7684\u5165\u53e3Main Class\u7684\u5168\u8def\u5f84\n-- \u7a0b\u5e8f\u7c7b\u578b\uff1a\u9009\u62e9JAVA\u8bed\u8a00 \n-- \u4e3bjar\u5305\uff1a\u662fMR\u7684jar\u5305\n-- \u547d\u4ee4\u884c\u53c2\u6570\uff1a\u662f\u8bbe\u7f6eMR\u7a0b\u5e8f\u7684\u8f93\u5165\u53c2\u6570\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u53c2\u6570\u53d8\u91cf\u7684\u66ff\u6362\n-- \u5176\u4ed6\u53c2\u6570\uff1a\u652f\u6301 \u2013D\u3001-files\u3001-libjars\u3001-archives\u683c\u5f0f\n-- \u8d44\u6e90\uff1a \u5982\u679c\u5176\u4ed6\u53c2\u6570\u4e2d\u5f15\u7528\u4e86\u8d44\u6e90\u6587\u4ef6\uff0c\u9700\u8981\u5728\u8d44\u6e90\u4e2d\u9009\u62e9\u6307\u5b9a\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u662fMR\u5c40\u90e8\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\uff0c\u4f1a\u66ff\u6362\u811a\u672c\u4e2d\u4ee5${\u53d8\u91cf}\u7684\u5185\u5bb9\n-\n-2. Python\u7a0b\u5e8f\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/mr_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u7a0b\u5e8f\u7c7b\u578b\uff1a\u9009\u62e9Python\u8bed\u8a00 \n-- \u4e3bjar\u5305\uff1a\u662f\u8fd0\u884cMR\u7684Python jar\u5305\n-- \u5176\u4ed6\u53c2\u6570\uff1a\u652f\u6301 \u2013D\u3001-mapper\u3001-reducer\u3001-input  -output\u683c\u5f0f\uff0c\u8fd9\u91cc\u53ef\u4ee5\u8bbe\u7f6e\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\u7684\u8f93\u5165\uff0c\u6bd4\u5982\uff1a\n-- -mapper  \"mapper.py 1\"  -file mapper.py   -reducer reducer.py  -file reducer.py \u2013input /journey/words.txt -output /journey/out/mr/${currentTimeMillis}\n-- \u5176\u4e2d -mapper \u540e\u7684 mapper.py 1\u662f\u4e24\u4e2a\u53c2\u6570\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u662fmapper.py\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f1\n-- \u8d44\u6e90\uff1a \u5982\u679c\u5176\u4ed6\u53c2\u6570\u4e2d\u5f15\u7528\u4e86\u8d44\u6e90\u6587\u4ef6\uff0c\u9700\u8981\u5728\u8d44\u6e90\u4e2d\u9009\u62e9\u6307\u5b9a\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u662fMR\u5c40\u90e8\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\uff0c\u4f1a\u66ff\u6362\u811a\u672c\u4e2d\u4ee5${\u53d8\u91cf}\u7684\u5185\u5bb9\n-\n-### Python\u8282\u70b9\n-  - \u4f7f\u7528python\u8282\u70b9\uff0c\u53ef\u4ee5\u76f4\u63a5\u6267\u884cpython\u811a\u672c\uff0c\u5bf9\u4e8epython\u8282\u70b9\uff0cworker\u4f1a\u4f7f\u7528`python **`\u65b9\u5f0f\u63d0\u4ea4\u4efb\u52a1\u3002\n-\n-\n-> \u62d6\u52a8\u5de5\u5177\u680f\u4e2d\u7684![PNG](https://analysys.github.io/easyscheduler_docs_cn/images/toolbar_PYTHON.png)\u4efb\u52a1\u8282\u70b9\u5230\u753b\u677f\u4e2d\uff0c\u53cc\u51fb\u4efb\u52a1\u8282\u70b9\uff0c\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/python_edit.png\" width=\"60%\" />\n- </p>\n-\n-- \u811a\u672c\uff1a\u7528\u6237\u5f00\u53d1\u7684Python\u7a0b\u5e8f\n-- \u8d44\u6e90\uff1a\u662f\u6307\u811a\u672c\u4e2d\u9700\u8981\u8c03\u7528\u7684\u8d44\u6e90\u6587\u4ef6\u5217\u8868\n-- \u81ea\u5b9a\u4e49\u53c2\u6570\uff1a\u662fPython\u5c40\u90e8\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\uff0c\u4f1a\u66ff\u6362\u811a\u672c\u4e2d\u4ee5${\u53d8\u91cf}\u7684\u5185\u5bb9\n-\n-### \u7cfb\u7edf\u53c2\u6570\n-\n-<table>\n-    <tr><th>\u53d8\u91cf</th><th>\u542b\u4e49</th></tr>\n-    <tr>\n-        <td>${system.biz.date}</td>\n-        <td>\u65e5\u5e38\u8c03\u5ea6\u5b9e\u4f8b\u5b9a\u65f6\u7684\u5b9a\u65f6\u65f6\u95f4\u524d\u4e00\u5929\uff0c\u683c\u5f0f\u4e3a yyyyMMdd\uff0c\u8865\u6570\u636e\u65f6\uff0c\u8be5\u65e5\u671f +1</td>\n-    </tr>\n-    <tr>\n-        <td>${system.biz.curdate}</td>\n-        <td>\u65e5\u5e38\u8c03\u5ea6\u5b9e\u4f8b\u5b9a\u65f6\u7684\u5b9a\u65f6\u65f6\u95f4\uff0c\u683c\u5f0f\u4e3a yyyyMMdd\uff0c\u8865\u6570\u636e\u65f6\uff0c\u8be5\u65e5\u671f +1</td>\n-    </tr>\n-    <tr>\n-        <td>${system.datetime}</td>\n-        <td>\u65e5\u5e38\u8c03\u5ea6\u5b9e\u4f8b\u5b9a\u65f6\u7684\u5b9a\u65f6\u65f6\u95f4\uff0c\u683c\u5f0f\u4e3a yyyyMMddHHmmss\uff0c\u8865\u6570\u636e\u65f6\uff0c\u8be5\u65e5\u671f +1</td>\n-    </tr>\n-</table>\n-\n-\n-### \u65f6\u95f4\u81ea\u5b9a\u4e49\u53c2\u6570\n-\n-> \u652f\u6301\u4ee3\u7801\u4e2d\u81ea\u5b9a\u4e49\u53d8\u91cf\u540d\uff0c\u58f0\u660e\u65b9\u5f0f\uff1a${\u53d8\u91cf\u540d}\u3002\u53ef\u4ee5\u662f\u5f15\u7528 \"\u7cfb\u7edf\u53c2\u6570\" \u6216\u6307\u5b9a \"\u5e38\u91cf\"\u3002\n-\n-> \u6211\u4eec\u5b9a\u4e49\u8fd9\u79cd\u57fa\u51c6\u53d8\u91cf\u4e3a $[...] \u683c\u5f0f\u7684\uff0c$[yyyyMMddHHmmss] \u662f\u53ef\u4ee5\u4efb\u610f\u5206\u89e3\u7ec4\u5408\u7684\uff0c\u6bd4\u5982\uff1a$[yyyyMMdd], $[HHmmss], $[yyyy-MM-dd] \u7b49\n-\n-> \u4e5f\u53ef\u4ee5\u8fd9\u6837\uff1a\n-\n-- \u540e N \u5e74\uff1a$[add_months(yyyyMMdd,12*N)]\n-- \u524d N \u5e74\uff1a$[add_months(yyyyMMdd,-12*N)]\n-- \u540e N \u6708\uff1a$[add_months(yyyyMMdd,N)]\n-- \u524d N \u6708\uff1a$[add_months(yyyyMMdd,-N)]\n-- \u540e N \u5468\uff1a$[yyyyMMdd+7*N]\n-- \u524d N \u5468\uff1a$[yyyyMMdd-7*N]\n-- \u540e N \u5929\uff1a$[yyyyMMdd+N]\n-- \u524d N \u5929\uff1a$[yyyyMMdd-N]\n-- \u540e N \u5c0f\u65f6\uff1a$[HHmmss+N/24]\n-- \u524d N \u5c0f\u65f6\uff1a$[HHmmss-N/24]\n-- \u540e N \u5206\u949f\uff1a$[HHmmss+N/24/60]\n-- \u524d N \u5206\u949f\uff1a$[HHmmss-N/24/60]\n-\n-### \u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\n-\n-> \u7528\u6237\u81ea\u5b9a\u4e49\u53c2\u6570\u5206\u4e3a\u5168\u5c40\u53c2\u6570\u548c\u5c40\u90e8\u53c2\u6570\u3002\u5168\u5c40\u53c2\u6570\u662f\u4fdd\u5b58\u5de5\u4f5c\u6d41\u5b9a\u4e49\u548c\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u7684\u65f6\u5019\u4f20\u9012\u7684\u5168\u5c40\u53c2\u6570\uff0c\u5168\u5c40\u53c2\u6570\u53ef\u4ee5\u5728\u6574\u4e2a\u6d41\u7a0b\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u4efb\u52a1\u8282\u70b9\u7684\u5c40\u90e8\u53c2\u6570\u5f15\u7528\u3002\n-\n-> \u4f8b\u5982\uff1a\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/local_parameter.png\" width=\"60%\" />\n- </p>\n-\n-> global_bizdate\u4e3a\u5168\u5c40\u53c2\u6570\uff0c\u5f15\u7528\u7684\u662f\u7cfb\u7edf\u53c2\u6570\u3002\n-\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/global_parameter.png\" width=\"60%\" />\n- </p>\n-\n-> \u4efb\u52a1\u4e2dlocal_param_bizdate\u901a\u8fc7${global_bizdate}\u6765\u5f15\u7528\u5168\u5c40\u53c2\u6570\uff0c\u5bf9\u4e8e\u811a\u672c\u53ef\u4ee5\u901a\u8fc7${local_param_bizdate}\u6765\u5f15\u7528\u53d8\u91cflocal_param_bizdate\u7684\u503c\uff0c\u6216\u901a\u8fc7JDBC\u76f4\u63a5\u5c06local_param_bizdate\u7684\u503cset\u8fdb\u53bb",
                "changes": 675
            },
            {
                "status": "removed",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.md",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.md?ref=e2e340baf90d3ea424656b46010f2fa8744e79fa",
                "filename": "docs/zh_CN/\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1.md",
                "deletions": 304,
                "sha": "61e522b6cd3083ef01459d5ed46b825e38e2372d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e2e340baf90d3ea424656b46010f2fa8744e79fa/docs/zh_CN/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1.md",
                "patch": "@@ -1,304 +0,0 @@\n-## \u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\n-\u5728\u5bf9\u8c03\u5ea6\u7cfb\u7edf\u67b6\u6784\u8bf4\u660e\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u8ba4\u8bc6\u4e00\u4e0b\u8c03\u5ea6\u7cfb\u7edf\u5e38\u7528\u7684\u540d\u8bcd\n-\n-### 1.\u540d\u8bcd\u89e3\u91ca\n-**DAG\uff1a** \u5168\u79f0Directed Acyclic Graph\uff0c\u7b80\u79f0DAG\u3002\u5de5\u4f5c\u6d41\u4e2d\u7684Task\u4efb\u52a1\u4ee5\u6709\u5411\u65e0\u73af\u56fe\u7684\u5f62\u5f0f\u7ec4\u88c5\u8d77\u6765\uff0c\u4ece\u5165\u5ea6\u4e3a\u96f6\u7684\u8282\u70b9\u8fdb\u884c\u62d3\u6251\u904d\u5386\uff0c\u76f4\u5230\u65e0\u540e\u7ee7\u8282\u70b9\u4e3a\u6b62\u3002\u4e3e\u4f8b\u5982\u4e0b\u56fe\uff1a\n-\n-<p align=\"center\">\n-  <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/dag_examples_cn.jpg\" alt=\"dag\u793a\u4f8b\"  width=\"60%\" />\n-  <p align=\"center\">\n-        <em>dag\u793a\u4f8b</em>\n-  </p>\n-</p>\n-\n-**\u6d41\u7a0b\u5b9a\u4e49**\uff1a\u901a\u8fc7\u62d6\u62fd\u4efb\u52a1\u8282\u70b9\u5e76\u5efa\u7acb\u4efb\u52a1\u8282\u70b9\u7684\u5173\u8054\u6240\u5f62\u6210\u7684\u53ef\u89c6\u5316**DAG**\n-\n-**\u6d41\u7a0b\u5b9e\u4f8b**\uff1a\u6d41\u7a0b\u5b9e\u4f8b\u662f\u6d41\u7a0b\u5b9a\u4e49\u7684\u5b9e\u4f8b\u5316\uff0c\u53ef\u4ee5\u901a\u8fc7\u624b\u52a8\u542f\u52a8\u6216\u5b9a\u65f6\u8c03\u5ea6\u751f\u6210,\u6d41\u7a0b\u5b9a\u4e49\u6bcf\u8fd0\u884c\u4e00\u6b21\uff0c\u4ea7\u751f\u4e00\u4e2a\u6d41\u7a0b\u5b9e\u4f8b\n-\n-**\u4efb\u52a1\u5b9e\u4f8b**\uff1a\u4efb\u52a1\u5b9e\u4f8b\u662f\u6d41\u7a0b\u5b9a\u4e49\u4e2d\u4efb\u52a1\u8282\u70b9\u7684\u5b9e\u4f8b\u5316\uff0c\u6807\u8bc6\u7740\u5177\u4f53\u7684\u4efb\u52a1\u6267\u884c\u72b6\u6001\n-\n-**\u4efb\u52a1\u7c7b\u578b**\uff1a \u76ee\u524d\u652f\u6301\u6709SHELL\u3001SQL\u3001SUB_PROCESS(\u5b50\u6d41\u7a0b)\u3001PROCEDURE\u3001MR\u3001SPARK\u3001PYTHON\u3001DEPENDENT(\u4f9d\u8d56)\uff0c\u540c\u65f6\u8ba1\u5212\u652f\u6301\u52a8\u6001\u63d2\u4ef6\u6269\u5c55\uff0c\u6ce8\u610f\uff1a\u5176\u4e2d\u5b50 **SUB_PROCESS**  \u4e5f\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u6d41\u7a0b\u5b9a\u4e49\uff0c\u662f\u53ef\u4ee5\u5355\u72ec\u542f\u52a8\u6267\u884c\u7684\n-\n-**\u8c03\u5ea6\u65b9\u5f0f\uff1a** \u7cfb\u7edf\u652f\u6301\u57fa\u4e8ecron\u8868\u8fbe\u5f0f\u7684\u5b9a\u65f6\u8c03\u5ea6\u548c\u624b\u52a8\u8c03\u5ea6\u3002\u547d\u4ee4\u7c7b\u578b\u652f\u6301\uff1a\u542f\u52a8\u5de5\u4f5c\u6d41\u3001\u4ece\u5f53\u524d\u8282\u70b9\u5f00\u59cb\u6267\u884c\u3001\u6062\u590d\u88ab\u5bb9\u9519\u7684\u5de5\u4f5c\u6d41\u3001\u6062\u590d\u6682\u505c\u6d41\u7a0b\u3001\u4ece\u5931\u8d25\u8282\u70b9\u5f00\u59cb\u6267\u884c\u3001\u8865\u6570\u3001\u5b9a\u65f6\u3001\u91cd\u8dd1\u3001\u6682\u505c\u3001\u505c\u6b62\u3001\u6062\u590d\u7b49\u5f85\u7ebf\u7a0b\u3002\u5176\u4e2d **\u6062\u590d\u88ab\u5bb9\u9519\u7684\u5de5\u4f5c\u6d41** \u548c **\u6062\u590d\u7b49\u5f85\u7ebf\u7a0b** \u4e24\u79cd\u547d\u4ee4\u7c7b\u578b\u662f\u7531\u8c03\u5ea6\u5185\u90e8\u63a7\u5236\u4f7f\u7528\uff0c\u5916\u90e8\u65e0\u6cd5\u8c03\u7528\n-\n-**\u5b9a\u65f6\u8c03\u5ea6**\uff1a\u7cfb\u7edf\u91c7\u7528 **quartz** \u5206\u5e03\u5f0f\u8c03\u5ea6\u5668\uff0c\u5e76\u540c\u65f6\u652f\u6301cron\u8868\u8fbe\u5f0f\u53ef\u89c6\u5316\u7684\u751f\u6210\n-\n-**\u4f9d\u8d56**\uff1a\u7cfb\u7edf\u4e0d\u5355\u5355\u652f\u6301 **DAG** \u7b80\u5355\u7684\u524d\u9a71\u548c\u540e\u7ee7\u8282\u70b9\u4e4b\u95f4\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u8fd8\u63d0\u4f9b**\u4efb\u52a1\u4f9d\u8d56**\u8282\u70b9\uff0c\u652f\u6301**\u6d41\u7a0b\u95f4\u7684\u81ea\u5b9a\u4e49\u4efb\u52a1\u4f9d\u8d56**\n-\n-**\u4f18\u5148\u7ea7** \uff1a\u652f\u6301\u6d41\u7a0b\u5b9e\u4f8b\u548c\u4efb\u52a1\u5b9e\u4f8b\u7684\u4f18\u5148\u7ea7\uff0c\u5982\u679c\u6d41\u7a0b\u5b9e\u4f8b\u548c\u4efb\u52a1\u5b9e\u4f8b\u7684\u4f18\u5148\u7ea7\u4e0d\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u662f\u5148\u8fdb\u5148\u51fa\n-\n-**\u90ae\u4ef6\u544a\u8b66**\uff1a\u652f\u6301 **SQL\u4efb\u52a1** \u67e5\u8be2\u7ed3\u679c\u90ae\u4ef6\u53d1\u9001\uff0c\u6d41\u7a0b\u5b9e\u4f8b\u8fd0\u884c\u7ed3\u679c\u90ae\u4ef6\u544a\u8b66\u53ca\u5bb9\u9519\u544a\u8b66\u901a\u77e5\n-\n-**\u5931\u8d25\u7b56\u7565**\uff1a\u5bf9\u4e8e\u5e76\u884c\u8fd0\u884c\u7684\u4efb\u52a1\uff0c\u5982\u679c\u6709\u4efb\u52a1\u5931\u8d25\uff0c\u63d0\u4f9b\u4e24\u79cd\u5931\u8d25\u7b56\u7565\u5904\u7406\u65b9\u5f0f\uff0c**\u7ee7\u7eed**\u662f\u6307\u4e0d\u7ba1\u5e76\u884c\u8fd0\u884c\u4efb\u52a1\u7684\u72b6\u6001\uff0c\u76f4\u5230\u6d41\u7a0b\u5931\u8d25\u7ed3\u675f\u3002**\u7ed3\u675f**\u662f\u6307\u4e00\u65e6\u53d1\u73b0\u5931\u8d25\u4efb\u52a1\uff0c\u5219\u540c\u65f6Kill\u6389\u6b63\u5728\u8fd0\u884c\u7684\u5e76\u884c\u4efb\u52a1\uff0c\u6d41\u7a0b\u5931\u8d25\u7ed3\u675f\n-\n-**\u8865\u6570**\uff1a\u8865\u5386\u53f2\u6570\u636e\uff0c\u652f\u6301**\u533a\u95f4\u5e76\u884c\u548c\u4e32\u884c**\u4e24\u79cd\u8865\u6570\u65b9\u5f0f\n-\n-### 2.\u7cfb\u7edf\u67b6\u6784\n-\n-#### 2.1 \u7cfb\u7edf\u67b6\u6784\u56fe\n-<p align=\"center\">\n-  <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/architecture.jpg\" alt=\"\u7cfb\u7edf\u67b6\u6784\u56fe\"  width=\"70%\" />\n-  <p align=\"center\">\n-        <em>\u7cfb\u7edf\u67b6\u6784\u56fe</em>\n-  </p>\n-</p>\n-\n-#### 2.2 \u67b6\u6784\u8bf4\u660e\n-\n-* **MasterServer** \n-\n-    MasterServer\u91c7\u7528\u5206\u5e03\u5f0f\u65e0\u4e2d\u5fc3\u8bbe\u8ba1\u7406\u5ff5\uff0cMasterServer\u4e3b\u8981\u8d1f\u8d23 DAG \u4efb\u52a1\u5207\u5206\u3001\u4efb\u52a1\u63d0\u4ea4\u76d1\u63a7\uff0c\u5e76\u540c\u65f6\u76d1\u542c\u5176\u5b83MasterServer\u548cWorkerServer\u7684\u5065\u5eb7\u72b6\u6001\u3002\n-    MasterServer\u670d\u52a1\u542f\u52a8\u65f6\u5411Zookeeper\u6ce8\u518c\u4e34\u65f6\u8282\u70b9\uff0c\u901a\u8fc7\u76d1\u542cZookeeper\u4e34\u65f6\u8282\u70b9\u53d8\u5316\u6765\u8fdb\u884c\u5bb9\u9519\u5904\u7406\u3002\n-\n-    ##### \u8be5\u670d\u52a1\u5185\u4e3b\u8981\u5305\u542b:\n-\n-    - **Distributed Quartz**\u5206\u5e03\u5f0f\u8c03\u5ea6\u7ec4\u4ef6\uff0c\u4e3b\u8981\u8d1f\u8d23\u5b9a\u65f6\u4efb\u52a1\u7684\u542f\u505c\u64cd\u4f5c\uff0c\u5f53quartz\u8c03\u8d77\u4efb\u52a1\u540e\uff0cMaster\u5185\u90e8\u4f1a\u6709\u7ebf\u7a0b\u6c60\u5177\u4f53\u8d1f\u8d23\u5904\u7406\u4efb\u52a1\u7684\u540e\u7eed\u64cd\u4f5c\n-\n-    - **MasterSchedulerThread**\u662f\u4e00\u4e2a\u626b\u63cf\u7ebf\u7a0b\uff0c\u5b9a\u65f6\u626b\u63cf\u6570\u636e\u5e93\u4e2d\u7684 **command** \u8868\uff0c\u6839\u636e\u4e0d\u540c\u7684**\u547d\u4ee4\u7c7b\u578b**\u8fdb\u884c\u4e0d\u540c\u7684\u4e1a\u52a1\u64cd\u4f5c\n-\n-    - **MasterExecThread**\u4e3b\u8981\u662f\u8d1f\u8d23DAG\u4efb\u52a1\u5207\u5206\u3001\u4efb\u52a1\u63d0\u4ea4\u76d1\u63a7\u3001\u5404\u79cd\u4e0d\u540c\u547d\u4ee4\u7c7b\u578b\u7684\u903b\u8f91\u5904\u7406\n-\n-    - **MasterTaskExecThread**\u4e3b\u8981\u8d1f\u8d23\u4efb\u52a1\u7684\u6301\u4e45\u5316\n-\n-* **WorkerServer** \n-\n-     WorkerServer\u4e5f\u91c7\u7528\u5206\u5e03\u5f0f\u65e0\u4e2d\u5fc3\u8bbe\u8ba1\u7406\u5ff5\uff0cWorkerServer\u4e3b\u8981\u8d1f\u8d23\u4efb\u52a1\u7684\u6267\u884c\u548c\u63d0\u4f9b\u65e5\u5fd7\u670d\u52a1\u3002WorkerServer\u670d\u52a1\u542f\u52a8\u65f6\u5411Zookeeper\u6ce8\u518c\u4e34\u65f6\u8282\u70b9\uff0c\u5e76\u7ef4\u6301\u5fc3\u8df3\u3002\n-     ##### \u8be5\u670d\u52a1\u5305\u542b\uff1a\n-     - **FetchTaskThread**\u4e3b\u8981\u8d1f\u8d23\u4e0d\u65ad\u4ece**Task Queue**\u4e2d\u9886\u53d6\u4efb\u52a1\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u8c03\u7528**TaskScheduleThread**\u5bf9\u5e94\u6267\u884c\u5668\u3002\n-\n-     - **LoggerServer**\u662f\u4e00\u4e2aRPC\u670d\u52a1\uff0c\u63d0\u4f9b\u65e5\u5fd7\u5206\u7247\u67e5\u770b\u3001\u5237\u65b0\u548c\u4e0b\u8f7d\u7b49\u529f\u80fd\n-\n-* **ZooKeeper** \n-\n-    ZooKeeper\u670d\u52a1\uff0c\u7cfb\u7edf\u4e2d\u7684MasterServer\u548cWorkerServer\u8282\u70b9\u90fd\u901a\u8fc7ZooKeeper\u6765\u8fdb\u884c\u96c6\u7fa4\u7ba1\u7406\u548c\u5bb9\u9519\u3002\u53e6\u5916\u7cfb\u7edf\u8fd8\u57fa\u4e8eZooKeeper\u8fdb\u884c\u4e8b\u4ef6\u76d1\u542c\u548c\u5206\u5e03\u5f0f\u9501\u3002\n-    \u6211\u4eec\u4e5f\u66fe\u7ecf\u57fa\u4e8eRedis\u5b9e\u73b0\u8fc7\u961f\u5217\uff0c\u4e0d\u8fc7\u6211\u4eec\u5e0c\u671bEasyScheduler\u4f9d\u8d56\u5230\u7684\u7ec4\u4ef6\u5c3d\u91cf\u5730\u5c11\uff0c\u6240\u4ee5\u6700\u540e\u8fd8\u662f\u53bb\u6389\u4e86Redis\u5b9e\u73b0\u3002\n-\n-* **Task Queue** \n-\n-    \u63d0\u4f9b\u4efb\u52a1\u961f\u5217\u7684\u64cd\u4f5c\uff0c\u76ee\u524d\u961f\u5217\u4e5f\u662f\u57fa\u4e8eZookeeper\u6765\u5b9e\u73b0\u3002\u7531\u4e8e\u961f\u5217\u4e2d\u5b58\u7684\u4fe1\u606f\u8f83\u5c11\uff0c\u4e0d\u5fc5\u62c5\u5fc3\u961f\u5217\u91cc\u6570\u636e\u8fc7\u591a\u7684\u60c5\u51b5\uff0c\u5b9e\u9645\u4e0a\u6211\u4eec\u538b\u6d4b\u8fc7\u767e\u4e07\u7ea7\u6570\u636e\u5b58\u961f\u5217\uff0c\u5bf9\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u6ca1\u5f71\u54cd\u3002\n-\n-* **Alert** \n-\n-    \u63d0\u4f9b\u544a\u8b66\u76f8\u5173\u63a5\u53e3\uff0c\u63a5\u53e3\u4e3b\u8981\u5305\u62ec**\u544a\u8b66**\u4e24\u79cd\u7c7b\u578b\u7684\u544a\u8b66\u6570\u636e\u7684\u5b58\u50a8\u3001\u67e5\u8be2\u548c\u901a\u77e5\u529f\u80fd\u3002\u5176\u4e2d\u901a\u77e5\u529f\u80fd\u53c8\u6709**\u90ae\u4ef6\u901a\u77e5**\u548c**SNMP(\u6682\u672a\u5b9e\u73b0)**\u4e24\u79cd\u3002\n-\n-* **API** \n-\n-    API\u63a5\u53e3\u5c42\uff0c\u4e3b\u8981\u8d1f\u8d23\u5904\u7406\u524d\u7aefUI\u5c42\u7684\u8bf7\u6c42\u3002\u8be5\u670d\u52a1\u7edf\u4e00\u63d0\u4f9bRESTful api\u5411\u5916\u90e8\u63d0\u4f9b\u8bf7\u6c42\u670d\u52a1\u3002\n-    \u63a5\u53e3\u5305\u62ec\u5de5\u4f5c\u6d41\u7684\u521b\u5efa\u3001\u5b9a\u4e49\u3001\u67e5\u8be2\u3001\u4fee\u6539\u3001\u53d1\u5e03\u3001\u4e0b\u7ebf\u3001\u624b\u5de5\u542f\u52a8\u3001\u505c\u6b62\u3001\u6682\u505c\u3001\u6062\u590d\u3001\u4ece\u8be5\u8282\u70b9\u5f00\u59cb\u6267\u884c\u7b49\u7b49\u3002\n-\n-* **UI** \n-\n-    \u7cfb\u7edf\u7684\u524d\u7aef\u9875\u9762\uff0c\u63d0\u4f9b\u7cfb\u7edf\u7684\u5404\u79cd\u53ef\u89c6\u5316\u64cd\u4f5c\u754c\u9762\uff0c\u8be6\u89c1**[\u7cfb\u7edf\u4f7f\u7528\u624b\u518c](\u7cfb\u7edf\u4f7f\u7528\u624b\u518c.md)**\u90e8\u5206\u3002\n-\n-#### 2.3 \u67b6\u6784\u8bbe\u8ba1\u601d\u60f3\n-\n-##### \u4e00\u3001\u53bb\u4e2d\u5fc3\u5316vs\u4e2d\u5fc3\u5316 \n-\n-###### \u4e2d\u5fc3\u5316\u601d\u60f3\n-\n-\u4e2d\u5fc3\u5316\u7684\u8bbe\u8ba1\u7406\u5ff5\u6bd4\u8f83\u7b80\u5355\uff0c\u5206\u5e03\u5f0f\u96c6\u7fa4\u4e2d\u7684\u8282\u70b9\u6309\u7167\u89d2\u8272\u5206\u5de5\uff0c\u5927\u4f53\u4e0a\u5206\u4e3a\u4e24\u79cd\u89d2\u8272\uff1a\n-<p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/master_slave.png\" alt=\"master-slave\u89d2\u8272\"  width=\"50%\" />\n- </p>\n- \n-- Master\u7684\u89d2\u8272\u4e3b\u8981\u8d1f\u8d23\u4efb\u52a1\u5206\u53d1\u5e76\u76d1\u7763Slave\u7684\u5065\u5eb7\u72b6\u6001\uff0c\u53ef\u4ee5\u52a8\u6001\u7684\u5c06\u4efb\u52a1\u5747\u8861\u5230Slave\u4e0a\uff0c\u4ee5\u81f4Slave\u8282\u70b9\u4e0d\u81f3\u4e8e\u201c\u5fd9\u6b7b\u201d\u6216\u201d\u95f2\u6b7b\u201d\u7684\u72b6\u6001\u3002\n-- Worker\u7684\u89d2\u8272\u4e3b\u8981\u8d1f\u8d23\u4efb\u52a1\u7684\u6267\u884c\u5de5\u4f5c\u5e76\u7ef4\u62a4\u548cMaster\u7684\u5fc3\u8df3\uff0c\u4ee5\u4fbfMaster\u53ef\u4ee5\u5206\u914d\u4efb\u52a1\u7ed9Slave\u3002\n-\n-\n-\n-\u4e2d\u5fc3\u5316\u601d\u60f3\u8bbe\u8ba1\u5b58\u5728\u7684\u95ee\u9898\uff1a\n-\n-- \u4e00\u65e6Master\u51fa\u73b0\u4e86\u95ee\u9898\uff0c\u5219\u7fa4\u9f99\u65e0\u9996\uff0c\u6574\u4e2a\u96c6\u7fa4\u5c31\u4f1a\u5d29\u6e83\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5927\u591a\u6570Master/Slave\u67b6\u6784\u6a21\u5f0f\u90fd\u91c7\u7528\u4e86\u4e3b\u5907Master\u7684\u8bbe\u8ba1\u65b9\u6848\uff0c\u53ef\u4ee5\u662f\u70ed\u5907\u6216\u8005\u51b7\u5907\uff0c\u4e5f\u53ef\u4ee5\u662f\u81ea\u52a8\u5207\u6362\u6216\u624b\u52a8\u5207\u6362\uff0c\u800c\u4e14\u8d8a\u6765\u8d8a\u591a\u7684\u65b0\u7cfb\u7edf\u90fd\u5f00\u59cb\u5177\u5907\u81ea\u52a8\u9009\u4e3e\u5207\u6362Master\u7684\u80fd\u529b,\u4ee5\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u3002\n-- \u53e6\u5916\u4e00\u4e2a\u95ee\u9898\u662f\u5982\u679cScheduler\u5728Master\u4e0a\uff0c\u867d\u7136\u53ef\u4ee5\u652f\u6301\u4e00\u4e2aDAG\u4e2d\u4e0d\u540c\u7684\u4efb\u52a1\u8fd0\u884c\u5728\u4e0d\u540c\u7684\u673a\u5668\u4e0a\uff0c\u4f46\u662f\u4f1a\u4ea7\u751fMaster\u7684\u8fc7\u8d1f\u8f7d\u3002\u5982\u679cScheduler\u5728Slave\u4e0a\uff0c\u5219\u4e00\u4e2aDAG\u4e2d\u6240\u6709\u7684\u4efb\u52a1\u90fd\u53ea\u80fd\u5728\u67d0\u4e00\u53f0\u673a\u5668\u4e0a\u8fdb\u884c\u4f5c\u4e1a\u63d0\u4ea4\uff0c\u5219\u5e76\u884c\u4efb\u52a1\u6bd4\u8f83\u591a\u7684\u65f6\u5019\uff0cSlave\u7684\u538b\u529b\u53ef\u80fd\u4f1a\u6bd4\u8f83\u5927\u3002\n-\n-\n-\n-###### \u53bb\u4e2d\u5fc3\u5316\n- <p align=\"center\"\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/decentralization.png\" alt=\"\u53bb\u4e2d\u5fc3\u5316\"  width=\"50%\" />\n- </p>\n- \n-- \u5728\u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u91cc\uff0c\u901a\u5e38\u6ca1\u6709Master/Slave\u7684\u6982\u5ff5\uff0c\u6240\u6709\u7684\u89d2\u8272\u90fd\u662f\u4e00\u6837\u7684\uff0c\u5730\u4f4d\u662f\u5e73\u7b49\u7684\uff0c\u5168\u7403\u4e92\u8054\u7f51\u5c31\u662f\u4e00\u4e2a\u5178\u578b\u7684\u53bb\u4e2d\u5fc3\u5316\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u8054\u7f51\u7684\u4efb\u610f\u8282\u70b9\u8bbe\u5907down\u673a\uff0c\u90fd\u53ea\u4f1a\u5f71\u54cd\u5f88\u5c0f\u8303\u56f4\u7684\u529f\u80fd\u3002\n-- \u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u7684\u6838\u5fc3\u8bbe\u8ba1\u5728\u4e8e\u6574\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4e0d\u5b58\u5728\u4e00\u4e2a\u533a\u522b\u4e8e\u5176\u4ed6\u8282\u70b9\u7684\u201d\u7ba1\u7406\u8005\u201d\uff0c\u56e0\u6b64\u4e0d\u5b58\u5728\u5355\u70b9\u6545\u969c\u95ee\u9898\u3002\u4f46\u7531\u4e8e\u4e0d\u5b58\u5728\u201d \u7ba1\u7406\u8005\u201d\u8282\u70b9\u6240\u4ee5\u6bcf\u4e2a\u8282\u70b9\u90fd\u9700\u8981\u8ddf\u5176\u4ed6\u8282\u70b9\u901a\u4fe1\u624d\u5f97\u5230\u5fc5\u987b\u8981\u7684\u673a\u5668\u4fe1\u606f\uff0c\u800c\u5206\u5e03\u5f0f\u7cfb\u7edf\u901a\u4fe1\u7684\u4e0d\u53ef\u9760\u884c\uff0c\u5219\u5927\u5927\u589e\u52a0\u4e86\u4e0a\u8ff0\u529f\u80fd\u7684\u5b9e\u73b0\u96be\u5ea6\u3002\n-- \u5b9e\u9645\u4e0a\uff0c\u771f\u6b63\u53bb\u4e2d\u5fc3\u5316\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u5e76\u4e0d\u591a\u89c1\u3002\u53cd\u800c\u52a8\u6001\u4e2d\u5fc3\u5316\u5206\u5e03\u5f0f\u7cfb\u7edf\u6b63\u5728\u4e0d\u65ad\u6d8c\u51fa\u3002\u5728\u8fd9\u79cd\u67b6\u6784\u4e0b\uff0c\u96c6\u7fa4\u4e2d\u7684\u7ba1\u7406\u8005\u662f\u88ab\u52a8\u6001\u9009\u62e9\u51fa\u6765\u7684\uff0c\u800c\u4e0d\u662f\u9884\u7f6e\u7684\uff0c\u5e76\u4e14\u96c6\u7fa4\u5728\u53d1\u751f\u6545\u969c\u7684\u65f6\u5019\uff0c\u96c6\u7fa4\u7684\u8282\u70b9\u4f1a\u81ea\u53d1\u7684\u4e3e\u884c\"\u4f1a\u8bae\"\u6765\u9009\u4e3e\u65b0\u7684\"\u7ba1\u7406\u8005\"\u53bb\u4e3b\u6301\u5de5\u4f5c\u3002\u6700\u5178\u578b\u7684\u6848\u4f8b\u5c31\u662fZooKeeper\u53caGo\u8bed\u8a00\u5b9e\u73b0\u7684Etcd\u3002\n-\n-\n-\n-- EasyScheduler\u7684\u53bb\u4e2d\u5fc3\u5316\u662fMaster/Worker\u6ce8\u518c\u5230Zookeeper\u4e2d\uff0c\u5b9e\u73b0Master\u96c6\u7fa4\u548cWorker\u96c6\u7fa4\u65e0\u4e2d\u5fc3\uff0c\u5e76\u4f7f\u7528Zookeeper\u5206\u5e03\u5f0f\u9501\u6765\u9009\u4e3e\u5176\u4e2d\u7684\u4e00\u53f0Master\u6216Worker\u4e3a\u201c\u7ba1\u7406\u8005\u201d\u6765\u6267\u884c\u4efb\u52a1\u3002\n-\n-#####  \u4e8c\u3001\u5206\u5e03\u5f0f\u9501\u5b9e\u8df5\n-\n-EasyScheduler\u4f7f\u7528ZooKeeper\u5206\u5e03\u5f0f\u9501\u6765\u5b9e\u73b0\u540c\u4e00\u65f6\u523b\u53ea\u6709\u4e00\u53f0Master\u6267\u884cScheduler\uff0c\u6216\u8005\u53ea\u6709\u4e00\u53f0Worker\u6267\u884c\u4efb\u52a1\u7684\u63d0\u4ea4\u3002\n-1. \u83b7\u53d6\u5206\u5e03\u5f0f\u9501\u7684\u6838\u5fc3\u6d41\u7a0b\u7b97\u6cd5\u5982\u4e0b\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/distributed_lock.png\" alt=\"\u83b7\u53d6\u5206\u5e03\u5f0f\u9501\u6d41\u7a0b\"  width=\"50%\" />\n- </p>\n-\n-2. EasyScheduler\u4e2dScheduler\u7ebf\u7a0b\u5206\u5e03\u5f0f\u9501\u5b9e\u73b0\u6d41\u7a0b\u56fe\uff1a\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/distributed_lock_procss.png\" alt=\"\u83b7\u53d6\u5206\u5e03\u5f0f\u9501\u6d41\u7a0b\"  width=\"50%\" />\n- </p>\n-\n-\n-##### \u4e09\u3001\u7ebf\u7a0b\u4e0d\u8db3\u5faa\u73af\u7b49\u5f85\u95ee\u9898\n-\n--  \u5982\u679c\u4e00\u4e2aDAG\u4e2d\u6ca1\u6709\u5b50\u6d41\u7a0b\uff0c\u5219\u5982\u679cCommand\u4e2d\u7684\u6570\u636e\u6761\u6570\u5927\u4e8e\u7ebf\u7a0b\u6c60\u8bbe\u7f6e\u7684\u9608\u503c\uff0c\u5219\u76f4\u63a5\u6d41\u7a0b\u7b49\u5f85\u6216\u5931\u8d25\u3002\n--  \u5982\u679c\u4e00\u4e2a\u5927\u7684DAG\u4e2d\u5d4c\u5957\u4e86\u5f88\u591a\u5b50\u6d41\u7a0b\uff0c\u5982\u4e0b\u56fe\u5219\u4f1a\u4ea7\u751f\u201c\u6b7b\u7b49\u201d\u72b6\u6001\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/lack_thread.png\" alt=\"\u7ebf\u7a0b\u4e0d\u8db3\u5faa\u73af\u7b49\u5f85\u95ee\u9898\"  width=\"50%\" />\n- </p>\n-\u4e0a\u56fe\u4e2dMainFlowThread\u7b49\u5f85SubFlowThread1\u7ed3\u675f\uff0cSubFlowThread1\u7b49\u5f85SubFlowThread2\u7ed3\u675f\uff0c SubFlowThread2\u7b49\u5f85SubFlowThread3\u7ed3\u675f\uff0c\u800cSubFlowThread3\u7b49\u5f85\u7ebf\u7a0b\u6c60\u6709\u65b0\u7ebf\u7a0b\uff0c\u5219\u6574\u4e2aDAG\u6d41\u7a0b\u4e0d\u80fd\u7ed3\u675f\uff0c\u4ece\u800c\u5176\u4e2d\u7684\u7ebf\u7a0b\u4e5f\u4e0d\u80fd\u91ca\u653e\u3002\u8fd9\u6837\u5c31\u5f62\u6210\u7684\u5b50\u7236\u6d41\u7a0b\u5faa\u73af\u7b49\u5f85\u7684\u72b6\u6001\u3002\u6b64\u65f6\u9664\u975e\u542f\u52a8\u65b0\u7684Master\u6765\u589e\u52a0\u7ebf\u7a0b\u6765\u6253\u7834\u8fd9\u6837\u7684\u201d\u50f5\u5c40\u201d\uff0c\u5426\u5219\u8c03\u5ea6\u96c6\u7fa4\u5c06\u4e0d\u80fd\u518d\u4f7f\u7528\u3002\n-\n-\u5bf9\u4e8e\u542f\u52a8\u65b0Master\u6765\u6253\u7834\u50f5\u5c40\uff0c\u4f3c\u4e4e\u6709\u70b9\u5dee\u5f3a\u4eba\u610f\uff0c\u4e8e\u662f\u6211\u4eec\u63d0\u51fa\u4e86\u4ee5\u4e0b\u4e09\u79cd\u65b9\u6848\u6765\u964d\u4f4e\u8fd9\u79cd\u98ce\u9669\uff1a\n-\n-1. \u8ba1\u7b97\u6240\u6709Master\u7684\u7ebf\u7a0b\u603b\u548c\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u4e2aDAG\u9700\u8981\u8ba1\u7b97\u5176\u9700\u8981\u7684\u7ebf\u7a0b\u6570\uff0c\u4e5f\u5c31\u662f\u5728DAG\u6d41\u7a0b\u6267\u884c\u4e4b\u524d\u505a\u9884\u8ba1\u7b97\u3002\u56e0\u4e3a\u662f\u591aMaster\u7ebf\u7a0b\u6c60\uff0c\u6240\u4ee5\u603b\u7ebf\u7a0b\u6570\u4e0d\u592a\u53ef\u80fd\u5b9e\u65f6\u83b7\u53d6\u3002 \n-2. \u5bf9\u5355Master\u7ebf\u7a0b\u6c60\u8fdb\u884c\u5224\u65ad\uff0c\u5982\u679c\u7ebf\u7a0b\u6c60\u5df2\u7ecf\u6ee1\u4e86\uff0c\u5219\u8ba9\u7ebf\u7a0b\u76f4\u63a5\u5931\u8d25\u3002\n-3. \u589e\u52a0\u4e00\u79cd\u8d44\u6e90\u4e0d\u8db3\u7684Command\u7c7b\u578b\uff0c\u5982\u679c\u7ebf\u7a0b\u6c60\u4e0d\u8db3\uff0c\u5219\u5c06\u4e3b\u6d41\u7a0b\u6302\u8d77\u3002\u8fd9\u6837\u7ebf\u7a0b\u6c60\u5c31\u6709\u4e86\u65b0\u7684\u7ebf\u7a0b\uff0c\u53ef\u4ee5\u8ba9\u8d44\u6e90\u4e0d\u8db3\u6302\u8d77\u7684\u6d41\u7a0b\u91cd\u65b0\u5524\u9192\u6267\u884c\u3002\n-\n-\u6ce8\u610f\uff1aMaster Scheduler\u7ebf\u7a0b\u5728\u83b7\u53d6Command\u7684\u65f6\u5019\u662fFIFO\u7684\u65b9\u5f0f\u6267\u884c\u7684\u3002\n-\n-\u4e8e\u662f\u6211\u4eec\u9009\u62e9\u4e86\u7b2c\u4e09\u79cd\u65b9\u5f0f\u6765\u89e3\u51b3\u7ebf\u7a0b\u4e0d\u8db3\u7684\u95ee\u9898\u3002\n-\n-\n-##### \u56db\u3001\u5bb9\u9519\u8bbe\u8ba1\n-\u5bb9\u9519\u5206\u4e3a\u670d\u52a1\u5b95\u673a\u5bb9\u9519\u548c\u4efb\u52a1\u91cd\u8bd5\uff0c\u670d\u52a1\u5b95\u673a\u5bb9\u9519\u53c8\u5206\u4e3aMaster\u5bb9\u9519\u548cWorker\u5bb9\u9519\u4e24\u79cd\u60c5\u51b5\n-\n-###### 1. \u5b95\u673a\u5bb9\u9519\n-\n-\u670d\u52a1\u5bb9\u9519\u8bbe\u8ba1\u4f9d\u8d56\u4e8eZooKeeper\u7684Watcher\u673a\u5236\uff0c\u5b9e\u73b0\u539f\u7406\u5982\u56fe\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant.png\" alt=\"EasyScheduler\u5bb9\u9519\u8bbe\u8ba1\"  width=\"40%\" />\n- </p>\n-\u5176\u4e2dMaster\u76d1\u63a7\u5176\u4ed6Master\u548cWorker\u7684\u76ee\u5f55\uff0c\u5982\u679c\u76d1\u542c\u5230remove\u4e8b\u4ef6\uff0c\u5219\u4f1a\u6839\u636e\u5177\u4f53\u7684\u4e1a\u52a1\u903b\u8f91\u8fdb\u884c\u6d41\u7a0b\u5b9e\u4f8b\u5bb9\u9519\u6216\u8005\u4efb\u52a1\u5b9e\u4f8b\u5bb9\u9519\u3002\n-\n-\n-\n-- Master\u5bb9\u9519\u6d41\u7a0b\u56fe\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant_master.png\" alt=\"Master\u5bb9\u9519\u6d41\u7a0b\u56fe\"  width=\"40%\" />\n- </p>\n-ZooKeeper Master\u5bb9\u9519\u5b8c\u6210\u4e4b\u540e\u5219\u91cd\u65b0\u7531EasyScheduler\u4e2dScheduler\u7ebf\u7a0b\u8c03\u5ea6\uff0c\u904d\u5386 DAG \u627e\u5230\u201d\u6b63\u5728\u8fd0\u884c\u201d\u548c\u201c\u63d0\u4ea4\u6210\u529f\u201d\u7684\u4efb\u52a1\uff0c\u5bf9\u201d\u6b63\u5728\u8fd0\u884c\u201d\u7684\u4efb\u52a1\u76d1\u63a7\u5176\u4efb\u52a1\u5b9e\u4f8b\u7684\u72b6\u6001\uff0c\u5bf9\u201d\u63d0\u4ea4\u6210\u529f\u201d\u7684\u4efb\u52a1\u9700\u8981\u5224\u65adTask Queue\u4e2d\u662f\u5426\u5df2\u7ecf\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u540c\u6837\u76d1\u63a7\u4efb\u52a1\u5b9e\u4f8b\u7684\u72b6\u6001\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u91cd\u65b0\u63d0\u4ea4\u4efb\u52a1\u5b9e\u4f8b\u3002\n-\n-\n-\n-- Worker\u5bb9\u9519\u6d41\u7a0b\u56fe\uff1a\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/fault-tolerant_worker.png\" alt=\"Worker\u5bb9\u9519\u6d41\u7a0b\u56fe\"  width=\"40%\" />\n- </p>\n-\n-Master Scheduler\u7ebf\u7a0b\u4e00\u65e6\u53d1\u73b0\u4efb\u52a1\u5b9e\u4f8b\u4e3a\u201d \u9700\u8981\u5bb9\u9519\u201d\u72b6\u6001\uff0c\u5219\u63a5\u7ba1\u4efb\u52a1\u5e76\u8fdb\u884c\u91cd\u65b0\u63d0\u4ea4\u3002\n-\n- \u6ce8\u610f\uff1a\u7531\u4e8e\u201d \u7f51\u7edc\u6296\u52a8\u201d\u53ef\u80fd\u4f1a\u4f7f\u5f97\u8282\u70b9\u77ed\u65f6\u95f4\u5185\u5931\u53bb\u548cZooKeeper\u7684\u5fc3\u8df3\uff0c\u4ece\u800c\u53d1\u751f\u8282\u70b9\u7684remove\u4e8b\u4ef6\u3002\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\uff0c\u6211\u4eec\u4f7f\u7528\u6700\u7b80\u5355\u7684\u65b9\u5f0f\uff0c\u90a3\u5c31\u662f\u8282\u70b9\u4e00\u65e6\u548cZooKeeper\u53d1\u751f\u8d85\u65f6\u8fde\u63a5\uff0c\u5219\u76f4\u63a5\u5c06Master\u6216Worker\u670d\u52a1\u505c\u6389\u3002\n-\n-###### 2.\u4efb\u52a1\u5931\u8d25\u91cd\u8bd5\n-\n-\u8fd9\u91cc\u9996\u5148\u8981\u533a\u5206\u4efb\u52a1\u5931\u8d25\u91cd\u8bd5\u3001\u6d41\u7a0b\u5931\u8d25\u6062\u590d\u3001\u6d41\u7a0b\u5931\u8d25\u91cd\u8dd1\u7684\u6982\u5ff5\uff1a\n-\n-- \u4efb\u52a1\u5931\u8d25\u91cd\u8bd5\u662f\u4efb\u52a1\u7ea7\u522b\u7684\uff0c\u662f\u8c03\u5ea6\u7cfb\u7edf\u81ea\u52a8\u8fdb\u884c\u7684\uff0c\u6bd4\u5982\u4e00\u4e2aShell\u4efb\u52a1\u8bbe\u7f6e\u91cd\u8bd5\u6b21\u6570\u4e3a3\u6b21\uff0c\u90a3\u4e48\u5728Shell\u4efb\u52a1\u8fd0\u884c\u5931\u8d25\u540e\u4f1a\u81ea\u5df1\u518d\u6700\u591a\u5c1d\u8bd5\u8fd0\u884c3\u6b21\n-- \u6d41\u7a0b\u5931\u8d25\u6062\u590d\u662f\u6d41\u7a0b\u7ea7\u522b\u7684\uff0c\u662f\u624b\u52a8\u8fdb\u884c\u7684\uff0c\u6062\u590d\u662f\u4ece\u53ea\u80fd**\u4ece\u5931\u8d25\u7684\u8282\u70b9\u5f00\u59cb\u6267\u884c**\u6216**\u4ece\u5f53\u524d\u8282\u70b9\u5f00\u59cb\u6267\u884c**\n-- \u6d41\u7a0b\u5931\u8d25\u91cd\u8dd1\u4e5f\u662f\u6d41\u7a0b\u7ea7\u522b\u7684\uff0c\u662f\u624b\u52a8\u8fdb\u884c\u7684\uff0c\u91cd\u8dd1\u662f\u4ece\u5f00\u59cb\u8282\u70b9\u8fdb\u884c\n-\n-\n-\n-\u63a5\u4e0b\u6765\u8bf4\u6b63\u9898\uff0c\u6211\u4eec\u5c06\u5de5\u4f5c\u6d41\u4e2d\u7684\u4efb\u52a1\u8282\u70b9\u5206\u4e86\u4e24\u79cd\u7c7b\u578b\u3002\n-\n-- \u4e00\u79cd\u662f\u4e1a\u52a1\u8282\u70b9\uff0c\u8fd9\u79cd\u8282\u70b9\u90fd\u5bf9\u5e94\u4e00\u4e2a\u5b9e\u9645\u7684\u811a\u672c\u6216\u8005\u5904\u7406\u8bed\u53e5\uff0c\u6bd4\u5982Shell\u8282\u70b9\uff0cMR\u8282\u70b9\u3001Spark\u8282\u70b9\u3001\u4f9d\u8d56\u8282\u70b9\u7b49\u3002\n-\n-- \u8fd8\u6709\u4e00\u79cd\u662f\u903b\u8f91\u8282\u70b9\uff0c\u8fd9\u79cd\u8282\u70b9\u4e0d\u505a\u5b9e\u9645\u7684\u811a\u672c\u6216\u8bed\u53e5\u5904\u7406\uff0c\u53ea\u662f\u6574\u4e2a\u6d41\u7a0b\u6d41\u8f6c\u7684\u903b\u8f91\u5904\u7406\uff0c\u6bd4\u5982\u5b50\u6d41\u7a0b\u8282\u7b49\u3002\n-\n-\u6bcf\u4e00\u4e2a**\u4e1a\u52a1\u8282\u70b9**\u90fd\u53ef\u4ee5\u914d\u7f6e\u5931\u8d25\u91cd\u8bd5\u7684\u6b21\u6570\uff0c\u5f53\u8be5\u4efb\u52a1\u8282\u70b9\u5931\u8d25\uff0c\u4f1a\u81ea\u52a8\u91cd\u8bd5\uff0c\u76f4\u5230\u6210\u529f\u6216\u8005\u8d85\u8fc7\u914d\u7f6e\u7684\u91cd\u8bd5\u6b21\u6570\u3002**\u903b\u8f91\u8282\u70b9**\u4e0d\u652f\u6301\u5931\u8d25\u91cd\u8bd5\u3002\u4f46\u662f\u903b\u8f91\u8282\u70b9\u91cc\u7684\u4efb\u52a1\u652f\u6301\u91cd\u8bd5\u3002\n-\n-\u5982\u679c\u5de5\u4f5c\u6d41\u4e2d\u6709\u4efb\u52a1\u5931\u8d25\u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u5de5\u4f5c\u6d41\u5c31\u4f1a\u5931\u8d25\u505c\u6b62\uff0c\u5931\u8d25\u7684\u5de5\u4f5c\u6d41\u53ef\u4ee5\u624b\u52a8\u8fdb\u884c\u91cd\u8dd1\u64cd\u4f5c\u6216\u8005\u6d41\u7a0b\u6062\u590d\u64cd\u4f5c\n-\n-\n-\n-##### \u4e94\u3001\u4efb\u52a1\u4f18\u5148\u7ea7\u8bbe\u8ba1\n-\u5728\u65e9\u671f\u8c03\u5ea6\u8bbe\u8ba1\u4e2d\uff0c\u5982\u679c\u6ca1\u6709\u4f18\u5148\u7ea7\u8bbe\u8ba1\uff0c\u91c7\u7528\u516c\u5e73\u8c03\u5ea6\u8bbe\u8ba1\u7684\u8bdd\uff0c\u4f1a\u9047\u5230\u5148\u884c\u63d0\u4ea4\u7684\u4efb\u52a1\u53ef\u80fd\u4f1a\u548c\u540e\u7ee7\u63d0\u4ea4\u7684\u4efb\u52a1\u540c\u65f6\u5b8c\u6210\u7684\u60c5\u51b5\uff0c\u800c\u4e0d\u80fd\u505a\u5230\u8bbe\u7f6e\u6d41\u7a0b\u6216\u8005\u4efb\u52a1\u7684\u4f18\u5148\u7ea7\uff0c\u56e0\u6b64\u6211\u4eec\u5bf9\u6b64\u8fdb\u884c\u4e86\u91cd\u65b0\u8bbe\u8ba1\uff0c\u76ee\u524d\u6211\u4eec\u8bbe\u8ba1\u5982\u4e0b\uff1a\n-\n--  \u6309\u7167**\u4e0d\u540c\u6d41\u7a0b\u5b9e\u4f8b\u4f18\u5148\u7ea7**\u4f18\u5148\u4e8e**\u540c\u4e00\u4e2a\u6d41\u7a0b\u5b9e\u4f8b\u4f18\u5148\u7ea7**\u4f18\u5148\u4e8e**\u540c\u4e00\u6d41\u7a0b\u5185\u4efb\u52a1\u4f18\u5148\u7ea7**\u4f18\u5148\u4e8e**\u540c\u4e00\u6d41\u7a0b\u5185\u4efb\u52a1**\u63d0\u4ea4\u987a\u5e8f\u4f9d\u6b21\u4ece\u9ad8\u5230\u4f4e\u8fdb\u884c\u4efb\u52a1\u5904\u7406\u3002\n-    - \u5177\u4f53\u5b9e\u73b0\u662f\u6839\u636e\u4efb\u52a1\u5b9e\u4f8b\u7684json\u89e3\u6790\u4f18\u5148\u7ea7\uff0c\u7136\u540e\u628a**\u6d41\u7a0b\u5b9e\u4f8b\u4f18\u5148\u7ea7_\u6d41\u7a0b\u5b9e\u4f8bid_\u4efb\u52a1\u4f18\u5148\u7ea7_\u4efb\u52a1id**\u4fe1\u606f\u4fdd\u5b58\u5728ZooKeeper\u4efb\u52a1\u961f\u5217\u4e2d\uff0c\u5f53\u4ece\u4efb\u52a1\u961f\u5217\u83b7\u53d6\u7684\u65f6\u5019\uff0c\u901a\u8fc7\u5b57\u7b26\u4e32\u6bd4\u8f83\u5373\u53ef\u5f97\u51fa\u6700\u9700\u8981\u4f18\u5148\u6267\u884c\u7684\u4efb\u52a1\n-\n-        - \u5176\u4e2d\u6d41\u7a0b\u5b9a\u4e49\u7684\u4f18\u5148\u7ea7\u662f\u8003\u8651\u5230\u6709\u4e9b\u6d41\u7a0b\u9700\u8981\u5148\u4e8e\u5176\u4ed6\u6d41\u7a0b\u8fdb\u884c\u5904\u7406\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u5728\u6d41\u7a0b\u542f\u52a8\u6216\u8005\u5b9a\u65f6\u542f\u52a8\u65f6\u914d\u7f6e\uff0c\u5171\u67095\u7ea7\uff0c\u4f9d\u6b21\u4e3aHIGHEST\u3001HIGH\u3001MEDIUM\u3001LOW\u3001LOWEST\u3002\u5982\u4e0b\u56fe\n-            <p align=\"center\">\n-               <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/process_priority.png\" alt=\"\u6d41\u7a0b\u4f18\u5148\u7ea7\u914d\u7f6e\"  width=\"40%\" />\n-             </p>\n-\n-        - \u4efb\u52a1\u7684\u4f18\u5148\u7ea7\u4e5f\u5206\u4e3a5\u7ea7\uff0c\u4f9d\u6b21\u4e3aHIGHEST\u3001HIGH\u3001MEDIUM\u3001LOW\u3001LOWEST\u3002\u5982\u4e0b\u56fe\n-            <p align=\"center\">\n-               <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/task_priority.png\" alt=\"\u4efb\u52a1\u4f18\u5148\u7ea7\u914d\u7f6e\"  width=\"35%\" />\n-             </p>\n-\n-\n-##### \u516d\u3001Logback\u548cgRPC\u5b9e\u73b0\u65e5\u5fd7\u8bbf\u95ee\n-\n--  \u7531\u4e8eWeb(UI)\u548cWorker\u4e0d\u4e00\u5b9a\u5728\u540c\u4e00\u53f0\u673a\u5668\u4e0a\uff0c\u6240\u4ee5\u67e5\u770b\u65e5\u5fd7\u4e0d\u80fd\u50cf\u67e5\u8be2\u672c\u5730\u6587\u4ef6\u90a3\u6837\u3002\u6709\u4e24\u79cd\u65b9\u6848\uff1a\n-  -  \u5c06\u65e5\u5fd7\u653e\u5230ES\u641c\u7d22\u5f15\u64ce\u4e0a\n-  -  \u901a\u8fc7gRPC\u901a\u4fe1\u83b7\u53d6\u8fdc\u7a0b\u65e5\u5fd7\u4fe1\u606f\n-\n--  \u4ecb\u4e8e\u8003\u8651\u5230\u5c3d\u53ef\u80fd\u7684EasyScheduler\u7684\u8f7b\u91cf\u7ea7\u6027\uff0c\u6240\u4ee5\u9009\u62e9\u4e86gRPC\u5b9e\u73b0\u8fdc\u7a0b\u8bbf\u95ee\u65e5\u5fd7\u4fe1\u606f\u3002\n-\n- <p align=\"center\">\n-   <img src=\"https://analysys.github.io/easyscheduler_docs_cn/images/grpc.png\" alt=\"grpc\u8fdc\u7a0b\u8bbf\u95ee\"  width=\"50%\" />\n- </p>\n-\n-\n-- \u6211\u4eec\u4f7f\u7528\u81ea\u5b9a\u4e49Logback\u7684FileAppender\u548cFilter\u529f\u80fd\uff0c\u5b9e\u73b0\u6bcf\u4e2a\u4efb\u52a1\u5b9e\u4f8b\u751f\u6210\u4e00\u4e2a\u65e5\u5fd7\u6587\u4ef6\u3002\n-- FileAppender\u4e3b\u8981\u5b9e\u73b0\u5982\u4e0b\uff1a\n-\n- ```java\n- /**\n-  * task log appender\n-  */\n- public class TaskLogAppender extends FileAppender<ILoggingEvent> {\n- \n-     ...\n-\n-    @Override\n-    protected void append(ILoggingEvent event) {\n-\n-        if (currentlyActiveFile == null){\n-            currentlyActiveFile = getFile();\n-        }\n-        String activeFile = currentlyActiveFile;\n-        // thread name\uff1a taskThreadName-processDefineId_processInstanceId_taskInstanceId\n-        String threadName = event.getThreadName();\n-        String[] threadNameArr = threadName.split(\"-\");\n-        // logId = processDefineId_processInstanceId_taskInstanceId\n-        String logId = threadNameArr[1];\n-        ...\n-        super.subAppend(event);\n-    }\n-}\n- ```\n-\n-\n-\u4ee5/\u6d41\u7a0b\u5b9a\u4e49id/\u6d41\u7a0b\u5b9e\u4f8bid/\u4efb\u52a1\u5b9e\u4f8bid.log\u7684\u5f62\u5f0f\u751f\u6210\u65e5\u5fd7\n-\n-- \u8fc7\u6ee4\u5339\u914d\u4ee5TaskLogInfo\u5f00\u59cb\u7684\u7ebf\u7a0b\u540d\u79f0\uff1a\n-\n-- TaskLogFilter\u5b9e\u73b0\u5982\u4e0b\uff1a\n-\n- ```java\n- /**\n- *  task log filter\n- */\n-public class TaskLogFilter extends Filter<ILoggingEvent> {\n-\n-    @Override\n-    public FilterReply decide(ILoggingEvent event) {\n-        if (event.getThreadName().startsWith(\"TaskLogInfo-\")){\n-            return FilterReply.ACCEPT;\n-        }\n-        return FilterReply.DENY;\n-    }\n-}\n- ```\n-\n-### \u603b\u7ed3\n-\u672c\u6587\u4ece\u8c03\u5ea6\u51fa\u53d1\uff0c\u521d\u6b65\u4ecb\u7ecd\u4e86\u5927\u6570\u636e\u5206\u5e03\u5f0f\u5de5\u4f5c\u6d41\u8c03\u5ea6\u7cfb\u7edf--EasyScheduler\u7684\u67b6\u6784\u539f\u7406\u53ca\u5b9e\u73b0\u601d\u8def\u3002\u672a\u5b8c\u5f85\u7eed\n-\n-",
                "changes": 304
            },
            {
                "status": "added",
                "additions": 120,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/pom.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/pom.xml",
                "deletions": 0,
                "sha": "ead46f5e8d8942be747551adbc0b6da13e0a5336",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/pom.xml",
                "patch": "@@ -0,0 +1,120 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <groupId>org.apache.dolphinscheduler</groupId>\n+        <artifactId>dolphinscheduler</artifactId>\n+        <version>1.2.1-SNAPSHOT</version>\n+    </parent>\n+    <artifactId>dolphinscheduler-alert</artifactId>\n+    <name>${project.artifactId}</name>\n+    <packaging>jar</packaging>\n+\n+    <properties>\n+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n+    </properties>\n+    <dependencies>\n+        <dependency>\n+            <groupId>junit</groupId>\n+            <artifactId>junit</artifactId>\n+            <scope>test</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.commons</groupId>\n+            <artifactId>commons-email</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.freemarker</groupId>\n+            <artifactId>freemarker</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.alibaba</groupId>\n+            <artifactId>fastjson</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-core</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.slf4j</groupId>\n+            <artifactId>slf4j-api</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.commons</groupId>\n+            <artifactId>commons-collections4</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>commons-logging</groupId>\n+            <artifactId>commons-logging</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.commons</groupId>\n+            <artifactId>commons-lang3</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>ch.qos.logback</groupId>\n+            <artifactId>logback-classic</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>commons-io</groupId>\n+            <artifactId>commons-io</artifactId>\n+        </dependency>\n+\n+\n+        <!--excel poi-->\n+        <dependency>\n+            <groupId>org.apache.poi</groupId>\n+            <artifactId>poi</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.dolphinscheduler</groupId>\n+            <artifactId>dolphinscheduler-dao</artifactId>\n+            <exclusions>\n+                <exclusion>\n+                    <artifactId>log4j-api</artifactId>\n+                    <groupId>org.apache.logging.log4j</groupId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+    </dependencies>\n+\n+</project>",
                "changes": 120
            },
            {
                "status": "added",
                "additions": 79,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java",
                "deletions": 0,
                "sha": "ee38f3d3c9c9713efc5d210462d1752678c98bb0",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java",
                "patch": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert;\n+\n+import org.apache.dolphinscheduler.alert.runner.AlertSender;\n+import org.apache.dolphinscheduler.alert.utils.Constants;\n+import org.apache.dolphinscheduler.common.thread.Stopper;\n+import org.apache.dolphinscheduler.dao.AlertDao;\n+import org.apache.dolphinscheduler.dao.DaoFactory;\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+\n+/**\n+ * alert of start\n+ */\n+public class AlertServer {\n+    private static final Logger logger = LoggerFactory.getLogger(AlertServer.class);\n+    /**\n+     * Alert Dao\n+     */\n+    private AlertDao alertDao = DaoFactory.getDaoInstance(AlertDao.class);\n+\n+    private AlertSender alertSender;\n+\n+    private static volatile AlertServer instance;\n+\n+    public AlertServer() {\n+\n+    }\n+\n+    public static AlertServer getInstance(){\n+        if (null == instance) {\n+            synchronized (AlertServer.class) {\n+                if(null == instance) {\n+                    instance = new AlertServer();\n+                }\n+            }\n+        }\n+        return instance;\n+    }\n+\n+    public void start(){\n+        logger.info(\"alert server ready start \");\n+        while (Stopper.isRunning()){\n+            try {\n+                Thread.sleep(Constants.ALERT_SCAN_INTERVEL);\n+            } catch (InterruptedException e) {\n+                logger.error(e.getMessage(),e);\n+            }\n+            List<Alert> alerts = alertDao.listWaitExecutionAlert();\n+            alertSender = new AlertSender(alerts, alertDao);\n+            alertSender.run();\n+        }\n+    }\n+\n+\n+    public static void main(String[] args){\n+        AlertServer alertServer = AlertServer.getInstance();\n+        alertServer.start();\n+    }\n+\n+}",
                "changes": 79
            },
            {
                "status": "added",
                "additions": 55,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EmailManager.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EmailManager.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EmailManager.java",
                "deletions": 0,
                "sha": "047ee8bfedade31b5891daa1fd8d8e472f82bcab",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EmailManager.java",
                "patch": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.manager;\n+\n+import org.apache.dolphinscheduler.alert.utils.MailUtils;\n+import org.apache.dolphinscheduler.common.enums.ShowType;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * email send manager\n+ */\n+public class EmailManager {\n+    /**\n+     * email send\n+     * @param receviersList the receiver list\n+     * @param receviersCcList the cc List\n+     * @param title the title\n+     * @param content the content\n+     * @param showType the showType\n+     * @return the send result\n+     */\n+    public Map<String,Object> send(List<String> receviersList,List<String> receviersCcList,String title,String content,ShowType showType){\n+\n+        return MailUtils.sendMails(receviersList, receviersCcList, title, content, showType);\n+    }\n+\n+    /**\n+     * msg send\n+     * @param receviersList the receiver list\n+     * @param title the title\n+     * @param content the content\n+     * @param showType the showType\n+     * @return the send result\n+     */\n+    public Map<String,Object> send(List<String> receviersList,String title,String content,ShowType showType){\n+\n+        return MailUtils.sendMails(receviersList,title, content, showType);\n+    }\n+}",
                "changes": 55
            },
            {
                "status": "added",
                "additions": 59,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EnterpriseWeChatManager.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EnterpriseWeChatManager.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EnterpriseWeChatManager.java",
                "deletions": 0,
                "sha": "510d73b9f78dbaa95093608955cfaee25ab43537",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EnterpriseWeChatManager.java",
                "patch": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.manager;\n+\n+import org.apache.dolphinscheduler.alert.utils.Constants;\n+import org.apache.dolphinscheduler.alert.utils.EnterpriseWeChatUtils;\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Enterprise WeChat Manager\n+ */\n+public class EnterpriseWeChatManager {\n+    private static final Logger logger = LoggerFactory.getLogger(MsgManager.class);\n+    /**\n+     * Enterprise We Chat send\n+     * @param alert the alert\n+     * @param token the token\n+     * @return the send result\n+     */\n+    public Map<String,Object> send(Alert alert, String token){\n+        Map<String,Object> retMap = new HashMap<>();\n+        retMap.put(Constants.STATUS, false);\n+        String agentId = EnterpriseWeChatUtils.enterpriseWeChatAgentId;\n+        String users = EnterpriseWeChatUtils.enterpriseWeChatUsers;\n+        List<String> userList = Arrays.asList(users.split(\",\"));\n+        logger.info(\"send message {}\",alert);\n+        String msg = EnterpriseWeChatUtils.makeUserSendMsg(userList, agentId,EnterpriseWeChatUtils.markdownByAlert(alert));\n+        try {\n+            EnterpriseWeChatUtils.sendEnterpriseWeChat(Constants.UTF_8, msg, token);\n+        } catch (IOException e) {\n+            logger.error(e.getMessage(),e);\n+        }\n+        retMap.put(Constants.STATUS, true);\n+        return retMap;\n+    }\n+\n+}",
                "changes": 59
            },
            {
                "status": "added",
                "additions": 36,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/MsgManager.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/MsgManager.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/MsgManager.java",
                "deletions": 0,
                "sha": "359492699dfc81816f8b1e86be7f5648ca09fd3d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/MsgManager.java",
                "patch": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.manager;\n+\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * SMS send manager\n+ */\n+public class MsgManager  {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(MsgManager.class);\n+    /**\n+     * SMS send\n+     * @param alert the alert\n+     */\n+    public void send(Alert alert){\n+        logger.info(\"send message {}\",alert);\n+    }\n+}",
                "changes": 36
            },
            {
                "status": "added",
                "additions": 144,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/runner/AlertSender.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/runner/AlertSender.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/runner/AlertSender.java",
                "deletions": 0,
                "sha": "5e0c2545f863ee33cd06ae05aecb95208ace0c7a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/runner/AlertSender.java",
                "patch": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.runner;\n+\n+import org.apache.commons.collections4.CollectionUtils;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.dolphinscheduler.alert.manager.EmailManager;\n+import org.apache.dolphinscheduler.alert.manager.EnterpriseWeChatManager;\n+import org.apache.dolphinscheduler.alert.utils.Constants;\n+import org.apache.dolphinscheduler.alert.utils.EnterpriseWeChatUtils;\n+import org.apache.dolphinscheduler.common.enums.AlertStatus;\n+import org.apache.dolphinscheduler.common.enums.AlertType;\n+import org.apache.dolphinscheduler.dao.AlertDao;\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * alert sender\n+ */\n+public class AlertSender{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(AlertSender.class);\n+\n+    private static final EmailManager emailManager= new EmailManager();\n+    private static final EnterpriseWeChatManager weChatManager= new EnterpriseWeChatManager();\n+\n+\n+    private List<Alert> alertList;\n+    private AlertDao alertDao;\n+\n+    public AlertSender(){}\n+    public AlertSender(List<Alert> alertList, AlertDao alertDao){\n+        super();\n+        this.alertList = alertList;\n+        this.alertDao = alertDao;\n+    }\n+\n+    public void run() {\n+\n+        List<User> users;\n+\n+        Map<String, Object> retMaps = null;\n+        for(Alert alert:alertList){\n+            users = alertDao.listUserByAlertgroupId(alert.getAlertGroupId());\n+\n+            // receiving group list\n+            List<String> receviersList = new ArrayList<String>();\n+            for(User user:users){\n+                receviersList.add(user.getEmail());\n+            }\n+            // custom receiver\n+            String receivers = alert.getReceivers();\n+            if (StringUtils.isNotEmpty(receivers)){\n+                String[] splits = receivers.split(\",\");\n+                for (String receiver : splits){\n+                    receviersList.add(receiver);\n+                }\n+            }\n+\n+            // copy list\n+            List<String> receviersCcList = new ArrayList<String>();\n+\n+\n+            // Custom Copier\n+            String receiversCc = alert.getReceiversCc();\n+\n+            if (StringUtils.isNotEmpty(receiversCc)){\n+                String[] splits = receiversCc.split(\",\");\n+                for (String receiverCc : splits){\n+                    receviersCcList.add(receiverCc);\n+                }\n+            }\n+\n+            if (CollectionUtils.isEmpty(receviersList) && CollectionUtils.isEmpty(receviersCcList)) {\n+                logger.warn(\"alert send error : At least one receiver address required\");\n+                alertDao.updateAlert(AlertStatus.EXECUTION_FAILURE, \"execution failure,At least one receiver address required.\", alert.getId());\n+                continue;\n+            }\n+\n+            if (alert.getAlertType() == AlertType.EMAIL){\n+                retMaps = emailManager.send(receviersList,receviersCcList, alert.getTitle(), alert.getContent(),alert.getShowType());\n+\n+                alert.setInfo(retMaps);\n+            }else if (alert.getAlertType() == AlertType.SMS){\n+                retMaps = emailManager.send(getReciversForSMS(users), alert.getTitle(), alert.getContent(),alert.getShowType());\n+                alert.setInfo(retMaps);\n+            }\n+\n+            boolean flag = Boolean.parseBoolean(String.valueOf(retMaps.get(Constants.STATUS)));\n+            if (flag) {\n+                alertDao.updateAlert(AlertStatus.EXECUTION_SUCCESS, \"execution success\", alert.getId());\n+                logger.info(\"alert send success\");\n+                if (EnterpriseWeChatUtils.isEnable()) {\n+                    logger.info(\"Enterprise WeChat is enable!\");\n+                    try {\n+                        String token = EnterpriseWeChatUtils.getToken();\n+                        weChatManager.send(alert, token);\n+                    } catch (Exception e) {\n+                        logger.error(e.getMessage(), e);\n+                    }\n+                }\n+\n+            } else {\n+                alertDao.updateAlert(AlertStatus.EXECUTION_FAILURE, String.valueOf(retMaps.get(Constants.MESSAGE)), alert.getId());\n+                logger.info(\"alert send error : {}\", String.valueOf(retMaps.get(Constants.MESSAGE)));\n+            }\n+        }\n+\n+    }\n+\n+\n+    /**\n+     * get a list of SMS users\n+     * @param users\n+     * @return\n+     */\n+    private List<String> getReciversForSMS(List<User> users){\n+        List<String> list = new ArrayList<>();\n+        for (User user : users){\n+            list.add(user.getPhone());\n+        }\n+        return list;\n+    }\n+}",
                "changes": 144
            },
            {
                "status": "added",
                "additions": 159,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/Constants.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/Constants.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/Constants.java",
                "deletions": 0,
                "sha": "665aac246ff199e37ccfb6dab216da66527df66a",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/Constants.java",
                "patch": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+/**\n+ * constants\n+ */\n+public class Constants {\n+\n+    /**\n+     * alert properties path\n+     */\n+    public static final String ALERT_PROPERTIES_PATH = \"/alert.properties\";\n+\n+    public static final String DATA_SOURCE_PROPERTIES_PATH = \"/dao/data_source.properties\";\n+\n+    public static final String SINGLE_SLASH = \"/\";\n+\n+    /**\n+     * UTF-8\n+     */\n+    public static final String UTF_8 = \"UTF-8\";\n+\n+    public static final String STATUS = \"status\";\n+\n+    public static final String MESSAGE = \"message\";\n+\n+    public static final String MAIL_PROTOCOL = \"mail.protocol\";\n+\n+    public static final String MAIL_SERVER_HOST = \"mail.server.host\";\n+\n+    public static final String MAIL_SERVER_PORT = \"mail.server.port\";\n+\n+    public static final String MAIL_SENDER = \"mail.sender\";\n+\n+    public static final String MAIL_USER = \"mail.user\";\n+\n+    public static final String MAIL_PASSWD = \"mail.passwd\";\n+\n+    public static final String XLS_FILE_PATH = \"xls.file.path\";\n+\n+    public static final String MAIL_HOST = \"mail.smtp.host\";\n+\n+    public static final String MAIL_PORT = \"mail.smtp.port\";\n+\n+    public static final String MAIL_SMTP_AUTH = \"mail.smtp.auth\";\n+\n+    public static final String MAIL_TRANSPORT_PROTOCOL = \"mail.transport.protocol\";\n+\n+    public static final String MAIL_SMTP_STARTTLS_ENABLE = \"mail.smtp.starttls.enable\";\n+\n+    public static final String MAIL_SMTP_SSL_ENABLE = \"mail.smtp.ssl.enable\";\n+\n+    public static final String MAIL_SMTP_SSL_TRUST=\"mail.smtp.ssl.trust\";\n+\n+    public static final String TEXT_HTML_CHARSET_UTF_8 = \"text/html;charset=utf-8\";\n+\n+    public static final String STRING_TRUE = \"true\";\n+\n+    public static final String EXCEL_SUFFIX_XLS = \".xls\";\n+\n+    public static final int NUMBER_1000 = 1000;\n+\n+    public static final String SPRING_DATASOURCE_DRIVER_CLASS_NAME = \"spring.datasource.driver-class-name\";\n+\n+    public static final String SPRING_DATASOURCE_URL = \"spring.datasource.url\";\n+\n+    public static final String SPRING_DATASOURCE_USERNAME = \"spring.datasource.username\";\n+\n+    public static final String SPRING_DATASOURCE_PASSWORD = \"spring.datasource.password\";\n+\n+    public static final String SPRING_DATASOURCE_VALIDATION_QUERY_TIMEOUT = \"spring.datasource.validationQueryTimeout\";\n+\n+    public static final String SPRING_DATASOURCE_INITIAL_SIZE = \"spring.datasource.initialSize\";\n+\n+    public static final String SPRING_DATASOURCE_MIN_IDLE = \"spring.datasource.minIdle\";\n+\n+    public static final String SPRING_DATASOURCE_MAX_ACTIVE = \"spring.datasource.maxActive\";\n+\n+    public static final String SPRING_DATASOURCE_MAX_WAIT = \"spring.datasource.maxWait\";\n+\n+    public static final String SPRING_DATASOURCE_TIME_BETWEEN_EVICTION_RUNS_MILLIS = \"spring.datasource.timeBetweenEvictionRunsMillis\";\n+\n+    public static final String SPRING_DATASOURCE_MIN_EVICTABLE_IDLE_TIME_MILLIS = \"spring.datasource.minEvictableIdleTimeMillis\";\n+\n+    public static final String SPRING_DATASOURCE_VALIDATION_QUERY = \"spring.datasource.validationQuery\";\n+\n+    public static final String SPRING_DATASOURCE_TEST_WHILE_IDLE = \"spring.datasource.testWhileIdle\";\n+\n+    public static final String SPRING_DATASOURCE_TEST_ON_BORROW = \"spring.datasource.testOnBorrow\";\n+\n+    public static final String SPRING_DATASOURCE_TEST_ON_RETURN = \"spring.datasource.testOnReturn\";\n+\n+    public static final String SPRING_DATASOURCE_POOL_PREPARED_STATEMENTS = \"spring.datasource.poolPreparedStatements\";\n+\n+    public static final String SPRING_DATASOURCE_DEFAULT_AUTO_COMMIT = \"spring.datasource.defaultAutoCommit\";\n+\n+    public static final String SPRING_DATASOURCE_KEEP_ALIVE = \"spring.datasource.keepAlive\";\n+\n+    public static final String SPRING_DATASOURCE_MAX_POOL_PREPARED_STATEMENT_PER_CONNECTION_SIZE = \"spring.datasource.maxPoolPreparedStatementPerConnectionSize\";\n+\n+    public static final String DEVELOPMENT = \"development\";\n+\n+    public static final String CLASSPATH_MAIL_TEMPLATES_ALERT_MAIL_TEMPLATE_FTL = \"classpath:mail_templates/alert_mail_template.ftl\";\n+\n+    public static final String TR = \"<tr>\";\n+\n+    public static final String TD = \"<td>\";\n+\n+    public static final String TD_END = \"</td>\";\n+\n+    public static final String TR_END = \"</tr>\";\n+\n+    public static final String TITLE = \"title\";\n+\n+    public static final String CONTENT = \"content\";\n+\n+    public static final String TH = \"<th>\";\n+\n+    public static final String TH_END = \"</th>\";\n+\n+    public static final int ALERT_SCAN_INTERVEL = 5000;\n+\n+    public static final String MARKDOWN_QUOTE = \">\";\n+\n+    public static final String MARKDOWN_ENTER = \"\\n\";\n+\n+    public static final String ENTERPRISE_WECHAT_ENABLE = \"enterprise.wechat.enable\";\n+\n+    public static final String ENTERPRISE_WECHAT_CORP_ID = \"enterprise.wechat.corp.id\";\n+\n+    public static final String ENTERPRISE_WECHAT_SECRET = \"enterprise.wechat.secret\";\n+\n+    public static final String ENTERPRISE_WECHAT_TOKEN_URL = \"enterprise.wechat.token.url\";\n+\n+    public static final String ENTERPRISE_WECHAT_PUSH_URL = \"enterprise.wechat.push.url\";\n+\n+    public static final String ENTERPRISE_WECHAT_TEAM_SEND_MSG = \"enterprise.wechat.team.send.msg\";\n+\n+    public static final String ENTERPRISE_WECHAT_USER_SEND_MSG = \"enterprise.wechat.user.send.msg\";\n+\n+    public static final String ENTERPRISE_WECHAT_AGENT_ID = \"enterprise.wechat.agent.id\";\n+\n+    public static final String ENTERPRISE_WECHAT_USERS = \"enterprise.wechat.users\";\n+}",
                "changes": 159
            },
            {
                "status": "added",
                "additions": 261,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java",
                "deletions": 0,
                "sha": "a11d37f3d3ad0e3d4e85e35a8375391cd6d082c6",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java",
                "patch": "@@ -0,0 +1,261 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import org.apache.dolphinscheduler.common.enums.ShowType;\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import com.alibaba.fastjson.JSON;\n+\n+import com.google.common.reflect.TypeToken;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.http.util.EntityUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.*;\n+\n+/**\n+ * Enterprise WeChat utils\n+ */\n+public class EnterpriseWeChatUtils {\n+\n+    public static final Logger logger = LoggerFactory.getLogger(EnterpriseWeChatUtils.class);\n+\n+    private static final String enterpriseWeChatCorpId = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_CORP_ID);\n+\n+    private static final String enterpriseWeChatSecret = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_SECRET);\n+\n+    private static final String enterpriseWeChatTokenUrl = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_TOKEN_URL);\n+    private static String enterpriseWeChatTokenUrlReplace = enterpriseWeChatTokenUrl\n+            .replaceAll(\"\\\\$corpId\", enterpriseWeChatCorpId)\n+            .replaceAll(\"\\\\$secret\", enterpriseWeChatSecret);\n+\n+    private static final String enterpriseWeChatPushUrl = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_PUSH_URL);\n+\n+    private static final String enterpriseWeChatTeamSendMsg = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_TEAM_SEND_MSG);\n+\n+    private static final String enterpriseWeChatUserSendMsg = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_USER_SEND_MSG);\n+\n+    public static final String enterpriseWeChatAgentId = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_AGENT_ID);\n+\n+    public static final String enterpriseWeChatUsers = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_USERS);\n+\n+    /**\n+     * get Enterprise WeChat is enable\n+     * @return isEnable\n+     */\n+    public static Boolean isEnable(){\n+        Boolean isEnable = false;\n+        try {\n+            isEnable = PropertyUtils.getBoolean(Constants.ENTERPRISE_WECHAT_ENABLE);\n+        } catch (Exception e) {\n+            logger.error(e.getMessage(),e);\n+        }\n+        return isEnable;\n+\n+    }\n+\n+    /**\n+     * get Enterprise WeChat token info\n+     * @return token string info\n+     * @throws IOException the IOException\n+     */\n+    public static String getToken() throws IOException {\n+        String resp;\n+\n+        CloseableHttpClient httpClient = HttpClients.createDefault();\n+        HttpGet httpGet = new HttpGet(enterpriseWeChatTokenUrlReplace);\n+        CloseableHttpResponse response = httpClient.execute(httpGet);\n+        try {\n+            HttpEntity entity = response.getEntity();\n+            resp = EntityUtils.toString(entity, Constants.UTF_8);\n+            EntityUtils.consume(entity);\n+        } finally {\n+            response.close();\n+        }\n+\n+        Map<String, Object> map = JSON.parseObject(resp,\n+                new TypeToken<Map<String, Object>>() {\n+                }.getType());\n+        return map.get(\"access_token\").toString();\n+    }\n+\n+    /**\n+     * make team single Enterprise WeChat message\n+     * @param toParty the toParty\n+     * @param agentId the agentId\n+     * @param msg the msg\n+     * @return Enterprise WeChat send message\n+     */\n+    public static String makeTeamSendMsg(String toParty, String agentId, String msg) {\n+        return enterpriseWeChatTeamSendMsg.replaceAll(\"\\\\$toParty\", toParty)\n+                .replaceAll(\"\\\\$agentId\", agentId)\n+                .replaceAll(\"\\\\$msg\", msg);\n+    }\n+\n+    /**\n+     * make team multi Enterprise WeChat message\n+     * @param toParty the toParty\n+     * @param agentId the agentId\n+     * @param msg the msg\n+     * @return Enterprise WeChat send message\n+     */\n+    public static String makeTeamSendMsg(Collection<String> toParty, String agentId, String msg) {\n+        String listParty = FuncUtils.mkString(toParty, \"|\");\n+        return enterpriseWeChatTeamSendMsg.replaceAll(\"\\\\$toParty\", listParty)\n+                .replaceAll(\"\\\\$agentId\", agentId)\n+                .replaceAll(\"\\\\$msg\", msg);\n+    }\n+\n+    /**\n+     * make team single user message\n+     * @param toUser the toUser\n+     * @param agentId the agentId\n+     * @param msg the msg\n+     * @return Enterprise WeChat send message\n+     */\n+    public static String makeUserSendMsg(String toUser, String agentId, String msg) {\n+        return enterpriseWeChatUserSendMsg.replaceAll(\"\\\\$toUser\", toUser)\n+                .replaceAll(\"\\\\$agentId\", agentId)\n+                .replaceAll(\"\\\\$msg\", msg);\n+    }\n+\n+    /**\n+     * make team multi user message\n+     * @param toUser the toUser\n+     * @param agentId the agentId\n+     * @param msg the msg\n+     * @return Enterprise WeChat send message\n+     */\n+    public static String makeUserSendMsg(Collection<String> toUser, String agentId, String msg) {\n+        String listUser = FuncUtils.mkString(toUser, \"|\");\n+        return enterpriseWeChatUserSendMsg.replaceAll(\"\\\\$toUser\", listUser)\n+                .replaceAll(\"\\\\$agentId\", agentId)\n+                .replaceAll(\"\\\\$msg\", msg);\n+    }\n+\n+    /**\n+     * send Enterprise WeChat\n+     * @param charset the charset\n+     * @param data the data\n+     * @param token the token\n+     * @return Enterprise WeChat resp, demo: {\"errcode\":0,\"errmsg\":\"ok\",\"invaliduser\":\"\"}\n+     * @throws IOException the IOException\n+     */\n+    public static String sendEnterpriseWeChat(String charset, String data, String token) throws IOException {\n+        String enterpriseWeChatPushUrlReplace = enterpriseWeChatPushUrl.replaceAll(\"\\\\$token\", token);\n+\n+        CloseableHttpClient httpclient = HttpClients.createDefault();\n+        HttpPost httpPost = new HttpPost(enterpriseWeChatPushUrlReplace);\n+        httpPost.setEntity(new StringEntity(data, charset));\n+        CloseableHttpResponse response = httpclient.execute(httpPost);\n+        String resp;\n+        try {\n+            HttpEntity entity = response.getEntity();\n+            resp = EntityUtils.toString(entity, charset);\n+            EntityUtils.consume(entity);\n+        } finally {\n+            response.close();\n+        }\n+        logger.info(\"Enterprise WeChat send [{}], param:{}, resp:{}\", enterpriseWeChatPushUrl, data, resp);\n+        return resp;\n+    }\n+\n+    /**\n+     * convert table to markdown style\n+     * @param title the title\n+     * @param content the content\n+     * @return markdown table content\n+     */\n+    public static String markdownTable(String title,String content){\n+        List<LinkedHashMap> mapItemsList = JSONUtils.toList(content, LinkedHashMap.class);\n+        StringBuilder contents = new StringBuilder(200);\n+        for (LinkedHashMap mapItems : mapItemsList){\n+\n+            Set<Map.Entry<String, String>> entries = mapItems.entrySet();\n+\n+            Iterator<Map.Entry<String, String>> iterator = entries.iterator();\n+\n+            StringBuilder t = new StringBuilder(String.format(\"`%s`%s\",title,Constants.MARKDOWN_ENTER));\n+            while (iterator.hasNext()){\n+\n+                Map.Entry<String, String> entry = iterator.next();\n+                t.append(Constants.MARKDOWN_QUOTE);\n+                t.append(entry.getKey()).append(\":\").append(entry.getValue());\n+                t.append(Constants.MARKDOWN_ENTER);\n+            }\n+\n+            contents.append(t);\n+        }\n+        return contents.toString();\n+    }\n+\n+    /**\n+     * convert text to markdown style\n+     * @param title the title\n+     * @param content the content\n+     * @return markdown text\n+     */\n+    public static String markdownText(String title,String content){\n+        if (StringUtils.isNotEmpty(content)){\n+            List<String> list;\n+            try {\n+                list = JSONUtils.toList(content,String.class);\n+            }catch (Exception e){\n+                logger.error(\"json format exception\",e);\n+                return null;\n+            }\n+\n+            StringBuilder contents = new StringBuilder(100);\n+            contents.append(String.format(\"`%s`%n\",title));\n+            for (String str : list){\n+                contents.append(Constants.MARKDOWN_QUOTE);\n+                contents.append(str);\n+                contents.append(Constants.MARKDOWN_ENTER);\n+            }\n+\n+            return contents.toString();\n+\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Determine the mardown style based on the show type of the alert\n+     * @param alert the alert\n+     * @return the markdown alert table/text\n+     */\n+    public static String markdownByAlert(Alert alert){\n+        String result = \"\";\n+        if (alert.getShowType() == ShowType.TABLE) {\n+            result = markdownTable(alert.getTitle(),alert.getContent());\n+        }else if(alert.getShowType() == ShowType.TEXT){\n+            result = markdownText(alert.getTitle(),alert.getContent());\n+        }\n+        return result;\n+\n+    }\n+\n+}",
                "changes": 261
            },
            {
                "status": "added",
                "additions": 129,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/ExcelUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/ExcelUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/ExcelUtils.java",
                "deletions": 0,
                "sha": "522a1b951364b22a06e53eae90d1e2fb172b36fd",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/ExcelUtils.java",
                "patch": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import org.apache.poi.hssf.usermodel.HSSFCell;\n+import org.apache.poi.hssf.usermodel.HSSFRow;\n+import org.apache.poi.hssf.usermodel.HSSFSheet;\n+import org.apache.poi.hssf.usermodel.HSSFWorkbook;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.util.*;\n+\n+/**\n+ * excel utils\n+ */\n+public class ExcelUtils {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ExcelUtils.class);\n+    /**\n+     * generate excel file\n+     * @param content the content\n+     * @param title the title\n+     * @param xlsFilePath the xls path\n+     */\n+    public static void genExcelFile(String content,String title,String xlsFilePath){\n+        List<LinkedHashMap> itemsList;\n+        try {\n+            itemsList = JSONUtils.toList(content, LinkedHashMap.class);\n+        }catch (Exception e){\n+            logger.error(String.format(\"json format incorrect : %s\",content),e);\n+            throw new RuntimeException(\"json format incorrect\",e);\n+        }\n+\n+        if (itemsList == null || itemsList.size() == 0){\n+            logger.error(\"itemsList is null\");\n+            throw new RuntimeException(\"itemsList is null\");\n+        }\n+\n+        LinkedHashMap<String, Object> headerMap = itemsList.get(0);\n+\n+        List<String> headerList = new ArrayList<>();\n+\n+        Iterator<Map.Entry<String, Object>> iter = headerMap.entrySet().iterator();\n+        while (iter.hasNext()){\n+            Map.Entry<String, Object> en = iter.next();\n+            headerList.add(en.getKey());\n+        }\n+\n+        HSSFWorkbook wb = null;\n+        FileOutputStream fos = null;\n+           try {\n+               // declare a workbook\n+               wb = new HSSFWorkbook();\n+               // generate a table\n+               HSSFSheet sheet = wb.createSheet();\n+               HSSFRow row = sheet.createRow(0);\n+               //set the height of the first line\n+               row.setHeight((short)500);\n+\n+\n+               //setting excel headers\n+               for (int i = 0; i < headerList.size(); i++) {\n+                   HSSFCell cell = row.createCell(i);\n+                   cell.setCellValue(headerList.get(i));\n+               }\n+\n+               //setting excel body\n+               int rowIndex = 1;\n+               for (LinkedHashMap<String, Object> itemsMap : itemsList){\n+                   Object[] values = itemsMap.values().toArray();\n+                   row = sheet.createRow(rowIndex);\n+                   //setting excel body height\n+                   row.setHeight((short)500);\n+                   rowIndex++;\n+                   for (int j = 0 ; j < values.length ; j++){\n+                       HSSFCell cell1 = row.createCell(j);\n+                       cell1.setCellValue(String.valueOf(values[j]));\n+                   }\n+               }\n+\n+               for (int i = 0; i < headerList.size(); i++) {\n+                   sheet.setColumnWidth(i, headerList.get(i).length() * 800);\n+\n+               }\n+\n+               //setting file output\n+               fos = new FileOutputStream(xlsFilePath + Constants.SINGLE_SLASH + title + Constants.EXCEL_SUFFIX_XLS);\n+\n+               wb.write(fos);\n+\n+           }catch (Exception e){\n+               logger.error(\"generate excel error\",e);\n+               throw new RuntimeException(\"generate excel error\",e);\n+           }finally {\n+               if (wb != null){\n+                   try {\n+                       wb.close();\n+                   } catch (IOException e) {\n+                       logger.error(e.getMessage(),e);\n+                   }\n+               }\n+               if (fos != null){\n+                   try {\n+                       fos.close();\n+                   } catch (IOException e) {\n+                       logger.error(e.getMessage(),e);\n+                   }\n+               }\n+           }\n+    }\n+\n+}",
                "changes": 129
            },
            {
                "status": "added",
                "additions": 35,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/FuncUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/FuncUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/FuncUtils.java",
                "deletions": 0,
                "sha": "e682fde2e7dac4aeab2324a77000531dcceff0e6",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/FuncUtils.java",
                "patch": "@@ -0,0 +1,35 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+public class FuncUtils {\n+\n+    static public String mkString(Iterable<String> list, String split) {\n+        StringBuilder sb = new StringBuilder();\n+        boolean first = true;\n+        for (String item : list) {\n+            if (first) {\n+                first = false;\n+            } else {\n+                sb.append(split);\n+            }\n+            sb.append(item);\n+        }\n+        return sb.toString();\n+    }\n+\n+}",
                "changes": 35
            },
            {
                "status": "added",
                "additions": 68,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/JSONUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/JSONUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/JSONUtils.java",
                "deletions": 0,
                "sha": "a88574f0e79b570d68e22187bf0bdcde8ee3380e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/JSONUtils.java",
                "patch": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import com.alibaba.fastjson.JSONArray;\n+import com.alibaba.fastjson.JSONObject;\n+import org.apache.commons.lang3.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+\n+/**\n+ * json utils\n+ */\n+public class JSONUtils {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(JSONUtils.class);\n+\n+  /**\n+   * object to json string\n+   * @param object the object to be converted to json\n+   * @return json string\n+   */\n+  public static String toJsonString(Object object) {\n+    try{\n+      return JSONObject.toJSONString(object,false);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Json deserialization exception.\", e);\n+    }\n+  }\n+\n+  /**\n+   * json to list\n+   *\n+   * @param json the json\n+   * @param clazz c\n+   * @param <T> the generic clazz\n+   * @return the result list\n+   */\n+  public static <T> List<T> toList(String json, Class<T> clazz) {\n+    if (StringUtils.isEmpty(json)) {\n+      return null;\n+    }\n+    try {\n+      return JSONArray.parseArray(json, clazz);\n+    } catch (Exception e) {\n+      logger.error(\"JSONArray.parseArray exception!\",e);\n+    }\n+\n+    return null;\n+  }\n+\n+}",
                "changes": 68
            },
            {
                "status": "added",
                "additions": 453,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/MailUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/MailUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/MailUtils.java",
                "deletions": 0,
                "sha": "d6edde240b9321876501c4d502fe7867f82c9b55",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/MailUtils.java",
                "patch": "@@ -0,0 +1,453 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import org.apache.dolphinscheduler.common.enums.ShowType;\n+import freemarker.cache.StringTemplateLoader;\n+import freemarker.template.Configuration;\n+import freemarker.template.Template;\n+import freemarker.template.TemplateException;\n+import org.apache.commons.collections4.CollectionUtils;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.mail.EmailException;\n+import org.apache.commons.mail.HtmlEmail;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.util.ResourceUtils;\n+\n+import javax.mail.*;\n+import javax.mail.internet.*;\n+import java.io.*;\n+import java.util.*;\n+\n+import static org.apache.dolphinscheduler.alert.utils.PropertyUtils.getInt;\n+\n+\n+/**\n+ * mail utils\n+ */\n+public class MailUtils {\n+\n+    public static final Logger logger = LoggerFactory.getLogger(MailUtils.class);\n+\n+    public static final String mailProtocol = PropertyUtils.getString(Constants.MAIL_PROTOCOL);\n+\n+    public static final String mailServerHost = PropertyUtils.getString(Constants.MAIL_SERVER_HOST);\n+\n+    public static final Integer mailServerPort = PropertyUtils.getInt(Constants.MAIL_SERVER_PORT);\n+\n+    public static final String mailSender = PropertyUtils.getString(Constants.MAIL_SENDER);\n+\n+    public static final String mailUser = PropertyUtils.getString(Constants.MAIL_USER);\n+\n+    public static final String mailPasswd = PropertyUtils.getString(Constants.MAIL_PASSWD);\n+\n+    public static final Boolean mailUseStartTLS = PropertyUtils.getBoolean(Constants.MAIL_SMTP_STARTTLS_ENABLE);\n+\n+    public static final Boolean mailUseSSL = PropertyUtils.getBoolean(Constants.MAIL_SMTP_SSL_ENABLE);\n+\n+    public static final String xlsFilePath = PropertyUtils.getString(Constants.XLS_FILE_PATH);\n+\n+    public static final String starttlsEnable = PropertyUtils.getString(Constants.MAIL_SMTP_STARTTLS_ENABLE);\n+\n+    public static final String sslEnable = PropertyUtils.getString(Constants.MAIL_SMTP_SSL_ENABLE);\n+\n+    public static final String sslTrust = PropertyUtils.getString(Constants.MAIL_SMTP_SSL_TRUST);\n+\n+    private static Template MAIL_TEMPLATE;\n+\n+    static {\n+        Configuration cfg = new Configuration(Configuration.VERSION_2_3_21);\n+        cfg.setDefaultEncoding(Constants.UTF_8);\n+        StringTemplateLoader stringTemplateLoader = new StringTemplateLoader();\n+        cfg.setTemplateLoader(stringTemplateLoader);\n+        InputStreamReader isr = null;\n+        try {\n+            isr = new InputStreamReader(new FileInputStream(ResourceUtils.getFile(Constants.CLASSPATH_MAIL_TEMPLATES_ALERT_MAIL_TEMPLATE_FTL)),\n+                    Constants.UTF_8);\n+\n+            MAIL_TEMPLATE = new Template(\"alert_mail_template\", isr, cfg);\n+        } catch (Exception e) {\n+            MAIL_TEMPLATE = null;\n+        } finally {\n+            IOUtils.closeQuietly(isr);\n+        }\n+    }\n+\n+\n+    /**\n+     * send mail to receivers\n+     * @param receivers the receiver list\n+     * @param title the title\n+     * @param content the content\n+     * @param showType the show type\n+     * @return the result map\n+     */\n+    public static Map<String,Object> sendMails(Collection<String> receivers, String title, String content,ShowType showType) {\n+        return sendMails(receivers, null, title, content, showType);\n+    }\n+\n+    /**\n+     * send mail\n+     * @param receivers the receiver list\n+     * @param receiversCc cc list\n+     * @param title the title\n+     * @param content the content\n+     * @param showType the show type\n+     * @return the send result\n+     */\n+    public static Map<String,Object> sendMails(Collection<String> receivers, Collection<String> receiversCc, String title, String content, ShowType showType) {\n+        Map<String,Object> retMap = new HashMap<>();\n+        retMap.put(Constants.STATUS, false);\n+        \n+        // if there is no receivers && no receiversCc, no need to process\n+        if (CollectionUtils.isEmpty(receivers) && CollectionUtils.isEmpty(receiversCc)) {\n+            return retMap;\n+        }\n+\n+        receivers.removeIf((from) -> (StringUtils.isEmpty(from)));\n+        \n+        if (showType == ShowType.TABLE || showType == ShowType.TEXT){\n+            // send email\n+            HtmlEmail email = new HtmlEmail();\n+\n+            try {\n+                Session session = getSession();\n+                email.setMailSession(session);\n+                email.setFrom(mailSender);\n+                email.setCharset(Constants.UTF_8);\n+                if (CollectionUtils.isNotEmpty(receivers)){\n+                    // receivers mail\n+                    for (String receiver : receivers) {\n+                        email.addTo(receiver);\n+                    }\n+                }\n+\n+                if (CollectionUtils.isNotEmpty(receiversCc)){\n+                    //cc\n+                    for (String receiverCc : receiversCc) {\n+                        email.addCc(receiverCc);\n+                    }\n+                }\n+                // sender mail\n+                return getStringObjectMap(title, content, showType, retMap, email);\n+            } catch (Exception e) {\n+                handleException(receivers, retMap, e);\n+            }\n+        }else if (showType == ShowType.ATTACHMENT || showType == ShowType.TABLEATTACHMENT){\n+            try {\n+\n+                String partContent = (showType == ShowType.ATTACHMENT ? \"Please see the attachment \" + title + Constants.EXCEL_SUFFIX_XLS : htmlTable(content,false));\n+\n+                attachment(receivers,receiversCc,title,content,partContent);\n+\n+                retMap.put(Constants.STATUS, true);\n+                return retMap;\n+            }catch (Exception e){\n+                handleException(receivers, retMap, e);\n+                return retMap;\n+            }\n+        }\n+        return retMap;\n+\n+    }\n+\n+    /**\n+     * html table content\n+     * @param content the content\n+     * @param showAll if show the whole content\n+     * @return the html table form\n+     */\n+    private static String htmlTable(String content, boolean showAll){\n+        if (StringUtils.isNotEmpty(content)){\n+            List<LinkedHashMap> mapItemsList = JSONUtils.toList(content, LinkedHashMap.class);\n+\n+            if(!showAll && mapItemsList.size() > Constants.NUMBER_1000){\n+                mapItemsList = mapItemsList.subList(0,Constants.NUMBER_1000);\n+            }\n+\n+            StringBuilder contents = new StringBuilder(200);\n+\n+            boolean flag = true;\n+\n+            String title = \"\";\n+            for (LinkedHashMap mapItems : mapItemsList){\n+\n+                Set<Map.Entry<String, Object>> entries = mapItems.entrySet();\n+\n+                Iterator<Map.Entry<String, Object>> iterator = entries.iterator();\n+\n+                StringBuilder t = new StringBuilder(Constants.TR);\n+                StringBuilder cs = new StringBuilder(Constants.TR);\n+                while (iterator.hasNext()){\n+\n+                    Map.Entry<String, Object> entry = iterator.next();\n+                    t.append(Constants.TH).append(entry.getKey()).append(Constants.TH_END);\n+                    cs.append(Constants.TD).append(String.valueOf(entry.getValue())).append(Constants.TD_END);\n+\n+                }\n+                t.append(Constants.TR_END);\n+                cs.append(Constants.TR_END);\n+                if (flag){\n+                    title = t.toString();\n+                }\n+                flag = false;\n+                contents.append(cs);\n+            }\n+\n+            return getTemplateContent(title,contents.toString());\n+        }\n+\n+        return null;\n+    }\n+\n+    /**\n+     * html table content\n+     * @param content the content\n+     * @return the html table form\n+     */\n+    private static String htmlTable(String content){\n+        return htmlTable(content,true);\n+    }\n+\n+    /**\n+     * html text content\n+     * @param content the content\n+     * @return text in html form\n+     */\n+    private static String htmlText(String content){\n+\n+        if (StringUtils.isNotEmpty(content)){\n+            List<String> list;\n+            try {\n+                list = JSONUtils.toList(content,String.class);\n+            }catch (Exception e){\n+                logger.error(\"json format exception\",e);\n+                return null;\n+            }\n+\n+            StringBuilder contents = new StringBuilder(100);\n+            for (String str : list){\n+                contents.append(Constants.TR);\n+                contents.append(Constants.TD).append(str).append(Constants.TD_END);\n+                contents.append(Constants.TR_END);\n+            }\n+\n+            return getTemplateContent(null,contents.toString());\n+\n+        }\n+\n+        return null;\n+    }\n+\n+\n+\n+\n+    /**\n+     * send mail as Excel attachment\n+     * @param receivers the receiver list\n+     * @param title the title\n+     * @throws Exception\n+     */\n+    private static void attachment(Collection<String> receivers,Collection<String> receiversCc,String title,String content,String partContent)throws Exception{\n+        MimeMessage msg = getMimeMessage(receivers);\n+\n+        attachContent(receiversCc, title, content,partContent, msg);\n+    }\n+\n+    /**\n+     * get MimeMessage\n+     * @param receivers\n+     * @return the MimeMessage\n+     * @throws MessagingException\n+     */\n+    private static MimeMessage getMimeMessage(Collection<String> receivers) throws MessagingException {\n+\n+        // 1. The first step in creating mail: creating session\n+        Session session = getSession();\n+        // Setting debug mode, can be turned off\n+        session.setDebug(false);\n+\n+        // 2. creating mail: Creating a MimeMessage\n+        MimeMessage msg = new MimeMessage(session);\n+        // 3. set sender\n+        msg.setFrom(new InternetAddress(mailSender));\n+        // 4. set receivers\n+        for (String receiver : receivers) {\n+            msg.addRecipients(MimeMessage.RecipientType.TO, InternetAddress.parse(receiver));\n+        }\n+        return msg;\n+    }\n+\n+    /**\n+     * get session\n+     * @return the new Session\n+     */\n+    private static Session getSession() {\n+        Properties props = new Properties();\n+        props.setProperty(Constants.MAIL_HOST, mailServerHost);\n+        props.setProperty(Constants.MAIL_PORT, String.valueOf(mailServerPort));\n+        props.setProperty(Constants.MAIL_SMTP_AUTH, Constants.STRING_TRUE);\n+        props.setProperty(Constants.MAIL_TRANSPORT_PROTOCOL, mailProtocol);\n+        props.setProperty(Constants.MAIL_SMTP_STARTTLS_ENABLE, starttlsEnable);\n+        props.setProperty(Constants.MAIL_SMTP_SSL_ENABLE, sslEnable);\n+        props.setProperty(Constants.MAIL_SMTP_SSL_TRUST, sslTrust);\n+\n+        Authenticator auth = new Authenticator() {\n+            @Override\n+            protected PasswordAuthentication getPasswordAuthentication() {\n+                // mail username and password\n+                return new PasswordAuthentication(mailUser, mailPasswd);\n+            }\n+        };\n+\n+        Session session = Session.getInstance(props, auth);\n+        return session;\n+    }\n+\n+    /**\n+     * attach content\n+     * @param receiversCc the cc list\n+     * @param title the title\n+     * @param content the content\n+     * @param partContent the partContent\n+     * @param msg the message\n+     * @throws MessagingException\n+     * @throws IOException\n+     */\n+    private static void attachContent(Collection<String> receiversCc, String title, String content, String partContent,MimeMessage msg) throws MessagingException, IOException {\n+        /**\n+         * set receiverCc\n+         */\n+        if(CollectionUtils.isNotEmpty(receiversCc)){\n+            for (String receiverCc : receiversCc){\n+                msg.addRecipients(MimeMessage.RecipientType.CC, InternetAddress.parse(receiverCc));\n+            }\n+        }\n+\n+        // set receivers type to cc\n+        // msg.addRecipients(MimeMessage.RecipientType.CC, InternetAddress.parse(propMap.get(\"${CC}\")));\n+        // set subject\n+        msg.setSubject(title);\n+        MimeMultipart partList = new MimeMultipart();\n+        // set signature\n+        MimeBodyPart part1 = new MimeBodyPart();\n+        part1.setContent(partContent, Constants.TEXT_HTML_CHARSET_UTF_8);\n+        // set attach file\n+        MimeBodyPart part2 = new MimeBodyPart();\n+        // make excel file\n+        ExcelUtils.genExcelFile(content,title,xlsFilePath);\n+        File file = new File(xlsFilePath + Constants.SINGLE_SLASH +  title + Constants.EXCEL_SUFFIX_XLS);\n+        part2.attachFile(file);\n+        part2.setFileName(MimeUtility.encodeText(title + Constants.EXCEL_SUFFIX_XLS,Constants.UTF_8,\"B\"));\n+        // add components to collection\n+        partList.addBodyPart(part1);\n+        partList.addBodyPart(part2);\n+        msg.setContent(partList);\n+        // 5. send Transport\n+        Transport.send(msg);\n+        // 6. delete saved file\n+        deleteFile(file);\n+    }\n+\n+    /**\n+     * the string object map\n+     * @param title the title\n+     * @param content the content\n+     * @param showType the showType\n+     * @param retMap the result map\n+     * @param email the email\n+     * @return the result map\n+     * @throws EmailException\n+     */\n+    private static Map<String, Object> getStringObjectMap(String title, String content, ShowType showType, Map<String, Object> retMap, HtmlEmail email) throws EmailException {\n+\n+        /**\n+         * the subject of the message to be sent\n+         */\n+        email.setSubject(title);\n+        /**\n+         * to send information, you can use HTML tags in mail content because of the use of HtmlEmail\n+         */\n+        if (showType == ShowType.TABLE) {\n+            email.setMsg(htmlTable(content));\n+        } else if (showType == ShowType.TEXT) {\n+            email.setMsg(htmlText(content));\n+        }\n+\n+        // send\n+        email.send();\n+\n+        retMap.put(Constants.STATUS, true);\n+\n+        return retMap;\n+    }\n+\n+    /**\n+     * file delete\n+     * @param file the file to delete\n+     */\n+    public static void deleteFile(File file){\n+        if(file.exists()){\n+            if(file.delete()){\n+                logger.info(\"delete success:\"+file.getAbsolutePath()+file.getName());\n+            }else{\n+                logger.info(\"delete fail\"+file.getAbsolutePath()+file.getName());\n+            }\n+        }else{\n+            logger.info(\"file not exists:\"+file.getAbsolutePath()+file.getName());\n+        }\n+    }\n+\n+\n+    /**\n+     * handle exception\n+     * @param receivers the receiver list\n+     * @param retMap the result map\n+     * @param e the exception\n+     */\n+    private static void handleException(Collection<String> receivers, Map<String, Object> retMap, Exception e) {\n+        logger.error(\"Send email to {} failed\", StringUtils.join(\",\", receivers), e);\n+        retMap.put(Constants.MESSAGE, \"Send email to {\" + StringUtils.join(\",\", receivers) + \"} failed\uff0c\" + e.toString());\n+    }\n+\n+    /**\n+     * get the content of the template\n+     * @param title the title\n+     * @param content the content to retrieve\n+     * @return the content in the template or null if exception occurs\n+     */\n+    private static String getTemplateContent(String title,String content){\n+        StringWriter out = new StringWriter();\n+        Map<String,String> map = new HashMap<>();\n+        if(null != title){\n+            map.put(Constants.TITLE,title);\n+        }\n+        map.put(Constants.CONTENT,content);\n+        try {\n+            MAIL_TEMPLATE.process(map, out);\n+            return out.toString();\n+        } catch (TemplateException e) {\n+            logger.error(e.getMessage(),e);\n+        } catch (IOException e) {\n+            logger.error(e.getMessage(),e);\n+        }\n+\n+        return null;\n+    }\n+}",
                "changes": 453
            },
            {
                "status": "added",
                "additions": 188,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/PropertyUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/PropertyUtils.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/PropertyUtils.java",
                "deletions": 0,
                "sha": "954ae23655dd0820b5ffd5a6d3f828e5734758f1",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/PropertyUtils.java",
                "patch": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Properties;\n+\n+import static org.apache.dolphinscheduler.alert.utils.Constants.ALERT_PROPERTIES_PATH;\n+import static org.apache.dolphinscheduler.alert.utils.Constants.DATA_SOURCE_PROPERTIES_PATH;\n+\n+/**\n+ * property utils\n+ * single instance\n+ */\n+public class PropertyUtils {\n+\n+    /**\n+     * logger\n+     */\n+    private static final Logger logger = LoggerFactory.getLogger(PropertyUtils.class);\n+\n+    private static final Properties properties = new Properties();\n+\n+    private static final PropertyUtils propertyUtils = new PropertyUtils();\n+\n+    private PropertyUtils(){\n+        init();\n+    }\n+\n+    private void init(){\n+        String[] propertyFiles = new String[]{ALERT_PROPERTIES_PATH};\n+        for (String fileName : propertyFiles) {\n+            InputStream fis = null;\n+            try {\n+                fis = PropertyUtils.class.getResourceAsStream(fileName);\n+                properties.load(fis);\n+\n+            } catch (IOException e) {\n+                logger.error(e.getMessage(), e);\n+                if (fis != null) {\n+                    IOUtils.closeQuietly(fis);\n+                }\n+                System.exit(1);\n+            } finally {\n+                IOUtils.closeQuietly(fis);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * get property value\n+     * @param key property name\n+     * @return the value\n+     */\n+    public static String getString(String key) {\n+        return properties.getProperty(key);\n+    }\n+\n+    /**\n+     * get property value\n+     *\n+     * @param key property name\n+     * @return  get property int value , if key == null, then return -1\n+     */\n+    public static int getInt(String key) {\n+        return getInt(key, -1);\n+    }\n+\n+    /**\n+     * get int value\n+     * @param key the key\n+     * @param defaultValue the default value\n+     * @return the value related the key or the default value if the key not existed\n+     */\n+    public static int getInt(String key, int defaultValue) {\n+        String value = getString(key);\n+        if (value == null) {\n+            return defaultValue;\n+        }\n+\n+        try {\n+            return Integer.parseInt(value);\n+        } catch (NumberFormatException e) {\n+            logger.info(e.getMessage(),e);\n+        }\n+        return defaultValue;\n+    }\n+\n+    /**\n+     * get property value\n+     * @param key property name\n+     * @return  the boolean result value\n+     */\n+    public static Boolean getBoolean(String key) {\n+        String value = properties.getProperty(key.trim());\n+        if(null != value){\n+            return Boolean.parseBoolean(value);\n+        }\n+\n+        return false;\n+    }\n+\n+    /**\n+     * get long value\n+     * @param key the key\n+     * @return if the value not existed, return -1, or will return the related value\n+     */\n+    public static long getLong(String key) {\n+        return getLong(key,-1);\n+    }\n+\n+    /**\n+     * get long value\n+     * @param key the key\n+     * @param defaultVal the default value\n+     * @return the value related the key or the default value if the key not existed\n+     */\n+    public static long getLong(String key, long defaultVal) {\n+        String val = getString(key);\n+        return val == null ? defaultVal : Long.parseLong(val);\n+    }\n+\n+\n+    /**\n+     * get double value\n+     * @param key the key\n+     * @param defaultVal the default value\n+     * @return the value related the key or the default value if the key not existed\n+     */\n+    public double getDouble(String key, double defaultVal) {\n+        String val = getString(key);\n+        return val == null ? defaultVal : Double.parseDouble(val);\n+    }\n+\n+\n+    /**\n+     *  get array\n+     * @param key       property name\n+     * @param splitStr  separator\n+     * @return the result array\n+     */\n+    public static String[] getArray(String key, String splitStr) {\n+        String value = getString(key);\n+        if (value == null) {\n+            return null;\n+        }\n+        try {\n+            String[] propertyArray = value.split(splitStr);\n+            return propertyArray;\n+        } catch (NumberFormatException e) {\n+            logger.info(e.getMessage(),e);\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * get enum\n+     * @param key the key\n+     * @param type the class type\n+     * @param defaultValue the default value\n+     * @param <T> the generic class type\n+     * @return  get enum value\n+     */\n+    public <T extends Enum<T>> T getEnum(String key, Class<T> type,\n+                                         T defaultValue) {\n+        String val = getString(key);\n+        return val == null ? defaultValue : Enum.valueOf(type, val);\n+    }\n+}",
                "changes": 188
            },
            {
                "status": "added",
                "additions": 50,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/alert.properties",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/resources/alert.properties?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/resources/alert.properties",
                "deletions": 0,
                "sha": "127ab5a91b33c9dbd7991328a6b932c9d1768da7",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/alert.properties",
                "patch": "@@ -0,0 +1,50 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+#alert type is EMAIL/SMS\n+alert.type=EMAIL\n+\n+# mail server configuration\n+mail.protocol=SMTP\n+mail.server.host=xxx.xxx.com\n+mail.server.port=25\n+mail.sender=xxx@xxx.com\n+mail.user=xxx@xxx.com\n+mail.passwd=111111\n+\n+# TLS\n+mail.smtp.starttls.enable=true\n+# SSL\n+mail.smtp.ssl.enable=false\n+mail.smtp.ssl.trust=xxx.xxx.com\n+\n+#xls file path,need create if not exist\n+xls.file.path=/tmp/xls\n+\n+# Enterprise WeChat configuration\n+enterprise.wechat.enable=false\n+enterprise.wechat.corp.id=xxxxxxx\n+enterprise.wechat.secret=xxxxxxx\n+enterprise.wechat.agent.id=xxxxxxx\n+enterprise.wechat.users=xxxxxxx\n+enterprise.wechat.token.url=https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$corpId&corpsecret=$secret\n+enterprise.wechat.push.url=https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$token\n+enterprise.wechat.team.send.msg={\\\"toparty\\\":\\\"$toParty\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"$msg\\\"},\\\"safe\\\":\\\"0\\\"}\n+enterprise.wechat.user.send.msg={\\\"touser\\\":\\\"$toUser\\\",\\\"agentid\\\":\\\"$agentId\\\",\\\"msgtype\\\":\\\"markdown\\\",\\\"markdown\\\":{\\\"content\\\":\\\"$msg\\\"}}\n+\n+\n+",
                "changes": 50
            },
            {
                "status": "added",
                "additions": 49,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/alert_logback.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/resources/alert_logback.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/resources/alert_logback.xml",
                "deletions": 0,
                "sha": "3474df8d2ef43f90c529b6e5d1a92987af7ec04c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/alert_logback.xml",
                "patch": "@@ -0,0 +1,49 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->\n+<configuration scan=\"true\" scanPeriod=\"120 seconds\"> <!--debug=\"true\" -->\n+\t<property name=\"log.base\" value=\"logs\" />\n+\t<appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<appender name=\"ALERTLOGFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n+\t\t<file>${log.base}/dolphinscheduler-alert.log</file>\n+\t\t<rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n+\t\t\t<fileNamePattern>${log.base}/dolphinscheduler-alert.%d{yyyy-MM-dd_HH}.%i.log</fileNamePattern>\n+\t\t\t<maxHistory>20</maxHistory>\n+\t\t\t<maxFileSize>64MB</maxFileSize>\n+\t\t</rollingPolicy>\n+\t\t<encoder>\n+\t\t\t<pattern>\n+\t\t\t\t[%level] %date{yyyy-MM-dd HH:mm:ss.SSS} %logger{96}:[%line] - %msg%n\n+\t\t\t</pattern>\n+\t\t\t<charset>UTF-8</charset>\n+\t\t</encoder>\n+\t</appender>\n+\n+\t<root level=\"INFO\">\n+\t\t<appender-ref ref=\"ALERTLOGFILE\"/>\n+\t</root>\n+</configuration>\n\\ No newline at end of file",
                "changes": 49
            },
            {
                "status": "added",
                "additions": 17,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/mail_templates/alert_mail_template.ftl",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/main/resources/mail_templates/alert_mail_template.ftl?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/main/resources/mail_templates/alert_mail_template.ftl",
                "deletions": 0,
                "sha": "c63860909065211ffc15cb230ba02b7ce4ff3b7c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/main/resources/mail_templates/alert_mail_template.ftl",
                "patch": "@@ -0,0 +1,17 @@\n+<#--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+-->\n+<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'><html><head><title> dolphinscheduler</title><meta name='Keywords' content=''><meta name='Description' content=''><style type=\"text/css\">table {            margin-top:0px;            padding-top:0px;            border:1px solid;            font-size: 14px;            color: #333333;            border-width: 1px;            border-color: #666666;            border-collapse: collapse;        }        table th {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #dedede;        }        table td {            border-width: 1px;            padding: 8px;            border-style: solid;            border-color: #666666;            background-color: #ffffff;        }</style></head><body style=\"margin:0;padding:0\"><table border=\"1px\" cellpadding=\"5px\" cellspacing=\"-10px\"><thead><#if title??> ${title}</#if></thead><#if content??> ${content}</#if></table></body></html>\n\\ No newline at end of file",
                "changes": 17
            },
            {
                "status": "added",
                "additions": 119,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtilsTest.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtilsTest.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtilsTest.java",
                "deletions": 0,
                "sha": "3471f6efdd690cadcfbae97ecd0810809569ede8",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtilsTest.java",
                "patch": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+import com.alibaba.fastjson.JSON;\n+import org.junit.Assert;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+\n+/**\n+ * Please manually modify the configuration file before testing.\n+ * file: alert.properties\n+ *   enterprise.wechat.corp.id\n+ *   enterprise.wechat.secret\n+ *   enterprise.wechat.token.url\n+ *   enterprise.wechat.push.url\n+ *   enterprise.wechat.send.msg\n+ *   enterprise.wechat.agent.id\n+ *   enterprise.wechat.users\n+ */\n+@Ignore\n+public class EnterpriseWeChatUtilsTest {\n+\n+    private String agentId = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_AGENT_ID); // app id\n+    private Collection<String> listUserId = Arrays.asList(PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_USERS).split(\",\"));\n+\n+    // Please change\n+    private String partyId = \"2\";\n+    private Collection<String> listPartyId = Arrays.asList(\"2\",\"4\");\n+    @Test\n+    public void testSendSingleTeamWeChat() {\n+        try {\n+            String token = EnterpriseWeChatUtils.getToken();\n+            String msg = EnterpriseWeChatUtils.makeTeamSendMsg(partyId, agentId, \"hello world\");\n+            String resp = EnterpriseWeChatUtils.sendEnterpriseWeChat(\"utf-8\", msg, token);\n+\n+            String errmsg = JSON.parseObject(resp).getString(\"errmsg\");\n+            Assert.assertEquals(errmsg, \"ok\");\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    @Test\n+    public void testSendMultiTeamWeChat() {\n+\n+        try {\n+            String token = EnterpriseWeChatUtils.getToken();\n+            String msg = EnterpriseWeChatUtils.makeTeamSendMsg(listPartyId, agentId, \"hello world\");\n+            String resp = EnterpriseWeChatUtils.sendEnterpriseWeChat(\"utf-8\", msg, token);\n+\n+            String errmsg = JSON.parseObject(resp).getString(\"errmsg\");\n+            Assert.assertEquals(errmsg, \"ok\");\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    @Test\n+    public void testSendSingleUserWeChat() {\n+        try {\n+            String token = EnterpriseWeChatUtils.getToken();\n+            String msg = EnterpriseWeChatUtils.makeUserSendMsg(listUserId.stream().findFirst().get(), agentId, \"your meeting room has been booked and will be synced to the 'mailbox' later \\n\" +\n+                    \">**matter details** \\n\" +\n+                    \">matter\uff1a<font color='info'>meeting</font> <br>\" +\n+                    \">organizer\uff1a@miglioguan \\n\" +\n+                    \">participant\uff1a@miglioguan\u3001@kunliu\u3001@jamdeezhou\u3001@kanexiong\u3001@kisonwang \\n\" +\n+                    \"> \\n\" +\n+                    \">meeting room\uff1a<font color='info'>Guangzhou TIT 1st Floor 301</font> \\n\" +\n+                    \">date\uff1a<font color='warning'>May 18, 2018</font> \\n\" +\n+                    \">time\uff1a<font color='comment'>9:00-11:00 am</font> \\n\" +\n+                    \"> \\n\" +\n+                    \">please attend the meeting on time\\n\" +\n+                    \"> \\n\" +\n+                    \">to modify the meeting information, please click: [Modify Meeting Information](https://work.weixin.qq.com)\\\"\");\n+\n+            String resp = EnterpriseWeChatUtils.sendEnterpriseWeChat(\"utf-8\", msg, token);\n+\n+            String errmsg = JSON.parseObject(resp).getString(\"errmsg\");\n+            Assert.assertEquals(errmsg, \"ok\");\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    @Test\n+    public void testSendMultiUserWeChat() {\n+        try {\n+            String token = EnterpriseWeChatUtils.getToken();\n+\n+            String msg = EnterpriseWeChatUtils.makeUserSendMsg(listUserId, agentId, \"hello world\");\n+            String resp = EnterpriseWeChatUtils.sendEnterpriseWeChat(\"utf-8\", msg, token);\n+\n+            String errmsg = JSON.parseObject(resp).getString(\"errmsg\");\n+            Assert.assertEquals(errmsg, \"ok\");\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+}",
                "changes": 119
            },
            {
                "status": "added",
                "additions": 232,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/MailUtilsTest.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/MailUtilsTest.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/MailUtilsTest.java",
                "deletions": 0,
                "sha": "96f1d9f21ee49b7d2094922ecb6be3e7238dd687",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/utils/MailUtilsTest.java",
                "patch": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.alert.utils;\n+\n+\n+import org.apache.dolphinscheduler.common.enums.AlertType;\n+import org.apache.dolphinscheduler.common.enums.ShowType;\n+import org.apache.dolphinscheduler.dao.AlertDao;\n+import org.apache.dolphinscheduler.dao.DaoFactory;\n+import org.apache.dolphinscheduler.dao.entity.Alert;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import freemarker.cache.StringTemplateLoader;\n+import freemarker.template.Configuration;\n+import freemarker.template.Template;\n+import freemarker.template.TemplateException;\n+import org.apache.commons.io.IOUtils;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.util.ResourceUtils;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.StringWriter;\n+import java.util.*;\n+\n+\n+/**\n+ */\n+@Ignore\n+public class MailUtilsTest {\n+    private static final Logger logger = LoggerFactory.getLogger(MailUtilsTest.class);\n+    @Test\n+    public void testSendMails() {\n+        String[] receivers = new String[]{\"xxx@qq.com\"};\n+        String[] receiversCc = new String[]{\"xxx@qq.com\"};\n+\n+        String content =\"[\\\"id:69\\\",\" +\n+                \"\\\"name:UserBehavior-0--1193959466\\\",\" +\n+                \"\\\"Job name: Start workflow\\\",\" +\n+                \"\\\"State: SUCCESS\\\",\" +\n+                \"\\\"Recovery:NO\\\",\" +\n+                \"\\\"Run time: 1\\\",\" +\n+                \"\\\"Start time: 2018-08-06 10:31:34.0\\\",\" +\n+                \"\\\"End time: 2018-08-06 10:31:49.0\\\",\" +\n+                \"\\\"Host: 192.168.xx.xx\\\",\" +\n+                \"\\\"Notify group :4\\\"]\";\n+\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.TEXT);\n+        alert.setContent(content);\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(4);\n+\n+        MailUtils.sendMails(Arrays.asList(receivers),Arrays.asList(receiversCc),alert.getTitle(),alert.getContent(), ShowType.TEXT);\n+    }\n+\n+\n+    @Test\n+    public void testQuery(){\n+        AlertDao alertDao = DaoFactory.getDaoInstance(AlertDao.class);\n+        List<Alert> alerts = alertDao.listWaitExecutionAlert();\n+\n+        String[] mails = new String[]{\"xx@xx.com\"};\n+\n+        for(Alert alert : alerts){\n+            MailUtils.sendMails(Arrays.asList(mails),\"gaojing\", alert.getContent(), alert.getShowType());\n+        }\n+\n+    }\n+\n+    public String list2String(){\n+\n+        LinkedHashMap<String, Object> map1 = new LinkedHashMap<>();\n+        map1.put(\"mysql service name\",\"mysql200\");\n+        map1.put(\"mysql address\",\"192.168.xx.xx\");\n+        map1.put(\"port\",\"3306\");\n+        map1.put(\"no index of number\",\"80\");\n+        map1.put(\"database client connections\",\"190\");\n+\n+        LinkedHashMap<String, Object> map2 = new LinkedHashMap<>();\n+        map2.put(\"mysql service name\",\"mysql210\");\n+        map2.put(\"mysql address\",\"192.168.xx.xx\");\n+        map2.put(\"port\",\"3306\");\n+        map2.put(\"no index of number\",\"10\");\n+        map2.put(\"database client connections\",\"90\");\n+\n+        List<LinkedHashMap<String, Object>> maps = new ArrayList<>();\n+        maps.add(0,map1);\n+        maps.add(1,map2);\n+        String mapjson = JSONUtils.toJsonString(maps);\n+        logger.info(mapjson);\n+\n+        return mapjson;\n+\n+    }\n+\n+    @Test\n+    public void testSendTableMail(){\n+        String[] mails = new String[]{\"825193156@qq.com\"};\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.TABLE);\n+        String content= list2String();\n+        alert.setContent(content);\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(1);\n+        MailUtils.sendMails(Arrays.asList(mails),\"gaojing\", alert.getContent(), ShowType.TABLE);\n+    }\n+\n+    /**\n+     * Used to test add alarm information, mail sent\n+     * Text\n+     */\n+    @Test\n+    public void addAlertText(){\n+        AlertDao alertDao = DaoFactory.getDaoInstance(AlertDao.class);\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.TEXT);\n+        alert.setContent(\"[\\\"alarm time\uff1a2018-02-05\\\", \\\"service name\uff1aMYSQL_ALTER\\\", \\\"alarm name\uff1aMYSQL_ALTER_DUMP\\\", \" +\n+                \"\\\"get the alarm exception.\uff01\uff0cinterface error\uff0cexception information\uff1atimed out\\\", \\\"request address\uff1ahttp://blog.csdn.net/dreamInTheWorld/article/details/78539286\\\"]\");\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(1);\n+        alertDao.addAlert(alert);\n+    }\n+\n+\n+    /**\n+     * Used to test add alarm information, mail sent\n+     * Table\n+     */\n+    @Test\n+    public void addAlertTable(){\n+        AlertDao alertDao = DaoFactory.getDaoInstance(AlertDao.class);\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.TABLE);\n+\n+        String content = list2String();\n+        alert.setContent(content);\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(1);\n+        alertDao.addAlert(alert);\n+    }\n+\n+    @Test\n+    public void testAlertDao(){\n+        AlertDao alertDao = DaoFactory.getDaoInstance(AlertDao.class);\n+        List<User> users = alertDao.listUserByAlertgroupId(3);\n+        logger.info(users.toString());\n+    }\n+\n+    @Test\n+    public void testAttachmentFile()throws Exception{\n+        String[] mails = new String[]{\"xx@xx.com\"};\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.ATTACHMENT);\n+        String content = list2String();\n+        alert.setContent(content);\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(1);\n+        MailUtils.sendMails(Arrays.asList(mails),\"gaojing\",alert.getContent(),ShowType.ATTACHMENT);\n+    }\n+\n+    @Test\n+    public void testTableAttachmentFile()throws Exception{\n+        String[] mails = new String[]{\"xx@xx.com\"};\n+        Alert alert = new Alert();\n+        alert.setTitle(\"Mysql Exception\");\n+        alert.setShowType(ShowType.TABLEATTACHMENT);\n+        String content = list2String();\n+        alert.setContent(content);\n+        alert.setAlertType(AlertType.EMAIL);\n+        alert.setAlertGroupId(1);\n+        MailUtils.sendMails(Arrays.asList(mails),\"gaojing\",alert.getContent(),ShowType.TABLEATTACHMENT);\n+    }\n+\n+    @Test\n+    public void template(){\n+        Template MAIL_TEMPLATE;\n+        Configuration cfg = new Configuration(Configuration.VERSION_2_3_21);\n+        cfg.setDefaultEncoding(Constants.UTF_8);\n+        StringTemplateLoader stringTemplateLoader = new StringTemplateLoader();\n+        cfg.setTemplateLoader(stringTemplateLoader);\n+        InputStreamReader isr = null;\n+        try {\n+            isr = new InputStreamReader(new FileInputStream(ResourceUtils.getFile(Constants.CLASSPATH_MAIL_TEMPLATES_ALERT_MAIL_TEMPLATE_FTL)),\n+                    Constants.UTF_8);\n+\n+            MAIL_TEMPLATE = new Template(\"alert_mail_template\", isr, cfg);\n+        } catch (Exception e) {\n+            MAIL_TEMPLATE = null;\n+        } finally {\n+            IOUtils.closeQuietly(isr);\n+        }\n+\n+\n+        StringWriter out = new StringWriter();\n+        Map<String,String> map = new HashMap<>();\n+        map.put(Constants.TITLE,\"title_test\");\n+        try {\n+            MAIL_TEMPLATE.process(map, out);\n+            logger.info(out.toString());\n+\n+        } catch (TemplateException e) {\n+            logger.error(e.getMessage(),e);\n+        } catch (IOException e) {\n+            logger.error(e.getMessage(),e);\n+        }\n+\n+    }\n+\n+}",
                "changes": 232
            },
            {
                "status": "added",
                "additions": 254,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/pom.xml?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/pom.xml",
                "deletions": 0,
                "sha": "06a444aa6d6294f857a1caf3dcc8b707c21474e0",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/pom.xml",
                "patch": "@@ -0,0 +1,254 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Licensed to the Apache Software Foundation (ASF) under one or more\n+  ~ contributor license agreements.  See the NOTICE file distributed with\n+  ~ this work for additional information regarding copyright ownership.\n+  ~ The ASF licenses this file to You under the Apache License, Version 2.0\n+  ~ (the \"License\"); you may not use this file except in compliance with\n+  ~ the License.  You may obtain a copy of the License at\n+  ~\n+  ~     http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>org.apache.dolphinscheduler</groupId>\n+    <artifactId>dolphinscheduler</artifactId>\n+    <version>1.2.1-SNAPSHOT</version>\n+  </parent>\n+  <artifactId>dolphinscheduler-api</artifactId>\n+  <name>${project.artifactId}</name>\n+  <packaging>jar</packaging>\n+\n+  <properties>\n+    <jasper-runtime.version>5.5.23</jasper-runtime.version>\n+    <servlet-api.version>2.5</servlet-api.version>\n+  </properties>\n+\n+  <dependencies>\n+      <dependency>\n+          <groupId>org.apache.dolphinscheduler</groupId>\n+          <artifactId>dolphinscheduler-alert</artifactId>\n+      </dependency>\n+      <dependency>\n+      <groupId>org.apache.dolphinscheduler</groupId>\n+      <artifactId>dolphinscheduler-server</artifactId>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>io.netty</groupId>\n+          <artifactId>netty</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>io.netty</groupId>\n+          <artifactId>netty-all</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>com.google</groupId>\n+          <artifactId>netty</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <artifactId>leveldbjni-all</artifactId>\n+          <groupId>org.fusesource.leveldbjni</groupId>\n+        </exclusion>\n+        <exclusion>\n+          <artifactId>protobuf-java</artifactId>\n+          <groupId>com.google.protobuf</groupId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+\n+    <!--springboot-->\n+    <dependency>\n+      <groupId>org.springframework.boot</groupId>\n+      <artifactId>spring-boot-starter-web</artifactId>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.springframework.boot</groupId>\n+          <artifactId>spring-boot-starter-tomcat</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <artifactId>log4j-to-slf4j</artifactId>\n+          <groupId>org.apache.logging.log4j</groupId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+\n+    <!-- use jetty -->\n+    <dependency>\n+      <groupId>org.springframework.boot</groupId>\n+      <artifactId>spring-boot-starter-jetty</artifactId>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.eclipse.jetty.websocket</groupId>\n+          <artifactId>javax-websocket-server-impl</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>org.eclipse.jetty.websocket</groupId>\n+          <artifactId>websocket-server</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.springframework.boot</groupId>\n+      <artifactId>spring-boot-starter-test</artifactId>\n+      <scope>test</scope>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.ow2.asm</groupId>\n+          <artifactId>asm</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>org.springframework.boot</groupId>\n+          <artifactId>spring-boot</artifactId>\n+        </exclusion>\n+        <exclusion>\n+          <groupId>org.springframework.boot</groupId>\n+          <artifactId>spring-boot-autoconfigure</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.springframework.boot</groupId>\n+      <artifactId>spring-boot-starter-aop</artifactId>\n+      <exclusions>\n+        <exclusion>\n+          <groupId>org.springframework.boot</groupId>\n+          <artifactId>spring-boot-starter</artifactId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.springframework</groupId>\n+      <artifactId>spring-context</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.apache.httpcomponents</groupId>\n+      <artifactId>httpcore</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.httpcomponents</groupId>\n+      <artifactId>httpclient</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>com.fasterxml.jackson.core</groupId>\n+      <artifactId>jackson-annotations</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.fasterxml.jackson.core</groupId>\n+      <artifactId>jackson-databind</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>com.fasterxml.jackson.core</groupId>\n+      <artifactId>jackson-core</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>com.alibaba</groupId>\n+      <artifactId>fastjson</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>commons-collections</groupId>\n+      <artifactId>commons-collections</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.quartz-scheduler</groupId>\n+      <artifactId>quartz</artifactId>\n+      <exclusions>\n+        <exclusion>\n+          <artifactId>c3p0</artifactId>\n+          <groupId>c3p0</groupId>\n+        </exclusion>\n+      </exclusions>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.quartz-scheduler</groupId>\n+      <artifactId>quartz-jobs</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>io.springfox</groupId>\n+      <artifactId>springfox-swagger2</artifactId>\n+      <version>2.9.2</version>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>io.springfox</groupId>\n+      <artifactId>springfox-swagger-ui</artifactId>\n+      <version>2.9.2</version>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>com.github.xiaoymin</groupId>\n+      <artifactId>swagger-bootstrap-ui</artifactId>\n+      <version>1.9.3</version>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.apache.dolphinscheduler</groupId>\n+      <artifactId>dolphinscheduler-rpc</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>junit</groupId>\n+      <artifactId>junit</artifactId>\n+      <version>4.12</version>\n+      <scope>test</scope>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>org.apache.curator</groupId>\n+      <artifactId>curator-framework</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.curator</groupId>\n+      <artifactId>curator-recipes</artifactId>\n+    </dependency>\n+    <!-- hadoop -->\n+    <dependency>\n+      <groupId>org.apache.hadoop</groupId>\n+      <artifactId>hadoop-common</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.hadoop</groupId>\n+      <artifactId>hadoop-client</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.hadoop</groupId>\n+      <artifactId>hadoop-hdfs</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.hadoop</groupId>\n+      <artifactId>hadoop-yarn-common</artifactId>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.hadoop</groupId>\n+      <artifactId>hadoop-aws</artifactId>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>tomcat</groupId>\n+      <artifactId>jasper-runtime</artifactId>\n+      <version>${jasper-runtime.version}</version>\n+    </dependency>\n+\n+    <dependency>\n+      <groupId>javax.servlet</groupId>\n+      <artifactId>servlet-api</artifactId>\n+      <version>${servlet-api.version}</version>\n+    </dependency>\n+\n+  </dependencies>\n+</project>\n\\ No newline at end of file",
                "changes": 254
            },
            {
                "status": "added",
                "additions": 37,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java",
                "deletions": 0,
                "sha": "ccf787d7064a2900a6cbc8630f45fb2537d07e23",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java",
                "patch": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api;\n+\n+import org.springframework.boot.SpringApplication;\n+import org.springframework.boot.autoconfigure.SpringBootApplication;\n+import org.springframework.boot.web.servlet.ServletComponentScan;\n+import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;\n+import org.springframework.context.annotation.ComponentScan;\n+import springfox.documentation.swagger2.annotations.EnableSwagger2;\n+\n+@SpringBootApplication\n+@ServletComponentScan\n+@ComponentScan(\"org.apache.dolphinscheduler\")\n+@EnableSwagger2\n+public class ApiApplicationServer extends SpringBootServletInitializer {\n+\n+  public static void main(String[] args) {\n+    SpringApplication.run(ApiApplicationServer.class, args);\n+  }\n+\n+\n+}",
                "changes": 37
            },
            {
                "status": "added",
                "additions": 49,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/CombinedApplicationServer.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/CombinedApplicationServer.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/CombinedApplicationServer.java",
                "deletions": 0,
                "sha": "5030890ae481f89a9d2c9cf21fd70e1512b70e0d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/CombinedApplicationServer.java",
                "patch": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api;\n+\n+import org.apache.dolphinscheduler.alert.AlertServer;\n+import org.apache.dolphinscheduler.server.master.MasterServer;\n+import org.apache.dolphinscheduler.server.rpc.LoggerServer;\n+import org.apache.dolphinscheduler.server.worker.WorkerServer;\n+import org.springframework.boot.autoconfigure.SpringBootApplication;\n+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\n+import org.springframework.boot.web.servlet.ServletComponentScan;\n+import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;\n+import org.springframework.context.annotation.ComponentScan;\n+import org.springframework.context.annotation.Import;\n+import springfox.documentation.swagger2.annotations.EnableSwagger2;\n+\n+@SpringBootApplication\n+@ConditionalOnProperty(prefix = \"server\", name = \"is-combined-server\", havingValue = \"true\")\n+@ServletComponentScan\n+@ComponentScan(\"org.apache.dolphinscheduler\")\n+@Import({MasterServer.class, WorkerServer.class})\n+@EnableSwagger2\n+public class CombinedApplicationServer extends SpringBootServletInitializer {\n+\n+    public static void main(String[] args) throws Exception {\n+\n+        ApiApplicationServer.main(args);\n+\n+        LoggerServer server = new LoggerServer();\n+        server.start();\n+\n+        AlertServer alertServer = AlertServer.getInstance();\n+        alertServer.start();\n+    }\n+}",
                "changes": 49
            },
            {
                "status": "added",
                "additions": 116,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AppConfiguration.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AppConfiguration.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AppConfiguration.java",
                "deletions": 0,
                "sha": "73ff74fd3dde5d795e8c1574ef1fa15f7ebb626f",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AppConfiguration.java",
                "patch": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.configuration;\n+\n+import org.apache.dolphinscheduler.api.interceptor.LoginHandlerInterceptor;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.web.servlet.LocaleResolver;\n+import org.springframework.web.servlet.config.annotation.*;\n+import org.springframework.web.servlet.i18n.CookieLocaleResolver;\n+import org.springframework.web.servlet.i18n.LocaleChangeInterceptor;\n+\n+import java.util.Locale;\n+\n+\n+/**\n+ * application configuration\n+ */\n+@Configuration\n+public class AppConfiguration implements WebMvcConfigurer {\n+\n+  public static final String LOGIN_INTERCEPTOR_PATH_PATTERN = \"/**/*\";\n+  public static final String LOGIN_PATH_PATTERN = \"/login\";\n+  public static final String PATH_PATTERN = \"/**\";\n+  public static final String LOCALE_LANGUAGE_COOKIE = \"language\";\n+  public static final int COOKIE_MAX_AGE = 3600;\n+\n+\n+  @Bean\n+  public LoginHandlerInterceptor loginInterceptor() {\n+    return new LoginHandlerInterceptor();\n+  }\n+\n+\n+  /**\n+   * Cookie\n+   * @return local resolver\n+   */\n+  @Bean(name = \"localeResolver\")\n+  public LocaleResolver localeResolver() {\n+    CookieLocaleResolver localeResolver = new CookieLocaleResolver();\n+    localeResolver.setCookieName(LOCALE_LANGUAGE_COOKIE);\n+    /** set default locale **/\n+    localeResolver.setDefaultLocale(Locale.US);\n+    /** set cookie max age **/\n+    localeResolver.setCookieMaxAge(COOKIE_MAX_AGE);\n+    return localeResolver;\n+  }\n+\n+  @Bean\n+  public LocaleChangeInterceptor localeChangeInterceptor() {\n+    LocaleChangeInterceptor lci = new LocaleChangeInterceptor();\n+    /**  **/\n+    lci.setParamName(\"language\");\n+\n+    return lci;\n+  }\n+\n+\n+  @Override\n+  public void addInterceptors(InterceptorRegistry registry) {\n+    //i18n\n+    registry.addInterceptor(localeChangeInterceptor());\n+\n+    registry.addInterceptor(loginInterceptor()).addPathPatterns(LOGIN_INTERCEPTOR_PATH_PATTERN).excludePathPatterns(LOGIN_PATH_PATTERN,\"/swagger-resources/**\", \"/webjars/**\", \"/v2/**\", \"/doc.html\", \"*.html\", \"/ui/**\");\n+  }\n+\n+\n+  @Override\n+  public void addResourceHandlers(ResourceHandlerRegistry registry) {\n+    registry.addResourceHandler(\"/static/**\").addResourceLocations(\"classpath:/static/\");\n+    registry.addResourceHandler(\"doc.html\").addResourceLocations(\"classpath:/META-INF/resources/\");\n+    registry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath:/META-INF/resources/webjars/\");\n+    registry.addResourceHandler(\"/ui/**\").addResourceLocations(\"file:ui/\");\n+  }\n+\n+  @Override\n+  public void addViewControllers(ViewControllerRegistry registry) {\n+    registry.addViewController(\"/ui/\").setViewName(\"forward:/ui/index.html\");\n+    registry.addViewController(\"/\").setViewName(\"forward:/ui/index.html\");\n+  }\n+\n+  @Override\n+  public void addCorsMappings(CorsRegistry registry) {\n+    registry.addMapping(PATH_PATTERN).allowedOrigins(\"*\").allowedMethods(\"*\");\n+  }\n+\n+\n+  /**\n+   * Turn off suffix-based content negotiation\n+   *\n+   * @param configurer configurer\n+   */\n+  @Override\n+  public void configureContentNegotiation(final ContentNegotiationConfigurer configurer) {\n+    configurer.favorPathExtension(false);\n+  }\n+\n+\n+\n+\n+}",
                "changes": 116
            },
            {
                "status": "added",
                "additions": 284,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/ServiceModelToSwagger2MapperImpl.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/ServiceModelToSwagger2MapperImpl.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/ServiceModelToSwagger2MapperImpl.java",
                "deletions": 0,
                "sha": "c0ceb66323e1ec3027bfb4a919731332ecfacf67",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/ServiceModelToSwagger2MapperImpl.java",
                "patch": "@@ -0,0 +1,284 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.configuration;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import com.google.common.collect.Multimap;\n+import io.swagger.models.*;\n+import io.swagger.models.parameters.Parameter;\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.context.MessageSource;\n+import org.springframework.context.annotation.Primary;\n+import org.springframework.context.i18n.LocaleContextHolder;\n+import org.springframework.stereotype.Component;\n+import springfox.documentation.service.ApiInfo;\n+import springfox.documentation.service.ApiListing;\n+import springfox.documentation.service.Documentation;\n+import springfox.documentation.service.ResourceListing;\n+import springfox.documentation.swagger2.mappers.*;\n+\n+import java.util.*;\n+\n+import static com.google.common.collect.Maps.newTreeMap;\n+\n+/**\n+ * application configuration\n+ */\n+@Component(value = \"ServiceModelToSwagger2Mapper\")\n+@Primary\n+public class ServiceModelToSwagger2MapperImpl extends ServiceModelToSwagger2Mapper {\n+\n+\n+    @Autowired\n+    private ModelMapper modelMapper;\n+    @Autowired\n+    private ParameterMapper parameterMapper;\n+    @Autowired\n+    private SecurityMapper securityMapper;\n+    @Autowired\n+    private LicenseMapper licenseMapper;\n+    @Autowired\n+    private VendorExtensionsMapper vendorExtensionsMapper;\n+\n+    @Autowired\n+    private MessageSource messageSource;\n+\n+    @Override\n+    public Swagger mapDocumentation(Documentation from) {\n+\n+        if (from == null) {\n+            return null;\n+        }\n+\n+        Swagger swagger = new Swagger();\n+\n+        swagger.setVendorExtensions(vendorExtensionsMapper.mapExtensions(from.getVendorExtensions()));\n+        swagger.setSchemes(mapSchemes(from.getSchemes()));\n+        swagger.setPaths(mapApiListings(from.getApiListings()));\n+        swagger.setHost(from.getHost());\n+        swagger.setDefinitions(modelsFromApiListings( from.getApiListings() ) );\n+        swagger.setSecurityDefinitions(securityMapper.toSecuritySchemeDefinitions(from.getResourceListing()));\n+        ApiInfo info = fromResourceListingInfo(from);\n+        if (info != null) {\n+            swagger.setInfo(mapApiInfo(info));\n+        }\n+        swagger.setBasePath(from.getBasePath());\n+        swagger.setTags(tagSetToTagList(from.getTags()));\n+        List<String> list2 = from.getConsumes();\n+        if (list2 != null) {\n+            swagger.setConsumes(new ArrayList<String>(list2));\n+        } else {\n+            swagger.setConsumes(null);\n+        }\n+        List<String> list3 = from.getProduces();\n+        if (list3 != null) {\n+            swagger.setProduces(new ArrayList<String>(list3));\n+        } else {\n+            swagger.setProduces(null);\n+        }\n+\n+        return swagger;\n+    }\n+\n+\n+    @Override\n+    protected Info mapApiInfo(ApiInfo from) {\n+\n+        if (from == null) {\n+            return null;\n+        }\n+\n+        Info info = new Info();\n+\n+        info.setLicense(licenseMapper.apiInfoToLicense(from));\n+        info.setVendorExtensions(vendorExtensionsMapper.mapExtensions(from.getVendorExtensions()));\n+        info.setTermsOfService(from.getTermsOfServiceUrl());\n+        info.setContact(map(from.getContact()));\n+        info.setDescription(from.getDescription());\n+        info.setVersion(from.getVersion());\n+        info.setTitle(from.getTitle());\n+\n+        return info;\n+    }\n+\n+    @Override\n+    protected Contact map(springfox.documentation.service.Contact from) {\n+\n+        if (from == null) {\n+            return null;\n+        }\n+\n+        Contact contact = new Contact();\n+\n+        contact.setName(from.getName());\n+        contact.setUrl(from.getUrl());\n+        contact.setEmail(from.getEmail());\n+\n+        return contact;\n+    }\n+\n+    @Override\n+    protected io.swagger.models.Operation mapOperation(springfox.documentation.service.Operation from) {\n+\n+        if (from == null) {\n+            return null;\n+        }\n+\n+        Locale locale = LocaleContextHolder.getLocale();\n+\n+        io.swagger.models.Operation operation = new io.swagger.models.Operation();\n+\n+        operation.setSecurity(mapAuthorizations(from.getSecurityReferences()));\n+        operation.setVendorExtensions(vendorExtensionsMapper.mapExtensions(from.getVendorExtensions()));\n+        operation.setDescription(messageSource.getMessage(from.getNotes(), null, from.getNotes(), locale));\n+        operation.setOperationId(from.getUniqueId());\n+        operation.setResponses(mapResponseMessages(from.getResponseMessages()));\n+        operation.setSchemes(stringSetToSchemeList(from.getProtocol()));\n+        Set<String> tagsSet = new HashSet<>(1);\n+\n+        if(from.getTags() != null && from.getTags().size() > 0){\n+\n+            List<String> list = new ArrayList<String>(tagsSet.size());\n+\n+            Iterator<String> it = from.getTags().iterator();\n+            while(it.hasNext())\n+            {\n+               String tag = it.next();\n+               list.add(StringUtils.isNotBlank(tag) ? messageSource.getMessage(tag, null, tag, locale) : \" \");\n+            }\n+\n+            operation.setTags(list);\n+        }else {\n+            operation.setTags(null);\n+        }\n+\n+        operation.setSummary(from.getSummary());\n+        Set<String> set1 = from.getConsumes();\n+        if (set1 != null) {\n+            operation.setConsumes(new ArrayList<String>(set1));\n+        } else {\n+            operation.setConsumes(null);\n+        }\n+\n+        Set<String> set2 = from.getProduces();\n+        if (set2 != null) {\n+            operation.setProduces(new ArrayList<String>(set2));\n+        } else {\n+            operation.setProduces(null);\n+        }\n+\n+\n+        operation.setParameters(parameterListToParameterList(from.getParameters()));\n+        if (from.getDeprecated() != null) {\n+            operation.setDeprecated(Boolean.parseBoolean(from.getDeprecated()));\n+        }\n+\n+        return operation;\n+    }\n+\n+    @Override\n+    protected Tag mapTag(springfox.documentation.service.Tag from) {\n+\n+        if (from == null) {\n+            return null;\n+        }\n+\n+        Locale locale = LocaleContextHolder.getLocale();\n+\n+        Tag tag = new Tag();\n+\n+        tag.setVendorExtensions(vendorExtensionsMapper.mapExtensions(from.getVendorExtensions()));\n+        tag.setName(messageSource.getMessage(from.getName(), null, from.getName(), locale));\n+        tag.setDescription(from.getDescription());\n+\n+        return tag;\n+    }\n+\n+\n+    private ApiInfo fromResourceListingInfo(Documentation documentation) {\n+\n+        if (documentation == null) {\n+            return null;\n+        }\n+        ResourceListing resourceListing = documentation.getResourceListing();\n+        if (resourceListing == null) {\n+            return null;\n+        }\n+        ApiInfo info = resourceListing.getInfo();\n+        if (info == null) {\n+            return null;\n+        }\n+        return info;\n+    }\n+\n+    protected List<Tag> tagSetToTagList(Set<springfox.documentation.service.Tag> set) {\n+\n+        if (set == null) {\n+            return null;\n+        }\n+\n+        List<Tag> list = new ArrayList<Tag>(set.size());\n+        for (springfox.documentation.service.Tag tag : set) {\n+            list.add(mapTag(tag));\n+        }\n+\n+        return list;\n+    }\n+\n+    protected List<Scheme> stringSetToSchemeList(Set<String> set) {\n+        if (set == null) {\n+            return null;\n+        }\n+\n+        List<Scheme> list = new ArrayList<Scheme>(set.size());\n+        for (String string : set) {\n+            list.add(Enum.valueOf(Scheme.class, string));\n+        }\n+\n+        return list;\n+    }\n+\n+    protected List<Parameter> parameterListToParameterList(List<springfox.documentation.service.Parameter> list) {\n+        if (list == null) {\n+            return null;\n+        }\n+\n+        List<Parameter> list1 = new ArrayList<Parameter>(list.size());\n+\n+        Locale locale = LocaleContextHolder.getLocale();\n+\n+        for (springfox.documentation.service.Parameter param : list) {\n+            String description = messageSource.getMessage(param.getDescription(), null, param.getDescription(), locale);\n+\n+            springfox.documentation.service.Parameter parameter = new springfox.documentation.service.Parameter(param.getName(),description,param.getDefaultValue(),param.isRequired(),param.isAllowMultiple(),param.isAllowEmptyValue(),param.getModelRef(),param.getType(),param.getAllowableValues(),param.getParamType(),param.getParamAccess(),param.isHidden(),param.getPattern(),param.getCollectionFormat(),param.getOrder(),param.getScalarExample(),param.getExamples() ,param.getVendorExtentions());\n+            list1.add(parameterMapper.mapParameter(parameter));\n+        }\n+\n+        return list1;\n+    }\n+\n+\n+    Map<String, Model> modelsFromApiListings(Multimap<String, ApiListing> apiListings) {\n+        Map<String, springfox.documentation.schema.Model> definitions = newTreeMap();\n+        for (ApiListing each : apiListings.values()) {\n+            definitions.putAll(each.getModels());\n+        }\n+        return modelMapper.mapModels(definitions);\n+    }\n+\n+}",
                "changes": 284
            },
            {
                "status": "added",
                "additions": 55,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/SwaggerConfig.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/SwaggerConfig.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/SwaggerConfig.java",
                "deletions": 0,
                "sha": "6240e7d92447996492dbb670b8ee6597cadb3f0c",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/SwaggerConfig.java",
                "patch": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.configuration;\n+\n+import com.github.xiaoymin.swaggerbootstrapui.annotations.EnableSwaggerBootstrapUI;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+\n+import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;\n+import springfox.documentation.builders.ApiInfoBuilder;\n+import springfox.documentation.builders.PathSelectors;\n+import springfox.documentation.builders.RequestHandlerSelectors;\n+import springfox.documentation.service.ApiInfo;\n+import springfox.documentation.spi.DocumentationType;\n+import springfox.documentation.spring.web.plugins.Docket;\n+import springfox.documentation.swagger2.annotations.EnableSwagger2;\n+\n+/**\n+ *\n+ * swager2 config class\n+ *\n+ */\n+@Configuration\n+@EnableSwagger2\n+@EnableSwaggerBootstrapUI\n+public class SwaggerConfig implements WebMvcConfigurer {\n+\n+    @Bean\n+    public Docket createRestApi() {\n+        return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select()\n+                .apis(RequestHandlerSelectors.basePackage(\"org.apache.dolphinscheduler.api.controller\")).paths(PathSelectors.any())\n+                .build();\n+    }\n+\n+    private ApiInfo apiInfo() {\n+        return new ApiInfoBuilder().title(\"Dolphin Scheduler Api Docs\").description(\"Dolphin Scheduler Api Docs\")\n+                .build();\n+    }\n+\n+\n+}",
                "changes": 55
            },
            {
                "status": "added",
                "additions": 193,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java",
                "deletions": 0,
                "sha": "c03281df7ecd5b311168257c8ed39c0571ade8b1",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java",
                "patch": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.AccessTokenService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+/**\n+ * access token controller\n+ */\n+@Api(tags = \"ACCESS_TOKEN_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"/access-token\")\n+public class AccessTokenController extends BaseController{\n+\n+\n+    private static final Logger logger = LoggerFactory.getLogger(AccessTokenController.class);\n+\n+\n+    @Autowired\n+    private AccessTokenService accessTokenService;\n+\n+    /**\n+     * create token\n+     * @param loginUser login user\n+     * @param userId token for user id\n+     * @param expireTime expire time for the token\n+     * @param token token\n+     * @return create result state code\n+     */\n+    @ApiIgnore\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createToken(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                  @RequestParam(value = \"userId\") int userId,\n+                                                  @RequestParam(value = \"expireTime\") String expireTime,\n+                                                  @RequestParam(value = \"token\") String token){\n+        logger.info(\"login user {}, create token , userId : {} , token expire time : {} , token : {}\", loginUser.getUserName(),\n+                userId,expireTime,token);\n+\n+        try {\n+            Map<String, Object> result = accessTokenService.createToken(userId, expireTime, token);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(CREATE_ACCESS_TOKEN_ERROR.getMsg(),e);\n+            return error(CREATE_ACCESS_TOKEN_ERROR.getCode(), CREATE_ACCESS_TOKEN_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * generate token string\n+     * @param loginUser login user\n+     * @param userId token for user\n+     * @param expireTime expire time\n+     * @return token string\n+     */\n+    @ApiIgnore\n+    @PostMapping(value = \"/generate\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result generateToken(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                              @RequestParam(value = \"userId\") int userId,\n+                              @RequestParam(value = \"expireTime\") String expireTime){\n+        logger.info(\"login user {}, generate token , userId : {} , token expire time : {}\",loginUser,userId,expireTime);\n+        try {\n+            Map<String, Object> result = accessTokenService.generateToken(userId, expireTime);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(GENERATE_TOKEN_ERROR.getMsg(),e);\n+            return error(GENERATE_TOKEN_ERROR.getCode(), GENERATE_TOKEN_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query access token list paging\n+     *\n+     * @param loginUser login user\n+     * @param pageNo page number\n+     * @param searchVal search value\n+     * @param pageSize page size\n+     * @return token list of page number and page size\n+     */\n+    @ApiOperation(value = \"queryAccessTokenList\", notes= \"QUERY_ACCESS_TOKEN_LIST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryAccessTokenList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"pageNo\") Integer pageNo,\n+                                @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                @RequestParam(\"pageSize\") Integer pageSize){\n+        logger.info(\"login user {}, list access token paging, pageNo: {}, searchVal: {}, pageSize: {}\",\n+                loginUser.getUserName(),pageNo,searchVal,pageSize);\n+        try{\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = accessTokenService.queryAccessTokenList(loginUser, searchVal, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_ACCESSTOKEN_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(QUERY_ACCESSTOKEN_LIST_PAGING_ERROR.getCode(),QUERY_ACCESSTOKEN_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete access token by id\n+     * @param loginUser login user\n+     * @param id token id\n+     * @return delete result code\n+     */\n+    @ApiIgnore\n+    @PostMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result delAccessTokenById(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                              @RequestParam(value = \"id\") int  id) {\n+        logger.info(\"login user {}, delete access token, id: {},\", loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> result = accessTokenService.delAccessTokenById(loginUser, id);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(DELETE_ACCESS_TOKEN_ERROR.getMsg(),e);\n+            return error(Status.DELETE_ACCESS_TOKEN_ERROR.getCode(), Status.DELETE_ACCESS_TOKEN_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * update token\n+     * @param loginUser login user\n+     * @param id token id\n+     * @param userId token for user\n+     * @param expireTime token expire time\n+     * @param token token string\n+     * @return update result code\n+     */\n+    @ApiIgnore\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateToken(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                              @RequestParam(value = \"id\") int id,\n+                              @RequestParam(value = \"userId\") int userId,\n+                              @RequestParam(value = \"expireTime\") String expireTime,\n+                              @RequestParam(value = \"token\") String token){\n+        logger.info(\"login user {}, update token , userId : {} , token expire time : {} , token : {}\", loginUser.getUserName(),\n+                userId,expireTime,token);\n+\n+        try {\n+            Map<String, Object> result = accessTokenService.updateToken(id,userId, expireTime, token);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(UPDATE_ACCESS_TOKEN_ERROR.getMsg(),e);\n+            return error(UPDATE_ACCESS_TOKEN_ERROR.getCode(), UPDATE_ACCESS_TOKEN_ERROR.getMsg());\n+        }\n+    }\n+\n+}",
                "changes": 193
            },
            {
                "status": "added",
                "additions": 253,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java",
                "deletions": 0,
                "sha": "e9bffa510bf180501851c9ec98718f7594879eea",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java",
                "patch": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.dolphinscheduler.api.service.AlertGroupService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.enums.AlertType;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * alert group controller\n+ */\n+@Api(tags = \"ALERT_GROUP_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"alert-group\")\n+public class AlertGroupController extends  BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(AlertGroupController.class);\n+\n+    @Autowired\n+    private AlertGroupService alertGroupService;\n+\n+\n+    /**\n+     * create alert group\n+     * @param loginUser login user\n+     * @param groupName group name\n+     * @param groupType group type\n+     * @param description description\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createAlertgroup\", notes= \"CREATE_ALERT_GROUP_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"groupName\", value = \"GROUP_NAME\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"groupType\", value = \"GROUP_TYPE\", required = true, dataType =\"AlertType\"),\n+            @ApiImplicitParam(name = \"description\", value = \"DESC\",  dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createAlertgroup(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                               @RequestParam(value = \"groupName\") String groupName,\n+                               @RequestParam(value = \"groupType\") AlertType groupType,\n+                               @RequestParam(value = \"description\",required = false) String description) {\n+        logger.info(\"loginUser user {}, create alertgroup, groupName: {}, groupType: {}, desc: {}\",\n+                loginUser.getUserName(), groupName, groupType,description);\n+        try {\n+            Map<String, Object> result = alertGroupService.createAlertgroup(loginUser, groupName, groupType,description);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.CREATE_ALERT_GROUP_ERROR.getMsg(),e);\n+            return error(Status.CREATE_ALERT_GROUP_ERROR.getCode(), Status.CREATE_ALERT_GROUP_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * alert group list\n+     * @param loginUser login user\n+     * @return alert group list\n+     */\n+    @ApiOperation(value = \"list\", notes= \"QUERY_ALERT_GROUP_LIST_NOTES\")\n+    @GetMapping(value = \"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result list(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+        logger.info(\"login  user {}, query all alertGroup\",\n+                loginUser.getUserName());\n+        try{\n+            HashMap<String, Object> result = alertGroupService.queryAlertgroup();\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_ALL_ALERTGROUP_ERROR.getMsg(),e);\n+            return error(Status.QUERY_ALL_ALERTGROUP_ERROR.getCode(), Status.QUERY_ALL_ALERTGROUP_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * paging query alarm group list\n+     *\n+     * @param loginUser login user\n+     * @param pageNo page number\n+     * @param searchVal search value\n+     * @param pageSize page size\n+     * @return alert group list page\n+     */\n+    @ApiOperation(value = \"queryAlertGroupListPaging\", notes= \"QUERY_ALERT_GROUP_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", type =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType = \"Int\", example = \"20\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result listPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                             @RequestParam(\"pageNo\") Integer pageNo,\n+                             @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                             @RequestParam(\"pageSize\") Integer pageSize){\n+        logger.info(\"login  user {}, list paging, pageNo: {}, searchVal: {}, pageSize: {}\",\n+                loginUser.getUserName(),pageNo,searchVal,pageSize);\n+        try{\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = alertGroupService.listPaging(loginUser, searchVal, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.LIST_PAGING_ALERT_GROUP_ERROR.getMsg(),e);\n+            return error(Status.LIST_PAGING_ALERT_GROUP_ERROR.getCode(), Status.LIST_PAGING_ALERT_GROUP_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * updateProcessInstance alert group\n+     * @param loginUser login user\n+     * @param id alert group id\n+     * @param groupName group name\n+     * @param groupType group type\n+     * @param description description\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateAlertgroup\", notes= \"UPDATE_ALERT_GROUP_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"ALERT_GROUP_ID\", required = true, dataType = \"Int\",example = \"100\"),\n+            @ApiImplicitParam(name = \"groupName\", value = \"GROUP_NAME\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"groupType\", value = \"GROUP_TYPE\", required = true, dataType =\"AlertType\"),\n+            @ApiImplicitParam(name = \"description\", value = \"DESC\",  dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateAlertgroup(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(value = \"id\") int id,\n+                                   @RequestParam(value = \"groupName\") String groupName,\n+                                   @RequestParam(value = \"groupType\") AlertType groupType,\n+                                   @RequestParam(value = \"description\",required = false) String description) {\n+        logger.info(\"login  user {}, updateProcessInstance alertgroup, groupName: {}, groupType: {}, desc: {}\",\n+                loginUser.getUserName(), groupName, groupType,description);\n+        try {\n+            Map<String, Object> result = alertGroupService.updateAlertgroup(loginUser, id, groupName, groupType, description);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.UPDATE_ALERT_GROUP_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_ALERT_GROUP_ERROR.getCode(), Status.UPDATE_ALERT_GROUP_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete alert group by id\n+     * @param loginUser login user\n+     * @param id alert group id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"delAlertgroupById\", notes= \"DELETE_ALERT_GROUP_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"ALERT_GROUP_ID\", required = true, dataType = \"Int\",example = \"100\")\n+    })\n+    @PostMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result delAlertgroupById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                  @RequestParam(value = \"id\") int id) {\n+        logger.info(\"login user {}, delete AlertGroup, id: {},\", loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> result = alertGroupService.delAlertgroupById(loginUser, id);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.DELETE_ALERT_GROUP_ERROR.getMsg(),e);\n+            return error(Status.DELETE_ALERT_GROUP_ERROR.getCode(), Status.DELETE_ALERT_GROUP_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * check alert group exist\n+     * @param loginUser login user\n+     * @param groupName group name\n+     * @return check result code\n+     */\n+    @ApiOperation(value = \"verifyGroupName\", notes= \"VERIFY_ALERT_GROUP_NAME_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"groupName\", value = \"GROUP_NAME\", required = true, dataType = \"String\"),\n+    })\n+    @GetMapping(value = \"/verify-group-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyGroupName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(value =\"groupName\") String groupName\n+    ) {\n+        logger.info(\"login user {}, verfiy group name: {}\",\n+                loginUser.getUserName(),groupName);\n+\n+        return alertGroupService.verifyGroupName(loginUser, groupName);\n+    }\n+\n+    /**\n+     * grant user\n+     *\n+     * @param loginUser login user\n+     * @param userIds user ids in the group\n+     * @param alertgroupId alert group id\n+     * @return grant result code\n+     */\n+    @ApiOperation(value = \"grantUser\", notes= \"GRANT_ALERT_GROUP_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"ALERT_GROUP_ID\", required = true, dataType = \"Int\",example = \"100\"),\n+            @ApiImplicitParam(name = \"userIds\", value = \"USER_IDS\", required = true, dataType = \"String\")\n+    })\n+    @PostMapping(value = \"/grant-user\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result grantUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                  @RequestParam(value = \"alertgroupId\") int  alertgroupId,\n+                                  @RequestParam(value = \"userIds\") String userIds) {\n+        logger.info(\"login user {}, grant user, alertGroupId: {},userIds : {}\", loginUser.getUserName(), alertgroupId,userIds);\n+        try {\n+            Map<String, Object> result = alertGroupService.grantUser(loginUser, alertgroupId, userIds);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.ALERT_GROUP_GRANT_USER_ERROR.getMsg(),e);\n+            return error(Status.ALERT_GROUP_GRANT_USER_ERROR.getCode(), Status.ALERT_GROUP_GRANT_USER_ERROR.getMsg());\n+        }\n+    }\n+}",
                "changes": 253
            },
            {
                "status": "added",
                "additions": 274,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/BaseController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/BaseController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/BaseController.java",
                "deletions": 0,
                "sha": "ba062472b36ccefe166f60420507ff88600c92b1",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/BaseController.java",
                "patch": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.utils.PageInfo;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.Resource;\n+import org.apache.commons.lang3.StringUtils;\n+\n+import javax.servlet.http.HttpServletRequest;\n+import java.text.MessageFormat;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.common.Constants.*;\n+\n+/**\n+ * base controller\n+ */\n+public class BaseController {\n+\n+    /**\n+     * check params\n+     *\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return check result code\n+     */\n+    public Map<String, Object> checkPageParams(int pageNo, int pageSize) {\n+        Map<String, Object> result = new HashMap<>(2);\n+        Status resultEnum = Status.SUCCESS;\n+        String msg = Status.SUCCESS.getMsg();\n+        if (pageNo <= 0) {\n+            resultEnum = Status.REQUEST_PARAMS_NOT_VALID_ERROR;\n+            msg = MessageFormat.format(Status.REQUEST_PARAMS_NOT_VALID_ERROR.getMsg(), Constants.PAGE_NUMBER);\n+        } else if (pageSize <= 0) {\n+            resultEnum = Status.REQUEST_PARAMS_NOT_VALID_ERROR;\n+            msg = MessageFormat.format(Status.REQUEST_PARAMS_NOT_VALID_ERROR.getMsg(), Constants.PAGE_SIZE);\n+        }\n+        result.put(Constants.STATUS, resultEnum);\n+        result.put(Constants.MSG, msg);\n+        return result;\n+    }\n+\n+    /**\n+     * get ip address in the http request\n+     *\n+     * @param request http servlet request\n+     * @return client ip address\n+     */\n+    public static String getClientIpAddress(HttpServletRequest request) {\n+        String clientIp = request.getHeader(HTTP_X_FORWARDED_FOR);\n+\n+        if (StringUtils.isNotEmpty(clientIp) && !StringUtils.equalsIgnoreCase(HTTP_HEADER_UNKNOWN, clientIp)) {\n+            int index = clientIp.indexOf(COMMA);\n+            if (index != -1) {\n+                return clientIp.substring(0, index);\n+            } else {\n+                return clientIp;\n+            }\n+        }\n+\n+        clientIp = request.getHeader(HTTP_X_REAL_IP);\n+        if (StringUtils.isNotEmpty(clientIp) && !StringUtils.equalsIgnoreCase(HTTP_HEADER_UNKNOWN, clientIp)) {\n+            return clientIp;\n+        }\n+\n+        return request.getRemoteAddr();\n+    }\n+\n+    /**\n+     * return data list\n+     *\n+     * @param result result code\n+     * @return result code\n+     */\n+    public Result returnDataList(Map<String, Object> result) {\n+        Status status = (Status) result.get(Constants.STATUS);\n+        if (status == Status.SUCCESS) {\n+            String msg = Status.SUCCESS.getMsg();\n+            Object datalist = result.get(Constants.DATA_LIST);\n+            return success(msg, datalist);\n+        } else {\n+            Integer code = status.getCode();\n+            String msg = (String) result.get(Constants.MSG);\n+            return error(code, msg);\n+        }\n+    }\n+\n+    /**\n+     * return data list with paging\n+     * @param result result code\n+     * @return result code\n+     */\n+    public Result returnDataListPaging(Map<String, Object> result) {\n+        Status status = (Status) result.get(Constants.STATUS);\n+        if (status == Status.SUCCESS) {\n+            result.put(Constants.MSG, Status.SUCCESS.getMsg());\n+            PageInfo<Resource> pageInfo = (PageInfo<Resource>) result.get(Constants.DATA_LIST);\n+            return success(pageInfo.getLists(), pageInfo.getCurrentPage(), pageInfo.getTotalCount(),\n+                    pageInfo.getTotalPage());\n+        } else {\n+            Integer code = status.getCode();\n+            String msg = (String) result.get(Constants.MSG);\n+            return error(code, msg);\n+        }\n+    }\n+\n+    /**\n+     * success\n+     *\n+     * @return success result code\n+     */\n+    public Result success() {\n+        Result result = new Result();\n+        result.setCode(Status.SUCCESS.getCode());\n+        result.setMsg(Status.SUCCESS.getMsg());\n+\n+        return result;\n+    }\n+\n+    /**\n+     * success does not need to return data\n+     *\n+     * @param msg success message\n+     * @return success result code\n+     */\n+    public Result success(String msg) {\n+        Result result = new Result();\n+        result.setCode(Status.SUCCESS.getCode());\n+        result.setMsg(msg);\n+\n+        return result;\n+    }\n+\n+    /**\n+     * return data no paging\n+     *\n+     * @param msg success message\n+     * @param list data list\n+     * @return success result code\n+     */\n+    public Result success(String msg, Object list) {\n+        Result result = getResult(msg, list);\n+        return result;\n+    }\n+\n+    /**\n+     * return data no paging\n+     *\n+     * @param list success\n+     * @return success result code\n+     */\n+    public Result success(Object list) {\n+        Result result = getResult(Status.SUCCESS.getMsg(), list);\n+        return result;\n+    }\n+\n+    /**\n+     * return the data use Map format, for example, passing the value of key, value, passing a value\n+     * eg. \"/user/add\"  then return user name: zhangsan\n+     *\n+     * @param msg message\n+     * @param object success object data\n+     * @return success result code\n+     */\n+    public Result success(String msg, Map<String, Object> object) {\n+        Result result = getResult(msg, object);\n+        return result;\n+    }\n+\n+    /**\n+     * return data with paging\n+     *\n+     * @param totalList success object list\n+     * @param currentPage current page\n+     * @param total total\n+     * @param totalPage  total page\n+     * @return success result code\n+     */\n+    public Result success(Object totalList, Integer currentPage,\n+                                                  Integer total, Integer totalPage) {\n+        Result result = new Result();\n+        result.setCode(Status.SUCCESS.getCode());\n+        result.setMsg(Status.SUCCESS.getMsg());\n+\n+        Map<String, Object> map = new HashMap<>(4);\n+        map.put(Constants.TOTAL_LIST, totalList);\n+        map.put(Constants.CURRENT_PAGE, currentPage);\n+        map.put(Constants.TOTAL_PAGE, totalPage);\n+        map.put(Constants.TOTAL, total);\n+        result.setData(map);\n+        return result;\n+    }\n+\n+    /**\n+     * error handle\n+     *\n+     * @param code result code\n+     * @param msg result message\n+     * @return error result code\n+     */\n+    public Result error(Integer code, String msg) {\n+        Result result = new Result();\n+        result.setCode(code);\n+        result.setMsg(msg);\n+        return result;\n+    }\n+\n+    /**\n+     * put message to map\n+     *\n+     * @param result result\n+     * @param status status\n+     * @param statusParams object messages\n+     */\n+    protected void putMsg(Map<String, Object> result, Status status, Object... statusParams) {\n+        result.put(Constants.STATUS, status);\n+        if (statusParams != null && statusParams.length > 0) {\n+            result.put(Constants.MSG, MessageFormat.format(status.getMsg(), statusParams));\n+        } else {\n+            result.put(Constants.MSG, status.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * put message to result object\n+     *\n+     * @param result result\n+     * @param status status\n+     * @param statusParams status parameters\n+     */\n+    protected void putMsg(Result result, Status status, Object... statusParams) {\n+        result.setCode(status.getCode());\n+\n+        if (statusParams != null && statusParams.length > 0) {\n+            result.setMsg(MessageFormat.format(status.getMsg(), statusParams));\n+        } else {\n+            result.setMsg(status.getMsg());\n+        }\n+\n+    }\n+\n+    /**\n+     * get result\n+     * @param msg message\n+     * @param list object list\n+     * @return result code\n+     */\n+    private Result getResult(String msg, Object list) {\n+        Result result = new Result();\n+        result.setCode(Status.SUCCESS.getCode());\n+        result.setMsg(msg);\n+\n+        result.setData(list);\n+        return result;\n+    }\n+}\n\\ No newline at end of file",
                "changes": 274
            },
            {
                "status": "added",
                "additions": 202,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataAnalysisController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataAnalysisController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataAnalysisController.java",
                "deletions": 0,
                "sha": "92897ac7ff976c2e0be25952a7078bde4c92cc87",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataAnalysisController.java",
                "patch": "@@ -0,0 +1,202 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.service.DataAnalysisService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+/**\n+ * data analysis controller\n+ */\n+@Api(tags = \"DATA_ANALYSIS_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"projects/analysis\")\n+public class DataAnalysisController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(DataAnalysisController.class);\n+\n+\n+    @Autowired\n+    DataAnalysisService dataAnalysisService;\n+\n+    /**\n+     * statistical task instance status data\n+     *\n+     * @param loginUser login user\n+     * @param startDate count start date\n+     * @param endDate count end date\n+     * @param projectId project id\n+     * @return task instance count data\n+     */\n+    @ApiOperation(value = \"countTaskState\", notes= \"COUNT_TASK_STATE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"startDate\", value = \"START_DATE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"endDate\", value = \"END_DATE\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\",  dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/task-state-count\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result countTaskState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                         @RequestParam(value=\"startDate\", required=false) String startDate,\n+                                                         @RequestParam(value=\"endDate\", required=false) String endDate,\n+                                                         @RequestParam(value=\"projectId\", required=false, defaultValue = \"0\") int projectId){\n+        try{\n+            logger.info(\"count task state, user:{}, start date: {}, end date:{}, project id {}\",\n+                    loginUser.getUserName(), startDate, endDate, projectId);\n+            Map<String, Object> result = dataAnalysisService.countTaskStateByProject(loginUser,projectId, startDate, endDate);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.TASK_INSTANCE_STATE_COUNT_ERROR.getMsg(),e);\n+            return error(Status.TASK_INSTANCE_STATE_COUNT_ERROR.getCode(), Status.TASK_INSTANCE_STATE_COUNT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * statistical process instance status data\n+     *\n+     * @param loginUser login user\n+     * @param startDate start date\n+     * @param endDate end date\n+     * @param projectId project id\n+     * @return process instance data\n+     */\n+    @ApiOperation(value = \"countProcessInstanceState\", notes= \"COUNT_PROCESS_INSTANCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"startDate\", value = \"START_DATE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"endDate\", value = \"END_DATE\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\",  dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/process-state-count\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result countProcessInstanceState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @RequestParam(value=\"startDate\", required=false) String startDate,\n+                                            @RequestParam(value=\"endDate\", required=false) String endDate,\n+                                            @RequestParam(value=\"projectId\", required=false, defaultValue = \"0\") int projectId){\n+        try{\n+            logger.info(\"count process instance state, user:{}, start date: {}, end date:{}, project id\",\n+                    loginUser.getUserName(), startDate, endDate, projectId);\n+            Map<String, Object> result = dataAnalysisService.countProcessInstanceStateByProject(loginUser, projectId, startDate, endDate);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.COUNT_PROCESS_INSTANCE_STATE_ERROR.getMsg(),e);\n+            return error(Status.COUNT_PROCESS_INSTANCE_STATE_ERROR.getCode(), Status.COUNT_PROCESS_INSTANCE_STATE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * statistics the process definition quantities of certain person\n+     *\n+     * @param loginUser login user\n+     * @param projectId project id\n+     * @return definition count in project id\n+     */\n+    @ApiOperation(value = \"countDefinitionByUser\", notes= \"COUNT_PROCESS_DEFINITION_BY_USER_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/define-user-count\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result countDefinitionByUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                        @RequestParam(value=\"projectId\", required=false, defaultValue = \"0\") int projectId){\n+        try{\n+            logger.info(\"count process definition , user:{}, project id\",\n+                    loginUser.getUserName(), projectId);\n+            Map<String, Object> result = dataAnalysisService.countDefinitionByUser(loginUser, projectId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.COUNT_PROCESS_DEFINITION_USER_ERROR.getMsg(),e);\n+            return error(Status.COUNT_PROCESS_DEFINITION_USER_ERROR.getCode(), Status.COUNT_PROCESS_DEFINITION_USER_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * statistical command status data\n+     *\n+     * @param loginUser login user\n+     * @param startDate start date\n+     * @param endDate end date\n+     * @param projectId project id\n+     * @return command state in project id\n+     */\n+    @ApiOperation(value = \"countCommandState\", notes= \"COUNT_COMMAND_STATE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"startDate\", value = \"START_DATE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"endDate\", value = \"END_DATE\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\",  dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/command-state-count\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result countCommandState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(value=\"startDate\", required=false) String startDate,\n+                                 @RequestParam(value=\"endDate\", required=false) String endDate,\n+                                 @RequestParam(value=\"projectId\", required=false, defaultValue = \"0\") int projectId){\n+        try{\n+            logger.info(\"count command state, user:{}, start date: {}, end date:{}, project id {}\",\n+                    loginUser.getUserName(), startDate, endDate, projectId);\n+            Map<String, Object> result = dataAnalysisService.countCommandState(loginUser, projectId, startDate, endDate);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.COMMAND_STATE_COUNT_ERROR.getMsg(),e);\n+            return error(Status.COMMAND_STATE_COUNT_ERROR.getCode(), Status.COMMAND_STATE_COUNT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * queue count\n+     *\n+     * @param loginUser login user\n+     * @param projectId project id\n+     * @return queue state count\n+     */\n+    @ApiOperation(value = \"countQueueState\", notes= \"COUNT_QUEUE_STATE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\",  dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/queue-count\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result countQueueState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                    @RequestParam(value=\"projectId\", required=false, defaultValue = \"0\") int projectId){\n+        try{\n+            logger.info(\"count command state, user:{}, start date: {}, end date:{}, project id {}\",\n+                    loginUser.getUserName(), projectId);\n+            Map<String, Object> result = dataAnalysisService.countQueueState(loginUser, projectId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUEUE_COUNT_ERROR.getMsg(),e);\n+            return error(Status.QUEUE_COUNT_ERROR.getCode(), Status.QUEUE_COUNT_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+}",
                "changes": 202
            },
            {
                "status": "added",
                "additions": 473,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java",
                "deletions": 0,
                "sha": "d4844a693d9991c2410e0c36c12b2f99e76d2fea",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java",
                "patch": "@@ -0,0 +1,473 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.DataSourceService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.enums.DbType;\n+import org.apache.dolphinscheduler.common.utils.CommonUtils;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+/**\n+ * data source controller\n+ */\n+@Api(tags = \"DATA_SOURCE_TAG\", position = 3)\n+@RestController\n+@RequestMapping(\"datasources\")\n+public class DataSourceController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(DataSourceController.class);\n+\n+    @Autowired\n+    private DataSourceService dataSourceService;\n+\n+    /**\n+     * create data source\n+     * @param loginUser login user\n+     * @param name data source name\n+     * @param note  data source description\n+     * @param type data source type\n+     * @param host host\n+     * @param port port\n+     * @param database data base\n+     * @param principal principal\n+     * @param userName user name\n+     * @param password password\n+     * @param other other arguments\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createDataSource\", notes= \"CREATE_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"DATA_SOURCE_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"note\", value = \"DATA_SOURCE_NOTE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"type\", value = \"DB_TYPE\", required = true,dataType =\"DbType\"),\n+            @ApiImplicitParam(name = \"host\", value = \"DATA_SOURCE_HOST\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"port\", value = \"DATA_SOURCE_PORT\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"database\", value = \"DATABASE_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"password\", value = \"PASSWORD\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"other\", value = \"DATA_SOURCE_OTHER\", dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createDataSource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"name\") String name,\n+                                   @RequestParam(value = \"note\", required = false) String note,\n+                                   @RequestParam(value = \"type\") DbType type,\n+                                   @RequestParam(value = \"host\") String host,\n+                                   @RequestParam(value = \"port\") String port,\n+                                   @RequestParam(value = \"database\") String database,\n+                                   @RequestParam(value = \"principal\") String principal,\n+                                   @RequestParam(value = \"userName\") String userName,\n+                                   @RequestParam(value = \"password\") String password,\n+                                   @RequestParam(value = \"other\") String other) {\n+        logger.info(\"login user {} create datasource name: {}, note: {}, type: {}, host: {},port: {},database : {},principal: {},userName : {} other: {}\",\n+                loginUser.getUserName(), name, note, type, host,port,database,principal,userName,other);\n+        try {\n+            String parameter = dataSourceService.buildParameter(name, note, type, host, port, database,principal,userName, password, other);\n+            Map<String, Object> result = dataSourceService.createDataSource(loginUser, name, note, type, parameter);\n+            return returnDataList(result);\n+\n+        } catch (Exception e) {\n+            logger.error(CREATE_DATASOURCE_ERROR.getMsg(),e);\n+            return error(Status.CREATE_DATASOURCE_ERROR.getCode(), Status.CREATE_DATASOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * updateProcessInstance data source\n+     *\n+     * @param loginUser login user\n+     * @param name data source name\n+     * @param note description\n+     * @param type data source type\n+     * @param other other arguments\n+     * @param id data source di\n+     * @param host host\n+     * @param port port\n+     * @param database database\n+     * @param principal principal\n+     * @param userName user name\n+     * @param password password\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateDataSource\", notes= \"UPDATE_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"DATA_SOURCE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"name\", value = \"DATA_SOURCE_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"note\", value = \"DATA_SOURCE_NOTE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"type\", value = \"DB_TYPE\", required = true,dataType =\"DbType\"),\n+            @ApiImplicitParam(name = \"host\", value = \"DATA_SOURCE_HOST\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"port\", value = \"DATA_SOURCE_PORT\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"database\", value = \"DATABASE_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"password\", value = \"PASSWORD\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"other\", value = \"DATA_SOURCE_OTHER\", dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateDataSource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"id\") int id,\n+                                   @RequestParam(\"name\") String name,\n+                                   @RequestParam(value = \"note\", required = false) String note,\n+                                   @RequestParam(value = \"type\") DbType type,\n+                                   @RequestParam(value = \"host\") String host,\n+                                   @RequestParam(value = \"port\") String port,\n+                                   @RequestParam(value = \"database\") String database,\n+                                   @RequestParam(value = \"principal\") String principal,\n+                                   @RequestParam(value = \"userName\") String userName,\n+                                   @RequestParam(value = \"password\") String password,\n+                                   @RequestParam(value = \"other\") String other) {\n+        logger.info(\"login user {} updateProcessInstance datasource name: {}, note: {}, type: {}, other: {}\",\n+                loginUser.getUserName(), name, note, type, other);\n+        try {\n+            String parameter = dataSourceService.buildParameter(name, note, type, host, port, database,principal, userName, password, other);\n+            Map<String, Object> dataSource = dataSourceService.updateDataSource(id, loginUser, name, note, type, parameter);\n+            return returnDataList(dataSource);\n+        } catch (Exception e) {\n+            logger.error(UPDATE_DATASOURCE_ERROR.getMsg(),e);\n+            return error(UPDATE_DATASOURCE_ERROR.getCode(), UPDATE_DATASOURCE_ERROR.getMsg());\n+        }\n+\n+\n+    }\n+\n+    /**\n+     * query data source detail\n+     *\n+     * @param loginUser login user\n+     * @param id datasource id\n+     * @return data source detail\n+     */\n+    @ApiOperation(value = \"queryDataSource\", notes= \"QUERY_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"DATA_SOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+\n+    })\n+    @PostMapping(value = \"/update-ui\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryDataSource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                  @RequestParam(\"id\") int id) {\n+        logger.info(\"login user {}, query datasource: {}\",\n+                loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> result  = dataSourceService.queryDataSource(id);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_DATASOURCE_ERROR.getMsg(),e);\n+            return error(Status.QUERY_DATASOURCE_ERROR.getCode(), Status.QUERY_DATASOURCE_ERROR.getMsg());\n+        }\n+\n+\n+    }\n+\n+    /**\n+     * query datasouce by type\n+     *\n+     * @param loginUser login user\n+     * @param type data source type\n+     * @return data source list page\n+     */\n+    @ApiOperation(value = \"queryDataSourceList\", notes= \"QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"DB_TYPE\", required = true,dataType =\"DbType\")\n+    })\n+    @GetMapping(value = \"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryDataSourceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                      @RequestParam(\"type\") DbType type) {\n+        try {\n+            Map<String, Object> result = dataSourceService.queryDataSourceList(loginUser, type.ordinal());\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_DATASOURCE_ERROR.getMsg(),e);\n+            return error(Status.QUERY_DATASOURCE_ERROR.getCode(), Status.QUERY_DATASOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query datasource with paging\n+     *\n+     * @param loginUser login user\n+     * @param searchVal search value\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return data source list page\n+     */\n+    @ApiOperation(value = \"queryDataSourceListPaging\", notes= \"QUERY_DATA_SOURCE_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value = \"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryDataSourceListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                            @RequestParam(\"pageNo\") Integer pageNo,\n+                                            @RequestParam(\"pageSize\") Integer pageSize) {\n+        try {\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if (result.get(Constants.STATUS) != Status.SUCCESS) {\n+                return returnDataListPaging(result);\n+            }\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = dataSourceService.queryDataSourceListPaging(loginUser, searchVal, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_DATASOURCE_ERROR.getMsg(),e);\n+            return error(QUERY_DATASOURCE_ERROR.getCode(), QUERY_DATASOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * connect datasource\n+     *\n+     * @param loginUser login user\n+     * @param name data source name\n+     * @param note data soruce description\n+     * @param type data source type\n+     * @param other other parameters\n+     * @param host host\n+     * @param port port\n+     * @param database data base\n+     * @param principal principal\n+     * @param userName user name\n+     * @param password password\n+     * @return connect result code\n+     */\n+    @ApiOperation(value = \"connectDataSource\", notes= \"CONNECT_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"DATA_SOURCE_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"note\", value = \"DATA_SOURCE_NOTE\", dataType = \"String\"),\n+            @ApiImplicitParam(name = \"type\", value = \"DB_TYPE\", required = true,dataType =\"DbType\"),\n+            @ApiImplicitParam(name = \"host\", value = \"DATA_SOURCE_HOST\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"port\", value = \"DATA_SOURCE_PORT\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"database\", value = \"DATABASE_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"password\", value = \"PASSWORD\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"other\", value = \"DATA_SOURCE_OTHER\", dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/connect\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result connectDataSource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                    @RequestParam(\"name\") String name,\n+                                    @RequestParam(value = \"note\", required = false) String note,\n+                                    @RequestParam(value = \"type\") DbType type,\n+                                    @RequestParam(value = \"host\") String host,\n+                                    @RequestParam(value = \"port\") String port,\n+                                    @RequestParam(value = \"database\") String database,\n+                                    @RequestParam(value = \"principal\") String principal,\n+                                    @RequestParam(value = \"userName\") String userName,\n+                                    @RequestParam(value = \"password\") String password,\n+                                    @RequestParam(value = \"other\") String other) {\n+        logger.info(\"login user {}, connect datasource: {} failure, note: {}, type: {}, other: {}\",\n+                loginUser.getUserName(), name, note, type, other);\n+        try {\n+            String parameter = dataSourceService.buildParameter(name, note, type, host, port, database,principal,userName, password, other);\n+            Boolean isConnection = dataSourceService.checkConnection(type, parameter);\n+            Result result = new Result();\n+\n+            if (isConnection) {\n+                putMsg(result, SUCCESS);\n+            } else {\n+                putMsg(result, CONNECT_DATASOURCE_FAILURE);\n+            }\n+            return result;\n+        } catch (Exception e) {\n+            logger.error(CONNECT_DATASOURCE_FAILURE.getMsg(),e);\n+            return error(CONNECT_DATASOURCE_FAILURE.getCode(), CONNECT_DATASOURCE_FAILURE.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * connection test\n+     *\n+     * @param loginUser login user\n+     * @param id  data source id\n+     * @return connect result code\n+     */\n+    @ApiOperation(value = \"connectionTest\", notes= \"CONNECT_DATA_SOURCE_TEST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"DATA_SOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/connect-by-id\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result connectionTest(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(\"id\") int id) {\n+        logger.info(\"connection test, login user:{}, id:{}\", loginUser.getUserName(), id);\n+\n+        try {\n+            Boolean isConnection = dataSourceService.connectionTest(loginUser, id);\n+            Result result = new Result();\n+\n+            if (isConnection) {\n+                putMsg(result, SUCCESS);\n+            } else {\n+                putMsg(result, CONNECTION_TEST_FAILURE);\n+            }\n+            return result;\n+        } catch (Exception e) {\n+            logger.error(CONNECTION_TEST_FAILURE.getMsg(),e);\n+            return error(CONNECTION_TEST_FAILURE.getCode(), CONNECTION_TEST_FAILURE.getMsg());\n+        }\n+\n+    }\n+\n+    /**\n+     * delete datasource by id\n+     *\n+     * @param loginUser login user\n+     * @param id datasource id\n+     * @return delete result\n+     */\n+    @ApiOperation(value = \"delete\", notes= \"DELETE_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"DATA_SOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result delete(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                         @RequestParam(\"id\") int id) {\n+        try {\n+            logger.info(\"delete datasource,login user:{}, id:{}\", loginUser.getUserName(), id);\n+            return dataSourceService.delete(loginUser, id);\n+        } catch (Exception e) {\n+            logger.error(DELETE_DATA_SOURCE_FAILURE.getMsg(),e);\n+            return error(DELETE_DATA_SOURCE_FAILURE.getCode(), DELETE_DATA_SOURCE_FAILURE.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * verify datasource name\n+     *\n+     * @param loginUser login user\n+     * @param name data source name\n+     * @return true if data source name not exists.otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyDataSourceName\", notes= \"VERIFY_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"DATA_SOURCE_NAME\", required = true, dataType =\"String\")\n+    })\n+    @GetMapping(value = \"/verify-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyDataSourceName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                       @RequestParam(value = \"name\") String name\n+    ) {\n+        logger.info(\"login user {}, verfiy datasource name: {}\",\n+                loginUser.getUserName(), name);\n+\n+        try {\n+            return dataSourceService.verifyDataSourceName(loginUser, name);\n+        } catch (Exception e) {\n+            logger.error(VERFIY_DATASOURCE_NAME_FAILURE.getMsg(),e);\n+            return error(VERFIY_DATASOURCE_NAME_FAILURE.getCode(), VERFIY_DATASOURCE_NAME_FAILURE.getMsg());\n+        }\n+    }\n+\n+\n+\n+    /**\n+     * unauthorized datasource\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return unauthed data source result code\n+     */\n+    @ApiOperation(value = \"unauthDatasource\", notes= \"UNAUTHORIZED_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/unauth-datasource\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result unauthDatasource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"userId\") Integer userId) {\n+        try {\n+            logger.info(\"unauthorized datasource, login user:{}, unauthorized userId:{}\",\n+                    loginUser.getUserName(), userId);\n+            Map<String, Object> result = dataSourceService.unauthDatasource(loginUser, userId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(UNAUTHORIZED_DATASOURCE.getMsg(),e);\n+            return error(UNAUTHORIZED_DATASOURCE.getCode(), UNAUTHORIZED_DATASOURCE.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * authorized datasource\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return authorized result code\n+     */\n+    @ApiOperation(value = \"authedDatasource\", notes= \"AUTHORIZED_DATA_SOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/authed-datasource\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result authedDatasource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"userId\") Integer userId) {\n+        try {\n+            logger.info(\"authorized data source, login user:{}, authorized useId:{}\",\n+                    loginUser.getUserName(), userId);\n+            Map<String, Object> result = dataSourceService.authedDatasource(loginUser, userId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(AUTHORIZED_DATA_SOURCE.getMsg(),e);\n+            return error(AUTHORIZED_DATA_SOURCE.getCode(), AUTHORIZED_DATA_SOURCE.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * get user info\n+     *\n+     * @param loginUser login user\n+     * @return user info data\n+     */\n+    @ApiOperation(value = \"getKerberosStartupState\", notes= \"GET_USER_INFO_NOTES\")\n+    @GetMapping(value=\"/kerberos-startup-state\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result getKerberosStartupState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        logger.info(\"login user {},get kerberos startup state : {}\", loginUser.getUserName());\n+        try{\n+            // if upload resource is HDFS and kerberos startup is true , else false\n+            return success(Status.SUCCESS.getMsg(), CommonUtils.getKerberosStartupState());\n+        }catch (Exception e){\n+            logger.error(KERBEROS_STARTUP_STATE.getMsg(),e);\n+            return error(Status.KERBEROS_STARTUP_STATE.getCode(), Status.KERBEROS_STARTUP_STATE.getMsg());\n+        }\n+    }\n+}",
                "changes": 473
            },
            {
                "status": "added",
                "additions": 218,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java",
                "deletions": 0,
                "sha": "93b095ddf8afed64fe80f17362a028b4e75b5021",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java",
                "patch": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.ExecuteType;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.ExecutorService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.apache.dolphinscheduler.common.enums.*;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * execute process controller\n+ */\n+@Api(tags = \"PROCESS_INSTANCE_EXECUTOR_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"projects/{projectName}/executors\")\n+public class ExecutorController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ExecutorController.class);\n+\n+    @Autowired\n+    private ExecutorService execService;\n+\n+    /**\n+     * execute process instance\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @param scheduleTime schedule time\n+     * @param failureStrategy failure strategy\n+     * @param startNodeList start nodes list\n+     * @param taskDependType task depend type\n+     * @param execType execute type\n+     * @param warningType warning type\n+     * @param warningGroupId warning group id\n+     * @param receivers receivers\n+     * @param receiversCc receivers cc\n+     * @param runMode run mode\n+     * @param processInstancePriority process instance priority\n+     * @param workerGroupId worker group id\n+     * @param timeout timeout\n+     * @return start process result code\n+     */\n+    @ApiOperation(value = \"startProcessInstance\", notes= \"RUN_PROCESS_INSTANCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"scheduleTime\", value = \"SCHEDULE_TIME\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"failureStrategy\", value = \"FAILURE_STRATEGY\", required = true, dataType =\"FailureStrategy\"),\n+            @ApiImplicitParam(name = \"startNodeList\", value = \"START_NODE_LIST\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"taskDependType\", value = \"TASK_DEPEND_TYPE\", dataType =\"TaskDependType\"),\n+            @ApiImplicitParam(name = \"execType\", value = \"COMMAND_TYPE\", dataType =\"CommandType\"),\n+            @ApiImplicitParam(name = \"warningType\", value = \"WARNING_TYPE\",required = true, dataType =\"WarningType\"),\n+            @ApiImplicitParam(name = \"warningGroupId\", value = \"WARNING_GROUP_ID\",required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"receivers\", value = \"RECEIVERS\",dataType =\"String\" ),\n+            @ApiImplicitParam(name = \"receiversCc\", value = \"RECEIVERS_CC\",dataType =\"String\" ),\n+            @ApiImplicitParam(name = \"runMode\", value = \"RUN_MODE\",dataType =\"RunMode\" ),\n+            @ApiImplicitParam(name = \"processInstancePriority\", value = \"PROCESS_INSTANCE_PRIORITY\", required = true, dataType = \"Priority\" ),\n+            @ApiImplicitParam(name = \"workerGroupId\", value = \"WORKER_GROUP_ID\", dataType = \"Int\",example = \"100\"),\n+            @ApiImplicitParam(name = \"timeout\", value = \"TIMEOUT\", dataType = \"Int\",example = \"100\"),\n+    })\n+    @PostMapping(value = \"start-process-instance\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result startProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                       @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                       @RequestParam(value = \"processDefinitionId\") int processDefinitionId,\n+                                       @RequestParam(value = \"scheduleTime\", required = false) String scheduleTime,\n+                                       @RequestParam(value = \"failureStrategy\", required = true) FailureStrategy failureStrategy,\n+                                       @RequestParam(value = \"startNodeList\", required = false) String startNodeList,\n+                                       @RequestParam(value = \"taskDependType\", required = false) TaskDependType taskDependType,\n+                                       @RequestParam(value = \"execType\", required = false) CommandType execType,\n+                                       @RequestParam(value = \"warningType\", required = true) WarningType warningType,\n+                                       @RequestParam(value = \"warningGroupId\", required = false) int warningGroupId,\n+                                       @RequestParam(value = \"receivers\", required = false) String receivers,\n+                                       @RequestParam(value = \"receiversCc\", required = false) String receiversCc,\n+                                       @RequestParam(value = \"runMode\", required = false) RunMode runMode,\n+                                       @RequestParam(value = \"processInstancePriority\", required = false) Priority processInstancePriority,\n+                                       @RequestParam(value = \"workerGroupId\", required = false, defaultValue = \"-1\") int workerGroupId,\n+                                       @RequestParam(value = \"timeout\", required = false) Integer timeout) {\n+        try {\n+            logger.info(\"login user {}, start process instance, project name: {}, process definition id: {}, schedule time: {}, \"\n+                            + \"failure policy: {}, node name: {}, node dep: {}, notify type: {}, \"\n+                            + \"notify group id: {},receivers:{},receiversCc:{}, run mode: {},process instance priority:{}, workerGroupId: {}, timeout: {}\",\n+                    loginUser.getUserName(), projectName, processDefinitionId, scheduleTime,\n+                    failureStrategy, startNodeList, taskDependType, warningType, warningGroupId,receivers,receiversCc,runMode,processInstancePriority,\n+                    workerGroupId, timeout);\n+\n+            if (timeout == null) {\n+                timeout = Constants.MAX_TASK_TIMEOUT;\n+            }\n+\n+            Map<String, Object> result = execService.execProcessInstance(loginUser, projectName, processDefinitionId, scheduleTime, execType, failureStrategy,\n+                            startNodeList, taskDependType, warningType,\n+                    warningGroupId,receivers,receiversCc, runMode,processInstancePriority, workerGroupId, timeout);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(Status.START_PROCESS_INSTANCE_ERROR.getMsg(),e);\n+            return error(Status.START_PROCESS_INSTANCE_ERROR.getCode(), Status.START_PROCESS_INSTANCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * do action to process instance\uff1apause, stop, repeat, recover from pause, recover from stop\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @param executeType execute type\n+     * @return execute result code\n+     */\n+    @ApiOperation(value = \"execute\", notes= \"EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"executeType\", value = \"EXECUTE_TYPE\", required = true, dataType = \"ExecuteType\")\n+    })\n+    @PostMapping(value = \"/execute\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result execute(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                          @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                          @RequestParam(\"processInstanceId\") Integer processInstanceId,\n+                          @RequestParam(\"executeType\") ExecuteType executeType\n+    ) {\n+        try {\n+            logger.info(\"execute command, login user: {}, project:{}, process instance id:{}, execute type:{}\",\n+                    loginUser.getUserName(), projectName, processInstanceId, executeType.toString());\n+            Map<String, Object> result = execService.execute(loginUser, projectName, processInstanceId, executeType);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(Status.EXECUTE_PROCESS_INSTANCE_ERROR.getMsg(),e);\n+            return error(Status.EXECUTE_PROCESS_INSTANCE_ERROR.getCode(), Status.EXECUTE_PROCESS_INSTANCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * check process definition and all of the son process definitions is on line.\n+     *\n+     * @param loginUser login user\n+     * @param processDefinitionId process definition id\n+     * @return check result code\n+     */\n+    @ApiOperation(value = \"startCheckProcessDefinition\", notes= \"START_CHECK_PROCESS_DEFINITION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(value = \"/start-check\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result startCheckProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                             @RequestParam(value = \"processDefinitionId\") int processDefinitionId) {\n+        logger.info(\"login user {}, check process definition\", loginUser.getUserName(), processDefinitionId);\n+        try {\n+            Map<String, Object> result = execService.startCheckByProcessDefinedId(processDefinitionId);\n+            return returnDataList(result);\n+\n+        } catch (Exception e) {\n+            logger.error(Status.CHECK_PROCESS_DEFINITION_ERROR.getMsg(),e);\n+            return error(Status.CHECK_PROCESS_DEFINITION_ERROR.getCode(), Status.CHECK_PROCESS_DEFINITION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query recipients and copyers by process definition ID\n+     *\n+     * @param loginUser login user\n+     * @param processDefinitionId process definition id\n+     * @param processInstanceId process instance id\n+     * @return receivers cc list\n+     */\n+    @ApiIgnore\n+    @ApiOperation(value = \"getReceiverCc\", notes= \"GET_RECEIVER_CC_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", required = true, dataType = \"Int\", example = \"100\")\n+\n+    })\n+    @GetMapping(value = \"/get-receiver-cc\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result getReceiverCc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(value = \"processDefinitionId\",required = false) Integer processDefinitionId,\n+                                @RequestParam(value = \"processInstanceId\",required = false) Integer processInstanceId) {\n+        logger.info(\"login user {}, get process definition receiver and cc\", loginUser.getUserName());\n+        try {\n+            Map<String, Object> result = execService.getReceiverCc(processDefinitionId,processInstanceId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(Status.QUERY_RECIPIENTS_AND_COPYERS_BY_PROCESS_DEFINITION_ERROR.getMsg(),e);\n+            return error(Status.QUERY_RECIPIENTS_AND_COPYERS_BY_PROCESS_DEFINITION_ERROR.getCode(), Status.QUERY_RECIPIENTS_AND_COPYERS_BY_PROCESS_DEFINITION_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+}",
                "changes": 218
            },
            {
                "status": "added",
                "additions": 112,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java",
                "deletions": 0,
                "sha": "802f09ff20b318ad20b93a9b712bc75ce39d329d",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java",
                "patch": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.service.LoggerService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpHeaders;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.ResponseEntity;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+\n+/**\n+ * log controller\n+ */\n+@Api(tags = \"LOGGER_TAG\", position = 13)\n+@RestController\n+@RequestMapping(\"/log\")\n+public class LoggerController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LoggerController.class);\n+\n+\n+    @Autowired\n+    private LoggerService loggerService;\n+\n+    /**\n+     * query task log\n+     * @param loginUser login user\n+     * @param taskInstanceId task instance id\n+     * @param skipNum skip number\n+     * @param limit limit\n+     * @return task log content\n+     */\n+    @ApiOperation(value = \"queryLog\", notes= \"QUERY_TASK_INSTANCE_LOG_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"taskInstId\", value = \"TASK_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"skipLineNum\", value = \"SKIP_LINE_NUM\", dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"limit\", value = \"LIMIT\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/detail\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryLog(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                           @RequestParam(value = \"taskInstId\") int taskInstanceId,\n+                           @RequestParam(value = \"skipLineNum\") int skipNum,\n+                           @RequestParam(value = \"limit\") int limit) {\n+        try {\n+\n+            logger.info(\n+                    \"login user {}, view {} task instance log ,skipLineNum {} , limit {}\", loginUser.getUserName(), taskInstanceId, skipNum, limit);\n+            return loggerService.queryLog(taskInstanceId, skipNum, limit);\n+        } catch (Exception e) {\n+            logger.error(Status.QUERY_TASK_INSTANCE_LOG_ERROR.getMsg(), e);\n+            return error(Status.QUERY_TASK_INSTANCE_LOG_ERROR.getCode(), Status.QUERY_TASK_INSTANCE_LOG_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * download log file\n+     *\n+     * @param loginUser login user\n+     * @param taskInstanceId task instance id\n+     * @return log file content\n+     */\n+    @ApiOperation(value = \"downloadTaskLog\", notes= \"DOWNLOAD_TASK_INSTANCE_LOG_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"taskInstId\", value = \"TASK_ID\",dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/download-log\")\n+    @ResponseBody\n+    public ResponseEntity downloadTaskLog(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                          @RequestParam(value = \"taskInstId\") int taskInstanceId) {\n+        try {\n+            byte[] logBytes = loggerService.getLogBytes(taskInstanceId);\n+            return ResponseEntity\n+                    .ok()\n+                    .header(HttpHeaders.CONTENT_DISPOSITION, \"attachment; filename=\\\"\" + System.currentTimeMillis() + \".log\" + \"\\\"\")\n+                    .body(logBytes);\n+        } catch (Exception e) {\n+            logger.error(Status.DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR.getMsg(), e);\n+            return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(Status.DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR.getMsg());\n+        }\n+    }\n+\n+}",
                "changes": 112
            },
            {
                "status": "added",
                "additions": 148,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java",
                "deletions": 0,
                "sha": "63b2d8447db282a5d6771951a56cf8656b6530c5",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java",
                "patch": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.SessionService;\n+import org.apache.dolphinscheduler.api.service.UsersService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.apache.commons.httpclient.HttpStatus;\n+import org.apache.commons.lang3.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import javax.servlet.http.Cookie;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+\n+/**\n+ * user login controller\n+ *\n+ * swagger bootstrap ui docs refer : https://doc.xiaominfo.com/guide/enh-func.html\n+ */\n+@Api(tags = \"LOGIN_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"\")\n+public class LoginController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LoginController.class);\n+\n+\n+    @Autowired\n+    private SessionService sessionService;\n+\n+    @Autowired\n+    private UsersService userService;\n+\n+\n+    /**\n+     * login\n+     *\n+     * @param userName user name\n+     * @param userPassword user password\n+     * @param request request\n+     * @param response  response\n+     * @return login result\n+     */\n+    @ApiOperation(value = \"login\", notes= \"LOGIN_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"userPassword\", value = \"USER_PASSWORD\", required = true, dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/login\")\n+    public Result login(@RequestParam(value = \"userName\") String userName,\n+                        @RequestParam(value = \"userPassword\") String userPassword,\n+                        HttpServletRequest request,\n+                        HttpServletResponse response) {\n+\n+        try {\n+            logger.info(\"login user name: {} \", userName);\n+\n+            //user name check\n+            if (StringUtils.isEmpty(userName)) {\n+                return error(Status.USER_NAME_NULL.getCode(),\n+                        Status.USER_NAME_NULL.getMsg());\n+            }\n+\n+            // user ip check\n+            String ip = getClientIpAddress(request);\n+            if (StringUtils.isEmpty(ip)) {\n+                return error(IP_IS_EMPTY.getCode(), IP_IS_EMPTY.getMsg());\n+            }\n+\n+            // verify username and password\n+            User user = userService.queryUser(userName, userPassword);\n+\n+            if (user == null) {\n+                return error(Status.USER_NAME_PASSWD_ERROR.getCode(),Status.USER_NAME_PASSWD_ERROR.getMsg()\n+                );\n+            }\n+\n+            // create session\n+            String sessionId = sessionService.createSession(user, ip);\n+\n+            if (sessionId == null) {\n+                return error(Status.LOGIN_SESSION_FAILED.getCode(),\n+                        Status.LOGIN_SESSION_FAILED.getMsg()\n+                );\n+            }\n+\n+            response.setStatus(HttpStatus.SC_OK);\n+            response.addCookie(new Cookie(Constants.SESSION_ID, sessionId));\n+\n+            logger.info(\"sessionId : {}\" , sessionId);\n+            return success(LOGIN_SUCCESS.getMsg(), sessionId);\n+        } catch (Exception e) {\n+            logger.error(USER_LOGIN_FAILURE.getMsg(),e);\n+            return error(USER_LOGIN_FAILURE.getCode(), USER_LOGIN_FAILURE.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * sign out\n+     *\n+     * @param loginUser login user\n+     * @param request  request\n+     * @return sign out result\n+     */\n+    @ApiOperation(value = \"signOut\", notes = \"SIGNOUT_NOTES\")\n+    @PostMapping(value = \"/signOut\")\n+    public Result signOut(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                          HttpServletRequest request) {\n+\n+        try {\n+            logger.info(\"login user:{} sign out\", loginUser.getUserName());\n+            String ip = getClientIpAddress(request);\n+            sessionService.signOut(ip, loginUser);\n+            //clear session\n+            request.removeAttribute(Constants.SESSION_USER);\n+            return success();\n+        } catch (Exception e) {\n+            logger.error(SIGN_OUT_ERROR.getMsg(),e);\n+            return error(SIGN_OUT_ERROR.getCode(), SIGN_OUT_ERROR.getMsg());\n+        }\n+    }\n+}",
                "changes": 148
            },
            {
                "status": "added",
                "additions": 131,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java",
                "deletions": 0,
                "sha": "74a5d91a6c4d76f89e55a7ab9d00010a09dc7cc4",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java",
                "patch": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.service.MonitorService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+/**\n+ * monitor controller\n+ */\n+@Api(tags = \"MONITOR_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"/monitor\")\n+public class MonitorController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(MonitorController.class);\n+\n+    @Autowired\n+    private MonitorService monitorService;\n+\n+    /**\n+     * master list\n+     * @param loginUser login user\n+     * @return master list\n+     */\n+    @ApiOperation(value = \"listMaster\", notes= \"MASTER_LIST_NOTES\")\n+    @GetMapping(value = \"/master/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result listMaster(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+        logger.info(\"login user: {}, query all master\", loginUser.getUserName());\n+        try{\n+            logger.info(\"list master, user:{}\", loginUser.getUserName());\n+            Map<String, Object> result = monitorService.queryMaster(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(LIST_MASTERS_ERROR.getMsg(),e);\n+            return error(LIST_MASTERS_ERROR.getCode(),\n+                    LIST_MASTERS_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * worker list\n+     * @param loginUser login user\n+     * @return worker information list\n+     */\n+    @ApiOperation(value = \"listWorker\", notes= \"WORKER_LIST_NOTES\")\n+    @GetMapping(value = \"/worker/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result listWorker(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+        logger.info(\"login user: {}, query all workers\", loginUser.getUserName());\n+        try{\n+            Map<String, Object> result = monitorService.queryWorker(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(LIST_WORKERS_ERROR.getMsg(),e);\n+            return error(LIST_WORKERS_ERROR.getCode(),\n+                    LIST_WORKERS_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query database state\n+     * @param loginUser login user\n+     * @return data base state\n+     */\n+    @ApiOperation(value = \"queryDatabaseState\", notes= \"QUERY_DATABASE_STATE_NOTES\")\n+    @GetMapping(value = \"/database\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryDatabaseState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+        logger.info(\"login user: {}, query database state\", loginUser.getUserName());\n+        try{\n+\n+            Map<String, Object> result = monitorService.queryDatabaseState(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_DATABASE_STATE_ERROR.getMsg(),e);\n+            return error(QUERY_DATABASE_STATE_ERROR.getCode(),\n+                    QUERY_DATABASE_STATE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query zookeeper state\n+     * @param loginUser login user\n+     * @return zookeeper information list\n+     */\n+    @ApiOperation(value = \"queryZookeeperState\", notes= \"QUERY_ZOOKEEPER_STATE_NOTES\")\n+    @GetMapping(value = \"/zookeeper/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryZookeeperState(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+        logger.info(\"login user: {}, query zookeeper state\", loginUser.getUserName());\n+        try{\n+            Map<String, Object> result = monitorService.queryZookeeperState(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_ZOOKEEPER_STATE_ERROR.getMsg(),e);\n+            return error(QUERY_ZOOKEEPER_STATE_ERROR.getCode(),\n+                    QUERY_ZOOKEEPER_STATE_ERROR.getMsg());\n+        }\n+    }\n+\n+}",
                "changes": 131
            },
            {
                "status": "added",
                "additions": 528,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java",
                "deletions": 0,
                "sha": "275dfdd3dbf6db077298dcc88358efd39c877d95",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java",
                "patch": "@@ -0,0 +1,528 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import javax.servlet.http.HttpServletResponse;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * process definition controller\n+ */\n+@Api(tags = \"PROCESS_DEFINITION_TAG\", position = 2)\n+@RestController\n+@RequestMapping(\"projects/{projectName}/process\")\n+public class ProcessDefinitionController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionController.class);\n+\n+    @Autowired\n+    private ProcessDefinitionService processDefinitionService;\n+\n+    /**\n+     * create process definition\n+     * \n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param name process definition name\n+     * @param json process definition json\n+     * @param description description\n+     * @param locations locations for nodes\n+     * @param connects connects for nodes\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"save\", notes= \"CREATE_PROCESS_DEFINITION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"PROCESS_DEFINITION_NAME\", required = true, type = \"String\"),\n+            @ApiImplicitParam(name = \"processDefinitionJson\", value = \"PROCESS_DEFINITION_JSON\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"locations\", value = \"PROCESS_DEFINITION_LOCATIONS\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"connects\", value = \"PROCESS_DEFINITION_CONNECTS\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"PROCESS_DEFINITION_DESC\", required = false, type =\"String\"),\n+    })\n+    @PostMapping(value = \"/save\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                          @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                          @RequestParam(value = \"name\", required = true) String name,\n+                                          @RequestParam(value = \"processDefinitionJson\", required = true) String json,\n+                                          @RequestParam(value = \"locations\", required = true) String locations,\n+                                          @RequestParam(value = \"connects\", required = true) String connects,\n+                                          @RequestParam(value = \"description\", required = false) String description) {\n+\n+        try {\n+            logger.info(\"login user {}, create  process definition, project name: {}, process definition name: {}, \" +\n+                            \"process_definition_json: {}, desc: {} locations:{}, connects:{}\",\n+                    loginUser.getUserName(), projectName, name, json, description, locations, connects);\n+            Map<String, Object> result = processDefinitionService.createProcessDefinition(loginUser, projectName, name, json,\n+                    description, locations, connects);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(Status.CREATE_PROCESS_DEFINITION.getMsg(), e);\n+            return error(Status.CREATE_PROCESS_DEFINITION.getCode(), Status.CREATE_PROCESS_DEFINITION.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * verify process definition name unique\n+     * \n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param name name\n+     * @return true if process definition name not exists, otherwise false\n+     */\n+    @ApiOperation(value = \"verify-name\", notes = \"VERIFY_PROCCESS_DEFINITION_NAME_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"PROCESS_DEFINITION_NAME\", required = true, type = \"String\")\n+    })\n+    @GetMapping(value = \"/verify-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyProccessDefinitionName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                               @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                                             @RequestParam(value = \"name\", required = true) String name){\n+        try {\n+            logger.info(\"verify process definition name unique, user:{}, project name:{}, process definition name:{}\",\n+                    loginUser.getUserName(), projectName, name);\n+            Map<String, Object> result = processDefinitionService.verifyProccessDefinitionName(loginUser, projectName, name);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR.getMsg(),e);\n+            return error(Status.VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR.getCode(), Status.VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * update process definition\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param name process definition name\n+     * @param id process definition id\n+     * @param processDefinitionJson process definition json\n+     * @param description description\n+     * @param locations locations for nodes\n+     * @param connects connects for nodes\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateProccessDefinition\", notes= \"UPDATE_PROCCESS_DEFINITION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"PROCESS_DEFINITION_NAME\", required = true, type = \"String\"),\n+            @ApiImplicitParam(name = \"id\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"processDefinitionJson\", value = \"PROCESS_DEFINITION_JSON\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"locations\", value = \"PROCESS_DEFINITION_LOCATIONS\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"connects\", value = \"PROCESS_DEFINITION_CONNECTS\", required = true, type =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"PROCESS_DEFINITION_DESC\", required = false, type =\"String\"),\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateProccessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                           @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                                         @RequestParam(value = \"name\", required = true) String name,\n+                                                         @RequestParam(value = \"id\", required = true) int id,\n+                                                         @RequestParam(value = \"processDefinitionJson\", required = true) String processDefinitionJson,\n+                                                         @RequestParam(value = \"locations\", required = false) String locations,\n+                                                         @RequestParam(value = \"connects\", required = false) String connects,\n+                                                         @RequestParam(value = \"description\", required = false) String description) {\n+\n+        try {\n+            logger.info(\"login user {}, update process define, project name: {}, process define name: {}, \" +\n+                            \"process_definition_json: {}, desc: {}, locations:{}, connects:{}\",\n+                    loginUser.getUserName(), projectName, name, processDefinitionJson,description, locations, connects);\n+            Map<String, Object> result = processDefinitionService.updateProcessDefinition(loginUser, projectName, id, name,\n+                    processDefinitionJson, description, locations, connects);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.UPDATE_PROCESS_DEFINITION_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_PROCESS_DEFINITION_ERROR.getCode(), Status.UPDATE_PROCESS_DEFINITION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * release process definition\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processId process definition id\n+     * @param releaseState release state\n+     * @return release result code\n+     */\n+    @ApiOperation(value = \"releaseProccessDefinition\", notes= \"RELEASE_PROCCESS_DEFINITION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"PROCESS_DEFINITION_NAME\", required = true, type = \"String\"),\n+            @ApiImplicitParam(name = \"processId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"releaseState\", value = \"PROCESS_DEFINITION_CONNECTS\", required = true, dataType = \"Int\", example = \"100\"),\n+    })\n+    @PostMapping(value = \"/release\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result releaseProccessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                                          @RequestParam(value = \"processId\", required = true) int processId,\n+                                                          @RequestParam(value = \"releaseState\", required = true) int releaseState) {\n+\n+        try {\n+            logger.info(\"login user {}, release process definition, project name: {}, release state: {}\",\n+                    loginUser.getUserName(), projectName, releaseState);\n+            Map<String, Object> result = processDefinitionService.releaseProcessDefinition(loginUser, projectName, processId, releaseState);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.RELEASE_PROCESS_DEFINITION_ERROR.getMsg(),e);\n+            return error(Status.RELEASE_PROCESS_DEFINITION_ERROR.getCode(), Status.RELEASE_PROCESS_DEFINITION_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * query datail of process definition\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processId process definition id\n+     * @return process definition detail\n+     */\n+    @ApiOperation(value = \"queryProccessDefinitionById\", notes= \"QUERY_PROCCESS_DEFINITION_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/select-by-id\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProccessDefinitionById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                              @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                              @RequestParam(\"processId\") Integer processId\n+    ){\n+        try{\n+            logger.info(\"query datail of process definition, login user:{}, project name:{}, process definition id:{}\",\n+                    loginUser.getUserName(), projectName, processId);\n+            Map<String, Object> result = processDefinitionService.queryProccessDefinitionById(loginUser, projectName, processId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR.getMsg(),e);\n+            return error(Status.QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR.getCode(), Status.QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * query proccess definition list\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @return process definition list\n+     */\n+    @ApiOperation(value = \"queryProccessDefinitionList\", notes= \"QUERY_PROCCESS_DEFINITION_LIST_NOTES\")\n+    @GetMapping(value=\"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProccessDefinitionList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                              @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName\n+    ){\n+        try{\n+            logger.info(\"query proccess definition list, login user:{}, project name:{}\",\n+                    loginUser.getUserName(), projectName);\n+            Map<String, Object> result = processDefinitionService.queryProccessDefinitionList(loginUser, projectName);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_PROCCESS_DEFINITION_LIST.getMsg(),e);\n+            return error(Status.QUERY_PROCCESS_DEFINITION_LIST.getCode(), Status.QUERY_PROCCESS_DEFINITION_LIST.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query proccess definition list paging\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param searchVal search value\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @param userId user id\n+     * @return process definition page\n+     */\n+    @ApiOperation(value = \"queryProcessDefinitionListPaging\", notes= \"QUERY_PROCCESS_DEFINITION_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", required = false, type = \"String\"),\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = false, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProcessDefinitionListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                   @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                                   @RequestParam(\"pageNo\") Integer pageNo,\n+                                                   @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                                   @RequestParam(value = \"userId\", required = false, defaultValue = \"0\") Integer userId,\n+                                                   @RequestParam(\"pageSize\") Integer pageSize){\n+        try{\n+            logger.info(\"query proccess definition list paging, login user:{}, project name:{}\", loginUser.getUserName(), projectName);\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = processDefinitionService.queryProcessDefinitionListPaging(loginUser, projectName, searchVal, pageNo, pageSize, userId);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR.getCode(), Status.QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * encapsulation treeview structure\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param id process definition id\n+     * @param limit limit\n+     * @return tree view json data\n+     */\n+    @ApiOperation(value = \"viewTree\", notes= \"VIEW_TREE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"limit\", value = \"LIMIT\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/view-tree\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result viewTree(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                           @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+                                                   @RequestParam(\"processId\") Integer id,\n+                                                   @RequestParam(\"limit\") Integer limit){\n+        try{\n+            Map<String, Object> result = processDefinitionService.viewTree(id, limit);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR.getMsg(),e);\n+            return error(Status.ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR.getCode(), Status.ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * \n+     * get tasks list by process definition id\n+     *  \n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @return task list\n+     */\n+    @ApiOperation(value = \"getNodeListByDefinitionId\", notes= \"GET_NODE_LIST_BY_DEFINITION_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"gen-task-list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result getNodeListByDefinitionId(\n+            @ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+            @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+            @RequestParam(\"processDefinitionId\") Integer processDefinitionId){\n+        try {\n+            logger.info(\"query task node name list by definitionId, login user:{}, project name:{}, id : {}\",\n+                    loginUser.getUserName(), projectName, processDefinitionId);\n+            Map<String, Object> result = processDefinitionService.getTaskNodeListByDefinitionId(processDefinitionId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getMsg(), e);\n+            return error(Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getCode(), Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     *\n+     * get tasks list by process definition id\n+     *\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionIdList process definition id list\n+     * @return node list data\n+     */\n+    @ApiOperation(value = \"getNodeListByDefinitionIdList\", notes= \"GET_NODE_LIST_BY_DEFINITION_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionIdList\", value = \"PROCESS_DEFINITION_ID_LIST\", required = true, type = \"String\")\n+    })\n+    @GetMapping(value=\"get-task-list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result getNodeListByDefinitionIdList(\n+            @ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+            @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\",required = true) @PathVariable String projectName,\n+            @RequestParam(\"processDefinitionIdList\") String processDefinitionIdList){\n+\n+        try {\n+            logger.info(\"query task node name list by definitionId list, login user:{}, project name:{}, id list: {}\",\n+                    loginUser.getUserName(), projectName, processDefinitionIdList);\n+            Map<String, Object> result = processDefinitionService.getTaskNodeListByDefinitionIdList(processDefinitionIdList);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getMsg(), e);\n+            return error(Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getCode(), Status.GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete process definition by id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteProcessDefinitionById\", notes= \"DELETE_PROCESS_DEFINITION_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteProcessDefinitionById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                              @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                            @RequestParam(\"processDefinitionId\") Integer processDefinitionId\n+    ){\n+        try{\n+            logger.info(\"delete process definition by id, login user:{}, project name:{}, process definition id:{}\",\n+                    loginUser.getUserName(), projectName, processDefinitionId);\n+            Map<String, Object> result = processDefinitionService.deleteProcessDefinitionById(loginUser, projectName, processDefinitionId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.DELETE_PROCESS_DEFINE_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.DELETE_PROCESS_DEFINE_BY_ID_ERROR.getCode(), Status.DELETE_PROCESS_DEFINE_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * batch delete process definition by ids\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionIds process definition id list\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"batchDeleteProcessDefinitionByIds\", notes= \"BATCH_DELETE_PROCESS_DEFINITION_BY_IDS_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionIds\", value = \"PROCESS_DEFINITION_IDS\", type = \"String\")\n+    })\n+    @GetMapping(value=\"/batch-delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result batchDeleteProcessDefinitionByIds(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                    @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                              @RequestParam(\"processDefinitionIds\") String processDefinitionIds\n+    ){\n+        try{\n+            logger.info(\"delete process definition by ids, login user:{}, project name:{}, process definition ids:{}\",\n+                    loginUser.getUserName(), projectName, processDefinitionIds);\n+\n+            Map<String, Object> result = new HashMap<>(5);\n+            List<Integer> deleteFailedIdList = new ArrayList<Integer>();\n+            if(StringUtils.isNotEmpty(processDefinitionIds)){\n+                String[] processDefinitionIdArray = processDefinitionIds.split(\",\");\n+\n+                for (String strProcessDefinitionId:processDefinitionIdArray) {\n+                    int processDefinitionId = Integer.parseInt(strProcessDefinitionId);\n+                    try {\n+                        Map<String, Object> deleteResult = processDefinitionService.deleteProcessDefinitionById(loginUser, projectName, processDefinitionId);\n+                        if(!Status.SUCCESS.equals(deleteResult.get(Constants.STATUS))){\n+                            deleteFailedIdList.add(processDefinitionId);\n+                            logger.error((String)deleteResult.get(Constants.MSG));\n+                        }\n+                    } catch (Exception e) {\n+                        deleteFailedIdList.add(processDefinitionId);\n+                    }\n+                }\n+            }\n+\n+            if(deleteFailedIdList.size() > 0){\n+                putMsg(result, Status.BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR,StringUtils.join(deleteFailedIdList.toArray(),\",\"));\n+            }else{\n+                putMsg(result, Status.SUCCESS);\n+            }\n+\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR.getMsg(),e);\n+            return error(Status.BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR.getCode(), Status.BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * export process definition by id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @param response response\n+     */\n+    @ApiOperation(value = \"exportProcessDefinitionById\", notes= \"EXPORT_PROCCESS_DEFINITION_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/export\")\n+    @ResponseBody\n+    public void exportProcessDefinitionById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @PathVariable String projectName,\n+                                            @RequestParam(\"processDefinitionId\") Integer processDefinitionId,\n+                                            HttpServletResponse response){\n+        try{\n+            logger.info(\"export process definition by id, login user:{}, project name:{}, process definition id:{}\",\n+                    loginUser.getUserName(), projectName, processDefinitionId);\n+            processDefinitionService.exportProcessDefinitionById(loginUser, projectName, processDefinitionId,response);\n+        }catch (Exception e){\n+            logger.error(Status.EXPORT_PROCESS_DEFINE_BY_ID_ERROR.getMsg(),e);\n+        }\n+    }\n+\n+\n+\n+    /**\n+     * query proccess definition all by project id\n+     *\n+     * @param loginUser login user\n+     * @param projectId  project id\n+     * @return process definition list\n+     */\n+    @ApiOperation(value = \"queryProccessDefinitionAllByProjectId\", notes= \"QUERY_PROCCESS_DEFINITION_All_BY_PROJECT_ID_NOTES\")\n+    @GetMapping(value=\"/queryProccessDefinitionAllByProjectId\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProccessDefinitionAllByProjectId(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                        @RequestParam(\"projectId\") Integer projectId){\n+        try{\n+            logger.info(\"query proccess definition list, login user:{}, project id:{}\",\n+                    loginUser.getUserName(),projectId);\n+            Map<String, Object> result = processDefinitionService.queryProccessDefinitionAllByProjectId(projectId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_PROCCESS_DEFINITION_LIST.getMsg(),e);\n+            return error(Status.QUERY_PROCCESS_DEFINITION_LIST.getCode(), Status.QUERY_PROCCESS_DEFINITION_LIST.getMsg());\n+        }\n+    }\n+\n+}",
                "changes": 528
            },
            {
                "status": "added",
                "additions": 404,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java",
                "deletions": 0,
                "sha": "743be7bd04ba6899728f287b559f7f9f5ec4ab31",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java",
                "patch": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.ProcessInstanceService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;\n+import org.apache.dolphinscheduler.common.enums.Flag;\n+import org.apache.dolphinscheduler.common.queue.ITaskQueue;\n+import org.apache.dolphinscheduler.common.queue.TaskQueueFactory;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+\n+/**\n+ * process instance controller\n+ */\n+@Api(tags = \"PROCESS_INSTANCE_TAG\", position = 10)\n+@RestController\n+@RequestMapping(\"projects/{projectName}/instance\")\n+public class ProcessInstanceController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ProcessInstanceController.class);\n+\n+\n+    @Autowired\n+    ProcessInstanceService processInstanceService;\n+\n+    /**\n+     * query process instance list paging\n+     * \n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @param processDefinitionId process definition id\n+     * @param searchVal search value\n+     * @param stateType state type\n+     * @param host host\n+     * @param startTime start time\n+     * @param endTime end time\n+     * @return process instance list\n+     */\n+    @ApiOperation(value = \"queryProcessInstanceList\", notes= \"QUERY_PROCESS_INSTANCE_LIST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", type =\"String\"),\n+            @ApiImplicitParam(name = \"stateType\", value = \"EXECUTION_STATUS\", type =\"ExecutionStatus\"),\n+            @ApiImplicitParam(name = \"host\", value = \"HOST\", type =\"String\"),\n+            @ApiImplicitParam(name = \"startDate\", value = \"START_DATE\", type =\"String\"),\n+            @ApiImplicitParam(name = \"endDate\", value = \"END_DATE\", type =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProcessInstanceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                           @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                                                   @RequestParam(value = \"processDefinitionId\", required = false, defaultValue = \"0\") Integer processDefinitionId,\n+                                                                   @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                                                   @RequestParam(value = \"stateType\", required = false) ExecutionStatus stateType,\n+                                                                   @RequestParam(value = \"host\", required = false) String host,\n+                                                                   @RequestParam(value = \"startDate\", required = false) String startTime,\n+                                                                   @RequestParam(value = \"endDate\", required = false) String endTime,\n+                                                                   @RequestParam(\"pageNo\") Integer pageNo,\n+                                                                   @RequestParam(\"pageSize\") Integer pageSize){\n+        try{\n+            logger.info(\"query all process instance list, login user:{},project name:{}, define id:{},\" +\n+                    \"search value:{},state type:{},host:{},start time:{}, end time:{},page number:{}, page size:{}\",\n+                    loginUser.getUserName(), projectName, processDefinitionId, searchVal, stateType,host,\n+                    startTime, endTime, pageNo, pageSize);\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            Map<String, Object> result = processInstanceService.queryProcessInstanceList(\n+                    loginUser, projectName, processDefinitionId, startTime, endTime, searchVal, stateType, host, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR.getCode(), Status.QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query task list by process instance id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @return task list for the process instance\n+     */\n+    @ApiOperation(value = \"queryTaskListByProcessId\", notes= \"QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/task-list-by-process-id\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryTaskListByProcessId(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                           @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                           @RequestParam(\"processInstanceId\") Integer processInstanceId\n+    ) {\n+        try{\n+            logger.info(\"query task instance list by process instance id, login user:{}, project name:{}, process instance id:{}\",\n+                    loginUser.getUserName(), projectName, processInstanceId);\n+            Map<String, Object> result = processInstanceService.queryTaskListByProcessId(loginUser, projectName, processInstanceId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR.getMsg(),e);\n+            return error(QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR.getCode(), QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * update process instance\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceJson process instance json\n+     * @param processInstanceId process instance id\n+     * @param scheduleTime schedule time\n+     * @param syncDefine sync define\n+     * @param flag flag\n+     * @param locations locations\n+     * @param connects connects\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateProcessInstance\", notes= \"UPDATE_PROCESS_INSTANCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceJson\", value = \"PROCESS_INSTANCE_JSON\", type = \"String\"),\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"scheduleTime\", value = \"SCHEDULE_TIME\", type = \"String\"),\n+            @ApiImplicitParam(name = \"syncDefine\", value = \"SYNC_DEFINE\", type = \"Boolean\"),\n+            @ApiImplicitParam(name = \"locations\", value = \"PROCESS_INSTANCE_LOCATIONS\", type = \"String\"),\n+            @ApiImplicitParam(name = \"connects\", value = \"PROCESS_INSTANCE_CONNECTS\", type = \"String\"),\n+            @ApiImplicitParam(name = \"flag\", value = \"RECOVERY_PROCESS_INSTANCE_FLAG\", type = \"Flag\"),\n+    })\n+    @PostMapping(value=\"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                        @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                        @RequestParam( value = \"processInstanceJson\", required = false) String processInstanceJson,\n+                                        @RequestParam( value = \"processInstanceId\") Integer processInstanceId,\n+                                        @RequestParam( value = \"scheduleTime\", required = false) String scheduleTime,\n+                                        @RequestParam( value = \"syncDefine\", required = true) Boolean syncDefine,\n+                                        @RequestParam(value = \"locations\", required = false) String locations,\n+                                        @RequestParam(value = \"connects\", required = false) String connects,\n+                                        @RequestParam( value = \"flag\", required = false) Flag flag\n+    ){\n+        try{\n+            logger.info(\"updateProcessInstance process instance, login user:{}, project name:{}, process instance json:{},\" +\n+                    \"process instance id:{}, schedule time:{}, sync define:{}, flag:{}, locations:{}, connects:{}\",\n+                    loginUser.getUserName(), projectName, processInstanceJson, processInstanceId, scheduleTime,\n+                    syncDefine, flag, locations, connects);\n+            Map<String, Object> result = processInstanceService.updateProcessInstance(loginUser, projectName,\n+                    processInstanceId, processInstanceJson, scheduleTime, syncDefine, flag, locations, connects);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(UPDATE_PROCESS_INSTANCE_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_PROCESS_INSTANCE_ERROR.getCode(), Status.UPDATE_PROCESS_INSTANCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query process instance by id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @return process instance detail\n+     */\n+    @ApiOperation(value = \"queryProcessInstanceById\", notes= \"QUERY_PROCESS_INSTANCE_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/select-by-id\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                                     @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                                                     @RequestParam(\"processInstanceId\") Integer processInstanceId\n+    ){\n+        try{\n+            logger.info(\"query process instance detail by id, login user:{},project name:{}, process instance id:{}\",\n+                    loginUser.getUserName(), projectName, processInstanceId);\n+            Map<String, Object> result = processInstanceService.queryProcessInstanceById(loginUser, projectName, processInstanceId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_PROCESS_INSTANCE_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.QUERY_PROCESS_INSTANCE_BY_ID_ERROR.getCode(), Status.QUERY_PROCESS_INSTANCE_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete process instance by id, at the same time,\n+     * delete task instance and their mapping relation data\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteProcessInstanceById\", notes= \"DELETE_PROCESS_INSTANCE_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteProcessInstanceById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                                     @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                                                     @RequestParam(\"processInstanceId\") Integer processInstanceId\n+    ){\n+        try{\n+            logger.info(\"delete process instance by id, login user:{}, project name:{}, process instance id:{}\",\n+                    loginUser.getUserName(), projectName, processInstanceId);\n+            // task queue\n+            ITaskQueue tasksQueue = TaskQueueFactory.getTaskQueueInstance();\n+            Map<String, Object> result = processInstanceService.deleteProcessInstanceById(loginUser, projectName, processInstanceId,tasksQueue);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(DELETE_PROCESS_INSTANCE_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.DELETE_PROCESS_INSTANCE_BY_ID_ERROR.getCode(), Status.DELETE_PROCESS_INSTANCE_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query sub process instance detail info by task id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param taskId task id\n+     * @return sub process instance detail\n+     */\n+    @ApiOperation(value = \"querySubProcessInstanceByTaskId\", notes= \"QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"taskId\", value = \"TASK_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/select-sub-process\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result querySubProcessInstanceByTaskId(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                  @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                                  @RequestParam(\"taskId\") Integer taskId){\n+        try{\n+            Map<String, Object> result = processInstanceService.querySubProcessInstanceByTaskId(loginUser, projectName, taskId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR.getMsg(),e);\n+            return error(Status.QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR.getCode(), Status.QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query parent process instance detail info by sub process instance id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param subId sub process id\n+     * @return parent instance detail\n+     */\n+    @ApiOperation(value = \"queryParentInstanceBySubId\", notes= \"QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"subId\", value = \"SUB_PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/select-parent-process\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryParentInstanceBySubId(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                             @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                             @RequestParam(\"subId\") Integer subId){\n+        try{\n+            Map<String, Object> result = processInstanceService.queryParentInstanceBySubId(loginUser, projectName, subId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR.getMsg(),e);\n+            return error(Status.QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR.getCode(), Status.QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query process instance global variables and local variables\n+     *\n+     * @param loginUser login user\n+     * @param processInstanceId process instance id\n+     * @return variables data\n+     */\n+    @ApiOperation(value = \"viewVariables\", notes= \"QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/view-variables\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result viewVariables(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser\n+            , @RequestParam(\"processInstanceId\") Integer processInstanceId){\n+        try{\n+            Map<String, Object> result = processInstanceService.viewVariables(processInstanceId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR.getMsg(),e);\n+            return error(Status.QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR.getCode(), Status.QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * encapsulation gantt structure\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @return gantt tree data\n+     */\n+    @ApiOperation(value = \"vieGanttTree\", notes= \"VIEW_GANTT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\", dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/view-gantt\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result viewTree(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                   @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                                   @RequestParam(\"processInstanceId\") Integer processInstanceId){\n+        try{\n+            Map<String, Object> result = processInstanceService.viewGantt(processInstanceId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR.getMsg(),e);\n+            return error(Status.ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR.getCode(),ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * batch delete process instance by ids, at the same time,\n+     * delete task instance and their mapping relation data\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceIds process instance id\n+     * @return delete result code\n+     */\n+    @GetMapping(value=\"/batch-delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result batchDeleteProcessInstanceByIds(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @PathVariable String projectName,\n+                                            @RequestParam(\"processInstanceIds\") String processInstanceIds\n+    ){\n+        try{\n+            logger.info(\"delete process instance by ids, login user:{}, project name:{}, process instance ids :{}\",\n+                    loginUser.getUserName(), projectName, processInstanceIds);\n+            // task queue\n+            ITaskQueue tasksQueue = TaskQueueFactory.getTaskQueueInstance();\n+            Map<String, Object> result = new HashMap<>(5);\n+            List<Integer> deleteFailedIdList = new ArrayList<Integer>();\n+            if(StringUtils.isNotEmpty(processInstanceIds)){\n+                String[] processInstanceIdArray = processInstanceIds.split(\",\");\n+\n+                for (String strProcessInstanceId:processInstanceIdArray) {\n+                    int processInstanceId = Integer.parseInt(strProcessInstanceId);\n+                    try {\n+                        Map<String, Object> deleteResult = processInstanceService.deleteProcessInstanceById(loginUser, projectName, processInstanceId,tasksQueue);\n+                        if(!Status.SUCCESS.equals(deleteResult.get(Constants.STATUS))){\n+                            deleteFailedIdList.add(processInstanceId);\n+                            logger.error((String)deleteResult.get(Constants.MSG));\n+                        }\n+                    } catch (Exception e) {\n+                        deleteFailedIdList.add(processInstanceId);\n+                    }\n+                }\n+            }\n+            if(deleteFailedIdList.size() > 0){\n+                putMsg(result, Status.BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR,StringUtils.join(deleteFailedIdList.toArray(),\",\"));\n+            }else{\n+                putMsg(result, Status.SUCCESS);\n+            }\n+\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR.getMsg(),e);\n+            return error(Status.BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR.getCode(), Status.BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR.getMsg());\n+        }\n+    }\n+}",
                "changes": 404
            },
            {
                "status": "added",
                "additions": 304,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java",
                "deletions": 0,
                "sha": "484d00bf2caad2e51c722fe332f44e5b796dad4b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java",
                "patch": "@@ -0,0 +1,304 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;\n+import org.apache.dolphinscheduler.api.service.ProjectService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.multipart.MultipartFile;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+\n+/**\n+ * project controller\n+ */\n+@Api(tags = \"PROJECT_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"projects\")\n+public class ProjectController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ProjectController.class);\n+\n+    @Autowired\n+    private ProjectService projectService;\n+\n+    @Autowired\n+    private ProcessDefinitionService processDefinitionService;\n+\n+    /**\n+     * create project\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param description description\n+     * @return returns an error if it exists\n+     */\n+    @ApiOperation(value = \"createProject\", notes= \"CREATE_PROJECT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectName\", value = \"PROJECT_NAME\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"PROJECT_DESC\", dataType = \"String\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"projectName\") String projectName,\n+                                @RequestParam(value = \"description\", required = false) String description) {\n+\n+        try {\n+            logger.info(\"login user {}, create project name: {}, desc: {}\", loginUser.getUserName(), projectName, description);\n+            Map<String, Object> result = projectService.createProject(loginUser, projectName, description);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(CREATE_PROJECT_ERROR.getMsg(), e);\n+            return error(CREATE_PROJECT_ERROR.getCode(), CREATE_PROJECT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * updateProcessInstance project\n+     *\n+     * @param loginUser login user\n+     * @param projectId project id\n+     * @param projectName project name\n+     * @param description description\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateProject\", notes= \"UPDATE_PROJECT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\", dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"projectName\",value = \"PROJECT_NAME\",dataType = \"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"PROJECT_DESC\", dataType = \"String\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"projectId\") Integer projectId,\n+                                @RequestParam(\"projectName\") String projectName,\n+                                @RequestParam(value = \"description\", required = false) String description) {\n+        try {\n+            logger.info(\"login user {} , updateProcessInstance project name: {}, desc: {}\", loginUser.getUserName(), projectName, description);\n+            Map<String, Object> result = projectService.update(loginUser, projectId, projectName, description);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(UPDATE_PROJECT_ERROR.getMsg(), e);\n+            return error(UPDATE_PROJECT_ERROR.getCode(), UPDATE_PROJECT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query project details by id\n+     *\n+     * @param loginUser login user\n+     * @param projectId project id\n+     * @return project detail information\n+     */\n+    @ApiOperation(value = \"queryProjectById\", notes= \"QUERY_PROJECT_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/query-by-id\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProjectById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"projectId\") Integer projectId) {\n+        logger.info(\"login user {}, query project by id: {}\", loginUser.getUserName(), projectId);\n+\n+        try {\n+            Map<String, Object> result = projectService.queryById(projectId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_PROJECT_DETAILS_BY_ID_ERROR.getMsg(), e);\n+            return error(QUERY_PROJECT_DETAILS_BY_ID_ERROR.getCode(), QUERY_PROJECT_DETAILS_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query project list paging\n+     *\n+     * @param loginUser login user\n+     * @param searchVal search value\n+     * @param pageSize page size\n+     * @param pageNo page number\n+     * @return project list which the login user have permission to see\n+     */\n+    @ApiOperation(value = \"queryProjectListPaging\", notes= \"QUERY_PROJECT_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"projectId\", value = \"PAGE_SIZE\", dataType =\"Int\", example = \"20\"),\n+            @ApiImplicitParam(name = \"projectId\", value = \"PAGE_NO\", dataType =\"Int\", example = \"1\")\n+    })\n+    @GetMapping(value = \"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryProjectListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                         @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                         @RequestParam(\"pageSize\") Integer pageSize,\n+                                         @RequestParam(\"pageNo\") Integer pageNo\n+    ) {\n+\n+        try {\n+            logger.info(\"login user {}, query project list paging\", loginUser.getUserName());\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            Map<String, Object> result = projectService.queryProjectListPaging(loginUser, pageSize, pageNo, searchVal);\n+            return returnDataListPaging(result);\n+        } catch (Exception e) {\n+            logger.error(LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getMsg(), e);\n+            return error(Status.LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getCode(), Status.LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete project by id\n+     *\n+     * @param loginUser login user\n+     * @param projectId project id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteProjectById\", notes= \"DELETE_PROJECT_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"projectId\", value = \"PROJECT_ID\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"projectId\") Integer projectId\n+    ) {\n+\n+        try {\n+            logger.info(\"login user {}, delete project: {}.\", loginUser.getUserName(), projectId);\n+            Map<String, Object> result = projectService.deleteProject(loginUser, projectId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(DELETE_PROJECT_ERROR.getMsg(), e);\n+            return error(DELETE_PROJECT_ERROR.getCode(), DELETE_PROJECT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query unauthorized project\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return the projects which user have not permission to see\n+     */\n+    @ApiOperation(value = \"queryUnauthorizedProject\", notes= \"QUERY_UNAUTHORIZED_PROJECT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/unauth-project\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryUnauthorizedProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                           @RequestParam(\"userId\") Integer userId) {\n+        try {\n+            logger.info(\"login user {}, query unauthorized project by user id: {}.\", loginUser.getUserName(), userId);\n+            Map<String, Object> result = projectService.queryUnauthorizedProject(loginUser, userId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_UNAUTHORIZED_PROJECT_ERROR.getMsg(), e);\n+            return error(QUERY_UNAUTHORIZED_PROJECT_ERROR.getCode(), QUERY_UNAUTHORIZED_PROJECT_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * query authorized project\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return projects which the user have permission to see, Except for items created by this user\n+     */\n+    @ApiOperation(value = \"queryAuthorizedProject\", notes= \"QUERY_AUTHORIZED_PROJECT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/authed-project\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryAuthorizedProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                         @RequestParam(\"userId\") Integer userId) {\n+        try {\n+            logger.info(\"login user {}, query authorized project by user id: {}.\", loginUser.getUserName(), userId);\n+            Map<String, Object> result = projectService.queryAuthorizedProject(loginUser, userId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_AUTHORIZED_PROJECT.getMsg(), e);\n+            return error(QUERY_AUTHORIZED_PROJECT.getCode(), QUERY_AUTHORIZED_PROJECT.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * import process definition\n+     *\n+     * @param loginUser login user\n+     * @param file resource file\n+     * @return import result code\n+     */\n+    @ApiOperation(value = \"importProcessDefinition\", notes= \"EXPORT_PROCCESS_DEFINITION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"file\", value = \"RESOURCE_FILE\", required = true, dataType = \"MultipartFile\")\n+    })\n+    @PostMapping(value=\"/importProcessDefinition\")\n+    public Result importProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                          @RequestParam(\"file\") MultipartFile file){\n+        try{\n+            logger.info(\"import process definition by id, login user:{}\",\n+                    loginUser.getUserName());\n+            Map<String, Object> result = processDefinitionService.importProcessDefinition(loginUser,file);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(IMPORT_PROCESS_DEFINE_ERROR.getMsg(),e);\n+            return error(IMPORT_PROCESS_DEFINE_ERROR.getCode(), IMPORT_PROCESS_DEFINE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query all project list\n+     * @param loginUser login user\n+     * @return all project list\n+     */\n+    @ApiOperation(value = \"queryAllProjectList\", notes= \"QUERY_ALL_PROJECT_LIST_NOTES\")\n+    @GetMapping(value = \"/queryAllProjectList\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryAllProjectList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {\n+\n+        try {\n+            logger.info(\"login user {}, query all project list\", loginUser.getUserName());\n+            Map<String, Object> result = projectService.queryAllProjectList();\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getMsg(), e);\n+            return error(Status.LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getCode(), Status.LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+\n+}",
                "changes": 304
            },
            {
                "status": "added",
                "additions": 204,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/QueueController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/QueueController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/QueueController.java",
                "deletions": 0,
                "sha": "056ca618f55ef7f2250bcab0be5812e0dc8aea30",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/QueueController.java",
                "patch": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.QueueService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * queue controller\n+ */\n+@Api(tags = \"QUEUE_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"/queue\")\n+public class QueueController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(QueueController.class);\n+\n+    @Autowired\n+    private QueueService queueService;\n+\n+\n+    /**\n+     * query queue list\n+     * @param loginUser login user\n+     * @return queue list\n+     */\n+    @ApiOperation(value = \"queryList\", notes= \"QUERY_QUEUE_LIST_NOTES\")\n+    @GetMapping(value=\"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        try{\n+            logger.info(\"login user {}, query queue list\", loginUser.getUserName());\n+            Map<String, Object> result = queueService.queryList(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_QUEUE_LIST_ERROR.getMsg(),e);\n+            return error(Status.QUERY_QUEUE_LIST_ERROR.getCode(), Status.QUERY_QUEUE_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query queue list paging\n+     * @param loginUser login user\n+     * @param pageNo page number\n+     * @param searchVal search value\n+     * @param pageSize page size\n+     * @return queue list\n+     */\n+    @ApiOperation(value = \"queryQueueListPaging\", notes= \"QUERY_QUEUE_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryQueueListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                  @RequestParam(\"pageNo\") Integer pageNo,\n+                                  @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                  @RequestParam(\"pageSize\") Integer pageSize){\n+        try{\n+            logger.info(\"login user {}, query queue list,search value:{}\", loginUser.getUserName(),searchVal);\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = queueService.queryList(loginUser,searchVal,pageNo,pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_QUEUE_LIST_ERROR.getMsg(),e);\n+            return error(Status.QUERY_QUEUE_LIST_ERROR.getCode(), Status.QUERY_QUEUE_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * create queue\n+     *\n+     * @param loginUser login user\n+     * @param queue queue\n+     * @param queueName queue name\n+     * @return create result\n+     */\n+    @ApiOperation(value = \"createQueue\", notes= \"CREATE_QUEUE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"queue\", value = \"YARN_QUEUE_NAME\", required = true,dataType =\"String\"),\n+            @ApiImplicitParam(name = \"queueName\", value = \"QUEUE_NAME\",required = true, dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createQueue(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                               @RequestParam(value = \"queue\") String queue,\n+                               @RequestParam(value = \"queueName\") String queueName) {\n+        logger.info(\"login user {}, create queue, queue: {}, queueName: {}\",\n+                loginUser.getUserName(), queue, queueName);\n+        try {\n+            Map<String, Object> result = queueService.createQueue(loginUser,queue,queueName);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.CREATE_QUEUE_ERROR.getMsg(),e);\n+            return error(Status.CREATE_QUEUE_ERROR.getCode(), Status.CREATE_QUEUE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * update queue\n+     *\n+     * @param loginUser login user\n+     * @param queue queue\n+     * @param id queue id\n+     * @param queueName queue name\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateQueue\", notes= \"UPDATE_QUEUE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"QUEUE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"queue\", value = \"YARN_QUEUE_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"queueName\", value = \"QUEUE_NAME\",required = true, dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result updateQueue(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                              @RequestParam(value = \"id\") int id,\n+                              @RequestParam(value = \"queue\") String queue,\n+                              @RequestParam(value = \"queueName\") String queueName) {\n+        logger.info(\"login user {}, update queue, id: {}, queue: {}, queueName: {}\",\n+                loginUser.getUserName(), id,queue, queueName);\n+        try {\n+            Map<String, Object> result = queueService.updateQueue(loginUser,id,queue,queueName);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.UPDATE_QUEUE_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_QUEUE_ERROR.getCode(), Status.UPDATE_QUEUE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * verify queue and queue name\n+     *\n+     * @param loginUser login user\n+     * @param queue queue\n+     * @param queueName queue name\n+     * @return true if the queue name not exists, otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyQueue\", notes= \"VERIFY_QUEUE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"QUEUE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"queue\", value = \"YARN_QUEUE_NAME\",required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"queueName\", value = \"QUEUE_NAME\",required = true, dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/verify-queue\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyQueue(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(value =\"queue\") String queue,\n+                                   @RequestParam(value =\"queueName\") String queueName\n+    ) {\n+\n+        try{\n+            logger.info(\"login user {}, verfiy queue: {} queue name: {}\",\n+                    loginUser.getUserName(),queue,queueName);\n+            return queueService.verifyQueue(queue,queueName);\n+        }catch (Exception e){\n+            logger.error(Status.VERIFY_QUEUE_ERROR.getMsg(),e);\n+            return error(Status.VERIFY_QUEUE_ERROR.getCode(), Status.VERIFY_QUEUE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+}",
                "changes": 204
            },
            {
                "status": "added",
                "additions": 734,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ResourcesController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ResourcesController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ResourcesController.java",
                "deletions": 0,
                "sha": "07d235d802ef2341157c38f3da93d6b253365a5e",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ResourcesController.java",
                "patch": "@@ -0,0 +1,734 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.ResourcesService;\n+import org.apache.dolphinscheduler.api.service.UdfFuncService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.enums.ResourceType;\n+import org.apache.dolphinscheduler.common.enums.UdfType;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.apache.commons.lang.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.core.io.Resource;\n+import org.springframework.http.HttpHeaders;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.ResponseEntity;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.multipart.MultipartFile;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+/**\n+ * resources controller\n+ */\n+@Api(tags = \"RESOURCES_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"resources\")\n+public class ResourcesController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(ResourcesController.class);\n+\n+\n+    @Autowired\n+    private ResourcesService resourceService;\n+    @Autowired\n+    private UdfFuncService udfFuncService;\n+\n+    /**\n+     * create resource\n+     *\n+     * @param loginUser login user\n+     * @param alias alias\n+     * @param description description\n+     * @param type type\n+     * @param file file\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createResource\", notes= \"CREATE_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\"),\n+            @ApiImplicitParam(name = \"name\", value = \"RESOURCE_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"RESOURCE_DESC\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"file\", value = \"RESOURCE_FILE\", required = true, dataType = \"MultipartFile\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    public Result createResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(value = \"type\") ResourceType type,\n+                                 @RequestParam(value =\"name\")String alias,\n+                                 @RequestParam(value = \"description\", required = false) String description,\n+                                 @RequestParam(\"file\") MultipartFile file) {\n+        try {\n+            logger.info(\"login user {}, create resource, type: {}, resource alias: {}, desc: {}, file: {},{}\",\n+                    loginUser.getUserName(),type, alias, description, file.getName(), file.getOriginalFilename());\n+            return resourceService.createResource(loginUser,alias, description,type ,file);\n+        } catch (Exception e) {\n+            logger.error(CREATE_RESOURCE_ERROR.getMsg(),e);\n+            return error(CREATE_RESOURCE_ERROR.getCode(), CREATE_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * update resource\n+     *\n+     * @param loginUser login user\n+     * @param alias alias\n+     * @param resourceId resource id\n+     * @param type resource type\n+     * @param description description\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateResource\", notes= \"UPDATE_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\"),\n+            @ApiImplicitParam(name = \"name\", value = \"RESOURCE_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"RESOURCE_DESC\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"file\", value = \"RESOURCE_FILE\", required = true,dataType = \"MultipartFile\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    public Result updateResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(value =\"id\") int resourceId,\n+                                 @RequestParam(value = \"type\") ResourceType type,\n+                                 @RequestParam(value =\"name\")String alias,\n+                                 @RequestParam(value = \"description\", required = false) String description) {\n+        try {\n+            logger.info(\"login user {}, update resource, type: {}, resource alias: {}, desc: {}\",\n+                    loginUser.getUserName(),type, alias, description);\n+            return resourceService.updateResource(loginUser,resourceId,alias, description,type);\n+        } catch (Exception e) {\n+            logger.error(UPDATE_RESOURCE_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_RESOURCE_ERROR.getCode(), Status.UPDATE_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query resources list\n+     *\n+     * @param loginUser login user\n+     * @param type resource type\n+     * @return resource list\n+     */\n+    @ApiOperation(value = \"queryResourceList\", notes= \"QUERY_RESOURCE_LIST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\")\n+    })\n+    @GetMapping(value=\"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryResourceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                     @RequestParam(value =\"type\") ResourceType type\n+    ){\n+        try{\n+            logger.info(\"query resource list, login user:{}, resource type:{}\", loginUser.getUserName(), type.toString());\n+            Map<String, Object> result = resourceService.queryResourceList(loginUser, type);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_RESOURCES_LIST_ERROR.getMsg(),e);\n+            return error(Status.QUERY_RESOURCES_LIST_ERROR.getCode(), Status.QUERY_RESOURCES_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query resources list paging\n+     *\n+     * @param loginUser login user\n+     * @param type resource type\n+     * @param searchVal search value\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return resource list page\n+     */\n+    @ApiOperation(value = \"queryResourceListPaging\", notes= \"QUERY_RESOURCE_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryResourceListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                     @RequestParam(value =\"type\") ResourceType type,\n+                                     @RequestParam(\"pageNo\") Integer pageNo,\n+                                     @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                     @RequestParam(\"pageSize\") Integer pageSize\n+    ){\n+        try{\n+            logger.info(\"query resource list, login user:{}, resource type:{}, search value:{}\",\n+                    loginUser.getUserName(), type.toString(), searchVal);\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = resourceService.queryResourceListPaging(loginUser,type,searchVal,pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_RESOURCES_LIST_PAGING.getMsg(),e);\n+            return error(Status.QUERY_RESOURCES_LIST_PAGING.getCode(), Status.QUERY_RESOURCES_LIST_PAGING.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * delete resource\n+     *\n+     * @param loginUser login user\n+     * @param resourceId resource id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteResource\", notes= \"DELETE_RESOURCE_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(value =\"id\") int resourceId\n+    ) {\n+        try{\n+            logger.info(\"login user {}, delete resource id: {}\",\n+                    loginUser.getUserName(),resourceId);\n+            return resourceService.delete(loginUser,resourceId);\n+        }catch (Exception e){\n+            logger.error(DELETE_RESOURCE_ERROR.getMsg(),e);\n+            return error(Status.DELETE_RESOURCE_ERROR.getCode(), Status.DELETE_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * verify resource by alias and type\n+     *\n+     * @param loginUser login user\n+     * @param alias resource name\n+     * @param type resource type\n+     * @return true if the resource name not exists, otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyResourceName\", notes= \"VERIFY_RESOURCE_NAME_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\"),\n+            @ApiImplicitParam(name = \"name\", value = \"RESOURCE_NAME\", required = true, dataType =\"String\")\n+    })\n+    @GetMapping(value = \"/verify-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyResourceName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                     @RequestParam(value =\"name\") String alias,\n+                                     @RequestParam(value =\"type\") ResourceType type\n+    ) {\n+        try {\n+            logger.info(\"login user {}, verfiy resource alias: {},resource type: {}\",\n+                    loginUser.getUserName(), alias,type);\n+\n+            return resourceService.verifyResourceName(alias,type,loginUser);\n+        } catch (Exception e) {\n+            logger.error(VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR.getMsg(), e);\n+            return error(Status.VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR.getCode(), Status.VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * view resource file online\n+     *\n+     * @param loginUser login user\n+     * @param resourceId resource id\n+     * @param skipLineNum skip line number\n+     * @param limit limit\n+     * @return resource content\n+     */\n+    @ApiOperation(value = \"viewResource\", notes= \"VIEW_RESOURCE_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"skipLineNum\", value = \"SKIP_LINE_NUM\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"limit\", value = \"LIMIT\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/view\")\n+    public Result viewResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                               @RequestParam(value = \"id\") int resourceId,\n+                               @RequestParam(value = \"skipLineNum\") int skipLineNum,\n+                               @RequestParam(value = \"limit\") int limit\n+    ) {\n+        try{\n+            logger.info(\"login user {}, view resource : {}, skipLineNum {} , limit {}\",\n+                    loginUser.getUserName(),resourceId,skipLineNum,limit);\n+\n+            return resourceService.readResource(resourceId,skipLineNum,limit);\n+        }catch (Exception e){\n+            logger.error(VIEW_RESOURCE_FILE_ON_LINE_ERROR.getMsg(),e);\n+            return error(Status.VIEW_RESOURCE_FILE_ON_LINE_ERROR.getCode(), Status.VIEW_RESOURCE_FILE_ON_LINE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * create resource file online\n+     *\n+     * @param loginUser login user\n+     * @param type resource type\n+     * @param fileName file name\n+     * @param fileSuffix file suffix\n+     * @param description description\n+     * @param content content\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"onlineCreateResource\", notes= \"ONLINE_CREATE_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"RESOURCE_TYPE\", required = true, dataType =\"ResourceType\"),\n+            @ApiImplicitParam(name = \"fileName\", value = \"RESOURCE_NAME\",required = true,  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"suffix\", value = \"SUFFIX\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"RESOURCE_DESC\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"content\", value = \"CONTENT\",required = true,  dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/online-create\")\n+    public Result onlineCreateResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                       @RequestParam(value = \"type\") ResourceType type,\n+                                       @RequestParam(value =\"fileName\")String fileName,\n+                                       @RequestParam(value =\"suffix\")String fileSuffix,\n+                                       @RequestParam(value = \"description\", required = false) String description,\n+                                       @RequestParam(value = \"content\") String content\n+    ) {\n+        try{\n+            logger.info(\"login user {}, online create resource! fileName : {}, type : {}, suffix : {},desc : {},content : {}\",\n+                    loginUser.getUserName(),type,fileName,fileSuffix,description,content);\n+            if(StringUtils.isEmpty(content)){\n+                logger.error(\"resource file contents are not allowed to be empty\");\n+                return error(Status.RESOURCE_FILE_IS_EMPTY.getCode(), RESOURCE_FILE_IS_EMPTY.getMsg());\n+            }\n+            return resourceService.onlineCreateResource(loginUser,type,fileName,fileSuffix,description,content);\n+        }catch (Exception e){\n+            logger.error(CREATE_RESOURCE_FILE_ON_LINE_ERROR.getMsg(),e);\n+            return error(Status.CREATE_RESOURCE_FILE_ON_LINE_ERROR.getCode(), Status.CREATE_RESOURCE_FILE_ON_LINE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * edit resource file online\n+     *\n+     * @param loginUser login user\n+     * @param resourceId resource id\n+     * @param content content\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateResourceContent\", notes= \"UPDATE_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"content\", value = \"CONTENT\",required = true,  dataType =\"String\")\n+    })\n+    @PostMapping(value = \"/update-content\")\n+    public Result updateResourceContent(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                        @RequestParam(value = \"id\") int resourceId,\n+                                        @RequestParam(value = \"content\") String content\n+    ) {\n+        try{\n+            logger.info(\"login user {}, updateProcessInstance resource : {}\",\n+                    loginUser.getUserName(),resourceId);\n+            if(StringUtils.isEmpty(content)){\n+                logger.error(\"The resource file contents are not allowed to be empty\");\n+                return error(Status.RESOURCE_FILE_IS_EMPTY.getCode(), RESOURCE_FILE_IS_EMPTY.getMsg());\n+            }\n+            return resourceService.updateResourceContent(resourceId,content);\n+        }catch (Exception e){\n+            logger.error(EDIT_RESOURCE_FILE_ON_LINE_ERROR.getMsg(),e);\n+            return error(Status.EDIT_RESOURCE_FILE_ON_LINE_ERROR.getCode(), Status.EDIT_RESOURCE_FILE_ON_LINE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * download resource file\n+     *\n+     * @param loginUser login user\n+     * @param resourceId resource id\n+     * @return resource content\n+     */\n+    @ApiOperation(value = \"downloadResource\", notes= \"DOWNLOAD_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/download\")\n+    @ResponseBody\n+    public ResponseEntity downloadResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                           @RequestParam(value = \"id\") int resourceId) {\n+        try{\n+            logger.info(\"login user {}, download resource : {}\",\n+                    loginUser.getUserName(), resourceId);\n+            Resource file = resourceService.downloadResource(resourceId);\n+            if (file == null) {\n+                return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(Status.RESOURCE_NOT_EXIST.getMsg());\n+            }\n+            return ResponseEntity\n+                    .ok()\n+                    .header(HttpHeaders.CONTENT_DISPOSITION, \"attachment; filename=\\\"\" + file.getFilename() + \"\\\"\")\n+                    .body(file);\n+        }catch (Exception e){\n+            logger.error(DOWNLOAD_RESOURCE_FILE_ERROR.getMsg(),e);\n+            return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(Status.DOWNLOAD_RESOURCE_FILE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * create udf function\n+     * @param loginUser login user\n+     * @param type udf type\n+     * @param funcName function name\n+     * @param argTypes argument types\n+     * @param database database\n+     * @param description description\n+     * @param className  class name\n+     * @param resourceId resource id\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createUdfFunc\", notes= \"CREATE_UDF_FUNCTION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"UDF_TYPE\", required = true, dataType =\"UdfType\"),\n+            @ApiImplicitParam(name = \"funcName\", value = \"FUNC_NAME\",required = true,  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"suffix\", value = \"CLASS_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"argTypes\", value = \"ARG_TYPES\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"database\", value = \"DATABASE_NAME\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"UDF_DESC\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"resourceId\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+\n+    })\n+    @PostMapping(value = \"/udf-func/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createUdfFunc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(value = \"type\") UdfType type,\n+                                @RequestParam(value =\"funcName\")String funcName,\n+                                @RequestParam(value =\"className\")String className,\n+                                @RequestParam(value =\"argTypes\", required = false)String argTypes,\n+                                @RequestParam(value =\"database\", required = false)String database,\n+                                @RequestParam(value = \"description\", required = false) String description,\n+                                @RequestParam(value = \"resourceId\") int resourceId) {\n+        logger.info(\"login user {}, create udf function, type: {},  funcName: {},argTypes: {} ,database: {},desc: {},resourceId: {}\",\n+                loginUser.getUserName(),type, funcName, argTypes,database,description, resourceId);\n+        Result result = new Result();\n+\n+        try {\n+            return udfFuncService.createUdfFunction(loginUser,funcName,className,argTypes,database,description,type,resourceId);\n+        } catch (Exception e) {\n+            logger.error(CREATE_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.CREATE_UDF_FUNCTION_ERROR.getCode(), Status.CREATE_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * view udf function\n+     *\n+     * @param loginUser login user\n+     * @param id resource id\n+     * @return udf function detail\n+     */\n+    @ApiOperation(value = \"viewUIUdfFunction\", notes= \"VIEW_UDF_FUNCTION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"resourceId\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+\n+    })\n+    @GetMapping(value = \"/udf-func/update-ui\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result viewUIUdfFunction(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                      @RequestParam(\"id\") int id)\n+    {\n+        logger.info(\"login user {}, query udf{}\",\n+                loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> map = udfFuncService.queryUdfFuncDetail(id);\n+            return returnDataList(map);\n+        } catch (Exception e) {\n+            logger.error(VIEW_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.VIEW_UDF_FUNCTION_ERROR.getCode(), Status.VIEW_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * update udf function\n+     *\n+     * @param loginUser login user\n+     * @param type  resource type\n+     * @param funcName function name\n+     * @param argTypes argument types\n+     * @param database data base\n+     * @param description description\n+     * @param resourceId resource id\n+     * @param className class name\n+     * @param udfFuncId  udf function id\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateUdfFunc\", notes= \"UPDATE_UDF_FUNCTION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"UDF_TYPE\", required = true, dataType =\"UdfType\"),\n+            @ApiImplicitParam(name = \"funcName\", value = \"FUNC_NAME\",required = true,  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"suffix\", value = \"CLASS_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"argTypes\", value = \"ARG_TYPES\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"database\", value = \"DATABASE_NAME\",  dataType =\"String\"),\n+            @ApiImplicitParam(name = \"description\", value = \"UDF_DESC\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+\n+    })\n+    @PostMapping(value = \"/udf-func/update\")\n+    public Result updateUdfFunc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(value = \"id\") int udfFuncId,\n+                                @RequestParam(value = \"type\") UdfType type,\n+                                @RequestParam(value =\"funcName\")String funcName,\n+                                @RequestParam(value =\"className\")String className,\n+                                @RequestParam(value =\"argTypes\", required = false)String argTypes,\n+                                @RequestParam(value =\"database\", required = false)String database,\n+                                @RequestParam(value = \"description\", required = false) String description,\n+                                @RequestParam(value = \"resourceId\") int resourceId) {\n+        try {\n+            logger.info(\"login user {}, updateProcessInstance udf function id: {},type: {},  funcName: {},argTypes: {} ,database: {},desc: {},resourceId: {}\",\n+                    loginUser.getUserName(),udfFuncId,type, funcName, argTypes,database,description, resourceId);\n+            Map<String, Object> result = udfFuncService.updateUdfFunc(udfFuncId,funcName,className,argTypes,database,description,type,resourceId);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(UPDATE_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_UDF_FUNCTION_ERROR.getCode(), Status.UPDATE_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query udf function list paging\n+     *\n+     * @param loginUser login user\n+     * @param searchVal search value\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return udf function list page\n+     */\n+    @ApiOperation(value = \"queryUdfFuncListPaging\", notes= \"QUERY_UDF_FUNCTION_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value=\"/udf-func/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryUdfFuncList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"pageNo\") Integer pageNo,\n+                                   @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                   @RequestParam(\"pageSize\") Integer pageSize\n+    ){\n+        try{\n+            logger.info(\"query udf functions list, login user:{},search value:{}\",\n+                    loginUser.getUserName(), searchVal);\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+\n+            result = udfFuncService.queryUdfFuncListPaging(loginUser,searchVal,pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_UDF_FUNCTION_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_UDF_FUNCTION_LIST_PAGING_ERROR.getCode(), Status.QUERY_UDF_FUNCTION_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query resource list by type\n+     *\n+     * @param loginUser login user\n+     * @param type  resource type\n+     * @return resource list\n+     */\n+    @ApiOperation(value = \"queryResourceList\", notes= \"QUERY_RESOURCE_LIST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"type\", value = \"UDF_TYPE\", required = true, dataType =\"UdfType\")\n+    })\n+    @GetMapping(value=\"/udf-func/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryResourceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                    @RequestParam(\"type\") UdfType type){\n+        try{\n+            logger.info(\"query datasource list, user:{}, type:{}\", loginUser.getUserName(), type.toString());\n+            Map<String, Object> result = udfFuncService.queryResourceList(loginUser,type.ordinal());\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(QUERY_DATASOURCE_BY_TYPE_ERROR.getMsg(),e);\n+            return error(Status.QUERY_DATASOURCE_BY_TYPE_ERROR.getCode(),QUERY_DATASOURCE_BY_TYPE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * verify udf function name can use or not\n+     *\n+     * @param loginUser login user\n+     * @param name name\n+     * @return true if the name can user, otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyUdfFuncName\", notes= \"VERIFY_UDF_FUNCTION_NAME_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"name\", value = \"FUNC_NAME\",required = true,  dataType =\"String\")\n+\n+    })\n+    @GetMapping(value = \"/udf-func/verify-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyUdfFuncName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                    @RequestParam(value =\"name\") String name\n+    ) {\n+        logger.info(\"login user {}, verfiy udf function name: {}\",\n+                loginUser.getUserName(),name);\n+\n+        try{\n+\n+            return udfFuncService.verifyUdfFuncByName(name);\n+        }catch (Exception e){\n+            logger.error(VERIFY_UDF_FUNCTION_NAME_ERROR.getMsg(),e);\n+            return error(Status.VERIFY_UDF_FUNCTION_NAME_ERROR.getCode(), Status.VERIFY_UDF_FUNCTION_NAME_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete udf function\n+     *\n+     * @param loginUser login user\n+     * @param udfFuncId udf function id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteUdfFunc\", notes= \"DELETE_UDF_FUNCTION_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"RESOURCE_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/udf-func/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteUdfFunc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(value =\"id\") int udfFuncId\n+    ) {\n+        try{\n+\n+            logger.info(\"login user {}, delete udf function id: {}\", loginUser.getUserName(),udfFuncId);\n+            return udfFuncService.delete(udfFuncId);\n+        }catch (Exception e){\n+            logger.error(DELETE_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.DELETE_UDF_FUNCTION_ERROR.getCode(), Status.DELETE_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * authorized file resource list\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return authorized result\n+     */\n+    @ApiOperation(value = \"authorizedFile\", notes= \"AUTHORIZED_FILE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/authed-file\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result authorizedFile(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(\"userId\") Integer userId) {\n+        try{\n+            logger.info(\"authorized file resource, user: {}, user id:{}\", loginUser.getUserName(), userId);\n+            Map<String, Object> result =  resourceService.authorizedFile(loginUser, userId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(AUTHORIZED_FILE_RESOURCE_ERROR.getMsg(),e);\n+            return error(Status.AUTHORIZED_FILE_RESOURCE_ERROR.getCode(), Status.AUTHORIZED_FILE_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * unauthorized file resource list\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return unauthorized result code\n+     */\n+    @ApiOperation(value = \"unauthorizedFile\", notes= \"UNAUTHORIZED_FILE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/unauth-file\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result unauthorizedFile(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"userId\") Integer userId) {\n+        try{\n+            logger.info(\"resource unauthorized file, user:{}, unauthorized user id:{}\", loginUser.getUserName(), userId);\n+            Map<String, Object> result =  resourceService.unauthorizedFile(loginUser, userId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(UNAUTHORIZED_FILE_RESOURCE_ERROR.getMsg(),e);\n+            return error(Status.UNAUTHORIZED_FILE_RESOURCE_ERROR.getCode(), Status.UNAUTHORIZED_FILE_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * unauthorized udf function\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return unauthorized result code\n+     */\n+    @ApiOperation(value = \"unauthUDFFunc\", notes= \"UNAUTHORIZED_UDF_FUNC_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/unauth-udf-func\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result unauthUDFFunc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"userId\") Integer userId) {\n+        try{\n+            logger.info(\"unauthorized udf function, login user:{}, unauthorized user id:{}\", loginUser.getUserName(), userId);\n+\n+            Map<String, Object>  result =  resourceService.unauthorizedUDFFunction(loginUser, userId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(UNAUTHORIZED_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.UNAUTHORIZED_UDF_FUNCTION_ERROR.getCode(), Status.UNAUTHORIZED_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * authorized udf function\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @return authorized result code\n+     */\n+    @ApiOperation(value = \"authUDFFunc\", notes= \"AUTHORIZED_UDF_FUNC_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\", required = true, dataType =\"Int\", example = \"100\")\n+    })\n+    @GetMapping(value = \"/authed-udf-func\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result authorizedUDFFunction(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                        @RequestParam(\"userId\") Integer userId) {\n+        try{\n+            logger.info(\"auth udf function, login user:{}, auth user id:{}\", loginUser.getUserName(), userId);\n+            Map<String, Object> result =  resourceService.authorizedUDFFunction(loginUser, userId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(AUTHORIZED_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.AUTHORIZED_UDF_FUNCTION_ERROR.getCode(), Status.AUTHORIZED_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+}\n\\ No newline at end of file",
                "changes": 734
            },
            {
                "status": "added",
                "additions": 346,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java",
                "deletions": 0,
                "sha": "96038dcf8c1e915219589dfe30193cfe22ccebbf",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java",
                "patch": "@@ -0,0 +1,346 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.SchedulerService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.enums.FailureStrategy;\n+import org.apache.dolphinscheduler.common.enums.Priority;\n+import org.apache.dolphinscheduler.common.enums.ReleaseState;\n+import org.apache.dolphinscheduler.common.enums.WarningType;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+import static org.apache.dolphinscheduler.api.enums.Status.*;\n+import static org.apache.dolphinscheduler.common.Constants.SESSION_USER;\n+\n+/**\n+ * schedule controller\n+ */\n+@Api(tags = \"SCHEDULER_TAG\", position = 13)\n+@RestController\n+@RequestMapping(\"/projects/{projectName}/schedule\")\n+public class SchedulerController extends BaseController {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SchedulerController.class);\n+    public static final String DEFAULT_WARNING_TYPE = \"NONE\";\n+    public static final String DEFAULT_NOTIFY_GROUP_ID = \"1\";\n+    public static final String DEFAULT_FAILURE_POLICY = \"CONTINUE\";\n+\n+\n+    @Autowired\n+    private SchedulerService schedulerService;\n+\n+\n+    /**\n+     * create schedule\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @param schedule scheduler\n+     * @param warningType  warning type\n+     * @param warningGroupId warning group id\n+     * @param failureStrategy failure strategy\n+     * @param processInstancePriority process instance priority\n+     * @param receivers receivers\n+     * @param receiversCc receivers cc\n+     * @param workerGroupId  worker group id\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createSchedule\", notes= \"CREATE_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"schedule\", value = \"SCHEDULE\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"warningType\", value = \"WARNING_TYPE\", type =\"WarningType\"),\n+            @ApiImplicitParam(name = \"warningGroupId\", value = \"WARNING_GROUP_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"failureStrategy\", value = \"FAILURE_STRATEGY\", type =\"FailureStrategy\"),\n+            @ApiImplicitParam(name = \"receivers\", value = \"RECEIVERS\", type =\"String\"),\n+            @ApiImplicitParam(name = \"receiversCc\", value = \"RECEIVERS_CC\", type =\"String\"),\n+            @ApiImplicitParam(name = \"workerGroupId\", value = \"WORKER_GROUP_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"processInstancePriority\", value = \"PROCESS_INSTANCE_PRIORITY\", type =\"Priority\"),\n+    })\n+    @PostMapping(\"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createSchedule(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                                 @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                 @RequestParam(value = \"processDefinitionId\") Integer processDefinitionId,\n+                                 @RequestParam(value = \"schedule\") String schedule,\n+                                 @RequestParam(value = \"warningType\", required = false, defaultValue = DEFAULT_WARNING_TYPE) WarningType warningType,\n+                                 @RequestParam(value = \"warningGroupId\", required = false, defaultValue = DEFAULT_NOTIFY_GROUP_ID) int warningGroupId,\n+                                 @RequestParam(value = \"failureStrategy\", required = false, defaultValue = DEFAULT_FAILURE_POLICY) FailureStrategy failureStrategy,\n+                                 @RequestParam(value = \"receivers\", required = false) String receivers,\n+                                 @RequestParam(value = \"receiversCc\", required = false) String receiversCc,\n+                                 @RequestParam(value = \"workerGroupId\", required = false, defaultValue = \"-1\") int workerGroupId,\n+                                 @RequestParam(value = \"processInstancePriority\", required = false) Priority processInstancePriority) {\n+        logger.info(\"login user {}, project name: {}, process name: {}, create schedule: {}, warning type: {}, warning group id: {},\" +\n+                        \"failure policy: {},receivers : {},receiversCc : {},processInstancePriority : {}, workGroupId:{}\",\n+                loginUser.getUserName(), projectName, processDefinitionId, schedule, warningType, warningGroupId,\n+                failureStrategy, receivers, receiversCc, processInstancePriority, workerGroupId);\n+        try {\n+            Map<String, Object> result = schedulerService.insertSchedule(loginUser, projectName, processDefinitionId, schedule,\n+                    warningType, warningGroupId, failureStrategy, receivers, receiversCc, processInstancePriority, workerGroupId);\n+\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(CREATE_SCHEDULE_ERROR.getMsg(), e);\n+            return error(CREATE_SCHEDULE_ERROR.getCode(), CREATE_SCHEDULE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * updateProcessInstance schedule\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param id scheduler id\n+     * @param schedule scheduler\n+     * @param warningType warning type\n+     * @param warningGroupId warning group id\n+     * @param failureStrategy failure strategy\n+     * @param receivers receivers\n+     * @param workerGroupId worker group id\n+     * @param processInstancePriority process instance priority\n+     * @param receiversCc receivers cc\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateSchedule\", notes= \"UPDATE_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"SCHEDULE_ID\", required = true, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"schedule\", value = \"SCHEDULE\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"warningType\", value = \"WARNING_TYPE\", type =\"WarningType\"),\n+            @ApiImplicitParam(name = \"warningGroupId\", value = \"WARNING_GROUP_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"failureStrategy\", value = \"FAILURE_STRATEGY\", type =\"FailureStrategy\"),\n+            @ApiImplicitParam(name = \"receivers\", value = \"RECEIVERS\", type =\"String\"),\n+            @ApiImplicitParam(name = \"receiversCc\", value = \"RECEIVERS_CC\", type =\"String\"),\n+            @ApiImplicitParam(name = \"workerGroupId\", value = \"WORKER_GROUP_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"processInstancePriority\", value = \"PROCESS_INSTANCE_PRIORITY\", type =\"Priority\"),\n+    })\n+    @PostMapping(\"/update\")\n+    public Result updateSchedule(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                                 @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                 @RequestParam(value = \"id\") Integer id,\n+                                 @RequestParam(value = \"schedule\") String schedule,\n+                                 @RequestParam(value = \"warningType\", required = false, defaultValue = DEFAULT_WARNING_TYPE) WarningType warningType,\n+                                 @RequestParam(value = \"warningGroupId\", required = false) int warningGroupId,\n+                                 @RequestParam(value = \"failureStrategy\", required = false, defaultValue = \"END\") FailureStrategy failureStrategy,\n+                                 @RequestParam(value = \"receivers\", required = false) String receivers,\n+                                 @RequestParam(value = \"receiversCc\", required = false) String receiversCc,\n+                                 @RequestParam(value = \"workerGroupId\", required = false, defaultValue = \"-1\") int workerGroupId,\n+                                 @RequestParam(value = \"processInstancePriority\", required = false) Priority processInstancePriority) {\n+        logger.info(\"login user {}, project name: {},id: {}, updateProcessInstance schedule: {}, notify type: {}, notify mails: {}, \" +\n+                        \"failure policy: {},receivers : {},receiversCc : {},processInstancePriority : {},workerGroupId:{}\",\n+                loginUser.getUserName(), projectName, id, schedule, warningType, warningGroupId, failureStrategy,\n+                receivers, receiversCc, processInstancePriority, workerGroupId);\n+\n+        try {\n+            Map<String, Object> result = schedulerService.updateSchedule(loginUser, projectName, id, schedule,\n+                    warningType, warningGroupId, failureStrategy, receivers, receiversCc, null, processInstancePriority, workerGroupId);\n+            return returnDataList(result);\n+\n+        } catch (Exception e) {\n+            logger.error(UPDATE_SCHEDULE_ERROR.getMsg(), e);\n+            return error(Status.UPDATE_SCHEDULE_ERROR.getCode(), Status.UPDATE_SCHEDULE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * publish schedule setScheduleState\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param id scheduler id\n+     * @return publish result code\n+     */\n+    @ApiOperation(value = \"online\", notes= \"ONLINE_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"SCHEDULE_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(\"/online\")\n+    public Result online(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                         @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable(\"projectName\") String projectName,\n+                         @RequestParam(\"id\") Integer id) {\n+        logger.info(\"login user {}, schedule setScheduleState, project name: {}, id: {}\",\n+                loginUser.getUserName(), projectName, id);\n+        try {\n+            Map<String, Object> result = schedulerService.setScheduleState(loginUser, projectName, id, ReleaseState.ONLINE);\n+            return returnDataList(result);\n+\n+        } catch (Exception e) {\n+            logger.error(PUBLISH_SCHEDULE_ONLINE_ERROR.getMsg(), e);\n+            return error(Status.PUBLISH_SCHEDULE_ONLINE_ERROR.getCode(), Status.PUBLISH_SCHEDULE_ONLINE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * offline schedule\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param id schedule id\n+     * @return operation result code\n+     */\n+    @ApiOperation(value = \"offline\", notes= \"OFFLINE_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"SCHEDULE_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(\"/offline\")\n+    public Result offline(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                          @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable(\"projectName\") String projectName,\n+                          @RequestParam(\"id\") Integer id) {\n+        logger.info(\"login user {}, schedule offline, project name: {}, process definition id: {}\",\n+                loginUser.getUserName(), projectName, id);\n+\n+        try {\n+            Map<String, Object> result = schedulerService.setScheduleState(loginUser, projectName, id, ReleaseState.OFFLINE);\n+            return returnDataList(result);\n+\n+        } catch (Exception e) {\n+            logger.error(OFFLINE_SCHEDULE_ERROR.getMsg(), e);\n+            return error(Status.OFFLINE_SCHEDULE_ERROR.getCode(), Status.OFFLINE_SCHEDULE_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query schedule list paging\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processDefinitionId process definition id\n+     * @param pageNo page number\n+     * @param pageSize  page size\n+     * @param searchVal search value\n+     * @return schedule list page\n+     */\n+    @ApiOperation(value = \"queryScheduleListPaging\", notes= \"QUERY_SCHEDULE_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processDefinitionId\", value = \"PROCESS_DEFINITION_ID\", required = true,dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\",  type = \"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\",  dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\",  dataType = \"Int\", example = \"100\")\n+\n+    })\n+  @GetMapping(\"/list-paging\")\n+    public Result queryScheduleListPaging(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                                          @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                          @RequestParam Integer processDefinitionId,\n+                                          @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                          @RequestParam(\"pageNo\") Integer pageNo,\n+                                          @RequestParam(\"pageSize\") Integer pageSize) {\n+    logger.info(\"login user {}, query schedule, project name: {}, process definition id: {}\",\n+            loginUser.getUserName(), projectName, processDefinitionId);\n+      try {\n+          searchVal = ParameterUtils.handleEscapes(searchVal);\n+          Map<String, Object> result = schedulerService.querySchedule(loginUser, projectName, processDefinitionId, searchVal, pageNo, pageSize);\n+          return returnDataListPaging(result);\n+       }catch (Exception e){\n+          logger.error(QUERY_SCHEDULE_LIST_PAGING_ERROR.getMsg(),e);\n+          return error(Status.QUERY_SCHEDULE_LIST_PAGING_ERROR.getCode(), Status.QUERY_SCHEDULE_LIST_PAGING_ERROR.getMsg());\n+      }\n+\n+    }\n+\n+    /**\n+     * delete schedule by id\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param scheduleId scheule id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteScheduleById\", notes= \"OFFLINE_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"scheduleId\", value = \"SCHEDULE_ID\", required = true, dataType = \"Int\", example = \"100\")\n+    })\n+    @GetMapping(value=\"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteScheduleById(@RequestAttribute(value = SESSION_USER) User loginUser,\n+                                              @PathVariable String projectName,\n+                                              @RequestParam(\"scheduleId\") Integer scheduleId\n+    ){\n+        try{\n+            logger.info(\"delete schedule by id, login user:{}, project name:{}, schedule id:{}\",\n+                    loginUser.getUserName(), projectName, scheduleId);\n+            Map<String, Object> result = schedulerService.deleteScheduleById(loginUser, projectName, scheduleId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(DELETE_SCHEDULE_CRON_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.DELETE_SCHEDULE_CRON_BY_ID_ERROR.getCode(), Status.DELETE_SCHEDULE_CRON_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+    /**\n+     * query schedule list\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @return schedule list\n+     */\n+    @ApiOperation(value = \"queryScheduleList\", notes= \"QUERY_SCHEDULE_LIST_NOTES\")\n+    @PostMapping(\"/list\")\n+    public Result queryScheduleList(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                                    @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName) {\n+        try {\n+            logger.info(\"login user {}, query schedule list, project name: {}\",\n+                    loginUser.getUserName(), projectName);\n+            Map<String, Object> result = schedulerService.queryScheduleList(loginUser, projectName);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(QUERY_SCHEDULE_LIST_ERROR.getMsg(), e);\n+            return error(Status.QUERY_SCHEDULE_LIST_ERROR.getCode(), Status.QUERY_SCHEDULE_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * preview schedule\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param schedule schedule expression\n+     * @return the next five fire time\n+     */\n+    @ApiOperation(value = \"previewSchedule\", notes= \"PREVIEW_SCHEDULE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"schedule\", value = \"SCHEDULE\", dataType = \"String\", example = \"{'startTime':'2019-06-10 00:00:00','endTime':'2019-06-13 00:00:00','crontab':'0 0 3/6 * * ? *'}\"),\n+    })\n+    @PostMapping(\"/preview\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result previewSchedule(@ApiIgnore @RequestAttribute(value = SESSION_USER) User loginUser,\n+                                 @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                 @RequestParam(value = \"schedule\") String schedule\n+    ){\n+        logger.info(\"login user {}, project name: {}, preview schedule: {}\",\n+                loginUser.getUserName(), projectName, schedule);\n+        try {\n+            Map<String, Object> result = schedulerService.previewSchedule(loginUser, projectName, schedule);\n+            return returnDataList(result);\n+        } catch (Exception e) {\n+            logger.error(PREVIEW_SCHEDULE_ERROR.getMsg(), e);\n+            return error(PREVIEW_SCHEDULE_ERROR.getCode(), PREVIEW_SCHEDULE_ERROR.getMsg());\n+        }\n+    }\n+}",
                "changes": 346
            },
            {
                "status": "added",
                "additions": 107,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceController.java",
                "deletions": 0,
                "sha": "5f63d744cf41cf71f00aa375f278ba0deb3ded08",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceController.java",
                "patch": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.service.TaskInstanceService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.*;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+/**\n+ * task instance controller\n+ */\n+@Api(tags = \"TASK_INSTANCE_TAG\", position = 11)\n+@RestController\n+@RequestMapping(\"/projects/{projectName}/task-instance\")\n+public class TaskInstanceController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(TaskInstanceController.class);\n+\n+    @Autowired\n+    TaskInstanceService taskInstanceService;\n+\n+\n+    /**\n+     * query task list paging\n+     *\n+     * @param loginUser login user\n+     * @param projectName project name\n+     * @param processInstanceId process instance id\n+     * @param searchVal search value\n+     * @param taskName task name\n+     * @param stateType state type\n+     * @param host host\n+     * @param startTime start time\n+     * @param endTime end time\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return task list page\n+     */\n+    @ApiOperation(value = \"queryTaskListPaging\", notes= \"QUERY_TASK_INSTANCE_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"processInstanceId\", value = \"PROCESS_INSTANCE_ID\",required = false, dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", type =\"String\"),\n+            @ApiImplicitParam(name = \"taskName\", value = \"TASK_NAME\", type =\"String\"),\n+            @ApiImplicitParam(name = \"stateType\", value = \"EXECUTION_STATUS\", type =\"ExecutionStatus\"),\n+            @ApiImplicitParam(name = \"host\", value = \"HOST\", type =\"String\"),\n+            @ApiImplicitParam(name = \"startDate\", value = \"START_DATE\", type =\"String\"),\n+            @ApiImplicitParam(name = \"endDate\", value = \"END_DATE\", type =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType = \"Int\", example = \"20\")\n+    })\n+    @GetMapping(\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryTaskListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                      @ApiParam(name = \"projectName\", value = \"PROJECT_NAME\", required = true) @PathVariable String projectName,\n+                                      @RequestParam(value = \"processInstanceId\", required = false, defaultValue = \"0\") Integer processInstanceId,\n+                                      @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                      @RequestParam(value = \"taskName\", required = false) String taskName,\n+                                      @RequestParam(value = \"stateType\", required = false) ExecutionStatus stateType,\n+                                      @RequestParam(value = \"host\", required = false) String host,\n+                                      @RequestParam(value = \"startDate\", required = false) String startTime,\n+                                      @RequestParam(value = \"endDate\", required = false) String endTime,\n+                                      @RequestParam(\"pageNo\") Integer pageNo,\n+                                      @RequestParam(\"pageSize\") Integer pageSize){\n+\n+        try{\n+            logger.info(\"query task instance list, project name:{},process instance:{}, search value:{},task name:{}, state type:{}, host:{}, start:{}, end:{}\",\n+                    projectName, processInstanceId, searchVal, taskName, stateType, host, startTime, endTime);\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            Map<String, Object> result = taskInstanceService.queryTaskListPaging(\n+                    loginUser, projectName, processInstanceId, taskName, startTime, endTime, searchVal, stateType, host, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_TASK_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_TASK_LIST_PAGING_ERROR.getCode(), Status.QUERY_TASK_LIST_PAGING_ERROR.getMsg());\n+        }\n+\n+    }\n+\n+}",
                "changes": 107
            },
            {
                "status": "added",
                "additions": 131,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRecordController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRecordController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRecordController.java",
                "deletions": 0,
                "sha": "64121c26dd0eb89da55f4ed344d58fe1fed13a3b",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRecordController.java",
                "patch": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.service.TaskRecordService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+/**\n+ * data quality controller\n+ */\n+@ApiIgnore\n+@RestController\n+@RequestMapping(\"/projects/task-record\")\n+public class TaskRecordController extends BaseController{\n+\n+\n+    private static final Logger logger = LoggerFactory.getLogger(TaskRecordController.class);\n+\n+\n+    @Autowired\n+    TaskRecordService taskRecordService;\n+\n+    /**\n+     * query task record list page\n+     *\n+     * @param loginUser login user\n+     * @param taskName task name\n+     * @param state state\n+     * @param sourceTable source table\n+     * @param destTable destination table\n+     * @param taskDate task date\n+     * @param startTime start time\n+     * @param endTime end time\n+     * @param pageNo page numbere\n+     * @param pageSize page size\n+     * @return task record list\n+     */\n+    @GetMapping(\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryTaskRecordListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @RequestParam(value = \"taskName\", required = false) String taskName,\n+                                            @RequestParam(value = \"state\", required = false) String state,\n+                                            @RequestParam(value = \"sourceTable\", required = false) String sourceTable,\n+                                            @RequestParam(value = \"destTable\", required = false) String destTable,\n+                                            @RequestParam(value = \"taskDate\", required = false) String taskDate,\n+                                            @RequestParam(value = \"startDate\", required = false) String startTime,\n+                                            @RequestParam(value = \"endDate\", required = false) String endTime,\n+                                            @RequestParam(\"pageNo\") Integer pageNo,\n+                                            @RequestParam(\"pageSize\") Integer pageSize\n+                                      ){\n+\n+   try{\n+        logger.info(\"query task record list, task name:{}, state :{}, taskDate: {}, start:{}, end:{}\",\n+                taskName, state,  taskDate, startTime, endTime);\n+        Map<String, Object> result = taskRecordService.queryTaskRecordListPaging(false, taskName, startTime,  taskDate, sourceTable, destTable, endTime,state, pageNo, pageSize);\n+        return returnDataListPaging(result);\n+    }catch (Exception e){\n+        logger.error(Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getMsg(),e);\n+        return error(Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getCode(), Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getMsg());\n+    }\n+\n+    }\n+\n+    /**\n+     * query history task record list paging\n+     *\n+     * @param loginUser login user\n+     * @param taskName task name\n+     * @param state state\n+     * @param sourceTable source table\n+     * @param destTable destination table\n+     * @param taskDate task date\n+     * @param startTime start time\n+     * @param endTime end time\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return history task record list\n+     */\n+    @GetMapping(\"/history-list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryHistoryTaskRecordListPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                            @RequestParam(value = \"taskName\", required = false) String taskName,\n+                                            @RequestParam(value = \"state\", required = false) String state,\n+                                            @RequestParam(value = \"sourceTable\", required = false) String sourceTable,\n+                                            @RequestParam(value = \"destTable\", required = false) String destTable,\n+                                            @RequestParam(value = \"taskDate\", required = false) String taskDate,\n+                                            @RequestParam(value = \"startDate\", required = false) String startTime,\n+                                            @RequestParam(value = \"endDate\", required = false) String endTime,\n+                                            @RequestParam(\"pageNo\") Integer pageNo,\n+                                            @RequestParam(\"pageSize\") Integer pageSize\n+    ){\n+\n+        try{\n+            logger.info(\"query hisotry task record list, task name:{}, state :{}, taskDate: {}, start:{}, end:{}\",\n+                    taskName, state,  taskDate, startTime, endTime);\n+            Map<String, Object> result = taskRecordService.queryTaskRecordListPaging(true, taskName, startTime,  taskDate, sourceTable, destTable, endTime,state, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getCode(), Status.QUERY_TASK_RECORD_LIST_PAGING_ERROR.getMsg());\n+        }\n+\n+    }\n+\n+}",
                "changes": 131
            },
            {
                "status": "added",
                "additions": 246,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TenantController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TenantController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TenantController.java",
                "deletions": 0,
                "sha": "6b0a4ec4962a4d637f000fbabe5c0b2c01fb6462",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TenantController.java",
                "patch": "@@ -0,0 +1,246 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.TenantService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * tenant controller\n+ */\n+@Api(tags = \"TENANT_TAG\", position = 1)\n+@RestController\n+@RequestMapping(\"/tenant\")\n+public class TenantController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(TenantController.class);\n+\n+\n+    @Autowired\n+    private TenantService tenantService;\n+\n+    /**\n+     * create tenant\n+     *\n+     * @param loginUser login user\n+     * @param tenantCode tenant code\n+     * @param tenantName tenant name\n+     * @param queueId queue id\n+     * @param description description\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createTenant\", notes= \"CREATE_TENANT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"tenantCode\", value = \"TENANT_CODE\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"tenantName\", value = \"TENANT_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"queueId\", value = \"QUEUE_ID\", required = true, dataType =\"Int\",example = \"100\"),\n+            @ApiImplicitParam(name = \"description\", value = \"TENANT_DESC\", dataType =\"String\")\n+\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createTenant(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                       @RequestParam(value = \"tenantCode\") String tenantCode,\n+                                                       @RequestParam(value = \"tenantName\") String tenantName,\n+                                                       @RequestParam(value = \"queueId\") int queueId,\n+                                                       @RequestParam(value = \"description\",required = false) String description) {\n+        logger.info(\"login user {}, create tenant, tenantCode: {}, tenantName: {}, queueId: {}, desc: {}\",\n+                loginUser.getUserName(), tenantCode, tenantName, queueId,description);\n+        try {\n+            Map<String, Object> result = tenantService.createTenant(loginUser,tenantCode,tenantName,queueId,description);\n+            return returnDataList(result);\n+\n+        }catch (Exception e){\n+            logger.error(Status.CREATE_TENANT_ERROR.getMsg(),e);\n+            return error(Status.CREATE_TENANT_ERROR.getCode(), Status.CREATE_TENANT_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * query tenant list paging\n+     *\n+     * @param loginUser login user\n+     * @param searchVal search value\n+     * @param pageNo page number\n+     * @param pageSize page size\n+     * @return tenant list page\n+     */\n+    @ApiOperation(value = \"queryTenantlistPaging\", notes= \"QUERY_TENANT_LIST_PAGING_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", dataType =\"String\"),\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\", dataType = \"Int\", example = \"1\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", dataType =\"Int\",example = \"20\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryTenantlistPaging(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                     @RequestParam(\"pageNo\") Integer pageNo,\n+                                                     @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                                     @RequestParam(\"pageSize\") Integer pageSize){\n+        logger.info(\"login user {}, list paging, pageNo: {}, searchVal: {}, pageSize: {}\",\n+                loginUser.getUserName(),pageNo,searchVal,pageSize);\n+        try{\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = tenantService.queryTenantList(loginUser, searchVal, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_TENANT_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_TENANT_LIST_PAGING_ERROR.getCode(), Status.QUERY_TENANT_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * tenant list\n+     *\n+     * @param loginUser login user\n+     * @return tenant list\n+     */\n+    @ApiOperation(value = \"queryTenantlist\", notes= \"QUERY_TENANT_LIST_NOTES\")\n+    @GetMapping(value=\"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryTenantlist(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        logger.info(\"login user {}, query tenant list\");\n+        try{\n+            Map<String, Object> result = tenantService.queryTenantList(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_TENANT_LIST_ERROR.getMsg(),e);\n+            return error(Status.QUERY_TENANT_LIST_ERROR.getCode(), Status.QUERY_TENANT_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+\n+    /**\n+     * udpate tenant\n+     *\n+     * @param loginUser login user\n+     * @param id tennat id\n+     * @param tenantCode tennat code\n+     * @param tenantName tennat name\n+     * @param queueId queue id\n+     * @param description description\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateTenant\", notes= \"UPDATE_TENANT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"ID\", value = \"TENANT_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"tenantCode\", value = \"TENANT_CODE\", required = true, dataType = \"String\"),\n+            @ApiImplicitParam(name = \"tenantName\", value = \"TENANT_NAME\", required = true, dataType =\"String\"),\n+            @ApiImplicitParam(name = \"queueId\", value = \"QUEUE_ID\", required = true, dataType =\"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"description\", value = \"TENANT_DESC\", type =\"String\")\n+\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateTenant(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                       @RequestParam(value = \"id\") int id,\n+                                                       @RequestParam(value = \"tenantCode\") String tenantCode,\n+                                                       @RequestParam(value = \"tenantName\") String tenantName,\n+                                                       @RequestParam(value = \"queueId\") int queueId,\n+                                                       @RequestParam(value = \"description\",required = false) String description) {\n+        logger.info(\"login user {}, updateProcessInstance tenant, tenantCode: {}, tenantName: {}, queueId: {}, description: {}\",\n+                loginUser.getUserName(), tenantCode, tenantName, queueId,description);\n+        try {\n+            Map<String, Object> result = tenantService.updateTenant(loginUser,id,tenantCode, tenantName, queueId, description);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.UPDATE_TENANT_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_TENANT_ERROR.getCode(), Status.UPDATE_TENANT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete tenant by id\n+     *\n+     * @param loginUser login user\n+     * @param id tenant id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"deleteTenantById\", notes= \"DELETE_TENANT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"ID\", value = \"TENANT_ID\", required = true, dataType =\"Int\", example = \"100\")\n+\n+    })\n+    @PostMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result deleteTenantById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(value = \"id\") int id) {\n+        logger.info(\"login user {}, delete tenant, tenantId: {},\", loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> result = tenantService.deleteTenantById(loginUser,id);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.DELETE_TENANT_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.DELETE_TENANT_BY_ID_ERROR.getCode(), Status.DELETE_TENANT_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * verify tenant code\n+     *\n+     * @param loginUser login user\n+     * @param tenantCode tenant code\n+     * @return true if tenant code can user, otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyTenantCode\", notes= \"VERIFY_TENANT_CODE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"tenantCode\", value = \"TENANT_CODE\", required = true, dataType = \"String\")\n+    })\n+    @GetMapping(value = \"/verify-tenant-code\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyTenantCode(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(value =\"tenantCode\") String tenantCode\n+    ) {\n+\n+        try{\n+            logger.info(\"login user {}, verfiy tenant code: {}\",\n+                    loginUser.getUserName(),tenantCode);\n+            return tenantService.verifyTenantCode(tenantCode);\n+        }catch (Exception e){\n+            logger.error(Status.VERIFY_TENANT_CODE_ERROR.getMsg(),e);\n+            return error(Status.VERIFY_TENANT_CODE_ERROR.getCode(), Status.VERIFY_TENANT_CODE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+}",
                "changes": 246
            },
            {
                "status": "added",
                "additions": 460,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java",
                "deletions": 0,
                "sha": "b89dd0fa2cd935efc2cd402a144a7d441ae50974",
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java",
                "patch": "@@ -0,0 +1,460 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dolphinscheduler.api.controller;\n+\n+\n+import org.apache.dolphinscheduler.api.enums.Status;\n+import org.apache.dolphinscheduler.api.service.UsersService;\n+import org.apache.dolphinscheduler.api.utils.Result;\n+import org.apache.dolphinscheduler.common.Constants;\n+import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n+import org.apache.dolphinscheduler.dao.entity.User;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiImplicitParam;\n+import io.swagger.annotations.ApiImplicitParams;\n+import io.swagger.annotations.ApiOperation;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.web.bind.annotation.*;\n+import springfox.documentation.annotations.ApiIgnore;\n+\n+import java.util.Map;\n+\n+\n+/**\n+ * user controller\n+ */\n+@Api(tags = \"USERS_TAG\" , position = 14)\n+@RestController\n+@RequestMapping(\"/users\")\n+public class UsersController extends BaseController{\n+\n+    private static final Logger logger = LoggerFactory.getLogger(UsersController.class);\n+\n+    @Autowired\n+    private UsersService usersService;\n+\n+    /**\n+     * create user\n+     * \n+     * @param loginUser login user\n+     * @param userName user name\n+     * @param userPassword user password\n+     * @param email email\n+     * @param tenantId tenant id\n+     * @param phone phone\n+     * @param queue  queue\n+     * @return create result code\n+     */\n+    @ApiOperation(value = \"createUser\", notes= \"CREATE_USER_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",type = \"String\"),\n+            @ApiImplicitParam(name = \"userPassword\", value = \"USER_PASSWORD\", type =\"String\"),\n+            @ApiImplicitParam(name = \"tenantId\", value = \"TENANT_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"queue\", value = \"QUEUE\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"email\", value = \"EMAIL\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"phone\", value = \"PHONE\", dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(value = \"/create\")\n+    @ResponseStatus(HttpStatus.CREATED)\n+    public Result createUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                     @RequestParam(value = \"userName\") String userName,\n+                                                     @RequestParam(value = \"userPassword\") String userPassword,\n+                                                     @RequestParam(value = \"tenantId\") int tenantId,\n+                                                     @RequestParam(value = \"queue\",required = false,defaultValue = \"\") String queue,\n+                                                     @RequestParam(value = \"email\") String email,\n+                                                     @RequestParam(value = \"phone\", required = false) String phone) {\n+        logger.info(\"login user {}, create user, userName: {}, email: {}, tenantId: {}, userPassword: {}, phone: {}, user queue: {}\",\n+                loginUser.getUserName(), userName, email, tenantId, Constants.PASSWORD_DEFAULT, phone,queue);\n+\n+        try {\n+            Map<String, Object> result = usersService.createUser(loginUser, userName, userPassword,email,tenantId, phone,queue);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.CREATE_USER_ERROR.getMsg(),e);\n+            return error(Status.CREATE_USER_ERROR.getCode(), Status.CREATE_USER_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * query user list paging\n+     *\n+     * @param loginUser login user\n+     * @param pageNo page number\n+     * @param searchVal search avlue\n+     * @param pageSize page size\n+     * @return user list page\n+     */\n+    @ApiOperation(value = \"queryUserList\", notes= \"QUERY_USER_LIST_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"pageNo\", value = \"PAGE_NO\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"pageSize\", value = \"PAGE_SIZE\", type =\"String\"),\n+            @ApiImplicitParam(name = \"searchVal\", value = \"SEARCH_VAL\", type =\"String\")\n+    })\n+    @GetMapping(value=\"/list-paging\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result queryUserList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                @RequestParam(\"pageNo\") Integer pageNo,\n+                                @RequestParam(value = \"searchVal\", required = false) String searchVal,\n+                                @RequestParam(\"pageSize\") Integer pageSize){\n+        logger.info(\"login user {}, list user paging, pageNo: {}, searchVal: {}, pageSize: {}\",\n+                loginUser.getUserName(),pageNo,searchVal,pageSize);\n+        try{\n+            Map<String, Object> result = checkPageParams(pageNo, pageSize);\n+            if(result.get(Constants.STATUS) != Status.SUCCESS){\n+                return returnDataListPaging(result);\n+            }\n+            searchVal = ParameterUtils.handleEscapes(searchVal);\n+            result = usersService.queryUserList(loginUser, searchVal, pageNo, pageSize);\n+            return returnDataListPaging(result);\n+        }catch (Exception e){\n+            logger.error(Status.QUERY_USER_LIST_PAGING_ERROR.getMsg(),e);\n+            return error(Status.QUERY_USER_LIST_PAGING_ERROR.getCode(), Status.QUERY_USER_LIST_PAGING_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * update user\n+     *\n+     * @param loginUser login user\n+     * @param id user id\n+     * @param userName user name\n+     * @param userPassword user password\n+     * @param email email\n+     * @param tenantId tennat id\n+     * @param phone phone\n+     * @param queue queue\n+     * @return update result code\n+     */\n+    @ApiOperation(value = \"updateUser\", notes= \"UPDATE_USER_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"USER_ID\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",type = \"String\"),\n+            @ApiImplicitParam(name = \"userPassword\", value = \"USER_PASSWORD\", type =\"String\"),\n+            @ApiImplicitParam(name = \"tenantId\", value = \"TENANT_ID\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"queue\", value = \"QUEUE\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"email\", value = \"EMAIL\", dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"phone\", value = \"PHONE\", dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(value = \"/update\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result updateUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                     @RequestParam(value = \"id\") int id,\n+                                                     @RequestParam(value = \"userName\") String userName,\n+                                                     @RequestParam(value = \"userPassword\") String userPassword,\n+                                                     @RequestParam(value = \"queue\",required = false,defaultValue = \"\") String queue,\n+                                                     @RequestParam(value = \"email\") String email,\n+                                                     @RequestParam(value = \"tenantId\") int tenantId,\n+                                                     @RequestParam(value = \"phone\", required = false) String phone) {\n+        logger.info(\"login user {}, updateProcessInstance user, userName: {}, email: {}, tenantId: {}, userPassword: {}, phone: {}, user queue: {}\",\n+                loginUser.getUserName(), userName, email, tenantId, Constants.PASSWORD_DEFAULT, phone,queue);\n+        try {\n+            Map<String, Object> result = usersService.updateUser(id, userName, userPassword, email, tenantId, phone, queue);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.UPDATE_USER_ERROR.getMsg(),e);\n+            return error(Status.UPDATE_USER_ERROR.getCode(), Status.UPDATE_USER_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * delete user by id\n+     * @param loginUser login user\n+     * @param id user id\n+     * @return delete result code\n+     */\n+    @ApiOperation(value = \"delUserById\", notes= \"DELETE_USER_BY_ID_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"id\", value = \"USER_ID\",dataType = \"Int\", example = \"100\")\n+    })\n+    @PostMapping(value = \"/delete\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result delUserById(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                      @RequestParam(value = \"id\") int  id) {\n+        logger.info(\"login user {}, delete user, userId: {},\", loginUser.getUserName(), id);\n+        try {\n+            Map<String, Object> result = usersService.deleteUserById(loginUser, id);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.DELETE_USER_BY_ID_ERROR.getMsg(),e);\n+            return error(Status.DELETE_USER_BY_ID_ERROR.getCode(), Status.DELETE_USER_BY_ID_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * grant project\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @param projectIds project id array\n+     * @return grant result code\n+     */\n+    @ApiOperation(value = \"grantProject\", notes= \"GRANT_PROJECT_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"projectIds\", value = \"PROJECT_IDS\",type = \"String\")\n+    })\n+    @PostMapping(value = \"/grant-project\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result grantProject(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                       @RequestParam(value = \"userId\") int  userId,\n+                                                       @RequestParam(value = \"projectIds\") String projectIds) {\n+        logger.info(\"login user {}, grant project, userId: {},projectIds : {}\", loginUser.getUserName(), userId,projectIds);\n+        try {\n+            Map<String, Object> result = usersService.grantProject(loginUser, userId, projectIds);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GRANT_PROJECT_ERROR.getMsg(),e);\n+            return error(Status.GRANT_PROJECT_ERROR.getCode(), Status.GRANT_PROJECT_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * grant resource\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @param resourceIds resource id array\n+     * @return grant result code\n+     */\n+    @ApiOperation(value = \"grantResource\", notes= \"GRANT_RESOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"resourceIds\", value = \"RESOURCE_IDS\",type = \"String\")\n+    })\n+    @PostMapping(value = \"/grant-file\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result grantResource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                        @RequestParam(value = \"userId\") int  userId,\n+                                                        @RequestParam(value = \"resourceIds\") String resourceIds) {\n+        logger.info(\"login user {}, grant project, userId: {},resourceIds : {}\", loginUser.getUserName(), userId,resourceIds);\n+        try {\n+            Map<String, Object> result = usersService.grantResources(loginUser, userId, resourceIds);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GRANT_RESOURCE_ERROR.getMsg(),e);\n+            return error(Status.GRANT_RESOURCE_ERROR.getCode(), Status.GRANT_RESOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * grant udf function\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @param udfIds udf id array\n+     * @return grant result code\n+     */\n+    @ApiOperation(value = \"grantUDFFunc\", notes= \"GRANT_UDF_FUNC_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"udfIds\", value = \"UDF_IDS\",type = \"String\")\n+    })\n+    @PostMapping(value = \"/grant-udf-func\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result grantUDFFunc(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                       @RequestParam(value = \"userId\") int  userId,\n+                                                       @RequestParam(value = \"udfIds\") String udfIds) {\n+        logger.info(\"login user {}, grant project, userId: {},resourceIds : {}\", loginUser.getUserName(), userId,udfIds);\n+        try {\n+            Map<String, Object> result = usersService.grantUDFFunction(loginUser, userId, udfIds);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GRANT_UDF_FUNCTION_ERROR.getMsg(),e);\n+            return error(Status.GRANT_UDF_FUNCTION_ERROR.getCode(), Status.GRANT_UDF_FUNCTION_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+\n+    /**\n+     * grant datasource\n+     *\n+     * @param loginUser login user\n+     * @param userId user id\n+     * @param datasourceIds  data source id array\n+     * @return grant result code\n+     */\n+    @ApiOperation(value = \"grantDataSource\", notes= \"GRANT_DATASOURCE_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userId\", value = \"USER_ID\",dataType = \"Int\", example = \"100\"),\n+            @ApiImplicitParam(name = \"datasourceIds\", value = \"DATASOURCE_IDS\",type = \"String\")\n+    })\n+    @PostMapping(value = \"/grant-datasource\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result grantDataSource(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                          @RequestParam(value = \"userId\") int  userId,\n+                                                          @RequestParam(value = \"datasourceIds\") String datasourceIds) {\n+        logger.info(\"login user {}, grant project, userId: {},projectIds : {}\", loginUser.getUserName(),userId,datasourceIds);\n+        try {\n+            Map<String, Object> result = usersService.grantDataSource(loginUser, userId, datasourceIds);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GRANT_DATASOURCE_ERROR.getMsg(),e);\n+            return error(Status.GRANT_DATASOURCE_ERROR.getCode(), Status.GRANT_DATASOURCE_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * get user info\n+     *\n+     * @param loginUser login user\n+     * @return user info\n+     */\n+    @ApiOperation(value = \"getUserInfo\", notes= \"GET_USER_INFO_NOTES\")\n+    @GetMapping(value=\"/get-user-info\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result getUserInfo(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        logger.info(\"login user {},get user info : {}\", loginUser.getUserName());\n+        try{\n+            Map<String, Object> result = usersService.getUserInfo(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.GET_USER_INFO_ERROR.getMsg(),e);\n+            return error(Status.GET_USER_INFO_ERROR.getCode(), Status.GET_USER_INFO_ERROR.getMsg());\n+        }\n+    }\n+\n+    /**\n+     * user list no paging\n+     *\n+     * @param loginUser login user\n+     * @return user list\n+     */\n+    @ApiOperation(value = \"listUser\", notes= \"LIST_USER_NOTES\")\n+    @GetMapping(value=\"/list\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result listUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        logger.info(\"login user {}, user list\");\n+        try{\n+            Map<String, Object> result = usersService.queryAllGeneralUsers(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.USER_LIST_ERROR.getMsg(),e);\n+            return error(Status.USER_LIST_ERROR.getCode(), Status.USER_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * user list no paging\n+     *\n+     * @param loginUser login user\n+     * @return user list\n+     */\n+    @GetMapping(value=\"/list-all\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result listAll(@RequestAttribute(value = Constants.SESSION_USER) User loginUser){\n+        logger.info(\"login user {}, user list\");\n+        try{\n+            Map<String, Object> result = usersService.queryUserList(loginUser);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.USER_LIST_ERROR.getMsg(),e);\n+            return error(Status.USER_LIST_ERROR.getCode(), Status.USER_LIST_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * verify username\n+     *\n+     * @param loginUser login user\n+     * @param userName user name\n+     * @return true if user name not exists, otherwise return false\n+     */\n+    @ApiOperation(value = \"verifyUserName\", notes= \"VERIFY_USER_NAME_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"userName\", value = \"USER_NAME\",type = \"String\")\n+    })\n+    @GetMapping(value = \"/verify-user-name\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result verifyUserName(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                                         @RequestParam(value =\"userName\") String userName\n+    ) {\n+        try{\n+\n+            logger.info(\"login user {}, verfiy user name: {}\",\n+                    loginUser.getUserName(),userName);\n+            return usersService.verifyUserName(userName);\n+        }catch (Exception e){\n+            logger.error(Status.VERIFY_USERNAME_ERROR.getMsg(),e);\n+            return error(Status.VERIFY_USERNAME_ERROR.getCode(), Status.VERIFY_USERNAME_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * unauthorized user\n+     *\n+     * @param loginUser login user\n+     * @param alertgroupId alert group id\n+     * @return unauthorize result code\n+     */\n+    @ApiOperation(value = \"unauthorizedUser\", notes= \"UNAUTHORIZED_USER_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"alertgroupId\", value = \"ALERT_GROUP_ID\",type = \"String\")\n+    })\n+    @GetMapping(value = \"/unauth-user\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result unauthorizedUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                   @RequestParam(\"alertgroupId\") Integer alertgroupId) {\n+        try{\n+            logger.info(\"unauthorized user, login user:{}, alert group id:{}\",\n+                    loginUser.getUserName(), alertgroupId);\n+            Map<String, Object> result =  usersService.unauthorizedUser(loginUser, alertgroupId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.UNAUTHORIZED_USER_ERROR.getMsg(),e);\n+            return error(Status.UNAUTHORIZED_USER_ERROR.getCode(), Status.UNAUTHORIZED_USER_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+    /**\n+     * authorized user\n+     *\n+     * @param loginUser login user\n+     * @param alertgroupId alert group id\n+     * @return authorized result code\n+     */\n+    @ApiOperation(value = \"authorizedUser\", notes= \"AUTHORIZED_USER_NOTES\")\n+    @ApiImplicitParams({\n+            @ApiImplicitParam(name = \"alertgroupId\", value = \"ALERT_GROUP_ID\",type = \"String\")\n+    })\n+    @GetMapping(value = \"/authed-user\")\n+    @ResponseStatus(HttpStatus.OK)\n+    public Result authorizedUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\n+                                 @RequestParam(\"alertgroupId\") Integer alertgroupId) {\n+        try{\n+            logger.info(\"authorized user , login user:{}, alert group id:{}\",\n+                    loginUser.getUserName(), alertgroupId);\n+            Map<String, Object> result = usersService.authorizedUser(loginUser, alertgroupId);\n+            return returnDataList(result);\n+        }catch (Exception e){\n+            logger.error(Status.AUTHORIZED_USER_ERROR.getMsg(),e);\n+            return error(Status.AUTHORIZED_USER_ERROR.getCode(), Status.AUTHORIZED_USER_ERROR.getMsg());\n+        }\n+    }\n+\n+\n+}",
                "changes": 460
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java",
                "deletions": 0,
                "sha": "8ec13354420e04839e5684e678f46defbd5c3959",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java"
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/CommandStateCount.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/CommandStateCount.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/CommandStateCount.java",
                "deletions": 0,
                "sha": "3c3c31bfce4ba4b124bbfff6c90977597c45f3dc",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/CommandStateCount.java"
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/DefineUserDto.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/DefineUserDto.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/DefineUserDto.java",
                "deletions": 0,
                "sha": "2f0167d0031e6f87fd13d7341b2bc701009b9175",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/DefineUserDto.java"
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ScheduleParam.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ScheduleParam.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ScheduleParam.java",
                "deletions": 0,
                "sha": "a842960bc2968cad1ccf661c0f4a3b0c2b145cf2",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ScheduleParam.java"
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java",
                "deletions": 0,
                "sha": "e7b182076d9a76ead8e0b4330b78badbad9a0897",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java"
            },
            {
                "status": "added",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskStateCount.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskStateCount.java?ref=1baa1f4279925f4eea8e07caedd6c67ab1284057",
                "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskStateCount.java",
                "deletions": 0,
                "sha": "a2fe348e4000abcad6094be7937722ba68d6249a",
                "changes": 0,
                "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/1baa1f4279925f4eea8e07caedd6c67ab1284057/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskStateCount.java"
            }
        ],
        "unit_tests": [
            "DataAnalysisControllerTest.java",
            "LoggerControllerTest.java",
            "UsersControllerTest.java",
            "JSONUtilsTest.java",
            "SchedulerControllerTest.java",
            "MonitorControllerTest.java",
            "ExecutorControllerTest.java",
            "EnterpriseWeChatUtilsTest.java",
            "LoginControllerTest.java",
            "TaskInstanceControllerTest.java",
            "ProcessInstanceControllerTest.java",
            "ProjectControllerTest.java",
            "PropertyUtilsTest.java",
            "ProcessDefinitionControllerTest.java",
            "QueueControllerTest.java",
            "ResourcesControllerTest.java",
            "TenantControllerTest.java",
            "MailUtilsTest.java",
            "DataSourceControllerTest.java"
        ]
    },
    {
        "buggy": false,
        "test_file": "dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/LoggerControllerTest.java",
        "buggy_files": [
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapMapper.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AccessTokenMapper.xml",
            "dolphinscheduler-server/src/main/resources/master.properties",
            "dockerfile/conf/dolphinscheduler/conf/master.properties",
            "dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties",
            "dockerfile/conf/dolphinscheduler/conf/i18n/messages_en_US.properties",
            "script/config/run_config.conf",
            "dockerfile/conf/dolphinscheduler/conf/config/run_config.conf",
            "dolphinscheduler-server/src/main/resources/worker_logback.xml",
            "dockerfile/conf/dolphinscheduler/conf/worker_logback.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java",
            "dolphinscheduler-common/src/main/resources/quartz.properties",
            "dockerfile/conf/dolphinscheduler/conf/quartz.properties",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/mail_templates/alert_mail_template.ftl",
            "dolphinscheduler-alert/src/main/resources/mail_templates/alert_mail_template.ftl",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/runner/AlertSender.java",
            "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/JSONUtils.java",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/JSONUtils.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserMapper.xml",
            "dolphinscheduler-api/src/main/resources/combined_logback.xml",
            "dockerfile/conf/dolphinscheduler/conf/combined_logback.xml",
            "DISCLAIMER",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/WorkerGroupMapper.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java",
            "dockerfile/conf/zookeeper/zoo.cfg",
            "dockerfile/conf/dolphinscheduler/conf/env/.escheduler_env.sh",
            "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/Constants.java",
            "dolphinscheduler-api/src/main/resources/i18n/messages_zh_CN.properties",
            "dockerfile/conf/dolphinscheduler/conf/i18n/messages_zh_CN.properties",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml",
            "dolphinscheduler-server/src/main/resources/master_logback.xml",
            "dockerfile/conf/dolphinscheduler/conf/master_logback.xml",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/ExcelUtils.java",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/DefineUserDto.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/CombinedApplicationServer.java",
            "dolphinscheduler-common/src/main/resources/zookeeper.properties",
            "dockerfile/conf/dolphinscheduler/conf/zookeeper.properties",
            "README.md",
            "dockerfile/README.md",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java",
            "dolphinscheduler-api/src/main/resources/apiserver_logback.xml",
            "dockerfile/conf/dolphinscheduler/conf/apiserver_logback.xml",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/MailUtils.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceMapper.xml",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/TenantMapper.xml",
            "dolphinscheduler-api/src/main/resources/application-api.properties",
            "dockerfile/conf/dolphinscheduler/conf/application-api.properties",
            "dolphinscheduler-server/src/main/resources/worker.properties",
            "dockerfile/conf/dolphinscheduler/conf/worker.properties",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProjectUserMapper.xml",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UdfFuncMapper.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/QueueController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AppConfiguration.java",
            "dockerfile/hooks/push",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java",
            "dolphinscheduler-api/src/main/resources/i18n/messages.properties",
            "dockerfile/conf/dolphinscheduler/conf/i18n/messages.properties",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/FuncUtils.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/BaseController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/SwaggerConfig.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/CommandStateCount.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml",
            "dolphinscheduler-common/src/main/resources/common/hadoop/hadoop.properties",
            "dockerfile/conf/dolphinscheduler/conf/common/hadoop/hadoop.properties",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/MsgManager.java",
            "dockerfile/startup.sh",
            "CONTRIBUTING.md",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataAnalysisController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRecordController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TenantController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml",
            "NOTICE",
            "dolphinscheduler-dist/release-docs/NOTICE",
            "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/PropertyUtils.java",
            "dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PropertyUtils.java",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/PropertyUtils.java",
            "dolphinscheduler-ui/src/images/favicon.ico",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ErrorCommandMapper.xml",
            "script/config/install_config.conf",
            "dockerfile/conf/dolphinscheduler/conf/config/install_config.conf",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java",
            "script/env/.dolphinscheduler_env.sh",
            "dockerfile/conf/dolphinscheduler/conf/env/.dolphinscheduler_env.sh",
            "dockerfile/Dockerfile",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/AlertMapper.xml",
            ".gitignore",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/ServiceModelToSwagger2MapperImpl.java",
            "dolphinscheduler-ui/build",
            "dockerfile/hooks/build",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UDFUserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/alert_logback.xml",
            "dolphinscheduler-alert/src/main/resources/alert_logback.xml",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ResourcesController.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/SessionMapper.xml",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/QueueMapper.xml",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.xml",
            "README_zh_CN.md",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ScheduleParam.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceMapper.xml",
            "dockerfile/conf/nginx/dolphinscheduler.conf",
            "dolphinscheduler-dao/src/main/resources/application-dao.properties",
            "dockerfile/conf/dolphinscheduler/conf/application-dao.properties",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EnterpriseWeChatManager.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/DataSourceUserMapper.xml",
            "dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/manager/EmailManager.java",
            "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskStateCount.java",
            "ReleaseNotes.md",
            "pom.xml",
            "dolphinscheduler-common/pom.xml",
            "dolphinscheduler-ui/pom.xml",
            "dolphinscheduler-dist/pom.xml",
            "dolphinscheduler-dist/dolphinscheduler-front/pom.xml",
            "dolphinscheduler-dist/dolphinscheduler-backend/pom.xml",
            "dolphinscheduler-dist/dolphinscheduler-src/pom.xml",
            "dolphinscheduler-rpc/pom.xml",
            "dolphinscheduler-dao/pom.xml",
            "dolphinscheduler-server/pom.xml",
            "dolphinscheduler-api/pom.xml",
            "dolphinscheduler-alert/pom.xml",
            "dockerfile/conf/dolphinscheduler/conf/alert.properties",
            "dolphinscheduler-alert/src/main/resources/alert.properties",
            "dolphinscheduler-common/src/main/resources/common/common.properties",
            "dockerfile/conf/dolphinscheduler/conf/common/common.properties",
            "dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml",
            "dockerfile/conf/dolphinscheduler/conf/org/apache/dolphinscheduler/dao/mapper/ResourceUserMapper.xml"
        ],
        "fixed": true
    }
]