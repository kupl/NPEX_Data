[{"commit": "https://github.com/apache/apex-malhar/commit/712027aec6388cb2af7709c63c6c59fa82a94307", "parent": "https://github.com/apache/apex-malhar/commit/d3f7faf58bff06a3c670241542476d1d4a07386f", "message": "APEXMALHAR-2535: change type of timeout variables from int to long\nFix NPE during teardown, when refreshtime is not set\nAllow setting expiration type", "bug_id": "apex-malhar_1", "file": [{"additions": 20, "raw_url": "https://github.com/apache/apex-malhar/raw/712027aec6388cb2af7709c63c6c59fa82a94307/contrib/src/main/java/com/datatorrent/contrib/enrich/AbstractEnricher.java", "blob_url": "https://github.com/apache/apex-malhar/blob/712027aec6388cb2af7709c63c6c59fa82a94307/contrib/src/main/java/com/datatorrent/contrib/enrich/AbstractEnricher.java", "sha": "c377b96260726d1a6d29859ee56afd30422d82e2", "changes": 27, "status": "modified", "deletions": 7, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/contrib/src/main/java/com/datatorrent/contrib/enrich/AbstractEnricher.java?ref=712027aec6388cb2af7709c63c6c59fa82a94307", "patch": "@@ -25,11 +25,13 @@\n import org.apache.hadoop.classification.InterfaceStability;\n \n import com.esotericsoftware.kryo.NotNull;\n+\n import com.datatorrent.api.Context;\n import com.datatorrent.api.Operator;\n import com.datatorrent.common.util.BaseOperator;\n import com.datatorrent.lib.db.cache.CacheManager;\n import com.datatorrent.lib.db.cache.CacheStore;\n+import com.datatorrent.lib.db.cache.CacheStore.ExpiryType;\n import com.datatorrent.lib.util.FieldInfo;\n import com.datatorrent.lib.util.FieldInfo.SupportType;\n \n@@ -66,8 +68,9 @@\n   /**\n    * Optional parameters for enricher.\n    */\n-  private int cacheExpirationInterval = 1 * 60 * 60 * 1000;  // 1 hour\n-  private int cacheCleanupInterval = 1 * 60 * 60 * 1000; // 1 hour\n+  private long cacheExpirationInterval = 1 * 60 * 60 * 1000;  // 1 hour\n+  private long cacheCleanupInterval = 1 * 60 * 60 * 1000; // 1 hour\n+  private ExpiryType expiryType = ExpiryType.EXPIRE_AFTER_WRITE;\n   private int cacheSize = 1024; // 1024 records\n \n   /**\n@@ -160,7 +163,7 @@ public void setup(Context.OperatorContext context)\n     // set expiration to one day.\n     primaryCache.setEntryExpiryDurationInMillis(cacheExpirationInterval);\n     primaryCache.setCacheCleanupInMillis(cacheCleanupInterval);\n-    primaryCache.setEntryExpiryStrategy(CacheStore.ExpiryType.EXPIRE_AFTER_WRITE);\n+    primaryCache.setEntryExpiryStrategy(expiryType);\n     primaryCache.setMaxCacheSize(cacheSize);\n \n     cacheManager.setPrimary(primaryCache);\n@@ -268,7 +271,7 @@ public void setStore(BackendLoader store)\n    *\n    * @return Cache entry expiration interval in ms\n    */\n-  public int getCacheExpirationInterval()\n+  public long getCacheExpirationInterval()\n   {\n     return cacheExpirationInterval;\n   }\n@@ -279,7 +282,7 @@ public int getCacheExpirationInterval()\n    *\n    * @param cacheExpirationInterval Cache entry expiration interval in ms\n    */\n-  public void setCacheExpirationInterval(int cacheExpirationInterval)\n+  public void setCacheExpirationInterval(long cacheExpirationInterval)\n   {\n     this.cacheExpirationInterval = cacheExpirationInterval;\n   }\n@@ -290,7 +293,7 @@ public void setCacheExpirationInterval(int cacheExpirationInterval)\n    *\n    * @return cache cleanup interval in ms.\n    */\n-  public int getCacheCleanupInterval()\n+  public long getCacheCleanupInterval()\n   {\n     return cacheCleanupInterval;\n   }\n@@ -301,7 +304,7 @@ public int getCacheCleanupInterval()\n    *\n    * @param cacheCleanupInterval cache cleanup interval in ms.\n    */\n-  public void setCacheCleanupInterval(int cacheCleanupInterval)\n+  public void setCacheCleanupInterval(long cacheCleanupInterval)\n   {\n     this.cacheCleanupInterval = cacheCleanupInterval;\n   }\n@@ -326,6 +329,16 @@ public void setCacheSize(int cacheSize)\n     this.cacheSize = cacheSize;\n   }\n \n+  public ExpiryType getExpiryType()\n+  {\n+    return expiryType;\n+  }\n+\n+  public void setExpiryType(ExpiryType expiryType)\n+  {\n+    this.expiryType = expiryType;\n+  }\n+\n   public CacheManager getCacheManager()\n   {\n     return cacheManager;", "filename": "contrib/src/main/java/com/datatorrent/contrib/enrich/AbstractEnricher.java"}, {"additions": 4, "raw_url": "https://github.com/apache/apex-malhar/raw/712027aec6388cb2af7709c63c6c59fa82a94307/library/src/main/java/com/datatorrent/lib/db/cache/CacheStore.java", "blob_url": "https://github.com/apache/apex-malhar/blob/712027aec6388cb2af7709c63c6c59fa82a94307/library/src/main/java/com/datatorrent/lib/db/cache/CacheStore.java", "sha": "c073affc4a1fd2b82bcd174e1fb6b57aa6ade1d8", "changes": 8, "status": "modified", "deletions": 4, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/db/cache/CacheStore.java?ref=712027aec6388cb2af7709c63c6c59fa82a94307", "patch": "@@ -58,10 +58,10 @@\n   protected long maxCacheSize = 2000;\n \n   @Min(0)\n-  protected int entryExpiryDurationInMillis = 60000; //1 minute\n+  protected long entryExpiryDurationInMillis = 60000; //1 minute\n \n   @Min(0)\n-  protected int cacheCleanupIntervalInMillis = 60500; //.5 seconds after entries are expired\n+  protected long cacheCleanupIntervalInMillis = 60500; //.5 seconds after entries are expired\n \n   @NotNull\n   protected ExpiryType entryExpiryStrategy = ExpiryType.EXPIRE_AFTER_ACCESS;\n@@ -190,7 +190,7 @@ public void setEntryExpiryStrategy(ExpiryType expiryType)\n    *\n    * @param durationInMillis the duration after which a cache entry is expired.\n    */\n-  public void setEntryExpiryDurationInMillis(int durationInMillis)\n+  public void setEntryExpiryDurationInMillis(long durationInMillis)\n   {\n     this.entryExpiryDurationInMillis = durationInMillis;\n   }\n@@ -200,7 +200,7 @@ public void setEntryExpiryDurationInMillis(int durationInMillis)\n    *\n    * @param durationInMillis the duration after which cache is cleaned up regularly.\n    */\n-  public void setCacheCleanupInMillis(int durationInMillis)\n+  public void setCacheCleanupInMillis(long durationInMillis)\n   {\n     this.cacheCleanupIntervalInMillis = durationInMillis;\n   }", "filename": "library/src/main/java/com/datatorrent/lib/db/cache/CacheStore.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6", "parent": "https://github.com/apache/apex-malhar/commit/0a87bc0a526e7355bc2764c83f6c9ed092b6f228", "message": "Merge branch 'APEXMALHAR-2136-NPE-RecoverWindows'", "bug_id": "apex-malhar_2", "file": [{"additions": 27, "raw_url": "https://github.com/apache/apex-malhar/raw/7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6/library/src/main/java/org/apache/apex/malhar/lib/state/managed/AbstractManagedStateImpl.java", "blob_url": "https://github.com/apache/apex-malhar/blob/7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6/library/src/main/java/org/apache/apex/malhar/lib/state/managed/AbstractManagedStateImpl.java", "sha": "b5b9f8ccc017b335563d34463791e3fb304b5214", "changes": 42, "status": "modified", "deletions": 15, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/org/apache/apex/malhar/lib/state/managed/AbstractManagedStateImpl.java?ref=7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6", "patch": "@@ -144,7 +144,7 @@\n   protected transient ExecutorService readerService;\n \n   @NotNull\n-  protected IncrementalCheckpointManager checkpointManager = new IncrementalCheckpointManager();\n+  private IncrementalCheckpointManager checkpointManager = new IncrementalCheckpointManager();\n \n   @NotNull\n   protected BucketsFileSystem bucketsFileSystem = new BucketsFileSystem();\n@@ -203,22 +203,24 @@ public void setup(OperatorContext context)\n       //delete all the wal files with windows > activationWindow.\n       //All the wal files with windows <= activationWindow are loaded and kept separately as recovered data.\n       try {\n-        for (long recoveredWindow : checkpointManager.getWindowIds(operatorContext.getId())) {\n-          if (recoveredWindow <= activationWindow) {\n-            @SuppressWarnings(\"unchecked\")\n-            Map<Long, Map<Slice, Bucket.BucketedValue>> recoveredData = (Map<Long, Map<Slice, Bucket.BucketedValue>>)\n-                checkpointManager.load(operatorContext.getId(), recoveredWindow);\n-            if (recoveredData != null && !recoveredData.isEmpty()) {\n-              for (Map.Entry<Long, Map<Slice, Bucket.BucketedValue>> entry : recoveredData.entrySet()) {\n-                int bucketIdx = prepareBucket(entry.getKey());\n-                buckets[bucketIdx].recoveredData(recoveredWindow, entry.getValue());\n+        long[] recoveredWindows = checkpointManager.getWindowIds(operatorContext.getId());\n+        if (recoveredWindows != null) {\n+          for (long recoveredWindow : recoveredWindows) {\n+            if (recoveredWindow <= activationWindow) {\n+              @SuppressWarnings(\"unchecked\")\n+              Map<Long, Map<Slice, Bucket.BucketedValue>> recoveredData = (Map<Long, Map<Slice, Bucket.BucketedValue>>)\n+                  checkpointManager.load(operatorContext.getId(), recoveredWindow);\n+              if (recoveredData != null && !recoveredData.isEmpty()) {\n+                for (Map.Entry<Long, Map<Slice, Bucket.BucketedValue>> entry : recoveredData.entrySet()) {\n+                  int bucketIdx = prepareBucket(entry.getKey());\n+                  buckets[bucketIdx].recoveredData(recoveredWindow, entry.getValue());\n+                }\n               }\n+              checkpointManager.save(recoveredData, operatorContext.getId(), recoveredWindow,\n+                  true /*skipWritingToWindowFile*/);\n+            } else {\n+              checkpointManager.delete(operatorContext.getId(), recoveredWindow);\n             }\n-            checkpointManager.save(recoveredData, operatorContext.getId(), recoveredWindow,\n-                true /*skipWritingToWindowFile*/);\n-\n-          } else {\n-            checkpointManager.delete(operatorContext.getId(), recoveredWindow);\n           }\n         }\n       } catch (IOException e) {\n@@ -536,6 +538,16 @@ public void setDurationPreventingFreeingSpace(Duration durationPreventingFreeing\n     this.durationPreventingFreeingSpace = durationPreventingFreeingSpace;\n   }\n \n+  public IncrementalCheckpointManager getCheckpointManager()\n+  {\n+    return checkpointManager;\n+  }\n+\n+  public void setCheckpointManager(@NotNull IncrementalCheckpointManager checkpointManager)\n+  {\n+    this.checkpointManager = Preconditions.checkNotNull(checkpointManager);\n+  }\n+\n   static class ValueFetchTask implements Callable<Slice>\n   {\n     private final Bucket bucket;", "filename": "library/src/main/java/org/apache/apex/malhar/lib/state/managed/AbstractManagedStateImpl.java"}, {"additions": 1, "raw_url": "https://github.com/apache/apex-malhar/raw/7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6/library/src/main/java/org/apache/apex/malhar/lib/state/managed/StateTracker.java", "blob_url": "https://github.com/apache/apex-malhar/blob/7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6/library/src/main/java/org/apache/apex/malhar/lib/state/managed/StateTracker.java", "sha": "56781074a925e76bccf871a4f0ec0e6ebec9092a", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/org/apache/apex/malhar/lib/state/managed/StateTracker.java?ref=7b019fa1ba2cac60565c5ee0d9ebdcf396cd93b6", "patch": "@@ -122,7 +122,7 @@ public void run()\n             synchronized (bucket) {\n               long sizeFreed;\n               try {\n-                sizeFreed = bucket.freeMemory(managedStateImpl.checkpointManager.getLastTransferredWindow());\n+                sizeFreed = bucket.freeMemory(managedStateImpl.getCheckpointManager().getLastTransferredWindow());\n                 LOG.debug(\"bucket freed {} {}\", bucketId, sizeFreed);\n               } catch (IOException e) {\n                 managedStateImpl.throwable.set(e);", "filename": "library/src/main/java/org/apache/apex/malhar/lib/state/managed/StateTracker.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/ed25960e142872827da06f2756bcf6d2adae3a4d", "parent": "https://github.com/apache/apex-malhar/commit/212a8af39175099d8ee4035121e9ca9b95cf3d52", "message": "Fix NPE", "bug_id": "apex-malhar_3", "file": [{"additions": 4, "raw_url": "https://github.com/apache/apex-malhar/raw/ed25960e142872827da06f2756bcf6d2adae3a4d/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java", "blob_url": "https://github.com/apache/apex-malhar/blob/ed25960e142872827da06f2756bcf6d2adae3a4d/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java", "sha": "75e206f5b0c23d36382f8374f61ec9742af6581f", "changes": 5, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java?ref=ed25960e142872827da06f2756bcf6d2adae3a4d", "patch": "@@ -318,8 +318,11 @@ public DATA getDataPoint(Map<String, ?> keys)\n           columnIndex < tempKeys.size();\n           columnIndex++) {\n         Object key = tempKeys.get(columnIndex);\n+        Object keyColumn = keyColumns.get(columnIndex).get(rowIndex);\n \n-        if(!keyColumns.get(columnIndex).get(rowIndex).equals(key)) {\n+        if((key == null && keyColumn != null) ||\n+           (key != null && keyColumn == null) ||\n+           (key != null && keyColumn != null && !keyColumn.equals(key))) {\n           allEqual = false;\n           break;\n         }", "filename": "library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/289dad7426ade1779733cead614d52946154211f", "parent": "https://github.com/apache/apex-malhar/commit/d23e283453a37e8f2385f6ca9bf46683ecf926e6", "message": "APEXMALHAR-2003 NPE in blockMetaDataIterator after recovery", "bug_id": "apex-malhar_4", "file": [{"additions": 3, "raw_url": "https://github.com/apache/apex-malhar/raw/289dad7426ade1779733cead614d52946154211f/library/src/main/java/com/datatorrent/lib/io/fs/AbstractFileSplitter.java", "blob_url": "https://github.com/apache/apex-malhar/blob/289dad7426ade1779733cead614d52946154211f/library/src/main/java/com/datatorrent/lib/io/fs/AbstractFileSplitter.java", "sha": "cd47d480b54bce43380e0622134afd8db6aaefd4", "changes": 6, "status": "modified", "deletions": 3, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/io/fs/AbstractFileSplitter.java?ref=289dad7426ade1779733cead614d52946154211f", "patch": "@@ -285,7 +285,7 @@ public int getBlocksThreshold()\n     private long pos;\n     private int blockNumber;\n \n-    private final transient AbstractFileSplitter splitter;\n+    private final AbstractFileSplitter splitter;\n \n     protected BlockMetadataIterator()\n     {\n@@ -319,8 +319,8 @@ public boolean hasNext()\n       }\n       boolean isLast = length >= fileMetadata.getFileLength();\n       long lengthOfFileInBlock = isLast ? fileMetadata.getFileLength() : length;\n-      BlockMetadata.FileBlockMetadata fileBlock = splitter\n-          .buildBlockMetadata(pos, lengthOfFileInBlock, blockNumber, fileMetadata, isLast);\n+      BlockMetadata.FileBlockMetadata fileBlock = splitter.buildBlockMetadata(pos, lengthOfFileInBlock, blockNumber,\n+          fileMetadata, isLast);\n       pos = lengthOfFileInBlock;\n       return fileBlock;\n     }", "filename": "library/src/main/java/com/datatorrent/lib/io/fs/AbstractFileSplitter.java"}, {"additions": 44, "raw_url": "https://github.com/apache/apex-malhar/raw/289dad7426ade1779733cead614d52946154211f/library/src/test/java/com/datatorrent/lib/io/fs/FileSplitterInputTest.java", "blob_url": "https://github.com/apache/apex-malhar/blob/289dad7426ade1779733cead614d52946154211f/library/src/test/java/com/datatorrent/lib/io/fs/FileSplitterInputTest.java", "sha": "cd0de2de87a11850dec3f6237eb9f113bbe24c06", "changes": 44, "status": "modified", "deletions": 0, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/test/java/com/datatorrent/lib/io/fs/FileSplitterInputTest.java?ref=289dad7426ade1779733cead614d52946154211f", "patch": "@@ -51,6 +51,7 @@\n import com.datatorrent.lib.io.IdempotentStorageManager;\n import com.datatorrent.lib.io.block.BlockMetadata;\n import com.datatorrent.lib.testbench.CollectorTestSink;\n+import com.datatorrent.lib.util.KryoCloneUtils;\n import com.datatorrent.lib.util.TestUtils;\n \n /**\n@@ -455,6 +456,49 @@ public void testSingleFile() throws InterruptedException, IOException\n         testMeta.fileMetadataSink.collectedTuples.get(0).getFilePath());\n   }\n \n+  @Test\n+  public void testRecoveryOfBlockMetadataIterator() throws InterruptedException\n+  {\n+    IdempotentStorageManager.FSIdempotentStorageManager fsIdempotentStorageManager =\n+        new IdempotentStorageManager.FSIdempotentStorageManager();\n+\n+    testMeta.fileSplitterInput.setIdempotentStorageManager(fsIdempotentStorageManager);\n+    testMeta.fileSplitterInput.setBlockSize(2L);\n+    testMeta.fileSplitterInput.setBlocksThreshold(2);\n+    testMeta.fileSplitterInput.getScanner().setScanIntervalMillis(500);\n+\n+\n+    testMeta.fileSplitterInput.setup(testMeta.context);\n+\n+    testMeta.fileSplitterInput.beginWindow(1);\n+\n+    ((MockScanner)testMeta.fileSplitterInput.getScanner()).semaphore.acquire();\n+    testMeta.fileSplitterInput.emitTuples();\n+    testMeta.fileSplitterInput.endWindow();\n+\n+    //file0.txt has just 5 blocks. Since blocks threshold is 2, only 2 are emitted.\n+    Assert.assertEquals(\"Files\", 1, testMeta.fileMetadataSink.collectedTuples.size());\n+    Assert.assertEquals(\"Blocks\", 2, testMeta.blockMetadataSink.collectedTuples.size());\n+\n+    testMeta.fileMetadataSink.clear();\n+    testMeta.blockMetadataSink.clear();\n+\n+    //At this point the operator was check-pointed and then there was a failure.\n+    testMeta.fileSplitterInput.teardown();\n+\n+    //The operator was restored from persisted state and re-deployed.\n+    testMeta.fileSplitterInput = KryoCloneUtils.cloneObject(testMeta.fileSplitterInput);\n+    TestUtils.setSink(testMeta.fileSplitterInput.blocksMetadataOutput, testMeta.blockMetadataSink);\n+    TestUtils.setSink(testMeta.fileSplitterInput.filesMetadataOutput, testMeta.fileMetadataSink);\n+\n+    testMeta.fileSplitterInput.setup(testMeta.context);\n+    testMeta.fileSplitterInput.beginWindow(1);\n+\n+    Assert.assertEquals(\"Recovered Files\", 1, testMeta.fileMetadataSink.collectedTuples.size());\n+    Assert.assertEquals(\"Recovered Blocks\", 2, testMeta.blockMetadataSink.collectedTuples.size());\n+  }\n+\n+\n   private static class MockScanner extends FileSplitterInput.TimeBasedDirectoryScanner\n   {\n     transient Semaphore semaphore;", "filename": "library/src/test/java/com/datatorrent/lib/io/fs/FileSplitterInputTest.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/5afe2414dbbc15b8a60c9b27a0eccfdd42ec6e36", "parent": "https://github.com/apache/apex-malhar/commit/6b2db4de9285fe926e6ef4ae5d3a701691a9db0f", "message": "NPE while closing streams", "bug_id": "apex-malhar_5", "file": [{"additions": 8, "raw_url": "https://github.com/apache/apex-malhar/raw/5afe2414dbbc15b8a60c9b27a0eccfdd42ec6e36/library/src/main/java/com/datatorrent/lib/bucket/HdfsBucketStore.java", "blob_url": "https://github.com/apache/apex-malhar/blob/5afe2414dbbc15b8a60c9b27a0eccfdd42ec6e36/library/src/main/java/com/datatorrent/lib/bucket/HdfsBucketStore.java", "sha": "73a852d3be269d16d303492679dc7fd433816121", "changes": 17, "status": "modified", "deletions": 9, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/bucket/HdfsBucketStore.java?ref=5afe2414dbbc15b8a60c9b27a0eccfdd42ec6e36", "patch": "@@ -370,23 +370,20 @@ public int hashCode()\n     }\n \n     @Override\n-    public Map<Object, T> call() throws Exception\n+    public Map<Object, T> call() throws IOException\n     {\n       Kryo readSerde = new Kryo();\n       readSerde.setClassLoader(classLoader);\n \n       Map<Object, T> bucketDataPerWindow = Maps.newHashMap();\n-      Input input = null;\n-      FSDataInputStream stream = null;\n       FileSystem fs = null;\n       try {\n-        long startTime = System.currentTimeMillis();\n         //Read data only for the fileIds in which bucketIdx had events.\n         Path dataFile = new Path(bucketRoot + PATH_SEPARATOR + window);\n         fs = FileSystem.newInstance(dataFile.toUri(), configuration);\n-        stream = fs.open(dataFile);\n+        FSDataInputStream stream = fs.open(dataFile);\n         stream.seek(bucketPositions[bucketIdx].get(window));\n-        input = new Input(stream);\n+        Input input = new Input(stream);\n \n         int length = stream.readInt();\n \n@@ -411,14 +408,16 @@ else if (keyPasses) {\n             bucketDataPerWindow.put(key, null);\n           }\n         }\n+        input.close();\n+        stream.close();\n       }\n       catch (IOException e) {\n         throw new RuntimeException(e);\n       }\n       finally {\n-        input.close();\n-        stream.close();\n-        fs.close();\n+        if (fs != null) {\n+          fs.close();\n+        }\n       }\n       return bucketDataPerWindow;\n     }", "filename": "library/src/main/java/com/datatorrent/lib/bucket/HdfsBucketStore.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/ebfffd6f03e665aff3a56ae46328019b7387411e", "parent": "https://github.com/apache/apex-malhar/commit/5d7b399473f77cd52cd898f3ad9bd338ff5aa94c", "message": "Fixed an NPE", "bug_id": "apex-malhar_6", "file": [{"additions": 4, "raw_url": "https://github.com/apache/apex-malhar/raw/ebfffd6f03e665aff3a56ae46328019b7387411e/library/src/main/java/com/malhartech/lib/testbench/SeedEventGenerator.java", "blob_url": "https://github.com/apache/apex-malhar/blob/ebfffd6f03e665aff3a56ae46328019b7387411e/library/src/main/java/com/malhartech/lib/testbench/SeedEventGenerator.java", "sha": "6212e7dd01b19293dceefe12d4eed1a467c083e8", "changes": 6, "status": "modified", "deletions": 2, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/malhartech/lib/testbench/SeedEventGenerator.java?ref=ebfffd6f03e665aff3a56ae46328019b7387411e", "patch": "@@ -113,16 +113,18 @@ public void emitTuples()\n    */\n   public void emitTuple(int i)\n   {\n-    HashMap<String, String> stuple = null;\n-    HashMap<String, ArrayList<OneKeyValPair>> atuple = null;\n+    HashMap<String, String> stuple;\n+    HashMap<String, ArrayList<OneKeyValPair>> atuple;\n     String key = Integer.toString(i);\n \n     if (keys == null) {\n       if (string_data.isConnected()) {\n+        stuple = new HashMap<String, String>(1);\n         stuple.put(key, null);\n         string_data.emit(stuple);\n       }\n       if (keyvalpair_list.isConnected()) {\n+        atuple = new HashMap<String, ArrayList<OneKeyValPair>>(1);\n         atuple.put(key, null);\n         keyvalpair_list.emit(atuple);\n       }", "filename": "library/src/main/java/com/malhartech/lib/testbench/SeedEventGenerator.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/de430a95f614696a0c00746d6a721f4b3b9b34eb", "parent": "https://github.com/apache/apex-malhar/commit/16922f245414e4fb709a14312dee17f8aa93a7a6", "message": "Merge pull request #1480 from ilooner/MLHR-1763\n\nFix NPE", "bug_id": "apex-malhar_7", "file": [{"additions": 4, "raw_url": "https://github.com/apache/apex-malhar/raw/de430a95f614696a0c00746d6a721f4b3b9b34eb/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java", "blob_url": "https://github.com/apache/apex-malhar/blob/de430a95f614696a0c00746d6a721f4b3b9b34eb/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java", "sha": "75e206f5b0c23d36382f8374f61ec9742af6581f", "changes": 5, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java?ref=de430a95f614696a0c00746d6a721f4b3b9b34eb", "patch": "@@ -318,8 +318,11 @@ public DATA getDataPoint(Map<String, ?> keys)\n           columnIndex < tempKeys.size();\n           columnIndex++) {\n         Object key = tempKeys.get(columnIndex);\n+        Object keyColumn = keyColumns.get(columnIndex).get(rowIndex);\n \n-        if(!keyColumns.get(columnIndex).get(rowIndex).equals(key)) {\n+        if((key == null && keyColumn != null) ||\n+           (key != null && keyColumn == null) ||\n+           (key != null && keyColumn != null && !keyColumn.equals(key))) {\n           allEqual = false;\n           break;\n         }", "filename": "library/src/main/java/com/datatorrent/lib/appdata/datastructs/DimensionalTable.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/cedfa0f3fae96af73b1ec237d31d1327ace9d03f", "parent": "https://github.com/apache/apex-malhar/commit/20edbd2b95ab5f3227a97d7b638e6b4426d979ed", "message": "Fix NPE in monitor thread when kafka cluster becomes unavailable.", "bug_id": "apex-malhar_8", "file": [{"additions": 110, "raw_url": "https://github.com/apache/apex-malhar/raw/cedfa0f3fae96af73b1ec237d31d1327ace9d03f/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java", "blob_url": "https://github.com/apache/apex-malhar/blob/cedfa0f3fae96af73b1ec237d31d1327ace9d03f/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java", "sha": "720d7a14a8bd9473e510e18c310e15649ee13ea3", "changes": 175, "status": "modified", "deletions": 65, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java?ref=cedfa0f3fae96af73b1ec237d31d1327ace9d03f", "patch": "@@ -30,6 +30,7 @@\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n \n import javax.validation.constraints.NotNull;\n \n@@ -299,9 +300,14 @@ public SimpleKafkaConsumer(SetMultimap<String, String> zks, String topic, int ti\n    */\n   private final ConcurrentHashMap<KafkaPartition, Long> offsetTrack = new ConcurrentHashMap<KafkaPartition, Long>();\n \n+  private transient AtomicReference<Throwable> monitorException;\n+  private transient AtomicInteger monitorExceptionCount;\n+\n   @Override\n   public void start()\n   {\n+    monitorException = new AtomicReference<Throwable>(null);\n+    monitorExceptionCount = new AtomicInteger(0);\n     super.start();\n \n     // thread to consume the kafka data\n@@ -315,71 +321,7 @@ public void start()\n     metadataRefreshExecutor = Executors.newScheduledThreadPool(1, new ThreadFactoryBuilder().setNameFormat(\"kafka-consumer-monitor-\" + topic + \"-%d\").setDaemon(true).build());\n \n     // start one monitor thread to monitor the leader broker change and trigger some action\n-    final SimpleKafkaConsumer ref = this;\n-    metadataRefreshExecutor.scheduleAtFixedRate(new Runnable() {\n-\n-      private transient final SetMultimap<Broker, KafkaPartition> deltaPositive = HashMultimap.create();\n-\n-      @Override\n-      public void run()\n-      {\n-        if (isAlive && (metadataRefreshRetryLimit == -1 || retryCounter.get() < metadataRefreshRetryLimit)) {\n-          logger.debug(\"{}: Update metadata for topic {}\", Thread.currentThread().getName(), topic);\n-          Map<String, List<PartitionMetadata>> pms = KafkaMetadataUtil.getPartitionsForTopic(brokers, topic);\n-          if (pms == null) {\n-            // retrieve metadata fail add retry count and return\n-            retryCounter.getAndAdd(1);\n-            return;\n-          }\n-\n-          for (Entry<String, List<PartitionMetadata>> pmLEntry : pms.entrySet()) {\n-            for (PartitionMetadata pm : pmLEntry.getValue()) {\n-              KafkaPartition kp = new KafkaPartition(pmLEntry.getKey(), topic, pm.partitionId());\n-              if (!kps.contains(kp)) {\n-                // Out of this consumer's scope\n-                continue;\n-              }\n-              Broker b = pm.leader();\n-              Broker oldB = partitionToBroker.put(kp, b);\n-              if(b.equals(oldB)) {\n-                continue;\n-              }\n-              // add to positive\n-              deltaPositive.put(b,kp);\n-\n-              // always update the latest connection information\n-              stats.updatePartitionStats(kp, pm.leader().id(), pm.leader().host() + \":\" + pm.leader().port());\n-            }\n-          }\n-\n-          // remove from map if the thread is done (partitions on this broker has all been reassigned to others(or temporarily not available) for\n-          // example)\n-          for (Iterator<Entry<Broker, ConsumerThread>> iterator = simpleConsumerThreads.entrySet().iterator(); iterator.hasNext();) {\n-            Entry<Broker, ConsumerThread> item = iterator.next();\n-            if (item.getValue().getThreadItSelf().isDone()) {\n-              iterator.remove();\n-            }\n-          }\n-\n-          for (Broker b : deltaPositive.keySet()) {\n-            if (!simpleConsumerThreads.containsKey(b)) {\n-              // start thread for new broker\n-              ConsumerThread ct = new ConsumerThread(b, deltaPositive.get(b), ref);\n-              ct.setThreadItSelf(kafkaConsumerExecutor.submit(ct));\n-              simpleConsumerThreads.put(b, ct);\n-\n-            } else {\n-              simpleConsumerThreads.get(b).addPartitions(deltaPositive.get(b));\n-            }\n-          }\n-\n-          deltaPositive.clear();\n-\n-          // reset to 0 if it reconnect to the broker which has current broker metadata\n-          retryCounter.set(0);\n-        }\n-      }\n-    }, 0, metadataRefreshInterval, TimeUnit.MILLISECONDS);\n+    metadataRefreshExecutor.scheduleAtFixedRate(new MetaDataMonitorTask(this) , 0, metadataRefreshInterval, TimeUnit.MILLISECONDS);\n   }\n \n   @Override\n@@ -491,4 +433,107 @@ protected void resetPartitionsAndOffset(Set<KafkaPartition> partitionIds, Map<Ka\n     this.kps = partitionIds;\n     resetOffset(startOffset);\n   }\n+\n+  protected Throwable getMonitorException()\n+  {\n+    return monitorException.get();\n+  }\n+\n+  protected int getMonitorExceptionCount()\n+  {\n+    return monitorExceptionCount.get();\n+  }\n+\n+  /**\n+   * Task to monitor metadata periodically. This task will detect changes in broker for partition\n+   * and restart failed consumer threads for the partitions.\n+   * Monitoring is disabled after metadataRefreshRetryLimit number of failure.\n+   */\n+  private class MetaDataMonitorTask implements Runnable {\n+\n+    private final SimpleKafkaConsumer ref;\n+\n+    private transient final SetMultimap<Broker, KafkaPartition> deltaPositive = HashMultimap.create();\n+\n+    private MetaDataMonitorTask(SimpleKafkaConsumer ref) {\n+      this.ref = ref;\n+    }\n+\n+    @Override public void run() {\n+      try {\n+        monitorMetadata();\n+        monitorException.set(null);\n+        monitorExceptionCount.set(0);\n+      } catch (Throwable ex) {\n+        logger.error(\"Exception {}\", ex);\n+        monitorException.set(ex);\n+        monitorExceptionCount.incrementAndGet();\n+      }\n+    }\n+\n+    /**\n+     * Monitor kafka topic metadata changes.\n+     */\n+    private void monitorMetadata()\n+    {\n+      if (isAlive && (metadataRefreshRetryLimit == -1 || retryCounter.get() < metadataRefreshRetryLimit)) {\n+        logger.debug(\"{}: Update metadata for topic {}\", Thread.currentThread().getName(), topic);\n+        Map<String, List<PartitionMetadata>> pms = KafkaMetadataUtil.getPartitionsForTopic(brokers, topic);\n+        if (pms == null) {\n+          // retrieve metadata fail add retry count and return\n+          retryCounter.getAndAdd(1);\n+          return;\n+        }\n+\n+        for (Entry<String, List<PartitionMetadata>> pmLEntry : pms.entrySet()) {\n+          if (pmLEntry.getValue() == null)\n+            continue;\n+          for (PartitionMetadata pm : pmLEntry.getValue()) {\n+            KafkaPartition kp = new KafkaPartition(pmLEntry.getKey(), topic, pm.partitionId());\n+            if (!kps.contains(kp)) {\n+              // Out of this consumer's scope\n+              continue;\n+            }\n+            Broker b = pm.leader();\n+            Broker oldB = partitionToBroker.put(kp, b);\n+            if (b.equals(oldB)) {\n+              continue;\n+            }\n+            // add to positive\n+            deltaPositive.put(b, kp);\n+\n+            // always update the latest connection information\n+            stats.updatePartitionStats(kp, pm.leader().id(), pm.leader().host() + \":\" + pm.leader().port());\n+          }\n+        }\n+\n+        // remove from map if the thread is done (partitions on this broker has all been reassigned to others(or temporarily not available) for\n+        // example)\n+        for (Iterator<Entry<Broker, ConsumerThread>> iterator = simpleConsumerThreads.entrySet().iterator(); iterator.hasNext(); ) {\n+          Entry<Broker, ConsumerThread> item = iterator.next();\n+          if (item.getValue().getThreadItSelf().isDone()) {\n+            iterator.remove();\n+          }\n+        }\n+\n+        for (Broker b : deltaPositive.keySet()) {\n+          if (!simpleConsumerThreads.containsKey(b)) {\n+            // start thread for new broker\n+            ConsumerThread ct = new ConsumerThread(b, deltaPositive.get(b), ref);\n+            ct.setThreadItSelf(kafkaConsumerExecutor.submit(ct));\n+            simpleConsumerThreads.put(b, ct);\n+\n+          } else {\n+            simpleConsumerThreads.get(b).addPartitions(deltaPositive.get(b));\n+          }\n+        }\n+\n+        deltaPositive.clear();\n+\n+        // reset to 0 if it reconnect to the broker which has current broker metadata\n+        retryCounter.set(0);\n+      }\n+    }\n+\n+  }\n } // End of SimpleKafkaConsumer", "filename": "contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/208ad9d933f8395177099fec473dc57e9ba32b26", "parent": "https://github.com/apache/apex-malhar/commit/10519bb6890862e639fd0c124e599660b92a1bc6", "message": "fixed the NPE in BlockReader which happens after recovery", "bug_id": "apex-malhar_9", "file": [{"additions": 1, "raw_url": "https://github.com/apache/apex-malhar/raw/208ad9d933f8395177099fec473dc57e9ba32b26/library/src/main/java/com/datatorrent/lib/io/block/AbstractBlockReader.java", "blob_url": "https://github.com/apache/apex-malhar/blob/208ad9d933f8395177099fec473dc57e9ba32b26/library/src/main/java/com/datatorrent/lib/io/block/AbstractBlockReader.java", "sha": "14b8b19b08b413668910db7f8de3e1aeb7f5b289", "changes": 2, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/io/block/AbstractBlockReader.java?ref=208ad9d933f8395177099fec473dc57e9ba32b26", "patch": "@@ -226,7 +226,7 @@ public void endWindow()\n   protected void processBlockMetadata(B block) throws IOException\n   {\n     long blockStartTime = System.currentTimeMillis();\n-    if (block.getPreviousBlockId() == -1 || block.getPreviousBlockId() != lastProcessedBlock.getBlockId()) {\n+    if (block.getPreviousBlockId() == -1 || lastProcessedBlock == null || block.getPreviousBlockId() != lastProcessedBlock.getBlockId()) {\n       teardownStream(lastProcessedBlock);\n       consecutiveBlock = false;\n       lastBlockOpenTime = System.currentTimeMillis();", "filename": "library/src/main/java/com/datatorrent/lib/io/block/AbstractBlockReader.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/36e8ae3db68f5d3ffab2bca0664e85c25ddbd022", "parent": "https://github.com/apache/apex-malhar/commit/ee92fc99176155590382a7855b628a861a898c42", "message": "MLHR-1820 Fix NPE if an embeddable query info provider is not set on the snapshot server.", "bug_id": "apex-malhar_10", "file": [{"additions": 3, "raw_url": "https://github.com/apache/apex-malhar/raw/36e8ae3db68f5d3ffab2bca0664e85c25ddbd022/library/src/main/java/com/datatorrent/lib/appdata/snapshot/AbstractAppDataSnapshotServer.java", "blob_url": "https://github.com/apache/apex-malhar/blob/36e8ae3db68f5d3ffab2bca0664e85c25ddbd022/library/src/main/java/com/datatorrent/lib/appdata/snapshot/AbstractAppDataSnapshotServer.java", "sha": "af89109ceb890681fab3605df489c7ddfe589138", "changes": 4, "status": "modified", "deletions": 1, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/library/src/main/java/com/datatorrent/lib/appdata/snapshot/AbstractAppDataSnapshotServer.java?ref=36e8ae3db68f5d3ffab2bca0664e85c25ddbd022", "patch": "@@ -158,7 +158,9 @@ public AbstractAppDataSnapshotServer()\n   @Override\n   final public void activate(OperatorContext ctx)\n   {\n-    embeddableQueryInfoProvider.activate(ctx);\n+    if (embeddableQueryInfoProvider != null) {\n+      embeddableQueryInfoProvider.activate(ctx);\n+    }\n   }\n \n   @SuppressWarnings(\"unchecked\")", "filename": "library/src/main/java/com/datatorrent/lib/appdata/snapshot/AbstractAppDataSnapshotServer.java"}], "repo": "apex-malhar"}, {"commit": "https://github.com/apache/apex-malhar/commit/39e7e8ba87bc8805c98aecab9d8ba8d6c57c494e", "parent": "https://github.com/apache/apex-malhar/commit/20edbd2b95ab5f3227a97d7b638e6b4426d979ed", "message": "Merge pull request #1408 from tushargosavi/SPOI-4896\n\nFix NPE in monitor thread when kafka cluster becomes unavailable.", "bug_id": "apex-malhar_11", "file": [{"additions": 110, "raw_url": "https://github.com/apache/apex-malhar/raw/39e7e8ba87bc8805c98aecab9d8ba8d6c57c494e/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java", "blob_url": "https://github.com/apache/apex-malhar/blob/39e7e8ba87bc8805c98aecab9d8ba8d6c57c494e/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java", "sha": "720d7a14a8bd9473e510e18c310e15649ee13ea3", "changes": 175, "status": "modified", "deletions": 65, "contents_url": "https://api.github.com/repos/apache/apex-malhar/contents/contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java?ref=39e7e8ba87bc8805c98aecab9d8ba8d6c57c494e", "patch": "@@ -30,6 +30,7 @@\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n \n import javax.validation.constraints.NotNull;\n \n@@ -299,9 +300,14 @@ public SimpleKafkaConsumer(SetMultimap<String, String> zks, String topic, int ti\n    */\n   private final ConcurrentHashMap<KafkaPartition, Long> offsetTrack = new ConcurrentHashMap<KafkaPartition, Long>();\n \n+  private transient AtomicReference<Throwable> monitorException;\n+  private transient AtomicInteger monitorExceptionCount;\n+\n   @Override\n   public void start()\n   {\n+    monitorException = new AtomicReference<Throwable>(null);\n+    monitorExceptionCount = new AtomicInteger(0);\n     super.start();\n \n     // thread to consume the kafka data\n@@ -315,71 +321,7 @@ public void start()\n     metadataRefreshExecutor = Executors.newScheduledThreadPool(1, new ThreadFactoryBuilder().setNameFormat(\"kafka-consumer-monitor-\" + topic + \"-%d\").setDaemon(true).build());\n \n     // start one monitor thread to monitor the leader broker change and trigger some action\n-    final SimpleKafkaConsumer ref = this;\n-    metadataRefreshExecutor.scheduleAtFixedRate(new Runnable() {\n-\n-      private transient final SetMultimap<Broker, KafkaPartition> deltaPositive = HashMultimap.create();\n-\n-      @Override\n-      public void run()\n-      {\n-        if (isAlive && (metadataRefreshRetryLimit == -1 || retryCounter.get() < metadataRefreshRetryLimit)) {\n-          logger.debug(\"{}: Update metadata for topic {}\", Thread.currentThread().getName(), topic);\n-          Map<String, List<PartitionMetadata>> pms = KafkaMetadataUtil.getPartitionsForTopic(brokers, topic);\n-          if (pms == null) {\n-            // retrieve metadata fail add retry count and return\n-            retryCounter.getAndAdd(1);\n-            return;\n-          }\n-\n-          for (Entry<String, List<PartitionMetadata>> pmLEntry : pms.entrySet()) {\n-            for (PartitionMetadata pm : pmLEntry.getValue()) {\n-              KafkaPartition kp = new KafkaPartition(pmLEntry.getKey(), topic, pm.partitionId());\n-              if (!kps.contains(kp)) {\n-                // Out of this consumer's scope\n-                continue;\n-              }\n-              Broker b = pm.leader();\n-              Broker oldB = partitionToBroker.put(kp, b);\n-              if(b.equals(oldB)) {\n-                continue;\n-              }\n-              // add to positive\n-              deltaPositive.put(b,kp);\n-\n-              // always update the latest connection information\n-              stats.updatePartitionStats(kp, pm.leader().id(), pm.leader().host() + \":\" + pm.leader().port());\n-            }\n-          }\n-\n-          // remove from map if the thread is done (partitions on this broker has all been reassigned to others(or temporarily not available) for\n-          // example)\n-          for (Iterator<Entry<Broker, ConsumerThread>> iterator = simpleConsumerThreads.entrySet().iterator(); iterator.hasNext();) {\n-            Entry<Broker, ConsumerThread> item = iterator.next();\n-            if (item.getValue().getThreadItSelf().isDone()) {\n-              iterator.remove();\n-            }\n-          }\n-\n-          for (Broker b : deltaPositive.keySet()) {\n-            if (!simpleConsumerThreads.containsKey(b)) {\n-              // start thread for new broker\n-              ConsumerThread ct = new ConsumerThread(b, deltaPositive.get(b), ref);\n-              ct.setThreadItSelf(kafkaConsumerExecutor.submit(ct));\n-              simpleConsumerThreads.put(b, ct);\n-\n-            } else {\n-              simpleConsumerThreads.get(b).addPartitions(deltaPositive.get(b));\n-            }\n-          }\n-\n-          deltaPositive.clear();\n-\n-          // reset to 0 if it reconnect to the broker which has current broker metadata\n-          retryCounter.set(0);\n-        }\n-      }\n-    }, 0, metadataRefreshInterval, TimeUnit.MILLISECONDS);\n+    metadataRefreshExecutor.scheduleAtFixedRate(new MetaDataMonitorTask(this) , 0, metadataRefreshInterval, TimeUnit.MILLISECONDS);\n   }\n \n   @Override\n@@ -491,4 +433,107 @@ protected void resetPartitionsAndOffset(Set<KafkaPartition> partitionIds, Map<Ka\n     this.kps = partitionIds;\n     resetOffset(startOffset);\n   }\n+\n+  protected Throwable getMonitorException()\n+  {\n+    return monitorException.get();\n+  }\n+\n+  protected int getMonitorExceptionCount()\n+  {\n+    return monitorExceptionCount.get();\n+  }\n+\n+  /**\n+   * Task to monitor metadata periodically. This task will detect changes in broker for partition\n+   * and restart failed consumer threads for the partitions.\n+   * Monitoring is disabled after metadataRefreshRetryLimit number of failure.\n+   */\n+  private class MetaDataMonitorTask implements Runnable {\n+\n+    private final SimpleKafkaConsumer ref;\n+\n+    private transient final SetMultimap<Broker, KafkaPartition> deltaPositive = HashMultimap.create();\n+\n+    private MetaDataMonitorTask(SimpleKafkaConsumer ref) {\n+      this.ref = ref;\n+    }\n+\n+    @Override public void run() {\n+      try {\n+        monitorMetadata();\n+        monitorException.set(null);\n+        monitorExceptionCount.set(0);\n+      } catch (Throwable ex) {\n+        logger.error(\"Exception {}\", ex);\n+        monitorException.set(ex);\n+        monitorExceptionCount.incrementAndGet();\n+      }\n+    }\n+\n+    /**\n+     * Monitor kafka topic metadata changes.\n+     */\n+    private void monitorMetadata()\n+    {\n+      if (isAlive && (metadataRefreshRetryLimit == -1 || retryCounter.get() < metadataRefreshRetryLimit)) {\n+        logger.debug(\"{}: Update metadata for topic {}\", Thread.currentThread().getName(), topic);\n+        Map<String, List<PartitionMetadata>> pms = KafkaMetadataUtil.getPartitionsForTopic(brokers, topic);\n+        if (pms == null) {\n+          // retrieve metadata fail add retry count and return\n+          retryCounter.getAndAdd(1);\n+          return;\n+        }\n+\n+        for (Entry<String, List<PartitionMetadata>> pmLEntry : pms.entrySet()) {\n+          if (pmLEntry.getValue() == null)\n+            continue;\n+          for (PartitionMetadata pm : pmLEntry.getValue()) {\n+            KafkaPartition kp = new KafkaPartition(pmLEntry.getKey(), topic, pm.partitionId());\n+            if (!kps.contains(kp)) {\n+              // Out of this consumer's scope\n+              continue;\n+            }\n+            Broker b = pm.leader();\n+            Broker oldB = partitionToBroker.put(kp, b);\n+            if (b.equals(oldB)) {\n+              continue;\n+            }\n+            // add to positive\n+            deltaPositive.put(b, kp);\n+\n+            // always update the latest connection information\n+            stats.updatePartitionStats(kp, pm.leader().id(), pm.leader().host() + \":\" + pm.leader().port());\n+          }\n+        }\n+\n+        // remove from map if the thread is done (partitions on this broker has all been reassigned to others(or temporarily not available) for\n+        // example)\n+        for (Iterator<Entry<Broker, ConsumerThread>> iterator = simpleConsumerThreads.entrySet().iterator(); iterator.hasNext(); ) {\n+          Entry<Broker, ConsumerThread> item = iterator.next();\n+          if (item.getValue().getThreadItSelf().isDone()) {\n+            iterator.remove();\n+          }\n+        }\n+\n+        for (Broker b : deltaPositive.keySet()) {\n+          if (!simpleConsumerThreads.containsKey(b)) {\n+            // start thread for new broker\n+            ConsumerThread ct = new ConsumerThread(b, deltaPositive.get(b), ref);\n+            ct.setThreadItSelf(kafkaConsumerExecutor.submit(ct));\n+            simpleConsumerThreads.put(b, ct);\n+\n+          } else {\n+            simpleConsumerThreads.get(b).addPartitions(deltaPositive.get(b));\n+          }\n+        }\n+\n+        deltaPositive.clear();\n+\n+        // reset to 0 if it reconnect to the broker which has current broker metadata\n+        retryCounter.set(0);\n+      }\n+    }\n+\n+  }\n } // End of SimpleKafkaConsumer", "filename": "contrib/src/main/java/com/datatorrent/contrib/kafka/SimpleKafkaConsumer.java"}], "repo": "apex-malhar"}]
