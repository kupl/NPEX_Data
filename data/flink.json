{
    "flink_101552b": {
        "bug_id": "flink_101552b",
        "commit": "https://github.com/apache/flink/commit/101552bf503cf0ca59493397ec4cd01bcc4c45a7",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/flink/blob/101552bf503cf0ca59493397ec4cd01bcc4c45a7/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java?ref=101552bf503cf0ca59493397ec4cd01bcc4c45a7",
                "deletions": 1,
                "filename": "flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java",
                "patch": "@@ -123,7 +123,7 @@ public PojoSerializer(\n \t\t\tthis.fields[i].setAccessible(true);\n \t\t}\n \n-\t\tcl = Thread.currentThread().getContextClassLoader();\n+\t\tthis.cl = Thread.currentThread().getContextClassLoader();\n \n \t\t// We only want those classes that are not our own class and are actually sub-classes.\n \t\tLinkedHashSet<Class<?>> registeredSubclasses =\n@@ -156,6 +156,7 @@ public PojoSerializer(\n \t\tthis.registeredSerializers = checkNotNull(registeredSerializers);\n \t\tthis.subclassSerializerCache = checkNotNull(subclassSerializerCache);\n \t\tthis.executionConfig = checkNotNull(executionConfig);\n+\t\tthis.cl = Thread.currentThread().getContextClassLoader();\n \t}\n \t\n \t@Override",
                "raw_url": "https://github.com/apache/flink/raw/101552bf503cf0ca59493397ec4cd01bcc4c45a7/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java",
                "sha": "5c43d1e172eba312bfc6efdb385bc1add3d852fa",
                "status": "modified"
            }
        ],
        "message": "[FLINK-13159] Fix the NPE when PojoSerializer restored",
        "parent": "https://github.com/apache/flink/commit/886419f12f60df803c9d757e381f201920a8061a",
        "repo": "flink",
        "unit_tests": [
            "PojoSerializerTest.java"
        ]
    },
    "flink_13150a4": {
        "bug_id": "flink_13150a4",
        "commit": "https://github.com/apache/flink/commit/13150a4ba26127b9ee2035fd3509b57bc3f7aa61",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flink/blob/13150a4ba26127b9ee2035fd3509b57bc3f7aa61/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/TwoInputStreamTask.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/TwoInputStreamTask.java?ref=13150a4ba26127b9ee2035fd3509b57bc3f7aa61",
                "deletions": 1,
                "filename": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/TwoInputStreamTask.java",
                "patch": "@@ -91,7 +91,9 @@ protected void run() throws Exception {\n \n \t@Override\n \tprotected void cleanup() throws Exception {\n-\t\tinputProcessor.cleanup();\n+\t\tif (inputProcessor != null) {\n+\t\t\tinputProcessor.cleanup();\n+\t\t}\n \t}\n \n \t@Override",
                "raw_url": "https://github.com/apache/flink/raw/13150a4ba26127b9ee2035fd3509b57bc3f7aa61/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/TwoInputStreamTask.java",
                "sha": "233e9f10db0c809213cafdedac435b7c84af65ef",
                "status": "modified"
            }
        ],
        "message": "[FLINK-4631] Prevent NPE in TwoInputStreamTask\n\nCheck that the input processor has been created before cleaning it up.",
        "parent": "https://github.com/apache/flink/commit/4410c04a68c7b247bb3d7113e5f40f2a9c2165af",
        "repo": "flink",
        "unit_tests": [
            "TwoInputStreamTaskTest.java"
        ]
    },
    "flink_191b9df": {
        "bug_id": "flink_191b9df",
        "commit": "https://github.com/apache/flink/commit/191b9dff2f3faf281a77e211c6ef47243d6a9e8d",
        "file": [
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/flink/blob/191b9dff2f3faf281a77e211c6ef47243d6a9e8d/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptAccumulatorsHandler.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptAccumulatorsHandler.java?ref=191b9dff2f3faf281a77e211c6ef47243d6a9e8d",
                "deletions": 7,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptAccumulatorsHandler.java",
                "patch": "@@ -100,13 +100,15 @@ protected SubtaskExecutionAttemptAccumulatorsInfo handleRequest(\n \n \t\t\t\tfor (int x = 0; x < subtask.getCurrentExecutionAttempt().getAttemptNumber(); x++) {\n \t\t\t\t\tAccessExecution attempt = subtask.getPriorExecutionAttempt(x);\n-\t\t\t\t\tResponseBody json = createAccumulatorInfo(attempt);\n-\t\t\t\t\tString path = getMessageHeaders().getTargetRestEndpointURL()\n-\t\t\t\t\t\t.replace(':' + JobIDPathParameter.KEY, graph.getJobID().toString())\n-\t\t\t\t\t\t.replace(':' + JobVertexIdPathParameter.KEY, task.getJobVertexId().toString())\n-\t\t\t\t\t\t.replace(':' + SubtaskIndexPathParameter.KEY, String.valueOf(subtask.getParallelSubtaskIndex()))\n-\t\t\t\t\t\t.replace(':' + SubtaskAttemptPathParameter.KEY, String.valueOf(attempt.getAttemptNumber()));\n-\t\t\t\t\tarchive.add(new ArchivedJson(path, json));\n+\t\t\t\t\tif (attempt != null){\n+\t\t\t\t\t\tResponseBody json = createAccumulatorInfo(attempt);\n+\t\t\t\t\t\tString path = getMessageHeaders().getTargetRestEndpointURL()\n+\t\t\t\t\t\t\t.replace(':' + JobIDPathParameter.KEY, graph.getJobID().toString())\n+\t\t\t\t\t\t\t.replace(':' + JobVertexIdPathParameter.KEY, task.getJobVertexId().toString())\n+\t\t\t\t\t\t\t.replace(':' + SubtaskIndexPathParameter.KEY, String.valueOf(subtask.getParallelSubtaskIndex()))\n+\t\t\t\t\t\t\t.replace(':' + SubtaskAttemptPathParameter.KEY, String.valueOf(attempt.getAttemptNumber()));\n+\t\t\t\t\t\tarchive.add(new ArchivedJson(path, json));\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \t\t}",
                "raw_url": "https://github.com/apache/flink/raw/191b9dff2f3faf281a77e211c6ef47243d6a9e8d/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptAccumulatorsHandler.java",
                "sha": "97da25a1230e65b32d6d207cbd94f2f347160b53",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/flink/blob/191b9dff2f3faf281a77e211c6ef47243d6a9e8d/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptDetailsHandler.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptDetailsHandler.java?ref=191b9dff2f3faf281a77e211c6ef47243d6a9e8d",
                "deletions": 7,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptDetailsHandler.java",
                "patch": "@@ -114,13 +114,15 @@ protected SubtaskExecutionAttemptDetailsInfo handleRequest(\n \n \t\t\t\tfor (int x = 0; x < subtask.getCurrentExecutionAttempt().getAttemptNumber(); x++) {\n \t\t\t\t\tAccessExecution attempt = subtask.getPriorExecutionAttempt(x);\n-\t\t\t\t\tResponseBody json = createDetailsInfo(attempt, graph.getJobID(), task.getJobVertexId(), null);\n-\t\t\t\t\tString path = getMessageHeaders().getTargetRestEndpointURL()\n-\t\t\t\t\t\t.replace(':' + JobIDPathParameter.KEY, graph.getJobID().toString())\n-\t\t\t\t\t\t.replace(':' + JobVertexIdPathParameter.KEY, task.getJobVertexId().toString())\n-\t\t\t\t\t\t.replace(':' + SubtaskIndexPathParameter.KEY, String.valueOf(subtask.getParallelSubtaskIndex()))\n-\t\t\t\t\t\t.replace(':' + SubtaskAttemptPathParameter.KEY, String.valueOf(attempt.getAttemptNumber()));\n-\t\t\t\t\tarchive.add(new ArchivedJson(path, json));\n+\t\t\t\t\tif (attempt != null) {\n+\t\t\t\t\t\tResponseBody json = createDetailsInfo(attempt, graph.getJobID(), task.getJobVertexId(), null);\n+\t\t\t\t\t\tString path = getMessageHeaders().getTargetRestEndpointURL()\n+\t\t\t\t\t\t\t.replace(':' + JobIDPathParameter.KEY, graph.getJobID().toString())\n+\t\t\t\t\t\t\t.replace(':' + JobVertexIdPathParameter.KEY, task.getJobVertexId().toString())\n+\t\t\t\t\t\t\t.replace(':' + SubtaskIndexPathParameter.KEY, String.valueOf(subtask.getParallelSubtaskIndex()))\n+\t\t\t\t\t\t\t.replace(':' + SubtaskAttemptPathParameter.KEY, String.valueOf(attempt.getAttemptNumber()));\n+\t\t\t\t\t\tarchive.add(new ArchivedJson(path, json));\n+\t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}\n \t\t}",
                "raw_url": "https://github.com/apache/flink/raw/191b9dff2f3faf281a77e211c6ef47243d6a9e8d/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/SubtaskExecutionAttemptDetailsHandler.java",
                "sha": "75fd100062e22e175fc4a748aa4271f044991737",
                "status": "modified"
            }
        ],
        "message": "[FLINK-12247][rest] Fix NPE when writing the archive json file to FileSystem\n\nThis closes #8250.",
        "parent": "https://github.com/apache/flink/commit/8a174833bee081f4f4a24caa5ddc5fe45996de13",
        "repo": "flink",
        "unit_tests": [
            "SubtaskExecutionAttemptDetailsHandlerTest.java"
        ]
    },
    "flink_26bac51": {
        "bug_id": "flink_26bac51",
        "commit": "https://github.com/apache/flink/commit/26bac51cae1d298078902a02e196fffc16ea5704",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/26bac51cae1d298078902a02e196fffc16ea5704/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java?ref=26bac51cae1d298078902a02e196fffc16ea5704",
                "deletions": 1,
                "filename": "flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java",
                "patch": "@@ -373,7 +373,10 @@ private GetRecordsResult getRecords(String shardItr, int maxNumberOfRecords) thr\n \t\t\t\tgetRecordsResult = kinesis.getRecords(shardItr, maxNumberOfRecords);\n \n \t\t\t\t// Update millis behind latest so it gets reported by the millisBehindLatest gauge\n-\t\t\t\tshardMetricsReporter.setMillisBehindLatest(getRecordsResult.getMillisBehindLatest());\n+\t\t\t\tLong millisBehindLatest = getRecordsResult.getMillisBehindLatest();\n+\t\t\t\tif (millisBehindLatest != null) {\n+\t\t\t\t\tshardMetricsReporter.setMillisBehindLatest(millisBehindLatest);\n+\t\t\t\t}\n \t\t\t} catch (ExpiredIteratorException eiEx) {\n \t\t\t\tLOG.warn(\"Encountered an unexpected expired iterator {} for shard {};\" +\n \t\t\t\t\t\" refreshing the iterator ...\", shardItr, subscribedShard);",
                "raw_url": "https://github.com/apache/flink/raw/26bac51cae1d298078902a02e196fffc16ea5704/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java",
                "sha": "36a4e92c179135fcb9f459fcff746be4069c184a",
                "status": "modified"
            }
        ],
        "message": "[FLINK-10358] fix NPE when running flink-kinesis connector against dynamodb streams\n\nThis closes #6708.",
        "parent": "https://github.com/apache/flink/commit/e58cc14db007123c6325c7e51291650da69a4ca2",
        "repo": "flink",
        "unit_tests": [
            "ShardConsumerTest.java"
        ]
    },
    "flink_26bc3c8": {
        "bug_id": "flink_26bc3c8",
        "commit": "https://github.com/apache/flink/commit/26bc3c8c65c757285c58b2cfcb0ba81111395ea4",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/flink/blob/26bc3c8c65c757285c58b2cfcb0ba81111395ea4/flink-runtime/src/main/java/org/apache/flink/runtime/history/FsJobArchivist.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/history/FsJobArchivist.java?ref=26bc3c8c65c757285c58b2cfcb0ba81111395ea4",
                "deletions": 7,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/history/FsJobArchivist.java",
                "patch": "@@ -109,15 +109,20 @@ public static Path archiveJob(Path rootPath, JobID jobId, Collection<ArchivedJso\n \t\t\tByteArrayOutputStream output = new ByteArrayOutputStream()) {\n \t\t\tIOUtils.copyBytes(input, output);\n \n-\t\t\tJsonNode archive = mapper.readTree(output.toByteArray());\n+\t\t\ttry {\n+\t\t\t\tJsonNode archive = mapper.readTree(output.toByteArray());\n \n-\t\t\tCollection<ArchivedJson> archives = new ArrayList<>();\n-\t\t\tfor (JsonNode archivePart : archive.get(ARCHIVE)) {\n-\t\t\t\tString path = archivePart.get(PATH).asText();\n-\t\t\t\tString json = archivePart.get(JSON).asText();\n-\t\t\t\tarchives.add(new ArchivedJson(path, json));\n+\t\t\t\tCollection<ArchivedJson> archives = new ArrayList<>();\n+\t\t\t\tfor (JsonNode archivePart : archive.get(ARCHIVE)) {\n+\t\t\t\t\tString path = archivePart.get(PATH).asText();\n+\t\t\t\t\tString json = archivePart.get(JSON).asText();\n+\t\t\t\t\tarchives.add(new ArchivedJson(path, json));\n+\t\t\t\t}\n+\t\t\t\treturn archives;\n+\t\t\t} catch (NullPointerException npe) {\n+\t\t\t\t// occurs if the archive is empty or any of the expected fields are not present\n+\t\t\t\tthrow new IOException(\"Job archive (\" + file.getPath() + \") did not conform to expected format.\");\n \t\t\t}\n-\t\t\treturn archives;\n \t\t}\n \t}\n }",
                "raw_url": "https://github.com/apache/flink/raw/26bc3c8c65c757285c58b2cfcb0ba81111395ea4/flink-runtime/src/main/java/org/apache/flink/runtime/history/FsJobArchivist.java",
                "sha": "ab1e34d74078a89fda138bc8d4fcc9c656e58700",
                "status": "modified"
            }
        ],
        "message": "[FLINK-14337][hs] Prevent NPE on corrupt archives",
        "parent": "https://github.com/apache/flink/commit/f22f1eba8f7695857a2015ed178365191849dac4",
        "repo": "flink",
        "unit_tests": [
            "FsJobArchivistTest.java"
        ]
    },
    "flink_3ce8596": {
        "bug_id": "flink_3ce8596",
        "commit": "https://github.com/apache/flink/commit/3ce8596b43f88b2b6d51dab687ab224a43b825fb",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flink/blob/3ce8596b43f88b2b6d51dab687ab224a43b825fb/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OneInputStreamTask.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OneInputStreamTask.java?ref=3ce8596b43f88b2b6d51dab687ab224a43b825fb",
                "deletions": 1,
                "filename": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OneInputStreamTask.java",
                "patch": "@@ -69,7 +69,9 @@ protected void run() throws Exception {\n \n \t@Override\n \tprotected void cleanup() throws Exception {\n-\t\tinputProcessor.cleanup();\n+\t\tif (inputProcessor != null) {\n+\t\t\tinputProcessor.cleanup();\n+\t\t}\n \t}\n \n \t@Override",
                "raw_url": "https://github.com/apache/flink/raw/3ce8596b43f88b2b6d51dab687ab224a43b825fb/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OneInputStreamTask.java",
                "sha": "0f8f4a4cf43914ca7a894f6793bbea1abe81737b",
                "status": "modified"
            }
        ],
        "message": "[FLINK-4631] Prevent NPE in OneInputStreamTask\n\nThis closes #2709.",
        "parent": "https://github.com/apache/flink/commit/211f5db9d764efe5318867993f1b33f4eee48117",
        "repo": "flink",
        "unit_tests": [
            "OneInputStreamTaskTest.java"
        ]
    },
    "flink_4064b5b": {
        "bug_id": "flink_4064b5b",
        "commit": "https://github.com/apache/flink/commit/4064b5b67d6d220e1d5518bca96688f51cbbb891",
        "file": [
            {
                "additions": 58,
                "blob_url": "https://github.com/apache/flink/blob/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/heartbeat/NoOpHeartbeatManager.java",
                "changes": 58,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/heartbeat/NoOpHeartbeatManager.java?ref=4064b5b67d6d220e1d5518bca96688f51cbbb891",
                "deletions": 0,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/heartbeat/NoOpHeartbeatManager.java",
                "patch": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.heartbeat;\n+\n+import org.apache.flink.runtime.clusterframework.types.ResourceID;\n+\n+/**\n+ * {@link HeartbeatManager} implementation which does nothing.\n+ *\n+ * @param <I> ignored\n+ * @param <O> ignored\n+ */\n+public class NoOpHeartbeatManager<I, O> implements HeartbeatManager<I, O> {\n+\tprivate static final NoOpHeartbeatManager<Object, Object> INSTANCE = new NoOpHeartbeatManager<>();\n+\n+\tprivate NoOpHeartbeatManager() {}\n+\n+\t@Override\n+\tpublic void monitorTarget(ResourceID resourceID, HeartbeatTarget<O> heartbeatTarget) {}\n+\n+\t@Override\n+\tpublic void unmonitorTarget(ResourceID resourceID) {}\n+\n+\t@Override\n+\tpublic void stop() {}\n+\n+\t@Override\n+\tpublic long getLastHeartbeatFrom(ResourceID resourceId) {\n+\t\treturn 0;\n+\t}\n+\n+\t@Override\n+\tpublic void receiveHeartbeat(ResourceID heartbeatOrigin, I heartbeatPayload) {}\n+\n+\t@Override\n+\tpublic void requestHeartbeat(ResourceID requestOrigin, I heartbeatPayload) {}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic static <A, B> NoOpHeartbeatManager<A, B> getInstance() {\n+\t\treturn (NoOpHeartbeatManager<A, B>) INSTANCE;\n+\t}\n+}",
                "raw_url": "https://github.com/apache/flink/raw/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/heartbeat/NoOpHeartbeatManager.java",
                "sha": "965a50b3f3539236a7e706dd51137b6b66ffcc57",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flink/blob/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobMaster.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobMaster.java?ref=4064b5b67d6d220e1d5518bca96688f51cbbb891",
                "deletions": 9,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobMaster.java",
                "patch": "@@ -38,6 +38,7 @@\n import org.apache.flink.runtime.heartbeat.HeartbeatManager;\n import org.apache.flink.runtime.heartbeat.HeartbeatServices;\n import org.apache.flink.runtime.heartbeat.HeartbeatTarget;\n+import org.apache.flink.runtime.heartbeat.NoOpHeartbeatManager;\n import org.apache.flink.runtime.highavailability.HighAvailabilityServices;\n import org.apache.flink.runtime.io.network.partition.PartitionTracker;\n import org.apache.flink.runtime.io.network.partition.PartitionTrackerFactory;\n@@ -269,6 +270,8 @@ public JobMaster(\n \t\tthis.establishedResourceManagerConnection = null;\n \n \t\tthis.accumulators = new HashMap<>();\n+\t\tthis.taskManagerHeartbeatManager = NoOpHeartbeatManager.getInstance();\n+\t\tthis.resourceManagerHeartbeatManager = NoOpHeartbeatManager.getInstance();\n \t}\n \n \tprivate SchedulerNG createScheduler(final JobManagerJobMetricGroup jobManagerJobMetricGroup) throws Exception {\n@@ -785,15 +788,8 @@ private Acknowledge suspendExecution(final Exception cause) {\n \t}\n \n \tprivate void stopHeartbeatServices() {\n-\t\tif (taskManagerHeartbeatManager != null) {\n-\t\t\ttaskManagerHeartbeatManager.stop();\n-\t\t\ttaskManagerHeartbeatManager = null;\n-\t\t}\n-\n-\t\tif (resourceManagerHeartbeatManager != null) {\n-\t\t\tresourceManagerHeartbeatManager.stop();\n-\t\t\tresourceManagerHeartbeatManager = null;\n-\t\t}\n+\t\ttaskManagerHeartbeatManager.stop();\n+\t\tresourceManagerHeartbeatManager.stop();\n \t}\n \n \tprivate void startHeartbeatServices() {",
                "raw_url": "https://github.com/apache/flink/raw/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobMaster.java",
                "sha": "665c4aa479d08a98efeed8e1c6b3fee49a99cb38",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java?ref=4064b5b67d6d220e1d5518bca96688f51cbbb891",
                "deletions": 7,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java",
                "patch": "@@ -38,6 +38,7 @@\n import org.apache.flink.runtime.heartbeat.HeartbeatManager;\n import org.apache.flink.runtime.heartbeat.HeartbeatServices;\n import org.apache.flink.runtime.heartbeat.HeartbeatTarget;\n+import org.apache.flink.runtime.heartbeat.NoOpHeartbeatManager;\n import org.apache.flink.runtime.highavailability.HighAvailabilityServices;\n import org.apache.flink.runtime.instance.HardwareDescription;\n import org.apache.flink.runtime.instance.InstanceID;\n@@ -178,6 +179,9 @@ public ResourceManager(\n \t\tthis.jmResourceIdRegistrations = new HashMap<>(4);\n \t\tthis.taskExecutors = new HashMap<>(8);\n \t\tthis.taskExecutorGatewayFutures = new HashMap<>(8);\n+\n+\t\tthis.jobManagerHeartbeatManager = NoOpHeartbeatManager.getInstance();\n+\t\tthis.taskManagerHeartbeatManager = NoOpHeartbeatManager.getInstance();\n \t}\n \n \n@@ -972,15 +976,8 @@ private void startHeartbeatServices() {\n \t}\n \n \tprivate void stopHeartbeatServices() {\n-\t\tif (taskManagerHeartbeatManager != null) {\n \t\t\ttaskManagerHeartbeatManager.stop();\n-\t\t\ttaskManagerHeartbeatManager = null;\n-\t\t}\n-\n-\t\tif (jobManagerHeartbeatManager != null) {\n \t\t\tjobManagerHeartbeatManager.stop();\n-\t\t\tjobManagerHeartbeatManager = null;\n-\t\t}\n \t}\n \n \t/**",
                "raw_url": "https://github.com/apache/flink/raw/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java",
                "sha": "8698e842ac548596330b545a4d74601cfd473046",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/flink/blob/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java",
                "changes": 58,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java?ref=4064b5b67d6d220e1d5518bca96688f51cbbb891",
                "deletions": 36,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java",
                "patch": "@@ -157,8 +157,6 @@\n \t/** The task manager configuration. */\n \tprivate final TaskManagerConfiguration taskManagerConfiguration;\n \n-\tprivate final HeartbeatServices heartbeatServices;\n-\n \t/** The fatal error handler to use in case of a fatal error. */\n \tprivate final FatalErrorHandler fatalErrorHandler;\n \n@@ -207,10 +205,10 @@\n \tprivate FileCache fileCache;\n \n \t/** The heartbeat manager for job manager in the task manager. */\n-\tprivate HeartbeatManager<AllocatedSlotReport, AccumulatorReport> jobManagerHeartbeatManager;\n+\tprivate final HeartbeatManager<AllocatedSlotReport, AccumulatorReport> jobManagerHeartbeatManager;\n \n \t/** The heartbeat manager for resource manager in the task manager. */\n-\tprivate HeartbeatManager<Void, SlotReport> resourceManagerHeartbeatManager;\n+\tprivate final HeartbeatManager<Void, SlotReport> resourceManagerHeartbeatManager;\n \n \tprivate final PartitionTable<JobID> partitionTable;\n \n@@ -249,7 +247,6 @@ public TaskExecutor(\n \t\tcheckArgument(taskManagerConfiguration.getNumberSlots() > 0, \"The number of slots has to be larger than 0.\");\n \n \t\tthis.taskManagerConfiguration = checkNotNull(taskManagerConfiguration);\n-\t\tthis.heartbeatServices = checkNotNull(heartbeatServices);\n \t\tthis.taskExecutorServices = checkNotNull(taskExecutorServices);\n \t\tthis.haServices = checkNotNull(haServices);\n \t\tthis.fatalErrorHandler = checkNotNull(fatalErrorHandler);\n@@ -278,6 +275,26 @@ public TaskExecutor(\n \n \t\tthis.stackTraceSampleService = new StackTraceSampleService(rpcService.getScheduledExecutor());\n \t\tthis.taskCompletionTracker = new TaskCompletionTracker();\n+\n+\t\tfinal ResourceID resourceId = taskExecutorServices.getTaskManagerLocation().getResourceID();\n+\t\tthis.jobManagerHeartbeatManager = createJobManagerHeartbeatManager(heartbeatServices, resourceId);\n+\t\tthis.resourceManagerHeartbeatManager = createResourceManagerHeartbeatManager(heartbeatServices, resourceId);\n+\t}\n+\n+\tprivate HeartbeatManager<Void, SlotReport> createResourceManagerHeartbeatManager(HeartbeatServices heartbeatServices, ResourceID resourceId) {\n+\t\treturn heartbeatServices.createHeartbeatManager(\n+\t\t\tresourceId,\n+\t\t\tnew ResourceManagerHeartbeatListener(),\n+\t\t\tgetMainThreadExecutor(),\n+\t\t\tlog);\n+\t}\n+\n+\tprivate HeartbeatManager<AllocatedSlotReport, AccumulatorReport> createJobManagerHeartbeatManager(HeartbeatServices heartbeatServices, ResourceID resourceId) {\n+\t\treturn heartbeatServices.createHeartbeatManager(\n+\t\t\tresourceId,\n+\t\t\tnew JobManagerHeartbeatListener(),\n+\t\t\tgetMainThreadExecutor(),\n+\t\t\tlog);\n \t}\n \n \t@Override\n@@ -304,8 +321,6 @@ public void onStart() throws Exception {\n \n \tprivate void startTaskExecutorServices() throws Exception {\n \t\ttry {\n-\t\t\tstartHeartbeatServices();\n-\n \t\t\t// start by connecting to the ResourceManager\n \t\t\tresourceManagerLeaderRetriever.start(new ResourceManagerLeaderListener());\n \n@@ -412,38 +427,9 @@ private void stopTaskExecutorServices() throws Exception {\n \t\t// it will call close() recursively from the parent to children\n \t\ttaskManagerMetricGroup.close();\n \n-\t\tstopHeartbeatServices();\n-\n \t\tExceptionUtils.tryRethrowException(exception);\n \t}\n \n-\tprivate void startHeartbeatServices() {\n-\t\tfinal ResourceID resourceId = taskExecutorServices.getTaskManagerLocation().getResourceID();\n-\t\tjobManagerHeartbeatManager = heartbeatServices.createHeartbeatManager(\n-\t\t\tresourceId,\n-\t\t\tnew JobManagerHeartbeatListener(),\n-\t\t\tgetMainThreadExecutor(),\n-\t\t\tlog);\n-\n-\t\tresourceManagerHeartbeatManager = heartbeatServices.createHeartbeatManager(\n-\t\t\tresourceId,\n-\t\t\tnew ResourceManagerHeartbeatListener(),\n-\t\t\tgetMainThreadExecutor(),\n-\t\t\tlog);\n-\t}\n-\n-\tprivate void stopHeartbeatServices() {\n-\t\tif (jobManagerHeartbeatManager != null) {\n-\t\t\tjobManagerHeartbeatManager.stop();\n-\t\t\tjobManagerHeartbeatManager = null;\n-\t\t}\n-\n-\t\tif (resourceManagerHeartbeatManager != null) {\n-\t\t\tresourceManagerHeartbeatManager.stop();\n-\t\t\tresourceManagerHeartbeatManager = null;\n-\t\t}\n-\t}\n-\n \t// ======================================================================\n \t//  RPC methods\n \t// ======================================================================",
                "raw_url": "https://github.com/apache/flink/raw/4064b5b67d6d220e1d5518bca96688f51cbbb891/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java",
                "sha": "f0db4cd82b2d371a72c1a12cbf6f650cfbc876e3",
                "status": "modified"
            }
        ],
        "message": "[FLINK-14315] Make heartbeat manager fields non-nullable\n\nThis commit introduces the NoOpHeartbeatManager which can be used to initialize\nan unset heartbeat manager field. This allows to make the heartbeat manager fields\nnon-nullable which in turn avoid NPE.\n\nMoreover, this commit makes the heartbeat manager fields of the TaskExecutor\nfinal.\n\nThis closes #9837.",
        "parent": "https://github.com/apache/flink/commit/c5c59feec0ed8a0ac5213802d79956c815a2b812",
        "repo": "flink",
        "unit_tests": [
            "TaskExecutorTest.java"
        ]
    },
    "flink_47db9cb": {
        "bug_id": "flink_47db9cb",
        "commit": "https://github.com/apache/flink/commit/47db9cb1a867870a8da0b403e0ec217ac461ba04",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/flink/blob/47db9cb1a867870a8da0b403e0ec217ac461ba04/flink-core/src/main/java/org/apache/flink/core/fs/local/LocalFileSystem.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-core/src/main/java/org/apache/flink/core/fs/local/LocalFileSystem.java?ref=47db9cb1a867870a8da0b403e0ec217ac461ba04",
                "deletions": 2,
                "filename": "flink-core/src/main/java/org/apache/flink/core/fs/local/LocalFileSystem.java",
                "patch": "@@ -184,8 +184,13 @@ public boolean delete(final Path f, final boolean recursive) throws IOException\n \t\tfinal File file = pathToFile(f);\n \t\tif (file.isFile()) {\n \t\t\treturn file.delete();\n-\t\t} else if ((!recursive) && file.isDirectory() && (file.listFiles().length != 0)) {\n-\t\t\tthrow new IOException(\"Directory \" + file.toString() + \" is not empty\");\n+\t\t} else if ((!recursive) && file.isDirectory()) {\n+\t\t\tFile[] containedFiles = file.listFiles();\n+\t\t\tif (containedFiles == null) {\n+\t\t\t\tthrow new IOException(\"Directory \" + file.toString() + \" does not exist or an I/O error occurred\");\n+\t\t\t} else if (containedFiles.length != 0) {\n+\t\t\t\tthrow new IOException(\"Directory \" + file.toString() + \" is not empty\");\n+\t\t\t}\n \t\t}\n \n \t\treturn delete(file);",
                "raw_url": "https://github.com/apache/flink/raw/47db9cb1a867870a8da0b403e0ec217ac461ba04/flink-core/src/main/java/org/apache/flink/core/fs/local/LocalFileSystem.java",
                "sha": "7ad68b35d7a5dedc5db6a8dcf212146c233fc481",
                "status": "modified"
            }
        ],
        "message": "[FLINK-5147] Prevent NPE in LocalFS#delete()\n\nThis closes #2859.",
        "parent": "https://github.com/apache/flink/commit/dc5dd5106738e393761a62a56d9e684c722c516f",
        "repo": "flink",
        "unit_tests": [
            "LocalFileSystemTest.java"
        ]
    },
    "flink_4b19e27": {
        "bug_id": "flink_4b19e27",
        "commit": "https://github.com/apache/flink/commit/4b19e272043907b70791bff8a85bd493e212947c",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flink/blob/4b19e272043907b70791bff8a85bd493e212947c/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SourceStreamTask.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SourceStreamTask.java?ref=4b19e272043907b70791bff8a85bd493e212947c",
                "deletions": 1,
                "filename": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SourceStreamTask.java",
                "patch": "@@ -58,6 +58,8 @@ protected void run() throws Exception {\n \t\n \t@Override\n \tprotected void cancelTask() throws Exception {\n-\t\theadOperator.cancel();\n+\t\tif (headOperator != null) {\n+\t\t\theadOperator.cancel();\n+\t\t}\n \t}\n }",
                "raw_url": "https://github.com/apache/flink/raw/4b19e272043907b70791bff8a85bd493e212947c/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SourceStreamTask.java",
                "sha": "18291408d0e35e73db8cdceb731870759b5f7c70",
                "status": "modified"
            }
        ],
        "message": "[FLINK-6182] Fix possible NPE in SourceStreamTask\n\nThis closes #3606.",
        "parent": "https://github.com/apache/flink/commit/11fe3dc89f6b6b24fa21cc51d5e935e91634dbe5",
        "repo": "flink",
        "unit_tests": [
            "SourceStreamTaskTest.java"
        ]
    },
    "flink_5f11df6": {
        "bug_id": "flink_5f11df6",
        "commit": "https://github.com/apache/flink/commit/5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flink/blob/5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliStrings.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliStrings.java?ref=5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65",
                "deletions": 0,
                "filename": "flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliStrings.java",
                "patch": "@@ -35,6 +35,7 @@ private CliStrings() {\n \n \tpublic static final String CLI_NAME = \"Flink SQL CLI Client\";\n \tpublic static final String DEFAULT_MARGIN = \" \";\n+\tpublic static final String NULL_COLUMN = \"(NULL)\";\n \n \t// --------------------------------------------------------------------------------------------\n ",
                "raw_url": "https://github.com/apache/flink/raw/5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliStrings.java",
                "sha": "1e8f696bdf26cb4826f9cbe6c96f8c15d279a209",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/flink/blob/5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliUtils.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliUtils.java?ref=5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65",
                "deletions": 1,
                "filename": "flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliUtils.java",
                "patch": "@@ -93,7 +93,12 @@ public static void normalizeColumn(AttributedStringBuilder sb, String col, int m\n \tpublic static String[] rowToString(Row row) {\n \t\tfinal String[] fields = new String[row.getArity()];\n \t\tfor (int i = 0; i < row.getArity(); i++) {\n-\t\t\tfields[i] = row.getField(i).toString();\n+\t\t\tfinal Object field = row.getField(i);\n+\t\t\tif (field == null) {\n+\t\t\t\tfields[i] = CliStrings.NULL_COLUMN;\n+\t\t\t} else {\n+\t\t\t\tfields[i] = field.toString();\n+\t\t\t}\n \t\t}\n \t\treturn fields;\n \t}",
                "raw_url": "https://github.com/apache/flink/raw/5f11df6eedf64f81ffdbf4afc2ad5d84b1b2ae65/flink-libraries/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliUtils.java",
                "sha": "77894e8b7e192dc37b305e43f2530c91bae7c034",
                "status": "modified"
            }
        ],
        "message": "[hotfix] [sql-client] Fix NPE when column is null",
        "parent": "https://github.com/apache/flink/commit/e8e74a648a134fe054081a49a36b8c45f30c21bc",
        "repo": "flink",
        "unit_tests": [
            "CliUtilsTest.java"
        ]
    },
    "flink_74b09ce": {
        "bug_id": "flink_74b09ce",
        "commit": "https://github.com/apache/flink/commit/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90",
        "file": [
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/flink/blob/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java?ref=74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90",
                "deletions": 12,
                "filename": "flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java",
                "patch": "@@ -31,7 +31,6 @@\n import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n import org.apache.flink.streaming.runtime.operators.CheckpointCommitter;\n import org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink;\n-import org.apache.flink.types.IntValue;\n \n import java.util.UUID;\n import java.util.concurrent.atomic.AtomicInteger;\n@@ -97,7 +96,7 @@ public void close() throws Exception {\n \n \t@Override\n \tprotected boolean sendValues(Iterable<IN> values, long timestamp) throws Exception {\n-\t\tfinal IntValue updatesCount = new IntValue(0);\n+\t\tfinal AtomicInteger updatesCount = new AtomicInteger(0);\n \t\tfinal AtomicInteger updatesConfirmed = new AtomicInteger(0);\n \n \t\tfinal AtomicReference<Throwable> exception = new AtomicReference<>();\n@@ -106,8 +105,8 @@ protected boolean sendValues(Iterable<IN> values, long timestamp) throws Excepti\n \t\t\t@Override\n \t\t\tpublic void onSuccess(ResultSet resultSet) {\n \t\t\t\tupdatesConfirmed.incrementAndGet();\n-\t\t\t\tif (updatesCount.getValue() > 0) { // only set if all updates have been sent\n-\t\t\t\t\tif (updatesCount.getValue() == updatesConfirmed.get()) {\n+\t\t\t\tif (updatesCount.get() > 0) { // only set if all updates have been sent\n+\t\t\t\t\tif (updatesCount.get() == updatesConfirmed.get()) {\n \t\t\t\t\t\tsynchronized (updatesConfirmed) {\n \t\t\t\t\t\t\tupdatesConfirmed.notifyAll();\n \t\t\t\t\t\t}\n@@ -142,18 +141,19 @@ public void onFailure(Throwable throwable) {\n \t\t\t\tFutures.addCallback(result, callback);\n \t\t\t}\n \t\t}\n-\t\tupdatesCount.setValue(updatesSent);\n+\t\tupdatesCount.set(updatesSent);\n \n \t\tsynchronized (updatesConfirmed) {\n-\t\t\twhile (updatesSent != updatesConfirmed.get()) {\n-\t\t\t\tif (exception.get() != null) { // verify that no query failed until now\n-\t\t\t\t\tLOG.warn(\"Sending a value failed.\", exception.get());\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n+\t\t\twhile (exception.get() == null && updatesSent != updatesConfirmed.get()) {\n \t\t\t\tupdatesConfirmed.wait();\n \t\t\t}\n \t\t}\n-\t\tboolean success = updatesSent == updatesConfirmed.get();\n-\t\treturn success;\n+\n+\t\tif (exception.get() != null) {\n+\t\t\tLOG.warn(\"Sending a value failed.\", exception.get());\n+\t\t\treturn false;\n+\t\t} else {\n+\t\t\treturn true;\n+\t\t}\n \t}\n }",
                "raw_url": "https://github.com/apache/flink/raw/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java",
                "sha": "192843107ef3546b6a5896b1dd1a2564bd8529a8",
                "status": "modified"
            },
            {
                "additions": 39,
                "blob_url": "https://github.com/apache/flink/blob/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java",
                "changes": 109,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java?ref=74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90",
                "deletions": 70,
                "filename": "flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java",
                "patch": "@@ -25,39 +25,33 @@\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.java.tuple.Tuple0;\n import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n-import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;\n import org.apache.flink.streaming.runtime.operators.CheckpointCommitter;\n import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;\n-import org.apache.flink.util.IterableIterator;\n-import org.junit.Assert;\n import org.junit.Test;\n-import org.junit.runner.RunWith;\n import org.mockito.Matchers;\n import org.mockito.invocation.InvocationOnMock;\n import org.mockito.stubbing.Answer;\n-import org.powermock.core.classloader.annotations.PowerMockIgnore;\n-import org.powermock.core.classloader.annotations.PrepareForTest;\n-import org.powermock.modules.junit4.PowerMockRunner;\n \n-import java.util.Iterator;\n+import java.util.Collections;\n import java.util.concurrent.Executor;\n import java.util.concurrent.atomic.AtomicReference;\n \n+import static org.junit.Assert.assertFalse;\n import static org.mockito.Matchers.any;\n import static org.mockito.Matchers.anyString;\n import static org.powermock.api.mockito.PowerMockito.doAnswer;\n import static org.powermock.api.mockito.PowerMockito.mock;\n import static org.powermock.api.mockito.PowerMockito.when;\n \n-@RunWith(PowerMockRunner.class)\n-@PrepareForTest({ResultPartitionWriter.class, CassandraTupleWriteAheadSink.class})\n-@PowerMockIgnore({\"javax.management.*\", \"com.sun.jndi.*\"})\n-public class CassandraConnectorUnitTest {\n-\t@Test\n+public class CassandraTupleWriteAheadSinkTest {\n+\n+\t@Test(timeout=20000)\n \tpublic void testAckLoopExitOnException() throws Exception {\n-\t\tfinal AtomicReference<Runnable> callback = new AtomicReference<>();\n+\t\tfinal AtomicReference<Runnable> runnableFuture = new AtomicReference<>();\n \n \t\tfinal ClusterBuilder clusterBuilder = new ClusterBuilder() {\n+\t\t\tprivate static final long serialVersionUID = 4624400760492936756L;\n+\n \t\t\t@Override\n \t\t\tprotected Cluster buildCluster(Cluster.Builder builder) {\n \t\t\t\ttry {\n@@ -73,7 +67,10 @@ protected Cluster buildCluster(Cluster.Builder builder) {\n \t\t\t\t\tdoAnswer(new Answer<Void>() {\n \t\t\t\t\t\t@Override\n \t\t\t\t\t\tpublic Void answer(InvocationOnMock invocationOnMock) throws Throwable {\n-\t\t\t\t\t\t\tcallback.set((((Runnable) invocationOnMock.getArguments()[0])));\n+\t\t\t\t\t\t\tsynchronized (runnableFuture) {\n+\t\t\t\t\t\t\t\trunnableFuture.set((((Runnable) invocationOnMock.getArguments()[0])));\n+\t\t\t\t\t\t\t\trunnableFuture.notifyAll();\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t\treturn null;\n \t\t\t\t\t\t}\n \t\t\t\t\t}).when(future).addListener(any(Runnable.class), any(Executor.class));\n@@ -91,68 +88,40 @@ public Void answer(InvocationOnMock invocationOnMock) throws Throwable {\n \t\t\t}\n \t\t};\n \n-\t\tfinal IterableIterator<Tuple0> iter = new IterableIterator<Tuple0>() {\n-\t\t\tprivate boolean exhausted = false;\n-\n-\t\t\t@Override\n-\t\t\tpublic boolean hasNext() {\n-\t\t\t\treturn !exhausted;\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic Tuple0 next() {\n-\t\t\t\texhausted = true;\n-\t\t\t\treturn new Tuple0();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic void remove() {\n-\t\t\t}\n-\n+\t\t// Our asynchronous executor thread\n+\t\tnew Thread(new Runnable() {\n \t\t\t@Override\n-\t\t\tpublic Iterator<Tuple0> iterator() {\n-\t\t\t\treturn this;\n-\t\t\t}\n-\t\t};\n-\n-\t\tfinal AtomicReference<Boolean> exceptionCaught = new AtomicReference<>();\n-\n-\t\tThread t = new Thread() {\n \t\t\tpublic void run() {\n-\t\t\t\ttry {\n-\t\t\t\t\tCheckpointCommitter cc = mock(CheckpointCommitter.class);\n-\t\t\t\t\tfinal CassandraTupleWriteAheadSink<Tuple0> sink = new CassandraTupleWriteAheadSink<>(\n-\t\t\t\t\t\t\"abc\",\n-\t\t\t\t\t\tTupleTypeInfo.of(Tuple0.class).createSerializer(new ExecutionConfig()),\n-\t\t\t\t\t\tclusterBuilder,\n-\t\t\t\t\t\tcc\n-\t\t\t\t\t);\n-\n-\t\t\t\t\tOneInputStreamOperatorTestHarness<Tuple0, Tuple0> harness = new OneInputStreamOperatorTestHarness(sink);\n-\t\t\t\t\tharness.getEnvironment().getTaskConfiguration().setBoolean(\"checkpointing\", true);\n-\n-\t\t\t\t\tharness.setup();\n-\t\t\t\t\tsink.open();\n-\t\t\t\t\tboolean result = sink.sendValues(iter, 0L);\n-\t\t\t\t\tsink.close();\n-\t\t\t\t\texceptionCaught.set(result == false);\n-\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t\tsynchronized (runnableFuture) {\n+\t\t\t\t\twhile (runnableFuture.get() == null) {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\trunnableFuture.wait();\n+\t\t\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\t\t\t// ignore interrupts\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n \t\t\t\t}\n+\t\t\t\trunnableFuture.get().run();\n \t\t\t}\n-\t\t};\n-\t\tt.start();\n+\t\t}).start();\n+\n+\t\tCheckpointCommitter cc = mock(CheckpointCommitter.class);\n+\t\tfinal CassandraTupleWriteAheadSink<Tuple0> sink = new CassandraTupleWriteAheadSink<>(\n+\t\t\t\"abc\",\n+\t\t\tTupleTypeInfo.of(Tuple0.class).createSerializer(new ExecutionConfig()),\n+\t\t\tclusterBuilder,\n+\t\t\tcc\n+\t\t);\n \n-\t\tint count = 0;\n-\t\twhile (t.getState() != Thread.State.WAITING && count < 100) { // 10 second timeout 10 * 10 * 100ms\n-\t\t\tThread.sleep(100);\n-\t\t\tcount++;\n-\t\t}\n+\t\tOneInputStreamOperatorTestHarness<Tuple0, Tuple0> harness = new OneInputStreamOperatorTestHarness(sink);\n+\t\tharness.getEnvironment().getTaskConfiguration().setBoolean(\"checkpointing\", true);\n \n-\t\tcallback.get().run();\n+\t\tharness.setup();\n+\t\tsink.open();\n \n-\t\tt.join();\n+\t\t// we should leave the loop and return false since we've seen an exception\n+\t\tassertFalse(sink.sendValues(Collections.singleton(new Tuple0()), 0L));\n \n-\t\tAssert.assertTrue(exceptionCaught.get());\n+\t\tsink.close();\n \t}\n }",
                "previous_filename": "flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraConnectorUnitTest.java",
                "raw_url": "https://github.com/apache/flink/raw/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java",
                "sha": "847d1a049e576a6f650fe84192e9719e55d1c966",
                "status": "renamed"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flink/blob/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java?ref=74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90",
                "deletions": 0,
                "filename": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java",
                "patch": "@@ -190,6 +190,9 @@ public void processWatermark(Watermark mark) throws Exception {\n \t * used since the last completed checkpoint.\n \t **/\n \tpublic static class ExactlyOnceState implements StateHandle<Serializable> {\n+\n+\t\tprivate static final long serialVersionUID = -3571063495273460743L;\n+\n \t\tprotected TreeMap<Long, Tuple2<Long, StateHandle<DataInputView>>> pendingHandles;\n \n \t\tpublic ExactlyOnceState() {",
                "raw_url": "https://github.com/apache/flink/raw/74b09ce0db4d24a0ac25de2ecac391fdf8bd5a90/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java",
                "sha": "5545717b24466fc5e1c6ae209c7323c9e551a8eb",
                "status": "modified"
            }
        ],
        "message": "[FLINK-4123] [cassandra] Fix concurrency issue in CassandraTupleWriteAheadSink\n\nThe updatesCount variable in the CassandraTupleWriteAheadSink.sendValues did not have\nguaranteed visibility. Thus, it was possible that the callback thread would read an\noutdated value for updatesCount, resulting in a deadlock. Replacing IntValue updatesCount\nwith AtomicInteger updatesCount fixes this issue.\n\nFurthermore, the PR hardens the CassandraTupleWriteAheadSinkTest which could have failed\nwith a NPE if the callback runnable was not set in time.",
        "parent": "https://github.com/apache/flink/commit/5c2da21f25741502dd8ca64ce9d314a1ebea1441",
        "repo": "flink",
        "unit_tests": [
            "GenericWriteAheadSinkTest.java"
        ]
    },
    "flink_9e139a7": {
        "bug_id": "flink_9e139a7",
        "commit": "https://github.com/apache/flink/commit/9e139a72ba45f2dd820bd3b9ecdf8428588666fd",
        "file": [
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/flink/blob/9e139a72ba45f2dd820bd3b9ecdf8428588666fd/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java?ref=9e139a72ba45f2dd820bd3b9ecdf8428588666fd",
                "deletions": 11,
                "filename": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java",
                "patch": "@@ -591,17 +591,20 @@ public void collect(StreamRecord<T> record) {\n \t\t\t\toperator.setKeyContextElement1(copy);\n \t\t\t\toperator.processElement(copy);\n \t\t\t} catch (ClassCastException e) {\n-\t\t\t\t// Enrich error message\n-\t\t\t\tClassCastException replace = new ClassCastException(\n-\t\t\t\t\tString.format(\n-\t\t\t\t\t\t\"%s. Failed to push OutputTag with id '%s' to operator. \" +\n-\t\t\t\t\t\t\"This can occur when multiple OutputTags with different types \" +\n-\t\t\t\t\t\t\"but identical names are being used.\",\n-\t\t\t\t\t\te.getMessage(),\n-\t\t\t\t\t\toutputTag.getId()));\n-\n-\t\t\t\tthrow new ExceptionInChainedOperatorException(replace);\n-\n+\t\t\t\tif (outputTag != null) {\n+\t\t\t\t\t// Enrich error message\n+\t\t\t\t\tClassCastException replace = new ClassCastException(\n+\t\t\t\t\t\tString.format(\n+\t\t\t\t\t\t\t\"%s. Failed to push OutputTag with id '%s' to operator. \" +\n+\t\t\t\t\t\t\t\t\"This can occur when multiple OutputTags with different types \" +\n+\t\t\t\t\t\t\t\t\"but identical names are being used.\",\n+\t\t\t\t\t\t\te.getMessage(),\n+\t\t\t\t\t\t\toutputTag.getId()));\n+\n+\t\t\t\t\tthrow new ExceptionInChainedOperatorException(replace);\n+\t\t\t\t} else {\n+\t\t\t\t\tthrow new ExceptionInChainedOperatorException(e);\n+\t\t\t\t}\n \t\t\t} catch (Exception e) {\n \t\t\t\tthrow new ExceptionInChainedOperatorException(e);\n \t\t\t}",
                "raw_url": "https://github.com/apache/flink/raw/9e139a72ba45f2dd820bd3b9ecdf8428588666fd/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java",
                "sha": "f3c7293fe1b17e04a8057c56aa4c2af732ae68e5",
                "status": "modified"
            }
        ],
        "message": "[FLINK-8423] OperatorChain#pushToOperator catch block may fail with NPE\n\nThis closes #5447.",
        "parent": "https://github.com/apache/flink/commit/24c30878ed6f6ed1599a5ec23362055e0e88916f",
        "repo": "flink",
        "unit_tests": [
            "OperatorChainTest.java"
        ]
    },
    "flink_a0249d9": {
        "bug_id": "flink_a0249d9",
        "commit": "https://github.com/apache/flink/commit/a0249d9935d54fbd6bb6c2cc130f51ce2ccafac3",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/flink/blob/a0249d9935d54fbd6bb6c2cc130f51ce2ccafac3/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/KinesisDataFetcher.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/KinesisDataFetcher.java?ref=a0249d9935d54fbd6bb6c2cc130f51ce2ccafac3",
                "deletions": 2,
                "filename": "flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/KinesisDataFetcher.java",
                "patch": "@@ -149,7 +149,7 @@\n \tprivate final KinesisProxyInterface kinesis;\n \n \t/** Thread that executed runFetcher() */\n-\tprivate Thread mainThread;\n+\tprivate volatile Thread mainThread;\n \n \t/**\n \t * The current number of shards that are actively read by this fetcher.\n@@ -408,7 +408,10 @@ public void runFetcher() throws Exception {\n \t */\n \tpublic void shutdownFetcher() {\n \t\trunning = false;\n-\t\tmainThread.interrupt(); // the main thread may be sleeping for the discovery interval\n+\n+\t\tif (mainThread != null) {\n+\t\t\tmainThread.interrupt(); // the main thread may be sleeping for the discovery interval\n+\t\t}\n \n \t\tif (LOG.isInfoEnabled()) {\n \t\t\tLOG.info(\"Shutting down the shard consumer threads of subtask {} ...\", indexOfThisConsumerSubtask);",
                "raw_url": "https://github.com/apache/flink/raw/a0249d9935d54fbd6bb6c2cc130f51ce2ccafac3/flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/KinesisDataFetcher.java",
                "sha": "8f7ca6c40f1e4871054374ae6b49797a665fdb15",
                "status": "modified"
            }
        ],
        "message": "[FLINK-6311] [kinesis] NPE in FlinkKinesisConsumer if source was closed before run\n\nThis closes #3738.",
        "parent": "https://github.com/apache/flink/commit/42328bd9b7f216e4c3aae2086b822b4a3a564970",
        "repo": "flink",
        "unit_tests": [
            "KinesisDataFetcherTest.java"
        ]
    },
    "flink_a442eb6": {
        "bug_id": "flink_a442eb6",
        "commit": "https://github.com/apache/flink/commit/a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/high_availability_zookeeper_configuration.html",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/high_availability_zookeeper_configuration.html?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 1,
                "filename": "docs/_includes/generated/high_availability_zookeeper_configuration.html",
                "patch": "@@ -60,7 +60,7 @@\n         <tr>\n             <td><h5>high-availability.zookeeper.path.mesos-workers</h5></td>\n             <td style=\"word-wrap: break-word;\">\"/mesos-workers\"</td>\n-            <td>ZooKeeper root path (ZNode) for Mesos workers.</td>\n+            <td>The ZooKeeper root path for persisting the Mesos worker information.</td>\n         </tr>\n         <tr>\n             <td><h5>high-availability.zookeeper.path.root</h5></td>",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/high_availability_zookeeper_configuration.html",
                "sha": "6577878674b3de994b64bd5f540ce14ba1e4d249",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/mesos_configuration.html",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/mesos_configuration.html?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 4,
                "filename": "docs/_includes/generated/mesos_configuration.html",
                "patch": "@@ -15,17 +15,17 @@\n         <tr>\n             <td><h5>mesos.initial-tasks</h5></td>\n             <td style=\"word-wrap: break-word;\">0</td>\n-            <td>The initial workers to bring up when the master starts</td>\n+            <td>The initial workers to bring up when the master starts. This option is ignored unless Flink is in <a href=\"#legacy\">legacy mode</a>.</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.master</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>The Mesos master URL. The value should be in one of the following forms: \"host:port\", \"zk://host1:port1,host2:port2,.../path\", \"zk://username:password@host1:port1,host2:port2,.../path\" or \"file:///path/to/file\"</td>\n+            <td>The Mesos master URL. The value should be in one of the following forms: <ul><li>host:port</li><li>zk://host1:port1,host2:port2,.../path</li><li>zk://username:password@host1:port1,host2:port2,.../path</li><li>file:///path/to/file</li></ul></td>\n         </tr>\n         <tr>\n             <td><h5>mesos.maximum-failed-tasks</h5></td>\n             <td style=\"word-wrap: break-word;\">-1</td>\n-            <td>The maximum number of failed workers before the cluster fails. May be set to -1 to disable this feature</td>\n+            <td>The maximum number of failed workers before the cluster fails. May be set to -1 to disable this feature. This option is ignored unless Flink is in <a href=\"#legacy\">legacy mode</a>.</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.resourcemanager.artifactserver.port</h5></td>\n@@ -65,7 +65,7 @@\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.port-assignments</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Comma-separated list of configuration keys which represent a configurable port.All port keys will dynamically get a port assigned through Mesos.</td>\n+            <td>Comma-separated list of configuration keys which represent a configurable port. All port keys will dynamically get a port assigned through Mesos.</td>\n         </tr>\n     </tbody>\n </table>",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/mesos_configuration.html",
                "sha": "54e92e5680c51e766cc07c1a976eb52aca573280",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/mesos_task_manager_configuration.html",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/_includes/generated/mesos_task_manager_configuration.html?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 4,
                "filename": "docs/_includes/generated/mesos_task_manager_configuration.html",
                "patch": "@@ -10,12 +10,12 @@\n         <tr>\n             <td><h5>mesos.constraints.hard.hostattribute</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td>Constraints for task placement on mesos.</td>\n+            <td>Constraints for task placement on Mesos based on agent attributes. Takes a comma-separated list of key:value pairs corresponding to the attributes exposed by the target mesos agents. Example: az:eu-west-1a,series:t2</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.bootstrap-cmd</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td></td>\n+            <td>A command which is executed before the TaskManager is started.</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.container.docker.force-pull-image</h5></td>\n@@ -50,12 +50,12 @@\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.gpus</h5></td>\n             <td style=\"word-wrap: break-word;\">0</td>\n-            <td></td>\n+            <td>GPUs to assign to the Mesos workers.</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.hostname</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>\n-            <td></td>\n+            <td>Optional value to define the TaskManager\u2019s hostname. The pattern _TASK_ is replaced by the actual id of the Mesos task. This can be used to configure the TaskManager to use Mesos DNS (e.g. _TASK_.flink-service.mesos) for name lookups.</td>\n         </tr>\n         <tr>\n             <td><h5>mesos.resourcemanager.tasks.mem</h5></td>",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/_includes/generated/mesos_task_manager_configuration.html",
                "sha": "1e67f8429d74665ac0033d38fd26a330f2c4a892",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/ops/deployment/mesos.md",
                "changes": 83,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/ops/deployment/mesos.md?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 69,
                "filename": "docs/ops/deployment/mesos.md",
                "patch": "@@ -59,13 +59,11 @@ or configuration files. For instance, in non-containerized environments, the\n artifact server will provide the Flink binaries. What files will be served\n depends on the configuration overlay used.\n \n-### Flink's JobManager and Web Interface\n+### Flink's Dispatcher and Web Interface\n \n-The Mesos scheduler currently resides with the JobManager but will be started\n-independently of the JobManager in future versions (see\n-[FLIP-6](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077)). The\n-proposed changes will also add a Dispatcher component which will be the central\n-point for job submission and monitoring.\n+The Dispatcher and the web interface provide a central point for monitoring,\n+job submission, and other client interaction with the cluster\n+(see [FLIP-6](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077)).\n \n ### Startup script and configuration overlays\n \n@@ -139,7 +137,7 @@ More information about the deployment scripts can be found [here](http://mesos.a\n \n ### Installing Marathon\n \n-Optionally, you may also [install Marathon](https://mesosphere.github.io/marathon/docs/) which will be necessary to run Flink in high availability (HA) mode.\n+Optionally, you may also [install Marathon](https://mesosphere.github.io/marathon/docs/) which enables you to run Flink in [high availability (HA) mode](#high-availability).\n \n ### Pre-installing Flink vs Docker/Mesos containers\n \n@@ -171,8 +169,6 @@ which manage the Flink processes in a Mesos cluster:\n    It is automatically launched by the Mesos worker node to bring up a new TaskManager.\n \n In order to run the `mesos-appmaster.sh` script you have to define `mesos.master` in the `flink-conf.yaml` or pass it via `-Dmesos.master=...` to the Java process.\n-Additionally, you should define the number of task managers which are started by Mesos via `mesos.initial-tasks`.\n-This value can also be defined in the `flink-conf.yaml` or passed as a Java property.\n \n When executing `mesos-appmaster.sh`, it will create a job manager on the machine where you executed the script.\n In contrast to that, the task managers will be run as Mesos tasks in the Mesos cluster.\n@@ -188,19 +184,21 @@ For example:\n         -Djobmanager.heap.mb=1024 \\\n         -Djobmanager.rpc.port=6123 \\\n         -Drest.port=8081 \\\n-        -Dmesos.initial-tasks=10 \\\n         -Dmesos.resourcemanager.tasks.mem=4096 \\\n         -Dtaskmanager.heap.mb=3500 \\\n         -Dtaskmanager.numberOfTaskSlots=2 \\\n         -Dparallelism.default=10\n \n+<div class=\"alert alert-info\">\n+  <strong>Note:</strong> If Flink is in <a href=\"{{ site.baseurl }}/ops/config.html#legacy\">legacy mode</a>,\n+  you should additionally define the number of task managers that are started by Mesos via\n+  <a href=\"{{ site.baseurl }}/ops/config.html#mesos-initial-tasks\"><code>mesos.initial-tasks</code></a>.\n+</div>\n \n ### High Availability\n \n You will need to run a service like Marathon or Apache Aurora which takes care of restarting the Flink master process in case of node or process failures.\n-In addition, Zookeeper needs to be configured like described in the [High Availability section of the Flink docs]({{ site.baseurl }}/ops/jobmanager_high_availability.html)\n-\n-For the reconciliation of tasks to work correctly, please also set `high-availability.zookeeper.path.mesos-workers` to a valid Zookeeper path.\n+In addition, Zookeeper needs to be configured like described in the [High Availability section of the Flink docs]({{ site.baseurl }}/ops/jobmanager_high_availability.html).\n \n #### Marathon\n \n@@ -211,7 +209,7 @@ Here is an example configuration for Marathon:\n \n     {\n         \"id\": \"flink\",\n-        \"cmd\": \"$FLINK_HOME/bin/mesos-appmaster.sh -Djobmanager.heap.mb=1024 -Djobmanager.rpc.port=6123 -Drest.port=8081 -Dmesos.initial-tasks=1 -Dmesos.resourcemanager.tasks.mem=1024 -Dtaskmanager.heap.mb=1024 -Dtaskmanager.numberOfTaskSlots=2 -Dparallelism.default=2 -Dmesos.resourcemanager.tasks.cpus=1\",\n+        \"cmd\": \"$FLINK_HOME/bin/mesos-appmaster.sh -Djobmanager.heap.mb=1024 -Djobmanager.rpc.port=6123 -Drest.port=8081 -Dmesos.resourcemanager.tasks.mem=1024 -Dtaskmanager.heap.mb=1024 -Dtaskmanager.numberOfTaskSlots=2 -Dparallelism.default=2 -Dmesos.resourcemanager.tasks.cpus=1\",\n         \"cpus\": 1.0,\n         \"mem\": 1024\n     }\n@@ -220,60 +218,7 @@ When running Flink with Marathon, the whole Flink cluster including the job mana\n \n ### Configuration parameters\n \n-`mesos.initial-tasks`: The initial workers to bring up when the master starts (**DEFAULT**: The number of workers specified at cluster startup).\n-\n-`mesos.constraints.hard.hostattribute`: Constraints for task placement on Mesos based on agent attributes (**DEFAULT**: None).\n-Takes a comma-separated list of key:value pairs corresponding to the attributes exposed by the target\n-mesos agents.  Example: `az:eu-west-1a,series:t2`\n-\n-`mesos.maximum-failed-tasks`: The maximum number of failed workers before the cluster fails (**DEFAULT**: Number of initial workers).\n-May be set to -1 to disable this feature.\n-\n-`mesos.master`: The Mesos master URL. The value should be in one of the following forms:\n-\n-* `host:port`\n-* `zk://host1:port1,host2:port2,.../path`\n-* `zk://username:password@host1:port1,host2:port2,.../path`\n-* `file:///path/to/file`\n-\n-`mesos.failover-timeout`: The failover timeout in seconds for the Mesos scheduler, after which running tasks are automatically shut down (**DEFAULT:** 600).\n-\n-`mesos.resourcemanager.artifactserver.port`:The config parameter defining the Mesos artifact server port to use. Setting the port to 0 will let the OS choose an available port.\n-\n-`mesos.resourcemanager.framework.name`: Mesos framework name (**DEFAULT:** Flink)\n-\n-`mesos.resourcemanager.framework.role`: Mesos framework role definition (**DEFAULT:** *)\n-\n-`high-availability.zookeeper.path.mesos-workers`: The ZooKeeper root path for persisting the Mesos worker information.\n-\n-`mesos.resourcemanager.framework.principal`: Mesos framework principal (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.framework.secret`: Mesos framework secret (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.framework.user`: Mesos framework user (**DEFAULT:**\"\")\n-\n-`mesos.resourcemanager.artifactserver.ssl.enabled`: Enables SSL for the Flink artifact server (**DEFAULT**: true). Note that `security.ssl.enabled` also needs to be set to `true` encryption to enable encryption.\n-\n-`mesos.resourcemanager.tasks.mem`: Memory to assign to the Mesos workers in MB (**DEFAULT**: 1024)\n-\n-`mesos.resourcemanager.tasks.cpus`: CPUs to assign to the Mesos workers (**DEFAULT**: 0.0)\n-\n-`mesos.resourcemanager.tasks.gpus`: GPUs to assign to the Mesos workers (**DEFAULT**: 0.0)\n-\n-`mesos.resourcemanager.tasks.container.type`: Type of the containerization used: \"mesos\" or \"docker\" (DEFAULT: mesos);\n-\n-`mesos.resourcemanager.tasks.container.image.name`: Image name to use for the container (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.tasks.container.volumes`: A comma separated list of `[host_path:]`container_path`[:RO|RW]`. This allows for mounting additional volumes into your container. (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.tasks.container.docker.parameters`: Custom parameters to be passed into docker run command when using the docker containerizer. Comma separated list of `key=value` pairs. `value` may contain '=' (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.tasks.uris`: A comma separated list of URIs of custom artifacts to be downloaded into the sandbox of Mesos workers. (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.tasks.container.docker.force-pull-image`: Instruct the docker containerizer to forcefully pull the image rather than reuse a cached version. (**DEFAULT**: false)\n-\n-`mesos.resourcemanager.tasks.hostname`: Optional value to define the TaskManager's hostname. The pattern `_TASK_` is replaced by the actual id of the Mesos task. This can be used to configure the TaskManager to use Mesos DNS (e.g. `_TASK_.flink-service.mesos`) for name lookups. (**NO DEFAULT**)\n-\n-`mesos.resourcemanager.tasks.bootstrap-cmd`: A command which is executed before the TaskManager is started (**NO DEFAULT**).\n+For a list of Mesos specific configuration, refer to the [Mesos section]({{ site.baseurl }}/ops/config.html#mesos)\n+of the configuration documentation.\n \n {% top %}",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/docs/ops/deployment/mesos.md",
                "sha": "1ff8afad74ebb5edd81836abe3e4e1d53b78e21c",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-core/src/main/java/org/apache/flink/configuration/HighAvailabilityOptions.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-core/src/main/java/org/apache/flink/configuration/HighAvailabilityOptions.java?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 1,
                "filename": "flink-core/src/main/java/org/apache/flink/configuration/HighAvailabilityOptions.java",
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.flink.annotation.docs.ConfigGroup;\n import org.apache.flink.annotation.docs.ConfigGroups;\n import org.apache.flink.annotation.docs.Documentation;\n+import org.apache.flink.configuration.description.Description;\n \n import static org.apache.flink.configuration.ConfigOptions.key;\n \n@@ -157,7 +158,9 @@\n \t\t\tkey(\"high-availability.zookeeper.path.mesos-workers\")\n \t\t\t.defaultValue(\"/mesos-workers\")\n \t\t\t.withDeprecatedKeys(\"recovery.zookeeper.path.mesos-workers\")\n-\t\t\t.withDescription(\"ZooKeeper root path (ZNode) for Mesos workers.\");\n+\t\t\t.withDescription(Description.builder()\n+\t\t\t\t.text(\"The ZooKeeper root path for persisting the Mesos worker information.\")\n+\t\t\t\t.build());\n \n \t// ------------------------------------------------------------------------\n \t//  ZooKeeper Client Settings",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-core/src/main/java/org/apache/flink/configuration/HighAvailabilityOptions.java",
                "sha": "787efffa3ede1004219cfd4d5192cb75c4e7b692",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-mesos/src/main/java/org/apache/flink/mesos/configuration/MesosOptions.java",
                "changes": 31,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-mesos/src/main/java/org/apache/flink/mesos/configuration/MesosOptions.java?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 8,
                "filename": "flink-mesos/src/main/java/org/apache/flink/mesos/configuration/MesosOptions.java",
                "patch": "@@ -19,6 +19,9 @@\n package org.apache.flink.mesos.configuration;\n \n import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.description.Description;\n+import org.apache.flink.configuration.description.LinkElement;\n+import org.apache.flink.configuration.description.TextElement;\n \n import static org.apache.flink.configuration.ConfigOptions.key;\n \n@@ -33,7 +36,10 @@\n \tpublic static final ConfigOption<Integer> INITIAL_TASKS =\n \t\tkey(\"mesos.initial-tasks\")\n \t\t\t.defaultValue(0)\n-\t\t\t.withDescription(\"The initial workers to bring up when the master starts\");\n+\t\t\t.withDescription(Description.builder()\n+\t\t\t\t.text(\"The initial workers to bring up when the master starts. \")\n+\t\t\t\t.text(\"This option is ignored unless Flink is in %s.\", LinkElement.link(\"#legacy\", \"legacy mode\"))\n+\t\t\t\t.build());\n \n \t/**\n \t * The maximum number of failed Mesos tasks before entirely stopping\n@@ -44,8 +50,10 @@\n \tpublic static final ConfigOption<Integer> MAX_FAILED_TASKS =\n \t\tkey(\"mesos.maximum-failed-tasks\")\n \t\t\t.defaultValue(-1)\n-\t\t\t.withDescription(\"The maximum number of failed workers before the cluster fails. May be set to -1 to disable\" +\n-\t\t\t\t\" this feature\");\n+\t\t\t.withDescription(Description.builder()\n+\t\t\t\t.text(\"The maximum number of failed workers before the cluster fails. May be set to -1 to disable this feature. \")\n+\t\t\t\t.text(\"This option is ignored unless Flink is in %s.\", LinkElement.link(\"#legacy\", \"legacy mode\"))\n+\t\t\t\t.build());\n \n \t/**\n \t * The Mesos master URL.\n@@ -63,9 +71,14 @@\n \tpublic static final ConfigOption<String> MASTER_URL =\n \t\tkey(\"mesos.master\")\n \t\t\t.noDefaultValue()\n-\t\t\t.withDescription(\"The Mesos master URL. The value should be in one of the following forms:\" +\n-\t\t\t\t\" \\\"host:port\\\", \\\"zk://host1:port1,host2:port2,.../path\\\",\" +\n-\t\t\t\t\" \\\"zk://username:password@host1:port1,host2:port2,.../path\\\" or \\\"file:///path/to/file\\\"\");\n+\t\t\t.withDescription(Description.builder()\n+\t\t\t\t.text(\"The Mesos master URL. The value should be in one of the following forms: \")\n+\t\t\t\t.list(\n+\t\t\t\t\tTextElement.text(\"host:port\"),\n+\t\t\t\t\tTextElement.text(\"zk://host1:port1,host2:port2,.../path\"),\n+\t\t\t\t\tTextElement.text(\"zk://username:password@host1:port1,host2:port2,.../path\"),\n+\t\t\t\t\tTextElement.text(\"file:///path/to/file\"))\n+\t\t\t\t.build());\n \n \t/**\n \t * The failover timeout for the Mesos scheduler, after which running tasks are automatically shut down.\n@@ -125,7 +138,9 @@\n \t */\n \tpublic static final ConfigOption<String> PORT_ASSIGNMENTS = key(\"mesos.resourcemanager.tasks.port-assignments\")\n \t\t.defaultValue(\"\")\n-\t\t.withDescription(\"Comma-separated list of configuration keys which represent a configurable port.\" +\n-\t\t\t\"All port keys will dynamically get a port assigned through Mesos.\");\n+\t\t.withDescription(Description.builder()\n+\t\t\t.text(\"Comma-separated list of configuration keys which represent a configurable port. \" +\n+\t\t\t\t\"All port keys will dynamically get a port assigned through Mesos.\")\n+\t\t\t.build());\n \n }",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-mesos/src/main/java/org/apache/flink/mesos/configuration/MesosOptions.java",
                "sha": "426a891e814237e410169e04c8210e2b4da9667b",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/flink/blob/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-mesos/src/main/java/org/apache/flink/mesos/runtime/clusterframework/MesosTaskManagerParameters.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-mesos/src/main/java/org/apache/flink/mesos/runtime/clusterframework/MesosTaskManagerParameters.java?ref=a442eb6c0388558c6fb2e5e616cd1cd15038b95c",
                "deletions": 4,
                "filename": "flink-mesos/src/main/java/org/apache/flink/mesos/runtime/clusterframework/MesosTaskManagerParameters.java",
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.flink.configuration.Configuration;\n import org.apache.flink.configuration.IllegalConfigurationException;\n import org.apache.flink.configuration.TaskManagerOptions;\n+import org.apache.flink.configuration.description.Description;\n import org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters;\n import org.apache.flink.util.Preconditions;\n \n@@ -65,7 +66,8 @@\n \n \tpublic static final ConfigOption<Integer> MESOS_RM_TASKS_GPUS =\n \t\tkey(\"mesos.resourcemanager.tasks.gpus\")\n-\t\t.defaultValue(0);\n+\t\t.defaultValue(0)\n+\t\t.withDescription(Description.builder().text(\"GPUs to assign to the Mesos workers.\").build());\n \n \tpublic static final ConfigOption<String> MESOS_RM_CONTAINER_TYPE =\n \t\tkey(\"mesos.resourcemanager.tasks.container.type\")\n@@ -79,15 +81,23 @@\n \n \tpublic static final ConfigOption<String> MESOS_TM_HOSTNAME =\n \t\tkey(\"mesos.resourcemanager.tasks.hostname\")\n-\t\t.noDefaultValue();\n+\t\t.noDefaultValue()\n+\t\t.withDescription(Description.builder()\n+\t\t\t.text(\"Optional value to define the TaskManager\u2019s hostname. \" +\n+\t\t\t\t\"The pattern _TASK_ is replaced by the actual id of the Mesos task. \" +\n+\t\t\t\t\"This can be used to configure the TaskManager to use Mesos DNS (e.g. _TASK_.flink-service.mesos) for name lookups.\")\n+\t\t\t.build());\n \n \tpublic static final ConfigOption<String> MESOS_TM_CMD =\n \t\tkey(\"mesos.resourcemanager.tasks.taskmanager-cmd\")\n \t\t.defaultValue(\"$FLINK_HOME/bin/mesos-taskmanager.sh\"); // internal\n \n \tpublic static final ConfigOption<String> MESOS_TM_BOOTSTRAP_CMD =\n \t\tkey(\"mesos.resourcemanager.tasks.bootstrap-cmd\")\n-\t\t.noDefaultValue();\n+\t\t.noDefaultValue()\n+\t\t.withDescription(Description.builder()\n+\t\t\t.text(\"A command which is executed before the TaskManager is started.\")\n+\t\t\t.build());\n \n \tpublic static final ConfigOption<String> MESOS_TM_URIS =\n \t\tkey(\"mesos.resourcemanager.tasks.uris\")\n@@ -116,7 +126,11 @@\n \tpublic static final ConfigOption<String> MESOS_CONSTRAINTS_HARD_HOSTATTR =\n \t\tkey(\"mesos.constraints.hard.hostattribute\")\n \t\t.noDefaultValue()\n-\t\t.withDescription(\"Constraints for task placement on mesos.\");\n+\t\t.withDescription(Description.builder()\n+\t\t\t.text(\"Constraints for task placement on Mesos based on agent attributes. \" +\n+\t\t\t\t\"Takes a comma-separated list of key:value pairs corresponding to the attributes exposed by the target mesos agents. \" +\n+\t\t\t\t\"Example: az:eu-west-1a,series:t2\")\n+\t\t\t.build());\n \n \t/**\n \t * Value for {@code MESOS_RESOURCEMANAGER_TASKS_CONTAINER_TYPE} setting. Tells to use the Mesos containerizer.",
                "raw_url": "https://github.com/apache/flink/raw/a442eb6c0388558c6fb2e5e616cd1cd15038b95c/flink-mesos/src/main/java/org/apache/flink/mesos/runtime/clusterframework/MesosTaskManagerParameters.java",
                "sha": "03156297188617e6670e72900264658fe6ec78e4",
                "status": "modified"
            }
        ],
        "message": "[FLINK-9795][mesos, docs] Update Mesos documentation\n\n[FLINK-9795][mesos, docs] Remove unnecessary remark about task reconciliation.\n\nThe config key high-availability.zookeeper.path.mesos-workers already has a\ndefault value. Even without explicitly setting the key, the task reconciliation\nwill work. Moreover, if there would not be a default key, the code would throw an NPE. So\neither way, the remark is only confusing the reader.\n\n[FLINK-9795][mesos, docs] Remove configuration keys from Mesos Setup page.\n\n- Remove the Mesos specific configuration keys from the Mesos Setup page because\nthey duplicate what is already on the configuration page.\n- Add missing descriptions for some of the keys that are under the Mesos section of the configuration\npage.\n- Improve formatting of the descriptions.\n\n[FLINK-9795][mesos, docs] Document which config options are only used in legacy mode.\n\n[FLINK-9795][mesos, docs] Document that mesos.initial-tasks is only needed in legacy mode.\n\n[FLINK-9795][mesos, docs] Clarify necessity of Marathon in documentation.\n\n[FLINK-9795][mesos, docs] Rewrite \"Flink's JobManager and Web Interface\" section.\n\n[FLINK-9795][mesos, docs] Add missing period at the end of sentence.\n\nThis closes #6533.",
        "parent": "https://github.com/apache/flink/commit/04ba9a85920bcab6c7b6c001a58c7570e987aabb",
        "repo": "flink",
        "unit_tests": [
            "MesosTaskManagerParametersTest.java"
        ]
    },
    "flink_b2c592a": {
        "bug_id": "flink_b2c592a",
        "commit": "https://github.com/apache/flink/commit/b2c592a87139c587777f9897613943639fac1d61",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/flink/blob/b2c592a87139c587777f9897613943639fac1d61/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java?ref=b2c592a87139c587777f9897613943639fac1d61",
                "deletions": 1,
                "filename": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java",
                "patch": "@@ -427,7 +427,7 @@ public void afterBulk(long executionId, BulkRequest request, BulkResponse respon\n \n \t\t@Override\n \t\tpublic void afterBulk(long executionId, BulkRequest request, Throwable failure) {\n-\t\t\tLOG.error(\"Failed Elasticsearch bulk request: {}\", failure.getMessage(), failure.getCause());\n+\t\t\tLOG.error(\"Failed Elasticsearch bulk request: {}\", failure.getMessage(), failure);\n \n \t\t\ttry {\n \t\t\t\tfor (ActionRequest action : request.requests()) {",
                "raw_url": "https://github.com/apache/flink/raw/b2c592a87139c587777f9897613943639fac1d61/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java",
                "sha": "96f4431493c9f6348f8675439391558c242360d7",
                "status": "modified"
            }
        ],
        "message": "[hotfix] [connectors] Fix shadowed NPE in elasticsearch sink connector\n\nThis closes #8849.",
        "parent": "https://github.com/apache/flink/commit/861bf73ada01e4d2d8c671e507974e5bfacd9218",
        "repo": "flink",
        "unit_tests": [
            "ElasticsearchSinkBaseTest.java"
        ]
    },
    "flink_c5dd1f1": {
        "bug_id": "flink_c5dd1f1",
        "commit": "https://github.com/apache/flink/commit/c5dd1f11f71471ba42e3a075651649e2ca258551",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/c5dd1f11f71471ba42e3a075651649e2ca258551/pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/Ordering.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/Ordering.java?ref=c5dd1f11f71471ba42e3a075651649e2ca258551",
                "deletions": 2,
                "filename": "pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/Ordering.java",
                "patch": "@@ -180,8 +180,10 @@ public String toString()\n \t\t\t\tbuf.append(\",\");\n \t\t\t}\n \t\t\tbuf.append(this.indexes.get(i));\n-\t\t\tbuf.append(\":\");\n-\t\t\tbuf.append(this.types.get(i).getName());\n+\t\t\tif (this.types.get(i) != null) {\n+\t\t\t\tbuf.append(\":\");\n+\t\t\t\tbuf.append(this.types.get(i).getName());\n+\t\t\t}\n \t\t\tbuf.append(\":\");\n \t\t\tbuf.append(this.orders.get(i).name());\n \t\t}",
                "raw_url": "https://github.com/apache/flink/raw/c5dd1f11f71471ba42e3a075651649e2ca258551/pact/pact-common/src/main/java/eu/stratosphere/pact/common/contract/Ordering.java",
                "sha": "ca0e4f8e38e1825fea35a9a382e5642ab5ce8615",
                "status": "modified"
            }
        ],
        "message": "Fix NPE in Ordering toString method: Keytypes may be null",
        "parent": "https://github.com/apache/flink/commit/692318593be6e5f7aa5fc62bf624ef34cb5a357a",
        "repo": "flink",
        "unit_tests": [
            "OrderingTest.java"
        ]
    },
    "flink_d7911c5": {
        "bug_id": "flink_d7911c5",
        "commit": "https://github.com/apache/flink/commit/d7911c5a8a6896261c55b61ea4633e706270baa1",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/flink/blob/d7911c5a8a6896261c55b61ea4633e706270baa1/flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java?ref=d7911c5a8a6896261c55b61ea4633e706270baa1",
                "deletions": 2,
                "filename": "flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java",
                "patch": "@@ -414,8 +414,10 @@ private void initFileSystem() throws IOException {\n \n \t@Override\n \tpublic void close() throws Exception {\n-\t\tfor (Map.Entry<String, BucketState<T>> entry : state.bucketStates.entrySet()) {\n-\t\t\tcloseCurrentPartFile(entry.getValue());\n+\t\tif (state != null) {\n+\t\t\tfor (Map.Entry<String, BucketState<T>> entry : state.bucketStates.entrySet()) {\n+\t\t\t\tcloseCurrentPartFile(entry.getValue());\n+\t\t\t}\n \t\t}\n \t}\n ",
                "raw_url": "https://github.com/apache/flink/raw/d7911c5a8a6896261c55b61ea4633e706270baa1/flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java",
                "sha": "db0a5d859bed4592627860748d687762a35964a7",
                "status": "modified"
            }
        ],
        "message": "[FLINK-6294] Fix potential NPE in BucketingSink.close()",
        "parent": "https://github.com/apache/flink/commit/d7c2c417213502130b1aeab1868313df178555cc",
        "repo": "flink",
        "unit_tests": [
            "BucketingSinkTest.java"
        ]
    },
    "flink_eece0dd": {
        "bug_id": "flink_eece0dd",
        "commit": "https://github.com/apache/flink/commit/eece0dd05bc38b88fcb6cbcef15add7f98eab456",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/flink/blob/eece0dd05bc38b88fcb6cbcef15add7f98eab456/flink-streaming-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09Fetcher.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-streaming-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09Fetcher.java?ref=eece0dd05bc38b88fcb6cbcef15add7f98eab456",
                "deletions": 2,
                "filename": "flink-streaming-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09Fetcher.java",
                "patch": "@@ -291,9 +291,9 @@ public void commitSpecificOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets)\n \t\tfor (KafkaTopicPartitionState<TopicPartition> partition : partitions) {\n \t\t\t// committed offsets through the KafkaConsumer need to be 1 more than the last processed offset.\n \t\t\t// This does not affect Flink's checkpoints/saved state.\n-\t\t\tLong offsetToCommit = offsets.get(partition.getKafkaTopicPartition()) + 1;\n+\t\t\tLong offsetToCommit = offsets.get(partition.getKafkaTopicPartition());\n \t\t\tif (offsetToCommit != null) {\n-\t\t\t\toffsetsToCommit.put(partition.getKafkaPartitionHandle(), new OffsetAndMetadata(offsetToCommit));\n+\t\t\t\toffsetsToCommit.put(partition.getKafkaPartitionHandle(), new OffsetAndMetadata(offsetToCommit + 1));\n \t\t\t\tpartition.setCommittedOffset(offsetToCommit);\n \t\t\t}\n \t\t}",
                "raw_url": "https://github.com/apache/flink/raw/eece0dd05bc38b88fcb6cbcef15add7f98eab456/flink-streaming-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09Fetcher.java",
                "sha": "ad7efa28014ffe6ac21c5d26f0b98b8fd2cb1ef5",
                "status": "modified"
            }
        ],
        "message": "[hotfix] [kafka] Fix NPE in Kafka09Fetcher",
        "parent": "https://github.com/apache/flink/commit/72e6b760fd951764c3ecc6fc191dc99a42d55e0b",
        "repo": "flink",
        "unit_tests": [
            "Kafka09FetcherTest.java"
        ]
    },
    "flink_f486a3f": {
        "bug_id": "flink_f486a3f",
        "commit": "https://github.com/apache/flink/commit/f486a3fd6ed80b67e8eeed9245ad37b6b0be740b",
        "file": [
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/flink/blob/f486a3fd6ed80b67e8eeed9245ad37b6b0be740b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestServerHandler.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestServerHandler.java?ref=f486a3fd6ed80b67e8eeed9245ad37b6b0be740b",
                "deletions": 3,
                "filename": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestServerHandler.java",
                "patch": "@@ -20,9 +20,9 @@\n \n import org.apache.flink.runtime.io.network.NetworkSequenceViewReader;\n import org.apache.flink.runtime.io.network.TaskEventDispatcher;\n+import org.apache.flink.runtime.io.network.netty.NettyMessage.AddCredit;\n import org.apache.flink.runtime.io.network.netty.NettyMessage.CancelPartitionRequest;\n import org.apache.flink.runtime.io.network.netty.NettyMessage.CloseRequest;\n-import org.apache.flink.runtime.io.network.netty.NettyMessage.AddCredit;\n import org.apache.flink.runtime.io.network.partition.PartitionNotFoundException;\n import org.apache.flink.runtime.io.network.partition.ResultPartitionProvider;\n import org.apache.flink.runtime.io.network.partition.consumer.InputChannelID;\n@@ -99,12 +99,12 @@ protected void channelRead0(ChannelHandlerContext ctx, NettyMessage msg) throws\n \t\t\t\t\t\t\toutboundQueue);\n \t\t\t\t\t}\n \n-\t\t\t\t\toutboundQueue.notifyReaderCreated(reader);\n-\n \t\t\t\t\treader.requestSubpartitionView(\n \t\t\t\t\t\tpartitionProvider,\n \t\t\t\t\t\trequest.partitionId,\n \t\t\t\t\t\trequest.queueIndex);\n+\n+\t\t\t\t\toutboundQueue.notifyReaderCreated(reader);\n \t\t\t\t} catch (PartitionNotFoundException notFound) {\n \t\t\t\t\trespondWithError(ctx, notFound, request.receiverId);\n \t\t\t\t}",
                "raw_url": "https://github.com/apache/flink/raw/f486a3fd6ed80b67e8eeed9245ad37b6b0be740b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestServerHandler.java",
                "sha": "e9ee10cbc4d953248955811899711ba3bfd12208",
                "status": "modified"
            }
        ],
        "message": "[FLINK-9057][network] fix an NPE when cleaning up before requesting a subpartition view\n\nIn PartitionRequestServerHandler, the view reader was created and immediately\nafterwards added to the PartitionRequestQueue which would attempt a cleanup of\nthe view reader's subpartition view. This view, however, was currently only\ncreated after adding the reader to the PartitionRequestQueue and may thus result\nin a NullPointerException if the cleanup happens very early in the\ninitialization phase, e.g. due to failures.\n\nThis closes #5747.",
        "parent": "https://github.com/apache/flink/commit/41ae13122bd1ca16f1c6779983dc0d17e3633e97",
        "repo": "flink",
        "unit_tests": [
            "PartitionRequestServerHandlerTest.java"
        ]
    }
}