[
    {
        "repo": "incubator-pinot",
        "commit": "https://github.com/apache/incubator-pinot/commit/b02cc238036b9cadc7c6df80a1004d61fa2349a6",
        "bug_id": "incubator-pinot_b02cc23",
        "message": "Using BlockingQueue for server merging phase.\nFixing NPE in related combine functions.\nRemove Exception handlers in MSelectionOnlyOperator.\nHandling metadata only DataTable Ser/DeSer.\n\nRB=478761\nR=xiafu\nA=kgopalak",
        "parent": "https://github.com/apache/incubator-pinot/commit/69a7ad04c3dbd78f23bd42bc2b33537f324b96c1",
        "patched_files": [
            "CombineService.java",
            "DataTable.java",
            "SelectionOperatorService.java",
            "ServerQueryExecutorV1Impl.java",
            "SelectionOperatorUtils.java",
            "MSelectionOnlyOperator.java",
            "QueryException.java",
            "DefaultReduceService.java",
            "IntermediateResultsBlock.java",
            "DataTableBuilder.java",
            "AggregationGroupByOperatorService.java",
            "MCombineOperator.java",
            "BrokerResponse.java"
        ],
        "file": [
            {
                "status": "modified",
                "additions": 14,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "deletions": 0,
                "sha": "0302aed9aab3c9209c2e536db986ea913f361a5c",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "patch": "@@ -15,6 +15,9 @@\n  */\n package com.linkedin.pinot.common.exception;\n \n+import java.io.PrintWriter;\n+import java.io.StringWriter;\n+\n import com.linkedin.pinot.common.response.ProcessingException;\n \n \n@@ -52,4 +55,15 @@\n     UNKNOWN_ERROR.setMessage(\"UnknownError\");\n   }\n \n+  public static ProcessingException getException(ProcessingException processingException, Exception exception, int sizeOfStackTraceToTruncate) {\n+    ProcessingException retProcessingException = QueryException.FUTURE_CALL_ERROR.deepCopy();\n+    StringWriter sw = new StringWriter(sizeOfStackTraceToTruncate);\n+    exception.printStackTrace(new PrintWriter(sw));\n+    retProcessingException.setMessage(sw.toString());\n+    return retProcessingException;\n+  }\n+\n+  public static ProcessingException getException(ProcessingException processingException, Exception exception) {\n+    return getException(processingException, exception, 1000);\n+  }\n }",
                "changes": 14
            },
            {
                "status": "modified",
                "additions": 1,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "deletions": 3,
                "sha": "42b8d2ca1e89b16c0cd0966391ce99bed312c1da",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "patch": "@@ -35,7 +35,7 @@\n public class BrokerResponse {\n   private long _totalDocs = 0;\n   private long _numDocsScanned = 0;\n-  private long _timeUsedMs;\n+  private long _timeUsedMs = 0;\n   private List<JSONObject> _aggregationResults;\n   private List<ResponseStatistics> _segmentStatistics;\n   private List<ProcessingException> _exceptions;\n@@ -62,8 +62,6 @@ public BrokerResponse() {\n     _segmentStatistics = new ArrayList<ResponseStatistics>();\n     _exceptions = new ArrayList<ProcessingException>();\n     _traceInfo = new HashMap<String, String>();\n-    _timeUsedMs = Long.MIN_VALUE;\n-\n   }\n \n   public long getTotalDocs() {",
                "changes": 4
            },
            {
                "status": "modified",
                "additions": 126,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "deletions": 99,
                "sha": "348b83ddb5c2c214fdf62905a789e5968bcc959e",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.common.utils;\n \n-import com.linkedin.pinot.common.Utils;\n import java.io.ByteArrayInputStream;\n import java.io.ByteArrayOutputStream;\n import java.io.Closeable;\n@@ -29,12 +28,15 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-import com.linkedin.pinot.common.data.FieldSpec.DataType;\n-import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n import org.apache.commons.io.IOUtils;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n+import com.linkedin.pinot.common.data.FieldSpec.DataType;\n+import com.linkedin.pinot.common.response.ProcessingException;\n+import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n+\n \n /**\n  *\n@@ -90,7 +92,6 @@ public DataTable(int numRows, Map<String, Map<Integer, String>> dictionary,\n     fixedSizeData = ByteBuffer.wrap(fixedSizeDataBytes);\n     variableSizeData = ByteBuffer.wrap(variableSizeDataBytes);\n     columnOffsets = computeColumnOffsets(schema);\n-\n   }\n \n   /**\n@@ -107,54 +108,57 @@ public DataTable(Map<String, String> metadata) {\n    * @return\n    */\n   private int[] computeColumnOffsets(DataSchema schema) {\n+    if (schema == null) {\n+      return null;\n+    }\n     final int[] columnOffsets = new int[schema.columnNames.length];\n     for (int i = 0; i < schema.columnNames.length; i++) {\n       final DataType type = schema.columnTypes[i];\n       columnOffsets[i] = rowSizeInBytes;\n       switch (type) {\n-      case BOOLEAN:\n-        rowSizeInBytes += 1;\n-        break;\n-      case BYTE:\n-        rowSizeInBytes += 1;\n-        break;\n-      case CHAR:\n-        rowSizeInBytes += 2;\n-        break;\n-      case SHORT:\n-        rowSizeInBytes += 2;\n-        break;\n-      case INT:\n-        rowSizeInBytes += 4;\n-        break;\n-      case LONG:\n-        rowSizeInBytes += 8;\n-        break;\n-      case FLOAT:\n-        rowSizeInBytes += 8;\n-        break;\n-      case DOUBLE:\n-        rowSizeInBytes += 8;\n-        break;\n-      case STRING:\n-        rowSizeInBytes += 4;\n-        break;\n-      case OBJECT:\n-        rowSizeInBytes += 8;\n-        break;\n-      case BYTE_ARRAY:\n-      case CHAR_ARRAY:\n-      case INT_ARRAY:\n-      case LONG_ARRAY:\n-      case FLOAT_ARRAY:\n-      case SHORT_ARRAY:\n-      case DOUBLE_ARRAY:\n-      case STRING_ARRAY:\n-        rowSizeInBytes += 8;\n-        break;\n-\n-      default:\n-        throw new RuntimeException(\"Unsupported datatype:\" + type);\n+        case BOOLEAN:\n+          rowSizeInBytes += 1;\n+          break;\n+        case BYTE:\n+          rowSizeInBytes += 1;\n+          break;\n+        case CHAR:\n+          rowSizeInBytes += 2;\n+          break;\n+        case SHORT:\n+          rowSizeInBytes += 2;\n+          break;\n+        case INT:\n+          rowSizeInBytes += 4;\n+          break;\n+        case LONG:\n+          rowSizeInBytes += 8;\n+          break;\n+        case FLOAT:\n+          rowSizeInBytes += 8;\n+          break;\n+        case DOUBLE:\n+          rowSizeInBytes += 8;\n+          break;\n+        case STRING:\n+          rowSizeInBytes += 4;\n+          break;\n+        case OBJECT:\n+          rowSizeInBytes += 8;\n+          break;\n+        case BYTE_ARRAY:\n+        case CHAR_ARRAY:\n+        case INT_ARRAY:\n+        case LONG_ARRAY:\n+        case FLOAT_ARRAY:\n+        case SHORT_ARRAY:\n+        case DOUBLE_ARRAY:\n+        case STRING_ARRAY:\n+          rowSizeInBytes += 8;\n+          break;\n+\n+        default:\n+          throw new RuntimeException(\"Unsupported datatype:\" + type);\n       }\n     }\n     return columnOffsets;\n@@ -195,24 +199,24 @@ public DataTable(byte[] buffer) {\n     input.get(metadataBytes);\n     metadata = (Map<String, String>) deserialize(metadataBytes);\n \n-    // READ METADATA\n+    // READ SCHEMA\n     final byte[] schemaBytes = new byte[schemaLength];\n     input.position(schemaStart);\n     input.get(schemaBytes);\n     schema = deserialize(schemaBytes);\n     columnOffsets = computeColumnOffsets(schema);\n \n-    // READ METADATA\n+    // READ FIXED SIZE DATA BYTES \n     fixedSizeDataBytes = new byte[fixedDataLength];\n     input.position(fixedDataStart);\n     input.get(fixedSizeDataBytes);\n     fixedSizeData = ByteBuffer.wrap(fixedSizeDataBytes);\n \n+    // READ VARIABLE SIZE DATA BYTES \n     variableSizeDataBytes = new byte[variableDataLength];\n     input.position(variableDataStart);\n     input.get(variableSizeDataBytes);\n     variableSizeData = ByteBuffer.wrap(variableSizeDataBytes);\n-\n   }\n \n   public DataTable() {\n@@ -260,19 +264,31 @@ public DataTable() {\n \n     // datatable\n     out.writeInt(baseOffset);\n-    out.writeInt(fixedSizeDataBytes.length);\n-    baseOffset += fixedSizeDataBytes.length;\n+    if (fixedSizeDataBytes == null) {\n+      out.writeInt(0);\n+    } else {\n+      out.writeInt(fixedSizeDataBytes.length);\n+      baseOffset += fixedSizeDataBytes.length;\n+    }\n \n     // variable data\n     out.writeInt(baseOffset);\n-    out.writeInt(variableSizeDataBytes.length);\n+    if (variableSizeDataBytes == null) {\n+      out.writeInt(0);\n+    } else {\n+      out.writeInt(variableSizeDataBytes.length);\n+    }\n \n     // write them\n     out.write(dictionaryBytes);\n     out.write(metadataBytes);\n     out.write(schemaBytes);\n-    out.write(fixedSizeDataBytes);\n-    out.write(variableSizeDataBytes);\n+    if (fixedSizeDataBytes != null) {\n+      out.write(fixedSizeDataBytes);\n+    }\n+    if (variableSizeDataBytes != null) {\n+      out.write(variableSizeDataBytes);\n+    }\n     return baos.toByteArray();\n   }\n \n@@ -536,6 +552,7 @@ public String getString(int rowId, int colId) {\n     }\n     return ret;\n   }\n+\n   /**\n    *\n    * @param rowId\n@@ -596,6 +613,9 @@ private int positionCursorInVariableBuffer(int rowId, int colId) {\n    */\n   @Override\n   public String toString() {\n+    if (schema == null) {\n+      return metadata.toString();\n+    }\n     final StringBuilder b = new StringBuilder();\n     b.append(schema.toString());\n     b.append(\"\\n\");\n@@ -606,55 +626,62 @@ public String toString() {\n       for (int colId = 0; colId < numCols; colId++) {\n         final DataType type = schema.columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          b.append(fixedSizeData.get());\n-          break;\n-        case BYTE:\n-          b.append(fixedSizeData.get());\n-          break;\n-        case CHAR:\n-          b.append(fixedSizeData.getChar());\n-          break;\n-        case SHORT:\n-          b.append(fixedSizeData.getShort());\n-          break;\n-        case INT:\n-          b.append(fixedSizeData.getInt());\n-          break;\n-        case LONG:\n-          b.append(fixedSizeData.getLong());\n-          break;\n-        case FLOAT:\n-          b.append(fixedSizeData.getFloat());\n-          break;\n-        case DOUBLE:\n-          b.append(fixedSizeData.getDouble());\n-          break;\n-        case STRING:\n-          b.append(fixedSizeData.getInt());\n-          break;\n-        case OBJECT:\n-          b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n-              fixedSizeData.getInt()));\n-          break;\n-        case BYTE_ARRAY:\n-        case CHAR_ARRAY:\n-        case SHORT_ARRAY:\n-        case INT_ARRAY:\n-        case LONG_ARRAY:\n-        case FLOAT_ARRAY:\n-        case DOUBLE_ARRAY:\n-        case STRING_ARRAY:\n-          b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n-              fixedSizeData.getInt()));\n-          break;\n-        default:\n-          throw new RuntimeException(\"Unsupported datatype:\" + type);\n+          case BOOLEAN:\n+            b.append(fixedSizeData.get());\n+            break;\n+          case BYTE:\n+            b.append(fixedSizeData.get());\n+            break;\n+          case CHAR:\n+            b.append(fixedSizeData.getChar());\n+            break;\n+          case SHORT:\n+            b.append(fixedSizeData.getShort());\n+            break;\n+          case INT:\n+            b.append(fixedSizeData.getInt());\n+            break;\n+          case LONG:\n+            b.append(fixedSizeData.getLong());\n+            break;\n+          case FLOAT:\n+            b.append(fixedSizeData.getFloat());\n+            break;\n+          case DOUBLE:\n+            b.append(fixedSizeData.getDouble());\n+            break;\n+          case STRING:\n+            b.append(fixedSizeData.getInt());\n+            break;\n+          case OBJECT:\n+            b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n+                fixedSizeData.getInt()));\n+            break;\n+          case BYTE_ARRAY:\n+          case CHAR_ARRAY:\n+          case SHORT_ARRAY:\n+          case INT_ARRAY:\n+          case LONG_ARRAY:\n+          case FLOAT_ARRAY:\n+          case DOUBLE_ARRAY:\n+          case STRING_ARRAY:\n+            b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n+                fixedSizeData.getInt()));\n+            break;\n+          default:\n+            throw new RuntimeException(\"Unsupported datatype:\" + type);\n         }\n         b.append(\"\\t\");\n       }\n       b.append(\"\\n\");\n     }\n     return b.toString();\n   }\n+\n+  public void addException(ProcessingException exception) {\n+    if (metadata == null) {\n+      metadata = new HashMap<String, String>();\n+    }\n+    metadata.put(\"Exception\" + exception.getErrorCode(), exception.getMessage());\n+  }\n }",
                "changes": 225
            },
            {
                "status": "modified",
                "additions": 164,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "deletions": 147,
                "sha": "b0bdcf02fee4ff46810e1656229a11edc2a439ea",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "patch": "@@ -25,10 +25,26 @@\n import org.testng.annotations.Test;\n \n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n+import com.linkedin.pinot.common.exception.QueryException;\n+import com.linkedin.pinot.common.response.ProcessingException;\n import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n \n+\n public class TestDataTableBuilder {\n \n+  @Test\n+  public void testException() throws Exception {\n+    Exception exception = new UnsupportedOperationException(\"msg 0\");\n+    ProcessingException processingException = QueryException.EXECUTION_TIMEOUT_ERROR.deepCopy();\n+    processingException.setMessage(exception.toString());\n+    DataTable dataTable = new DataTable();\n+    dataTable.addException(processingException);\n+    byte[] bytes = dataTable.toBytes();\n+    DataTable desDataTable = new DataTable(bytes);\n+    String exceptionMsg = desDataTable.getMetadata().get(\"Exception\" + QueryException.EXECUTION_TIMEOUT_ERROR.getErrorCode());\n+    org.testng.Assert.assertEquals(exceptionMsg, exception.toString());\n+  }\n+\n   @Test\n   public void testSimple() throws Exception {\n     final DataType[] columnTypes = DataType.values();\n@@ -60,63 +76,63 @@ public void testSimple() throws Exception {\n       for (int colId = 0; colId < schema.columnNames.length; colId++) {\n         final DataType type = columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          final boolean bool = r.nextBoolean();\n-          boolArr[rowId] = bool;\n-          builder.setColumn(colId, bool);\n-          break;\n-        case CHAR:\n-          final char ch = (char) (r.nextInt(26) + 'a');\n-          cArr[rowId] = ch;\n-          builder.setColumn(colId, ch);\n-          break;\n-        case BYTE:\n-          final byte b = (byte) (r.nextInt((int) Math.pow(2, 8)));\n-          bArr[rowId] = b;\n-          builder.setColumn(colId, b);\n-\n-          break;\n-        case SHORT:\n-          final short s = (short) (r.nextInt((int) Math.pow(2, 16)));\n-          sArr[rowId] = s;\n-          builder.setColumn(colId, s);\n-\n-          break;\n-        case INT:\n-          final int i = (r.nextInt());\n-          iArr[rowId] = i;\n-          builder.setColumn(colId, i);\n-\n-          break;\n-        case LONG:\n-          final long l = (r.nextLong());\n-          lArr[rowId] = l;\n-          builder.setColumn(colId, l);\n-\n-          break;\n-        case FLOAT:\n-          final float f = (r.nextFloat());\n-          fArr[rowId] = f;\n-          builder.setColumn(colId, f);\n-          break;\n-        case DOUBLE:\n-          final double d = (r.nextDouble());\n-          dArr[rowId] = d;\n-          builder.setColumn(colId, d);\n-          break;\n-        case STRING:\n-          final String str = new BigInteger(130, r).toString(32);\n-          strArr[rowId] = str;\n-          builder.setColumn(colId, str);\n-          break;\n-        case OBJECT:\n-          final A obj = new A(r.nextInt());\n-          oArr[rowId] = obj;\n-          builder.setColumn(colId, obj);\n-\n-          break;\n-        default:\n-          break;\n+          case BOOLEAN:\n+            final boolean bool = r.nextBoolean();\n+            boolArr[rowId] = bool;\n+            builder.setColumn(colId, bool);\n+            break;\n+          case CHAR:\n+            final char ch = (char) (r.nextInt(26) + 'a');\n+            cArr[rowId] = ch;\n+            builder.setColumn(colId, ch);\n+            break;\n+          case BYTE:\n+            final byte b = (byte) (r.nextInt((int) Math.pow(2, 8)));\n+            bArr[rowId] = b;\n+            builder.setColumn(colId, b);\n+\n+            break;\n+          case SHORT:\n+            final short s = (short) (r.nextInt((int) Math.pow(2, 16)));\n+            sArr[rowId] = s;\n+            builder.setColumn(colId, s);\n+\n+            break;\n+          case INT:\n+            final int i = (r.nextInt());\n+            iArr[rowId] = i;\n+            builder.setColumn(colId, i);\n+\n+            break;\n+          case LONG:\n+            final long l = (r.nextLong());\n+            lArr[rowId] = l;\n+            builder.setColumn(colId, l);\n+\n+            break;\n+          case FLOAT:\n+            final float f = (r.nextFloat());\n+            fArr[rowId] = f;\n+            builder.setColumn(colId, f);\n+            break;\n+          case DOUBLE:\n+            final double d = (r.nextDouble());\n+            dArr[rowId] = d;\n+            builder.setColumn(colId, d);\n+            break;\n+          case STRING:\n+            final String str = new BigInteger(130, r).toString(32);\n+            strArr[rowId] = str;\n+            builder.setColumn(colId, str);\n+            break;\n+          case OBJECT:\n+            final A obj = new A(r.nextInt());\n+            oArr[rowId] = obj;\n+            builder.setColumn(colId, obj);\n+\n+            break;\n+          default:\n+            break;\n         }\n       }\n       builder.finishRow();\n@@ -133,6 +149,7 @@ public void testSimple() throws Exception {\n         fArr, lArr, dArr, strArr, oArr);\n \n   }\n+\n   @Test\n   public void testStringArray() throws Exception {\n     DataType[] columnTypes = new DataType[] { DataType.STRING_ARRAY };\n@@ -168,6 +185,7 @@ public void testStringArray() throws Exception {\n     }\n \n   }\n+\n   @Test\n   public void testIntArray() throws Exception {\n     DataType[] columnTypes = new DataType[] { DataType.INT_ARRAY };\n@@ -256,62 +274,62 @@ public void testComplexDataTypes() throws Exception {\n   private void validate(DataType type, DataTable dataTable, Object[] arr,\n       int rowId, int colId) {\n     switch (type) {\n-    case BOOLEAN:\n-      Assert.assertEquals(arr[rowId], dataTable.getBoolean(rowId, colId));\n-      break;\n-    case CHAR:\n-      Assert.assertEquals(arr[rowId], dataTable.getChar(rowId, colId));\n-      break;\n-    case BYTE:\n-      Assert.assertEquals(arr[rowId], dataTable.getByte(rowId, colId));\n-      break;\n-    case SHORT:\n-      Assert.assertEquals(arr[rowId], dataTable.getShort(rowId, colId));\n-      break;\n-    case INT:\n-      Assert.assertEquals(arr[rowId], dataTable.getInt(rowId, colId));\n-      break;\n-    case LONG:\n-      Assert.assertEquals(arr[rowId], dataTable.getLong(rowId, colId));\n-      break;\n-    case FLOAT:\n-      Assert.assertEquals(arr[rowId], dataTable.getFloat(rowId, colId));\n-      break;\n-    case DOUBLE:\n-      Assert.assertEquals(arr[rowId], dataTable.getDouble(rowId, colId));\n-      break;\n-    case STRING:\n-      Assert.assertEquals(arr[rowId], dataTable.getString(rowId, colId));\n-      break;\n-    case BYTE_ARRAY:\n-      byte[] expectedByteArray = (byte[]) arr[rowId];\n-      byte[] actualByteArray = (byte[]) dataTable.getByteArray(rowId, colId);\n-      Assert.assertEquals(expectedByteArray.length, actualByteArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedByteArray, actualByteArray));\n-      break;\n-    case CHAR_ARRAY:\n-      char[] expectedCharArray = (char[]) arr[rowId];\n-      char[] actualChartArray = (char[]) dataTable.getCharArray(rowId, colId);\n-      Assert.assertEquals(expectedCharArray.length, actualChartArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedCharArray, actualChartArray));\n-      break;\n-    case INT_ARRAY:\n-      int[] expectedIntArray = (int[]) arr[rowId];\n-      int[] actualIntArray = (int[]) dataTable.getIntArray(rowId, colId);\n-      Assert.assertEquals(expectedIntArray.length, actualIntArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedIntArray, actualIntArray));\n-      break;\n-    case STRING_ARRAY:\n-      String[] expectedStringArray = (String[]) arr[rowId];\n-      String[] actualStringArray = (String[]) dataTable.getStringArray(rowId, colId);\n-      Assert.assertEquals(expectedStringArray.length, actualStringArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedStringArray, actualStringArray));\n-      break;\n-    case OBJECT:\n-      Assert.assertEquals(arr[rowId], dataTable.getObject(rowId, colId));\n-      break;\n-    default:\n-      break;\n+      case BOOLEAN:\n+        Assert.assertEquals(arr[rowId], dataTable.getBoolean(rowId, colId));\n+        break;\n+      case CHAR:\n+        Assert.assertEquals(arr[rowId], dataTable.getChar(rowId, colId));\n+        break;\n+      case BYTE:\n+        Assert.assertEquals(arr[rowId], dataTable.getByte(rowId, colId));\n+        break;\n+      case SHORT:\n+        Assert.assertEquals(arr[rowId], dataTable.getShort(rowId, colId));\n+        break;\n+      case INT:\n+        Assert.assertEquals(arr[rowId], dataTable.getInt(rowId, colId));\n+        break;\n+      case LONG:\n+        Assert.assertEquals(arr[rowId], dataTable.getLong(rowId, colId));\n+        break;\n+      case FLOAT:\n+        Assert.assertEquals(arr[rowId], dataTable.getFloat(rowId, colId));\n+        break;\n+      case DOUBLE:\n+        Assert.assertEquals(arr[rowId], dataTable.getDouble(rowId, colId));\n+        break;\n+      case STRING:\n+        Assert.assertEquals(arr[rowId], dataTable.getString(rowId, colId));\n+        break;\n+      case BYTE_ARRAY:\n+        byte[] expectedByteArray = (byte[]) arr[rowId];\n+        byte[] actualByteArray = (byte[]) dataTable.getByteArray(rowId, colId);\n+        Assert.assertEquals(expectedByteArray.length, actualByteArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedByteArray, actualByteArray));\n+        break;\n+      case CHAR_ARRAY:\n+        char[] expectedCharArray = (char[]) arr[rowId];\n+        char[] actualChartArray = (char[]) dataTable.getCharArray(rowId, colId);\n+        Assert.assertEquals(expectedCharArray.length, actualChartArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedCharArray, actualChartArray));\n+        break;\n+      case INT_ARRAY:\n+        int[] expectedIntArray = (int[]) arr[rowId];\n+        int[] actualIntArray = (int[]) dataTable.getIntArray(rowId, colId);\n+        Assert.assertEquals(expectedIntArray.length, actualIntArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedIntArray, actualIntArray));\n+        break;\n+      case STRING_ARRAY:\n+        String[] expectedStringArray = (String[]) arr[rowId];\n+        String[] actualStringArray = (String[]) dataTable.getStringArray(rowId, colId);\n+        Assert.assertEquals(expectedStringArray.length, actualStringArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedStringArray, actualStringArray));\n+        break;\n+      case OBJECT:\n+        Assert.assertEquals(arr[rowId], dataTable.getObject(rowId, colId));\n+        break;\n+      default:\n+        break;\n     }\n   }\n \n@@ -322,39 +340,39 @@ private void validate(DataTable dataTable, int numRows, DataSchema schema,\n       for (int colId = 0; colId < schema.columnNames.length; colId++) {\n         final DataType type = schema.columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          Assert.assertEquals(boolArr[rowId],\n-              dataTable.getBoolean(rowId, colId));\n-          break;\n-        case CHAR:\n-          Assert.assertEquals(cArr[rowId], dataTable.getChar(rowId, colId));\n-          break;\n-        case BYTE:\n-          Assert.assertEquals(bArr[rowId], dataTable.getByte(rowId, colId));\n-          break;\n-        case SHORT:\n-          Assert.assertEquals(sArr[rowId], dataTable.getShort(rowId, colId));\n-          break;\n-        case INT:\n-          Assert.assertEquals(iArr[rowId], dataTable.getInt(rowId, colId));\n-          break;\n-        case LONG:\n-          Assert.assertEquals(lArr[rowId], dataTable.getLong(rowId, colId));\n-          break;\n-        case FLOAT:\n-          Assert.assertEquals(fArr[rowId], dataTable.getFloat(rowId, colId));\n-          break;\n-        case DOUBLE:\n-          Assert.assertEquals(dArr[rowId], dataTable.getDouble(rowId, colId));\n-          break;\n-        case STRING:\n-          Assert.assertEquals(strArr[rowId], dataTable.getString(rowId, colId));\n-          break;\n-        case OBJECT:\n-          Assert.assertEquals(oArr[rowId], dataTable.getObject(rowId, colId));\n-          break;\n-        default:\n-          break;\n+          case BOOLEAN:\n+            Assert.assertEquals(boolArr[rowId],\n+                dataTable.getBoolean(rowId, colId));\n+            break;\n+          case CHAR:\n+            Assert.assertEquals(cArr[rowId], dataTable.getChar(rowId, colId));\n+            break;\n+          case BYTE:\n+            Assert.assertEquals(bArr[rowId], dataTable.getByte(rowId, colId));\n+            break;\n+          case SHORT:\n+            Assert.assertEquals(sArr[rowId], dataTable.getShort(rowId, colId));\n+            break;\n+          case INT:\n+            Assert.assertEquals(iArr[rowId], dataTable.getInt(rowId, colId));\n+            break;\n+          case LONG:\n+            Assert.assertEquals(lArr[rowId], dataTable.getLong(rowId, colId));\n+            break;\n+          case FLOAT:\n+            Assert.assertEquals(fArr[rowId], dataTable.getFloat(rowId, colId));\n+            break;\n+          case DOUBLE:\n+            Assert.assertEquals(dArr[rowId], dataTable.getDouble(rowId, colId));\n+            break;\n+          case STRING:\n+            Assert.assertEquals(strArr[rowId], dataTable.getString(rowId, colId));\n+            break;\n+          case OBJECT:\n+            Assert.assertEquals(oArr[rowId], dataTable.getObject(rowId, colId));\n+            break;\n+          default:\n+            break;\n         }\n       }\n     }\n@@ -376,6 +394,5 @@ public boolean equals(Object obj) {\n     public int hashCode() {\n       return new Integer(i).hashCode();\n     }\n-\n   }\n }",
                "changes": 311
            },
            {
                "status": "modified",
                "additions": 12,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "deletions": 0,
                "sha": "a58bd3046369e850362f8584656bf09b928a5168",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "patch": "@@ -131,6 +131,9 @@ public DataTable getDataTable() throws Exception {\n     if (_selectionResult != null) {\n       return getSelectionResultDataTable();\n     }\n+    if (_processingExceptions != null && _processingExceptions.size() > 0) {\n+      return getExceptionsDataTable();\n+    }\n     throw new UnsupportedOperationException(\"Cannot get DataTable from IntermediateResultBlock!\");\n   }\n \n@@ -139,9 +142,18 @@ public DataTable attachMetadataToDataTable(DataTable dataTable) {\n     dataTable.getMetadata().put(NUM_DOCS_SCANNED, _numDocsScanned + \"\");\n     dataTable.getMetadata().put(TIME_USED_MS, _timeUsedMs + \"\");\n     dataTable.getMetadata().put(TOTAL_DOCS, _totalDocs + \"\");\n+    if (_processingExceptions != null && _processingExceptions.size() > 0) {\n+      for (int i = 0; i < _processingExceptions.size(); ++i) {\n+        dataTable.addException(_processingExceptions.get(i));\n+      }\n+    }\n     return dataTable;\n   }\n \n+  public DataTable getExceptionsDataTable() {\n+    return attachMetadataToDataTable(new DataTable());\n+  }\n+\n   private DataTable getSelectionResultDataTable() throws Exception {\n     return attachMetadataToDataTable(SelectionOperatorUtils.getDataTableFromRowSet(_selectionResult, _dataSchema));\n   }",
                "changes": 12
            },
            {
                "status": "modified",
                "additions": 59,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "deletions": 32,
                "sha": "3813f8be7438ddc23a1840285f8a82c4e3d3e1d5",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "patch": "@@ -17,6 +17,8 @@\n \n import java.util.ArrayList;\n import java.util.List;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n@@ -99,35 +101,65 @@ public boolean open() {\n \n   @Override\n   public Block nextBlock() {\n-    long start = System.currentTimeMillis();\n+    final long startTime = System.currentTimeMillis();\n     if (_isParallel) {\n-      long queryEndTime = System.currentTimeMillis() + _timeOutMs;\n+      final long queryEndTime = System.currentTimeMillis() + _timeOutMs;\n+      final BlockingQueue<Block> blockingQueue = new ArrayBlockingQueue<Block>(_operators.size());\n \n-      @SuppressWarnings(\"rawtypes\")\n-      List<Future> blocks = new ArrayList<Future>();\n+      // Submit operators.\n       for (final Operator operator : _operators) {\n-        blocks.add(_executorService.submit(new Callable<Block>() {\n+        _executorService.submit(new Runnable() {\n           @Override\n-          public Block call() throws Exception {\n-            return operator.nextBlock();\n+          public void run() {\n+            Block retBlock;\n+            try {\n+              retBlock = operator.nextBlock();\n+            } catch (Exception e) {\n+              retBlock = new IntermediateResultsBlock(e);\n+            }\n+            if (blockingQueue != null) {\n+              blockingQueue.offer(retBlock);\n+            }\n           }\n-        }));\n+        });\n       }\n-      LOGGER.debug(\"Submitting operators to be run in parallel and it took:\" + (System.currentTimeMillis() - start));\n+      LOGGER.debug(\"Submitting operators to be run in parallel and it took:\" + (System.currentTimeMillis() - startTime));\n+\n+      // Submit merger job:\n+      Future<IntermediateResultsBlock> mergedBlockFuture =\n+          _executorService.submit(new Callable<IntermediateResultsBlock>() {\n+            @Override\n+            public IntermediateResultsBlock call() throws Exception {\n+              int mergedBlocksNumber = 0;\n+              IntermediateResultsBlock mergedBlock = null;\n+              while ((queryEndTime > System.currentTimeMillis()) && (mergedBlocksNumber < _operators.size())) {\n+                if (mergedBlock == null) {\n+                  mergedBlock = (IntermediateResultsBlock) blockingQueue.poll(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n+                  if (mergedBlock != null) {\n+                    mergedBlocksNumber++;\n+                  }\n+                  LOGGER.debug(\"Got response from operator 0 after: {}\", (System.currentTimeMillis() - startTime));\n+                } else {\n+                  IntermediateResultsBlock blockToMerge = (IntermediateResultsBlock) blockingQueue.poll(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n+                  if (blockToMerge != null) {\n+                    try {\n+                      LOGGER.debug(\"Got response from operator {} after: {}\", mergedBlocksNumber, (System.currentTimeMillis() - startTime));\n+                      CombineService.mergeTwoBlocks(_brokerRequest, mergedBlock, blockToMerge);\n+                      LOGGER.debug(\"Merged response from operator {} after: {}\", mergedBlocksNumber, (System.currentTimeMillis() - startTime));\n+                    } catch (Exception e) {\n+                      mergedBlock.getExceptions().add(QueryException.getException(QueryException.MERGE_RESPONSE_ERROR, e));\n+                    }\n+                    mergedBlocksNumber++;\n+                  }\n+                }\n+              }\n+              return mergedBlock;\n+            }\n+          });\n+\n+      // Get merge results.\n       try {\n-        _mergedBlock =\n-            (IntermediateResultsBlock) blocks.get(0).get(queryEndTime - System.currentTimeMillis(),\n-                TimeUnit.MILLISECONDS);\n-        LOGGER.debug(\"Got response from operator 0 after: \" + (System.currentTimeMillis() - start));\n-\n-        for (int i = 1; i < blocks.size(); ++i) {\n-          IntermediateResultsBlock blockToMerge =\n-              (IntermediateResultsBlock) blocks.get(i).get(queryEndTime - System.currentTimeMillis(),\n-                  TimeUnit.MILLISECONDS);\n-          LOGGER.debug(\"Got response from operator \" + i + \" after: \" + (System.currentTimeMillis() - start));\n-          CombineService.mergeTwoBlocks(_brokerRequest, _mergedBlock, blockToMerge);\n-          LOGGER.debug(\"Merged response from operator \" + i + \" after: \" + (System.currentTimeMillis() - start));\n-        }\n+        _mergedBlock = mergedBlockFuture.get(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n       } catch (InterruptedException e) {\n         LOGGER.error(\"InterruptedException \", e);\n         if (_mergedBlock == null) {\n@@ -137,9 +169,7 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.FUTURE_CALL_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.FUTURE_CALL_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       } catch (ExecutionException e) {\n         LOGGER.error(\"Execution Exception\", e);\n@@ -150,9 +180,7 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.QUERY_EXECUTION_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.MERGE_RESPONSE_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       } catch (TimeoutException e) {\n         LOGGER.error(\"TimeoutException \", e);\n@@ -163,11 +191,10 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.EXECUTION_TIMEOUT_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.EXECUTION_TIMEOUT_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       }\n+\n     } else {\n       for (Operator operator : _operators) {\n         if ((operator instanceof MAggregationOperator) || (operator instanceof MSelectionOrderByOperator) || (operator instanceof MSelectionOnlyOperator)\n@@ -189,7 +216,7 @@ public Block call() throws Exception {\n       trimToSize(_brokerRequest, _mergedBlock);\n     }\n     long end = System.currentTimeMillis();\n-    LOGGER.info(\"Time spent in MCombineOperator:\" + (end - start));\n+    LOGGER.info(\"Time spent in MCombineOperator:\" + (end - startTime));\n \n     return _mergedBlock;\n   }",
                "changes": 91
            },
            {
                "status": "modified",
                "additions": 20,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "deletions": 39,
                "sha": "af9f6e2ca1e02e1aeea5860e6ab487cfd381cb6c",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "patch": "@@ -18,14 +18,11 @@\n import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.List;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.request.Selection;\n-import com.linkedin.pinot.common.response.ProcessingException;\n import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n import com.linkedin.pinot.core.block.query.IntermediateResultsBlock;\n import com.linkedin.pinot.core.block.query.ProjectionBlock;\n@@ -82,45 +79,29 @@ public Block nextBlock() {\n \n     long numDocsScanned = 0;\n     ProjectionBlock projectionBlock = null;\n-    try {\n-      while ((projectionBlock = (ProjectionBlock) _projectionOperator.nextBlock()) != null) {\n-        int j = 0;\n-        for (int i = 0; i < _dataSchema.size(); ++i) {\n-          _blocks[j++] = projectionBlock.getBlock(_dataSchema.getColumnName(i));\n-        }\n-        BlockDocIdIterator blockDocIdIterator = projectionBlock.getDocIdSetBlock().getBlockDocIdSet().iterator();\n-        int docId;\n-        while ((docId = blockDocIdIterator.next()) != Constants.EOF && _rowEvents.size() < _limitDocs) {\n-          numDocsScanned++;\n-          _rowEvents.add(SelectionOperatorUtils.collectRowFromBlockValSets(docId, _blocks, _dataSchema));\n-        }\n+    while ((projectionBlock = (ProjectionBlock) _projectionOperator.nextBlock()) != null) {\n+      int j = 0;\n+      for (int i = 0; i < _dataSchema.size(); ++i) {\n+        _blocks[j++] = projectionBlock.getBlock(_dataSchema.getColumnName(i));\n+      }\n+      BlockDocIdIterator blockDocIdIterator = projectionBlock.getDocIdSetBlock().getBlockDocIdSet().iterator();\n+      int docId;\n+      while ((docId = blockDocIdIterator.next()) != Constants.EOF && _rowEvents.size() < _limitDocs) {\n+        numDocsScanned++;\n+        _rowEvents.add(SelectionOperatorUtils.collectRowFromBlockValSets(docId, _blocks, _dataSchema));\n       }\n-\n-      final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n-      resultBlock.setSelectionResult(_rowEvents);\n-      resultBlock.setSelectionDataSchema(_dataSchema);\n-      resultBlock.setNumDocsScanned(numDocsScanned);\n-      resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n-      final long endTime = System.currentTimeMillis();\n-      resultBlock.setTimeUsedMs(endTime - startTime);\n-      LOGGER.debug(\"Time spent in MSelectionOnlyOperator:\" + (endTime - startTime));\n-      return resultBlock;\n-    } catch (Exception e) {\n-      LOGGER.warn(\"Caught exception while processing selection operator\", e);\n-      final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n-\n-      List<ProcessingException> processingExceptions = new ArrayList<ProcessingException>();\n-      ProcessingException exception = QueryException.QUERY_EXECUTION_ERROR.deepCopy();\n-      exception.setMessage(e.getMessage());\n-      processingExceptions.add(exception);\n-\n-      resultBlock.setExceptionsList(processingExceptions);\n-      resultBlock.setNumDocsScanned(0);\n-      resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n-      resultBlock.setTimeUsedMs(System.currentTimeMillis() - startTime);\n-      return resultBlock;\n     }\n \n+    final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n+    resultBlock.setSelectionResult(_rowEvents);\n+    resultBlock.setSelectionDataSchema(_dataSchema);\n+    resultBlock.setNumDocsScanned(numDocsScanned);\n+    resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n+    final long endTime = System.currentTimeMillis();\n+    resultBlock.setTimeUsedMs(endTime - startTime);\n+    LOGGER.debug(\"Time spent in MSelectionOnlyOperator:\" + (endTime - startTime));\n+    return resultBlock;\n+\n   }\n \n   @Override",
                "changes": 59
            },
            {
                "status": "modified",
                "additions": 28,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "deletions": 2,
                "sha": "f5128b38600c1769971a239d21f03efbc25e1de6",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "patch": "@@ -41,7 +41,14 @@\n \n   public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResultsBlock mergedBlock,\n       IntermediateResultsBlock blockToMerge) {\n-\n+    // Sanity check\n+    if (blockToMerge == null) {\n+      return;\n+    }\n+    if (mergedBlock == null) {\n+      mergedBlock = blockToMerge;\n+      return;\n+    }\n     // Combine NumDocsScanned\n     mergedBlock.setNumDocsScanned(mergedBlock.getNumDocsScanned() + blockToMerge.getNumDocsScanned());\n     // Combine TotalDocs\n@@ -83,6 +90,13 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static List<Map<String, Serializable>> combineAggregationGroupByResults1(BrokerRequest brokerRequest,\n       List<Map<String, Serializable>> list1, List<Map<String, Serializable>> list2) {\n+    if (list1 == null) {\n+      return list2;\n+    }\n+    if (list2 == null) {\n+      return list1;\n+    }\n+\n     for (int i = 0; i < list1.size(); ++i) {\n       list1.set(i, mergeTwoGroupedResults(brokerRequest.getAggregationsInfo().get(i), list1.get(i), list2.get(i)));\n     }\n@@ -93,6 +107,13 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static Map<String, Serializable> mergeTwoGroupedResults(AggregationInfo aggregationInfo,\n       Map<String, Serializable> map1, Map<String, Serializable> map2) {\n+    if (map1 == null) {\n+      return map2;\n+    }\n+    if (map2 == null) {\n+      return map1;\n+    }\n+\n     AggregationFunction aggregationFunction = AggregationFunctionFactory.get(aggregationInfo, true);\n     for (String key : map2.keySet()) {\n       if (map1.containsKey(key)) {\n@@ -106,7 +127,12 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static List<Serializable> combineAggregationResults(BrokerRequest brokerRequest,\n       List<Serializable> aggregationResult1, List<Serializable> aggregationResult2) {\n-\n+    if (aggregationResult1 == null) {\n+      return aggregationResult2;\n+    }\n+    if (aggregationResult2 == null) {\n+      return aggregationResult1;\n+    }\n     List<List<Serializable>> aggregationResultsList = new ArrayList<List<Serializable>>();\n \n     for (int i = 0; i < brokerRequest.getAggregationsInfoSize(); ++i) {",
                "changes": 30
            },
            {
                "status": "modified",
                "additions": 17,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "deletions": 11,
                "sha": "db0a27e6438f18a9a92af891bce65906ca626b64",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.groupby;\n \n-import com.linkedin.pinot.common.Utils;\n import it.unimi.dsi.fastutil.PriorityQueue;\n import it.unimi.dsi.fastutil.objects.ObjectArrayPriorityQueue;\n \n@@ -31,7 +30,10 @@\n import org.json.JSONArray;\n import org.json.JSONException;\n import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n import com.linkedin.pinot.common.request.AggregationInfo;\n import com.linkedin.pinot.common.request.GroupBy;\n@@ -40,8 +42,6 @@\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunctionFactory;\n import com.linkedin.pinot.core.query.utils.Pair;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n \n \n /**\n@@ -91,7 +91,9 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n     List<Map<String, Serializable>> reducedResult = null;\n     for (DataTable toBeReducedGroupByResults : instanceResponseMap.values()) {\n       if (reducedResult == null) {\n-        reducedResult = transformDataTableToGroupByResult(toBeReducedGroupByResults);\n+        if (toBeReducedGroupByResults != null) {\n+          reducedResult = transformDataTableToGroupByResult(toBeReducedGroupByResults);\n+        }\n       } else {\n         List<Map<String, Serializable>> toBeReducedResult =\n             transformDataTableToGroupByResult(toBeReducedGroupByResults);\n@@ -109,12 +111,14 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n         }\n       }\n     }\n-    for (int i = 0; i < reducedResult.size(); ++i) {\n-      Map<String, Serializable> functionLevelReducedResult = reducedResult.get(i);\n-      for (String key : functionLevelReducedResult.keySet()) {\n-        if (functionLevelReducedResult.get(key) != null) {\n-          functionLevelReducedResult.put(key,\n-              _aggregationFunctionList.get(i).reduce(Arrays.asList(functionLevelReducedResult.get(key))));\n+    if (reducedResult != null) {\n+      for (int i = 0; i < reducedResult.size(); ++i) {\n+        Map<String, Serializable> functionLevelReducedResult = reducedResult.get(i);\n+        for (String key : functionLevelReducedResult.keySet()) {\n+          if (functionLevelReducedResult.get(key) != null) {\n+            functionLevelReducedResult.put(key,\n+                _aggregationFunctionList.get(i).reduce(Arrays.asList(functionLevelReducedResult.get(key))));\n+          }\n         }\n       }\n     }\n@@ -123,7 +127,9 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n \n   public List<JSONObject> renderGroupByOperators(List<Map<String, Serializable>> finalAggregationResult) {\n     try {\n-\n+      if (finalAggregationResult == null || finalAggregationResult.size() != _aggregationFunctionList.size()) {\n+        return null;\n+      }\n       List<JSONObject> retJsonResultList = new ArrayList<JSONObject>();\n       for (int i = 0; i < _aggregationFunctionList.size(); ++i) {\n         DecimalFormat df = DEFAULT_FORMAT_STRING_MAP.get(_aggregationFunctionList.get(i).aggregateResultDataType());",
                "changes": 28
            },
            {
                "status": "modified",
                "additions": 14,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "deletions": 5,
                "sha": "8825e161f69d927080caaa3c5bce3e834629b5ad",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "patch": "@@ -29,6 +29,7 @@\n import org.slf4j.LoggerFactory;\n \n import com.linkedin.pinot.common.data.DataManager;\n+import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.metrics.ServerMeter;\n import com.linkedin.pinot.common.metrics.ServerMetrics;\n import com.linkedin.pinot.common.metrics.ServerQueryPhase;\n@@ -101,8 +102,8 @@ public void init(Configuration queryExecutorConfig, DataManager dataManager, Ser\n   @Override\n   public DataTable processQuery(final InstanceRequest instanceRequest) {\n     DataTable instanceResponse;\n+    long start = System.currentTimeMillis();\n     try {\n-      long start = System.currentTimeMillis();\n       final BrokerRequest brokerRequest = instanceRequest.getQuery();\n       LOGGER.info(\"Incoming query is :\" + brokerRequest);\n       final List<IndexSegment> queryableSegmentDataManagerList = _serverMetrics.timePhase(brokerRequest,\n@@ -127,6 +128,7 @@ public Plan call() throws Exception {\n               getResourceTimeOut(instanceRequest.getQuery()));\n         }\n       });\n+\n       if (_printQueryPlan) {\n         LOGGER.debug(\"***************************** Query Plan for Request \" + instanceRequest.getRequestId() + \"***********************************\");\n         globalQueryPlan.print();\n@@ -142,21 +144,28 @@ public Object call()\n       });\n       instanceResponse = globalQueryPlan.getInstanceResponse();\n       long end = System.currentTimeMillis();\n-      LOGGER.info(\"Searching Instance for Request Id - \" + instanceRequest.getRequestId() + \", browse took: \" + (end - start));\n-      LOGGER.debug(\"InstanceResponse for Request Id - \" + instanceRequest.getRequestId() + \" : \" + instanceResponse.toString());\n+      LOGGER.info(\"Searching Instance for Request Id - {}, browse took: {}\", instanceRequest.getRequestId(), (end - start));\n+      LOGGER.debug(\"InstanceResponse for Request Id - {} : {}\", instanceRequest.getRequestId(), instanceResponse.toString());\n       instanceResponse.getMetadata().put(\"timeUsedMs\", Long.toString((end - start)));\n       instanceResponse.getMetadata().put(\"requestId\", Long.toString(instanceRequest.getRequestId()));\n+      return instanceResponse;\n     } catch (Exception e) {\n       _serverMetrics.addMeteredValue(instanceRequest.getQuery(), ServerMeter.QUERY_EXECUTION_EXCEPTIONS, 1);\n       LOGGER.error(e.getMessage(), e);\n-      instanceResponse = null;\n+      instanceResponse = new DataTable();\n+      instanceResponse.addException(QueryException.getException(QueryException.QUERY_EXECUTION_ERROR, e));\n+      long end = System.currentTimeMillis();\n+      LOGGER.info(\"Searching Instance for Request Id - {}, browse took: {}\", instanceRequest.getRequestId(), (end - start));\n+      LOGGER.debug(\"InstanceResponse for Request Id - {} : {}\", instanceRequest.getRequestId(), instanceResponse.toString());\n+      instanceResponse.getMetadata().put(\"timeUsedMs\", Long.toString((end - start)));\n+      instanceResponse.getMetadata().put(\"requestId\", Long.toString(instanceRequest.getRequestId()));\n+      return instanceResponse;\n     } finally {\n       if (_instanceDataManager.getResourceDataManager(instanceRequest.getQuery().getQuerySource().getResourceName()) != null) {\n         _instanceDataManager.getResourceDataManager(instanceRequest.getQuery().getQuerySource().getResourceName())\n             .returnSegmentReaders(instanceRequest.getSearchSegments());\n       }\n     }\n-    return instanceResponse;\n   }\n \n   private List<IndexSegment> getPrunedQueryableSegments(final InstanceRequest instanceRequest) {",
                "changes": 19
            },
            {
                "status": "modified",
                "additions": 52,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "deletions": 29,
                "sha": "91b40dc30da8e196004f8cbce7ce1ecbbf3312f7",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "patch": "@@ -15,8 +15,6 @@\n  */\n package com.linkedin.pinot.core.query.reduce;\n \n-import com.linkedin.pinot.common.Utils;\n-\n import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.Collection;\n@@ -25,7 +23,11 @@\n \n import org.json.JSONException;\n import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n+import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.query.ReduceService;\n import com.linkedin.pinot.common.request.BrokerRequest;\n import com.linkedin.pinot.common.response.AggregationResult;\n@@ -42,9 +44,6 @@\n import com.linkedin.pinot.core.query.selection.SelectionOperatorService;\n import com.linkedin.pinot.core.query.selection.SelectionOperatorUtils;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n \n /**\n  * DefaultReduceService will reduce DataTables gathered from multiple instances\n@@ -123,8 +122,24 @@ public BrokerResponse reduceOnDataTable(BrokerRequest brokerRequest,\n     if (instanceResponseMap == null || instanceResponseMap.size() == 0) {\n       return BrokerResponse.EMPTY_RESULT;\n     }\n-    for (ServerInstance serverInstance : instanceResponseMap.keySet()) {\n+    for (ServerInstance serverInstance : instanceResponseMap.keySet().toArray(new ServerInstance[instanceResponseMap.size()])) {\n       DataTable instanceResponse = instanceResponseMap.get(serverInstance);\n+      if (instanceResponse == null) {\n+        continue;\n+      }\n+      if (instanceResponse.getDataSchema() == null && instanceResponse.getMetadata() != null) {\n+        for (String key : instanceResponse.getMetadata().keySet()) {\n+          if (key.startsWith(\"Exception\")) {\n+            ProcessingException processingException = new ProcessingException();\n+            processingException.setErrorCode(Integer.parseInt(key.substring(9)));\n+            processingException.setMessage(instanceResponse.getMetadata().get(key));\n+            brokerResponse.addToExceptions(processingException);\n+          }\n+        }\n+        instanceResponseMap.remove(serverInstance);\n+        continue;\n+      }\n+\n       // reduceOnNumDocsScanned\n       brokerResponse.setNumDocsScanned(brokerResponse.getNumDocsScanned()\n           + Long.parseLong(instanceResponse.getMetadata().get(NUM_DOCS_SCANNED)));\n@@ -135,35 +150,40 @@ public BrokerResponse reduceOnDataTable(BrokerRequest brokerRequest,\n         brokerResponse.setTimeUsedMs(Long.parseLong(instanceResponse.getMetadata().get(TIME_USED_MS)));\n       }\n     }\n+    try {\n \n-    if (brokerRequest.isSetSelections() && (brokerRequest.getSelections().getSelectionColumns() != null)\n-        && (brokerRequest.getSelections().getSelectionColumns().size() >= 0)) {\n-      // Reduce DataTable for selection query.\n-      JSONObject selectionRet = reduceOnSelectionResults(brokerRequest, instanceResponseMap);\n-      brokerResponse.setSelectionResults(selectionRet);\n-      return brokerResponse;\n-    }\n-    if (brokerRequest.isSetAggregationsInfo()) {\n-      if (!brokerRequest.isSetGroupBy()) {\n-        List<List<Serializable>> aggregationResultsList =\n-            getShuffledAggregationResults(brokerRequest, instanceResponseMap);\n-        brokerResponse.setAggregationResults(reduceOnAggregationResults(brokerRequest, aggregationResultsList));\n-      } else {\n-        // Reduce DataTable for aggregation groupby query.\n-        //        GroupByAggregationService groupByAggregationService =\n-        //            new GroupByAggregationService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n-        //        brokerResponse.setAggregationResults(reduceOnAggregationGroupByResults(groupByAggregationService,\n-        //            instanceResponseMap));\n+      if (brokerRequest.isSetSelections() && (brokerRequest.getSelections().getSelectionColumns() != null)\n+          && (brokerRequest.getSelections().getSelectionColumns().size() >= 0)) {\n+        // Reduce DataTable for selection query.\n+        JSONObject selectionRet = reduceOnSelectionResults(brokerRequest, instanceResponseMap);\n+        brokerResponse.setSelectionResults(selectionRet);\n+        return brokerResponse;\n+      }\n+      if (brokerRequest.isSetAggregationsInfo()) {\n+        if (!brokerRequest.isSetGroupBy()) {\n+          List<List<Serializable>> aggregationResultsList =\n+              getShuffledAggregationResults(brokerRequest, instanceResponseMap);\n+          brokerResponse.setAggregationResults(reduceOnAggregationResults(brokerRequest, aggregationResultsList));\n+        } else {\n+          // Reduce DataTable for aggregation groupby query.\n+          //        GroupByAggregationService groupByAggregationService =\n+          //            new GroupByAggregationService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n+          //        brokerResponse.setAggregationResults(reduceOnAggregationGroupByResults(groupByAggregationService,\n+          //            instanceResponseMap));\n \n-        AggregationGroupByOperatorService aggregationGroupByOperatorService =\n-            new AggregationGroupByOperatorService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n-        brokerResponse.setAggregationResults(reduceOnAggregationGroupByOperatorResults(\n-            aggregationGroupByOperatorService, instanceResponseMap));\n+          AggregationGroupByOperatorService aggregationGroupByOperatorService =\n+              new AggregationGroupByOperatorService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n+          brokerResponse.setAggregationResults(reduceOnAggregationGroupByOperatorResults(\n+              aggregationGroupByOperatorService, instanceResponseMap));\n \n+        }\n+        return brokerResponse;\n       }\n+\n+    } catch (Exception e) {\n+      brokerResponse.addToExceptions(QueryException.getException(QueryException.BROKER_GATHER_ERROR, e));\n       return brokerResponse;\n     }\n-\n     throw new UnsupportedOperationException(\n         \"Should not reach here, the query has no attributes of selection or aggregation!\");\n   }\n@@ -226,6 +246,9 @@ private JSONObject reduceOnSelectionResults(BrokerRequest brokerRequest,\n     for (ServerInstance serverInstance : instanceResponseMap.keySet()) {\n       DataTable instanceResponse = instanceResponseMap.get(serverInstance);\n       aggregationResultSchema = instanceResponse.getDataSchema();\n+      if (aggregationResultSchema == null) {\n+        continue;\n+      }\n       // Shuffle AggregationResults\n       for (int rowId = 0; rowId < instanceResponse.getNumberOfRows(); ++rowId) {\n         for (int colId = 0; colId < brokerRequest.getAggregationsInfoSize(); ++colId) {",
                "changes": 81
            },
            {
                "status": "modified",
                "additions": 6,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "deletions": 0,
                "sha": "3a1627e7e8a8f5da90c751444222d66c40177c2f",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "patch": "@@ -173,6 +173,12 @@ public SelectionOperatorService(Selection selections, DataSchema dataSchema) {\n \n   public Collection<Serializable[]> merge(Collection<Serializable[]> rowEventsSet1,\n       Collection<Serializable[]> rowEventsSet2) {\n+    if (rowEventsSet1 == null) {\n+      return rowEventsSet2;\n+    }\n+    if (rowEventsSet2 == null) {\n+      return rowEventsSet1;\n+    }\n     if (_doOrdering) {\n       PriorityQueue<Serializable[]> queue1 = (PriorityQueue<Serializable[]>) rowEventsSet1;\n       PriorityQueue<Serializable[]> queue2 = (PriorityQueue<Serializable[]>) rowEventsSet2;",
                "changes": 6
            },
            {
                "status": "modified",
                "additions": 10,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "deletions": 9,
                "sha": "4cb37776f844260192d20e5a006f34912da1c104",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "patch": "@@ -53,8 +53,8 @@\n import com.linkedin.pinot.core.realtime.impl.dictionary.LongMutableDictionary;\n import com.linkedin.pinot.core.realtime.impl.dictionary.StringMutableDictionary;\n import com.linkedin.pinot.core.segment.index.data.source.mv.block.MultiValueBlock;\n-import com.linkedin.pinot.core.segment.index.data.source.sv.block.UnSortedSingleValueBlock;\n import com.linkedin.pinot.core.segment.index.data.source.sv.block.SortedSingleValueBlock;\n+import com.linkedin.pinot.core.segment.index.data.source.sv.block.UnSortedSingleValueBlock;\n import com.linkedin.pinot.core.segment.index.readers.Dictionary;\n import com.linkedin.pinot.core.segment.index.readers.DoubleDictionary;\n import com.linkedin.pinot.core.segment.index.readers.FloatDictionary;\n@@ -120,6 +120,12 @@\n \n   public static Collection<Serializable[]> merge(Collection<Serializable[]> rowEventsSet1,\n       Collection<Serializable[]> rowEventsSet2, int maxRowSize) {\n+    if (rowEventsSet1 == null) {\n+      return rowEventsSet2;\n+    }\n+    if (rowEventsSet2 == null) {\n+      return rowEventsSet1;\n+    }\n     final Iterator<Serializable[]> iterator = rowEventsSet2.iterator();\n     while (rowEventsSet1.size() < maxRowSize && iterator.hasNext()) {\n       final Serializable[] row = iterator.next();\n@@ -130,15 +136,10 @@\n \n   public static Collection<Serializable[]> reduce(Map<ServerInstance, DataTable> selectionResults, int maxRowSize) {\n     Collection<Serializable[]> rowEventsSet = new ArrayList<Serializable[]>();\n-\n     for (final DataTable dt : selectionResults.values()) {\n-      for (int rowId = 0; rowId < dt.getNumberOfRows(); ++rowId) {\n+      for (int rowId = 0; rowId < Math.min(dt.getNumberOfRows(), maxRowSize); ++rowId) {\n         final Serializable[] row = extractRowFromDataTable(dt, rowId);\n-        if (rowEventsSet.size() < maxRowSize) {\n-          rowEventsSet.add(row);\n-        } else {\n-          break;\n-        }\n+        rowEventsSet.add(row);\n       }\n     }\n     return rowEventsSet;\n@@ -202,7 +203,7 @@ public static DataSchema extractDataSchema(List<SelectionSort> sortSequence, Lis\n     return new DataSchema(columns.toArray(new String[0]), dataTypes);\n   }\n \n-  public static Serializable[] collectRowFromBlockValSets(int docId, Block[] blocks, DataSchema dataSchema) throws Exception {\n+  public static Serializable[] collectRowFromBlockValSets(int docId, Block[] blocks, DataSchema dataSchema) {\n \n     final Serializable[] row = new Serializable[dataSchema.size()];\n     int j = 0;",
                "changes": 19
            },
            {
                "status": "modified",
                "additions": 0,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "deletions": 1,
                "sha": "d10b5b7a3eb8c1181f3574f55c4818de9e23c3c3",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "patch": "@@ -77,7 +77,6 @@\n   private final String AVRO_DATA = \"data/mirror-mv.avro\";\n   private static File INDEX_DIR = new File(FileUtils.getTempDirectory() + File.separator + \"QueriesSentinelTest\");\n   private static AvroQueryGenerator AVRO_QUERY_GENERATOR;\n-  private static FileBasedInstanceDataManager INSTANCE_DATA_MANAGER;\n   private static QueryExecutor QUERY_EXECUTOR;\n   private static TestingServerPropertiesBuilder CONFIG_BUILDER;\n   private String segmentName;",
                "changes": 1
            },
            {
                "status": "added",
                "additions": 186,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "deletions": 0,
                "sha": "672fa36f779f42a8bad785ac99a0bbc831cf7af3",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "patch": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (C) 2014-2015 LinkedIn Corp. (pinot-core@linkedin.com)\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.linkedin.pinot.queries;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.antlr.runtime.RecognitionException;\n+import org.apache.commons.configuration.PropertiesConfiguration;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import com.linkedin.pinot.common.client.request.RequestConverter;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n+import com.linkedin.pinot.common.query.QueryExecutor;\n+import com.linkedin.pinot.common.query.ReduceService;\n+import com.linkedin.pinot.common.request.BrokerRequest;\n+import com.linkedin.pinot.common.request.InstanceRequest;\n+import com.linkedin.pinot.common.response.BrokerResponse;\n+import com.linkedin.pinot.common.response.ServerInstance;\n+import com.linkedin.pinot.common.segment.ReadMode;\n+import com.linkedin.pinot.common.utils.DataTable;\n+import com.linkedin.pinot.core.data.manager.config.FileBasedInstanceDataManagerConfig;\n+import com.linkedin.pinot.core.data.manager.offline.FileBasedInstanceDataManager;\n+import com.linkedin.pinot.core.indexsegment.IndexSegment;\n+import com.linkedin.pinot.core.indexsegment.columnar.ColumnarSegmentLoader;\n+import com.linkedin.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import com.linkedin.pinot.core.query.executor.ServerQueryExecutorV1Impl;\n+import com.linkedin.pinot.core.query.reduce.DefaultReduceService;\n+import com.linkedin.pinot.core.segment.creator.SegmentIndexCreationDriver;\n+import com.linkedin.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import com.linkedin.pinot.pql.parsers.PQLCompiler;\n+import com.linkedin.pinot.segments.v1.creator.SegmentTestUtils;\n+import com.linkedin.pinot.util.TestUtils;\n+import com.yammer.metrics.core.MetricsRegistry;\n+\n+\n+public class QueryExceptionTest {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(QueriesSentinelTest.class);\n+  private static ReduceService REDUCE_SERVICE = new DefaultReduceService();\n+\n+  private static final PQLCompiler REQUEST_COMPILER = new PQLCompiler(new HashMap<String, String[]>());\n+  private final String AVRO_DATA = \"data/mirror-mv.avro\";\n+  private static File INDEX_DIR = new File(FileUtils.getTempDirectory() + File.separator + \"QueriesSentinelTest\");\n+  private static QueryExecutor QUERY_EXECUTOR;\n+  private static TestingServerPropertiesBuilder CONFIG_BUILDER;\n+  private String segmentName;\n+\n+  @BeforeClass\n+  public void setup() throws Exception {\n+    CONFIG_BUILDER = new TestingServerPropertiesBuilder(\"mirror\");\n+\n+    setupSegmentFor(\"mirror\");\n+\n+    final PropertiesConfiguration serverConf = CONFIG_BUILDER.build();\n+    serverConf.setDelimiterParsingDisabled(false);\n+\n+    final FileBasedInstanceDataManager instanceDataManager = FileBasedInstanceDataManager.getInstanceDataManager();\n+    instanceDataManager.init(new FileBasedInstanceDataManagerConfig(serverConf.subset(\"pinot.server.instance\")));\n+    instanceDataManager.start();\n+\n+    System.out.println(\"************************** : \" + new File(INDEX_DIR, \"segment\").getAbsolutePath());\n+    File segmentFile = new File(INDEX_DIR, \"segment\").listFiles()[0];\n+    segmentName = segmentFile.getName();\n+    final IndexSegment indexSegment = ColumnarSegmentLoader.load(segmentFile, ReadMode.heap);\n+    instanceDataManager.getResourceDataManager(\"mirror\");\n+    instanceDataManager.getResourceDataManager(\"mirror\").addSegment(indexSegment);\n+\n+    QUERY_EXECUTOR = new ServerQueryExecutorV1Impl(false);\n+    QUERY_EXECUTOR.init(serverConf.subset(\"pinot.server.query.executor\"), instanceDataManager, new ServerMetrics(\n+        new MetricsRegistry()));\n+  }\n+\n+  @AfterClass\n+  public void tearDown() {\n+    FileUtils.deleteQuietly(INDEX_DIR);\n+  }\n+\n+  private void setupSegmentFor(String resource) throws Exception {\n+    final String filePath = TestUtils.getFileFromResourceUrl(getClass().getClassLoader().getResource(AVRO_DATA));\n+\n+    if (INDEX_DIR.exists()) {\n+      FileUtils.deleteQuietly(INDEX_DIR);\n+    }\n+    INDEX_DIR.mkdir();\n+\n+    final SegmentGeneratorConfig config =\n+        SegmentTestUtils.getSegmentGenSpecWithSchemAndProjectedColumns(new File(filePath), new File(INDEX_DIR,\n+            \"segment\"), \"daysSinceEpoch\", TimeUnit.DAYS, resource, resource);\n+\n+    final SegmentIndexCreationDriver driver = new SegmentIndexCreationDriverImpl();\n+\n+    driver.init(config);\n+    driver.build();\n+\n+    System.out.println(\"built at : \" + INDEX_DIR.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void testSingleQuery() throws RecognitionException, Exception {\n+    String query = \"select count(*) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is \" + brokerResponse.getAggregationResults().get(0));\n+  }\n+\n+  @Test\n+  public void testQueryParsingFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select sudm(blablaa) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() > 0);\n+  }\n+\n+  @Test\n+  public void testQueryPlanFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select sum(blablaa) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() > 0);\n+  }\n+\n+  @Test\n+  public void testQueryExecuteFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select count(*) from mirror where viewerId='24516187' group by bla\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() == 0);\n+  }\n+}",
                "changes": 186
            },
            {
                "status": "modified",
                "additions": 2,
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "deletions": 0,
                "sha": "57fb3b4a6f47a5f31fdc9f6048feac5fa4007514",
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "patch": "@@ -112,6 +112,8 @@ public PropertiesConfiguration build() throws IOException {\n \n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"pruner.class\"),\n         \"TableNameSegmentPruner\");\n+    config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"pruner.class\"),\n+        \"DataSchemaSegmentPruner\");\n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"class\"),\n         \"com.linkedin.pinot.core.query.executor.ServerQueryExecutor\");\n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"timeout\"), \"150000\");",
                "changes": 2
            }
        ],
        "unit_tests": [
            "TestBrokerResponse.java",
            "TestingServerPropertiesBuilder.java",
            "QueryExceptionTest.java",
            "TestDefaultReduceService.java",
            "TestDataTableBuilder.java",
            "QueriesSentinelTest.java"
        ]
    },
    {
        "buggy": false,
        "test_file": "pinot-common/src/test/java/com/linkedin/pinot/request/TestBrokerResponse.java",
        "buggy_files": [
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
            "pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
            "pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
            "pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTableBuilder.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
            "pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
            "pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java"
        ],
        "fixed": true
    }
]