{
    "incubator-pinot_08a2919": {
        "bug_id": "incubator-pinot_08a2919",
        "commit": "https://github.com/apache/incubator-pinot/commit/08a29193b546f652002f3f80ca7046fa41405953",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/08a29193b546f652002f3f80ca7046fa41405953/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java?ref=08a29193b546f652002f3f80ca7046fa41405953",
                "deletions": 1,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "patch": "@@ -252,7 +252,7 @@ public boolean evaluate(Object object) {\n \n   @JsonIgnore(true)\n   public String getTimeColumnName() {\n-    return timeFieldSpec.getName();\n+    return (timeFieldSpec != null) ? timeFieldSpec.getName() : null;\n   }\n \n   public TimeFieldSpec getTimeFieldSpec() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/08a29193b546f652002f3f80ca7046fa41405953/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "sha": "c5e25ba62e432793947ddb60f57a2437ecebcca3",
                "status": "modified"
            }
        ],
        "message": "NPE fix\n\nRB=495083\nR=kgopalak,xiafu,jfim,dpatel\nA=dpatel",
        "parent": "https://github.com/apache/incubator-pinot/commit/aad717eb4050a375ef586d7f638204fc5079902d",
        "patched_files": [
            "Schema.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestSchema.java"
        ]
    },
    "incubator-pinot_0a32309": {
        "bug_id": "incubator-pinot_0a32309",
        "commit": "https://github.com/apache/incubator-pinot/commit/0a3230928a52814f6926b38038a2f0c9bc704f31",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/0a3230928a52814f6926b38038a2f0c9bc704f31/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DetectionConfigValidator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DetectionConfigValidator.java?ref=0a3230928a52814f6926b38038a2f0c9bc704f31",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DetectionConfigValidator.java",
                "patch": "@@ -159,7 +159,7 @@ private void validateMetricAlertConfig(Map<String, Object> detectionYaml, String\n     // Check if the metric defined in the config exists\n     MetricConfigDTO metricConfig = provider.fetchMetric(metric, dataset);\n     Preconditions.checkArgument(metricConfig != null,\n-        \"Metric doesn't exist in our records. Metric \" + metric + \" in sub-alert \" + alertName);\n+        \"Metric doesn't exist in our records. Metric \" + metric + \" Dataset \" + dataset + \" in sub-alert \" + alertName);\n \n     // Check if the dataset defined in the config exists\n     DatasetConfigDTO datasetConfig = provider",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/0a3230928a52814f6926b38038a2f0c9bc704f31/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DetectionConfigValidator.java",
                "sha": "cc31aa5ab1c28cb839c9c2d1b3d8242c85a044a2",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/0a3230928a52814f6926b38038a2f0c9bc704f31/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/YamlResource.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/YamlResource.java?ref=0a3230928a52814f6926b38038a2f0c9bc704f31",
                "deletions": 4,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/YamlResource.java",
                "patch": "@@ -234,10 +234,12 @@ private Response processBadRequestResponse(String type, String operation, String\n     Map<String, String> responseMessage = new HashMap<>();\n     LOG.warn(\"Validation error while {} {} with payload {}\", operation, type, payload, e);\n     responseMessage.put(\"message\", \"Validation Error in \" + type + \"! \" + e.getMessage());\n-    StringWriter sw = new StringWriter();\n-    PrintWriter pw = new PrintWriter(sw);\n-    e.getCause().printStackTrace(pw);\n-    responseMessage.put(\"more-info\", \"Error = \" + sw.toString());\n+    if (e.getCause() != null) {\n+      StringWriter sw = new StringWriter();\n+      PrintWriter pw = new PrintWriter(sw);\n+      e.getCause().printStackTrace(pw);\n+      responseMessage.put(\"more-info\", \"Error = \" + sw.toString());\n+    }\n     return Response.status(Response.Status.BAD_REQUEST).entity(responseMessage).build();\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/0a3230928a52814f6926b38038a2f0c9bc704f31/thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/YamlResource.java",
                "sha": "8ddc66f269ed5dd4fa81327448a36f460d2ef1ac",
                "status": "modified"
            }
        ],
        "message": "[TE] fix create alert error message NPE (#4594)\n\nThis PR fixes the create alert error message null pointer exception.",
        "parent": "https://github.com/apache/incubator-pinot/commit/5e525d095cfc5d5aa20a2f3de4f9f46d15c4fa22",
        "patched_files": [
            "DetectionConfigValidator.java",
            "YamlResource.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "YamlResourceTest.java",
            "DetectionConfigValidatorTest.java"
        ]
    },
    "incubator-pinot_0b33742": {
        "bug_id": "incubator-pinot_0b33742",
        "commit": "https://github.com/apache/incubator-pinot/commit/0b33742453430bde730fac4f6185ba7970c60991",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/0b33742453430bde730fac4f6185ba7970c60991/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java?ref=0b33742453430bde730fac4f6185ba7970c60991",
                "deletions": 10,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "patch": "@@ -256,19 +256,15 @@ public String getTimeColumnName() {\n   }\n \n   @JsonIgnore(true)\n-  public TimeUnit getIncomingTimeUnit() throws NullPointerException {\n-    if (timeFieldSpec == null || timeFieldSpec.getIncomingGranularitySpec() == null) {\n-      throw new NullPointerException();\n-    }\n-    return timeFieldSpec.getIncomingGranularitySpec().getTimeType();\n+  public TimeUnit getIncomingTimeUnit() {\n+    return (timeFieldSpec != null && timeFieldSpec.getIncomingGranularitySpec() != null) ?\n+        timeFieldSpec.getIncomingGranularitySpec().getTimeType() : null;\n   }\n \n   @JsonIgnore(true)\n-  public TimeUnit getOutgoingTimeUnit() throws NullPointerException {\n-    if (timeFieldSpec == null || timeFieldSpec.getOutgoingGranularitySpec() == null) {\n-      throw new NullPointerException();\n-    }\n-    return timeFieldSpec.getIncomingGranularitySpec().getTimeType();\n+  public TimeUnit getOutgoingTimeUnit() {\n+    return (timeFieldSpec != null && timeFieldSpec.getOutgoingGranularitySpec() != null) ?\n+        timeFieldSpec.getIncomingGranularitySpec().getTimeType() : null;\n   }\n \n   public TimeFieldSpec getTimeFieldSpec() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/0b33742453430bde730fac4f6185ba7970c60991/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "sha": "e9fe8525da72971616a507ef2620f20c135c9b69",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/0b33742453430bde730fac4f6185ba7970c60991/pinot-perf/src/main/java/com/linkedin/pinot/perf/PerfBenchmarkRunner.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-perf/src/main/java/com/linkedin/pinot/perf/PerfBenchmarkRunner.java?ref=0b33742453430bde730fac4f6185ba7970c60991",
                "deletions": 1,
                "filename": "pinot-perf/src/main/java/com/linkedin/pinot/perf/PerfBenchmarkRunner.java",
                "patch": "@@ -99,7 +99,7 @@ public static void main(String[] args) throws Exception {\n       }\n \n     } else {\n-      System.err.println(\"Expected one of [setupWithPreLoadedSegments]\");\n+      System.err.println(\"Expected one of [startAll|startAllButServer|StartServerWithPreLoadedSegments]\");\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/0b33742453430bde730fac4f6185ba7970c60991/pinot-perf/src/main/java/com/linkedin/pinot/perf/PerfBenchmarkRunner.java",
                "sha": "b9e63e0f0cb0dd7f51753544344cca759e3c33f7",
                "status": "modified"
            }
        ],
        "message": "Avoid throwing NPE",
        "parent": "https://github.com/apache/incubator-pinot/commit/a26c9adc7bbb75217ea4abfb3c36b7ae6e674a87",
        "patched_files": [
            "Schema.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestSchema.java"
        ]
    },
    "incubator-pinot_1b8be22": {
        "bug_id": "incubator-pinot_1b8be22",
        "commit": "https://github.com/apache/incubator-pinot/commit/1b8be226b0084cbd6ae246a1e86df9aad5f95045",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1b8be226b0084cbd6ae246a1e86df9aad5f95045/thirdeye/thirdeye-core/src/main/java/com/linkedin/thirdeye/impl/StarTreeImpl.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-core/src/main/java/com/linkedin/thirdeye/impl/StarTreeImpl.java?ref=1b8be226b0084cbd6ae246a1e86df9aad5f95045",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-core/src/main/java/com/linkedin/thirdeye/impl/StarTreeImpl.java",
                "patch": "@@ -251,7 +251,11 @@ public void close() throws IOException {\n \n   private void close(StarTreeNode node) throws IOException {\n     if (node.isLeaf()) {\n-      node.getRecordStore().close();\n+      if (node.getRecordStore() != null) {\n+        node.getRecordStore().close();\n+      } else {\n+        throw new IllegalStateException(\"Cannot close null record store for leaf node \"+node.getId());\n+      }\n     } else {\n       for (StarTreeNode child : node.getChildren()) {\n         close(child);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1b8be226b0084cbd6ae246a1e86df9aad5f95045/thirdeye/thirdeye-core/src/main/java/com/linkedin/thirdeye/impl/StarTreeImpl.java",
                "sha": "00b94cac4fd53a8d9015dd42e413da5ba0f59751",
                "status": "modified"
            }
        ],
        "message": "THIRDEYE-335 : DELETE of collection resulted in NPE\n\nRB=471549\nR=kgopalak,gbrandt\nA=gbrandt",
        "parent": "https://github.com/apache/incubator-pinot/commit/05ba487d43ea015fddd1d903257da9118264983e",
        "patched_files": [
            "StarTreeImpl.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestStarTreeImpl.java"
        ]
    },
    "incubator-pinot_1bf0f91": {
        "bug_id": "incubator-pinot_1bf0f91",
        "commit": "https://github.com/apache/incubator-pinot/commit/1bf0f913568c4e3f08546ea55934139340735f2b",
        "file": [
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResource.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResource.java?ref=1bf0f913568c4e3f08546ea55934139340735f2b",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResource.java",
                "patch": "@@ -23,6 +23,7 @@\n import com.linkedin.pinot.common.metrics.ControllerMeter;\n import com.linkedin.pinot.common.metrics.ControllerMetrics;\n import com.linkedin.pinot.common.utils.CommonConstants;\n+import com.linkedin.pinot.common.utils.CommonConstants.Helix.TableType;\n import com.linkedin.pinot.controller.ControllerConf;\n import com.linkedin.pinot.controller.helix.core.PinotHelixResourceManager;\n import com.linkedin.pinot.controller.helix.core.PinotResourceManagerResponse;\n@@ -413,10 +414,17 @@ public String rebalance(\n     rebalanceUserConfig.addProperty(RebalanceUserConfigConstants.DRYRUN, dryRun);\n     rebalanceUserConfig.addProperty(RebalanceUserConfigConstants.INCLUDE_CONSUMING, includeConsuming);\n \n+    TableType type = TableType.valueOf(tableType.toUpperCase());\n+    if (type == TableType.OFFLINE && (!_pinotHelixResourceManager.hasOfflineTable(tableName))\n+        || type == TableType.REALTIME && (!_pinotHelixResourceManager\n+        .hasRealtimeTable(tableName))) {\n+      throw new ControllerApplicationException(LOGGER, \"Table \" + tableName + \" does not exist\",\n+          Response.Status.NOT_FOUND);\n+    }\n+\n     JSONObject jsonObject;\n     try {\n-      jsonObject = _pinotHelixResourceManager.rebalanceTable(tableName,\n-          CommonConstants.Helix.TableType.valueOf(tableType.toUpperCase()), rebalanceUserConfig);\n+      jsonObject = _pinotHelixResourceManager.rebalanceTable(tableName, type, rebalanceUserConfig);\n     } catch (JSONException e) {\n       throw new ControllerApplicationException(LOGGER, e.getMessage(), Response.Status.INTERNAL_SERVER_ERROR);\n     } catch (InvalidConfigException e) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResource.java",
                "sha": "e5d7dd704fc874347261b8998f18ba8864d43599",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/ControllerRequestURLBuilder.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/ControllerRequestURLBuilder.java?ref=1bf0f913568c4e3f08546ea55934139340735f2b",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/ControllerRequestURLBuilder.java",
                "patch": "@@ -135,6 +135,11 @@ public String forUpdateTableConfig(String tableName) {\n     return StringUtil.join(\"/\", StringUtils.chomp(_baseUrl, \"/\"), \"tables\", tableName);\n   }\n \n+  public String forTableRebalance(String tableName, String tableType) {\n+    String query = \"rebalance?dryrun=false&type=\" + tableType;\n+    return StringUtil.join(\"/\", StringUtils.chomp(_baseUrl, \"/\"), \"tables\", tableName, query);\n+  }\n+\n   public String forTableUpdateIndexingConfigs(String tableName) {\n     return StringUtil.join(\"/\", StringUtils.chomp(_baseUrl, \"/\"), \"tables\", tableName, \"indexingConfigs\");\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/ControllerRequestURLBuilder.java",
                "sha": "bccc21ad2daeb56cfb2e7014164bbe4bb3d6aa4b",
                "status": "modified"
            },
            {
                "additions": 47,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "changes": 47,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResourceTest.java?ref=1bf0f913568c4e3f08546ea55934139340735f2b",
                "deletions": 0,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "patch": "@@ -28,6 +28,7 @@\n import java.io.IOException;\n import java.util.HashMap;\n import java.util.Map;\n+import org.json.JSONException;\n import org.json.JSONObject;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n@@ -266,6 +267,52 @@ public void testUpdateTableConfig() throws Exception {\n     Assert.assertTrue(notFoundException);\n   }\n \n+  @Test(expectedExceptions = FileNotFoundException.class)\n+  public void rebalanceNonExistentOfflineTable() throws IOException, JSONException {\n+    String tableName = \"nonExistentTable\";\n+    // should result in file not found exception\n+    sendPostRequest(_controllerRequestURLBuilder.forTableRebalance(tableName, \"offline\"), null);\n+  }\n+\n+  @Test(expectedExceptions = FileNotFoundException.class)\n+  public void rebalanceNonExistentRealtimeTable() throws IOException, JSONException {\n+    String tableName = \"nonExistentTable\";\n+    // should result in file not found exception\n+    sendPostRequest(_controllerRequestURLBuilder.forTableRebalance(tableName, \"realtime\"), null);\n+  }\n+\n+  @Test\n+  public void rebalanceOfflineTable() {\n+    String tableName = \"testOfflineTable\";\n+    _offlineBuilder.setTableName(tableName);\n+    // create the table\n+    try {\n+      TableConfig offlineTableConfig = _offlineBuilder.build();\n+      sendPostRequest(_createTableUrl, offlineTableConfig.toJSONConfigString());\n+    } catch (Exception e) {\n+      Assert.fail(\"Failed to create offline table \" + tableName + \"Error: \" + e.getMessage());\n+    }\n+\n+    // rebalance should not throw exception\n+    try {\n+      sendPostRequest(_controllerRequestURLBuilder.forTableRebalance(tableName, \"offline\"), null);\n+    } catch (Exception e) {\n+      Assert.fail(\"Failed to rebalance existing offline table \" + tableName);\n+    }\n+\n+    // rebalance should throw exception because realtime table does not exist\n+    try {\n+      sendPostRequest(_controllerRequestURLBuilder.forTableRebalance(tableName, \"realtime\"), null);\n+    } catch (Exception e) {\n+      if (!(e instanceof FileNotFoundException)) {\n+        Assert.fail(\"Did not fail to create non existent realtime table \" + tableName);\n+      } else {\n+        return;\n+      }\n+    }\n+    Assert.fail(\"Did not fail to create non existent realtime table \" + tableName);\n+  }\n+\n   @AfterClass\n   public void tearDown() {\n     stopController();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1bf0f913568c4e3f08546ea55934139340735f2b/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "sha": "7ef3eb87ec97a80dbac476ab282eb0e56ccce926",
                "status": "modified"
            }
        ],
        "message": "Fix NPE when rebalance is called with a table that does not exist (#2969)",
        "parent": "https://github.com/apache/incubator-pinot/commit/80ddaf48cd61e8d9fa3e558eedf829f60aa23bb9",
        "patched_files": [
            "PinotTableRestletResource.java",
            "ControllerRequestURLBuilder.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotTableRestletResourceTest.java"
        ]
    },
    "incubator-pinot_1cb9b44": {
        "bug_id": "incubator-pinot_1cb9b44",
        "commit": "https://github.com/apache/incubator-pinot/commit/1cb9b44c1cd470662d22b3113c8dec4e11612e03",
        "file": [
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1cb9b44c1cd470662d22b3113c8dec4e11612e03/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java?ref=1cb9b44c1cd470662d22b3113c8dec4e11612e03",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "patch": "@@ -1,11 +1,13 @@\n package com.linkedin.pinot.controller.api.restlet.resources;\n \n+import com.linkedin.pinot.common.data.Schema;\n import java.io.File;\n import java.io.IOException;\n \n import com.linkedin.pinot.common.metrics.ControllerMeter;\n import com.linkedin.pinot.controller.api.ControllerRestApplication;\n import org.apache.commons.io.FileUtils;\n+import org.restlet.data.MediaType;\n import org.restlet.data.Status;\n import org.restlet.representation.Representation;\n import org.restlet.representation.StringRepresentation;\n@@ -72,8 +74,15 @@ private Representation getTableSchema(\n       AbstractTableConfig config;\n       try {\n         config = _pinotHelixResourceManager.getTableConfig(tableName, TableType.OFFLINE);\n-        return new StringRepresentation(_pinotHelixResourceManager.getSchema(config.getValidationConfig().getSchemaName()).getJSONSchema()\n-            .toString());\n+        String schemaName = config.getValidationConfig().getSchemaName();\n+        Schema schema = _pinotHelixResourceManager.getSchema(schemaName);\n+        if (schema == null) {\n+          setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n+          StringRepresentation repr = new StringRepresentation(\"{\\\"error\\\": \\\"Schema \" + schemaName + \" not found\\\"\");\n+          repr.setMediaType(MediaType.APPLICATION_JSON);\n+          return repr;\n+        }\n+        return new StringRepresentation(schema.getJSONSchema().toString());\n       } catch (Exception e) {\n         LOGGER.error(\"Caught exception while fetching schema for a offline table : {} \", tableName, e);\n         ControllerRestApplication.getControllerMetrics().addMeteredGlobalValue(ControllerMeter.CONTROLLER_TABLE_SCHEMA_GET_ERROR, 1L);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1cb9b44c1cd470662d22b3113c8dec4e11612e03/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "sha": "691941059cab484ea88d7f0c3c9d1e5ff2b1ecd3",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/1cb9b44c1cd470662d22b3113c8dec4e11612e03/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=1cb9b44c1cd470662d22b3113c8dec4e11612e03",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -24,6 +24,7 @@\n import java.util.Set;\n import java.util.concurrent.Callable;\n import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n import org.apache.commons.collections.CollectionUtils;\n import org.apache.commons.collections.Predicate;\n import org.apache.helix.AccessOption;\n@@ -863,10 +864,9 @@ public boolean deleteSchema(Schema schema) {\n    * @throws JsonMappingException\n    * @throws IOException\n    */\n-  public Schema getSchema(String schemaName) throws JsonParseException, JsonMappingException, IOException {\n+  public @Nullable Schema getSchema(String schemaName) throws JsonParseException, JsonMappingException, IOException {\n     PinotHelixPropertyStoreZnRecordProvider propertyStoreHelper =\n         PinotHelixPropertyStoreZnRecordProvider.forSchema(_propertyStore);\n-    LOGGER.info(\"found schema {} \", schemaName);\n     ZNRecord record = propertyStoreHelper.get(schemaName);\n     return record != null ? SchemaUtils.fromZNRecord(record) : null;\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/1cb9b44c1cd470662d22b3113c8dec4e11612e03/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "d3734137476e81fc62fd2d24e3b857ebc9e76f8e",
                "status": "modified"
            }
        ],
        "message": "Fix NPE and return 404 if schema is not found (#696)\n\nOn controller REST API call to read table schema, return\r\n404 if the schema is not found. This also fixes NPE issue.",
        "parent": "https://github.com/apache/incubator-pinot/commit/00047a7af24721cd3ed82c4a74aebb4e659432be",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    },
    "incubator-pinot_21bb2b8": {
        "bug_id": "incubator-pinot_21bb2b8",
        "commit": "https://github.com/apache/incubator-pinot/commit/21bb2b849e6de348406516ed84ce7532703d1e2e",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/21bb2b849e6de348406516ed84ce7532703d1e2e/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=21bb2b849e6de348406516ed84ce7532703d1e2e",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -1114,8 +1114,10 @@ public void deleteRealtimeTable(String tableName) {\n     // Remove groupId/PartitionId mapping for realtime table type.\n     for (String instance : getAllInstancesForTable(realtimeTableName)) {\n       InstanceZKMetadata instanceZKMetadata = ZKMetadataProvider.getInstanceZKMetadata(getPropertyStore(), instance);\n-      instanceZKMetadata.removeResource(realtimeTableName);\n-      ZKMetadataProvider.setInstanceZKMetadata(getPropertyStore(), instanceZKMetadata);\n+      if (instanceZKMetadata != null) {\n+        instanceZKMetadata.removeResource(realtimeTableName);\n+        ZKMetadataProvider.setInstanceZKMetadata(getPropertyStore(), instanceZKMetadata);\n+      }\n     }\n \n     // dropping table",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/21bb2b849e6de348406516ed84ce7532703d1e2e/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "efe20f6ce11e4615aa4b49e49524d936aa6690b6",
                "status": "modified"
            }
        ],
        "message": "Fixed DELETE table to not throw NPE when table has only LLC consumer type (#421)",
        "parent": "https://github.com/apache/incubator-pinot/commit/e2992e6d1bd421ce79faad5ac4ce31cf3132739e",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    },
    "incubator-pinot_2221623": {
        "bug_id": "incubator-pinot_2221623",
        "commit": "https://github.com/apache/incubator-pinot/commit/222162323d7a782a10d831ced93b95538a90e74a",
        "file": [
            {
                "additions": 58,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/222162323d7a782a10d831ced93b95538a90e74a/pinot-common/src/main/java/org/apache/pinot/common/metadata/ZKMetadataProvider.java",
                "changes": 98,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/org/apache/pinot/common/metadata/ZKMetadataProvider.java?ref=222162323d7a782a10d831ced93b95538a90e74a",
                "deletions": 40,
                "filename": "pinot-common/src/main/java/org/apache/pinot/common/metadata/ZKMetadataProvider.java",
                "patch": "@@ -297,70 +297,88 @@ public static Schema getTableSchema(@Nonnull ZkHelixPropertyStore<ZNRecord> prop\n    */\n   public static List<OfflineSegmentZKMetadata> getOfflineSegmentZKMetadataListForTable(\n       ZkHelixPropertyStore<ZNRecord> propertyStore, String tableName) {\n-    List<OfflineSegmentZKMetadata> resultList = new ArrayList<>();\n-    if (propertyStore == null) {\n-      return resultList;\n-    }\n     String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(tableName);\n-    if (propertyStore.exists(constructPropertyStorePathForResource(offlineTableName), AccessOption.PERSISTENT)) {\n-      List<ZNRecord> znRecordList = propertyStore\n-          .getChildren(constructPropertyStorePathForResource(offlineTableName), null, AccessOption.PERSISTENT);\n-      if (znRecordList != null) {\n-        for (ZNRecord record : znRecordList) {\n-          resultList.add(new OfflineSegmentZKMetadata(record));\n+    String parentPath = constructPropertyStorePathForResource(offlineTableName);\n+    List<ZNRecord> znRecords = propertyStore.getChildren(parentPath, null, AccessOption.PERSISTENT);\n+    if (znRecords != null) {\n+      int numZNRecords = znRecords.size();\n+      List<OfflineSegmentZKMetadata> offlineSegmentZKMetadataList = new ArrayList<>(numZNRecords);\n+      for (ZNRecord znRecord : znRecords) {\n+        // NOTE: it is possible that znRecord is null if the record gets removed while calling this method\n+        if (znRecord != null) {\n+          offlineSegmentZKMetadataList.add(new OfflineSegmentZKMetadata(znRecord));\n         }\n       }\n+      int numNullZNRecords = numZNRecords - offlineSegmentZKMetadataList.size();\n+      if (numNullZNRecords > 0) {\n+        LOGGER.warn(\"Failed to read {}/{} offline segment ZK metadata under path: {}\", numZNRecords - numNullZNRecords,\n+            numZNRecords, parentPath);\n+      }\n+      return offlineSegmentZKMetadataList;\n+    } else {\n+      LOGGER.warn(\"Path: {} does not exist\", parentPath);\n+      return Collections.emptyList();\n     }\n-    return resultList;\n   }\n \n   /**\n    * NOTE: this method is very expensive, use {@link #getSegments(ZkHelixPropertyStore, String)} instead if only segment\n    * segment names are needed.\n    */\n   public static List<RealtimeSegmentZKMetadata> getRealtimeSegmentZKMetadataListForTable(\n-      ZkHelixPropertyStore<ZNRecord> propertyStore, String resourceName) {\n-    List<RealtimeSegmentZKMetadata> resultList = new ArrayList<>();\n-    if (propertyStore == null) {\n-      return resultList;\n-    }\n-    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(resourceName);\n-    if (propertyStore.exists(constructPropertyStorePathForResource(realtimeTableName), AccessOption.PERSISTENT)) {\n-      List<ZNRecord> znRecordList = propertyStore\n-          .getChildren(constructPropertyStorePathForResource(realtimeTableName), null, AccessOption.PERSISTENT);\n-      if (znRecordList != null) {\n-        for (ZNRecord record : znRecordList) {\n-          resultList.add(new RealtimeSegmentZKMetadata(record));\n+      ZkHelixPropertyStore<ZNRecord> propertyStore, String tableName) {\n+    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(tableName);\n+    String parentPath = constructPropertyStorePathForResource(realtimeTableName);\n+    List<ZNRecord> znRecords = propertyStore.getChildren(parentPath, null, AccessOption.PERSISTENT);\n+    if (znRecords != null) {\n+      int numZNRecords = znRecords.size();\n+      List<RealtimeSegmentZKMetadata> realtimeSegmentZKMetadataList = new ArrayList<>(numZNRecords);\n+      for (ZNRecord znRecord : znRecords) {\n+        // NOTE: it is possible that znRecord is null if the record gets removed while calling this method\n+        if (znRecord != null) {\n+          realtimeSegmentZKMetadataList.add(new RealtimeSegmentZKMetadata(znRecord));\n         }\n       }\n+      int numNullZNRecords = numZNRecords - realtimeSegmentZKMetadataList.size();\n+      if (numNullZNRecords > 0) {\n+        LOGGER.warn(\"Failed to read {}/{} realtime segment ZK metadata under path: {}\", numZNRecords - numNullZNRecords,\n+            numZNRecords, parentPath);\n+      }\n+      return realtimeSegmentZKMetadataList;\n+    } else {\n+      LOGGER.warn(\"Path: {} does not exist\", parentPath);\n+      return Collections.emptyList();\n     }\n-    return resultList;\n   }\n \n   /**\n    * NOTE: this method is very expensive, use {@link #getLLCRealtimeSegments(ZkHelixPropertyStore, String)} instead if\n    * only segment names are needed.\n    */\n   public static List<LLCRealtimeSegmentZKMetadata> getLLCRealtimeSegmentZKMetadataListForTable(\n-      ZkHelixPropertyStore<ZNRecord> propertyStore, String resourceName) {\n-    List<LLCRealtimeSegmentZKMetadata> resultList = new ArrayList<>();\n-    if (propertyStore == null) {\n-      return resultList;\n-    }\n-    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(resourceName);\n-    if (propertyStore.exists(constructPropertyStorePathForResource(realtimeTableName), AccessOption.PERSISTENT)) {\n-      List<ZNRecord> znRecordList = propertyStore\n-          .getChildren(constructPropertyStorePathForResource(realtimeTableName), null, AccessOption.PERSISTENT);\n-      if (znRecordList != null) {\n-        for (ZNRecord record : znRecordList) {\n-          RealtimeSegmentZKMetadata realtimeSegmentZKMetadata = new RealtimeSegmentZKMetadata(record);\n-          if (SegmentName.isLowLevelConsumerSegmentName(realtimeSegmentZKMetadata.getSegmentName())) {\n-            resultList.add(new LLCRealtimeSegmentZKMetadata(record));\n-          }\n+      ZkHelixPropertyStore<ZNRecord> propertyStore, String tableName) {\n+    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(tableName);\n+    String parentPath = constructPropertyStorePathForResource(realtimeTableName);\n+    List<ZNRecord> znRecords = propertyStore.getChildren(parentPath, null, AccessOption.PERSISTENT);\n+    if (znRecords != null) {\n+      int numZNRecords = znRecords.size();\n+      List<LLCRealtimeSegmentZKMetadata> llcRealtimeSegmentZKMetadataList = new ArrayList<>(numZNRecords);\n+      for (ZNRecord znRecord : znRecords) {\n+        // NOTE: it is possible that znRecord is null if the record gets removed while calling this method\n+        if (znRecord != null) {\n+          llcRealtimeSegmentZKMetadataList.add(new LLCRealtimeSegmentZKMetadata(znRecord));\n         }\n       }\n+      int numNullZNRecords = numZNRecords - llcRealtimeSegmentZKMetadataList.size();\n+      if (numNullZNRecords > 0) {\n+        LOGGER.warn(\"Failed to read {}/{} LLC realtime segment ZK metadata under path: {}\",\n+            numZNRecords - numNullZNRecords, numZNRecords, parentPath);\n+      }\n+      return llcRealtimeSegmentZKMetadataList;\n+    } else {\n+      LOGGER.warn(\"Path: {} does not exist\", parentPath);\n+      return Collections.emptyList();\n     }\n-    return resultList;\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/222162323d7a782a10d831ced93b95538a90e74a/pinot-common/src/main/java/org/apache/pinot/common/metadata/ZKMetadataProvider.java",
                "sha": "6634b2787777a6d03f33673a54ffdfcce333df1d",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/222162323d7a782a10d831ced93b95538a90e74a/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=222162323d7a782a10d831ced93b95538a90e74a",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -289,8 +289,18 @@ private HelixManager registerAndConnectAsHelixParticipant() {\n    */\n   public List<InstanceConfig> getAllHelixInstanceConfigs() {\n     List<ZNRecord> znRecords = _cacheInstanceConfigsDataAccessor.getChildren(\"/\", null, AccessOption.PERSISTENT);\n-    List<InstanceConfig> instanceConfigs = new ArrayList<>(znRecords.size());\n-    znRecords.forEach(znRecord -> instanceConfigs.add(new InstanceConfig(znRecord)));\n+    int numZNRecords = znRecords.size();\n+    List<InstanceConfig> instanceConfigs = new ArrayList<>(numZNRecords);\n+    for (ZNRecord znRecord : znRecords) {\n+      // NOTE: it is possible that znRecord is null if the record gets removed while calling this method\n+      if (znRecord != null) {\n+        instanceConfigs.add(new InstanceConfig(znRecord));\n+      }\n+    }\n+    int numNullZNRecords = numZNRecords - instanceConfigs.size();\n+    if (numNullZNRecords > 0) {\n+      LOGGER.warn(\"Failed to read {}/{} instance configs\", numZNRecords - numNullZNRecords, numZNRecords);\n+    }\n     return instanceConfigs;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/222162323d7a782a10d831ced93b95538a90e74a/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "0d0f6c07ba999aefe873b15d48feaed0d40b4da7",
                "status": "modified"
            },
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/222162323d7a782a10d831ced93b95538a90e74a/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java?ref=222162323d7a782a10d831ced93b95538a90e74a",
                "deletions": 8,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "patch": "@@ -82,7 +82,8 @@\n   private ControllerMetrics _controllerMetrics;\n   private final ControllerLeadershipManager _controllerLeadershipManager;\n \n-  public PinotRealtimeSegmentManager(PinotHelixResourceManager pinotManager, ControllerLeadershipManager controllerLeadershipManager) {\n+  public PinotRealtimeSegmentManager(PinotHelixResourceManager pinotManager,\n+      ControllerLeadershipManager controllerLeadershipManager) {\n     _pinotHelixResourceManager = pinotManager;\n     _controllerLeadershipManager = controllerLeadershipManager;\n     String clusterName = _pinotHelixResourceManager.getHelixClusterName();\n@@ -331,6 +332,10 @@ private void refreshWatchers(String path) {\n     }\n \n     for (ZNRecord tableConfigZnRecord : tableConfigs) {\n+      // NOTE: it is possible that znRecord is null if the record gets removed while calling this method\n+      if (tableConfigZnRecord == null) {\n+        continue;\n+      }\n       try {\n         String znRecordId = tableConfigZnRecord.getId();\n         if (TableNameBuilder.getTableTypeFromTableName(znRecordId) == TableType.REALTIME) {\n@@ -374,13 +379,8 @@ private void refreshWatchers(String path) {\n       } catch (Exception e) {\n         // we want to continue setting watches for other tables for any kind of exception here so that\n         // errors with one table don't impact others\n-        if (tableConfigZnRecord == null) {\n-          // Can happen if the table config zn record failed to parse.\n-          LOGGER.error(\"Got null ZN record for table config\", e);\n-        } else {\n-          LOGGER.error(\"Caught exception while processing ZNRecord id: {}. Skipping node to continue setting watches\",\n-              tableConfigZnRecord.getId(), e);\n-        }\n+        LOGGER.error(\"Caught exception while processing ZNRecord id: {}. Skipping node to continue setting watches\",\n+            tableConfigZnRecord.getId(), e);\n       }\n     }\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/222162323d7a782a10d831ced93b95538a90e74a/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "sha": "331a4a0a9f0ac8b0e2436db72afadff79b4879a8",
                "status": "modified"
            }
        ],
        "message": "Fix the issue where ZkCacheBaseDataAccessor.getChildren() can return list with null znRecords (#4152)\n\nThis can happen if the record gets removed while calling this method.\r\nNeed to handle it to prevent NPE.",
        "parent": "https://github.com/apache/incubator-pinot/commit/032866202df9d9cdb45fead75dbeed100be22a0a",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    },
    "incubator-pinot_2d20c64": {
        "bug_id": "incubator-pinot_2d20c64",
        "commit": "https://github.com/apache/incubator-pinot/commit/2d20c64793474125a575df3b9b0fd8d90a1afd1e",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/2d20c64793474125a575df3b9b0fd8d90a1afd1e/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManagerTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManagerTest.java?ref=2d20c64793474125a575df3b9b0fd8d90a1afd1e",
                "deletions": 1,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManagerTest.java",
                "patch": "@@ -1559,7 +1559,7 @@ protected int getPartitionCount(StreamConfig metadata) {\n     @Override\n     public LLCRealtimeSegmentZKMetadata getRealtimeSegmentZKMetadata(String realtimeTableName, String segmentName,\n         Stat stat) {\n-      LLCRealtimeSegmentZKMetadata metadata = super.getRealtimeSegmentZKMetadata(realtimeTableName, segmentName, stat);\n+      LLCRealtimeSegmentZKMetadata metadata = _metadataMap.get(segmentName);\n       switch (_scenario) {\n         case SCENARIO_1_ZK_VERSION_NUM_HAS_CHANGE:\n           // Mock another controller has already updated the segment metadata, which makes the version number self increase.",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/2d20c64793474125a575df3b9b0fd8d90a1afd1e/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManagerTest.java",
                "sha": "50042e9ae61347b801430836d28859154d2a94ad",
                "status": "modified"
            }
        ],
        "message": "Possible fix for NPE seen in this test. (#4684)",
        "parent": "https://github.com/apache/incubator-pinot/commit/18a9f2fa62e1aebe5c5678fa696faffc44e548d7",
        "patched_files": [
            "PinotLLCRealtimeSegmentManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotLLCRealtimeSegmentManagerTest.java"
        ]
    },
    "incubator-pinot_2f0e003": {
        "bug_id": "incubator-pinot_2f0e003",
        "commit": "https://github.com/apache/incubator-pinot/commit/2f0e00392a9f52ffb1a6fdf263e826e699daf38c",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/2f0e00392a9f52ffb1a6fdf263e826e699daf38c/pinot-common/src/main/java/com/linkedin/pinot/common/data/FieldSpec.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/data/FieldSpec.java?ref=2f0e00392a9f52ffb1a6fdf263e826e699daf38c",
                "deletions": 2,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/data/FieldSpec.java",
                "patch": "@@ -21,7 +21,6 @@\n import com.linkedin.pinot.common.utils.DataSchema;\n import com.linkedin.pinot.common.utils.EqualityUtils;\n import javax.annotation.Nonnull;\n-import javax.annotation.Nullable;\n import org.apache.avro.Schema.Type;\n \n \n@@ -123,7 +122,7 @@ public void setDefaultNullValue(@Nonnull Object defaultNullValue) {\n   }\n \n   private static Object getDefaultNullValue(@Nonnull FieldType fieldType, @Nonnull DataType dataType,\n-      @Nullable String stringDefaultNullValue) {\n+      String stringDefaultNullValue) {\n     if (stringDefaultNullValue != null) {\n       switch (dataType) {\n         case INT:",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/2f0e00392a9f52ffb1a6fdf263e826e699daf38c/pinot-common/src/main/java/com/linkedin/pinot/common/data/FieldSpec.java",
                "sha": "91be6d07674abc1a9070a6f97741d067d2fa4c3b",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/2f0e00392a9f52ffb1a6fdf263e826e699daf38c/pinot-common/src/main/java/com/linkedin/pinot/common/data/MetricFieldSpec.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/data/MetricFieldSpec.java?ref=2f0e00392a9f52ffb1a6fdf263e826e699daf38c",
                "deletions": 4,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/data/MetricFieldSpec.java",
                "patch": "@@ -19,7 +19,6 @@\n import com.google.gson.JsonObject;\n import com.linkedin.pinot.common.utils.EqualityUtils;\n import javax.annotation.Nonnull;\n-import javax.annotation.Nullable;\n import org.codehaus.jackson.annotate.JsonIgnore;\n import org.codehaus.jackson.annotate.JsonIgnoreProperties;\n \n@@ -78,20 +77,19 @@ public int getFieldSize() {\n   // Required by JSON de-serializer. DO NOT REMOVE.\n   public void setFieldSize(int fieldSize) {\n     Preconditions.checkArgument(fieldSize > 0, \"Field size: \" + fieldSize + \" is not a positive number.\");\n-    if (_dataType != DataType.STRING) {\n+    if (_dataType != null && _dataType != DataType.STRING) {\n       Preconditions.checkArgument(fieldSize == _dataType.size(),\n           \"Field size: \" + fieldSize + \" does not match data type: \" + _dataType);\n     }\n     _fieldSize = fieldSize;\n   }\n \n-  @Nullable\n   public DerivedMetricType getDerivedMetricType() {\n     return _derivedMetricType;\n   }\n \n   // Required by JSON de-serializer. DO NOT REMOVE.\n-  public void setDerivedMetricType(@Nullable DerivedMetricType derivedMetricType) {\n+  public void setDerivedMetricType(DerivedMetricType derivedMetricType) {\n     _derivedMetricType = derivedMetricType;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/2f0e00392a9f52ffb1a6fdf263e826e699daf38c/pinot-common/src/main/java/com/linkedin/pinot/common/data/MetricFieldSpec.java",
                "sha": "5d13fe1c410b2e483ef954276c7f15440c79f29b",
                "status": "modified"
            }
        ],
        "message": "Fix the NPE in MetricFieldSpec.setFieldSize() (#2493)",
        "parent": "https://github.com/apache/incubator-pinot/commit/f617059b1d1a99733f7264dd8ca885879eb21bd3",
        "patched_files": [
            "FieldSpec.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "FieldSpecTest.java"
        ]
    },
    "incubator-pinot_30722d3": {
        "bug_id": "incubator-pinot_30722d3",
        "commit": "https://github.com/apache/incubator-pinot/commit/30722d3429fee28f5cba7ef6cc992338c362c68a",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/30722d3429fee28f5cba7ef6cc992338c362c68a/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=30722d3429fee28f5cba7ef6cc992338c362c68a",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -172,6 +172,12 @@ private void updateDeletionStrategiesForEntireCluster() {\n       LOGGER.error(\"Error getting offline table config from property store!\", e);\n       return tableToDeletionStrategyMap;\n     }\n+\n+    if (offlineTableConfig == null) {\n+      LOGGER.info(\"Table config null for table: {}, treating it as refresh only table.\", offlineTableName);\n+      return tableToDeletionStrategyMap;\n+    }\n+    \n     if (offlineTableConfig.getValidationConfig().getSegmentPushType().equalsIgnoreCase(\"REFRESH\")) {\n       LOGGER.info(\"Table: {} is a refresh only table.\", offlineTableName);\n       return tableToDeletionStrategyMap;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/30722d3429fee28f5cba7ef6cc992338c362c68a/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "f59b467ecbf36c68e29e33e96f26cb3398d0db65",
                "status": "modified"
            }
        ],
        "message": "[PINOT-1978]: Fix for NPE in Retention Manager",
        "parent": "https://github.com/apache/incubator-pinot/commit/3a533fc9625b85de2b816d92fc5b3954abf01417",
        "patched_files": [
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_319e1aa": {
        "bug_id": "incubator-pinot_319e1aa",
        "commit": "https://github.com/apache/incubator-pinot/commit/319e1aa8d6e1ed3b1a129606df6731d662204520",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/319e1aa8d6e1ed3b1a129606df6731d662204520/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=319e1aa8d6e1ed3b1a129606df6731d662204520",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -191,7 +191,7 @@ private void updateDeletionStrategiesForEntireCluster() {\n \n     AbstractTableConfig realtimeTableConfig;\n     try {\n-      realtimeTableConfig = ZKMetadataProvider.getOfflineTableConfig(_pinotHelixResourceManager.getPropertyStore(), realtimeTableName);\n+      realtimeTableConfig = ZKMetadataProvider.getRealtimeTableConfig(_pinotHelixResourceManager.getPropertyStore(), realtimeTableName);\n     } catch (Exception e) {\n       LOGGER.error(\"Error getting realtime table config from property store!\", e);\n       return tableToDeletionStrategyMap;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/319e1aa8d6e1ed3b1a129606df6731d662204520/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "c678b2ebd3860351cfbfaeba612928546634af89",
                "status": "modified"
            }
        ],
        "message": "Merge pull request #17 from fx19880617/master\n\nFixing realtime retention NPE",
        "parent": "https://github.com/apache/incubator-pinot/commit/c875cc0a91046c21f5cfd53fbb98a24c13ce34b1",
        "patched_files": [
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_46eaed6": {
        "bug_id": "incubator-pinot_46eaed6",
        "commit": "https://github.com/apache/incubator-pinot/commit/46eaed6e931fb633d415877c3430d134b4163141",
        "file": [
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "patch": "@@ -122,7 +122,6 @@ public void start() {\n       LOGGER.info(\"Starting task manager\");\n       _taskManager =\n           new PinotTaskManager(taskDriver, helixResourceManager, _helixTaskResourceManager, config, controllerMetrics);\n-      _taskManager.ensureTaskQueuesExist();\n       int taskManagerFrequencyInSeconds = config.getTaskManagerFrequencyInSeconds();\n       if (taskManagerFrequencyInSeconds > 0) {\n         LOGGER.info(\"Starting task manager with running frequency of {} seconds\", taskManagerFrequencyInSeconds);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "sha": "daff8c01faefd26a1654cea1d1533c44789a134c",
                "status": "modified"
            },
            {
                "additions": 54,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTaskRestletResource.java",
                "changes": 234,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTaskRestletResource.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 180,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTaskRestletResource.java",
                "patch": "@@ -16,35 +16,27 @@\n \n package com.linkedin.pinot.controller.api.resources;\n \n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import org.json.JSONArray;\n-import org.json.JSONObject;\n import com.linkedin.pinot.common.config.PinotTaskConfig;\n import com.linkedin.pinot.controller.helix.core.minion.PinotHelixTaskResourceManager;\n import com.linkedin.pinot.controller.helix.core.minion.PinotTaskManager;\n import io.swagger.annotations.Api;\n import io.swagger.annotations.ApiOperation;\n import io.swagger.annotations.ApiParam;\n+import java.util.Map;\n+import java.util.Set;\n import javax.inject.Inject;\n-import javax.ws.rs.Consumes;\n import javax.ws.rs.DELETE;\n import javax.ws.rs.GET;\n-import javax.ws.rs.POST;\n import javax.ws.rs.PUT;\n import javax.ws.rs.Path;\n import javax.ws.rs.PathParam;\n-import javax.ws.rs.Produces;\n import javax.ws.rs.QueryParam;\n import javax.ws.rs.WebApplicationException;\n-import javax.ws.rs.core.MediaType;\n+import org.apache.helix.task.TaskState;\n \n \n @Api(tags = Constants.TASK_TAG)\n+@Path(\"/\")\n public class PinotTaskRestletResource {\n   private static final String TASK_QUEUE_STATE_STOP = \"STOP\";\n   private static final String TASK_QUEUE_STATE_RESUME = \"RESUME\";\n@@ -55,211 +47,118 @@\n   @Inject\n   PinotTaskManager _pinotTaskManager;\n \n-  /**\n-   * URI Mappings:\n-   * <ul>\n-   *   <li>\n-   *     \"/tasks/tasktypes\":\n-   *     List all task types.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/tasks/{taskType}\":\n-   *     List all tasks for the specified task type.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/taskconfig/{taskName}\":\n-   *     Get the task config for the specified task name.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/taskstates/{taskType}\":\n-   *     Get a map from task name to task state for the specified task type.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/taskstate/{taskName}\":\n-   *     Get the task state for the specified task name.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/taskqueues\":\n-   *     List all task queues.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/taskqueuestate/{taskType}\":\n-   *     Get the task queue state for the specified task type.\n-   *   </li>\n-   * </ul>\n-   */\n-\n   @GET\n   @Path(\"/tasks/tasktypes\")\n-  @Produces(MediaType.APPLICATION_JSON)\n-  @ApiOperation(value = \"List all task types\", notes = \"List all task types\")\n-  public JSONArray listTaskTypes(\n-\n-  ) {\n-    List<String> taskTypes = new ArrayList<>(_pinotHelixTaskResourceManager.getTaskTypes());\n-    Collections.sort(taskTypes);\n-    return new JSONArray(taskTypes);\n+  @ApiOperation(\"List all task types\")\n+  public Set<String> listTaskTypes() {\n+    try {\n+      return _pinotHelixTaskResourceManager.getTaskTypes();\n+    } catch (Exception e) {\n+      throw new WebApplicationException(e);\n+    }\n   }\n \n   @GET\n-  @ApiOperation( value = \"List all tasks\", notes = \"List all tasks\")\n   @Path(\"/tasks/tasks/{taskType}\")\n-  @Produces(MediaType.APPLICATION_JSON)\n-  public JSONArray getTasks(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType\n-  ) {\n-    List<String> tasks = new ArrayList<>(_pinotHelixTaskResourceManager.getTasks(taskType));\n-    Collections.sort(tasks);\n-    return new JSONArray(tasks);\n+  @ApiOperation(\"List all tasks for the given task type\")\n+  public Set<String> getTasks(@ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType) {\n+    try {\n+      return _pinotHelixTaskResourceManager.getTasks(taskType);\n+    } catch (Exception e) {\n+      throw new WebApplicationException(e);\n+    }\n   }\n \n   @GET\n-  @ApiOperation(value = \"Get a task's configuration\")\n   @Path(\"/tasks/taskconfig/{taskName}\")\n-  @Produces(MediaType.APPLICATION_JSON)\n-  public JSONObject getTaskConfig(\n-      @ApiParam(value = \"Task name\", required = true) @PathParam(\"taskName\") String taskName\n-  ) {\n+  @ApiOperation(\"Get the task config for the given task name\")\n+  public PinotTaskConfig getTaskConfig(\n+      @ApiParam(value = \"Task name\", required = true) @PathParam(\"taskName\") String taskName) {\n     try {\n-      PinotTaskConfig taskConfig = _pinotHelixTaskResourceManager.getTaskConfig(taskName);\n-      JSONObject result = new JSONObject();\n-      result.put(\"taskType\", taskConfig.getTaskType());\n-      result.put(\"configs\", new JSONObject(taskConfig.getConfigs()));\n-      return result;\n+      return _pinotHelixTaskResourceManager.getTaskConfig(taskName);\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n   @GET\n-  @ApiOperation(value = \"Get all tasks' configuration\", notes = \"Get all tasks' configuration\")\n   @Path(\"/tasks/taskstates/{taskType}\")\n-  public JSONObject getTasksConfiguration(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType\n-  ) {\n+  @ApiOperation(\"Get a map from task name to task state for the given task type\")\n+  public Map<String, TaskState> getTaskStates(\n+      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType) {\n     try {\n-      return new JSONObject(_pinotHelixTaskResourceManager.getTaskStates(taskType));\n+      return _pinotHelixTaskResourceManager.getTaskStates(taskType);\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n   @GET\n-  @ApiOperation(value = \"Get a task's state\", notes = \"Get a task's state\")\n   @Path(\"/tasks/taskstate/{taskName}\")\n-  public String getTaskState(\n-      @ApiParam(value = \"Task name\", required = true) @PathParam(\"taskName\") String taskName\n-  ) {\n+  @ApiOperation(\"Get the task state for the given task name\")\n+  public StringResultResponse getTaskState(\n+      @ApiParam(value = \"Task name\", required = true) @PathParam(\"taskName\") String taskName) {\n     try {\n-      return _pinotHelixTaskResourceManager.getTaskState(taskName).toString();\n+      return new StringResultResponse(_pinotHelixTaskResourceManager.getTaskState(taskName).toString());\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n   @GET\n-  @ApiOperation(value = \"List all task queues\", notes = \"List all task queues\")\n   @Path(\"/tasks/taskqueues\")\n-  public JSONArray getTaskQueues(\n-\n-  ) {\n+  @ApiOperation(\"List all task queues\")\n+  public Set<String> getTaskQueues() {\n     try {\n-      List<String> taskQueues = new ArrayList<>(_pinotHelixTaskResourceManager.getTaskQueues());\n-      Collections.sort(taskQueues);\n-      return new JSONArray(taskQueues);\n+      return _pinotHelixTaskResourceManager.getTaskQueues();\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n   @GET\n-  @ApiOperation(value = \"Get a task queue's state\", notes = \"Get a task queue's state\")\n   @Path(\"/tasks/taskqueuestate/{taskType}\")\n-  public String getTaskQueueState(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType\n-  ) {\n+  @ApiOperation(\"Get the task queue state for the given task type\")\n+  public StringResultResponse getTaskQueueState(\n+      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType) {\n     try {\n-      return _pinotHelixTaskResourceManager.getTaskQueueState(taskType).toString();\n+      return new StringResultResponse(_pinotHelixTaskResourceManager.getTaskQueueState(taskType).toString());\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n-  /**\n-   * URI Mappings:\n-   * <ul>\n-   *   <li>\n-   *     \"/tasks/taskqueue/{taskType}\":\n-   *     Create a task queue for the specified task type.\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/task/{taskType}\":\n-   *     Submit a task of the specified task type to the task queue.\n-   *   </li>\n-   * </ul>\n-   */\n-  @POST\n-  @ApiOperation(value = \"Create a task queue\", notes = \"Create a task queue\")\n-  @Path(\"/tasks/taskqueue/{taskType}\")\n-  public SuccessResponse createTaskQueue(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType\n-  ) {\n+  @PUT\n+  @Path(\"/tasks/scheduletasks\")\n+  @ApiOperation(\"Schedule tasks\")\n+  public SuccessResponse scheduleTasks() {\n     try {\n-      _pinotHelixTaskResourceManager.createTaskQueue(taskType);\n-      return new SuccessResponse(\"Successfully created task queue for task type: \" + taskType);\n+      _pinotTaskManager.scheduleTasks();\n+      return new SuccessResponse(\"Successfully scheduled tasks\");\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n-  @POST\n-  @ApiOperation(value = \"Submit a task\", notes = \"Submit a task\")\n-  @Path(\"/tasks/task/{taskType}\")\n-  @Consumes(MediaType.APPLICATION_JSON)\n-  public SuccessResponse submitTask(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType,\n-      String configMapStr\n-  ) {\n+  @PUT\n+  @Path(\"/tasks/cleanuptasks/{taskType}\")\n+  @ApiOperation(\"Clean up tasks for the given task type\")\n+  public SuccessResponse cleanUpTasks(\n+      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType) {\n     try {\n-      Map<String, String> configs = new HashMap<>();\n-      PinotTaskConfig pinotTaskConfig;\n-      if (configMapStr != null) {\n-        JSONObject jsonConfig = new JSONObject(configMapStr);\n-        Iterator iterator = jsonConfig.keys();\n-        while (iterator.hasNext()) {\n-          String key = (String) iterator.next();\n-          configs.put(key, jsonConfig.getString(key));\n-        }\n-      }\n-      pinotTaskConfig = new PinotTaskConfig(taskType, configs);\n-      String taskName = _pinotHelixTaskResourceManager.submitTask(pinotTaskConfig);\n-      return new SuccessResponse(\"Successfully submitted task: \" + taskName);\n+      _pinotHelixTaskResourceManager.cleanUpTaskQueue(taskType);\n+      return new SuccessResponse(\"Successfully cleaned up tasks for task type: \" + taskType);\n     } catch (Exception e) {\n       throw new WebApplicationException(e);\n     }\n   }\n \n-  /**\n-   * URI Mappings:\n-   * <ul>\n-   *   <li>\n-   *     \"/tasks/taskqueue/{taskType}?state={state}\":\n-   *     Stop/resume a task queue based on the specified {state} (stop|resume).\n-   *   </li>\n-   *   <li>\n-   *     \"/tasks/scheduletasks\":\n-   *     Schedule tasks.\n-   *   </li>\n-   * </ul>\n-   */\n-\n   @PUT\n-  @ApiOperation(value = \"Stop/resume a task queue\", notes = \"Stop/resume a task queue\")\n   @Path(\"/tasks/taskqueue/{taskType}\")\n+  @ApiOperation(\"Stop/resume a task queue\")\n   public SuccessResponse toggleTaskQueueState(\n       @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType,\n-      @ApiParam(value = \"state\", required = true) @QueryParam(\"state\") String state\n-  ) {\n+      @ApiParam(value = \"state\", required = true) @QueryParam(\"state\") String state) {\n     try {\n       switch (state.toUpperCase()) {\n         case TASK_QUEUE_STATE_STOP:\n@@ -276,36 +175,11 @@ public SuccessResponse toggleTaskQueueState(\n     }\n   }\n \n-  @PUT\n-  @ApiOperation(value = \"Schedule tasks\", notes = \"Schedule tasks\")\n-  @Path(\"/tasks/scheduletasks\")\n-  public SuccessResponse scheduleTasks(\n-  ) {\n-    try {\n-      _pinotTaskManager.scheduleTasks();\n-      return new SuccessResponse(\"Succeeded\");\n-    } catch (Exception e) {\n-      throw new WebApplicationException(e);\n-    }\n-  }\n-\n-\n-  /**\n-   * URI Mappings:\n-   * <ul>\n-   *   <li>\n-   *     \"/tasks/taskqueue/{taskType}\":\n-   *     Delete a task queue for the specified task type.\n-   *   </li>\n-   * </ul>\n-   */\n-\n   @DELETE\n-  @ApiOperation(notes = \"Delete a task queue\", value = \"Delete a task queue\")\n   @Path(\"/tasks/taskqueue/{taskType}\")\n+  @ApiOperation(\"Delete a task queue\")\n   public SuccessResponse deleteTaskQueue(\n-      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType\n-  ) {\n+      @ApiParam(value = \"Task type\", required = true) @PathParam(\"taskType\") String taskType) {\n     try {\n       _pinotHelixTaskResourceManager.deleteTaskQueue(taskType);\n       return new SuccessResponse(\"Successfully deleted task queue for task type: \" + taskType);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/PinotTaskRestletResource.java",
                "sha": "ca7632dd0201ac892cd373cf117986b9b5bcda73",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/StringResultResponse.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/StringResultResponse.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/StringResultResponse.java",
                "patch": "@@ -0,0 +1,28 @@\n+/**\n+ * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.linkedin.pinot.controller.api.resources;\n+\n+public final class StringResultResponse {\n+  private final String _result;\n+\n+  public StringResultResponse(String result) {\n+    _result = result;\n+  }\n+\n+  public String getResult() {\n+    return _result;\n+  }\n+}",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/StringResultResponse.java",
                "sha": "3510b04c1b4bcd3436e7bf8bb32fcdc629b80497",
                "status": "added"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/SuccessResponse.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/SuccessResponse.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 17,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/SuccessResponse.java",
                "patch": "@@ -15,26 +15,14 @@\n  */\n package com.linkedin.pinot.controller.api.resources;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import com.fasterxml.jackson.annotation.JsonProperty;\n+public final class SuccessResponse {\n+  private final String _status;\n \n-\n-public class SuccessResponse {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(SuccessResponse.class);\n-  private String status;\n-\n-  public SuccessResponse(@JsonProperty(\"status\") String status) {\n-    this.status = status;\n+  public SuccessResponse(String status) {\n+    _status = status;\n   }\n \n   public String getStatus() {\n-    return status;\n+    return _status;\n   }\n-\n-  public SuccessResponse setStatus(String status) {\n-    this.status = status;\n-    return this;\n-  }\n-\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/resources/SuccessResponse.java",
                "sha": "6966736347019b66e284bb8e07c0e88a34259dde",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotHelixTaskResourceManager.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotHelixTaskResourceManager.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotHelixTaskResourceManager.java",
                "patch": "@@ -80,6 +80,18 @@ public synchronized void createTaskQueue(@Nonnull String taskType) {\n     _taskDriver.createQueue(jobQueue);\n   }\n \n+  /**\n+   * Clean up a task queue for the given task type.\n+   *\n+   * @param taskType Task type\n+   */\n+  // TODO: Seems the node under PROPERTYSTORE/TaskRebalancer is not cleaned up properly\n+  public synchronized void cleanUpTaskQueue(@Nonnull String taskType) {\n+    String helixJobQueueName = getHelixJobQueueName(taskType);\n+    LOGGER.info(\"Cleaning up task queue: {} for task type: {}\", helixJobQueueName, taskType);\n+    _taskDriver.cleanupJobQueue(helixJobQueueName);\n+  }\n+\n   /**\n    * Stop the task queue for the given task type.\n    *",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotHelixTaskResourceManager.java",
                "sha": "0940e803e22890a89be90cd0acfd4eaa3858e761",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotTaskManager.java",
                "changes": 54,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotTaskManager.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 18,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotTaskManager.java",
                "patch": "@@ -16,6 +16,7 @@\n package com.linkedin.pinot.controller.helix.core.minion;\n \n import com.google.common.base.Preconditions;\n+import com.google.common.util.concurrent.Uninterruptibles;\n import com.linkedin.pinot.common.config.PinotTaskConfig;\n import com.linkedin.pinot.common.config.TableConfig;\n import com.linkedin.pinot.common.config.TableTaskConfig;\n@@ -92,19 +93,6 @@ public void registerTaskGenerator(@Nonnull PinotTaskGenerator pinotTaskGenerator\n     _taskGeneratorRegistry.registerTaskGenerator(pinotTaskGenerator);\n   }\n \n-  /**\n-   * Ensure all registered task queues exist.\n-   * <p>Should be called after all task generators get registered.\n-   */\n-  public void ensureTaskQueuesExist() {\n-    Map<String, WorkflowConfig> helixWorkflows = _taskDriver.getWorkflows();\n-    for (String taskType : _taskGeneratorRegistry.getAllTaskTypes()) {\n-      if (!helixWorkflows.containsKey(PinotHelixTaskResourceManager.getHelixJobQueueName(taskType))) {\n-        _pinotHelixTaskResourceManager.createTaskQueue(taskType);\n-      }\n-    }\n-  }\n-\n   /**\n    * Start the task scheduler with the given running frequency.\n    *\n@@ -132,13 +120,22 @@ public void run() {\n     }, Math.min(60, runFrequencyInSeconds), runFrequencyInSeconds, TimeUnit.SECONDS);\n   }\n \n+  /**\n+   * Stop the task scheduler.\n+   */\n+  public void stopScheduler() {\n+    if (_executorService != null) {\n+      _executorService.shutdown();\n+    }\n+  }\n+\n   /**\n    * Check the Pinot cluster status and schedule new tasks.\n    */\n   public void scheduleTasks() {\n     _controllerMetrics.addMeteredGlobalValue(ControllerMeter.NUMBER_TIMES_SCHEDULE_TASKS_CALLED, 1L);\n \n-    // TODO: add JobQueue health check here\n+    ensureTaskQueuesExist();\n \n     Set<String> taskTypes = _taskGeneratorRegistry.getAllTaskTypes();\n     Map<String, List<TableConfig>> enabledTableConfigMap = new HashMap<>();\n@@ -177,11 +174,32 @@ public void scheduleTasks() {\n   }\n \n   /**\n-   * Stop the task scheduler.\n+   * Helper method to ensure all registered task queues exist.\n+   * <p>Should be called after all task generators get registered.\n    */\n-  public void stopScheduler() {\n-    if (_executorService != null) {\n-      _executorService.shutdown();\n+  private void ensureTaskQueuesExist() {\n+    Set<String> allTaskTypes = _taskGeneratorRegistry.getAllTaskTypes();\n+    Map<String, WorkflowConfig> helixWorkflows = _taskDriver.getWorkflows();\n+\n+    boolean done = true;\n+    for (String taskType : allTaskTypes) {\n+      if (!helixWorkflows.containsKey(PinotHelixTaskResourceManager.getHelixJobQueueName(taskType))) {\n+        _pinotHelixTaskResourceManager.createTaskQueue(taskType);\n+        done = false;\n+      }\n+    }\n+\n+    // Wait until all task queues show up\n+    while (!done) {\n+      Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);\n+      done = true;\n+      helixWorkflows = _taskDriver.getWorkflows();\n+      for (String taskType : allTaskTypes) {\n+        if (!helixWorkflows.containsKey(PinotHelixTaskResourceManager.getHelixJobQueueName(taskType))) {\n+          done = false;\n+          break;\n+        }\n+      }\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/minion/PinotTaskManager.java",
                "sha": "e7b8342640e98d4034d34807aeeeb896bde6815d",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ConvertToRawIndexMinionClusterIntegrationTest.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ConvertToRawIndexMinionClusterIntegrationTest.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 4,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ConvertToRawIndexMinionClusterIntegrationTest.java",
                "patch": "@@ -108,7 +108,7 @@ public void testConvertToRawIndexTask() throws Exception {\n     TestUtils.waitForCondition(new Function<Void, Boolean>() {\n       @Override\n       public Boolean apply(@Nullable Void aVoid) {\n-        return _helixTaskResourceManager.getTaskStates(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size() == 5;\n+        return _helixTaskResourceManager.getTasks(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size() == 5;\n       }\n     }, 60_000L, \"Failed to get all tasks showing up in the cluster\");\n \n@@ -118,14 +118,13 @@ public Boolean apply(@Nullable Void aVoid) {\n     TestUtils.waitForCondition(new Function<Void, Boolean>() {\n       @Override\n       public Boolean apply(@Nullable Void aVoid) {\n-        return _helixTaskResourceManager.getTaskStates(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size() == 8;\n+        return _helixTaskResourceManager.getTasks(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size() == 8;\n       }\n     }, 60_000L, \"Failed to get all tasks showing up in the cluster\");\n \n     // Should not generate more tasks\n     _taskManager.scheduleTasks();\n-    Assert.assertEquals(_helixTaskResourceManager.getTaskStates(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size(),\n-        8);\n+    Assert.assertEquals(_helixTaskResourceManager.getTasks(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size(), 8);\n \n     // Wait at most 600 seconds for all tasks COMPLETED and new segments refreshed\n     TestUtils.waitForCondition(new Function<Void, Boolean>() {\n@@ -182,6 +181,10 @@ public Boolean apply(@Nullable Void aVoid) {\n         }\n       }\n     }, 600_000L, \"Failed to get all tasks COMPLETED and new segments refreshed\");\n+\n+    // Clean up the COMPLETED tasks\n+    _helixTaskResourceManager.cleanUpTaskQueue(MinionConstants.ConvertToRawIndexTask.TASK_TYPE);\n+    Assert.assertEquals(_helixTaskResourceManager.getTasks(MinionConstants.ConvertToRawIndexTask.TASK_TYPE).size(), 0);\n   }\n \n   @Test",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ConvertToRawIndexMinionClusterIntegrationTest.java",
                "sha": "2bcf01de9025cc8e9a90c0f0ad8a5ac2f18ddd1f",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eaed6e931fb633d415877c3430d134b4163141/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SimpleMinionClusterIntegrationTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SimpleMinionClusterIntegrationTest.java?ref=46eaed6e931fb633d415877c3430d134b4163141",
                "deletions": 2,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SimpleMinionClusterIntegrationTest.java",
                "patch": "@@ -80,7 +80,6 @@ public void setUp() throws Exception {\n \n     // Register the test task generator into task manager\n     _pinotTaskManager.registerTaskGenerator(new TestTaskGenerator(_pinotTaskManager.getClusterInfoProvider()));\n-    _pinotTaskManager.ensureTaskQueuesExist();\n \n     Map<String, Class<? extends PinotTaskExecutor>> taskExecutorsToRegister = new HashMap<>(1);\n     taskExecutorsToRegister.put(TestTaskGenerator.TASK_TYPE, TestTaskExecutor.class);\n@@ -97,7 +96,7 @@ public void testStopAndResumeTaskQueue() throws Exception {\n     TestUtils.waitForCondition(new Function<Void, Boolean>() {\n       @Override\n       public Boolean apply(@Nullable Void aVoid) {\n-        return _pinotHelixTaskResourceManager.getTaskStates(TestTaskGenerator.TASK_TYPE).size() == 4;\n+        return _pinotHelixTaskResourceManager.getTasks(TestTaskGenerator.TASK_TYPE).size() == 4;\n       }\n     }, 60_000L, \"Failed to get all tasks showing up in the cluster\");\n \n@@ -143,6 +142,10 @@ public Boolean apply(@Nullable Void aVoid) {\n       }\n     }, 60_000L, \"Failed to get all tasks COMPLETED\");\n \n+    // Clean up the COMPLETED tasks\n+    _pinotHelixTaskResourceManager.cleanUpTaskQueue(TestTaskGenerator.TASK_TYPE);\n+    Assert.assertEquals(_pinotHelixTaskResourceManager.getTasks(TestTaskGenerator.TASK_TYPE).size(), 0);\n+\n     // Delete the task queue\n     _pinotHelixTaskResourceManager.deleteTaskQueue(TestTaskGenerator.TASK_TYPE);\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eaed6e931fb633d415877c3430d134b4163141/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SimpleMinionClusterIntegrationTest.java",
                "sha": "e6812c6194bf5d88b4b33afcfbf757b29538aca0",
                "status": "modified"
            }
        ],
        "message": "[MINION] Clean up rest APIS and add API to clean up finished tasks (#1889)\n\nFixed the issue where TaskResource is not attached to the rest server\r\nAlways return result in JSON format (Added StringResultResponse class)\r\nRemoved rest APIs to create task/task queue because they should only be created by the scheduleTasks()\r\nAdded rest API to clean up finished tasks\r\nModified tests to test clean up API\r\nAlso Fixed the NPE in SimpleMinionClusterIntegrationTest by ensuring task queues show up in ZK when create them",
        "parent": "https://github.com/apache/incubator-pinot/commit/d44d16acce4cccf6e18da5dc20f887dadd0b0d2c",
        "patched_files": [
            "ControllerStarter.java",
            "SuccessResponse.java",
            "PinotHelixTaskResourceManager.java",
            "PinotTaskRestletResource.java",
            "PinotTaskManager.java",
            "StringResultResponse.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "SimpleMinionClusterIntegrationTest.java",
            "ConvertToRawIndexMinionClusterIntegrationTest.java"
        ]
    },
    "incubator-pinot_46eedd5": {
        "bug_id": "incubator-pinot_46eedd5",
        "commit": "https://github.com/apache/incubator-pinot/commit/46eedd56f93190b961e62a1ac855e4fa99b19e3b",
        "file": [
            {
                "additions": 16,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/SegmentDeletionManager.java",
                "changes": 22,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/SegmentDeletionManager.java?ref=46eedd56f93190b961e62a1ac855e4fa99b19e3b",
                "deletions": 6,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/SegmentDeletionManager.java",
                "patch": "@@ -31,7 +31,6 @@\n import org.apache.commons.io.FileUtils;\n import org.apache.commons.io.filefilter.AgeFileFilter;\n import org.apache.commons.io.filefilter.DirectoryFileFilter;\n-import org.apache.commons.io.filefilter.TrueFileFilter;\n import org.apache.helix.AccessOption;\n import org.apache.helix.HelixAdmin;\n import org.apache.helix.ZNRecord;\n@@ -205,21 +204,32 @@ protected void removeSegmentFromStore(String tableName, String segmentId) {\n    */\n   public void removeAgedDeletedSegments(int retentionInDays) {\n     if (_localDiskDir != null) {\n-      File targetDir = new File(_localDiskDir, DELETED_SEGMENTS);\n+      File deletedDir = new File(_localDiskDir, DELETED_SEGMENTS);\n+      // Check that the directory for deleted segments exists\n+      if (!deletedDir.isDirectory()) {\n+        LOGGER.warn(\"Deleted segment directory {} does not exist or it is not directory.\", deletedDir.getAbsolutePath());\n+        return;\n+      }\n+\n       AgeFileFilter fileFilter = new AgeFileFilter(DateTime.now().minusDays(retentionInDays).toDate());\n-      for (File currentDir : targetDir.listFiles((FileFilter) DirectoryFileFilter.DIRECTORY)) {\n+      File[] directories = deletedDir.listFiles((FileFilter) DirectoryFileFilter.DIRECTORY);\n+      // Check that the directory for deleted segments is empty\n+      if (directories == null) {\n+        LOGGER.warn(\"Deleted segment directory {} does not exist or it caused an I/O error.\", deletedDir);\n+        return;\n+      }\n+\n+      for (File currentDir : directories) {\n         // Get files that are aged\n         Collection<File> targetFiles = FileUtils.listFiles(currentDir, fileFilter, null);\n-\n         // Delete aged files\n         for (File f : targetFiles) {\n           if (!f.delete()) {\n             LOGGER.warn(\"Cannot remove file {} from deleted directory.\", f.getAbsolutePath());\n           }\n         }\n-\n         // Delete directory if it's empty\n-        if (currentDir.list().length == 0) {\n+        if (currentDir.list() != null && currentDir.list().length == 0) {\n           if (!currentDir.delete()) {\n             LOGGER.warn(\"The directory {} cannot be removed. The directory may not be empty.\", currentDir.getAbsolutePath());\n           }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/SegmentDeletionManager.java",
                "sha": "4112929fd3e0485214708fccf9b691a39fe8c50b",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=46eedd56f93190b961e62a1ac855e4fa99b19e3b",
                "deletions": 3,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -124,6 +124,8 @@ private void execute() {\n         LOGGER.info(\"Finished update segment metadata for entire cluster!\");\n         scanSegmentMetadataAndPurge();\n         LOGGER.info(\"Finished segment purge for entire cluster!\");\n+        removeAgedDeletedSegments();\n+        LOGGER.info(\"Finished remove aged deleted segments!\");\n       } else {\n         LOGGER.info(\"Not leader of the controller, sleep!\");\n       }\n@@ -177,12 +179,14 @@ private void scanSegmentMetadataAndPurge() {\n         LOGGER.info(\"Trying to delete {} segments for table {}\", segmentsToDelete.size(), tableName);\n         _pinotHelixResourceManager.deleteSegments(tableName, segmentsToDelete);\n       }\n-\n-      // Trigger clean-up for deleted segments from the deleted directory\n-      _pinotHelixResourceManager.getSegmentDeletionManager().removeAgedDeletedSegments(_deletedSegmentsRetentionInDays);\n     }\n   }\n \n+  private void removeAgedDeletedSegments() {\n+    // Trigger clean-up for deleted segments from the deleted directory\n+    _pinotHelixResourceManager.getSegmentDeletionManager().removeAgedDeletedSegments(_deletedSegmentsRetentionInDays);\n+  }\n+\n   private boolean shouldDeleteInProgressLLCSegment(final String segmentId, final IdealState idealState, RealtimeSegmentZKMetadata segmentZKMetadata) {\n     if (idealState == null) {\n       return false;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "213d319792fd44096684db058003864bf8f3b4ec",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/util/SegmentDeletionManagerTest.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/util/SegmentDeletionManagerTest.java?ref=46eedd56f93190b961e62a1ac855e4fa99b19e3b",
                "deletions": 0,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/util/SegmentDeletionManagerTest.java",
                "patch": "@@ -195,17 +195,32 @@ public void testRemoveDeletedSegments() throws Exception {\n     tempDir.deleteOnExit();\n     FakeDeletionManager deletionManager = new FakeDeletionManager(tempDir.getAbsolutePath(), helixAdmin, propertyStore);\n \n+    // Test delete when deleted segments directory does not exists\n+    deletionManager.removeAgedDeletedSegments(1);\n+\n     // Create deleted directory\n     String deletedDirectoryPath = tempDir + File.separator + \"Deleted_Segments\";\n     File deletedDirectory = new File(deletedDirectoryPath);\n     deletedDirectory.mkdir();\n \n+    // Test delete when deleted segments directory is empty\n+    deletionManager.removeAgedDeletedSegments(1);\n+\n     // Create dummy directories and files\n     File dummyDir1 = new File(deletedDirectoryPath + File.separator + \"dummy1\");\n     dummyDir1.mkdir();\n     File dummyDir2 = new File(deletedDirectoryPath + File.separator + \"dummy2\");\n     dummyDir2.mkdir();\n \n+    // Test delete when there is no files but some directories exist\n+    deletionManager.removeAgedDeletedSegments(1);\n+    Assert.assertEquals(dummyDir1.exists(), false);\n+    Assert.assertEquals(dummyDir2.exists(), false);\n+\n+    // Create dummy directories and files\n+    dummyDir1.mkdir();\n+    dummyDir2.mkdir();\n+\n     // Create dummy files\n     for (int i = 0; i < 3; i++) {\n       createTestFileWithAge(dummyDir1.getAbsolutePath() + File.separator + \"file\" + i, i);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/46eedd56f93190b961e62a1ac855e4fa99b19e3b/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/util/SegmentDeletionManagerTest.java",
                "sha": "d46971640782d85e45e9e1a0a357f71375be25b4",
                "status": "modified"
            }
        ],
        "message": "Fix segment deletion manager to handle deleted directory correctly (#1368)\n\nWhen deleted segment directory does not exist, segment deletion manager throws the NullPointerException because it does not check if the deleted directory path exists.\r\n- Added check for deleted directory path\r\n- Added unit test for checking when deleted segment directory does not exist",
        "parent": "https://github.com/apache/incubator-pinot/commit/2c3685a19e9c152aea407172bf7ef807b57ded31",
        "patched_files": [
            "SegmentDeletionManager.java",
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "SegmentDeletionManagerTest.java",
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_4d527b2": {
        "bug_id": "incubator-pinot_4d527b2",
        "commit": "https://github.com/apache/incubator-pinot/commit/4d527b24d99610290e3487b0319a24836ec2dfc2",
        "file": [
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/4d527b24d99610290e3487b0319a24836ec2dfc2/pinot-core/src/main/java/com/linkedin/pinot/core/operator/filter/OrOperator.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/filter/OrOperator.java?ref=4d527b24d99610290e3487b0319a24836ec2dfc2",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/filter/OrOperator.java",
                "patch": "@@ -64,7 +64,6 @@ public boolean close() {\n     for (Operator operator : operators) {\n       operator.close();\n     }\n-    LOGGER.info(\"Time spent in OrOperator operator:{} is {}\", this, orBlock.orBlockDocIdSet.timeMeasure);\n     return true;\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/4d527b24d99610290e3487b0319a24836ec2dfc2/pinot-core/src/main/java/com/linkedin/pinot/core/operator/filter/OrOperator.java",
                "sha": "51e9abe62c42d6e6b57c55fe69b33b31f49a6c2f",
                "status": "modified"
            }
        ],
        "message": "Remove the log statement from Or operator close() operation\n\nBlocks are not guaranteed to be initialized at the time of close\noperation. So, these log statements cause NPE. Removing because\nlogging profiling information isn't ideal.\n\nRB=620288\nG=pinot-dev-reviewers\nR=kgopalak,jfim,ssubrama,mshrivas\nA=kgopalak",
        "parent": "https://github.com/apache/incubator-pinot/commit/5edaaa0c809a2c4012693997a139772b7659be37",
        "patched_files": [
            "OrOperator.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "OrOperatorTest.java"
        ]
    },
    "incubator-pinot_4f7a970": {
        "bug_id": "incubator-pinot_4f7a970",
        "commit": "https://github.com/apache/incubator-pinot/commit/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/BasePartitionAwareRoutingTableBuilder.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/BasePartitionAwareRoutingTableBuilder.java?ref=4f7a970d6d4b66924f08239c47e2fc6fafcc2f64",
                "deletions": 3,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/BasePartitionAwareRoutingTableBuilder.java",
                "patch": "@@ -61,17 +61,15 @@\n \n   protected ZkHelixPropertyStore<ZNRecord> _propertyStore;\n   protected SegmentZKMetadataPrunerService _pruner;\n-  protected TableConfig _tableConfig;\n   protected Random _random = new Random();\n-  protected int _numReplicas;\n+  protected volatile int _numReplicas;\n \n   protected void setSegmentToReplicaToServerMap(Map<String, Map<Integer, String>> segmentToReplicaToServerMap) {\n     _segmentToReplicaToServerMap = segmentToReplicaToServerMap;\n   }\n \n   @Override\n   public void init(Configuration configuration, TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n-    _tableConfig = tableConfig;\n     _propertyStore = propertyStore;\n \n     // TODO: We need to specify the type of pruners via config instead of hardcoding.",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/BasePartitionAwareRoutingTableBuilder.java",
                "sha": "35fa19ed15e17f7ff85d3c6da6d9a3fd18852f6c",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilder.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilder.java?ref=4f7a970d6d4b66924f08239c47e2fc6fafcc2f64",
                "deletions": 0,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilder.java",
                "patch": "@@ -89,6 +89,12 @@ public synchronized void computeRoutingTableFromExternalView(String tableName, E\n     ReplicaGroupPartitionAssignment partitionAssignment =\n         partitionAssignmentGenerator.getReplicaGroupPartitionAssignment(tableName);\n \n+    // Update numReplicas if the replica group partition assignment has been changed.\n+    int numReplicas = partitionAssignment.getNumReplicaGroups();\n+    if (_numReplicas != numReplicas) {\n+      _numReplicas = numReplicas;\n+    }\n+\n     // 1. Compute the partition id set by looking at the segment zk metadata and cache metadata when possible\n     Set<Integer> partitionIds = new HashSet<>();\n     for (String segmentName : segmentSet) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilder.java",
                "sha": "18d5a496108cb3b199fb2db80d69ae64df50da42",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareRealtimeRoutingTableBuilder.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareRealtimeRoutingTableBuilder.java?ref=4f7a970d6d4b66924f08239c47e2fc6fafcc2f64",
                "deletions": 1,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareRealtimeRoutingTableBuilder.java",
                "patch": "@@ -48,7 +48,7 @@\n   @Override\n   public void init(Configuration configuration, TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n     super.init(configuration, tableConfig, propertyStore);\n-    _numReplicas = Integer.valueOf(_tableConfig.getValidationConfig().getReplicasPerPartition());\n+    _numReplicas = Integer.valueOf(tableConfig.getValidationConfig().getReplicasPerPartition());\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/main/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareRealtimeRoutingTableBuilder.java",
                "sha": "bd5744c7c1475274507c126a9b86b4271dd36d44",
                "status": "modified"
            },
            {
                "additions": 78,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/test/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilderTest.java",
                "changes": 82,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/test/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilderTest.java?ref=4f7a970d6d4b66924f08239c47e2fc6fafcc2f64",
                "deletions": 4,
                "filename": "pinot-broker/src/test/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilderTest.java",
                "patch": "@@ -94,14 +94,14 @@ public void testBrokerSideServerAndSegmentPruning() throws Exception {\n       }\n \n       // Update replica group mapping zk metadata\n-      updatePartitionMappingZkMetadata(OFFLINE_TABLE_NAME, fakePropertyStore);\n+      updatgeReplicaGroupPartitionAssignment(OFFLINE_TABLE_NAME, fakePropertyStore);\n \n       // Create the fake external view\n       ExternalView externalView = buildExternalView(OFFLINE_TABLE_NAME, replicaToServerMapping);\n \n       // Create instance Configs\n       List<InstanceConfig> instanceConfigs = new ArrayList<>();\n-      for (int serverId = 0; serverId <= NUM_SERVERS; serverId++) {\n+      for (int serverId = 0; serverId < NUM_SERVERS; serverId++) {\n         String serverName = \"Server_localhost_\" + serverId;\n         instanceConfigs.add(new InstanceConfig(serverName));\n       }\n@@ -151,12 +151,86 @@ public void testBrokerSideServerAndSegmentPruning() throws Exception {\n     }\n   }\n \n-  private void updatePartitionMappingZkMetadata(String tableNameWithType, FakePropertyStore propertyStore) {\n+  @Test\n+  public void testRoutingTableAfterRebalance() throws Exception {\n+    NUM_REPLICA = 1;\n+    NUM_PARTITION = 1;\n+    NUM_SERVERS = 1;\n+    NUM_SEGMENTS = 10;\n+\n+    // Create the fake property store\n+    FakePropertyStore fakePropertyStore = new FakePropertyStore();\n+\n+    // Create the table config, partition mapping,\n+    TableConfig tableConfig = buildOfflineTableConfig();\n+\n+    // Create the replica group id to server mapping\n+    Map<Integer, List<String>> replicaToServerMapping = buildReplicaGroupMapping();\n+\n+    // Update segment zk metadata.\n+    for (int i = 0; i < NUM_SEGMENTS; i++) {\n+      String segmentName = \"segment\" + i;\n+      int partition = i % NUM_PARTITION;\n+      SegmentZKMetadata metadata = buildOfflineSegmentZKMetadata(segmentName, partition);\n+      fakePropertyStore.setContents(\n+          ZKMetadataProvider.constructPropertyStorePathForSegment(OFFLINE_TABLE_NAME, segmentName),\n+          metadata.toZNRecord());\n+    }\n+\n+    // Update replica group mapping zk metadata\n+    updatgeReplicaGroupPartitionAssignment(OFFLINE_TABLE_NAME, fakePropertyStore);\n+\n+    // Create the fake external view\n+    ExternalView externalView = buildExternalView(OFFLINE_TABLE_NAME, replicaToServerMapping);\n+\n+    // Create instance Configs\n+    List<InstanceConfig> instanceConfigs = new ArrayList<>();\n+    for (int serverId = 0; serverId < NUM_SERVERS; serverId++) {\n+      String serverName = \"Server_localhost_\" + serverId;\n+      instanceConfigs.add(new InstanceConfig(serverName));\n+    }\n+\n+    // Create the partition aware offline routing table builder.\n+    RoutingTableBuilder routingTableBuilder =\n+        buildPartitionAwareOfflineRoutingTableBuilder(fakePropertyStore, tableConfig, externalView, instanceConfigs);\n+\n+    // Simulate the case where we add 1 more server/replica\n+    NUM_REPLICA = 2;\n+    NUM_SERVERS = 2;\n+\n+    // Update instance configs\n+    String newServerName = \"Server_localhost_\" + (NUM_SERVERS - 1);\n+    instanceConfigs.add(new InstanceConfig(newServerName));\n+\n+    // Update replica group partition assignment\n+    updatgeReplicaGroupPartitionAssignment(OFFLINE_TABLE_NAME, fakePropertyStore);\n+\n+    // Update external view\n+    Map<Integer, List<String>> newReplicaToServerMapping = buildReplicaGroupMapping();\n+    ExternalView newExternalView = buildExternalView(OFFLINE_TABLE_NAME, newReplicaToServerMapping);\n+\n+    // Compute routing table and this should not throw null pointer exception\n+    routingTableBuilder.computeRoutingTableFromExternalView(OFFLINE_TABLE_NAME, newExternalView, instanceConfigs);\n+\n+    Set<String> servers = new HashSet<>();\n+    for (int i = 0; i < 100; i++) {\n+      String countStarQuery = \"select count(*) from myTable\";\n+      Map<String, List<String>> routingTable =\n+          routingTableBuilder.getRoutingTable(buildRoutingTableLookupRequest(countStarQuery));\n+      Assert.assertEquals(routingTable.keySet().size(), 1);\n+      servers.add(routingTable.keySet().iterator().next());\n+    }\n+\n+    // Check if both servers are get picked\n+    Assert.assertEquals(servers.size(), 2);\n+  }\n+\n+  private void updatgeReplicaGroupPartitionAssignment(String tableNameWithType, FakePropertyStore propertyStore) {\n     // Create partition assignment mapping table.\n     ReplicaGroupPartitionAssignment replicaGroupPartitionAssignment = new ReplicaGroupPartitionAssignment(tableNameWithType);\n \n     int partitionId = 0;\n-    for (int serverId = 0; serverId <= NUM_SERVERS; serverId++) {\n+    for (int serverId = 0; serverId < NUM_SERVERS; serverId++) {\n       String serverName = \"Server_localhost_\" + serverId;\n       int replicaGroupId = serverId / (NUM_SERVERS / NUM_REPLICA);\n       replicaGroupPartitionAssignment.addInstanceToReplicaGroup(partitionId, replicaGroupId, serverName);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/4f7a970d6d4b66924f08239c47e2fc6fafcc2f64/pinot-broker/src/test/java/com/linkedin/pinot/broker/routing/builder/PartitionAwareOfflineRoutingTableBuilderTest.java",
                "sha": "810aa998321422710f5011a38057e34e0d2b6a89",
                "status": "modified"
            }
        ],
        "message": "Fixed NPE bug for PartitionAwareOfflineRoutingTableBuilder (#2806)\n\nPartitionAwareOfflineRoutingTableBuilder was caching the number of replicas\r\nfrom the table config during the initialization and never updates the value\r\neven if there was a change. This caused NPE when the broker attempts to compute\r\nrouting table after servers were added to table and rebalance was invoked.\r\nThis PR addresses this bug and also added the unit test to make sure the fix\r\nresolves the issue.",
        "parent": "https://github.com/apache/incubator-pinot/commit/7570d00089c76fc69372bd5b7b2dfa1d8318d60c",
        "patched_files": [
            "BasePartitionAwareRoutingTableBuilder.java",
            "PartitionAwareOfflineRoutingTableBuilder.java",
            "PartitionAwareRealtimeRoutingTableBuilder.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PartitionAwareOfflineRoutingTableBuilderTest.java",
            "PartitionAwareRealtimeRoutingTableBuilderTest.java"
        ]
    },
    "incubator-pinot_51c7a0f": {
        "bug_id": "incubator-pinot_51c7a0f",
        "commit": "https://github.com/apache/incubator-pinot/commit/51c7a0f6b87f78d73a146607e5e8f4cdb8a6edd9",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/51c7a0f6b87f78d73a146607e5e8f4cdb8a6edd9/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=51c7a0f6b87f78d73a146607e5e8f4cdb8a6edd9",
                "deletions": 9,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -44,7 +44,6 @@\n import javax.annotation.Nullable;\n import org.apache.commons.configuration.Configuration;\n import org.apache.helix.AccessOption;\n-import org.apache.helix.BaseDataAccessor;\n import org.apache.helix.ClusterMessagingService;\n import org.apache.helix.Criteria;\n import org.apache.helix.HelixAdmin;\n@@ -801,10 +800,9 @@ public boolean isServerTenantDeletable(String tenantName) {\n \n   public Set<String> getAllBrokerTenantNames() {\n     Set<String> tenantSet = new HashSet<>();\n-    List<String> instancesInCluster = _helixAdmin.getInstancesInCluster(_helixClusterName);\n-    for (String instanceName : instancesInCluster) {\n-      InstanceConfig config = _helixDataAccessor.getProperty(_keyBuilder.instanceConfig(instanceName));\n-      for (String tag : config.getTags()) {\n+    List<InstanceConfig> instanceConfigs = getAllHelixInstanceConfigs();\n+    for (InstanceConfig instanceConfig : instanceConfigs) {\n+      for (String tag : instanceConfig.getTags()) {\n         if (TagNameUtils.isBrokerTag(tag)) {\n           tenantSet.add(TagNameUtils.getTenantNameFromTag(tag));\n         }\n@@ -815,10 +813,9 @@ public boolean isServerTenantDeletable(String tenantName) {\n \n   public Set<String> getAllServerTenantNames() {\n     Set<String> tenantSet = new HashSet<>();\n-    List<String> instancesInCluster = _helixAdmin.getInstancesInCluster(_helixClusterName);\n-    for (String instanceName : instancesInCluster) {\n-      InstanceConfig config = _helixDataAccessor.getProperty(_keyBuilder.instanceConfig(instanceName));\n-      for (String tag : config.getTags()) {\n+    List<InstanceConfig> instanceConfigs = getAllHelixInstanceConfigs();\n+    for (InstanceConfig instanceConfig : instanceConfigs) {\n+      for (String tag : instanceConfig.getTags()) {\n         if (TagNameUtils.isServerTag(tag)) {\n           tenantSet.add(TagNameUtils.getTenantNameFromTag(tag));\n         }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/51c7a0f6b87f78d73a146607e5e8f4cdb8a6edd9/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "6ea61c18ba25049557a8b30e55898f16cf611a2e",
                "status": "modified"
            }
        ],
        "message": "Modify get tenant names APIs (#4688)\n\nThis PR modifies the logic of getting tenant name APIs.\r\n\r\nThe previous code firstly gets the list of instance names from /INSTANCES ZNode and then gets the instance config one by one from /CONFIG/PARTICIPANT/INSTANCES ZNode. Whereas these two ZNodes may be inconsistent.\r\nThat's why we sometimes encounter flaky NPE when calling these APIs.",
        "parent": "https://github.com/apache/incubator-pinot/commit/ce298bae09b316b40fa1af65ce96af2bdfcbc286",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    },
    "incubator-pinot_55faf77": {
        "bug_id": "incubator-pinot_55faf77",
        "commit": "https://github.com/apache/incubator-pinot/commit/55faf779594eaebfb5edceb47eeed0d2818cf32f",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/55faf779594eaebfb5edceb47eeed0d2818cf32f/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=55faf779594eaebfb5edceb47eeed0d2818cf32f",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -173,7 +173,7 @@ private void updateDeletionStrategiesForEntireCluster() {\n       return tableToDeletionStrategyMap;\n     }\n \n-    if (offlineTableConfig == null) {\n+    if (offlineTableConfig == null || offlineTableConfig.getValidationConfig() == null) {\n       LOGGER.info(\"Table config null for table: {}, treating it as refresh only table.\", offlineTableName);\n       return tableToDeletionStrategyMap;\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/55faf779594eaebfb5edceb47eeed0d2818cf32f/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "5b4e0eebcbab0e6782042de6fb31251362f6ff5a",
                "status": "modified"
            }
        ],
        "message": "PINOT-1978 NPE fix when an offline table has no validation config\n\nRB=558304\nG=pinot-dev-reviewers\nR=kgopalak,xiafu,jfim,dpatel,mshrivas\nA=mshrivas",
        "parent": "https://github.com/apache/incubator-pinot/commit/aef7db88ff8563cbe59189ccda4eeefab55cffd4",
        "patched_files": [
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_5cb7839": {
        "bug_id": "incubator-pinot_5cb7839",
        "commit": "https://github.com/apache/incubator-pinot/commit/5cb7839f5f8978eaae2a9c31aba72234bad6660e",
        "file": [
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/5cb7839f5f8978eaae2a9c31aba72234bad6660e/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java?ref=5cb7839f5f8978eaae2a9c31aba72234bad6660e",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java",
                "patch": "@@ -139,7 +139,11 @@ public String getSegmentFile() {\n     }\n \n     public void deleteSegmentFile() {\n-      FileUtils.deleteQuietly(new File(_segmentFile));\n+      // If segment build fails with an exception then we will not be able to create a segment file and\n+      // the file name will be null.\n+      if (_segmentFile != null) {\n+        FileUtils.deleteQuietly(new File(_segmentFile));\n+      }\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/5cb7839f5f8978eaae2a9c31aba72234bad6660e/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java",
                "sha": "ebb23717ff1c3437d78965f1072b4d00199559d8",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/5cb7839f5f8978eaae2a9c31aba72234bad6660e/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java?ref=5cb7839f5f8978eaae2a9c31aba72234bad6660e",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "patch": "@@ -252,6 +252,25 @@ public void testCommitAfterHold() throws Exception {\n     Assert.assertEquals(segmentDataManager._state.get(segmentDataManager), LLRealtimeSegmentDataManager.State.COMMITTED);\n   }\n \n+  @Test\n+  public void testSegmentBuildException() throws Exception {\n+    FakeLLRealtimeSegmentDataManager segmentDataManager = createFakeSegmentManager();\n+    LLRealtimeSegmentDataManager.PartitionConsumer consumer = segmentDataManager.createPartitionConsumer();\n+    final long endOffset = _startOffset + 500;\n+    // We should consume initially...\n+    segmentDataManager._consumeOffsets.add(endOffset);\n+    final SegmentCompletionProtocol.Response commitResponse = new SegmentCompletionProtocol.Response(\n+        new SegmentCompletionProtocol.Response.Params().withOffset(endOffset).withStatus(\n+            SegmentCompletionProtocol.ControllerResponseStatus.COMMIT));\n+    segmentDataManager._responses.add(commitResponse);\n+    segmentDataManager._failSegmentBuild = true;\n+\n+    consumer.run();\n+    Assert.assertTrue(segmentDataManager._buildSegmentCalled);\n+    Assert.assertEquals(segmentDataManager._state.get(segmentDataManager), LLRealtimeSegmentDataManager.State.ERROR);\n+  }\n+\n+\n   // Test hold, catchup. hold, commit\n   @Test\n   public void testCommitAfterCatchup() throws Exception {\n@@ -627,6 +646,7 @@ public void testFileRemovedDuringOnlineTransition() throws Exception {\n     public LinkedList<SegmentCompletionProtocol.Response> _responses = new LinkedList<>();\n     public boolean _commitSegmentCalled = false;\n     public boolean _buildSegmentCalled = false;\n+    public boolean _failSegmentBuild = false;\n     public boolean _buildAndReplaceCalled = false;\n     public int _stopWaitTimeMs = 100;\n     private boolean _downloadAndReplaceCalled = false;\n@@ -760,6 +780,9 @@ protected boolean buildSegmentAndReplace() {\n     @Override\n     protected String buildSegmentInternal(boolean forCommit) {\n       _buildSegmentCalled = true;\n+      if (_failSegmentBuild) {\n+        return null;\n+      }\n       if (!forCommit) {\n         return _segmentDir;\n       }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/5cb7839f5f8978eaae2a9c31aba72234bad6660e/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "sha": "d3bb18289fb009a6969b4153f07a292bd73fa1b5",
                "status": "modified"
            }
        ],
        "message": "Fix LLC consumer to handle segment build fails gracefully (#2499)\n\n* Fix LLC consumer to handle segment build fails gracefully\r\n\r\nIf segment build fails then we used throw NPE while tyring to delete a null file name.\r\nFixed the condition, and added a test.\r\nWe now handle the condition gracefully, and also set LLC_PARTITION_CONSUMING gauge to 0\r\nso that we can alert on the partition that stopped consumption.\r\n\r\n* Modified comment",
        "parent": "https://github.com/apache/incubator-pinot/commit/ccaa9f5ed02bcd26af78ffc1d4c1126b180566ad",
        "patched_files": [
            "LLRealtimeSegmentDataManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "LLRealtimeSegmentDataManagerTest.java"
        ]
    },
    "incubator-pinot_69b2e7b": {
        "bug_id": "incubator-pinot_69b2e7b",
        "commit": "https://github.com/apache/incubator-pinot/commit/69b2e7b0483dd697014d381dcc99a3fdb78282c9",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitSkipListSCMVReader.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitSkipListSCMVReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitSkipListSCMVReader.java",
                "patch": "@@ -155,8 +155,15 @@ public int getRowsPerChunk() {\n   @Override\n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(chunkOffsetsBuffer);\n+    chunkOffsetsBuffer = null;\n     MmapUtils.unloadByteBuffer(bitsetBuffer);\n+    bitsetBuffer = null;\n     MmapUtils.unloadByteBuffer(rawDataBuffer);\n+    rawDataBuffer = null;\n+    customBitSet.close();\n+    customBitSet = null;\n+    rawDataReader.close();\n+    rawDataReader = null;\n \n     if (isMmap) {\n       raf.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitSkipListSCMVReader.java",
                "sha": "3367939e188bcfe3413b35eaaa703733951ad7de",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitWidthRowColDataFileReader.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitWidthRowColDataFileReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitWidthRowColDataFileReader.java",
                "patch": "@@ -15,20 +15,17 @@\n  */\n package com.linkedin.pinot.core.index.reader.impl;\n \n-import com.google.common.primitives.Ints;\n+import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.util.CustomBitSet;\n import java.io.File;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n import java.util.Arrays;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import com.linkedin.pinot.common.utils.MmapUtils;\n-import com.linkedin.pinot.core.util.CustomBitSet;\n-\n \n /**\n  *\n@@ -61,7 +58,7 @@\n    * contain negative numbers\n    */\n   private int[] offsets;\n-  private final CustomBitSet customBitSet;\n+  private CustomBitSet customBitSet;\n \n   private int totalSizeInBytes;\n   private boolean isMmap;\n@@ -286,6 +283,9 @@ public int getNumberOfCols() {\n   public void close() throws IOException {\n     if (ownsByteBuffer) {\n       MmapUtils.unloadByteBuffer(byteBuffer);\n+      byteBuffer = null;\n+      customBitSet.close();\n+      customBitSet = null;\n \n       if (isMmap) {\n         file.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedBitWidthRowColDataFileReader.java",
                "sha": "dc631f862d853ea0938e89468ef6adddadac4c19",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteSkipListSCMVReader.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteSkipListSCMVReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteSkipListSCMVReader.java",
                "patch": "@@ -15,18 +15,16 @@\n  */\n package com.linkedin.pinot.core.index.reader.impl;\n \n-import com.google.common.primitives.Ints;\n+import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n+import com.linkedin.pinot.core.index.reader.SingleColumnMultiValueReader;\n+import com.linkedin.pinot.core.util.CustomBitSet;\n import java.io.File;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n \n-import com.linkedin.pinot.common.utils.MmapUtils;\n-import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n-import com.linkedin.pinot.core.index.reader.SingleColumnMultiValueReader;\n-import com.linkedin.pinot.core.util.CustomBitSet;\n-\n \n /**\n  * Storage Layout\n@@ -166,8 +164,15 @@ private int computeStartOffset(int row) {\n \n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(chunkOffsetsBuffer);\n+    chunkOffsetsBuffer = null;\n     MmapUtils.unloadByteBuffer(bitsetBuffer);\n+    bitsetBuffer = null;\n     MmapUtils.unloadByteBuffer(rawDataBuffer);\n+    rawDataBuffer = null;\n+    customBitSet.close();\n+    customBitSet = null;\n+    rawDataReader.close();\n+    rawDataReader = null;\n \n     if (isMmap) {\n       raf.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteSkipListSCMVReader.java",
                "sha": "1eb4e73c6a7de3c5f6babd4824ee5702f4c9cee2",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthRowColDataFileReader.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthRowColDataFileReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthRowColDataFileReader.java",
                "patch": "@@ -272,6 +272,7 @@ public int getNumberOfCols() {\n \n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(byteBuffer);\n+    byteBuffer = null;\n \n     if (isMMap) {\n       file.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthRowColDataFileReader.java",
                "sha": "321d1ec23dec093537487c1770e8c55f18a9e29d",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthSingleColumnMultiValueReader.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthSingleColumnMultiValueReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthSingleColumnMultiValueReader.java",
                "patch": "@@ -131,7 +131,13 @@ public DataFileMetadata getMetadata() {\n   @Override\n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(headerSectionByteBuffer);\n+    headerSectionByteBuffer = null;\n     MmapUtils.unloadByteBuffer(dataSectionByteBuffer);\n+    dataSectionByteBuffer = null;\n+    headerSectionReader.close();\n+    headerSectionReader = null;\n+    dataSectionReader.close();\n+    dataSectionReader = null;\n \n     if (isMMap) {\n       raf.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/reader/impl/FixedByteWidthSingleColumnMultiValueReader.java",
                "sha": "f238d23770f784185173ceacc6e56cc71f45dd6d",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnMultiValueReaderWriter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnMultiValueReaderWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnMultiValueReaderWriter.java",
                "patch": "@@ -156,7 +156,9 @@ public void close() {\n     for (ByteBuffer dataBuffer : dataBuffers) {\n       MmapUtils.unloadByteBuffer(dataBuffer);\n     }\n+    dataBuffers.clear();\n     MmapUtils.unloadByteBuffer(headerBuffer);\n+    headerBuffer = null;\n   }\n \n   private int updateHeader(int row, int length) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnMultiValueReaderWriter.java",
                "sha": "d222ff254d8cee052a09463ded76e9ba4108878e",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnSingleValueReaderWriter.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnSingleValueReaderWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnSingleValueReaderWriter.java",
                "patch": "@@ -16,17 +16,14 @@\n package com.linkedin.pinot.core.index.readerwriter.impl;\n \n import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n+import com.linkedin.pinot.core.index.reader.impl.FixedByteWidthRowColDataFileReader;\n import com.linkedin.pinot.core.index.readerwriter.SingleColumnSingleValueReaderWriter;\n+import com.linkedin.pinot.core.index.writer.impl.FixedByteWidthRowColDataFileWriter;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n import java.nio.ByteOrder;\n \n-import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n-import com.linkedin.pinot.core.index.reader.SingleColumnSingleValueReader;\n-import com.linkedin.pinot.core.index.reader.impl.FixedByteWidthRowColDataFileReader;\n-import com.linkedin.pinot.core.index.writer.SingleColumnSingleValueWriter;\n-import com.linkedin.pinot.core.index.writer.impl.FixedByteWidthRowColDataFileWriter;\n-\n \n public class FixedByteSingleColumnSingleValueReaderWriter implements SingleColumnSingleValueReaderWriter {\n \n@@ -68,8 +65,11 @@ public DataFileMetadata getMetadata() {\n   @Override\n   public void close() throws IOException {\n     reader.close();\n+    reader = null;\n     writer.close();\n+    writer = null;\n     MmapUtils.unloadByteBuffer(_buffer);\n+    _buffer = null;\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/readerwriter/impl/FixedByteSingleColumnSingleValueReaderWriter.java",
                "sha": "b10045f3c2e771b8f511fc14d27c93ff7c33bb91",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitSkipListSCMVWriter.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitSkipListSCMVWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitSkipListSCMVWriter.java",
                "patch": "@@ -139,8 +139,17 @@ public void close() {\n     IOUtils.closeQuietly(raf);\n     raf = null;\n     MmapUtils.unloadByteBuffer(chunkOffsetsBuffer);\n+    chunkOffsetsBuffer = null;\n     MmapUtils.unloadByteBuffer(bitsetBuffer);\n+    bitsetBuffer = null;\n     MmapUtils.unloadByteBuffer(rawDataBuffer);\n+    rawDataBuffer = null;\n+    customBitSet.close();\n+    customBitSet = null;\n+    chunkOffsetsWriter.close();\n+    chunkOffsetsWriter = null;\n+    rawDataWriter.close();\n+    rawDataWriter = null;\n   }\n \n   private int updateHeader(int rowId, int length) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitSkipListSCMVWriter.java",
                "sha": "b60a9331f091672fa482860785c0524ec2c3c43b",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthRowColDataFileWriter.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthRowColDataFileWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthRowColDataFileWriter.java",
                "patch": "@@ -15,8 +15,8 @@\n  */\n package com.linkedin.pinot.core.index.writer.impl;\n \n-import com.google.common.primitives.Ints;\n import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.util.CustomBitSet;\n import java.io.Closeable;\n import java.io.File;\n import java.io.FileNotFoundException;\n@@ -25,8 +25,6 @@\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n import java.util.Arrays;\n-\n-import com.linkedin.pinot.core.util.CustomBitSet;\n import org.apache.commons.io.IOUtils;\n \n \n@@ -146,9 +144,13 @@ public void setInt(int row, int col, int val) {\n     }\n   }\n \n+  @Override\n   public void close() {\n     IOUtils.closeQuietly(raf);\n     raf = null;\n     MmapUtils.unloadByteBuffer(byteBuffer);\n+    byteBuffer = null;\n+    bitSet.close();\n+    bitSet = null;\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthRowColDataFileWriter.java",
                "sha": "6f758bb0bfb56aeb4095fd0d4c036ac9658eda5e",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthSingleColumnMultiValueWriter.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthSingleColumnMultiValueWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthSingleColumnMultiValueWriter.java",
                "patch": "@@ -17,6 +17,7 @@\n \n import com.linkedin.pinot.common.utils.MmapUtils;\n import java.io.File;\n+import java.io.IOException;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n@@ -67,11 +68,18 @@ public boolean setMetadata(DataFileMetadata metadata) {\n   }\n \n   @Override\n-  public void close() {\n+  public void close() throws IOException {\n     IOUtils.closeQuietly(raf);\n     raf = null;\n     MmapUtils.unloadByteBuffer(dataBuffer);\n+    dataBuffer = null;\n     MmapUtils.unloadByteBuffer(headerBuffer);\n+    headerBuffer = null;\n+    headerWriter.close();\n+    headerWriter = null;\n+    headerReader.close();\n+    dataWriter.close();\n+    dataWriter = null;\n   }\n \n   private int updateHeader(int row, int length) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedBitWidthSingleColumnMultiValueWriter.java",
                "sha": "5c84861193c482d70d27fd4f817e62c7a21a1b4a",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteSkipListSCMVWriter.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteSkipListSCMVWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteSkipListSCMVWriter.java",
                "patch": "@@ -15,18 +15,16 @@\n  */\n package com.linkedin.pinot.core.index.writer.impl;\n \n+import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n+import com.linkedin.pinot.core.index.writer.SingleColumnMultiValueWriter;\n+import com.linkedin.pinot.core.util.CustomBitSet;\n import java.io.File;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n-\n import org.apache.commons.io.IOUtils;\n \n-import com.linkedin.pinot.common.utils.MmapUtils;\n-import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n-import com.linkedin.pinot.core.index.writer.SingleColumnMultiValueWriter;\n-import com.linkedin.pinot.core.util.CustomBitSet;\n-\n \n /**\n  * Storage Layout\n@@ -132,8 +130,17 @@ public void close() {\n     IOUtils.closeQuietly(raf);\n     raf = null;\n     MmapUtils.unloadByteBuffer(chunkOffsetsBuffer);\n+    chunkOffsetsBuffer = null;\n     MmapUtils.unloadByteBuffer(bitsetBuffer);\n+    bitsetBuffer = null;\n     MmapUtils.unloadByteBuffer(rawDataBuffer);\n+    rawDataBuffer = null;\n+    customBitSet.close();\n+    customBitSet = null;\n+    chunkOffsetsWriter.close();\n+    chunkOffsetsWriter = null;\n+    rawDataWriter.close();\n+    rawDataWriter = null;\n   }\n \n   private int updateHeader(int rowId, int length) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteSkipListSCMVWriter.java",
                "sha": "bc63ac88a91602a8a7e9e6e796691ece2b0b8735",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthRowColDataFileWriter.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthRowColDataFileWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthRowColDataFileWriter.java",
                "patch": "@@ -120,6 +120,7 @@ public void close() {\n     raf = null;\n     if (ownsByteBuffer) {\n       MmapUtils.unloadByteBuffer(byteBuffer);\n+      byteBuffer = null;\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthRowColDataFileWriter.java",
                "sha": "7a5e21777f287725449deaf4b4fe32b4fbe07545",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthSingleColumnMultiValueWriter.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthSingleColumnMultiValueWriter.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 5,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthSingleColumnMultiValueWriter.java",
                "patch": "@@ -16,15 +16,14 @@\n package com.linkedin.pinot.core.index.writer.impl;\n \n import com.linkedin.pinot.common.utils.MmapUtils;\n+import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n+import com.linkedin.pinot.core.index.reader.impl.FixedByteWidthRowColDataFileReader;\n+import com.linkedin.pinot.core.index.writer.SingleColumnMultiValueWriter;\n import java.io.File;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n-\n-import com.linkedin.pinot.core.index.reader.DataFileMetadata;\n-import com.linkedin.pinot.core.index.reader.impl.FixedByteWidthRowColDataFileReader;\n-import com.linkedin.pinot.core.index.writer.SingleColumnMultiValueWriter;\n import org.apache.commons.io.IOUtils;\n \n \n@@ -68,11 +67,19 @@ public boolean setMetadata(DataFileMetadata metadata) {\n   }\n \n   @Override\n-  public void close() {\n+  public void close() throws IOException {\n     IOUtils.closeQuietly(raf);\n     raf = null;\n     MmapUtils.unloadByteBuffer(dataBuffer);\n+    dataBuffer = null;\n     MmapUtils.unloadByteBuffer(headerBuffer);\n+    headerBuffer = null;\n+    dataWriter.close();\n+    dataWriter = null;\n+    headerWriter.close();\n+    headerWriter = null;\n+    headerReader.close();\n+    headerReader = null;\n   }\n \n   private int updateHeader(int row, int length) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/index/writer/impl/FixedByteWidthSingleColumnMultiValueWriter.java",
                "sha": "9ad02874e8b4101019666b34a58c22c70fedab09",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/indexsegment/utils/GenericRowColumnDataFileReader.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/indexsegment/utils/GenericRowColumnDataFileReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/indexsegment/utils/GenericRowColumnDataFileReader.java",
                "patch": "@@ -232,5 +232,6 @@ public int getNumberOfCols() {\n   public void close() {\n     IOUtils.closeQuietly(file);\n     MmapUtils.unloadByteBuffer(byteBuffer);\n+    byteBuffer = null;\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/indexsegment/utils/GenericRowColumnDataFileReader.java",
                "sha": "ee7b10277f607dbdd927387d3a2a843768ed2d2c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/BitmapInvertedIndexReader.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/BitmapInvertedIndexReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/BitmapInvertedIndexReader.java",
                "patch": "@@ -127,6 +127,7 @@ private void load(File file, boolean isMmap) throws IOException {\n   @Override\n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(buffer);\n+    buffer = null;\n     if (_rndFile != null) {\n       _rndFile.close();\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/BitmapInvertedIndexReader.java",
                "sha": "a44719f99565e26244cad71fa723a92e16fe6681",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/readers/FixedBitCompressedMVForwardIndexReader.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/readers/FixedBitCompressedMVForwardIndexReader.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/readers/FixedBitCompressedMVForwardIndexReader.java",
                "patch": "@@ -164,7 +164,13 @@ public DataFileMetadata getMetadata() {\n   @Override\n   public void close() throws IOException {\n     MmapUtils.unloadByteBuffer(dataSectionBuffer);\n+    dataSectionBuffer = null;\n     MmapUtils.unloadByteBuffer(headerSectionBuffer);\n+    headerSectionBuffer = null;\n+    dataSectionReader.close();\n+    dataSectionReader = null;\n+    headerSectionReader.close();\n+    headerSectionReader = null;\n \n     if (isMmap) {\n       raf.close();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/readers/FixedBitCompressedMVForwardIndexReader.java",
                "sha": "0e00e12b204a2e14a24e4f2c4fe60ec1b5505929",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/util/CustomBitSet.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/util/CustomBitSet.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/util/CustomBitSet.java",
                "patch": "@@ -15,9 +15,9 @@\n  */\n package com.linkedin.pinot.core.util;\n \n-import com.google.common.primitives.Ints;\n import com.linkedin.pinot.common.utils.MmapUtils;\n import com.linkedin.pinot.core.indexsegment.utils.BitUtils;\n+import java.io.Closeable;\n import java.nio.ByteBuffer;\n \n \n@@ -26,10 +26,10 @@\n  * Util class to store bit set, provides additional utility over java bit set by\n  * allowing reading int from start bit to end bit\n  */\n-public final class CustomBitSet {\n+public final class CustomBitSet implements Closeable {\n \n   private final int nrBytes;\n-  private final ByteBuffer buf;\n+  private ByteBuffer buf;\n   private final static int[] bitCountArray = new int[256];\n   private final static int IGNORED_ZEROS_COUNT = Integer.SIZE - Byte.SIZE;\n   private final boolean ownsByteBuffer;\n@@ -268,11 +268,11 @@ public boolean isBitSet(long index) {\n     return ((b & (1 << offset)) != 0);\n   }\n \n-  protected void finalize() throws Throwable {\n+  @Override\n+  public void close() {\n     if (ownsByteBuffer) {\n       MmapUtils.unloadByteBuffer(buf);\n+      buf = null;\n     }\n-\n-    super.finalize();\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/main/java/com/linkedin/pinot/core/util/CustomBitSet.java",
                "sha": "de0eeed17d9f17d63c2377dd21cd1ad7a2d9660b",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/core/util/CustomBitSetTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/core/util/CustomBitSetTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/core/util/CustomBitSetTest.java",
                "patch": "@@ -41,6 +41,7 @@ public void testSetBit() {\n         Assert.assertFalse(customBitSet.isBitSet(i));\n       }\n     }\n+    customBitSet.close();\n   }\n \n   @Test\n@@ -52,6 +53,7 @@ public void testFindNthBitSet() {\n     customBitSet.setBit(250);\n     System.out.println(customBitSet.findNthBitSetAfter(0, 1));\n     System.out.println(customBitSet.findNthBitSetAfter(100, 1));\n+    customBitSet.close();\n \n   }\n \n@@ -135,6 +137,7 @@ public void testFindNthBitSetRandom() {\n       }\n       Assert.assertEquals(nthBitSetAfter, expectedIndex, \"Bits set \" +\n           bitsOnCopy + \", searching for \" + nthBitToFind + \"th bit from \" + startSearchIndex);\n+      customBitSet.close();\n     }\n   }\n \n@@ -153,6 +156,7 @@ public void testNthBit() {\n           Assert.assertEquals(foundSetBitIndex, -1, \"Found bit at index \" + foundSetBitIndex + \" while it was set at \"\n               + setBitIndex + \" searching from \" + searchStartIndex);\n         }\n+        customBitSet.close();\n       }\n     }\n   }\n@@ -179,6 +183,7 @@ public void testNthBitWithConfusingBit() {\n             Assert.assertEquals(foundSetBitIndex, -1, \"Found bit at index \" + foundSetBitIndex\n                 + \" while it was set at \" + setBitIndex + \" searching from \" + searchStartIndex);\n           }\n+          customBitSet.close();\n         }\n       }\n     }\n@@ -200,5 +205,6 @@ public void testNthBitFixed() {\n       Assert.assertEquals(foundSetBitIndex, -1, \"Found bit at index \" + foundSetBitIndex + \" while it was set at \"\n           + setBitIndex + \" searching from \" + searchStartIndex);\n     }\n+    customBitSet.close();\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/core/util/CustomBitSetTest.java",
                "sha": "4130d93c4a61c54c5c0c13f189a800ae228b8888",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthRowColDataFileReaderTest.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthRowColDataFileReaderTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 6,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthRowColDataFileReaderTest.java",
                "patch": "@@ -72,7 +72,7 @@ public void testReadIntFromByteBuffer() {\n       }\n       System.out.println(\"END MAX BITS:\" + maxBits);\n       maxBits = maxBits + 1;\n-\n+      customBitSet.close();\n     }\n   }\n \n@@ -88,10 +88,11 @@ public void testSingleColUnsigned() throws Exception {\n     for (int maxBits : maxBitArray) {\n       String fileName = \"test\" + maxBits + \"FixedBitWidthSingleCol\";\n       File file = new File(fileName);\n+      CustomBitSet bitset = null;\n       try {\n         System.out.println(\"START MAX BITS:\" + maxBits);\n         int numElements = 100;\n-        CustomBitSet bitset = CustomBitSet.withBitLength(numElements * maxBits);\n+        bitset = CustomBitSet.withBitLength(numElements * maxBits);\n         int max = (int) Math.pow(2, maxBits);\n         Random r = new Random();\n         int[] values = new int[numElements];\n@@ -135,9 +136,8 @@ public void testSingleColUnsigned() throws Exception {\n         System.out.println(\"END MAX BITS:\" + maxBits);\n       } finally {\n         file.delete();\n-\n+        bitset.close();\n       }\n-\n     }\n   }\n \n@@ -153,12 +153,12 @@ public void testSingleColSigned() throws Exception {\n     for (int maxBits : maxBitArray) {\n       String fileName = \"test\" + maxBits + \"FixedBitWidthSingleCol\";\n       File file = new File(fileName);\n+      CustomBitSet bitset = null;\n       try {\n         System.out.println(\"START MAX BITS:\" + maxBits);\n         int numElements = 100;\n         int requiredBits = maxBits + 1;\n-        CustomBitSet bitset = CustomBitSet.withBitLength(numElements\n-            * requiredBits);\n+        bitset = CustomBitSet.withBitLength(numElements * requiredBits);\n         int max = (int) Math.pow(2, maxBits);\n         Random r = new Random();\n         int[] values = new int[numElements];\n@@ -207,6 +207,7 @@ public void testSingleColSigned() throws Exception {\n         System.out.println(\"END MAX BITS:\" + maxBits);\n       } finally {\n         file.delete();\n+        bitset.close();\n       }\n \n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthRowColDataFileReaderTest.java",
                "sha": "339987172e8f4eb964802fc8fa37ea71b5820c1b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthSingleColumnMultiValueReaderTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthSingleColumnMultiValueReaderTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthSingleColumnMultiValueReaderTest.java",
                "patch": "@@ -74,6 +74,7 @@ public void testSingleColMultiValue() throws Exception {\n       dos.write(bitSet.toByteArray());\n       dos.flush();\n       dos.close();\n+      bitSet.close();\n \n       // Assert.assertEquals(FileReaderTestUtils.getNumOpenFiles(f), 0);\n       final int[] readValues = new int[100];",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/reader/FixedBitWidthSingleColumnMultiValueReaderTest.java",
                "sha": "65c7f384011cf74acc6f4fc302f1ad0aaa4ee047",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitSkipListSCMVWriterTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitSkipListSCMVWriterTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitSkipListSCMVWriterTest.java",
                "patch": "@@ -114,6 +114,8 @@ public void testSingleColMultiValue() throws Exception {\n       file.delete();\n       System.out.println(\"END test maxBit:\" + maxBits);\n       maxBits = maxBits + 1;\n+      bitSet.close();\n+      customBit.close();\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitSkipListSCMVWriterTest.java",
                "sha": "04db98342ecbf4eff0d761b5ea48301d6a3d218f",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthRowColDataFileWriterTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthRowColDataFileWriterTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthRowColDataFileWriterTest.java",
                "patch": "@@ -79,6 +79,7 @@ public void testSingleColUnsigned() throws Exception {\n       System.out.println(\"END test maxBits:\" + maxBits);\n       maxBits = maxBits + 1;\n       file.delete();\n+      set.close();\n     }\n   }\n \n@@ -140,6 +141,7 @@ public void testSingleColSigned() throws Exception {\n       System.out.println(\"END test maxBits:\" + maxBits);\n       maxBits = maxBits + 1;\n       file.delete();\n+      set.close();\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthRowColDataFileWriterTest.java",
                "sha": "d9afc8ff569bc93964be902302c4962a10396c69",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthSingleColumnMultiValueWriterTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthSingleColumnMultiValueWriterTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthSingleColumnMultiValueWriterTest.java",
                "patch": "@@ -90,6 +90,7 @@ public void testSingleColMultiValue() throws Exception {\n       file.delete();\n       System.out.println(\"END test maxBit:\" + maxBits);\n       maxBits = maxBits + 1;\n+      bitSet.close();\n     }\n \n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedBitWidthSingleColumnMultiValueWriterTest.java",
                "sha": "f569683bd9450d072f061197ee4a104df2310cc9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedByteSkipListSCMVWriterTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedByteSkipListSCMVWriterTest.java?ref=69b2e7b0483dd697014d381dcc99a3fdb78282c9",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedByteSkipListSCMVWriterTest.java",
                "patch": "@@ -92,5 +92,6 @@ public void testSingleColMultiValue() throws Exception {\n     dis.close();\n     file.delete();\n     raf.close();\n+    customBit.close();\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/69b2e7b0483dd697014d381dcc99a3fdb78282c9/pinot-core/src/test/java/com/linkedin/pinot/index/writer/FixedByteSkipListSCMVWriterTest.java",
                "sha": "12d180628cd25b7e8d0c4e2a1207e8a4ab7ba153",
                "status": "modified"
            }
        ],
        "message": "[PINOT-2262] Set mmap handles to null after the file is unmapped.\n\nThis moves us one step easier to debug the issue. We will get an NPE instead of\na JVM crash (which is what is happening now)\n\nFix usages of CustomBitSet to close it, and remove the finalize method from it.\nThe finalize method was used only in tests\n\nRB=596782\nBUG=PINOT-2262\nG=pinot-dev-reviewers\nR=kgopalak,jfim\nA=kgopalak,jfim",
        "parent": "https://github.com/apache/incubator-pinot/commit/2cb57cea1d7292dd09a31e361120edc0db7c9c47",
        "patched_files": [
            "FixedBitWidthSingleColumnMultiValueWriter.java",
            "FixedBitWidthRowColDataFileReader.java",
            "BitmapInvertedIndexReader.java",
            "FixedByteSkipListSCMVWriter.java",
            "FixedByteSingleColumnSingleValueReaderWriter.java",
            "FixedByteWidthRowColDataFileWriter.java",
            "FixedBitSkipListSCMVReader.java",
            "FixedByteWidthRowColDataFileReader.java",
            "FixedByteSkipListSCMVReader.java",
            "FixedBitWidthRowColDataFileWriter.java",
            "GenericRowColumnDataFileReader.java",
            "FixedBitCompressedMVForwardIndexReader.java",
            "FixedByteWidthSingleColumnMultiValueReader.java",
            "CustomBitSet.java",
            "FixedByteSingleColumnMultiValueReaderWriter.java",
            "FixedByteWidthSingleColumnMultiValueWriter.java",
            "FixedBitSkipListSCMVWriter.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "FixedByteWidthRowColDataFileReaderTest.java",
            "FixedBitWidthSingleColumnMultiValueWriterTest.java",
            "FixedByteWidthSingleColumnMultiValueReaderTest.java",
            "FixedByteSingleColumnMultiValueReaderWriterTest.java",
            "FixedBitWidthRowColDataFileReaderTest.java",
            "FixedByteSkipListSCMVWriterTest.java",
            "FixedBitWidthRowColDataFileWriterTest.java",
            "FixedByteSkipListSCMVReaderTest.java",
            "FixedByteSingleColumnSingleValueReaderWriterTest.java",
            "FixedByteWidthRowColDataFileWriterTest.java",
            "FixedBitSkipListSCMVWriterTest.java",
            "FixedByteWidthSingleColumnMultiValueWriterTest.java",
            "CustomBitSetTest.java",
            "FixedBitWidthSingleColumnMultiValueReaderTest.java",
            "FixedBitSkipListSCMVReaderTest.java"
        ]
    },
    "incubator-pinot_6e209e4": {
        "bug_id": "incubator-pinot_6e209e4",
        "commit": "https://github.com/apache/incubator-pinot/commit/6e209e4e0ef138f8c21d597aeb20d1993fd1af2b",
        "file": [
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/6e209e4e0ef138f8c21d597aeb20d1993fd1af2b/pinot-common/src/main/java/org/apache/pinot/common/utils/ServiceStatus.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/org/apache/pinot/common/utils/ServiceStatus.java?ref=6e209e4e0ef138f8c21d597aeb20d1993fd1af2b",
                "deletions": 2,
                "filename": "pinot-common/src/main/java/org/apache/pinot/common/utils/ServiceStatus.java",
                "patch": "@@ -24,6 +24,7 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import javax.annotation.Nullable;\n import org.apache.helix.HelixAdmin;\n import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n@@ -209,6 +210,7 @@ public synchronized String getStatusDescription() {\n           getResourceListAsString(), _instanceName);\n     }\n \n+    @Nullable\n     protected abstract T getState(String resourceName);\n \n     protected abstract Map<String, String> getPartitionStateMap(T state);\n@@ -381,12 +383,21 @@ public IdealStateAndCurrentStateMatchServiceStatusCallback(HelixManager helixMan\n       super(helixManager, clusterName, instanceName, resourcesToMonitor, minResourcesStartPercent);\n     }\n \n+    /**\n+     * Returns the current state for the given resource, or {@code null} if instance is not live or current state does\n+     * not exist.\n+     */\n+    @Nullable\n     @Override\n     protected CurrentState getState(String resourceName) {\n       PropertyKey.Builder keyBuilder = _helixDataAccessor.keyBuilder();\n       LiveInstance liveInstance = _helixDataAccessor.getProperty(keyBuilder.liveInstance(_instanceName));\n-      String sessionId = liveInstance.getSessionId();\n-      return _helixDataAccessor.getProperty(keyBuilder.currentState(_instanceName, sessionId, resourceName));\n+      if (liveInstance == null) {\n+        return null;\n+      } else {\n+        String sessionId = liveInstance.getSessionId();\n+        return _helixDataAccessor.getProperty(keyBuilder.currentState(_instanceName, sessionId, resourceName));\n+      }\n     }\n \n     @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/6e209e4e0ef138f8c21d597aeb20d1993fd1af2b/pinot-common/src/main/java/org/apache/pinot/common/utils/ServiceStatus.java",
                "sha": "2079dbeb64c849fdd2bc8220dca5a02d8f914f77",
                "status": "modified"
            }
        ],
        "message": "Handle NPE from getting live instance (#4528)",
        "parent": "https://github.com/apache/incubator-pinot/commit/0a13d98760cf5ac557e5ea47766b68a4ad3131b7",
        "patched_files": [
            "ServiceStatus.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "ServiceStatusTest.java"
        ]
    },
    "incubator-pinot_70c8f1b": {
        "bug_id": "incubator-pinot_70c8f1b",
        "commit": "https://github.com/apache/incubator-pinot/commit/70c8f1b16cebbfadb025468e562e1a70a745fe81",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java?ref=70c8f1b16cebbfadb025468e562e1a70a745fe81",
                "deletions": 5,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.controller;\n \n-import com.google.common.primitives.Longs;\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.IOException;\n@@ -26,14 +25,14 @@\n import org.apache.commons.httpclient.HttpConnectionManager;\n import org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;\n import org.apache.commons.io.FileUtils;\n-import org.apache.commons.io.IOUtils;\n import org.apache.helix.PreConnectCallback;\n import org.restlet.Application;\n import org.restlet.Component;\n import org.restlet.Context;\n import org.restlet.data.Protocol;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import com.google.common.primitives.Longs;\n import com.google.common.util.concurrent.ThreadFactoryBuilder;\n import com.linkedin.pinot.common.Utils;\n import com.linkedin.pinot.common.metrics.ControllerMeter;\n@@ -61,7 +60,7 @@\n   private final Application controllerRestApp;\n   private final PinotHelixResourceManager helixResourceManager;\n   private final RetentionManager retentionManager;\n-  private final ValidationManager validationManager;\n+  private ValidationManager validationManager;\n   private final MetricsRegistry _metricsRegistry;\n   private final PinotRealtimeSegmentManager realtimeSegmentsManager;\n   private final SegmentStatusChecker segmentStatusChecker;\n@@ -75,8 +74,6 @@ public ControllerStarter(ControllerConf conf) {\n     retentionManager = new RetentionManager(helixResourceManager, config.getRetentionControllerFrequencyInSeconds());\n     _metricsRegistry = new MetricsRegistry();\n     realtimeSegmentsManager = new PinotRealtimeSegmentManager(helixResourceManager);\n-    ValidationMetrics validationMetrics = new ValidationMetrics(_metricsRegistry);\n-    validationManager = new ValidationManager(validationMetrics, helixResourceManager, config, null);\n     segmentStatusChecker = new SegmentStatusChecker(helixResourceManager, config);\n     executorService = Executors.newCachedThreadPool(\n         new ThreadFactoryBuilder().setNameFormat(\"restlet-multiget-thread-%d\").build());\n@@ -86,6 +83,10 @@ public PinotHelixResourceManager getHelixResourceManager() {\n     return helixResourceManager;\n   }\n \n+  public ValidationManager getValidationManager() {\n+    return validationManager;\n+  }\n+\n   public void start() {\n     LOGGER.info(\"Starting Pinot controller\");\n \n@@ -119,6 +120,8 @@ public void start() {\n       helixResourceManager.start();\n       // Helix resource manager must be started in order to create PinotLLCRealtimeSegmentManager\n       PinotLLCRealtimeSegmentManager.create(helixResourceManager, config, controllerMetrics);\n+      ValidationMetrics validationMetrics = new ValidationMetrics(_metricsRegistry);\n+      validationManager = new ValidationManager(validationMetrics, helixResourceManager, config, PinotLLCRealtimeSegmentManager.getInstance());\n       LOGGER.info(\"Starting Pinot REST API component\");\n       component.start();\n       LOGGER.info(\"Starting retention manager\");",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/main/java/com/linkedin/pinot/controller/ControllerStarter.java",
                "sha": "62edfb964df6ffe0acfdaeb1c607472c8d9dacaa",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/main/java/com/linkedin/pinot/controller/validation/ValidationManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/validation/ValidationManager.java?ref=70c8f1b16cebbfadb025468e562e1a70a745fe81",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/validation/ValidationManager.java",
                "patch": "@@ -169,6 +169,8 @@ public void runValidation() {\n             LOGGER.warn(\"Cannot get realtime tableconfig for {}\", tableName);\n           } else if (streamMetadata == null) {\n             LOGGER.warn(\"Cannot get streamconfig for {}\", tableName);\n+          } else {\n+            LOGGER.error(\"Exception while validating table {}\", tableName, e);\n           }\n         }\n       } else {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/main/java/com/linkedin/pinot/controller/validation/ValidationManager.java",
                "sha": "5f597bc88e726d5d0e7a2bfe7bba33f9b6a1f596",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java?ref=70c8f1b16cebbfadb025468e562e1a70a745fe81",
                "deletions": 0,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "patch": "@@ -36,6 +36,7 @@\n import com.linkedin.pinot.common.utils.ZkStarter;\n import com.linkedin.pinot.controller.ControllerConf;\n import com.linkedin.pinot.controller.ControllerStarter;\n+import com.linkedin.pinot.controller.validation.ValidationManager;\n \n \n /**\n@@ -139,6 +140,11 @@ protected void startController() {\n     startController(false);\n   }\n \n+  protected ValidationManager getControllerValidationManager() throws Exception {\n+    assert _controllerStarter != null;\n+    return _controllerStarter.getValidationManager();\n+  }\n+\n   /**\n    * Stops an already started controller\n    */",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "sha": "62cae19760b7a2747267e97250c1850d52c88c59",
                "status": "modified"
            },
            {
                "additions": 23,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SegmentCompletionIntegrationTests.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SegmentCompletionIntegrationTests.java?ref=70c8f1b16cebbfadb025468e562e1a70a745fe81",
                "deletions": 1,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SegmentCompletionIntegrationTests.java",
                "patch": "@@ -27,6 +27,7 @@\n import org.apache.helix.NotificationContext;\n import org.apache.helix.ZNRecord;\n import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n import org.apache.helix.model.Message;\n import org.apache.helix.participant.StateMachineEngine;\n import org.apache.helix.participant.statemachine.StateModel;\n@@ -45,6 +46,7 @@\n import com.linkedin.pinot.common.utils.CommonConstants;\n import com.linkedin.pinot.common.utils.ControllerTenantNameBuilder;\n import com.linkedin.pinot.common.utils.KafkaStarterUtils;\n+import com.linkedin.pinot.common.utils.LLCSegmentName;\n import com.linkedin.pinot.common.utils.NetUtil;\n import com.linkedin.pinot.common.utils.ZkStarter;\n import com.linkedin.pinot.common.utils.ZkUtils;\n@@ -132,7 +134,7 @@ private void stopFakeServer() {\n \n   // Test that if we send stoppedConsuming to the controller, the segment goes offline.\n   @Test\n-  public void testStopConsumingToOffline() throws  Exception {\n+  public void testStopConsumingToOfflineAndAutofix() throws  Exception {\n     final String realtimeTableName = TableNameBuilder.REALTIME_TABLE_NAME_BUILDER.forTable(_tableName);\n     long endTime = now() + MAX_RUN_TIME_SECONDS * 1000L;\n \n@@ -169,6 +171,26 @@ public void testStopConsumingToOffline() throws  Exception {\n     }\n \n     Assert.assertTrue(now() < endTime, \"Failed trying to reach offline state\");\n+\n+    // Now call the validation manager, and the segment should fix itself\n+    getControllerValidationManager().runValidation();\n+\n+    // Now there should be a new segment in CONSUMING state in the IDEALSTATE.\n+    IdealState idealState = HelixHelper.getTableIdealState(_helixManager, realtimeTableName);\n+    Assert.assertEquals(idealState.getPartitionSet().size(), 2);\n+    for (String segmentId : idealState.getPartitionSet()) {\n+      if (!segmentId.equals(_segmentName)) {\n+        // This is a new segment. Verify that it is in CONSUMING state, and has a sequence number 1 more than prev one\n+        LLCSegmentName oldSegmentName = new LLCSegmentName(_segmentName);\n+        LLCSegmentName newSegmentName = new LLCSegmentName(segmentId);\n+        Assert.assertEquals(newSegmentName.getSequenceNumber(), oldSegmentName.getSequenceNumber() + 1);\n+        Map<String, String> instanceStateMap = idealState.getInstanceStateMap(segmentId);\n+        for (String state : instanceStateMap.values()) {\n+          Assert.assertTrue(state.equals(PinotHelixSegmentOnlineOfflineStateModelGenerator.CONSUMING_STATE));\n+        }\n+      }\n+    }\n+    // We will assume that it eventually makes it to externalview\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/70c8f1b16cebbfadb025468e562e1a70a745fe81/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/SegmentCompletionIntegrationTests.java",
                "sha": "e9c0736f43506ae91e744221cb643608aaa756dd",
                "status": "modified"
            }
        ],
        "message": "[PINOT-4312] Fix NPE in ValidationManager (#952)\n\nMoved the instantiation of ValidationManager to to be after that of PinotLLCRealtimeSegmentManager\r\nso that it can get a handle to the right instance of the latter.\r\n\r\nAdded an integration test to make sure that a ValidationManager run fixes offline partitions",
        "parent": "https://github.com/apache/incubator-pinot/commit/5e222ca123e7adbdb6d207dd8831810e6dceccb6",
        "patched_files": [
            "ValidationManager.java",
            "ControllerStarter.java",
            "SegmentCompletionIntegrationTests.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "ValidationManagerTest.java",
            "ControllerTest.java"
        ]
    },
    "incubator-pinot_72a3b62": {
        "bug_id": "incubator-pinot_72a3b62",
        "commit": "https://github.com/apache/incubator-pinot/commit/72a3b62fbae38654331b9602234746da19ef3b8d",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/72a3b62fbae38654331b9602234746da19ef3b8d/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=72a3b62fbae38654331b9602234746da19ef3b8d",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -191,7 +191,7 @@ private void updateDeletionStrategiesForEntireCluster() {\n \n     AbstractTableConfig realtimeTableConfig;\n     try {\n-      realtimeTableConfig = ZKMetadataProvider.getOfflineTableConfig(_pinotHelixResourceManager.getPropertyStore(), realtimeTableName);\n+      realtimeTableConfig = ZKMetadataProvider.getRealtimeTableConfig(_pinotHelixResourceManager.getPropertyStore(), realtimeTableName);\n     } catch (Exception e) {\n       LOGGER.error(\"Error getting realtime table config from property store!\", e);\n       return tableToDeletionStrategyMap;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/72a3b62fbae38654331b9602234746da19ef3b8d/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "c678b2ebd3860351cfbfaeba612928546634af89",
                "status": "modified"
            }
        ],
        "message": "Fixing realtime retention NPE",
        "parent": "https://github.com/apache/incubator-pinot/commit/3494074e27ae4000a4e9362329df87ec994a7a66",
        "patched_files": [
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_73ee15e": {
        "bug_id": "incubator-pinot_73ee15e",
        "commit": "https://github.com/apache/incubator-pinot/commit/73ee15e16a25f693f0f99cb01095426ffb04c23d",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/73ee15e16a25f693f0f99cb01095426ffb04c23d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java?ref=73ee15e16a25f693f0f99cb01095426ffb04c23d",
                "deletions": 3,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "patch": "@@ -31,20 +31,17 @@\n import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import org.testng.Assert;\n \n import com.linkedin.pinot.broker.broker.BrokerTestUtils;\n import com.linkedin.pinot.broker.broker.helix.HelixBrokerStarter;\n import com.linkedin.pinot.common.ZkTestUtils;\n-import com.linkedin.pinot.common.data.FieldSpec;\n import com.linkedin.pinot.common.data.Schema;\n import com.linkedin.pinot.common.request.helper.ControllerRequestBuilder;\n import com.linkedin.pinot.common.utils.CommonConstants.Helix;\n import com.linkedin.pinot.common.utils.CommonConstants.Helix.DataSource;\n import com.linkedin.pinot.common.utils.CommonConstants.Helix.DataSource.Realtime.Kafka;\n import com.linkedin.pinot.common.utils.CommonConstants.Server;\n import com.linkedin.pinot.common.utils.FileUploadUtils;\n-import com.linkedin.pinot.controller.helix.ControllerRequestBuilderUtil;\n import com.linkedin.pinot.controller.helix.ControllerRequestURLBuilder;\n import com.linkedin.pinot.controller.helix.ControllerTest;\n import com.linkedin.pinot.controller.helix.ControllerTestUtils;\n@@ -76,6 +73,7 @@ protected void startBrokers(int brokerCount) {\n         Configuration configuration = BrokerTestUtils.getDefaultBrokerConfiguration();\n         configuration.setProperty(\"pinot.broker.time.out\", 100 * 1000L);\n         configuration.setProperty(\"pinot.broker.client.queryPort\", Integer.toString(18099 + i));\n+        configuration.setProperty(\"pinot.broker.routing.table.builder.class\", \"random\");\n         overrideBrokerConf(configuration);\n         _brokerStarters.add(BrokerTestUtils.startBroker(helixClusterName, ZkTestUtils.DEFAULT_ZK_STR, configuration));\n       }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/73ee15e16a25f693f0f99cb01095426ffb04c23d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "sha": "3972ed3dd5066a118359a7027be41ab205948ef9",
                "status": "modified"
            }
        ],
        "message": "Fix NPE in integration tests when starting the broker\n\nRB=489921\nR=kgopalak,xiafu,jfim,dpatel,mshrivas\nA=kgopalak",
        "parent": "https://github.com/apache/incubator-pinot/commit/32e4b247046f94aba8f5d2287b18dd31455f4b47",
        "patched_files": [],
        "repo": "incubator-pinot",
        "unit_tests": [
            "ClusterTest.java"
        ]
    },
    "incubator-pinot_77726cb": {
        "bug_id": "incubator-pinot_77726cb",
        "commit": "https://github.com/apache/incubator-pinot/commit/77726cb01d1d7ac596bccefb71bfeb8c5099b055",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/ThirdEyeAnomalyApplication.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/ThirdEyeAnomalyApplication.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 2,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/ThirdEyeAnomalyApplication.java",
                "patch": "@@ -33,7 +33,7 @@\n   private AnomalyMergeExecutor anomalyMergeExecutor = null;\n \n   public static void main(final String[] args) throws Exception {\n-    List<String> argList = new ArrayList<String>(Arrays.asList(args));\n+    List<String> argList = new ArrayList<>(Arrays.asList(args));\n     if (argList.size() == 1) {\n       argList.add(0, \"server\");\n     }\n@@ -62,7 +62,6 @@ public void run(final ThirdEyeAnomalyConfiguration config, final Environment env\n     LOG.info(\"Starting ThirdeyeAnomalyApplication : Scheduler {} Worker {}\", config.isScheduler(), config.isWorker());\n     super.initDAOs();\n     ThirdEyeCacheRegistry.initializeCaches(config, webappConfigDAO);\n-\n     environment.lifecycle().manage(new Managed() {\n       @Override\n       public void start() throws Exception {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/ThirdEyeAnomalyApplication.java",
                "sha": "17a654931b55836498d6dbd42ce4c736e49b17ad",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/detection/DetectionTaskRunner.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/detection/DetectionTaskRunner.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 3,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/detection/DetectionTaskRunner.java",
                "patch": "@@ -91,12 +91,11 @@ public DetectionTaskRunner() {\n \n     CollectionSchema collectionSchema = null;\n     try {\n-      collectionSchema = CACHE_REGISTRY_INSTANCE.getCollectionSchemaCache()\n-          .get(anomalyFunctionSpec.getCollection());\n+      collectionSchema = CACHE_REGISTRY_INSTANCE.getCollectionSchemaCache().get(anomalyFunctionSpec.getCollection());\n+      collectionDimensions = collectionSchema.getDimensionNames();\n     } catch (Exception e) {\n       LOG.error(\"Exception when reading collection schema cache\", e);\n     }\n-    collectionDimensions = collectionSchema.getDimensionNames();\n \n     // Get existing anomalies for this time range\n     knownAnomalies = getExistingAnomalies();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/detection/DetectionTaskRunner.java",
                "sha": "2bd55a6ccc2e576d4e5572a3228677a02b367386",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/job/JobRunner.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/job/JobRunner.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/job/JobRunner.java",
                "patch": "@@ -7,6 +7,6 @@\n  */\n public interface JobRunner extends Runnable {\n \n-  long createJob();\n+  Long createJob();\n   List<Long> createTasks();\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/job/JobRunner.java",
                "sha": "6485c490af342c59e3a2bd0a6562d17b5250feb7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorConstants.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorConstants.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorConstants.java",
                "patch": "@@ -6,7 +6,7 @@\n     EXPIRE\n   }\n \n-  public static int DEFAULT_EXPIRE_DAYS_AGO = 7;\n+  public static int DEFAULT_EXPIRE_DAYS_AGO = 3;\n   public static int DEFAULT_MONITOR_FREQUENCY_HOURS = 1;\n \n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorConstants.java",
                "sha": "9251fe6146ab12254fea393d941e2acb8eb041e1",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorJobRunner.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorJobRunner.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 5,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorJobRunner.java",
                "patch": "@@ -45,16 +45,17 @@ public void run() {\n       List<AnomalyJobSpec> anomalyJobSpecs = findAnomalyJobsWithStatusScheduled();\n       monitorJobContext.setJobName(TaskType.MONITOR.toString());\n       monitorJobContext.setAnomalyJobSpecs(anomalyJobSpecs);\n-      long jobExecutionId = createJob();\n-      monitorJobContext.setJobExecutionId(jobExecutionId);\n-      List<Long> taskIds = createTasks();\n-\n+      Long jobExecutionId = createJob();\n+      if (jobExecutionId != null) {\n+        monitorJobContext.setJobExecutionId(jobExecutionId);\n+        List<Long> taskIds = createTasks();\n+      }\n     } catch (Exception e) {\n       LOG.error(\"Exception in monitor job runner\", e);\n     }\n   }\n \n-  public long createJob() {\n+  public Long createJob() {\n     Long jobExecutionId = null;\n     try {\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/monitor/MonitorJobRunner.java",
                "sha": "f37a6c5425894b5facf72e382753782a4d6b264a",
                "status": "modified"
            },
            {
                "additions": 47,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/task/TaskDriver.java",
                "changes": 90,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/task/TaskDriver.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 43,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/task/TaskDriver.java",
                "patch": "@@ -7,6 +7,7 @@\n \n import java.util.ArrayList;\n import java.util.List;\n+import java.util.Random;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n@@ -31,24 +32,21 @@\n   private ExecutorService taskExecutorService;\n \n   private final AnomalyTaskDAO anomalyTaskDAO;\n-  private final AnomalyResultDAO anomalyResultDAO;\n-  private final AnomalyMergedResultDAO mergedResultDAO;\n-  private AnomalyFunctionFactory anomalyFunctionFactory;\n   private TaskContext taskContext;\n-  private ThirdEyeAnomalyConfiguration thirdEyeAnomalyConfiguration;\n   private long workerId;\n \n-  volatile boolean shutdown = false;\n-  private static int MAX_PARALLEL_TASK = 3;\n+  private volatile boolean shutdown = false;\n+  private static final int MAX_PARALLEL_TASK = 3;\n+  private static final int NO_TASK_IDLE_DELAY_MILLIS = 15_000; // 15 seconds\n+  private static final int TASK_FAILURE_DELAY_MILLIS = 5 * 60_000; // 5 minutes\n+  private static final int TASK_FETCH_SIZE = 10;\n+  private static final Random RANDOM = new Random();\n \n   public TaskDriver(ThirdEyeAnomalyConfiguration thirdEyeAnomalyConfiguration, AnomalyJobDAO anomalyJobDAO,\n       AnomalyTaskDAO anomalyTaskDAO, AnomalyResultDAO anomalyResultDAO, AnomalyMergedResultDAO mergedResultDAO,\n       AnomalyFunctionFactory anomalyFunctionFactory) {\n     this.workerId = thirdEyeAnomalyConfiguration.getId();\n     this.anomalyTaskDAO = anomalyTaskDAO;\n-    this.anomalyResultDAO = anomalyResultDAO;\n-    this.mergedResultDAO = mergedResultDAO;\n-    this.anomalyFunctionFactory = anomalyFunctionFactory;\n     taskExecutorService = Executors.newFixedThreadPool(MAX_PARALLEL_TASK);\n \n     taskContext = new TaskContext();\n@@ -63,36 +61,31 @@ public TaskDriver(ThirdEyeAnomalyConfiguration thirdEyeAnomalyConfiguration, Ano\n   public void start() throws Exception {\n     List<Callable<Void>> callables = new ArrayList<>();\n     for (int i = 0; i < MAX_PARALLEL_TASK; i++) {\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          while (!shutdown) {\n-\n-            LOG.info(Thread.currentThread().getId() + \" : Finding next task to execute for threadId:{}\",\n-                Thread.currentThread().getId());\n-\n-            try {\n-              // select a task to execute, and update it to RUNNING\n-              AnomalyTaskSpec anomalyTaskSpec = selectAndUpdate();\n-              LOG.info(Thread.currentThread().getId() + \" : Executing task: {} {}\", anomalyTaskSpec.getId(),\n-                  anomalyTaskSpec.getTaskInfo());\n-\n-              // execute the selected task\n-              TaskType taskType = anomalyTaskSpec.getTaskType();\n-              TaskRunner taskRunner = TaskRunnerFactory.getTaskRunnerFromTaskType(taskType);\n-              TaskInfo taskInfo = TaskInfoFactory.getTaskInfoFromTaskType(taskType, anomalyTaskSpec.getTaskInfo());\n-              LOG.info(Thread.currentThread().getId() + \" : Task Info {}\", taskInfo);\n-              List<TaskResult> taskResults = taskRunner.execute(taskInfo, taskContext);\n-              LOG.info(Thread.currentThread().getId() + \" : DONE Executing task: {}\", anomalyTaskSpec.getId());\n-\n-              // update status to COMPLETED\n-              updateStatusAndTaskEndTime(anomalyTaskSpec.getId(), TaskStatus.RUNNING, TaskStatus.COMPLETED);\n-            } catch (Exception e) {\n-              LOG.error(\"Exception in electing and executing task\", e);\n-            }\n+      Callable<Void> callable = () -> {\n+        while (!shutdown) {\n+          LOG.info(Thread.currentThread().getId() + \" : Finding next task to execute for threadId:{}\",\n+              Thread.currentThread().getId());\n+          try {\n+            // select a task to execute, and update it to RUNNING\n+            AnomalyTaskSpec anomalyTaskSpec = selectAndUpdate();\n+            LOG.info(Thread.currentThread().getId() + \" : Executing task: {} {}\", anomalyTaskSpec.getId(),\n+                anomalyTaskSpec.getTaskInfo());\n+\n+            // execute the selected task\n+            TaskType taskType = anomalyTaskSpec.getTaskType();\n+            TaskRunner taskRunner = TaskRunnerFactory.getTaskRunnerFromTaskType(taskType);\n+            TaskInfo taskInfo = TaskInfoFactory.getTaskInfoFromTaskType(taskType, anomalyTaskSpec.getTaskInfo());\n+            LOG.info(Thread.currentThread().getId() + \" : Task Info {}\", taskInfo);\n+            List<TaskResult> taskResults = taskRunner.execute(taskInfo, taskContext);\n+            LOG.info(Thread.currentThread().getId() + \" : DONE Executing task: {}\", anomalyTaskSpec.getId());\n+\n+            // update status to COMPLETED\n+            updateStatusAndTaskEndTime(anomalyTaskSpec.getId(), TaskStatus.RUNNING, TaskStatus.COMPLETED);\n+          } catch (Exception e) {\n+            LOG.error(\"Exception in electing and executing task\", e);\n           }\n-          return null;\n         }\n+        return null;\n       };\n       callables.add(callable);\n     }\n@@ -106,16 +99,28 @@ public void stop() {\n     taskExecutorService.shutdown();\n   }\n \n-  private AnomalyTaskSpec selectAndUpdate() {\n+  private AnomalyTaskSpec selectAndUpdate() throws Exception {\n     LOG.info(Thread.currentThread().getId() + \" : Starting selectAndUpdate {}\", Thread.currentThread().getId());\n     AnomalyTaskSpec acquiredTask = null;\n     LOG.info(Thread.currentThread().getId() + \" : Trying to find a task to execute\");\n     do {\n-\n       List<AnomalyTaskSpec> anomalyTasks = new ArrayList<>();\n-      anomalyTasks = anomalyTaskDAO.findByStatusOrderByCreateTimeAscending(TaskStatus.WAITING);\n-      if (anomalyTasks.size() > 0)\n+      try {\n+        anomalyTasks = anomalyTaskDAO.findByStatusOrderByCreateTimeAsc(TaskStatus.WAITING, TASK_FETCH_SIZE);\n+      } catch (Exception e) {\n+        LOG.error(\"Exception found in fetching new tasks, sleeping for few seconds\", e);\n+        // TODO : Add better wait / clear call\n+        Thread.sleep(TASK_FAILURE_DELAY_MILLIS);\n+      }\n+      if (anomalyTasks.size() > 0) {\n         LOG.info(Thread.currentThread().getId() + \" : Found {} tasks in waiting state\", anomalyTasks.size());\n+      } else {\n+        // sleep for few seconds if not tasks found - avoid cpu thrashing\n+        // also add some extra random number of milli seconds to allow threads to start at different times\n+        // TODO : Add better wait / clear call\n+        LOG.debug(\"No tasks found to execute, sleeping for {} MS\", NO_TASK_IDLE_DELAY_MILLIS + RANDOM.nextInt(1000));\n+        Thread.sleep(NO_TASK_IDLE_DELAY_MILLIS);\n+      }\n \n       for (AnomalyTaskSpec anomalyTaskSpec : anomalyTasks) {\n         LOG.info(Thread.currentThread().getId() + \" : Trying to acquire task : {}\", anomalyTaskSpec.getId());\n@@ -126,7 +131,7 @@ private AnomalyTaskSpec selectAndUpdate() {\n               TaskStatus.RUNNING);\n           LOG.info(Thread.currentThread().getId() + \" : Task acquired success: {}\", success);\n         } catch (OptimisticLockException | RollbackException | StaleObjectStateException e) {\n-          LOG.warn(\"Optimistic lock exception in acquiring task by threadId {} and workerId {}\",\n+          LOG.warn(\"[{}] in acquiring task by threadId {} and workerId {}\", e.getClass().getSimpleName(),\n               Thread.currentThread().getId(), workerId);\n         }\n         if (success) {\n@@ -136,7 +141,6 @@ private AnomalyTaskSpec selectAndUpdate() {\n       }\n     } while (acquiredTask == null);\n     LOG.info(Thread.currentThread().getId() + \" : Acquired task ======\" + acquiredTask);\n-\n     return acquiredTask;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/anomaly/task/TaskDriver.java",
                "sha": "a1d5922a9a7ad7711d7b2084cd8fd0cda305fc20",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/common/persistence/PersistenceUtil.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/common/persistence/PersistenceUtil.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 3,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/common/persistence/PersistenceUtil.java",
                "patch": "@@ -40,18 +40,21 @@ public static void init(File localConfigFile) {\n     ds.setDriverClassName(configuration.getDatabaseConfiguration().getProperties().get(\"hibernate.connection.driver_class\"));\n \n     // pool size configurations\n-    ds.setMaxActive(100);\n+    ds.setMaxActive(200);\n     ds.setMinIdle(10);\n     ds.setInitialSize(10);\n \n     // validate connection\n     ds.setValidationQuery(\"select 1 as dbcp_connection_test\");\n     ds.setTestWhileIdle(true);\n-    ds.setTestOnReturn(true);\n     ds.setTestOnBorrow(true);\n \n+    // when returning connection to pool\n+    ds.setTestOnReturn(true);\n+    ds.setRollbackOnReturn(true);\n+\n     // Timeout in seconds before an abandoned(in use) connection can be removed.\n-    ds.setRemoveAbandonedTimeout(15 * 60);\n+    ds.setRemoveAbandonedTimeout(600);\n     ds.setRemoveAbandoned(true);\n \n     properties.put(Environment.CONNECTION_PROVIDER, DatasourceConnectionProviderImpl.class.getName());",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/common/persistence/PersistenceUtil.java",
                "sha": "c018b746f8be2532a8e496f816a8a7e1f16fbcaa",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/dashboard/resources/DashboardResource.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/dashboard/resources/DashboardResource.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/dashboard/resources/DashboardResource.java",
                "patch": "@@ -326,7 +326,6 @@ public String getDashboardData(@QueryParam(\"dataset\") String collection,\n       LOG.error(\"Exception while processing /data/tabular call\", e);\n       return \"{\\\"ERROR\\\": + \" + e.getMessage() + \"}\";\n     }\n-\n   }\n \n   @GET",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/dashboard/resources/DashboardResource.java",
                "sha": "946d76538d29b5c28aecd72655d5a98e3d07a1af",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/db/dao/AnomalyTaskDAO.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/db/dao/AnomalyTaskDAO.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 5,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/db/dao/AnomalyTaskDAO.java",
                "patch": "@@ -17,8 +17,7 @@\n       + \"AND at.status != :status\";\n \n   private static final String FIND_BY_STATUS_ORDER_BY_CREATE_TIME_ASC = \"SELECT at FROM AnomalyTaskSpec at \"\n-      + \"WHERE at.status = :status \"\n-      + \"order by at.taskStartTime asc\";\n+      + \"WHERE at.status = :status order by at.taskStartTime asc\";\n \n   private static final String FIND_BY_STATUS_AND_LAST_MODIFIED_TIME_LT_EXPIRE = \"SELECT at FROM AnomalyTaskSpec at \"\n       + \"WHERE at.status = :status AND at.lastModified < :expireTimestamp\";\n@@ -35,10 +34,9 @@ public AnomalyTaskDAO() {\n   }\n \n   @Transactional\n-  public List<AnomalyTaskSpec> findByStatusOrderByCreateTimeAscending(TaskStatus status) {\n+  public List<AnomalyTaskSpec> findByStatusOrderByCreateTimeAsc(TaskStatus status, int fetchSize) {\n     return getEntityManager().createQuery(FIND_BY_STATUS_ORDER_BY_CREATE_TIME_ASC, entityClass)\n-            .setParameter(\"status\", status)\n-            .getResultList();\n+        .setMaxResults(fetchSize).setParameter(\"status\", status).getResultList();\n   }\n \n   @Transactional",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/db/dao/AnomalyTaskDAO.java",
                "sha": "b2623dd09672dbe31568fdd56918c92b97220e77",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/util/ThirdEyeUtils.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/util/ThirdEyeUtils.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 10,
                "filename": "thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/util/ThirdEyeUtils.java",
                "patch": "@@ -21,7 +21,6 @@\n import com.google.common.collect.Multimap;\n import com.linkedin.thirdeye.client.ThirdEyeCacheRegistry;\n import com.linkedin.thirdeye.dashboard.configs.CollectionConfig;\n-import com.linkedin.thirdeye.dashboard.resources.AnomalyResource;\n \n public class ThirdEyeUtils {\n   private static final Logger LOG = LoggerFactory.getLogger(ThirdEyeUtils.class);\n@@ -97,7 +96,6 @@ public static String getSortedFiltersFromMultiMap(Multimap<String, String> filte\n         sb.append(FILTER_CLAUSE_SEPARATOR);\n       }\n     }\n-\n     return StringUtils.chop(sb.toString());\n   }\n \n@@ -108,7 +106,6 @@ public static String getSortedFilters(String filters) {\n     if (StringUtils.isBlank(sortedFilters)) {\n       return null;\n     }\n-\n     return sortedFilters;\n   }\n \n@@ -119,7 +116,6 @@ public static String getSortedFiltersFromJson(String filterJson) {\n     if (StringUtils.isBlank(sortedFilters)) {\n       return null;\n     }\n-\n     return sortedFilters;\n   }\n \n@@ -151,7 +147,6 @@ public static String getAliasFromCollection(String collection) throws ExecutionE\n   }\n \n   public static String constructCron(String scheduleMinute, String scheduleHour, TimeUnit repeatEvery) {\n-\n     if (StringUtils.isNotBlank(scheduleMinute)\n         && (Integer.valueOf(scheduleMinute) < 0 || Integer.valueOf(scheduleMinute) > 59)) {\n       throw new IllegalArgumentException(\"scheduleMinute \" + scheduleMinute + \" must be between [0,60)\");\n@@ -162,17 +157,13 @@ public static String constructCron(String scheduleMinute, String scheduleHour, T\n     }\n     String minute = \"0\";\n     String hour = \"0\";\n-    String cron = AnomalyResource.DEFAULT_CRON;\n     if (repeatEvery.equals(TimeUnit.DAYS)) {\n       minute = StringUtils.isEmpty(scheduleMinute) ? minute : scheduleMinute;\n       hour = StringUtils.isEmpty(scheduleHour) ? hour : scheduleHour;\n     } else if (repeatEvery.equals(TimeUnit.HOURS)) {\n       minute = StringUtils.isEmpty(scheduleMinute) ? minute : scheduleMinute;\n       hour = \"*\";\n     }\n-    cron = String.format(\"0 %s %s * * ?\", minute, hour);\n-    return cron;\n+    return String.format(\"0 %s %s * * ?\", minute, hour);\n   }\n-\n-\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/main/java/com/linkedin/thirdeye/util/ThirdEyeUtils.java",
                "sha": "6e5ef65eb8a86209eb7352cffe965bed901d3bb3",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/test/java/com/linkedin/thirdeye/db/dao/TestAnomalyTaskDAO.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/thirdeye/thirdeye-pinot/src/test/java/com/linkedin/thirdeye/db/dao/TestAnomalyTaskDAO.java?ref=77726cb01d1d7ac596bccefb71bfeb8c5099b055",
                "deletions": 1,
                "filename": "thirdeye/thirdeye-pinot/src/test/java/com/linkedin/thirdeye/db/dao/TestAnomalyTaskDAO.java",
                "patch": "@@ -52,7 +52,8 @@ public void testUpdateStatusAndWorkerId() {\n \n   @Test(dependsOnMethods = {\"testUpdateStatusAndWorkerId\"})\n   public void testFindByStatusOrderByCreationTimeAsc() {\n-    List<AnomalyTaskSpec> anomalyTasks = anomalyTaskDAO.findByStatusOrderByCreateTimeAscending(TaskStatus.WAITING);\n+    List<AnomalyTaskSpec> anomalyTasks =\n+        anomalyTaskDAO.findByStatusOrderByCreateTimeAsc(TaskStatus.WAITING, Integer.MAX_VALUE);\n     Assert.assertEquals(anomalyTasks.size(), 1);\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/77726cb01d1d7ac596bccefb71bfeb8c5099b055/thirdeye/thirdeye-pinot/src/test/java/com/linkedin/thirdeye/db/dao/TestAnomalyTaskDAO.java",
                "sha": "d8e0ed0dce433df8ce93938c55ebf398e5ccc616",
                "status": "modified"
            }
        ],
        "message": "TE: adding improvements for task driver (#467)\n\n* TE: adding improvements for task driver\r\n\r\n* removing another NPE from DetectionTaskRunner\r\n\r\n* randomizing start time for task workers",
        "parent": "https://github.com/apache/incubator-pinot/commit/730dc153e62fdcabd61770f6f5f197364b8fd488",
        "patched_files": [
            "ThirdEyeAnomalyApplication.java",
            "DashboardResource.java",
            "JobRunner.java",
            "TaskDriver.java",
            "MonitorConstants.java",
            "DetectionTaskRunner.java",
            "PersistenceUtil.java",
            "MonitorJobRunner.java",
            "AnomalyTaskDAO.java",
            "ThirdEyeUtils.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "ThirdEyeUtilsTest.java",
            "TestAnomalyTaskDAO.java"
        ]
    },
    "incubator-pinot_7c70b57": {
        "bug_id": "incubator-pinot_7c70b57",
        "commit": "https://github.com/apache/incubator-pinot/commit/7c70b577a586c184d8cd635d2850c3946f1de149",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/7c70b577a586c184d8cd635d2850c3946f1de149/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/HelixBrokerStarter.java",
                "changes": 9,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/HelixBrokerStarter.java?ref=7c70b577a586c184d8cd635d2850c3946f1de149",
                "deletions": 2,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/HelixBrokerStarter.java",
                "patch": "@@ -145,8 +145,13 @@ private void addInstanceTagIfNeeded(String clusterName, String instanceName) {\n   }\n \n   private RoutingTableBuilder getRoutingTableBuilder(Configuration routingTableBuilderConfig) {\n-    String routingTableBuilderKey = routingTableBuilderConfig.getString(\"class\", null);\n-    RoutingTableBuilder routingTableBuilder = RoutingTableBuilderFactory.get(routingTableBuilderKey);\n+    RoutingTableBuilder routingTableBuilder;\n+    try {\n+      String routingTableBuilderKey = routingTableBuilderConfig.getString(\"class\", null);\n+      routingTableBuilder = RoutingTableBuilderFactory.get(routingTableBuilderKey);\n+    } catch (Exception e) {\n+      return null;\n+    }\n     if (routingTableBuilder == null) {\n       return null;\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/7c70b577a586c184d8cd635d2850c3946f1de149/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/HelixBrokerStarter.java",
                "sha": "5c0f87b8073950105f900eac8bb9db92f241a2e7",
                "status": "modified"
            }
        ],
        "message": "Fixing NPE in getting routing table builder\n\nRB=489957\nR=xiafu\nA=jfim",
        "parent": "https://github.com/apache/incubator-pinot/commit/a699a293905cbfff80a37b66d4949c2c838f660b",
        "patched_files": [
            "HelixBrokerStarter.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "HelixBrokerStarterTest.java"
        ]
    },
    "incubator-pinot_819d29b": {
        "bug_id": "incubator-pinot_819d29b",
        "commit": "https://github.com/apache/incubator-pinot/commit/819d29b6b4b1f546b53492dd5c0ca81b384acce4",
        "file": [
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/ControllerRestApplication.java",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/ControllerRestApplication.java?ref=819d29b6b4b1f546b53492dd5c0ca81b384acce4",
                "deletions": 16,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/ControllerRestApplication.java",
                "patch": "@@ -15,21 +15,6 @@\n  */\n package com.linkedin.pinot.controller.api;\n \n-import com.linkedin.pinot.controller.api.restlet.resources.TableViews;\n-import org.restlet.Context;\n-import org.restlet.Request;\n-import org.restlet.Response;\n-import org.restlet.Restlet;\n-import org.restlet.data.MediaType;\n-import org.restlet.representation.StringRepresentation;\n-import org.restlet.resource.Directory;\n-import org.restlet.resource.ServerResource;\n-import org.restlet.routing.Filter;\n-import org.restlet.routing.Redirector;\n-import org.restlet.routing.Router;\n-import org.restlet.routing.Template;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n import com.linkedin.pinot.common.metrics.ControllerMetrics;\n import com.linkedin.pinot.common.restlet.PinotRestletApplication;\n import com.linkedin.pinot.common.restlet.swagger.SwaggerResource;\n@@ -52,6 +37,21 @@\n import com.linkedin.pinot.controller.api.restlet.resources.PinotVersionRestletResource;\n import com.linkedin.pinot.controller.api.restlet.resources.PqlQueryResource;\n import com.linkedin.pinot.controller.api.restlet.resources.TableSize;\n+import com.linkedin.pinot.controller.api.restlet.resources.TableViews;\n+import org.restlet.Context;\n+import org.restlet.Request;\n+import org.restlet.Response;\n+import org.restlet.Restlet;\n+import org.restlet.data.MediaType;\n+import org.restlet.representation.StringRepresentation;\n+import org.restlet.resource.Directory;\n+import org.restlet.resource.ServerResource;\n+import org.restlet.routing.Filter;\n+import org.restlet.routing.Redirector;\n+import org.restlet.routing.Router;\n+import org.restlet.routing.Template;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n public class ControllerRestApplication extends PinotRestletApplication {\n   private static final Logger LOGGER = LoggerFactory.getLogger(ControllerRestApplication.class);\n@@ -94,7 +94,6 @@ protected void configureRouter(Router router) {\n     attachRoutesForClass(router, PinotTableSchema.class);\n     attachRoutesForClass(router, PinotSegmentRestletResource.class);\n     attachRoutesForClass(router, TableSize.class);\n-    attachRoutesForClass(router, TableViews.class);\n     // PUT\n     attachRoutesForClass(router, PinotTableSegmentConfigs.class);\n     attachRoutesForClass(router, PinotTableIndexingConfigs.class);\n@@ -110,6 +109,9 @@ protected void configureRouter(Router router) {\n     attachRoutesForClass(router, LLCSegmentCommit.class);\n     attachRoutesForClass(router, LLCSegmentConsumed.class);\n \n+    // GET... add it here because it can block visibility of\n+    // some of the existing paths (like indexingConfigs) added above\n+    attachRoutesForClass(router, TableViews.class);\n \n     router.attach(\"/api\", SwaggerResource.class);\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/ControllerRestApplication.java",
                "sha": "b9b5ec86de771ff65790c3418dc96de4a26a1346",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableIndexingConfigs.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableIndexingConfigs.java?ref=819d29b6b4b1f546b53492dd5c0ca81b384acce4",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableIndexingConfigs.java",
                "patch": "@@ -48,7 +48,10 @@ public Representation put(Representation entity) {\n       setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n       return new StringRepresentation(error);\n     }\n-\n+    if (entity == null) {\n+      setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n+      return new StringRepresentation(\"{\\\"error\\\" : \\\"Request body is required\\\"}\");\n+    }\n     try {\n       return updateIndexingConfig(tableName, entity);\n     } catch (final Exception e) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableIndexingConfigs.java",
                "sha": "4b60e41e80340cac13582ae4d6070267e7e15dd0",
                "status": "modified"
            },
            {
                "additions": 36,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/TableViews.java",
                "changes": 49,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/TableViews.java?ref=819d29b6b4b1f546b53492dd5c0ca81b384acce4",
                "deletions": 13,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/TableViews.java",
                "patch": "@@ -42,12 +42,25 @@\n \n public class TableViews extends BasePinotControllerRestletResource {\n   private static final Logger LOGGER = LoggerFactory.getLogger(TableViews.class);\n+  public static final String IDEALSTATE = \"idealstate\";\n+  public static final String EXTERNALVIEW = \"externalview\";\n \n   @Get\n   @Override\n   public Representation get() {\n     final String tableName = (String) getRequest().getAttributes().get(\"tableName\");\n-    final String view = (String) getRequest().getAttributes().get(\"view\");\n+    final int viewPositon = 3;\n+\n+    String[] path = getReference().getPath().split(\"/\");\n+    // first part is \"\" because paths start with /\n+    if (path.length < (viewPositon + 1) ||\n+        (!path[viewPositon].equalsIgnoreCase(EXTERNALVIEW) && !path[viewPositon].equalsIgnoreCase(IDEALSTATE))) {\n+      // this is unexpected condition\n+      LOGGER.error(\"Invalid path: {} while reading views\", path);\n+      return responseRepresentation(Status.SERVER_ERROR_INTERNAL, \"{\\\"error\\\":\\\"Invalid reqeust path\\\"\");\n+    }\n+\n+    final String view = path[viewPositon];\n     String tableTypeStr = getQuery().getValues(\"tableType\");\n \n     if (tableTypeStr == null) {\n@@ -83,21 +96,14 @@ public Representation get() {\n \n   // we use name \"view\" to closely match underlying names and to not\n   // confuse with table state of enable/disable\n-  @HttpVerb(\"get\")\n-  @Summary(\"Get table idealstate or external view\")\n-  @Tags({\"table\"})\n-  @Paths({\"/tables/{tableName}/{view}\"})\n   private Representation getTableState(\n-      @Parameter(name = \"tableName\", in = \"path\", description = \"Table name(without type)\", required = true)\n       String tableName,\n-      @Parameter(name=\"view\", in = \"path\", description = \"Table idealstate or external view\", required = true)\n       String view,\n-      @Parameter(name = \"tableType\", in=\"query\", description = \"Table type\", required = false)\n       TableType tableType) {\n     TableView tableView;\n-    if (view.equalsIgnoreCase(\"idealstate\")) {\n+    if (view.equalsIgnoreCase(IDEALSTATE)) {\n       tableView = getTableIdealState(tableName, tableType);\n-    } else if (view.equalsIgnoreCase(\"externalview\")) {\n+    } else if (view.equalsIgnoreCase(EXTERNALVIEW)) {\n       tableView = getTableExternalView(tableName, tableType);\n     } else {\n       return responseRepresentation(Status.CLIENT_ERROR_BAD_REQUEST,\n@@ -119,7 +125,15 @@ private Representation getTableState(\n     }\n   }\n \n-  private TableView getTableExternalView(@Nonnull String tableNameOptType, @Nullable TableType tableType) {\n+  @HttpVerb(\"get\")\n+  @Summary(\"Get table external view\")\n+  @Tags({\"table\"})\n+  @Paths({\"/tables/{tableName}/externalview\"})\n+  private TableView getTableExternalView(\n+      @Parameter(name = \"tableName\", in = \"path\", description = \"Table name(without type)\", required = true)\n+      @Nonnull String tableNameOptType,\n+      @Parameter(name = \"tableType\", in=\"query\", description = \"Table type\", required = false)\n+      @Nullable TableType tableType) {\n     TableView tableView = new TableView();\n     if (tableType == null || tableType == TableType.OFFLINE) {\n       tableView.offline = getExternalView(tableNameOptType, TableType.OFFLINE);\n@@ -130,7 +144,15 @@ private TableView getTableExternalView(@Nonnull String tableNameOptType, @Nullab\n     return tableView;\n   }\n \n-  private TableView getTableIdealState(String tableNameOptType, TableType tableType) {\n+  @HttpVerb(\"get\")\n+  @Summary(\"Get table idealstate\")\n+  @Tags({\"table\"})\n+  @Paths({\"/tables/{tableName}/idealstate\"})\n+  private TableView getTableIdealState(\n+      @Parameter(name = \"tableName\", in = \"path\", description = \"Table name(without type)\", required = true)\n+      String tableNameOptType,\n+      @Parameter(name = \"tableType\", in=\"query\", description = \"Table type\", required = false)\n+      TableType tableType) {\n     TableView tableView = new TableView();\n     if (tableType == null || tableType == TableType.OFFLINE) {\n       tableView.offline = getIdealState(tableNameOptType, TableType.OFFLINE);\n@@ -142,7 +164,8 @@ private TableView getTableIdealState(String tableNameOptType, TableType tableTyp\n   }\n \n   public @Nullable\n-  Map<String, Map<String, String>> getIdealState(@Nonnull String tableNameOptType, @Nullable TableType tableType) {\n+  Map<String, Map<String, String>> getIdealState(@Nonnull String tableNameOptType,\n+      @Parameter(name = \"tableType\", in=\"query\", description = \"Table type\", required = false)@Nullable TableType tableType) {\n     String tableName = getTableName(tableNameOptType, tableType);\n     IdealState resourceIdealState = _pinotHelixResourceManager.getHelixAdmin()\n         .getResourceIdealState(_pinotHelixResourceManager.getHelixClusterName(), tableName);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/TableViews.java",
                "sha": "f791ffa486a589e93bcd0a38e56d6115015b075d",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/restlet/resources/TableViewsTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/restlet/resources/TableViewsTest.java?ref=819d29b6b4b1f546b53492dd5c0ca81b384acce4",
                "deletions": 2,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/api/restlet/resources/TableViewsTest.java",
                "patch": "@@ -111,8 +111,8 @@ public void teardownTest()\n   @DataProvider(name = \"stateProvider\")\n   public Object[][] stateProvider() {\n     Object[][] configs = {\n-        { \"idealstate\"},\n-        { \"externalview\"}\n+        {TableViews.IDEALSTATE},\n+        {TableViews.EXTERNALVIEW}\n     };\n     return configs;\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/819d29b6b4b1f546b53492dd5c0ca81b384acce4/pinot-controller/src/test/java/com/linkedin/pinot/controller/api/restlet/resources/TableViewsTest.java",
                "sha": "cf606dbb90e686ca9bb9093a2cb9cc43a40e4992",
                "status": "modified"
            }
        ],
        "message": "Reorder addition of pinot table views API (#835)\n\n* Reorder addition of pinot table views API\r\n\r\nMove addition of pinot tables views below the existing list.\r\nKeeping it clustered with other GET calls hides existing paths.\r\n\r\nTesting: manual\r\n\r\n* Gracefully handle missing request body on updating controller index\r\n\r\nReturn bad request error if the request to update indexing config is\r\nmissing request body instead of failing with NPE.",
        "parent": "https://github.com/apache/incubator-pinot/commit/1e906370c878f60d94ac301a30ba13537b6a483e",
        "patched_files": [
            "ControllerRestApplication.java",
            "PinotTableIndexingConfigs.java",
            "TableViews.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TableViewsTest.java"
        ]
    },
    "incubator-pinot_83b3512": {
        "bug_id": "incubator-pinot_83b3512",
        "commit": "https://github.com/apache/incubator-pinot/commit/83b3512def190c49233a14280e5c178169ff155f",
        "file": [
            {
                "additions": 50,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/segment/SegmentMetadata.java",
                "changes": 150,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/segment/SegmentMetadata.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 100,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/segment/SegmentMetadata.java",
                "patch": "@@ -15,158 +15,108 @@\n  */\n package com.linkedin.pinot.common.segment;\n \n-import java.io.File;\n+import com.linkedin.pinot.common.data.MetricFieldSpec;\n+import com.linkedin.pinot.common.data.Schema;\n import java.util.Map;\n-\n import javax.annotation.Nullable;\n import org.joda.time.Duration;\n import org.joda.time.Interval;\n \n-import com.linkedin.pinot.common.data.Schema;\n-\n \n /**\n- * SegmentMetadata holds segment level management information and data\n- * statistics.\n+ * The <code>SegmentMetadata</code> class holds the segment level management information and data statistics.\n  */\n public interface SegmentMetadata {\n-  /**\n-   * @return\n-   */\n-  public String getTableName();\n \n-  /**\n-   * @return\n-   */\n-  public String getIndexType();\n+  String getTableName();\n \n-  /**\n-   * @return\n-   */\n-  public Duration getTimeGranularity();\n+  String getIndexType();\n \n-  /**\n-   * @return\n-   */\n-  public Interval getTimeInterval();\n+  Duration getTimeGranularity();\n \n-  /**\n-   * @return\n-   */\n-  public String getCrc();\n+  Interval getTimeInterval();\n \n-  /**\n-   * @return\n-   */\n-  public String getVersion();\n+  String getCrc();\n \n-  /**\n-   * @return\n-   */\n-  public Schema getSchema();\n+  String getVersion();\n \n-  /**\n-   * @return\n-   */\n-  public String getShardingKey();\n+  Schema getSchema();\n \n-  /**\n-   * @return\n-   */\n-  public int getTotalDocs();\n+  String getShardingKey();\n+\n+  int getTotalDocs();\n \n-  /**\n-   *\n-   * @return\n-   */\n   int getTotalRawDocs();\n \n-  /**\n-   * @return\n-   */\n-  public String getIndexDir();\n+  String getIndexDir();\n \n-  /**\n-   * @return\n-   */\n-  public String getName();\n+  String getName();\n \n-  /**\n-   * @return\n-   */\n-  public long getIndexCreationTime();\n+  long getIndexCreationTime();\n \n   /**\n-   * Returns the last time that this segment was pushed or Long.MIN_VALUE if it has never been\n-   * pushed.\n+   * Get the last time that this segment was pushed or <code>Long.MIN_VALUE</code> if it has never been pushed.\n    */\n-  public long getPushTime();\n+  long getPushTime();\n \n   /**\n-   * Returns the last time that this segment was refreshed or Long.MIN_VALUE if it has never been\n-   * refreshed.\n+   * Get the last time that this segment was refreshed or <code>Long.MIN_VALUE</code> if it has never been refreshed.\n    */\n-  public long getRefreshTime();\n+  long getRefreshTime();\n \n-  /**\n-   * Returns if a column has dictionary or not.\n-   */\n-  public boolean hasDictionary(String columnName);\n+  boolean hasDictionary(String columnName);\n \n-  /** Returns true if the segment has a StarTree index defined */\n-  public boolean hasStarTree();\n+  boolean hasStarTree();\n \n-  /**\n-   * Returns the StarTreeMetadata for the segment\n-   * @return\n-   */\n-  public StarTreeMetadata getStarTreeMetadata();\n+  @Nullable\n+  StarTreeMetadata getStarTreeMetadata();\n \n   /**\n-   * returns the forward Index file name with appropriate extension for a given version\n-   * @param column\n-   * @return\n+   * Get the forward index file name with appropriate extension for a given version.\n+   *\n+   * @param column column name.\n+   * @param segmentVersion segment version.\n+   * @return forward index file name.\n    */\n   String getForwardIndexFileName(String column, String segmentVersion);\n \n   /**\n-   * returns the dictionary file name with appropriate extension for a given version\n-   * @param column\n-   * @return\n+   * Get the dictionary file name with appropriate extension for a given version.\n+   *\n+   * @param column column name.\n+   * @param segmentVersion segment version.\n+   * @return dictionary file name.\n    */\n   String getDictionaryFileName(String column, String segmentVersion);\n \n   /**\n-   * returns the bitmap inverted index file name with appropriate extension for a given version\n-   * @param column\n-   * @return\n+   * Get the bitmap inverted index file name with appropriate extension for a given version.\n+   *\n+   * @param column column name.\n+   * @param segmentVersion segment version.\n+   * @return bitmap inverted index file name.\n    */\n   String getBitmapInvertedIndexFileName(String column, String segmentVersion);\n \n-  /**\n-   * returns the name of the component that created the segment\n-   * @return\n-   */\n   @Nullable\n   String getCreatorName();\n \n-  /**\n-   * returns the padding character\n-   * @return\n-   */\n-  Character getPaddingCharacter();\n+  char getPaddingCharacter();\n \n-  /**\n-   * returns Hll Log2m parameter\n-   * @return\n-   */\n   int getHllLog2m();\n \n   /**\n-   * @return\n+   * Get the derived column name for the given original column and derived metric type.\n+   *\n+   * @param column original column name.\n+   * @param derivedMetricType derived metric type.\n+   * @return derived column name if exists.\n+   *         null if not.\n    */\n-  public Map<String, String> toMap();\n+  @Nullable\n+  String getDerivedColumn(String column, MetricFieldSpec.DerivedMetricType derivedMetricType);\n \n-  public boolean close();\n+  Map<String, String> toMap();\n \n+  boolean close();\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/segment/SegmentMetadata.java",
                "sha": "120b5b0c250ac3b0c7c1341f7bdc2dac1a60b1d4",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/segment/StarTreeMetadata.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/segment/StarTreeMetadata.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 13,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/segment/StarTreeMetadata.java",
                "patch": "@@ -16,8 +16,6 @@\n package com.linkedin.pinot.common.segment;\n \n import java.util.List;\n-import java.util.Map;\n-import javax.annotation.Nullable;\n \n \n /**\n@@ -32,8 +30,6 @@\n   private long _maxLeafRecords;\n   private long _skipMaterializationCardinality;\n \n-  private Map<String, String> _hllOriginToDerivedColumnMap;\n-\n   public StarTreeMetadata() {\n   }\n \n@@ -76,13 +72,4 @@ public void setSkipMaterializationCardinality(Long skipMaterializationCardinalit\n   public void setSkipMaterializationForDimensions(List<String> skipMaterializationForDimensions) {\n     _skipMaterializationForDimensions = skipMaterializationForDimensions;\n   }\n-\n-  @Nullable\n-  public String getDerivedHllColumnFromOrigin(String originColumn) {\n-    return _hllOriginToDerivedColumnMap.get(originColumn);\n-  }\n-\n-  public void setHllOriginToDerivedColumnMap(Map<String, String> hllOriginToDerivedColumnMap) {\n-    _hllOriginToDerivedColumnMap = hllOriginToDerivedColumnMap;\n-  }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/segment/StarTreeMetadata.java",
                "sha": "36cdb1d1193a49118049a03b62157c9f284acaf1",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "changes": 44,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 42,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.common.utils.request;\n \n-import com.google.common.base.Preconditions;\n import com.google.common.collect.ImmutableSet;\n import com.linkedin.pinot.common.request.AggregationInfo;\n import com.linkedin.pinot.common.request.BrokerRequest;\n@@ -31,14 +30,14 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import javax.annotation.Nullable;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n \n public class RequestUtils {\n+  private RequestUtils() {\n+  }\n \n-  private static final Logger LOGGER = LoggerFactory.getLogger(RequestUtils.class);\n   private static final String USE_STAR_TREE_KEY = \"useStarTree\";\n \n   /**\n@@ -220,45 +219,6 @@ public static boolean isFitForStarTreeIndex(SegmentMetadata segmentMetadata, Fil\n     return true;\n   }\n \n-  /**\n-   * Must be called after a successful check of {@link #isFitForStarTreeIndex}\n-   * @return true if no fasthll aggregation or rewriting successful, false otherwise\n-   */\n-  public static boolean performFastHllRewriting(SegmentMetadata segmentMetadata, BrokerRequest brokerRequest) {\n-    List<AggregationInfo> aggregationsInfo = brokerRequest.getAggregationsInfo();\n-    StarTreeMetadata starTreeMetadata = segmentMetadata.getStarTreeMetadata();\n-    Map<AggregationInfo, String> fastHllAggregationInfoToDerivedColumnNameMap = new HashMap<>();\n-    // Check if all fasthll derived columns exist\n-    for (AggregationInfo aggregationInfo : aggregationsInfo) {\n-      if (aggregationInfo.getAggregationType().toLowerCase().equals(\"fasthll\")) {\n-        String derivedColumn = extractDerivedColumn(aggregationInfo, starTreeMetadata);\n-        if (derivedColumn == null) {\n-          // If derivedColumn does not exist, which means we need to aggregate directly on original column,\n-          // in that case, star tree can not be used since no generated star tree docs are available.\n-          return false;\n-        } else {\n-          fastHllAggregationInfoToDerivedColumnNameMap.put(aggregationInfo, derivedColumn);\n-        }\n-      }\n-    }\n-    // Rewrite all fasthll derived columns\n-    for (AggregationInfo aggregationInfo : fastHllAggregationInfoToDerivedColumnNameMap.keySet()) {\n-      String derivedColumn = fastHllAggregationInfoToDerivedColumnNameMap.get(aggregationInfo);\n-      LOGGER.info(\"Performed rewriting to fasthll({})\", derivedColumn);\n-      aggregationInfo.getAggregationParams().put(\"column\", derivedColumn);\n-    }\n-    return true;\n-  }\n-\n-  @Nullable\n-  private static String extractDerivedColumn(AggregationInfo aggregationInfo, StarTreeMetadata starTreeMetadata) {\n-    String[] columns = aggregationInfo.getAggregationParams().get(\"column\").trim().split(\",\");\n-    Preconditions.checkArgument(columns.length == 1);\n-    String aggrColumn = columns[0];\n-    return starTreeMetadata.getDerivedHllColumnFromOrigin(aggrColumn);\n-  }\n-\n-\n   /**\n    * This method returns the value of {@link #USE_STAR_TREE_KEY} boolean flag specified in the debug options\n    * in broker request. If the flag is not specified in the debug options, it returns true.",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "sha": "0d46df09e1f7fe8c6235e3432884003461c31459",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/retention/RetentionManagerTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/retention/RetentionManagerTest.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 2,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/retention/RetentionManagerTest.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.controller.helix.retention;\n \n+import com.linkedin.pinot.common.data.MetricFieldSpec;\n import com.linkedin.pinot.core.startree.hll.HllConstants;\n import java.io.File;\n import java.io.IOException;\n@@ -452,12 +453,14 @@ public String getBitmapInvertedIndexFileName(String column, String segmentVersio\n         throw new UnsupportedOperationException(\"getBitmapInvertedIndexFileName not supported in \" + this.getClass());\n       }\n \n-      @Nullable @Override public String getCreatorName() {\n+      @Nullable\n+      @Override\n+      public String getCreatorName() {\n         return null;\n       }\n \n       @Override\n-      public Character getPaddingCharacter() {\n+      public char getPaddingCharacter() {\n         return V1Constants.Str.DEFAULT_STRING_PAD_CHAR;\n       }\n \n@@ -466,6 +469,11 @@ public int getHllLog2m() {\n         return HllConstants.DEFAULT_LOG2M;\n       }\n \n+      @Nullable\n+      @Override\n+      public String getDerivedColumn(String column, MetricFieldSpec.DerivedMetricType derivedMetricType) {\n+        return null;\n+      }\n     };\n     return segmentMetadata;\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/retention/RetentionManagerTest.java",
                "sha": "fcf74592a23fdf8be8ad8c20d7e1b9cdde2105b9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-controller/src/test/java/com/linkedin/pinot/controller/validation/ValidationManagerTest.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/validation/ValidationManagerTest.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 2,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/validation/ValidationManagerTest.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.controller.validation;\n \n+import com.linkedin.pinot.common.data.MetricFieldSpec;\n import com.linkedin.pinot.common.metrics.ControllerMetrics;\n import com.yammer.metrics.core.MetricsRegistry;\n import java.util.ArrayList;\n@@ -541,6 +542,7 @@ public boolean hasStarTree() {\n       return false;\n     }\n \n+    @Nullable\n     @Override\n     public StarTreeMetadata getStarTreeMetadata() {\n       return null;\n@@ -564,18 +566,26 @@ public String getBitmapInvertedIndexFileName(String column, String segmentVersio\n       return null;\n     }\n \n-    @Nullable @Override public String getCreatorName() {\n+    @Nullable\n+    @Override\n+    public String getCreatorName() {\n       return null;\n     }\n \n     @Override\n-    public Character getPaddingCharacter() {\n+    public char getPaddingCharacter() {\n       return V1Constants.Str.DEFAULT_STRING_PAD_CHAR;\n     }\n \n     @Override\n     public int getHllLog2m() {\n       return HllConstants.DEFAULT_LOG2M;\n     }\n+\n+    @Nullable\n+    @Override\n+    public String getDerivedColumn(String column, MetricFieldSpec.DerivedMetricType derivedMetricType) {\n+      return null;\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-controller/src/test/java/com/linkedin/pinot/controller/validation/ValidationManagerTest.java",
                "sha": "976325577260f90e2ba30beb3f2ace1abfb622b9",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationGroupByPlanNode.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationGroupByPlanNode.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationGroupByPlanNode.java",
                "patch": "@@ -61,9 +61,6 @@ public AggregationGroupByPlanNode(IndexSegment indexSegment, BrokerRequest broke\n       }\n       String columns = aggregationInfo.getAggregationParams().get(\"column\").trim();\n       aggregationGroupByRelatedColumns.addAll(Arrays.asList(columns.split(\",\")));\n-      if (aggregationInfo.getAggregationType().equalsIgnoreCase(\"fasthll\")) {\n-        aggregationGroupByRelatedColumns.add(columns + HllConstants.DEFAULT_HLL_DERIVE_COLUMN_SUFFIX);\n-      }\n     }\n     aggregationGroupByRelatedColumns.addAll(_groupBy.getColumns());\n     return aggregationGroupByRelatedColumns.toArray(new String[aggregationGroupByRelatedColumns.size()]);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationGroupByPlanNode.java",
                "sha": "e1007349436fd2e2178799bb94d39369f9101e77",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationPlanNode.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationPlanNode.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationPlanNode.java",
                "patch": "@@ -58,9 +58,6 @@ public AggregationPlanNode(IndexSegment indexSegment, BrokerRequest brokerReques\n       if (!aggregationInfo.getAggregationType().equalsIgnoreCase(\"count\")) {\n         String columns = aggregationInfo.getAggregationParams().get(\"column\").trim();\n         aggregationRelatedColumns.addAll(Arrays.asList(columns.split(\",\")));\n-        if (aggregationInfo.getAggregationType().equalsIgnoreCase(\"fasthll\")) {\n-          aggregationRelatedColumns.add(columns + HllConstants.DEFAULT_HLL_DERIVE_COLUMN_SUFFIX);\n-        }\n       }\n     }\n     return aggregationRelatedColumns.toArray(new String[aggregationRelatedColumns.size()]);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/AggregationPlanNode.java",
                "sha": "39e13bad5d8c5a4460509d0d66257bbd4476af87",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/FilterPlanNode.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/plan/FilterPlanNode.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/plan/FilterPlanNode.java",
                "patch": "@@ -63,9 +63,8 @@ public Operator run() {\n     long start = System.currentTimeMillis();\n     Operator operator;\n     FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(_brokerRequest);\n-    if (_segment.getSegmentMetadata().hasStarTree() &&\n-        RequestUtils.isFitForStarTreeIndex(_segment.getSegmentMetadata(), filterQueryTree, _brokerRequest) &&\n-        RequestUtils.performFastHllRewriting(_segment.getSegmentMetadata(), _brokerRequest)) {\n+    if (_segment.getSegmentMetadata().hasStarTree()\n+        && RequestUtils.isFitForStarTreeIndex(_segment.getSegmentMetadata(), filterQueryTree, _brokerRequest)) {\n       operator = new StarTreeIndexOperator(_segment, _brokerRequest);\n     } else {\n       operator = constructPhysicalOperator(filterQueryTree);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/FilterPlanNode.java",
                "sha": "476ddcc91cf2819fb72a8997cc806749fef40723",
                "status": "modified"
            },
            {
                "additions": 93,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/BrokerRequestPreProcessor.java",
                "changes": 93,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/BrokerRequestPreProcessor.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/BrokerRequestPreProcessor.java",
                "patch": "@@ -0,0 +1,93 @@\n+/**\n+ * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.linkedin.pinot.core.plan.maker;\n+\n+import com.linkedin.pinot.common.data.MetricFieldSpec;\n+import com.linkedin.pinot.common.request.AggregationInfo;\n+import com.linkedin.pinot.common.request.BrokerRequest;\n+import com.linkedin.pinot.common.segment.SegmentMetadata;\n+import com.linkedin.pinot.core.indexsegment.IndexSegment;\n+import java.util.List;\n+import java.util.Objects;\n+\n+\n+/**\n+ * The <code>BrokerRequestPreProcessor</code> class provides the utility to pre-process the {@link BrokerRequest}.\n+ * <p>After the pre-process, the {@link BrokerRequest} should not be further changed.\n+ */\n+public class BrokerRequestPreProcessor {\n+  private BrokerRequestPreProcessor() {\n+  }\n+\n+  /**\n+   * Pre-process the {@link BrokerRequest}.\n+   * <p>Will apply the changes directly to the passed in object.\n+   * <p>The following steps are performed:\n+   * <ul>\n+   *   <li>Rewrite 'fasthll' column name.</li>\n+   * </ul>\n+   *\n+   * @param indexSegments list of index segments.\n+   * @param brokerRequest broker request.\n+   */\n+  public static void preProcess(List<IndexSegment> indexSegments, BrokerRequest brokerRequest) {\n+    if (brokerRequest.isSetAggregationsInfo()) {\n+      List<AggregationInfo> aggregationsInfo = brokerRequest.getAggregationsInfo();\n+      rewriteFastHllColumnName(indexSegments, aggregationsInfo);\n+    }\n+  }\n+\n+  /**\n+   * Rewrite 'fasthll' column name.\n+   *\n+   * @param indexSegments list of index segments.\n+   * @param aggregationsInfo list of aggregation info.\n+   */\n+  private static void rewriteFastHllColumnName(List<IndexSegment> indexSegments,\n+      List<AggregationInfo> aggregationsInfo) {\n+    // Consistent check.\n+    for (AggregationInfo aggregationInfo : aggregationsInfo) {\n+      if (aggregationInfo.getAggregationType().equalsIgnoreCase(\"fasthll\")) {\n+        String column = aggregationInfo.getAggregationParams().get(\"column\").trim();\n+        boolean isFirstSegment = true;\n+        String firstSegmentName = null;\n+        String hllDerivedColumn = null;\n+        for (IndexSegment indexSegment : indexSegments) {\n+          SegmentMetadata segmentMetadata = indexSegment.getSegmentMetadata();\n+          if (isFirstSegment) {\n+            // Use metadata from first index segment to perform rewrite.\n+            isFirstSegment = false;\n+            firstSegmentName = segmentMetadata.getName();\n+            hllDerivedColumn = segmentMetadata.getDerivedColumn(column, MetricFieldSpec.DerivedMetricType.HLL);\n+            if (hllDerivedColumn != null) {\n+              aggregationInfo.getAggregationParams().put(\"column\", hllDerivedColumn);\n+            }\n+          } else {\n+            // Perform consistency check on other index segments.\n+            String hllDerivedColumnToCheck =\n+                segmentMetadata.getDerivedColumn(column, MetricFieldSpec.DerivedMetricType.HLL);\n+            if (!Objects.equals(hllDerivedColumn, hllDerivedColumnToCheck)) {\n+              throw new RuntimeException(\n+                  \"Found inconsistency HLL derived column name. In segment \" + firstSegmentName + \": \"\n+                      + hllDerivedColumn + \"; In segment \" + segmentMetadata.getName() + \": \"\n+                      + hllDerivedColumnToCheck);\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+}",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/BrokerRequestPreProcessor.java",
                "sha": "f4b4035f1a4c1df9aec2e70998c763f2ee25b63b",
                "status": "added"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/InstancePlanMakerImplV2.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/InstancePlanMakerImplV2.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/InstancePlanMakerImplV2.java",
                "patch": "@@ -92,12 +92,19 @@ public PlanNode makeInnerSegmentPlan(IndexSegment indexSegment, BrokerRequest br\n   @Override\n   public Plan makeInterSegmentPlan(List<SegmentDataManager> segmentDataManagers, BrokerRequest brokerRequest,\n       ExecutorService executorService, long timeOutMs) {\n-    List<PlanNode> planNodes = new ArrayList<>();\n+    // TODO: pass in List<IndexSegment> directly.\n+    List<IndexSegment> indexSegments = new ArrayList<>(segmentDataManagers.size());\n     for (SegmentDataManager segmentDataManager : segmentDataManagers) {\n-      IndexSegment indexSegment = segmentDataManager.getSegment();\n+      indexSegments.add(segmentDataManager.getSegment());\n+    }\n+    BrokerRequestPreProcessor.preProcess(indexSegments, brokerRequest);\n+\n+    List<PlanNode> planNodes = new ArrayList<>();\n+    for (IndexSegment indexSegment : indexSegments) {\n       planNodes.add(makeInnerSegmentPlan(indexSegment, brokerRequest));\n     }\n     CombinePlanNode combinePlanNode = new CombinePlanNode(planNodes, brokerRequest, executorService, timeOutMs);\n+\n     return new GlobalPlanImplV0(new InstanceResponsePlanNode(combinePlanNode));\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/plan/maker/InstancePlanMakerImplV2.java",
                "sha": "9f1ad6d82499979dea5a0180112c979e949b85a9",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/query/utils/SimpleSegmentMetadata.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/utils/SimpleSegmentMetadata.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/utils/SimpleSegmentMetadata.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.query.utils;\n \n+import com.linkedin.pinot.common.data.MetricFieldSpec;\n import com.linkedin.pinot.common.segment.StarTreeMetadata;\n import com.linkedin.pinot.core.segment.creator.impl.V1Constants;\n import com.linkedin.pinot.core.startree.hll.HllConstants;\n@@ -172,6 +173,7 @@ public boolean hasStarTree() {\n     return false;\n   }\n \n+  @Nullable\n   @Override\n   public StarTreeMetadata getStarTreeMetadata() {\n     return null;\n@@ -195,11 +197,14 @@ public String getBitmapInvertedIndexFileName(String column, String segmentVersio\n     return null;\n   }\n \n-  @Nullable @Override public String getCreatorName() {\n+  @Nullable\n+  @Override\n+  public String getCreatorName() {\n     return null;\n   }\n \n-  @Override public Character getPaddingCharacter() {\n+  @Override\n+  public char getPaddingCharacter() {\n     return _paddingCharacter;\n   }\n \n@@ -208,4 +213,9 @@ public int getHllLog2m() {\n     return HllConstants.DEFAULT_LOG2M;\n   }\n \n+  @Nullable\n+  @Override\n+  public String getDerivedColumn(String column, MetricFieldSpec.DerivedMetricType derivedMetricType) {\n+    return null;\n+  }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/query/utils/SimpleSegmentMetadata.java",
                "sha": "efb66f202813d196be0d9666cf35f400daadd1f9",
                "status": "modified"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "changes": 68,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java?ref=83b3512def190c49233a14280e5c178169ff155f",
                "deletions": 35,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "patch": "@@ -85,6 +85,7 @@\n   private String _creatorName;\n   private char _paddingCharacter = V1Constants.Str.DEFAULT_STRING_PAD_CHAR;\n   private int _hllLog2m = HllConstants.DEFAULT_LOG2M;\n+  private final Map<String, String> _hllDerivedColumnMap = new HashMap<>();\n \n   public SegmentMetadataImpl(File indexDir) throws ConfigurationException, IOException {\n     LOGGER.debug(\"SegmentMetadata location: {}\", indexDir);\n@@ -284,28 +285,27 @@ private void init() {\n       }\n     }\n \n-    // Column Metadata\n-    for (final String column : _allColumns) {\n-      _columnMetadataMap.put(column,\n-          ColumnMetadata.fromPropertiesConfiguration(column, _segmentMetadataPropertiesConfiguration));\n-    }\n-\n-    // Segment Name\n+    // Set segment name.\n     _segmentName = _segmentMetadataPropertiesConfiguration.getString(Segment.SEGMENT_NAME);\n \n-    // Set hll log2m\n+    // Set hll log2m.\n     _hllLog2m = _segmentMetadataPropertiesConfiguration.getInt(Segment.SEGMENT_HLL_LOG2M, HllConstants.DEFAULT_LOG2M);\n \n-    // StarTree config here\n-    _hasStarTree = _segmentMetadataPropertiesConfiguration.getBoolean(\n-        MetadataKeys.StarTree.STAR_TREE_ENABLED, false);\n-    if (_hasStarTree) {\n-      initStarTreeMetadata();\n+    // Build column metadata map, schema and hll derived column map.\n+    for (String column : _allColumns) {\n+      ColumnMetadata columnMetadata =\n+          ColumnMetadata.fromPropertiesConfiguration(column, _segmentMetadataPropertiesConfiguration);\n+      _columnMetadataMap.put(column, columnMetadata);\n+      _schema.addField(columnMetadata.getFieldSpec());\n+      if (columnMetadata.getDerivedMetricType() == MetricFieldSpec.DerivedMetricType.HLL) {\n+        _hllDerivedColumnMap.put(columnMetadata.getOriginColumnName(), columnMetadata.getColumnName());\n+      }\n     }\n \n-    // Build Schema\n-    for (final String column : _columnMetadataMap.keySet()) {\n-      _schema.addField(_columnMetadataMap.get(column).getFieldSpec());\n+    // Build star-tree metadata.\n+    _hasStarTree = _segmentMetadataPropertiesConfiguration.getBoolean(MetadataKeys.StarTree.STAR_TREE_ENABLED, false);\n+    if (_hasStarTree) {\n+      initStarTreeMetadata();\n     }\n   }\n \n@@ -315,23 +315,6 @@ private void init() {\n   private void initStarTreeMetadata() {\n     _starTreeMetadata = new StarTreeMetadata();\n \n-    // Build Derived Column Map\n-    Map<String, String> hllOriginToDerivedColumnMap = new HashMap<>();\n-    for (final ColumnMetadata columnMetadata : _columnMetadataMap.values()) {\n-      MetricFieldSpec.DerivedMetricType derivedMetricType = columnMetadata.getDerivedMetricType();\n-      if (derivedMetricType != null) {\n-        switch (derivedMetricType) {\n-          case HLL:\n-            hllOriginToDerivedColumnMap.put(columnMetadata.getOriginColumnName(), columnMetadata.getColumnName());\n-            break;\n-          default:\n-            throw new IllegalArgumentException(\n-                columnMetadata.getDerivedMetricType() + \" type is not supported in building derived columns.\");\n-        }\n-      }\n-    }\n-    _starTreeMetadata.setHllOriginToDerivedColumnMap(hllOriginToDerivedColumnMap);\n-\n     // Set the maxLeafRecords\n     String maxLeafRecordsString =\n         _segmentMetadataPropertiesConfiguration.getString(\n@@ -533,6 +516,7 @@ public boolean hasStarTree() {\n     return _hasStarTree;\n   }\n \n+  @Nullable\n   @Override\n   public StarTreeMetadata getStarTreeMetadata() {\n     return _starTreeMetadata;\n@@ -568,11 +552,14 @@ public String getBitmapInvertedIndexFileName(String column, String segmentVersio\n     return column + V1Constants.Indexes.BITMAP_INVERTED_INDEX_FILE_EXTENSION;\n   }\n \n-  @Nullable @Override public String getCreatorName() {\n+  @Nullable\n+  @Override\n+  public String getCreatorName() {\n     return _creatorName;\n   }\n \n-  @Override public Character getPaddingCharacter() {\n+  @Override\n+  public char getPaddingCharacter() {\n     return _paddingCharacter;\n   }\n \n@@ -581,6 +568,17 @@ public int getHllLog2m() {\n     return _hllLog2m;\n   }\n \n+  @Nullable\n+  @Override\n+  public String getDerivedColumn(String column, MetricFieldSpec.DerivedMetricType derivedMetricType) {\n+    switch (derivedMetricType) {\n+      case HLL:\n+        return _hllDerivedColumnMap.get(column);\n+      default:\n+        throw new IllegalArgumentException();\n+    }\n+  }\n+\n   /**\n    * Converts segment metadata to json\n    * @param columnFilter list only  the columns in the set. Lists all the columns if",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/83b3512def190c49233a14280e5c178169ff155f/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "sha": "76007d16f15f660818de15909dca3d038e94bb23",
                "status": "modified"
            }
        ],
        "message": "Fix FastHLL throw NPE. (#849)\n\nAdd BrokerRequestPreProcessor class to pre-process the broker request.\r\nMove hll derived column name map from StarTreeMetadata to SegmentMetadata.\r\nRewrite the hll derived column name before making the plan node.",
        "parent": "https://github.com/apache/incubator-pinot/commit/cb866d837f72232201daa394b7188a1bd61199e9",
        "patched_files": [
            "RetentionManager.java",
            "ValidationManager.java",
            "RequestUtils.java",
            "FilterPlanNode.java",
            "SimpleSegmentMetadata.java",
            "AggregationGroupByPlanNode.java",
            "BrokerRequestPreProcessor.java",
            "StarTreeMetadata.java",
            "SegmentMetadata.java",
            "InstancePlanMakerImplV2.java",
            "SegmentMetadataImpl.java",
            "AggregationPlanNode.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestStarTreeMetadata.java",
            "RetentionManagerTest.java",
            "ValidationManagerTest.java",
            "SegmentMetadataImplTest.java"
        ]
    },
    "incubator-pinot_872db00": {
        "bug_id": "incubator-pinot_872db00",
        "commit": "https://github.com/apache/incubator-pinot/commit/872db00ad57d35552894c36e54c722f88a831002",
        "file": [
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/872db00ad57d35552894c36e54c722f88a831002/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java?ref=872db00ad57d35552894c36e54c722f88a831002",
                "deletions": 24,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "patch": "@@ -118,34 +118,39 @@ public void stop() {\n   private synchronized void assignRealtimeSegmentsToServerInstancesIfNecessary()\n       throws JSONException, IOException {\n     // Fetch current ideal state snapshot\n-    Map<String, IdealState> idealStateMap = new HashMap<String, IdealState>();\n+    Map<String, IdealState> idealStateMap = new HashMap<>();\n+\n+    for (String realtimeTableName : _pinotHelixResourceManager.getAllRealtimeTables()) {\n+      TableConfig tableConfig = _pinotHelixResourceManager.getTableConfig(realtimeTableName);\n+\n+      // Table config might have already been deleted\n+      if (tableConfig == null) {\n+        continue;\n+      }\n \n-    for (String resource : _pinotHelixResourceManager.getAllRealtimeTables()) {\n-      final String tableName = TableNameBuilder.extractRawTableName(resource);\n-      TableConfig tableConfig = _pinotHelixResourceManager.getRealtimeTableConfig(tableName);\n       KafkaStreamMetadata metadata = new KafkaStreamMetadata(tableConfig.getIndexingConfig().getStreamConfigs());\n       if (metadata.hasHighLevelKafkaConsumerType()) {\n-        idealStateMap.put(resource, _pinotHelixResourceManager.getHelixAdmin()\n-            .getResourceIdealState(_pinotHelixResourceManager.getHelixClusterName(), resource));\n+        idealStateMap.put(realtimeTableName, _pinotHelixResourceManager.getHelixAdmin()\n+            .getResourceIdealState(_pinotHelixResourceManager.getHelixClusterName(), realtimeTableName));\n       } else {\n         LOGGER.debug(\"Not considering table {} for realtime segment assignment\");\n       }\n     }\n \n     List<Pair<String, String>> listOfSegmentsToAddToInstances = new ArrayList<Pair<String, String>>();\n \n-    for (String resource : idealStateMap.keySet()) {\n+    for (String realtimeTableName : idealStateMap.keySet()) {\n       try {\n-        IdealState state = idealStateMap.get(resource);\n+        IdealState state = idealStateMap.get(realtimeTableName);\n \n         // Are there any partitions?\n         if (state.getPartitionSet().size() == 0) {\n           // No, this is a brand new ideal state, so we will add one new segment to every partition and replica\n-          List<String> instancesInResource = new ArrayList<String>();\n+          List<String> instancesInResource = new ArrayList<>();\n           try {\n-            instancesInResource.addAll(_pinotHelixResourceManager.getServerInstancesForTable(resource, TableType.REALTIME));\n+            instancesInResource.addAll(_pinotHelixResourceManager.getServerInstancesForTable(realtimeTableName, TableType.REALTIME));\n           } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while fetching instances for resource {}\", resource, e);\n+            LOGGER.error(\"Caught exception while fetching instances for resource {}\", realtimeTableName, e);\n             _controllerMetrics.addMeteredGlobalValue(ControllerMeter.CONTROLLER_REALTIME_TABLE_SEGMENT_ASSIGNMENT_ERROR, 1L);\n           }\n \n@@ -160,15 +165,15 @@ private synchronized void assignRealtimeSegmentsToServerInstancesIfNecessary()\n               continue;\n             }\n \n-            String groupId = instanceZKMetadata.getGroupId(resource);\n-            String partitionId = instanceZKMetadata.getPartition(resource);\n+            String groupId = instanceZKMetadata.getGroupId(realtimeTableName);\n+            String partitionId = instanceZKMetadata.getPartition(realtimeTableName);\n             if (groupId != null && !groupId.isEmpty() && partitionId != null && !partitionId.isEmpty()) {\n               listOfSegmentsToAddToInstances.add(new Pair<String, String>(\n                   new HLCSegmentName(groupId, partitionId, String.valueOf(System.currentTimeMillis())).getSegmentName(),\n                   instanceId));\n             } else {\n               LOGGER.warn(\"Instance {} has invalid groupId ({}) and/or partitionId ({}) for resource {}, ignoring for segment assignment.\",\n-                  instanceId, groupId, partitionId, resource);\n+                  instanceId, groupId, partitionId, realtimeTableName);\n               _controllerMetrics.addMeteredGlobalValue(ControllerMeter.CONTROLLER_REALTIME_TABLE_SEGMENT_ASSIGNMENT_ERROR, 1L);\n             }\n           }\n@@ -177,9 +182,9 @@ private synchronized void assignRealtimeSegmentsToServerInstancesIfNecessary()\n           Set<String> instancesToAssignRealtimeSegment = new HashSet<String>();\n           try {\n             instancesToAssignRealtimeSegment.addAll(\n-                _pinotHelixResourceManager.getServerInstancesForTable(resource, TableType.REALTIME));\n+                _pinotHelixResourceManager.getServerInstancesForTable(realtimeTableName, TableType.REALTIME));\n           } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while fetching instances for resource {}\", resource, e);\n+            LOGGER.error(\"Caught exception while fetching instances for resource {}\", realtimeTableName, e);\n             _controllerMetrics.addMeteredGlobalValue(ControllerMeter.CONTROLLER_REALTIME_TABLE_SEGMENT_ASSIGNMENT_ERROR, 1L);\n           }\n \n@@ -204,15 +209,15 @@ private synchronized void assignRealtimeSegmentsToServerInstancesIfNecessary()\n           // Assign a new segment to the server instances not currently processing this segment\n           for (String instanceId : instancesToAssignRealtimeSegment) {\n             InstanceZKMetadata instanceZKMetadata = _pinotHelixResourceManager.getInstanceZKMetadata(instanceId);\n-            String groupId = instanceZKMetadata.getGroupId(resource);\n-            String partitionId = instanceZKMetadata.getPartition(resource);\n+            String groupId = instanceZKMetadata.getGroupId(realtimeTableName);\n+            String partitionId = instanceZKMetadata.getPartition(realtimeTableName);\n             listOfSegmentsToAddToInstances.add(new Pair<String, String>(\n                 new HLCSegmentName(groupId, partitionId, String.valueOf(System.currentTimeMillis())).getSegmentName(),\n                 instanceId));\n           }\n         }\n       } catch (Exception e) {\n-        LOGGER.warn(\"Caught exception while processing resource {}, skipping.\", resource, e);\n+        LOGGER.warn(\"Caught exception while processing resource {}, skipping.\", realtimeTableName, e);\n         _controllerMetrics.addMeteredGlobalValue(ControllerMeter.CONTROLLER_REALTIME_TABLE_SEGMENT_ASSIGNMENT_ERROR, 1L);\n       }\n     }\n@@ -372,14 +377,18 @@ private void refreshWatchers(String path) {\n   }\n \n   @Override\n-  public void handleChildChange(String parentPath, List<String> currentChilds)\n+  public void handleChildChange(String parentPath, List<String> currentChildren)\n       throws Exception {\n     LOGGER.info(\"PinotRealtimeSegmentManager.handleChildChange: {}\", parentPath);\n     processPropertyStoreChange(parentPath);\n-    for (String table : currentChilds) {\n-      if (table.endsWith(\"_REALTIME\")) {\n-        LOGGER.info(\"PinotRealtimeSegmentManager.handleChildChange with table: {}\", parentPath + \"/\" + table);\n-        processPropertyStoreChange(parentPath + \"/\" + table);\n+\n+    // If parent path get removed, currentChildren will be null\n+    if (currentChildren != null) {\n+      for (String table : currentChildren) {\n+        if (table.endsWith(\"_REALTIME\")) {\n+          LOGGER.info(\"PinotRealtimeSegmentManager.handleChildChange with table: {}\", parentPath + \"/\" + table);\n+          processPropertyStoreChange(parentPath + \"/\" + table);\n+        }\n       }\n     }\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/872db00ad57d35552894c36e54c722f88a831002/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotRealtimeSegmentManager.java",
                "sha": "5fd39c12b9e96812931362b087947268b6571c7d",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/872db00ad57d35552894c36e54c722f88a831002/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java?ref=872db00ad57d35552894c36e54c722f88a831002",
                "deletions": 0,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "patch": "@@ -115,6 +115,7 @@ public void testInstanceShutdown()\n   @AfterClass\n   public void tearDown()\n       throws Exception {\n+    dropRealtimeTable(getTableName());\n     stopServer();\n     stopBroker();\n     stopController();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/872db00ad57d35552894c36e54c722f88a831002/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "sha": "d71b76f246b9ad50ef17dbb08eb806655b224d3d",
                "status": "modified"
            }
        ],
        "message": "Fix the bug where dropping a HLC table will throw NPE (#1666)\n\nThe reason for the NPE is that:\r\n1. We first drop the table config, then remove the Helix resource. When we rebuild IdealState, it accesses the table config, which will be null at that time.\r\n2. In the handleChildChange callback, when parentPath get removed, currentChildren will be null.\r\n\r\nUpdated RealtimeClusterIntegrationTest to test dropRealtimeTable() (also tested in HybridClusterIntegrationTest)",
        "parent": "https://github.com/apache/incubator-pinot/commit/18a9d14a7a44c0e9e1ecceeff87f89e4dc211fac",
        "patched_files": [
            "PinotRealtimeSegmentManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RealtimeClusterIntegrationTest.java"
        ]
    },
    "incubator-pinot_8c6fd1c": {
        "bug_id": "incubator-pinot_8c6fd1c",
        "commit": "https://github.com/apache/incubator-pinot/commit/8c6fd1ccfd615c0f4848186a63aa12df579d4846",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeResourceDataManager.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeResourceDataManager.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeResourceDataManager.java",
                "patch": "@@ -39,6 +39,7 @@\n import com.linkedin.pinot.common.segment.ReadMode;\n import com.linkedin.pinot.common.segment.SegmentMetadata;\n import com.linkedin.pinot.common.utils.CommonConstants;\n+import com.linkedin.pinot.common.utils.CommonConstants.Segment.Realtime.Status;\n import com.linkedin.pinot.common.utils.NamedThreadFactory;\n import com.linkedin.pinot.core.data.manager.config.ResourceDataManagerConfig;\n import com.linkedin.pinot.core.data.manager.offline.OfflineSegmentDataManager;\n@@ -166,7 +167,7 @@ public void addSegment(ZkHelixPropertyStore<ZNRecord> propertyStore, DataResourc\n     this._helixPropertyStore = propertyStore;\n     String segmentId = segmentZKMetadata.getSegmentName();\n     if (segmentZKMetadata instanceof RealtimeSegmentZKMetadata) {\n-      if (new File(_indexDir, segmentId).exists()) {\n+      if (new File(_indexDir, segmentId).exists() && ((RealtimeSegmentZKMetadata) segmentZKMetadata).getStatus() == Status.DONE) {\n         // segment already exists on file, simply load it and add it to the map\n         if (!_segmentsMap.containsKey(segmentId)) {\n           synchronized (getGlobalLock()) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeResourceDataManager.java",
                "sha": "fc7605cecafc69ecdeff46ae40e5cc8a971274b6",
                "status": "modified"
            },
            {
                "additions": 3,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "changes": 5,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "patch": "@@ -147,8 +147,9 @@ public void run() {\n         try {\n           logger.info(\"Trying to build segment!\");\n           conveter.build();\n-          FileUtils.moveDirectory(tempSegmentFolder.listFiles()[0], new File(resourceDataDir,\n-              segmentMetadata.getSegmentName()));\n+          File destDir = new File(resourceDataDir, segmentMetadata.getSegmentName());\n+          FileUtils.deleteQuietly(destDir);\n+          FileUtils.moveDirectory(tempSegmentFolder.listFiles()[0], destDir);\n           FileUtils.deleteQuietly(tempSegmentFolder);\n           long startTime = ((RealtimeSegmentImpl) realtimeSegment).getMinTime();\n           long endTime = ((RealtimeSegmentImpl) realtimeSegment).getMaxTime();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "sha": "c4736deaeeaa77fc3a6de0700f8c946d2f275cff",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MAggregationOperator.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MAggregationOperator.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MAggregationOperator.java",
                "patch": "@@ -70,7 +70,7 @@ public boolean open() {\n   public Block nextBlock() {\n     List<Serializable> aggregationResults = new ArrayList<Serializable>();\n     for (int i = 0; i < _aggregationFunctionOperatorList.size(); ++i) {\n-      aggregationResults.add(null);\n+      aggregationResults.add(AggregationFunctionFactory.get(_aggregationInfoList.get(i), true).getDefaultValue());\n     }\n     final long startTime = System.currentTimeMillis();\n     long numDocsScanned = 0;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MAggregationOperator.java",
                "sha": "951f3d4dad6ab977a3a53d7215ef6c66ca80d932",
                "status": "modified"
            },
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/AggregationFunction.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/AggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/AggregationFunction.java",
                "patch": "@@ -23,7 +23,6 @@\n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n import com.linkedin.pinot.common.request.AggregationInfo;\n import com.linkedin.pinot.core.common.Block;\n-import com.linkedin.pinot.core.common.BlockValIterator;\n \n \n /**\n@@ -109,4 +108,11 @@\n    */\n   String getFunctionName();\n \n+  /**\n+   * Return default value if no doc is scanned.\n+   *\n+   * @return defaultValue\n+   */\n+  public Serializable getDefaultValue();\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/AggregationFunction.java",
                "sha": "cce431b853a4cfacc10c81ecd7d081249c0a1b34",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/AvgAggregationFunction.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/AvgAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/AvgAggregationFunction.java",
                "patch": "@@ -27,14 +27,12 @@\n import com.linkedin.pinot.core.common.Block;\n import com.linkedin.pinot.core.common.BlockDocIdIterator;\n import com.linkedin.pinot.core.common.BlockSingleValIterator;\n-import com.linkedin.pinot.core.common.BlockValIterator;\n import com.linkedin.pinot.core.common.Constants;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.CombineLevel;\n import com.linkedin.pinot.core.query.aggregation.function.AvgAggregationFunction.AvgPair;\n import com.linkedin.pinot.core.query.utils.Pair;\n import com.linkedin.pinot.core.segment.index.readers.Dictionary;\n-import com.linkedin.pinot.core.segment.index.readers.ImmutableDictionaryReader;\n \n \n /**\n@@ -173,11 +171,20 @@ public int compareTo(AvgPair o) {\n \n     @Override\n     public String toString() {\n-      return new DecimalFormat(\"####################.##########\").format((getFirst() / getSecond()));\n+      if (getSecond() != 0) {\n+        return new DecimalFormat(\"####################.##########\").format((getFirst() / getSecond()));\n+      } else {\n+        return \"0.0\";\n+      }\n     }\n   }\n \n   public AvgPair getAvgPair(double first, long second) {\n     return new AvgPair(first, second);\n   }\n+\n+  @Override\n+  public Serializable getDefaultValue() {\n+    return new AvgPair(0.0, 0L);\n+  }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/AvgAggregationFunction.java",
                "sha": "d29405228fe9f4e93b484cc53537592b734b9437",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/CountAggregationFunction.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/CountAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/CountAggregationFunction.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.function;\n \n+import java.io.Serializable;\n import java.util.List;\n \n import org.json.JSONException;\n@@ -23,7 +24,6 @@\n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n import com.linkedin.pinot.common.request.AggregationInfo;\n import com.linkedin.pinot.core.common.Block;\n-import com.linkedin.pinot.core.common.BlockValIterator;\n import com.linkedin.pinot.core.operator.DocIdSetBlock;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.CombineLevel;\n@@ -111,4 +111,9 @@ public String getFunctionName() {\n     return \"count_star\";\n   }\n \n+  @Override\n+  public Serializable getDefaultValue() {\n+    return Long.valueOf(0);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/CountAggregationFunction.java",
                "sha": "b52d2d9fe52cb3da6a9cd9c5059a731796db519c",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/DistinctCountAggregationFunction.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/DistinctCountAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/DistinctCountAggregationFunction.java",
                "patch": "@@ -17,6 +17,7 @@\n \n import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n \n+import java.io.Serializable;\n import java.util.List;\n \n import org.json.JSONException;\n@@ -27,12 +28,10 @@\n import com.linkedin.pinot.core.common.Block;\n import com.linkedin.pinot.core.common.BlockDocIdIterator;\n import com.linkedin.pinot.core.common.BlockSingleValIterator;\n-import com.linkedin.pinot.core.common.BlockValIterator;\n import com.linkedin.pinot.core.common.Constants;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.CombineLevel;\n import com.linkedin.pinot.core.segment.index.readers.Dictionary;\n-import com.linkedin.pinot.core.segment.index.readers.ImmutableDictionaryReader;\n \n \n public class DistinctCountAggregationFunction implements AggregationFunction<IntOpenHashSet, Integer> {\n@@ -145,4 +144,9 @@ public String getFunctionName() {\n     return \"distinctCount_\" + _distinctCountColumnName;\n   }\n \n+  @Override\n+  public Serializable getDefaultValue() {\n+    return new IntOpenHashSet();\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/DistinctCountAggregationFunction.java",
                "sha": "e9bfd34e1477226f826357d8970c6f460bdc3b53",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MaxAggregationFunction.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MaxAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 4,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MaxAggregationFunction.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.function;\n \n+import java.io.Serializable;\n import java.util.List;\n import java.util.NoSuchElementException;\n \n@@ -33,7 +34,7 @@\n \n \n public class MaxAggregationFunction implements AggregationFunction<Double, Double> {\n-\n+  private static final double DEFAULT_VALUE = Double.NEGATIVE_INFINITY;\n   private String _maxColumnName;\n \n   public MaxAggregationFunction() {\n@@ -47,7 +48,7 @@ public void init(AggregationInfo aggregationInfo) {\n \n   @Override\n   public Double aggregate(Block docIdSetBlock, Block[] block) {\n-    double ret = Double.NEGATIVE_INFINITY;\n+    double ret = DEFAULT_VALUE;\n     double tmp = 0;\n     int docId = 0;\n     Dictionary dictionaryReader = block[0].getMetadata().getDictionary();\n@@ -86,7 +87,7 @@ public Double aggregate(Double mergedResult, int docId, Block[] block) {\n \n   @Override\n   public List<Double> combine(List<Double> aggregationResultList, CombineLevel combineLevel) {\n-    double maxValue = Double.NEGATIVE_INFINITY;\n+    double maxValue = DEFAULT_VALUE;\n     for (double aggregationResult : aggregationResultList) {\n       if (maxValue < aggregationResult) {\n         maxValue = aggregationResult;\n@@ -110,7 +111,7 @@ public Double combineTwoValues(Double aggregationResult0, Double aggregationResu\n \n   @Override\n   public Double reduce(List<Double> combinedResultList) {\n-    double maxValue = Double.NEGATIVE_INFINITY;\n+    double maxValue = DEFAULT_VALUE;\n     for (double combinedResult : combinedResultList) {\n       if (maxValue < combinedResult) {\n         maxValue = combinedResult;\n@@ -125,6 +126,9 @@ public JSONObject render(Double finalAggregationResult) {\n       if (finalAggregationResult == null) {\n         throw new NoSuchElementException(\"Final result is null!\");\n       }\n+      if (finalAggregationResult.isInfinite()) {\n+        return new JSONObject().put(\"value\", \"null\");\n+      }\n       return new JSONObject().put(\"value\", String.format(\"%1.5f\", finalAggregationResult));\n     } catch (JSONException e) {\n       throw new RuntimeException(e);\n@@ -141,4 +145,9 @@ public String getFunctionName() {\n     return \"max_\" + _maxColumnName;\n   }\n \n+  @Override\n+  public Serializable getDefaultValue() {\n+    return new Double(DEFAULT_VALUE);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MaxAggregationFunction.java",
                "sha": "02605014a9295a28a21d992fc05f576b36494c7f",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MinAggregationFunction.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MinAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 3,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MinAggregationFunction.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.function;\n \n+import java.io.Serializable;\n import java.util.List;\n import java.util.NoSuchElementException;\n \n@@ -33,6 +34,7 @@\n \n \n public class MinAggregationFunction implements AggregationFunction<Double, Double> {\n+  private static final double DEFAULT_VALUE = Double.POSITIVE_INFINITY;\n   private String _minColumnName;\n \n   public MinAggregationFunction() {\n@@ -46,7 +48,7 @@ public void init(AggregationInfo aggregationInfo) {\n \n   @Override\n   public Double aggregate(Block docIdSetBlock, Block[] block) {\n-    double ret = Double.POSITIVE_INFINITY;\n+    double ret = DEFAULT_VALUE;\n     double tmp = 0;\n     int docId = 0;\n     Dictionary dictionaryReader = block[0].getMetadata().getDictionary();\n@@ -85,7 +87,7 @@ public Double aggregate(Double mergedResult, int docId, Block[] block) {\n \n   @Override\n   public List<Double> combine(List<Double> aggregationResultList, CombineLevel combineLevel) {\n-    double minValue = Double.POSITIVE_INFINITY;\n+    double minValue = DEFAULT_VALUE;\n     for (double aggregationResult : aggregationResultList) {\n       if (aggregationResult < minValue) {\n         minValue = aggregationResult;\n@@ -109,7 +111,7 @@ public Double combineTwoValues(Double aggregationResult0, Double aggregationResu\n \n   @Override\n   public Double reduce(List<Double> combinedResultList) {\n-    double minValue = Double.POSITIVE_INFINITY;\n+    double minValue = DEFAULT_VALUE;\n     for (double combinedResult : combinedResultList) {\n       if (combinedResult < minValue) {\n         minValue = combinedResult;\n@@ -124,6 +126,9 @@ public JSONObject render(Double finalAggregationResult) {\n       if (finalAggregationResult == null) {\n         throw new NoSuchElementException(\"Final result is null!\");\n       }\n+      if (finalAggregationResult.isInfinite()) {\n+        return new JSONObject().put(\"value\", \"null\");\n+      }\n       return new JSONObject().put(\"value\", String.format(\"%1.5f\", finalAggregationResult));\n     } catch (JSONException e) {\n       throw new RuntimeException(e);\n@@ -140,4 +145,9 @@ public String getFunctionName() {\n     return \"min_\" + _minColumnName;\n   }\n \n+  @Override\n+  public Serializable getDefaultValue() {\n+    return new Double(DEFAULT_VALUE);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/MinAggregationFunction.java",
                "sha": "8996ba720696521e4318c2dec547fc71002260f4",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/SumAggregationFunction.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/SumAggregationFunction.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/SumAggregationFunction.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.function;\n \n+import java.io.Serializable;\n import java.util.List;\n \n import org.json.JSONException;\n@@ -25,12 +26,10 @@\n import com.linkedin.pinot.core.common.Block;\n import com.linkedin.pinot.core.common.BlockDocIdIterator;\n import com.linkedin.pinot.core.common.BlockSingleValIterator;\n-import com.linkedin.pinot.core.common.BlockValIterator;\n import com.linkedin.pinot.core.common.Constants;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.CombineLevel;\n import com.linkedin.pinot.core.segment.index.readers.Dictionary;\n-import com.linkedin.pinot.core.segment.index.readers.ImmutableDictionaryReader;\n \n \n /**\n@@ -139,4 +138,9 @@ public String getFunctionName() {\n     return \"sum_\" + _sumByColumn;\n   }\n \n+  @Override\n+  public Serializable getDefaultValue() {\n+    return Double.valueOf(0);\n+  }\n+\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/function/SumAggregationFunction.java",
                "sha": "f35aab63779e533f5fee64d554c295869b938fb6",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "changes": 36,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java?ref=8c6fd1ccfd615c0f4848186a63aa12df579d4846",
                "deletions": 14,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "patch": "@@ -15,9 +15,9 @@\n  */\n package com.linkedin.pinot.core.realtime.impl.datasource;\n \n-import java.util.ArrayList;\n-import java.util.List;\n+import java.util.HashSet;\n import java.util.Map;\n+import java.util.Set;\n \n import org.apache.commons.lang3.tuple.Pair;\n import org.roaringbitmap.buffer.MutableRoaringBitmap;\n@@ -131,25 +131,32 @@ public boolean setPredicate(Predicate predicate) {\n     switch (predicate.getType()) {\n       case EQ:\n         String equalsValueToLookup = ((EqPredicate) predicate).getEqualsValue();\n-        filteredDocIdBitmap = invertedINdex.getDocIdSetFor(dictionary.indexOf(equalsValueToLookup));\n+        if (dictionary.contains(equalsValueToLookup)) {\n+          filteredDocIdBitmap = invertedINdex.getDocIdSetFor(dictionary.indexOf(equalsValueToLookup));\n+        } else {\n+          filteredDocIdBitmap = new MutableRoaringBitmap();\n+        }\n         break;\n       case IN:\n         MutableRoaringBitmap orBitmapForInQueries = new MutableRoaringBitmap();\n         String[] inRangeStrings = ((InPredicate) predicate).getInRange();\n-        int[] dicIdsToOrTogether = new int[inRangeStrings.length];\n-        int counter = 0;\n         for (String rawValueInString : inRangeStrings) {\n-          dicIdsToOrTogether[counter++] = dictionary.indexOf(rawValueInString);\n-        }\n-        for (int dicId : dicIdsToOrTogether) {\n-          orBitmapForInQueries.or(invertedINdex.getDocIdSetFor(dicId));\n+          if (dictionary.contains(rawValueInString)) {\n+            int dictId = dictionary.indexOf(rawValueInString);\n+            orBitmapForInQueries.or(invertedINdex.getDocIdSetFor(dictId));\n+          }\n         }\n         filteredDocIdBitmap = orBitmapForInQueries;\n         break;\n       case NEQ:\n         MutableRoaringBitmap neqBitmap = new MutableRoaringBitmap();\n-        int valueToExclude = ((NEqPredicate) predicate).getNotEqualsValue() == null ? 0 : dictionary.indexOf(((NEqPredicate) predicate).getNotEqualsValue());\n-\n+        String neqValue = ((NEqPredicate) predicate).getNotEqualsValue();\n+        int valueToExclude = -1;\n+        if (neqValue == null) {\n+          valueToExclude = 0;\n+        } else if (neqValue != null && dictionary.contains(neqValue)) {\n+          valueToExclude = dictionary.indexOf(neqValue);\n+        }\n         for (int i = 1; i <= dictionary.length(); i++) {\n           if (valueToExclude != i) {\n             neqBitmap.or(invertedINdex.getDocIdSetFor(i));\n@@ -159,10 +166,12 @@ public boolean setPredicate(Predicate predicate) {\n         break;\n       case NOT_IN:\n         final String[] notInValues = ((NotInPredicate) predicate).getNotInRange();\n-        final List<Integer> notInIds = new ArrayList<Integer>();\n+        final Set<Integer> notInIds = new HashSet<Integer>();\n \n         for (final String notInValue : notInValues) {\n-          notInIds.add(new Integer(dictionary.indexOf(notInValue)));\n+          if (dictionary.contains(notInValue)) {\n+            notInIds.add(dictionary.indexOf(notInValue));\n+          }\n         }\n \n         final MutableRoaringBitmap notINHolder = new MutableRoaringBitmap();\n@@ -209,5 +218,4 @@ public boolean setPredicate(Predicate predicate) {\n     }\n     return true;\n   }\n-\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/8c6fd1ccfd615c0f4848186a63aa12df579d4846/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "sha": "231947563bba9cbd935cb8bff5f46f69ee3fa05c",
                "status": "modified"
            }
        ],
        "message": "Fixing NPE during filtering unexisted value in realtime segment.\nFixing no docs matched issue for aggregation functions.\n\nRB=465638\nR=xiafu\nA=jfim",
        "parent": "https://github.com/apache/incubator-pinot/commit/4f13ac7b588ec8baf353a7f5495aa07b8fd9147e",
        "patched_files": [
            "RealtimeResourceDataManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestRealtimeResourceDataManager.java"
        ]
    },
    "incubator-pinot_962c96a": {
        "bug_id": "incubator-pinot_962c96a",
        "commit": "https://github.com/apache/incubator-pinot/commit/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeTableDataManager.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeTableDataManager.java?ref=962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeTableDataManager.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.core.data.manager.realtime;\n \n+import com.linkedin.pinot.common.Utils;\n import com.linkedin.pinot.common.config.IndexingConfig;\n import com.linkedin.pinot.common.config.TableConfig;\n import com.linkedin.pinot.common.config.TableNameBuilder;\n@@ -96,7 +97,12 @@ protected void doInit() {\n         LOGGER.error(\"Could not move {} to {}\", statsFile.getAbsolutePath(), savedFile.getAbsolutePath(), e1);\n         throw new RuntimeException(e);\n       }\n-      LOGGER.warn(\"Saved unreadable {} into {}\", statsFile.getAbsolutePath(), savedFile.getAbsolutePath());\n+      LOGGER.warn(\"Saved unreadable {} into {}. Creating a fresh instance\", statsFile.getAbsolutePath(), savedFile.getAbsolutePath());\n+      try {\n+        _statsHistory = RealtimeSegmentStatsHistory.deserialzeFrom(statsFile);\n+      } catch (Exception e2) {\n+        Utils.rethrowException(e2);\n+      }\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeTableDataManager.java",
                "sha": "0d0bbaa90b4cdf5b0c74d509da5961ca100f492c",
                "status": "modified"
            },
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/test/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentStatsHistoryTest.java",
                "changes": 25,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentStatsHistoryTest.java?ref=962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentStatsHistoryTest.java",
                "patch": "@@ -16,6 +16,7 @@\n \n package com.linkedin.pinot.core.realtime.impl;\n \n+import com.linkedin.pinot.util.TestUtils;\n import java.io.File;\n import java.util.Random;\n import org.apache.commons.io.FileUtils;\n@@ -180,6 +181,30 @@ public void testMultiThreadedUse() throws Exception {\n     FileUtils.deleteQuietly(serializedFile);\n   }\n \n+  // This test attempts to ensure that future modifications to RealtimeSegmentStatsHistory does not prevent the software\n+  // from reading data serialized by earlier versions. The serialized data has one segment, with 2 columns -- \"v1col1\" and\n+  // \"v1col2\".\n+  @Test\n+  public void testVersion1() throws Exception {\n+    final String fileName = \"realtime-segment-stats-history-v1.ser\";\n+    File v1StatsFile = new File(TestUtils.getFileFromResourceUrl(RealtimeSegmentStatsHistoryTest.class.getClassLoader().getResource(\"data\")), fileName);\n+    RealtimeSegmentStatsHistory statsHistory = RealtimeSegmentStatsHistory.deserialzeFrom(v1StatsFile);\n+    RealtimeSegmentStatsHistory.SegmentStats segmentStats = statsHistory.getSegmentStatsAt(0);\n+    RealtimeSegmentStatsHistory.ColumnStats columnStats;\n+\n+    columnStats = segmentStats.getColumnStats(\"v1col1\");\n+    Assert.assertEquals(columnStats.getCardinality(), 100);\n+    Assert.assertEquals(columnStats.getAvgColumnSize(), 200);\n+    columnStats = segmentStats.getColumnStats(\"v1col2\");\n+    Assert.assertEquals(columnStats.getCardinality(), 300);\n+    Assert.assertEquals(columnStats.getAvgColumnSize(), 400);\n+\n+    Assert.assertEquals(segmentStats.getNumRowsConsumed(), 500);\n+    Assert.assertEquals(segmentStats.getMemUsedBytes(), 600);\n+    Assert.assertEquals(segmentStats.getNumSeconds(), 700);\n+\n+  }\n+\n   private static class StatsUpdater implements Runnable {\n     private final RealtimeSegmentStatsHistory _statsHistory;\n     private final int _numIterations;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/test/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentStatsHistoryTest.java",
                "sha": "2eec674b45f2074e02bbcd3d05c194c39158d091",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/test/resources/data/realtime-segment-stats-history-v1.ser",
                "changes": 0,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/resources/data/realtime-segment-stats-history-v1.ser?ref=962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da",
                "deletions": 0,
                "filename": "pinot-core/src/test/resources/data/realtime-segment-stats-history-v1.ser",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/962c96a00c3dfd06f1ebf391a6b7ee26a3d1c3da/pinot-core/src/test/resources/data/realtime-segment-stats-history-v1.ser",
                "sha": "e0f09dc769423498ee3ecf3515117ac455c19fd0",
                "status": "added"
            }
        ],
        "message": "Fix NPE and add a test case for older history files (#1827)\n\n* Fix NPE and add a test case for older history files\r\n\r\nIf we fail to read the stats history file for any reason, we would end up getting an NPE because _statsHistory\r\nwent uninitialized. Fixed to create an instance with a new file.\r\n\r\nAlso added a v1 serialized file to the repository so that we can ensure that future changes to the class\r\ncan still read v1 files.\r\n\r\n* Address review comments",
        "parent": "https://github.com/apache/incubator-pinot/commit/050886603ea2b4bc0eac543adeb96d6887ce237c",
        "patched_files": [
            "RealtimeSegmentStatsHistory.java",
            "RealtimeTableDataManager.java",
            "realtime-segment-stats-history-v1.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RealtimeSegmentStatsHistoryTest.java",
            "RealtimeTableDataManagerTest.java"
        ]
    },
    "incubator-pinot_966f1ba": {
        "bug_id": "incubator-pinot_966f1ba",
        "commit": "https://github.com/apache/incubator-pinot/commit/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/BrokerServerBuilder.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/BrokerServerBuilder.java?ref=966f1ba84a385f4a9eb811ef6a917c9a6aa485c1",
                "deletions": 1,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/BrokerServerBuilder.java",
                "patch": "@@ -163,7 +163,7 @@ public void buildHTTP() {\n     context.addServlet(PinotClientRequestServlet.class, \"/query\");\n \n     if (clientConfig.enableConsole()) {\n-      System.out.println(clientConfig.getConsoleWebappPath());\n+      LOGGER.info(\"Console webapp path: \" + clientConfig.getConsoleWebappPath());\n       context.setResourceBase(clientConfig.getConsoleWebappPath());\n     } else {\n       context.setResourceBase(\"\");",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/BrokerServerBuilder.java",
                "sha": "1b6e8506970933c787be4ab428f587f36a5ce51a",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/BrokerResourceOnlineOfflineStateModelFactory.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/BrokerResourceOnlineOfflineStateModelFactory.java?ref=966f1ba84a385f4a9eb811ef6a917c9a6aa485c1",
                "deletions": 4,
                "filename": "pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/BrokerResourceOnlineOfflineStateModelFactory.java",
                "patch": "@@ -49,7 +49,6 @@ public StateModel createNewStateModel(String resourceName) {\n     @Transition(from = \"OFFLINE\", to = \"ONLINE\")\n     public void onBecomeOnlineFromOffline(Message message, NotificationContext context) {\n       try {\n-        System.out.println(\"BrokerResourceOnlineOfflineStateModel.onBecomeOnlineFromOffline() : \" + message);\n         LOGGER.info(\"BrokerResourceOnlineOfflineStateModel.onBecomeOnlineFromOffline() : \" + message);\n         String resourceName = message.getPartitionName();\n         _helixExternalViewBasedRouting.markDataResourceOnline(\n@@ -64,7 +63,6 @@ public void onBecomeOnlineFromOffline(Message message, NotificationContext conte\n     @Transition(from = \"ONLINE\", to = \"OFFLINE\")\n     public void onBecomeOfflineFromOnline(Message message, NotificationContext context) {\n       try {\n-        System.out.println(\"BrokerResourceOnlineOfflineStateModel.onBecomeOfflineFromOnline() : \" + message);\n         LOGGER.info(\"BrokerResourceOnlineOfflineStateModel.onBecomeOfflineFromOnline() : \" + message);\n         String resourceName = message.getResourceName();\n         _helixExternalViewBasedRouting.markDataResourceOffline(resourceName);\n@@ -76,7 +74,6 @@ public void onBecomeOfflineFromOnline(Message message, NotificationContext conte\n     @Transition(from = \"OFFLINE\", to = \"DROPPED\")\n     public void onBecomeDroppedFromOffline(Message message, NotificationContext context) {\n       try {\n-        System.out.println(\"BrokerResourceOnlineOfflineStateModel.onBecomeDroppedFromOffline() : \" + message);\n         LOGGER.info(\"BrokerResourceOnlineOfflineStateModel.onBecomeDroppedFromOffline() : \" + message);\n         String resourceName = message.getResourceName();\n         _helixExternalViewBasedRouting.markDataResourceOffline(resourceName);\n@@ -88,7 +85,6 @@ public void onBecomeDroppedFromOffline(Message message, NotificationContext cont\n     @Transition(from = \"ONLINE\", to = \"DROPPED\")\n     public void onBecomeDroppedFromOnline(Message message, NotificationContext context) {\n       try {\n-        System.out.println(\"BrokerResourceOnlineOfflineStateModel.onBecomeDroppedFromOnline() : \" + message);\n         LOGGER.info(\"BrokerResourceOnlineOfflineStateModel.onBecomeDroppedFromOnline() : \" + message);\n         String resourceName = message.getResourceName();\n         _helixExternalViewBasedRouting.markDataResourceOffline(resourceName);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-broker/src/main/java/com/linkedin/pinot/broker/broker/helix/BrokerResourceOnlineOfflineStateModelFactory.java",
                "sha": "a78ab81c51d2563f5212e29b0e5b52dcb5684a84",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/MetricsHelper.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/MetricsHelper.java?ref=966f1ba84a385f4a9eb811ef6a917c9a6aa485c1",
                "deletions": 8,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/metrics/MetricsHelper.java",
                "patch": "@@ -1,6 +1,5 @@\n package com.linkedin.pinot.common.metrics;\n \n-import com.google.common.base.Splitter;\n import com.yammer.metrics.core.Timer;\n import java.lang.reflect.Constructor;\n import java.util.Map;\n@@ -41,8 +40,7 @@ public static void initializeMetrics(Configuration configuration) {\n       String[] listenerClassNames = configuration.getStringArray(\"metricsRegistryRegistrationListeners\");\n \n       if (listenerClassNames.length < 1) {\n-        listenerClassNames = new String[] {\n-            \"com.linkedin.pinot.common.metrics.JmxReporterMetricsRegistryRegistrationListener\" };\n+        listenerClassNames = new String[] { JmxReporterMetricsRegistryRegistrationListener.class.getName() };\n       }\n \n       // Build each listener using their default constructor and add them\n@@ -294,18 +292,18 @@ public static TimerContext startTimer() {\n    *\n    */\n   public static class TimerContext {\n-    private final long _startTimeMs;\n-    private long _stopTimeMs;\n+    private final long _startTimeNanos;\n+    private long _stopTimeNanos;\n     private boolean _isDone;\n \n     public TimerContext() {\n-      _startTimeMs = System.nanoTime();\n+      _startTimeNanos = System.nanoTime();\n       _isDone = false;\n     }\n \n     public void stop() {\n       _isDone = true;\n-      _stopTimeMs = System.nanoTime();\n+      _stopTimeNanos = System.nanoTime();\n     }\n \n     /**\n@@ -316,7 +314,7 @@ public long getLatencyMs() {\n       if (!_isDone) {\n         stop();\n       }\n-      return (_stopTimeMs - _startTimeMs) / 1000000L;\n+      return (_stopTimeNanos - _startTimeNanos) / 1000000L;\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/MetricsHelper.java",
                "sha": "b5437772d7091a443fcc983f9036bf86669505a7",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/InstanceDataManager.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/InstanceDataManager.java?ref=966f1ba84a385f4a9eb811ef6a917c9a6aa485c1",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/InstanceDataManager.java",
                "patch": "@@ -59,7 +59,8 @@ public synchronized void init(Configuration dataManagerConfig) {\n       _instanceDataManagerConfig = new InstanceDataManagerConfig(dataManagerConfig);\n     } catch (Exception e) {\n       _instanceDataManagerConfig = null;\n-      e.printStackTrace();\n+      LOGGER.error(\"Error during InstanceDataManager initialization\", e);\n+      throw new RuntimeException(e);\n     }\n     for (String resourceName : _instanceDataManagerConfig.getResourceNames()) {\n       ResourceDataManagerConfig resourceDataManagerConfig =",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/966f1ba84a385f4a9eb811ef6a917c9a6aa485c1/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/InstanceDataManager.java",
                "sha": "a9e110b19f0b1cfa7250776ddc6567d78235d5e4",
                "status": "modified"
            }
        ],
        "message": "Minor code cleanups: Removed some System.out.println calls, fixed a variable name, removed a hardcoded class name, logged an error properly and rethrew the exception instead of NPE'ing on the next line\n\nRB=424253\nR=kgopalak,xiafu,jfim,dpatel\nA=dpatel",
        "parent": "https://github.com/apache/incubator-pinot/commit/6a0f57fadc881815d9b3a81d1cbc3186390d7179",
        "patched_files": [
            "MetricsHelper.java",
            "BrokerServerBuilder.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestBrokerServerBuilder.java",
            "TestMetricsHelper.java"
        ]
    },
    "incubator-pinot_a365190": {
        "bug_id": "incubator-pinot_a365190",
        "commit": "https://github.com/apache/incubator-pinot/commit/a365190dfbfe6adc7836bf8f33ed100f2674e58a",
        "file": [
            {
                "additions": 30,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/a365190dfbfe6adc7836bf8f33ed100f2674e58a/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "changes": 48,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java?ref=a365190dfbfe6adc7836bf8f33ed100f2674e58a",
                "deletions": 18,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "patch": "@@ -15,6 +15,7 @@\n  */\n package com.linkedin.pinot.controller.helix.core.retention;\n \n+import com.linkedin.pinot.common.config.SegmentsValidationAndRetentionConfig;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.List;\n@@ -165,30 +166,41 @@ private void updateDeletionStrategiesForEntireCluster() {\n   private Map<String, RetentionStrategy> handleOfflineDeletionStrategy(String offlineTableName) {\n     Map<String, RetentionStrategy> tableToDeletionStrategyMap = new HashMap<String, RetentionStrategy>();\n \n-    AbstractTableConfig offlineTableConfig;\n     try {\n-      offlineTableConfig = ZKMetadataProvider.getOfflineTableConfig(_pinotHelixResourceManager.getPropertyStore(), offlineTableName);\n-    } catch (Exception e) {\n-      LOGGER.error(\"Error getting offline table config from property store!\", e);\n-      return tableToDeletionStrategyMap;\n-    }\n+      AbstractTableConfig offlineTableConfig;\n \n-    if (offlineTableConfig == null || offlineTableConfig.getValidationConfig() == null) {\n-      LOGGER.info(\"Table config null for table: {}, treating it as refresh only table.\", offlineTableName);\n-      return tableToDeletionStrategyMap;\n-    }\n-    \n-    if (offlineTableConfig.getValidationConfig().getSegmentPushType().equalsIgnoreCase(\"REFRESH\")) {\n-      LOGGER.info(\"Table: {} is a refresh only table.\", offlineTableName);\n-      return tableToDeletionStrategyMap;\n-    }\n-    try {\n-      TimeRetentionStrategy timeRetentionStrategy = new TimeRetentionStrategy(offlineTableConfig.getValidationConfig().getRetentionTimeUnit(),\n-          offlineTableConfig.getValidationConfig().getRetentionTimeValue());\n+      try {\n+        offlineTableConfig = ZKMetadataProvider.getOfflineTableConfig(_pinotHelixResourceManager.getPropertyStore(), offlineTableName);\n+      } catch (Exception e) {\n+        LOGGER.error(\"Error getting offline table config from property store!\", e);\n+        return tableToDeletionStrategyMap;\n+      }\n+\n+      if (offlineTableConfig == null || offlineTableConfig.getValidationConfig() == null) {\n+        LOGGER.info(\"Table config null for table: {}, treating it as refresh only table.\", offlineTableName);\n+        return tableToDeletionStrategyMap;\n+      }\n+\n+      SegmentsValidationAndRetentionConfig validationConfig = offlineTableConfig.getValidationConfig();\n+\n+      if (validationConfig.getSegmentPushType() == null || validationConfig.getSegmentPushType().isEmpty()) {\n+        LOGGER.info(\"Segment push type for table {} is empty, skipping retention processing\");\n+        return tableToDeletionStrategyMap;\n+      }\n+\n+      if (\"REFRESH\".equalsIgnoreCase(validationConfig.getSegmentPushType())) {\n+        LOGGER.info(\"Table: {} is a refresh only table.\", offlineTableName);\n+        return tableToDeletionStrategyMap;\n+      }\n+\n+      TimeRetentionStrategy timeRetentionStrategy = new TimeRetentionStrategy(\n+          validationConfig.getRetentionTimeUnit(),\n+          validationConfig.getRetentionTimeValue());\n       tableToDeletionStrategyMap.put(offlineTableName, timeRetentionStrategy);\n     } catch (Exception e) {\n       LOGGER.error(\"Error creating TimeRetentionStrategy for table: {}\", offlineTableName, e);\n     }\n+\n     return tableToDeletionStrategyMap;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/a365190dfbfe6adc7836bf8f33ed100f2674e58a/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/retention/RetentionManager.java",
                "sha": "a88d9eb700ff603aafa0b364fd3d4e9af8f32645",
                "status": "modified"
            }
        ],
        "message": "PINOT-1978 NPE fix for retention\n\nRB=558948\nG=pinot-dev-reviewers\nR=kgopalak,xiafu,jfim,dpatel,mshrivas\nA=mshrivas",
        "parent": "https://github.com/apache/incubator-pinot/commit/908b5e1bba7341dd7a5ecbfd06241e39f52ebe19",
        "patched_files": [
            "RetentionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "RetentionManagerTest.java"
        ]
    },
    "incubator-pinot_b02cc23": {
        "bug_id": "incubator-pinot_b02cc23",
        "commit": "https://github.com/apache/incubator-pinot/commit/b02cc238036b9cadc7c6df80a1004d61fa2349a6",
        "file": [
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "changes": 14,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 0,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "patch": "@@ -15,6 +15,9 @@\n  */\n package com.linkedin.pinot.common.exception;\n \n+import java.io.PrintWriter;\n+import java.io.StringWriter;\n+\n import com.linkedin.pinot.common.response.ProcessingException;\n \n \n@@ -52,4 +55,15 @@\n     UNKNOWN_ERROR.setMessage(\"UnknownError\");\n   }\n \n+  public static ProcessingException getException(ProcessingException processingException, Exception exception, int sizeOfStackTraceToTruncate) {\n+    ProcessingException retProcessingException = QueryException.FUTURE_CALL_ERROR.deepCopy();\n+    StringWriter sw = new StringWriter(sizeOfStackTraceToTruncate);\n+    exception.printStackTrace(new PrintWriter(sw));\n+    retProcessingException.setMessage(sw.toString());\n+    return retProcessingException;\n+  }\n+\n+  public static ProcessingException getException(ProcessingException processingException, Exception exception) {\n+    return getException(processingException, exception, 1000);\n+  }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/exception/QueryException.java",
                "sha": "0302aed9aab3c9209c2e536db986ea913f361a5c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 3,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "patch": "@@ -35,7 +35,7 @@\n public class BrokerResponse {\n   private long _totalDocs = 0;\n   private long _numDocsScanned = 0;\n-  private long _timeUsedMs;\n+  private long _timeUsedMs = 0;\n   private List<JSONObject> _aggregationResults;\n   private List<ResponseStatistics> _segmentStatistics;\n   private List<ProcessingException> _exceptions;\n@@ -62,8 +62,6 @@ public BrokerResponse() {\n     _segmentStatistics = new ArrayList<ResponseStatistics>();\n     _exceptions = new ArrayList<ProcessingException>();\n     _traceInfo = new HashMap<String, String>();\n-    _timeUsedMs = Long.MIN_VALUE;\n-\n   }\n \n   public long getTotalDocs() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/response/BrokerResponse.java",
                "sha": "42b8d2ca1e89b16c0cd0966391ce99bed312c1da",
                "status": "modified"
            },
            {
                "additions": 126,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "changes": 225,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 99,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.common.utils;\n \n-import com.linkedin.pinot.common.Utils;\n import java.io.ByteArrayInputStream;\n import java.io.ByteArrayOutputStream;\n import java.io.Closeable;\n@@ -29,12 +28,15 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-import com.linkedin.pinot.common.data.FieldSpec.DataType;\n-import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n import org.apache.commons.io.IOUtils;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n+import com.linkedin.pinot.common.data.FieldSpec.DataType;\n+import com.linkedin.pinot.common.response.ProcessingException;\n+import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n+\n \n /**\n  *\n@@ -90,7 +92,6 @@ public DataTable(int numRows, Map<String, Map<Integer, String>> dictionary,\n     fixedSizeData = ByteBuffer.wrap(fixedSizeDataBytes);\n     variableSizeData = ByteBuffer.wrap(variableSizeDataBytes);\n     columnOffsets = computeColumnOffsets(schema);\n-\n   }\n \n   /**\n@@ -107,54 +108,57 @@ public DataTable(Map<String, String> metadata) {\n    * @return\n    */\n   private int[] computeColumnOffsets(DataSchema schema) {\n+    if (schema == null) {\n+      return null;\n+    }\n     final int[] columnOffsets = new int[schema.columnNames.length];\n     for (int i = 0; i < schema.columnNames.length; i++) {\n       final DataType type = schema.columnTypes[i];\n       columnOffsets[i] = rowSizeInBytes;\n       switch (type) {\n-      case BOOLEAN:\n-        rowSizeInBytes += 1;\n-        break;\n-      case BYTE:\n-        rowSizeInBytes += 1;\n-        break;\n-      case CHAR:\n-        rowSizeInBytes += 2;\n-        break;\n-      case SHORT:\n-        rowSizeInBytes += 2;\n-        break;\n-      case INT:\n-        rowSizeInBytes += 4;\n-        break;\n-      case LONG:\n-        rowSizeInBytes += 8;\n-        break;\n-      case FLOAT:\n-        rowSizeInBytes += 8;\n-        break;\n-      case DOUBLE:\n-        rowSizeInBytes += 8;\n-        break;\n-      case STRING:\n-        rowSizeInBytes += 4;\n-        break;\n-      case OBJECT:\n-        rowSizeInBytes += 8;\n-        break;\n-      case BYTE_ARRAY:\n-      case CHAR_ARRAY:\n-      case INT_ARRAY:\n-      case LONG_ARRAY:\n-      case FLOAT_ARRAY:\n-      case SHORT_ARRAY:\n-      case DOUBLE_ARRAY:\n-      case STRING_ARRAY:\n-        rowSizeInBytes += 8;\n-        break;\n-\n-      default:\n-        throw new RuntimeException(\"Unsupported datatype:\" + type);\n+        case BOOLEAN:\n+          rowSizeInBytes += 1;\n+          break;\n+        case BYTE:\n+          rowSizeInBytes += 1;\n+          break;\n+        case CHAR:\n+          rowSizeInBytes += 2;\n+          break;\n+        case SHORT:\n+          rowSizeInBytes += 2;\n+          break;\n+        case INT:\n+          rowSizeInBytes += 4;\n+          break;\n+        case LONG:\n+          rowSizeInBytes += 8;\n+          break;\n+        case FLOAT:\n+          rowSizeInBytes += 8;\n+          break;\n+        case DOUBLE:\n+          rowSizeInBytes += 8;\n+          break;\n+        case STRING:\n+          rowSizeInBytes += 4;\n+          break;\n+        case OBJECT:\n+          rowSizeInBytes += 8;\n+          break;\n+        case BYTE_ARRAY:\n+        case CHAR_ARRAY:\n+        case INT_ARRAY:\n+        case LONG_ARRAY:\n+        case FLOAT_ARRAY:\n+        case SHORT_ARRAY:\n+        case DOUBLE_ARRAY:\n+        case STRING_ARRAY:\n+          rowSizeInBytes += 8;\n+          break;\n+\n+        default:\n+          throw new RuntimeException(\"Unsupported datatype:\" + type);\n       }\n     }\n     return columnOffsets;\n@@ -195,24 +199,24 @@ public DataTable(byte[] buffer) {\n     input.get(metadataBytes);\n     metadata = (Map<String, String>) deserialize(metadataBytes);\n \n-    // READ METADATA\n+    // READ SCHEMA\n     final byte[] schemaBytes = new byte[schemaLength];\n     input.position(schemaStart);\n     input.get(schemaBytes);\n     schema = deserialize(schemaBytes);\n     columnOffsets = computeColumnOffsets(schema);\n \n-    // READ METADATA\n+    // READ FIXED SIZE DATA BYTES \n     fixedSizeDataBytes = new byte[fixedDataLength];\n     input.position(fixedDataStart);\n     input.get(fixedSizeDataBytes);\n     fixedSizeData = ByteBuffer.wrap(fixedSizeDataBytes);\n \n+    // READ VARIABLE SIZE DATA BYTES \n     variableSizeDataBytes = new byte[variableDataLength];\n     input.position(variableDataStart);\n     input.get(variableSizeDataBytes);\n     variableSizeData = ByteBuffer.wrap(variableSizeDataBytes);\n-\n   }\n \n   public DataTable() {\n@@ -260,19 +264,31 @@ public DataTable() {\n \n     // datatable\n     out.writeInt(baseOffset);\n-    out.writeInt(fixedSizeDataBytes.length);\n-    baseOffset += fixedSizeDataBytes.length;\n+    if (fixedSizeDataBytes == null) {\n+      out.writeInt(0);\n+    } else {\n+      out.writeInt(fixedSizeDataBytes.length);\n+      baseOffset += fixedSizeDataBytes.length;\n+    }\n \n     // variable data\n     out.writeInt(baseOffset);\n-    out.writeInt(variableSizeDataBytes.length);\n+    if (variableSizeDataBytes == null) {\n+      out.writeInt(0);\n+    } else {\n+      out.writeInt(variableSizeDataBytes.length);\n+    }\n \n     // write them\n     out.write(dictionaryBytes);\n     out.write(metadataBytes);\n     out.write(schemaBytes);\n-    out.write(fixedSizeDataBytes);\n-    out.write(variableSizeDataBytes);\n+    if (fixedSizeDataBytes != null) {\n+      out.write(fixedSizeDataBytes);\n+    }\n+    if (variableSizeDataBytes != null) {\n+      out.write(variableSizeDataBytes);\n+    }\n     return baos.toByteArray();\n   }\n \n@@ -536,6 +552,7 @@ public String getString(int rowId, int colId) {\n     }\n     return ret;\n   }\n+\n   /**\n    *\n    * @param rowId\n@@ -596,6 +613,9 @@ private int positionCursorInVariableBuffer(int rowId, int colId) {\n    */\n   @Override\n   public String toString() {\n+    if (schema == null) {\n+      return metadata.toString();\n+    }\n     final StringBuilder b = new StringBuilder();\n     b.append(schema.toString());\n     b.append(\"\\n\");\n@@ -606,55 +626,62 @@ public String toString() {\n       for (int colId = 0; colId < numCols; colId++) {\n         final DataType type = schema.columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          b.append(fixedSizeData.get());\n-          break;\n-        case BYTE:\n-          b.append(fixedSizeData.get());\n-          break;\n-        case CHAR:\n-          b.append(fixedSizeData.getChar());\n-          break;\n-        case SHORT:\n-          b.append(fixedSizeData.getShort());\n-          break;\n-        case INT:\n-          b.append(fixedSizeData.getInt());\n-          break;\n-        case LONG:\n-          b.append(fixedSizeData.getLong());\n-          break;\n-        case FLOAT:\n-          b.append(fixedSizeData.getFloat());\n-          break;\n-        case DOUBLE:\n-          b.append(fixedSizeData.getDouble());\n-          break;\n-        case STRING:\n-          b.append(fixedSizeData.getInt());\n-          break;\n-        case OBJECT:\n-          b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n-              fixedSizeData.getInt()));\n-          break;\n-        case BYTE_ARRAY:\n-        case CHAR_ARRAY:\n-        case SHORT_ARRAY:\n-        case INT_ARRAY:\n-        case LONG_ARRAY:\n-        case FLOAT_ARRAY:\n-        case DOUBLE_ARRAY:\n-        case STRING_ARRAY:\n-          b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n-              fixedSizeData.getInt()));\n-          break;\n-        default:\n-          throw new RuntimeException(\"Unsupported datatype:\" + type);\n+          case BOOLEAN:\n+            b.append(fixedSizeData.get());\n+            break;\n+          case BYTE:\n+            b.append(fixedSizeData.get());\n+            break;\n+          case CHAR:\n+            b.append(fixedSizeData.getChar());\n+            break;\n+          case SHORT:\n+            b.append(fixedSizeData.getShort());\n+            break;\n+          case INT:\n+            b.append(fixedSizeData.getInt());\n+            break;\n+          case LONG:\n+            b.append(fixedSizeData.getLong());\n+            break;\n+          case FLOAT:\n+            b.append(fixedSizeData.getFloat());\n+            break;\n+          case DOUBLE:\n+            b.append(fixedSizeData.getDouble());\n+            break;\n+          case STRING:\n+            b.append(fixedSizeData.getInt());\n+            break;\n+          case OBJECT:\n+            b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n+                fixedSizeData.getInt()));\n+            break;\n+          case BYTE_ARRAY:\n+          case CHAR_ARRAY:\n+          case SHORT_ARRAY:\n+          case INT_ARRAY:\n+          case LONG_ARRAY:\n+          case FLOAT_ARRAY:\n+          case DOUBLE_ARRAY:\n+          case STRING_ARRAY:\n+            b.append(String.format(\"(%s:%s)\", fixedSizeData.getInt(),\n+                fixedSizeData.getInt()));\n+            break;\n+          default:\n+            throw new RuntimeException(\"Unsupported datatype:\" + type);\n         }\n         b.append(\"\\t\");\n       }\n       b.append(\"\\n\");\n     }\n     return b.toString();\n   }\n+\n+  public void addException(ProcessingException exception) {\n+    if (metadata == null) {\n+      metadata = new HashMap<String, String>();\n+    }\n+    metadata.put(\"Exception\" + exception.getErrorCode(), exception.getMessage());\n+  }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/main/java/com/linkedin/pinot/common/utils/DataTable.java",
                "sha": "348b83ddb5c2c214fdf62905a789e5968bcc959e",
                "status": "modified"
            },
            {
                "additions": 164,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "changes": 311,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 147,
                "filename": "pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "patch": "@@ -25,10 +25,26 @@\n import org.testng.annotations.Test;\n \n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n+import com.linkedin.pinot.common.exception.QueryException;\n+import com.linkedin.pinot.common.response.ProcessingException;\n import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n \n+\n public class TestDataTableBuilder {\n \n+  @Test\n+  public void testException() throws Exception {\n+    Exception exception = new UnsupportedOperationException(\"msg 0\");\n+    ProcessingException processingException = QueryException.EXECUTION_TIMEOUT_ERROR.deepCopy();\n+    processingException.setMessage(exception.toString());\n+    DataTable dataTable = new DataTable();\n+    dataTable.addException(processingException);\n+    byte[] bytes = dataTable.toBytes();\n+    DataTable desDataTable = new DataTable(bytes);\n+    String exceptionMsg = desDataTable.getMetadata().get(\"Exception\" + QueryException.EXECUTION_TIMEOUT_ERROR.getErrorCode());\n+    org.testng.Assert.assertEquals(exceptionMsg, exception.toString());\n+  }\n+\n   @Test\n   public void testSimple() throws Exception {\n     final DataType[] columnTypes = DataType.values();\n@@ -60,63 +76,63 @@ public void testSimple() throws Exception {\n       for (int colId = 0; colId < schema.columnNames.length; colId++) {\n         final DataType type = columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          final boolean bool = r.nextBoolean();\n-          boolArr[rowId] = bool;\n-          builder.setColumn(colId, bool);\n-          break;\n-        case CHAR:\n-          final char ch = (char) (r.nextInt(26) + 'a');\n-          cArr[rowId] = ch;\n-          builder.setColumn(colId, ch);\n-          break;\n-        case BYTE:\n-          final byte b = (byte) (r.nextInt((int) Math.pow(2, 8)));\n-          bArr[rowId] = b;\n-          builder.setColumn(colId, b);\n-\n-          break;\n-        case SHORT:\n-          final short s = (short) (r.nextInt((int) Math.pow(2, 16)));\n-          sArr[rowId] = s;\n-          builder.setColumn(colId, s);\n-\n-          break;\n-        case INT:\n-          final int i = (r.nextInt());\n-          iArr[rowId] = i;\n-          builder.setColumn(colId, i);\n-\n-          break;\n-        case LONG:\n-          final long l = (r.nextLong());\n-          lArr[rowId] = l;\n-          builder.setColumn(colId, l);\n-\n-          break;\n-        case FLOAT:\n-          final float f = (r.nextFloat());\n-          fArr[rowId] = f;\n-          builder.setColumn(colId, f);\n-          break;\n-        case DOUBLE:\n-          final double d = (r.nextDouble());\n-          dArr[rowId] = d;\n-          builder.setColumn(colId, d);\n-          break;\n-        case STRING:\n-          final String str = new BigInteger(130, r).toString(32);\n-          strArr[rowId] = str;\n-          builder.setColumn(colId, str);\n-          break;\n-        case OBJECT:\n-          final A obj = new A(r.nextInt());\n-          oArr[rowId] = obj;\n-          builder.setColumn(colId, obj);\n-\n-          break;\n-        default:\n-          break;\n+          case BOOLEAN:\n+            final boolean bool = r.nextBoolean();\n+            boolArr[rowId] = bool;\n+            builder.setColumn(colId, bool);\n+            break;\n+          case CHAR:\n+            final char ch = (char) (r.nextInt(26) + 'a');\n+            cArr[rowId] = ch;\n+            builder.setColumn(colId, ch);\n+            break;\n+          case BYTE:\n+            final byte b = (byte) (r.nextInt((int) Math.pow(2, 8)));\n+            bArr[rowId] = b;\n+            builder.setColumn(colId, b);\n+\n+            break;\n+          case SHORT:\n+            final short s = (short) (r.nextInt((int) Math.pow(2, 16)));\n+            sArr[rowId] = s;\n+            builder.setColumn(colId, s);\n+\n+            break;\n+          case INT:\n+            final int i = (r.nextInt());\n+            iArr[rowId] = i;\n+            builder.setColumn(colId, i);\n+\n+            break;\n+          case LONG:\n+            final long l = (r.nextLong());\n+            lArr[rowId] = l;\n+            builder.setColumn(colId, l);\n+\n+            break;\n+          case FLOAT:\n+            final float f = (r.nextFloat());\n+            fArr[rowId] = f;\n+            builder.setColumn(colId, f);\n+            break;\n+          case DOUBLE:\n+            final double d = (r.nextDouble());\n+            dArr[rowId] = d;\n+            builder.setColumn(colId, d);\n+            break;\n+          case STRING:\n+            final String str = new BigInteger(130, r).toString(32);\n+            strArr[rowId] = str;\n+            builder.setColumn(colId, str);\n+            break;\n+          case OBJECT:\n+            final A obj = new A(r.nextInt());\n+            oArr[rowId] = obj;\n+            builder.setColumn(colId, obj);\n+\n+            break;\n+          default:\n+            break;\n         }\n       }\n       builder.finishRow();\n@@ -133,6 +149,7 @@ public void testSimple() throws Exception {\n         fArr, lArr, dArr, strArr, oArr);\n \n   }\n+\n   @Test\n   public void testStringArray() throws Exception {\n     DataType[] columnTypes = new DataType[] { DataType.STRING_ARRAY };\n@@ -168,6 +185,7 @@ public void testStringArray() throws Exception {\n     }\n \n   }\n+\n   @Test\n   public void testIntArray() throws Exception {\n     DataType[] columnTypes = new DataType[] { DataType.INT_ARRAY };\n@@ -256,62 +274,62 @@ public void testComplexDataTypes() throws Exception {\n   private void validate(DataType type, DataTable dataTable, Object[] arr,\n       int rowId, int colId) {\n     switch (type) {\n-    case BOOLEAN:\n-      Assert.assertEquals(arr[rowId], dataTable.getBoolean(rowId, colId));\n-      break;\n-    case CHAR:\n-      Assert.assertEquals(arr[rowId], dataTable.getChar(rowId, colId));\n-      break;\n-    case BYTE:\n-      Assert.assertEquals(arr[rowId], dataTable.getByte(rowId, colId));\n-      break;\n-    case SHORT:\n-      Assert.assertEquals(arr[rowId], dataTable.getShort(rowId, colId));\n-      break;\n-    case INT:\n-      Assert.assertEquals(arr[rowId], dataTable.getInt(rowId, colId));\n-      break;\n-    case LONG:\n-      Assert.assertEquals(arr[rowId], dataTable.getLong(rowId, colId));\n-      break;\n-    case FLOAT:\n-      Assert.assertEquals(arr[rowId], dataTable.getFloat(rowId, colId));\n-      break;\n-    case DOUBLE:\n-      Assert.assertEquals(arr[rowId], dataTable.getDouble(rowId, colId));\n-      break;\n-    case STRING:\n-      Assert.assertEquals(arr[rowId], dataTable.getString(rowId, colId));\n-      break;\n-    case BYTE_ARRAY:\n-      byte[] expectedByteArray = (byte[]) arr[rowId];\n-      byte[] actualByteArray = (byte[]) dataTable.getByteArray(rowId, colId);\n-      Assert.assertEquals(expectedByteArray.length, actualByteArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedByteArray, actualByteArray));\n-      break;\n-    case CHAR_ARRAY:\n-      char[] expectedCharArray = (char[]) arr[rowId];\n-      char[] actualChartArray = (char[]) dataTable.getCharArray(rowId, colId);\n-      Assert.assertEquals(expectedCharArray.length, actualChartArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedCharArray, actualChartArray));\n-      break;\n-    case INT_ARRAY:\n-      int[] expectedIntArray = (int[]) arr[rowId];\n-      int[] actualIntArray = (int[]) dataTable.getIntArray(rowId, colId);\n-      Assert.assertEquals(expectedIntArray.length, actualIntArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedIntArray, actualIntArray));\n-      break;\n-    case STRING_ARRAY:\n-      String[] expectedStringArray = (String[]) arr[rowId];\n-      String[] actualStringArray = (String[]) dataTable.getStringArray(rowId, colId);\n-      Assert.assertEquals(expectedStringArray.length, actualStringArray.length);\n-      Assert.assertTrue(Arrays.equals(expectedStringArray, actualStringArray));\n-      break;\n-    case OBJECT:\n-      Assert.assertEquals(arr[rowId], dataTable.getObject(rowId, colId));\n-      break;\n-    default:\n-      break;\n+      case BOOLEAN:\n+        Assert.assertEquals(arr[rowId], dataTable.getBoolean(rowId, colId));\n+        break;\n+      case CHAR:\n+        Assert.assertEquals(arr[rowId], dataTable.getChar(rowId, colId));\n+        break;\n+      case BYTE:\n+        Assert.assertEquals(arr[rowId], dataTable.getByte(rowId, colId));\n+        break;\n+      case SHORT:\n+        Assert.assertEquals(arr[rowId], dataTable.getShort(rowId, colId));\n+        break;\n+      case INT:\n+        Assert.assertEquals(arr[rowId], dataTable.getInt(rowId, colId));\n+        break;\n+      case LONG:\n+        Assert.assertEquals(arr[rowId], dataTable.getLong(rowId, colId));\n+        break;\n+      case FLOAT:\n+        Assert.assertEquals(arr[rowId], dataTable.getFloat(rowId, colId));\n+        break;\n+      case DOUBLE:\n+        Assert.assertEquals(arr[rowId], dataTable.getDouble(rowId, colId));\n+        break;\n+      case STRING:\n+        Assert.assertEquals(arr[rowId], dataTable.getString(rowId, colId));\n+        break;\n+      case BYTE_ARRAY:\n+        byte[] expectedByteArray = (byte[]) arr[rowId];\n+        byte[] actualByteArray = (byte[]) dataTable.getByteArray(rowId, colId);\n+        Assert.assertEquals(expectedByteArray.length, actualByteArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedByteArray, actualByteArray));\n+        break;\n+      case CHAR_ARRAY:\n+        char[] expectedCharArray = (char[]) arr[rowId];\n+        char[] actualChartArray = (char[]) dataTable.getCharArray(rowId, colId);\n+        Assert.assertEquals(expectedCharArray.length, actualChartArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedCharArray, actualChartArray));\n+        break;\n+      case INT_ARRAY:\n+        int[] expectedIntArray = (int[]) arr[rowId];\n+        int[] actualIntArray = (int[]) dataTable.getIntArray(rowId, colId);\n+        Assert.assertEquals(expectedIntArray.length, actualIntArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedIntArray, actualIntArray));\n+        break;\n+      case STRING_ARRAY:\n+        String[] expectedStringArray = (String[]) arr[rowId];\n+        String[] actualStringArray = (String[]) dataTable.getStringArray(rowId, colId);\n+        Assert.assertEquals(expectedStringArray.length, actualStringArray.length);\n+        Assert.assertTrue(Arrays.equals(expectedStringArray, actualStringArray));\n+        break;\n+      case OBJECT:\n+        Assert.assertEquals(arr[rowId], dataTable.getObject(rowId, colId));\n+        break;\n+      default:\n+        break;\n     }\n   }\n \n@@ -322,39 +340,39 @@ private void validate(DataTable dataTable, int numRows, DataSchema schema,\n       for (int colId = 0; colId < schema.columnNames.length; colId++) {\n         final DataType type = schema.columnTypes[colId];\n         switch (type) {\n-        case BOOLEAN:\n-          Assert.assertEquals(boolArr[rowId],\n-              dataTable.getBoolean(rowId, colId));\n-          break;\n-        case CHAR:\n-          Assert.assertEquals(cArr[rowId], dataTable.getChar(rowId, colId));\n-          break;\n-        case BYTE:\n-          Assert.assertEquals(bArr[rowId], dataTable.getByte(rowId, colId));\n-          break;\n-        case SHORT:\n-          Assert.assertEquals(sArr[rowId], dataTable.getShort(rowId, colId));\n-          break;\n-        case INT:\n-          Assert.assertEquals(iArr[rowId], dataTable.getInt(rowId, colId));\n-          break;\n-        case LONG:\n-          Assert.assertEquals(lArr[rowId], dataTable.getLong(rowId, colId));\n-          break;\n-        case FLOAT:\n-          Assert.assertEquals(fArr[rowId], dataTable.getFloat(rowId, colId));\n-          break;\n-        case DOUBLE:\n-          Assert.assertEquals(dArr[rowId], dataTable.getDouble(rowId, colId));\n-          break;\n-        case STRING:\n-          Assert.assertEquals(strArr[rowId], dataTable.getString(rowId, colId));\n-          break;\n-        case OBJECT:\n-          Assert.assertEquals(oArr[rowId], dataTable.getObject(rowId, colId));\n-          break;\n-        default:\n-          break;\n+          case BOOLEAN:\n+            Assert.assertEquals(boolArr[rowId],\n+                dataTable.getBoolean(rowId, colId));\n+            break;\n+          case CHAR:\n+            Assert.assertEquals(cArr[rowId], dataTable.getChar(rowId, colId));\n+            break;\n+          case BYTE:\n+            Assert.assertEquals(bArr[rowId], dataTable.getByte(rowId, colId));\n+            break;\n+          case SHORT:\n+            Assert.assertEquals(sArr[rowId], dataTable.getShort(rowId, colId));\n+            break;\n+          case INT:\n+            Assert.assertEquals(iArr[rowId], dataTable.getInt(rowId, colId));\n+            break;\n+          case LONG:\n+            Assert.assertEquals(lArr[rowId], dataTable.getLong(rowId, colId));\n+            break;\n+          case FLOAT:\n+            Assert.assertEquals(fArr[rowId], dataTable.getFloat(rowId, colId));\n+            break;\n+          case DOUBLE:\n+            Assert.assertEquals(dArr[rowId], dataTable.getDouble(rowId, colId));\n+            break;\n+          case STRING:\n+            Assert.assertEquals(strArr[rowId], dataTable.getString(rowId, colId));\n+            break;\n+          case OBJECT:\n+            Assert.assertEquals(oArr[rowId], dataTable.getObject(rowId, colId));\n+            break;\n+          default:\n+            break;\n         }\n       }\n     }\n@@ -376,6 +394,5 @@ public boolean equals(Object obj) {\n     public int hashCode() {\n       return new Integer(i).hashCode();\n     }\n-\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-common/src/test/java/com/linkedin/pinot/common/utils/TestDataTableBuilder.java",
                "sha": "b0bdcf02fee4ff46810e1656229a11edc2a439ea",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "patch": "@@ -131,6 +131,9 @@ public DataTable getDataTable() throws Exception {\n     if (_selectionResult != null) {\n       return getSelectionResultDataTable();\n     }\n+    if (_processingExceptions != null && _processingExceptions.size() > 0) {\n+      return getExceptionsDataTable();\n+    }\n     throw new UnsupportedOperationException(\"Cannot get DataTable from IntermediateResultBlock!\");\n   }\n \n@@ -139,9 +142,18 @@ public DataTable attachMetadataToDataTable(DataTable dataTable) {\n     dataTable.getMetadata().put(NUM_DOCS_SCANNED, _numDocsScanned + \"\");\n     dataTable.getMetadata().put(TIME_USED_MS, _timeUsedMs + \"\");\n     dataTable.getMetadata().put(TOTAL_DOCS, _totalDocs + \"\");\n+    if (_processingExceptions != null && _processingExceptions.size() > 0) {\n+      for (int i = 0; i < _processingExceptions.size(); ++i) {\n+        dataTable.addException(_processingExceptions.get(i));\n+      }\n+    }\n     return dataTable;\n   }\n \n+  public DataTable getExceptionsDataTable() {\n+    return attachMetadataToDataTable(new DataTable());\n+  }\n+\n   private DataTable getSelectionResultDataTable() throws Exception {\n     return attachMetadataToDataTable(SelectionOperatorUtils.getDataTableFromRowSet(_selectionResult, _dataSchema));\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/block/query/IntermediateResultsBlock.java",
                "sha": "a58bd3046369e850362f8584656bf09b928a5168",
                "status": "modified"
            },
            {
                "additions": 59,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "changes": 91,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 32,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "patch": "@@ -17,6 +17,8 @@\n \n import java.util.ArrayList;\n import java.util.List;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n@@ -99,35 +101,65 @@ public boolean open() {\n \n   @Override\n   public Block nextBlock() {\n-    long start = System.currentTimeMillis();\n+    final long startTime = System.currentTimeMillis();\n     if (_isParallel) {\n-      long queryEndTime = System.currentTimeMillis() + _timeOutMs;\n+      final long queryEndTime = System.currentTimeMillis() + _timeOutMs;\n+      final BlockingQueue<Block> blockingQueue = new ArrayBlockingQueue<Block>(_operators.size());\n \n-      @SuppressWarnings(\"rawtypes\")\n-      List<Future> blocks = new ArrayList<Future>();\n+      // Submit operators.\n       for (final Operator operator : _operators) {\n-        blocks.add(_executorService.submit(new Callable<Block>() {\n+        _executorService.submit(new Runnable() {\n           @Override\n-          public Block call() throws Exception {\n-            return operator.nextBlock();\n+          public void run() {\n+            Block retBlock;\n+            try {\n+              retBlock = operator.nextBlock();\n+            } catch (Exception e) {\n+              retBlock = new IntermediateResultsBlock(e);\n+            }\n+            if (blockingQueue != null) {\n+              blockingQueue.offer(retBlock);\n+            }\n           }\n-        }));\n+        });\n       }\n-      LOGGER.debug(\"Submitting operators to be run in parallel and it took:\" + (System.currentTimeMillis() - start));\n+      LOGGER.debug(\"Submitting operators to be run in parallel and it took:\" + (System.currentTimeMillis() - startTime));\n+\n+      // Submit merger job:\n+      Future<IntermediateResultsBlock> mergedBlockFuture =\n+          _executorService.submit(new Callable<IntermediateResultsBlock>() {\n+            @Override\n+            public IntermediateResultsBlock call() throws Exception {\n+              int mergedBlocksNumber = 0;\n+              IntermediateResultsBlock mergedBlock = null;\n+              while ((queryEndTime > System.currentTimeMillis()) && (mergedBlocksNumber < _operators.size())) {\n+                if (mergedBlock == null) {\n+                  mergedBlock = (IntermediateResultsBlock) blockingQueue.poll(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n+                  if (mergedBlock != null) {\n+                    mergedBlocksNumber++;\n+                  }\n+                  LOGGER.debug(\"Got response from operator 0 after: {}\", (System.currentTimeMillis() - startTime));\n+                } else {\n+                  IntermediateResultsBlock blockToMerge = (IntermediateResultsBlock) blockingQueue.poll(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n+                  if (blockToMerge != null) {\n+                    try {\n+                      LOGGER.debug(\"Got response from operator {} after: {}\", mergedBlocksNumber, (System.currentTimeMillis() - startTime));\n+                      CombineService.mergeTwoBlocks(_brokerRequest, mergedBlock, blockToMerge);\n+                      LOGGER.debug(\"Merged response from operator {} after: {}\", mergedBlocksNumber, (System.currentTimeMillis() - startTime));\n+                    } catch (Exception e) {\n+                      mergedBlock.getExceptions().add(QueryException.getException(QueryException.MERGE_RESPONSE_ERROR, e));\n+                    }\n+                    mergedBlocksNumber++;\n+                  }\n+                }\n+              }\n+              return mergedBlock;\n+            }\n+          });\n+\n+      // Get merge results.\n       try {\n-        _mergedBlock =\n-            (IntermediateResultsBlock) blocks.get(0).get(queryEndTime - System.currentTimeMillis(),\n-                TimeUnit.MILLISECONDS);\n-        LOGGER.debug(\"Got response from operator 0 after: \" + (System.currentTimeMillis() - start));\n-\n-        for (int i = 1; i < blocks.size(); ++i) {\n-          IntermediateResultsBlock blockToMerge =\n-              (IntermediateResultsBlock) blocks.get(i).get(queryEndTime - System.currentTimeMillis(),\n-                  TimeUnit.MILLISECONDS);\n-          LOGGER.debug(\"Got response from operator \" + i + \" after: \" + (System.currentTimeMillis() - start));\n-          CombineService.mergeTwoBlocks(_brokerRequest, _mergedBlock, blockToMerge);\n-          LOGGER.debug(\"Merged response from operator \" + i + \" after: \" + (System.currentTimeMillis() - start));\n-        }\n+        _mergedBlock = mergedBlockFuture.get(queryEndTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n       } catch (InterruptedException e) {\n         LOGGER.error(\"InterruptedException \", e);\n         if (_mergedBlock == null) {\n@@ -137,9 +169,7 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.FUTURE_CALL_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.FUTURE_CALL_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       } catch (ExecutionException e) {\n         LOGGER.error(\"Execution Exception\", e);\n@@ -150,9 +180,7 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.QUERY_EXECUTION_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.MERGE_RESPONSE_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       } catch (TimeoutException e) {\n         LOGGER.error(\"TimeoutException \", e);\n@@ -163,11 +191,10 @@ public Block call() throws Exception {\n         if (exceptions == null) {\n           exceptions = new ArrayList<ProcessingException>();\n         }\n-        ProcessingException exception = QueryException.EXECUTION_TIMEOUT_ERROR.deepCopy();\n-        exception.setMessage(e.getMessage());\n-        exceptions.add(exception);\n+        exceptions.add(QueryException.getException(QueryException.EXECUTION_TIMEOUT_ERROR, e));\n         _mergedBlock.setExceptionsList(exceptions);\n       }\n+\n     } else {\n       for (Operator operator : _operators) {\n         if ((operator instanceof MAggregationOperator) || (operator instanceof MSelectionOrderByOperator) || (operator instanceof MSelectionOnlyOperator)\n@@ -189,7 +216,7 @@ public Block call() throws Exception {\n       trimToSize(_brokerRequest, _mergedBlock);\n     }\n     long end = System.currentTimeMillis();\n-    LOGGER.info(\"Time spent in MCombineOperator:\" + (end - start));\n+    LOGGER.info(\"Time spent in MCombineOperator:\" + (end - startTime));\n \n     return _mergedBlock;\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/MCombineOperator.java",
                "sha": "3813f8be7438ddc23a1840285f8a82c4e3d3e1d5",
                "status": "modified"
            },
            {
                "additions": 20,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "changes": 59,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 39,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "patch": "@@ -18,14 +18,11 @@\n import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.List;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.request.Selection;\n-import com.linkedin.pinot.common.response.ProcessingException;\n import com.linkedin.pinot.common.utils.DataTableBuilder.DataSchema;\n import com.linkedin.pinot.core.block.query.IntermediateResultsBlock;\n import com.linkedin.pinot.core.block.query.ProjectionBlock;\n@@ -82,45 +79,29 @@ public Block nextBlock() {\n \n     long numDocsScanned = 0;\n     ProjectionBlock projectionBlock = null;\n-    try {\n-      while ((projectionBlock = (ProjectionBlock) _projectionOperator.nextBlock()) != null) {\n-        int j = 0;\n-        for (int i = 0; i < _dataSchema.size(); ++i) {\n-          _blocks[j++] = projectionBlock.getBlock(_dataSchema.getColumnName(i));\n-        }\n-        BlockDocIdIterator blockDocIdIterator = projectionBlock.getDocIdSetBlock().getBlockDocIdSet().iterator();\n-        int docId;\n-        while ((docId = blockDocIdIterator.next()) != Constants.EOF && _rowEvents.size() < _limitDocs) {\n-          numDocsScanned++;\n-          _rowEvents.add(SelectionOperatorUtils.collectRowFromBlockValSets(docId, _blocks, _dataSchema));\n-        }\n+    while ((projectionBlock = (ProjectionBlock) _projectionOperator.nextBlock()) != null) {\n+      int j = 0;\n+      for (int i = 0; i < _dataSchema.size(); ++i) {\n+        _blocks[j++] = projectionBlock.getBlock(_dataSchema.getColumnName(i));\n+      }\n+      BlockDocIdIterator blockDocIdIterator = projectionBlock.getDocIdSetBlock().getBlockDocIdSet().iterator();\n+      int docId;\n+      while ((docId = blockDocIdIterator.next()) != Constants.EOF && _rowEvents.size() < _limitDocs) {\n+        numDocsScanned++;\n+        _rowEvents.add(SelectionOperatorUtils.collectRowFromBlockValSets(docId, _blocks, _dataSchema));\n       }\n-\n-      final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n-      resultBlock.setSelectionResult(_rowEvents);\n-      resultBlock.setSelectionDataSchema(_dataSchema);\n-      resultBlock.setNumDocsScanned(numDocsScanned);\n-      resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n-      final long endTime = System.currentTimeMillis();\n-      resultBlock.setTimeUsedMs(endTime - startTime);\n-      LOGGER.debug(\"Time spent in MSelectionOnlyOperator:\" + (endTime - startTime));\n-      return resultBlock;\n-    } catch (Exception e) {\n-      LOGGER.warn(\"Caught exception while processing selection operator\", e);\n-      final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n-\n-      List<ProcessingException> processingExceptions = new ArrayList<ProcessingException>();\n-      ProcessingException exception = QueryException.QUERY_EXECUTION_ERROR.deepCopy();\n-      exception.setMessage(e.getMessage());\n-      processingExceptions.add(exception);\n-\n-      resultBlock.setExceptionsList(processingExceptions);\n-      resultBlock.setNumDocsScanned(0);\n-      resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n-      resultBlock.setTimeUsedMs(System.currentTimeMillis() - startTime);\n-      return resultBlock;\n     }\n \n+    final IntermediateResultsBlock resultBlock = new IntermediateResultsBlock();\n+    resultBlock.setSelectionResult(_rowEvents);\n+    resultBlock.setSelectionDataSchema(_dataSchema);\n+    resultBlock.setNumDocsScanned(numDocsScanned);\n+    resultBlock.setTotalDocs(_indexSegment.getTotalDocs());\n+    final long endTime = System.currentTimeMillis();\n+    resultBlock.setTimeUsedMs(endTime - startTime);\n+    LOGGER.debug(\"Time spent in MSelectionOnlyOperator:\" + (endTime - startTime));\n+    return resultBlock;\n+\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/operator/query/MSelectionOnlyOperator.java",
                "sha": "af9f6e2ca1e02e1aeea5860e6ab487cfd381cb6c",
                "status": "modified"
            },
            {
                "additions": 28,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "changes": 30,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "patch": "@@ -41,7 +41,14 @@\n \n   public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResultsBlock mergedBlock,\n       IntermediateResultsBlock blockToMerge) {\n-\n+    // Sanity check\n+    if (blockToMerge == null) {\n+      return;\n+    }\n+    if (mergedBlock == null) {\n+      mergedBlock = blockToMerge;\n+      return;\n+    }\n     // Combine NumDocsScanned\n     mergedBlock.setNumDocsScanned(mergedBlock.getNumDocsScanned() + blockToMerge.getNumDocsScanned());\n     // Combine TotalDocs\n@@ -83,6 +90,13 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static List<Map<String, Serializable>> combineAggregationGroupByResults1(BrokerRequest brokerRequest,\n       List<Map<String, Serializable>> list1, List<Map<String, Serializable>> list2) {\n+    if (list1 == null) {\n+      return list2;\n+    }\n+    if (list2 == null) {\n+      return list1;\n+    }\n+\n     for (int i = 0; i < list1.size(); ++i) {\n       list1.set(i, mergeTwoGroupedResults(brokerRequest.getAggregationsInfo().get(i), list1.get(i), list2.get(i)));\n     }\n@@ -93,6 +107,13 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static Map<String, Serializable> mergeTwoGroupedResults(AggregationInfo aggregationInfo,\n       Map<String, Serializable> map1, Map<String, Serializable> map2) {\n+    if (map1 == null) {\n+      return map2;\n+    }\n+    if (map2 == null) {\n+      return map1;\n+    }\n+\n     AggregationFunction aggregationFunction = AggregationFunctionFactory.get(aggregationInfo, true);\n     for (String key : map2.keySet()) {\n       if (map1.containsKey(key)) {\n@@ -106,7 +127,12 @@ public static void mergeTwoBlocks(BrokerRequest brokerRequest, IntermediateResul\n \n   private static List<Serializable> combineAggregationResults(BrokerRequest brokerRequest,\n       List<Serializable> aggregationResult1, List<Serializable> aggregationResult2) {\n-\n+    if (aggregationResult1 == null) {\n+      return aggregationResult2;\n+    }\n+    if (aggregationResult2 == null) {\n+      return aggregationResult1;\n+    }\n     List<List<Serializable>> aggregationResultsList = new ArrayList<List<Serializable>>();\n \n     for (int i = 0; i < brokerRequest.getAggregationsInfoSize(); ++i) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/CombineService.java",
                "sha": "f5128b38600c1769971a239d21f03efbc25e1de6",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "changes": 28,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 11,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "patch": "@@ -15,7 +15,6 @@\n  */\n package com.linkedin.pinot.core.query.aggregation.groupby;\n \n-import com.linkedin.pinot.common.Utils;\n import it.unimi.dsi.fastutil.PriorityQueue;\n import it.unimi.dsi.fastutil.objects.ObjectArrayPriorityQueue;\n \n@@ -31,7 +30,10 @@\n import org.json.JSONArray;\n import org.json.JSONException;\n import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n import com.linkedin.pinot.common.data.FieldSpec.DataType;\n import com.linkedin.pinot.common.request.AggregationInfo;\n import com.linkedin.pinot.common.request.GroupBy;\n@@ -40,8 +42,6 @@\n import com.linkedin.pinot.core.query.aggregation.AggregationFunction;\n import com.linkedin.pinot.core.query.aggregation.AggregationFunctionFactory;\n import com.linkedin.pinot.core.query.utils.Pair;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n \n \n /**\n@@ -91,7 +91,9 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n     List<Map<String, Serializable>> reducedResult = null;\n     for (DataTable toBeReducedGroupByResults : instanceResponseMap.values()) {\n       if (reducedResult == null) {\n-        reducedResult = transformDataTableToGroupByResult(toBeReducedGroupByResults);\n+        if (toBeReducedGroupByResults != null) {\n+          reducedResult = transformDataTableToGroupByResult(toBeReducedGroupByResults);\n+        }\n       } else {\n         List<Map<String, Serializable>> toBeReducedResult =\n             transformDataTableToGroupByResult(toBeReducedGroupByResults);\n@@ -109,12 +111,14 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n         }\n       }\n     }\n-    for (int i = 0; i < reducedResult.size(); ++i) {\n-      Map<String, Serializable> functionLevelReducedResult = reducedResult.get(i);\n-      for (String key : functionLevelReducedResult.keySet()) {\n-        if (functionLevelReducedResult.get(key) != null) {\n-          functionLevelReducedResult.put(key,\n-              _aggregationFunctionList.get(i).reduce(Arrays.asList(functionLevelReducedResult.get(key))));\n+    if (reducedResult != null) {\n+      for (int i = 0; i < reducedResult.size(); ++i) {\n+        Map<String, Serializable> functionLevelReducedResult = reducedResult.get(i);\n+        for (String key : functionLevelReducedResult.keySet()) {\n+          if (functionLevelReducedResult.get(key) != null) {\n+            functionLevelReducedResult.put(key,\n+                _aggregationFunctionList.get(i).reduce(Arrays.asList(functionLevelReducedResult.get(key))));\n+          }\n         }\n       }\n     }\n@@ -123,7 +127,9 @@ public AggregationGroupByOperatorService(List<AggregationInfo> aggregationInfos,\n \n   public List<JSONObject> renderGroupByOperators(List<Map<String, Serializable>> finalAggregationResult) {\n     try {\n-\n+      if (finalAggregationResult == null || finalAggregationResult.size() != _aggregationFunctionList.size()) {\n+        return null;\n+      }\n       List<JSONObject> retJsonResultList = new ArrayList<JSONObject>();\n       for (int i = 0; i < _aggregationFunctionList.size(); ++i) {\n         DecimalFormat df = DEFAULT_FORMAT_STRING_MAP.get(_aggregationFunctionList.get(i).aggregateResultDataType());",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/aggregation/groupby/AggregationGroupByOperatorService.java",
                "sha": "db0a27e6438f18a9a92af891bce65906ca626b64",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 5,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "patch": "@@ -29,6 +29,7 @@\n import org.slf4j.LoggerFactory;\n \n import com.linkedin.pinot.common.data.DataManager;\n+import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.metrics.ServerMeter;\n import com.linkedin.pinot.common.metrics.ServerMetrics;\n import com.linkedin.pinot.common.metrics.ServerQueryPhase;\n@@ -101,8 +102,8 @@ public void init(Configuration queryExecutorConfig, DataManager dataManager, Ser\n   @Override\n   public DataTable processQuery(final InstanceRequest instanceRequest) {\n     DataTable instanceResponse;\n+    long start = System.currentTimeMillis();\n     try {\n-      long start = System.currentTimeMillis();\n       final BrokerRequest brokerRequest = instanceRequest.getQuery();\n       LOGGER.info(\"Incoming query is :\" + brokerRequest);\n       final List<IndexSegment> queryableSegmentDataManagerList = _serverMetrics.timePhase(brokerRequest,\n@@ -127,6 +128,7 @@ public Plan call() throws Exception {\n               getResourceTimeOut(instanceRequest.getQuery()));\n         }\n       });\n+\n       if (_printQueryPlan) {\n         LOGGER.debug(\"***************************** Query Plan for Request \" + instanceRequest.getRequestId() + \"***********************************\");\n         globalQueryPlan.print();\n@@ -142,21 +144,28 @@ public Object call()\n       });\n       instanceResponse = globalQueryPlan.getInstanceResponse();\n       long end = System.currentTimeMillis();\n-      LOGGER.info(\"Searching Instance for Request Id - \" + instanceRequest.getRequestId() + \", browse took: \" + (end - start));\n-      LOGGER.debug(\"InstanceResponse for Request Id - \" + instanceRequest.getRequestId() + \" : \" + instanceResponse.toString());\n+      LOGGER.info(\"Searching Instance for Request Id - {}, browse took: {}\", instanceRequest.getRequestId(), (end - start));\n+      LOGGER.debug(\"InstanceResponse for Request Id - {} : {}\", instanceRequest.getRequestId(), instanceResponse.toString());\n       instanceResponse.getMetadata().put(\"timeUsedMs\", Long.toString((end - start)));\n       instanceResponse.getMetadata().put(\"requestId\", Long.toString(instanceRequest.getRequestId()));\n+      return instanceResponse;\n     } catch (Exception e) {\n       _serverMetrics.addMeteredValue(instanceRequest.getQuery(), ServerMeter.QUERY_EXECUTION_EXCEPTIONS, 1);\n       LOGGER.error(e.getMessage(), e);\n-      instanceResponse = null;\n+      instanceResponse = new DataTable();\n+      instanceResponse.addException(QueryException.getException(QueryException.QUERY_EXECUTION_ERROR, e));\n+      long end = System.currentTimeMillis();\n+      LOGGER.info(\"Searching Instance for Request Id - {}, browse took: {}\", instanceRequest.getRequestId(), (end - start));\n+      LOGGER.debug(\"InstanceResponse for Request Id - {} : {}\", instanceRequest.getRequestId(), instanceResponse.toString());\n+      instanceResponse.getMetadata().put(\"timeUsedMs\", Long.toString((end - start)));\n+      instanceResponse.getMetadata().put(\"requestId\", Long.toString(instanceRequest.getRequestId()));\n+      return instanceResponse;\n     } finally {\n       if (_instanceDataManager.getResourceDataManager(instanceRequest.getQuery().getQuerySource().getResourceName()) != null) {\n         _instanceDataManager.getResourceDataManager(instanceRequest.getQuery().getQuerySource().getResourceName())\n             .returnSegmentReaders(instanceRequest.getSearchSegments());\n       }\n     }\n-    return instanceResponse;\n   }\n \n   private List<IndexSegment> getPrunedQueryableSegments(final InstanceRequest instanceRequest) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/executor/ServerQueryExecutorV1Impl.java",
                "sha": "8825e161f69d927080caaa3c5bce3e834629b5ad",
                "status": "modified"
            },
            {
                "additions": 52,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "changes": 81,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 29,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "patch": "@@ -15,8 +15,6 @@\n  */\n package com.linkedin.pinot.core.query.reduce;\n \n-import com.linkedin.pinot.common.Utils;\n-\n import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.Collection;\n@@ -25,7 +23,11 @@\n \n import org.json.JSONException;\n import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.Utils;\n+import com.linkedin.pinot.common.exception.QueryException;\n import com.linkedin.pinot.common.query.ReduceService;\n import com.linkedin.pinot.common.request.BrokerRequest;\n import com.linkedin.pinot.common.response.AggregationResult;\n@@ -42,9 +44,6 @@\n import com.linkedin.pinot.core.query.selection.SelectionOperatorService;\n import com.linkedin.pinot.core.query.selection.SelectionOperatorUtils;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n \n /**\n  * DefaultReduceService will reduce DataTables gathered from multiple instances\n@@ -123,8 +122,24 @@ public BrokerResponse reduceOnDataTable(BrokerRequest brokerRequest,\n     if (instanceResponseMap == null || instanceResponseMap.size() == 0) {\n       return BrokerResponse.EMPTY_RESULT;\n     }\n-    for (ServerInstance serverInstance : instanceResponseMap.keySet()) {\n+    for (ServerInstance serverInstance : instanceResponseMap.keySet().toArray(new ServerInstance[instanceResponseMap.size()])) {\n       DataTable instanceResponse = instanceResponseMap.get(serverInstance);\n+      if (instanceResponse == null) {\n+        continue;\n+      }\n+      if (instanceResponse.getDataSchema() == null && instanceResponse.getMetadata() != null) {\n+        for (String key : instanceResponse.getMetadata().keySet()) {\n+          if (key.startsWith(\"Exception\")) {\n+            ProcessingException processingException = new ProcessingException();\n+            processingException.setErrorCode(Integer.parseInt(key.substring(9)));\n+            processingException.setMessage(instanceResponse.getMetadata().get(key));\n+            brokerResponse.addToExceptions(processingException);\n+          }\n+        }\n+        instanceResponseMap.remove(serverInstance);\n+        continue;\n+      }\n+\n       // reduceOnNumDocsScanned\n       brokerResponse.setNumDocsScanned(brokerResponse.getNumDocsScanned()\n           + Long.parseLong(instanceResponse.getMetadata().get(NUM_DOCS_SCANNED)));\n@@ -135,35 +150,40 @@ public BrokerResponse reduceOnDataTable(BrokerRequest brokerRequest,\n         brokerResponse.setTimeUsedMs(Long.parseLong(instanceResponse.getMetadata().get(TIME_USED_MS)));\n       }\n     }\n+    try {\n \n-    if (brokerRequest.isSetSelections() && (brokerRequest.getSelections().getSelectionColumns() != null)\n-        && (brokerRequest.getSelections().getSelectionColumns().size() >= 0)) {\n-      // Reduce DataTable for selection query.\n-      JSONObject selectionRet = reduceOnSelectionResults(brokerRequest, instanceResponseMap);\n-      brokerResponse.setSelectionResults(selectionRet);\n-      return brokerResponse;\n-    }\n-    if (brokerRequest.isSetAggregationsInfo()) {\n-      if (!brokerRequest.isSetGroupBy()) {\n-        List<List<Serializable>> aggregationResultsList =\n-            getShuffledAggregationResults(brokerRequest, instanceResponseMap);\n-        brokerResponse.setAggregationResults(reduceOnAggregationResults(brokerRequest, aggregationResultsList));\n-      } else {\n-        // Reduce DataTable for aggregation groupby query.\n-        //        GroupByAggregationService groupByAggregationService =\n-        //            new GroupByAggregationService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n-        //        brokerResponse.setAggregationResults(reduceOnAggregationGroupByResults(groupByAggregationService,\n-        //            instanceResponseMap));\n+      if (brokerRequest.isSetSelections() && (brokerRequest.getSelections().getSelectionColumns() != null)\n+          && (brokerRequest.getSelections().getSelectionColumns().size() >= 0)) {\n+        // Reduce DataTable for selection query.\n+        JSONObject selectionRet = reduceOnSelectionResults(brokerRequest, instanceResponseMap);\n+        brokerResponse.setSelectionResults(selectionRet);\n+        return brokerResponse;\n+      }\n+      if (brokerRequest.isSetAggregationsInfo()) {\n+        if (!brokerRequest.isSetGroupBy()) {\n+          List<List<Serializable>> aggregationResultsList =\n+              getShuffledAggregationResults(brokerRequest, instanceResponseMap);\n+          brokerResponse.setAggregationResults(reduceOnAggregationResults(brokerRequest, aggregationResultsList));\n+        } else {\n+          // Reduce DataTable for aggregation groupby query.\n+          //        GroupByAggregationService groupByAggregationService =\n+          //            new GroupByAggregationService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n+          //        brokerResponse.setAggregationResults(reduceOnAggregationGroupByResults(groupByAggregationService,\n+          //            instanceResponseMap));\n \n-        AggregationGroupByOperatorService aggregationGroupByOperatorService =\n-            new AggregationGroupByOperatorService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n-        brokerResponse.setAggregationResults(reduceOnAggregationGroupByOperatorResults(\n-            aggregationGroupByOperatorService, instanceResponseMap));\n+          AggregationGroupByOperatorService aggregationGroupByOperatorService =\n+              new AggregationGroupByOperatorService(brokerRequest.getAggregationsInfo(), brokerRequest.getGroupBy());\n+          brokerResponse.setAggregationResults(reduceOnAggregationGroupByOperatorResults(\n+              aggregationGroupByOperatorService, instanceResponseMap));\n \n+        }\n+        return brokerResponse;\n       }\n+\n+    } catch (Exception e) {\n+      brokerResponse.addToExceptions(QueryException.getException(QueryException.BROKER_GATHER_ERROR, e));\n       return brokerResponse;\n     }\n-\n     throw new UnsupportedOperationException(\n         \"Should not reach here, the query has no attributes of selection or aggregation!\");\n   }\n@@ -226,6 +246,9 @@ private JSONObject reduceOnSelectionResults(BrokerRequest brokerRequest,\n     for (ServerInstance serverInstance : instanceResponseMap.keySet()) {\n       DataTable instanceResponse = instanceResponseMap.get(serverInstance);\n       aggregationResultSchema = instanceResponse.getDataSchema();\n+      if (aggregationResultSchema == null) {\n+        continue;\n+      }\n       // Shuffle AggregationResults\n       for (int rowId = 0; rowId < instanceResponse.getNumberOfRows(); ++rowId) {\n         for (int colId = 0; colId < brokerRequest.getAggregationsInfoSize(); ++colId) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/reduce/DefaultReduceService.java",
                "sha": "91b40dc30da8e196004f8cbce7ce1ecbbf3312f7",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "changes": 6,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "patch": "@@ -173,6 +173,12 @@ public SelectionOperatorService(Selection selections, DataSchema dataSchema) {\n \n   public Collection<Serializable[]> merge(Collection<Serializable[]> rowEventsSet1,\n       Collection<Serializable[]> rowEventsSet2) {\n+    if (rowEventsSet1 == null) {\n+      return rowEventsSet2;\n+    }\n+    if (rowEventsSet2 == null) {\n+      return rowEventsSet1;\n+    }\n     if (_doOrdering) {\n       PriorityQueue<Serializable[]> queue1 = (PriorityQueue<Serializable[]>) rowEventsSet1;\n       PriorityQueue<Serializable[]> queue2 = (PriorityQueue<Serializable[]>) rowEventsSet2;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorService.java",
                "sha": "3a1627e7e8a8f5da90c751444222d66c40177c2f",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 9,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "patch": "@@ -53,8 +53,8 @@\n import com.linkedin.pinot.core.realtime.impl.dictionary.LongMutableDictionary;\n import com.linkedin.pinot.core.realtime.impl.dictionary.StringMutableDictionary;\n import com.linkedin.pinot.core.segment.index.data.source.mv.block.MultiValueBlock;\n-import com.linkedin.pinot.core.segment.index.data.source.sv.block.UnSortedSingleValueBlock;\n import com.linkedin.pinot.core.segment.index.data.source.sv.block.SortedSingleValueBlock;\n+import com.linkedin.pinot.core.segment.index.data.source.sv.block.UnSortedSingleValueBlock;\n import com.linkedin.pinot.core.segment.index.readers.Dictionary;\n import com.linkedin.pinot.core.segment.index.readers.DoubleDictionary;\n import com.linkedin.pinot.core.segment.index.readers.FloatDictionary;\n@@ -120,6 +120,12 @@\n \n   public static Collection<Serializable[]> merge(Collection<Serializable[]> rowEventsSet1,\n       Collection<Serializable[]> rowEventsSet2, int maxRowSize) {\n+    if (rowEventsSet1 == null) {\n+      return rowEventsSet2;\n+    }\n+    if (rowEventsSet2 == null) {\n+      return rowEventsSet1;\n+    }\n     final Iterator<Serializable[]> iterator = rowEventsSet2.iterator();\n     while (rowEventsSet1.size() < maxRowSize && iterator.hasNext()) {\n       final Serializable[] row = iterator.next();\n@@ -130,15 +136,10 @@\n \n   public static Collection<Serializable[]> reduce(Map<ServerInstance, DataTable> selectionResults, int maxRowSize) {\n     Collection<Serializable[]> rowEventsSet = new ArrayList<Serializable[]>();\n-\n     for (final DataTable dt : selectionResults.values()) {\n-      for (int rowId = 0; rowId < dt.getNumberOfRows(); ++rowId) {\n+      for (int rowId = 0; rowId < Math.min(dt.getNumberOfRows(), maxRowSize); ++rowId) {\n         final Serializable[] row = extractRowFromDataTable(dt, rowId);\n-        if (rowEventsSet.size() < maxRowSize) {\n-          rowEventsSet.add(row);\n-        } else {\n-          break;\n-        }\n+        rowEventsSet.add(row);\n       }\n     }\n     return rowEventsSet;\n@@ -202,7 +203,7 @@ public static DataSchema extractDataSchema(List<SelectionSort> sortSequence, Lis\n     return new DataSchema(columns.toArray(new String[0]), dataTypes);\n   }\n \n-  public static Serializable[] collectRowFromBlockValSets(int docId, Block[] blocks, DataSchema dataSchema) throws Exception {\n+  public static Serializable[] collectRowFromBlockValSets(int docId, Block[] blocks, DataSchema dataSchema) {\n \n     final Serializable[] row = new Serializable[dataSchema.size()];\n     int j = 0;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/main/java/com/linkedin/pinot/core/query/selection/SelectionOperatorUtils.java",
                "sha": "4cb37776f844260192d20e5a006f34912da1c104",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 1,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "patch": "@@ -77,7 +77,6 @@\n   private final String AVRO_DATA = \"data/mirror-mv.avro\";\n   private static File INDEX_DIR = new File(FileUtils.getTempDirectory() + File.separator + \"QueriesSentinelTest\");\n   private static AvroQueryGenerator AVRO_QUERY_GENERATOR;\n-  private static FileBasedInstanceDataManager INSTANCE_DATA_MANAGER;\n   private static QueryExecutor QUERY_EXECUTOR;\n   private static TestingServerPropertiesBuilder CONFIG_BUILDER;\n   private String segmentName;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueriesSentinelTest.java",
                "sha": "d10b5b7a3eb8c1181f3574f55c4818de9e23c3c3",
                "status": "modified"
            },
            {
                "additions": 186,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "changes": 186,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "patch": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (C) 2014-2015 LinkedIn Corp. (pinot-core@linkedin.com)\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.linkedin.pinot.queries;\n+\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.antlr.runtime.RecognitionException;\n+import org.apache.commons.configuration.PropertiesConfiguration;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import com.linkedin.pinot.common.client.request.RequestConverter;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n+import com.linkedin.pinot.common.query.QueryExecutor;\n+import com.linkedin.pinot.common.query.ReduceService;\n+import com.linkedin.pinot.common.request.BrokerRequest;\n+import com.linkedin.pinot.common.request.InstanceRequest;\n+import com.linkedin.pinot.common.response.BrokerResponse;\n+import com.linkedin.pinot.common.response.ServerInstance;\n+import com.linkedin.pinot.common.segment.ReadMode;\n+import com.linkedin.pinot.common.utils.DataTable;\n+import com.linkedin.pinot.core.data.manager.config.FileBasedInstanceDataManagerConfig;\n+import com.linkedin.pinot.core.data.manager.offline.FileBasedInstanceDataManager;\n+import com.linkedin.pinot.core.indexsegment.IndexSegment;\n+import com.linkedin.pinot.core.indexsegment.columnar.ColumnarSegmentLoader;\n+import com.linkedin.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import com.linkedin.pinot.core.query.executor.ServerQueryExecutorV1Impl;\n+import com.linkedin.pinot.core.query.reduce.DefaultReduceService;\n+import com.linkedin.pinot.core.segment.creator.SegmentIndexCreationDriver;\n+import com.linkedin.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import com.linkedin.pinot.pql.parsers.PQLCompiler;\n+import com.linkedin.pinot.segments.v1.creator.SegmentTestUtils;\n+import com.linkedin.pinot.util.TestUtils;\n+import com.yammer.metrics.core.MetricsRegistry;\n+\n+\n+public class QueryExceptionTest {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(QueriesSentinelTest.class);\n+  private static ReduceService REDUCE_SERVICE = new DefaultReduceService();\n+\n+  private static final PQLCompiler REQUEST_COMPILER = new PQLCompiler(new HashMap<String, String[]>());\n+  private final String AVRO_DATA = \"data/mirror-mv.avro\";\n+  private static File INDEX_DIR = new File(FileUtils.getTempDirectory() + File.separator + \"QueriesSentinelTest\");\n+  private static QueryExecutor QUERY_EXECUTOR;\n+  private static TestingServerPropertiesBuilder CONFIG_BUILDER;\n+  private String segmentName;\n+\n+  @BeforeClass\n+  public void setup() throws Exception {\n+    CONFIG_BUILDER = new TestingServerPropertiesBuilder(\"mirror\");\n+\n+    setupSegmentFor(\"mirror\");\n+\n+    final PropertiesConfiguration serverConf = CONFIG_BUILDER.build();\n+    serverConf.setDelimiterParsingDisabled(false);\n+\n+    final FileBasedInstanceDataManager instanceDataManager = FileBasedInstanceDataManager.getInstanceDataManager();\n+    instanceDataManager.init(new FileBasedInstanceDataManagerConfig(serverConf.subset(\"pinot.server.instance\")));\n+    instanceDataManager.start();\n+\n+    System.out.println(\"************************** : \" + new File(INDEX_DIR, \"segment\").getAbsolutePath());\n+    File segmentFile = new File(INDEX_DIR, \"segment\").listFiles()[0];\n+    segmentName = segmentFile.getName();\n+    final IndexSegment indexSegment = ColumnarSegmentLoader.load(segmentFile, ReadMode.heap);\n+    instanceDataManager.getResourceDataManager(\"mirror\");\n+    instanceDataManager.getResourceDataManager(\"mirror\").addSegment(indexSegment);\n+\n+    QUERY_EXECUTOR = new ServerQueryExecutorV1Impl(false);\n+    QUERY_EXECUTOR.init(serverConf.subset(\"pinot.server.query.executor\"), instanceDataManager, new ServerMetrics(\n+        new MetricsRegistry()));\n+  }\n+\n+  @AfterClass\n+  public void tearDown() {\n+    FileUtils.deleteQuietly(INDEX_DIR);\n+  }\n+\n+  private void setupSegmentFor(String resource) throws Exception {\n+    final String filePath = TestUtils.getFileFromResourceUrl(getClass().getClassLoader().getResource(AVRO_DATA));\n+\n+    if (INDEX_DIR.exists()) {\n+      FileUtils.deleteQuietly(INDEX_DIR);\n+    }\n+    INDEX_DIR.mkdir();\n+\n+    final SegmentGeneratorConfig config =\n+        SegmentTestUtils.getSegmentGenSpecWithSchemAndProjectedColumns(new File(filePath), new File(INDEX_DIR,\n+            \"segment\"), \"daysSinceEpoch\", TimeUnit.DAYS, resource, resource);\n+\n+    final SegmentIndexCreationDriver driver = new SegmentIndexCreationDriverImpl();\n+\n+    driver.init(config);\n+    driver.build();\n+\n+    System.out.println(\"built at : \" + INDEX_DIR.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void testSingleQuery() throws RecognitionException, Exception {\n+    String query = \"select count(*) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is \" + brokerResponse.getAggregationResults().get(0));\n+  }\n+\n+  @Test\n+  public void testQueryParsingFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select sudm(blablaa) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() > 0);\n+  }\n+\n+  @Test\n+  public void testQueryPlanFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select sum(blablaa) from mirror where viewerId='24516187'\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() > 0);\n+  }\n+\n+  @Test\n+  public void testQueryExecuteFailedQuery() throws RecognitionException, Exception {\n+    String query = \"select count(*) from mirror where viewerId='24516187' group by bla\";\n+    LOGGER.info(\"running  : \" + query);\n+    final Map<ServerInstance, DataTable> instanceResponseMap = new HashMap<ServerInstance, DataTable>();\n+    final BrokerRequest brokerRequest = RequestConverter.fromJSON(REQUEST_COMPILER.compile(query));\n+    InstanceRequest instanceRequest = new InstanceRequest(1, brokerRequest);\n+    instanceRequest.setSearchSegments(new ArrayList<String>());\n+    instanceRequest.getSearchSegments().add(segmentName);\n+    final DataTable instanceResponse = QUERY_EXECUTOR.processQuery(instanceRequest);\n+    instanceResponseMap.clear();\n+    instanceResponseMap.put(new ServerInstance(\"localhost:0000\"), instanceResponse);\n+    final BrokerResponse brokerResponse = REDUCE_SERVICE.reduceOnDataTable(brokerRequest, instanceResponseMap);\n+    LOGGER.info(\"BrokerResponse is {}\", brokerResponse);\n+    Assert.assertTrue(brokerResponse.getExceptionsSize() == 0);\n+  }\n+}",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/QueryExceptionTest.java",
                "sha": "672fa36f779f42a8bad785ac99a0bbc831cf7af3",
                "status": "added"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java?ref=b02cc238036b9cadc7c6df80a1004d61fa2349a6",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "patch": "@@ -112,6 +112,8 @@ public PropertiesConfiguration build() throws IOException {\n \n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"pruner.class\"),\n         \"TableNameSegmentPruner\");\n+    config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"pruner.class\"),\n+        \"DataSchemaSegmentPruner\");\n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"class\"),\n         \"com.linkedin.pinot.core.query.executor.ServerQueryExecutor\");\n     config.addProperty(StringUtil.join(\".\", PINOT_SERVER_PREFIX, EXECUTOR_PREFIX, \"timeout\"), \"150000\");",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/b02cc238036b9cadc7c6df80a1004d61fa2349a6/pinot-core/src/test/java/com/linkedin/pinot/queries/TestingServerPropertiesBuilder.java",
                "sha": "57fb3b4a6f47a5f31fdc9f6048feac5fa4007514",
                "status": "modified"
            }
        ],
        "message": "Using BlockingQueue for server merging phase.\nFixing NPE in related combine functions.\nRemove Exception handlers in MSelectionOnlyOperator.\nHandling metadata only DataTable Ser/DeSer.\n\nRB=478761\nR=xiafu\nA=kgopalak",
        "parent": "https://github.com/apache/incubator-pinot/commit/69a7ad04c3dbd78f23bd42bc2b33537f324b96c1",
        "patched_files": [
            "DataTableBuilder.java",
            "CombineService.java",
            "BrokerResponse.java",
            "AggregationGroupByOperatorService.java",
            "QueryException.java",
            "MSelectionOnlyOperator.java",
            "DataTable.java",
            "ServerQueryExecutorV1Impl.java",
            "DefaultReduceService.java",
            "SelectionOperatorUtils.java",
            "SelectionOperatorService.java",
            "MCombineOperator.java",
            "IntermediateResultsBlock.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "QueriesSentinelTest.java",
            "TestDefaultReduceService.java",
            "TestDataTableBuilder.java",
            "QueryExceptionTest.java",
            "TestBrokerResponse.java",
            "TestingServerPropertiesBuilder.java"
        ]
    },
    "incubator-pinot_c53fbd2": {
        "bug_id": "incubator-pinot_c53fbd2",
        "commit": "https://github.com/apache/incubator-pinot/commit/c53fbd219fe48bd8ddc98a2b54ba1056386a90d9",
        "file": [
            {
                "additions": 25,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c53fbd219fe48bd8ddc98a2b54ba1056386a90d9/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "changes": 45,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java?ref=c53fbd219fe48bd8ddc98a2b54ba1056386a90d9",
                "deletions": 20,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "patch": "@@ -1,5 +1,7 @@\n package com.linkedin.pinot.controller.api.restlet.resources;\n \n+import com.google.common.base.Preconditions;\n+import com.linkedin.pinot.common.config.TableNameBuilder;\n import java.io.File;\n import java.io.IOException;\n import org.apache.commons.io.FileUtils;\n@@ -55,41 +57,44 @@ public Representation get() {\n       \"/tables/{tableName}/schema/\"\n   })\n   private Representation getTableSchema(\n-      @Parameter(name = \"tableName\", in = \"path\", description = \"Table name for which to get the schema\", required = true)\n-      String tableName) {\n+      @Parameter(name = \"tableName\", in = \"path\", description = \"Table name for which to get the schema\",\n+          required = true) String tableName) {\n     if (_pinotHelixResourceManager.hasRealtimeTable(tableName)) {\n       try {\n         AbstractTableConfig config = _pinotHelixResourceManager.getTableConfig(tableName, TableType.REALTIME);\n-        return new StringRepresentation(_pinotHelixResourceManager.getSchema(config.getValidationConfig().getSchemaName()).getJSONSchema()\n-            .toString());\n+        String schemaName = config.getValidationConfig().getSchemaName();\n+        Schema schema = _pinotHelixResourceManager.getSchema(schemaName);\n+        Preconditions.checkNotNull(schema, \"Failed to fetch schema: %s for REALTIME table: %s\", schemaName, tableName);\n+        return new StringRepresentation(schema.getJSONSchema());\n       } catch (Exception e) {\n-        LOGGER.error(\"Caught exception while fetching schema for a realtime table : {} \", tableName, e);\n-        ControllerRestApplication.getControllerMetrics().addMeteredGlobalValue(ControllerMeter.CONTROLLER_TABLE_SCHEMA_GET_ERROR, 1L);\n+        LOGGER.error(\"Caught exception while fetching schema for REALTIME table: {} \", tableName, e);\n+        ControllerRestApplication.getControllerMetrics()\n+            .addMeteredGlobalValue(ControllerMeter.CONTROLLER_TABLE_SCHEMA_GET_ERROR, 1L);\n         setStatus(Status.SERVER_ERROR_INTERNAL);\n         return PinotSegmentUploadRestletResource.exceptionToStringRepresentation(e);\n       }\n-    } else {\n-      AbstractTableConfig config;\n+    }\n+\n+    if (_pinotHelixResourceManager.hasOfflineTable(tableName)) {\n+      // For OFFLINE table, schema name is the same as table name\n+      String schemaName = TableNameBuilder.OFFLINE_TABLE_NAME_BUILDER.forTable(tableName);\n       try {\n-        config = _pinotHelixResourceManager.getTableConfig(tableName, TableType.OFFLINE);\n-        String schemaName = config.getValidationConfig().getSchemaName();\n-        Schema schema = null;\n-        if (schemaName != null && !schemaName.isEmpty()) {\n-          schema = _pinotHelixResourceManager.getSchema(schemaName);\n-        }\n+        Schema schema = _pinotHelixResourceManager.getSchema(schemaName);\n         if (schema == null) {\n           setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n-          StringRepresentation repr = new StringRepresentation(\"{\\\"error\\\": \\\"Schema \" + schemaName + \" not found\\\"\");\n-          repr.setMediaType(MediaType.APPLICATION_JSON);\n-          return repr;\n+          return new StringRepresentation(\"Error: schema \" + schemaName + \" not found\");\n         }\n-        return new StringRepresentation(schema.getJSONSchema().toString());\n+        return new StringRepresentation(schema.getJSONSchema());\n       } catch (Exception e) {\n-        LOGGER.error(\"Caught exception while fetching schema for a offline table : {} \", tableName, e);\n-        ControllerRestApplication.getControllerMetrics().addMeteredGlobalValue(ControllerMeter.CONTROLLER_TABLE_SCHEMA_GET_ERROR, 1L);\n+        LOGGER.error(\"Caught exception while fetching schema for OFFLINE table :{} \", tableName, e);\n+        ControllerRestApplication.getControllerMetrics()\n+            .addMeteredGlobalValue(ControllerMeter.CONTROLLER_TABLE_SCHEMA_GET_ERROR, 1L);\n         setStatus(Status.SERVER_ERROR_INTERNAL);\n         return PinotSegmentUploadRestletResource.exceptionToStringRepresentation(e);\n       }\n     }\n+\n+    setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n+    return new StringRepresentation(\"Error: table \" + tableName + \" not found\");\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c53fbd219fe48bd8ddc98a2b54ba1056386a90d9/pinot-controller/src/main/java/com/linkedin/pinot/controller/api/restlet/resources/PinotTableSchema.java",
                "sha": "2ec8fe42201a1b44f7c863145faffac1ff0d6790",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c53fbd219fe48bd8ddc98a2b54ba1056386a90d9/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=c53fbd219fe48bd8ddc98a2b54ba1056386a90d9",
                "deletions": 9,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -936,15 +936,10 @@ public boolean deleteSchema(Schema schema) {\n     }\n     return false;\n   }\n-  /**\n-   *\n-   * @param schemaName\n-   * @return\n-   * @throws JsonParseException\n-   * @throws JsonMappingException\n-   * @throws IOException\n-   */\n-  public @Nullable Schema getSchema(String schemaName) throws JsonParseException, JsonMappingException, IOException {\n+\n+  @Nullable\n+  public Schema getSchema(String schemaName)\n+      throws IOException {\n     PinotHelixPropertyStoreZnRecordProvider propertyStoreHelper =\n         PinotHelixPropertyStoreZnRecordProvider.forSchema(_propertyStore);\n     ZNRecord record = propertyStoreHelper.get(schemaName);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c53fbd219fe48bd8ddc98a2b54ba1056386a90d9/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "68dc728d6429a2a84f02c23e7bef578555fe8dd6",
                "status": "modified"
            }
        ],
        "message": "Fix NPE from getTableSchema (#1284)\n\nWhen table does not exist, it will throw NPE.\r\nFor OFFLINE table, schema name should be the same as table name.",
        "parent": "https://github.com/apache/incubator-pinot/commit/bd85e25513213c19d93fbe77fed6558250356b2a",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    },
    "incubator-pinot_c802cda": {
        "bug_id": "incubator-pinot_c802cda",
        "commit": "https://github.com/apache/incubator-pinot/commit/c802cdafb57343d174fdef623f25ef15aa45d782",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/ServerGauge.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/ServerGauge.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 0,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/metrics/ServerGauge.java",
                "patch": "@@ -32,6 +32,7 @@\n   LAST_REALTIME_SEGMENT_CATCHUP_DURATION_SECONDS(\"seconds\", false),\n   LAST_REALTIME_SEGMENT_COMPLETION_DURATION_SECONDS(\"seconds\", false),\n   KAFKA_PARTITION_OFFSET_LAG(\"messages\", false),\n+  REALTIME_OFFHEAP_MEMORY_USED(\"bytes\", false),\n   RUNNING_QUERIES(\"runningQueries\", false);\n \n   private final String gaugeName;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-common/src/main/java/com/linkedin/pinot/common/metrics/ServerGauge.java",
                "sha": "39b0726824823b8e6c7c519dc8593357bb43441e",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/offline/AbstractTableDataManager.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/offline/AbstractTableDataManager.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/offline/AbstractTableDataManager.java",
                "patch": "@@ -252,6 +252,10 @@ public void releaseSegment(SegmentDataManager segmentDataManager) {\n     }\n   }\n \n+  public ServerMetrics getServerMetrics() {\n+    return _serverMetrics;\n+  }\n+\n   @Override\n   public String getTableName() {\n     return _tableName;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/offline/AbstractTableDataManager.java",
                "sha": "14c10c71617fe6e8acb93e16eb7fab894192329c",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "patch": "@@ -17,6 +17,7 @@\n package com.linkedin.pinot.core.data.manager.realtime;\n \n import com.linkedin.pinot.common.data.Schema;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n import com.linkedin.pinot.core.data.manager.offline.SegmentDataManager;\n import com.linkedin.pinot.core.io.readerwriter.RealtimeIndexOffHeapMemoryManager;\n import com.linkedin.pinot.core.io.writer.impl.DirectMemoryManager;\n@@ -49,10 +50,12 @@ public RealtimeSegmentStatsHistory getStatsHistory() {\n   }\n \n   protected void initMemoryManager(RealtimeTableDataManager realtimeTableDataManager, boolean isOffHeapAllocation, String segmentName) {\n+    ServerMetrics serverMetrics = realtimeTableDataManager.getServerMetrics();\n     if (isOffHeapAllocation) {\n-      _memoryManager = new MmapMemoryManager(realtimeTableDataManager.getConsumerDir(), segmentName);\n+      _memoryManager = new MmapMemoryManager(realtimeTableDataManager.getConsumerDir(), segmentName,\n+          realtimeTableDataManager.getServerMetrics());\n     } else {\n-      _memoryManager = new DirectMemoryManager(segmentName);\n+      _memoryManager = new DirectMemoryManager(segmentName, realtimeTableDataManager.getServerMetrics());\n     }\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "sha": "0d391a65fe7485246f0198e0d87a983966eb709b",
                "status": "modified"
            },
            {
                "additions": 22,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/readerwriter/RealtimeIndexOffHeapMemoryManager.java",
                "changes": 24,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/io/readerwriter/RealtimeIndexOffHeapMemoryManager.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/io/readerwriter/RealtimeIndexOffHeapMemoryManager.java",
                "patch": "@@ -16,11 +16,16 @@\n \n package com.linkedin.pinot.core.io.readerwriter;\n \n+import com.linkedin.pinot.common.metrics.ServerGauge;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n+import com.linkedin.pinot.common.utils.HLCSegmentName;\n+import com.linkedin.pinot.common.utils.LLCSegmentName;\n+import com.linkedin.pinot.common.utils.SegmentName;\n+import com.linkedin.pinot.core.segment.memory.PinotDataBuffer;\n import java.io.Closeable;\n import java.io.IOException;\n import java.util.LinkedList;\n import java.util.List;\n-import com.linkedin.pinot.core.segment.memory.PinotDataBuffer;\n \n \n /**\n@@ -35,10 +40,23 @@\n public abstract class RealtimeIndexOffHeapMemoryManager implements Closeable {\n   private final List<PinotDataBuffer> _buffers = new LinkedList<>();\n   private final String _segmentName;\n+  private final ServerMetrics _serverMetrics;\n   private long _totalMemBytes = 0;\n+  private final String _tableName;\n \n-  protected RealtimeIndexOffHeapMemoryManager(String segmentName) {\n+  protected RealtimeIndexOffHeapMemoryManager(ServerMetrics serverMetrics, String segmentName) {\n+    _serverMetrics = serverMetrics;\n     _segmentName = segmentName;\n+    if (SegmentName.isLowLevelConsumerSegmentName(segmentName)) {\n+      LLCSegmentName llcSegmentName = new LLCSegmentName(segmentName);\n+      _tableName = llcSegmentName.getTableName();\n+    } else if (SegmentName.isHighLevelConsumerSegmentName(segmentName)){\n+      HLCSegmentName hlcSegmentName = new HLCSegmentName(segmentName);\n+      _tableName = hlcSegmentName.getTableName();\n+    } else {\n+      // For testing only\n+      _tableName = \"NoSuchTable\";\n+    }\n   }\n \n   /**\n@@ -63,6 +81,7 @@ public PinotDataBuffer allocate(long size, String columnName) {\n     PinotDataBuffer buffer = allocateInternal(size, columnName);\n     _totalMemBytes += size;\n     _buffers.add(buffer);\n+    _serverMetrics.setValueOfTableGauge(_tableName, ServerGauge.REALTIME_OFFHEAP_MEMORY_USED, _totalMemBytes);\n     return buffer;\n   }\n \n@@ -85,6 +104,7 @@ public void close() throws IOException {\n     for (PinotDataBuffer buffer : _buffers) {\n       buffer.close();\n     }\n+    _serverMetrics.setValueOfTableGauge(_tableName, ServerGauge.REALTIME_OFFHEAP_MEMORY_USED, 0);\n     doClose();\n     _buffers.clear();\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/readerwriter/RealtimeIndexOffHeapMemoryManager.java",
                "sha": "b4f30cbd788a5b0784441ba30b6a5473c841dd6c",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/DirectMemoryManager.java",
                "changes": 10,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/DirectMemoryManager.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/DirectMemoryManager.java",
                "patch": "@@ -16,8 +16,11 @@\n \n package com.linkedin.pinot.core.io.writer.impl;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n import com.linkedin.pinot.core.io.readerwriter.RealtimeIndexOffHeapMemoryManager;\n import com.linkedin.pinot.core.segment.memory.PinotDataBuffer;\n+import com.yammer.metrics.core.MetricsRegistry;\n \n \n // Allocates memory using direct allocation\n@@ -26,8 +29,13 @@\n   /**\n    * @see RealtimeIndexOffHeapMemoryManager\n    */\n+  public DirectMemoryManager(final String segmentName, ServerMetrics serverMetrics) {\n+    super(serverMetrics, segmentName);\n+  }\n+\n+  @VisibleForTesting\n   public DirectMemoryManager(final String segmentName) {\n-    super(segmentName);\n+    this(segmentName, new ServerMetrics(new MetricsRegistry()));\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/DirectMemoryManager.java",
                "sha": "28a11a284d440e81bfa95b5bf0934b23da1582b9",
                "status": "modified"
            },
            {
                "additions": 10,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/MmapMemoryManager.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/MmapMemoryManager.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/MmapMemoryManager.java",
                "patch": "@@ -16,6 +16,8 @@\n \n package com.linkedin.pinot.core.io.writer.impl;\n \n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n+import com.yammer.metrics.core.MetricsRegistry;\n import java.io.File;\n import java.io.FileNotFoundException;\n import java.io.FilenameFilter;\n@@ -70,10 +72,11 @@ public static long getDefaultFileLength() {\n    * @param dirPathName directory under which all mmap files are created.\n    * @param segmentName Name of the segment for which this memory manager allocates memory\n    *\n+   * @param serverMetrics\n    * @see RealtimeIndexOffHeapMemoryManager\n    */\n-  public MmapMemoryManager(String dirPathName, String segmentName) {\n-    super(segmentName);\n+  public MmapMemoryManager(String dirPathName, String segmentName, ServerMetrics serverMetrics) {\n+    super(serverMetrics, segmentName);\n     _dirPathName = dirPathName;\n     File dirFile = new File(_dirPathName);\n     if (dirFile.exists()) {\n@@ -93,6 +96,11 @@ public boolean accept(File dir, String name) {\n     }\n   }\n \n+  @VisibleForTesting\n+  public MmapMemoryManager(String dirPathName, String segmentName) {\n+    this(dirPathName, segmentName, new ServerMetrics(new MetricsRegistry()));\n+  }\n+\n   private String getFilePrefix() {\n     return getSegmentName() + \".\";\n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/main/java/com/linkedin/pinot/core/io/writer/impl/MmapMemoryManager.java",
                "sha": "a45b3a52c54238a42df2878d176fa80ad4984df7",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "changes": 1,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java?ref=c802cdafb57343d174fdef623f25ef15aa45d782",
                "deletions": 0,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "patch": "@@ -123,6 +123,7 @@ private RealtimeTableDataManager createTableDataManager() {\n     when(statsHistory.getEstimatedCardinality(any(String.class))).thenReturn(200);\n     when(statsHistory.getEstimatedAvgColSize(any(String.class))).thenReturn(32);\n     when(tableDataManager.getStatsHistory()).thenReturn(statsHistory);\n+    when(tableDataManager.getServerMetrics()).thenReturn(new ServerMetrics(new MetricsRegistry()));\n     return tableDataManager;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/c802cdafb57343d174fdef623f25ef15aa45d782/pinot-core/src/test/java/com/linkedin/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManagerTest.java",
                "sha": "95c49ed5dc3cf91f4cb7e0b5617abac30696e122",
                "status": "modified"
            }
        ],
        "message": "Add metrics for keeping track of off-heap allocation for consuming segments (#1874)\n\n* Add metrics for keeping track of off-heap allocation for consuming segments\r\n\r\n* Undo changes to test, in favor of a new constructor\r\n\r\n* Fix NPE in a test. Don't know why other tests are failing yet\r\n\r\n* Fix NPE in tests\r\n\r\n* Calling size() on buffer object can throw NPE while closing memory manager\r\n\r\nThis is beacuse some of the memory is already freed up before we reach close() method of MemoryManager.\r\nSo, it seems better to just use _totalMemBytes to set the guage (and unset it)",
        "parent": "https://github.com/apache/incubator-pinot/commit/0d7d865d792205d33f1262588ff486dd47b2aeda",
        "patched_files": [
            "AbstractTableDataManager.java",
            "LLRealtimeSegmentDataManager.java",
            "ServerGauge.java",
            "MmapMemoryManager.java",
            "RealtimeSegmentDataManager.java",
            "RealtimeIndexOffHeapMemoryManager.java",
            "DirectMemoryManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "MmapMemoryManagerTest.java",
            "LLRealtimeSegmentDataManagerTest.java"
        ]
    },
    "incubator-pinot_d5205cd": {
        "bug_id": "incubator-pinot_d5205cd",
        "commit": "https://github.com/apache/incubator-pinot/commit/d5205cd7ade0c5223c5d6dbbffde5f51f13a056d",
        "file": [
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/d5205cd7ade0c5223c5d6dbbffde5f51f13a056d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "changes": 17,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java?ref=d5205cd7ade0c5223c5d6dbbffde5f51f13a056d",
                "deletions": 6,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "patch": "@@ -169,8 +169,9 @@ public GenericRow decode(byte[] payload) {\n     }\n   }\n \n-  protected void addRealtimeTable(String tableName, String timeColumnName, String timeColumnType, String kafkaZkUrl,\n-      String kafkaTopic, String schemaName, String serverTenant, String brokerTenant, File avroFile) throws Exception {\n+  protected void addRealtimeTable(String tableName, String timeColumnName, String timeColumnType,\n+      int retentionDays, String retentionTimeUnit, String kafkaZkUrl, String kafkaTopic,\n+      String schemaName, String serverTenant, String brokerTenant, File avroFile) throws Exception {\n     JSONObject metadata = new JSONObject();\n     metadata.put(\"streamType\", \"kafka\");\n     metadata.put(DataSource.STREAM_PREFIX + \".\" + Kafka.CONSUMER_TYPE, Kafka.ConsumerType.highLevel.toString());\n@@ -183,7 +184,8 @@ protected void addRealtimeTable(String tableName, String timeColumnName, String\n     JSONObject request =\n         ControllerRequestBuilder\n             .buildCreateRealtimeTableJSON(tableName, serverTenant, brokerTenant, timeColumnName, timeColumnType,\n-                \"rententionTimeUnit\", \"900\", 1, \"BalanceNumSegmentAssignmentStrategy\", metadata, schemaName);\n+                retentionTimeUnit, Integer.toString(retentionDays),\n+                1, \"BalanceNumSegmentAssignmentStrategy\", metadata, schemaName);\n     sendPostRequest(ControllerRequestURLBuilder.baseUrl(CONTROLLER_BASE_API_URL).forTableCreate(), request.toString());\n \n     AvroFileSchemaKafkaAvroMessageDecoder.avroFile = avroFile;\n@@ -192,8 +194,11 @@ protected void addRealtimeTable(String tableName, String timeColumnName, String\n \n   protected void addHybridTable(String tableName, String timeColumnName, String timeColumnType, String kafkaZkUrl,\n       String kafkaTopic, String schemaName, String serverTenant, String brokerTenant, File avroFile) throws Exception {\n-    addRealtimeTable(tableName, timeColumnName, timeColumnType, kafkaZkUrl, kafkaTopic, schemaName, serverTenant,\n-        brokerTenant, avroFile);\n-    addOfflineTable(tableName, timeColumnName, timeColumnType, 900, \"Days\", brokerTenant, serverTenant);\n+    int retentionDays = 900;\n+    String retentionTimeUnit = \"Days\";\n+    addRealtimeTable(tableName, timeColumnName, timeColumnType,\n+        retentionDays, retentionTimeUnit, kafkaZkUrl, kafkaTopic,\n+        schemaName, serverTenant, brokerTenant, avroFile);\n+    addOfflineTable(tableName, timeColumnName, timeColumnType, retentionDays, retentionTimeUnit, brokerTenant, serverTenant);\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/d5205cd7ade0c5223c5d6dbbffde5f51f13a056d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/ClusterTest.java",
                "sha": "9c421fba6b840ad02497846b5763a58d4dedef2a",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/d5205cd7ade0c5223c5d6dbbffde5f51f13a056d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java?ref=d5205cd7ade0c5223c5d6dbbffde5f51f13a056d",
                "deletions": 1,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "patch": "@@ -61,7 +61,7 @@ protected void setUpTable(String tableName, String timeColumnName, String timeCo\n       String kafkaTopic, File schemaFile, File avroFile) throws Exception {\n     Schema schema = Schema.fromFile(schemaFile);\n     addSchema(schemaFile, schema.getSchemaName());\n-    addRealtimeTable(tableName, timeColumnName, timeColumnType, kafkaZkUrl, kafkaTopic, schema.getSchemaName(),\n+    addRealtimeTable(tableName, timeColumnName, timeColumnType, 900, \"Days\", kafkaZkUrl, kafkaTopic, schema.getSchemaName(),\n         null, null, avroFile);\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/d5205cd7ade0c5223c5d6dbbffde5f51f13a056d/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "sha": "881a0207902a534ab3019b8827ddc20c876a6f34",
                "status": "modified"
            }
        ],
        "message": "[PINOT 2095] Use valid time retention values in integration tests\n\nIntegration tests passed bogus values for retention time unit causing\nNPE. Refactored the code to use valid and consistent values for time\nretention units\n\nRB=576002\nG=pinot-dev-reviewers\nR=kgopalak,jfim,ssubrama,dpatel,mshrivas\nA=ssubrama",
        "parent": "https://github.com/apache/incubator-pinot/commit/151c4b32b3ea476a5f308cc1b1dd823ac70e9281",
        "patched_files": [],
        "repo": "incubator-pinot",
        "unit_tests": [
            "ClusterTest.java",
            "RealtimeClusterIntegrationTest.java"
        ]
    },
    "incubator-pinot_dc88ec2": {
        "bug_id": "incubator-pinot_dc88ec2",
        "commit": "https://github.com/apache/incubator-pinot/commit/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManager.java",
                "changes": 8,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManager.java?ref=dc88ec2dcabea304e98cb4b52fadfdaf385b9f36",
                "deletions": 2,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManager.java",
                "patch": "@@ -660,8 +660,12 @@ protected SegmentMetadataImpl extractSegmentMetadata(final String rawTableName,\n   }\n \n   public LLCRealtimeSegmentZKMetadata getRealtimeSegmentZKMetadata(String realtimeTableName, String segmentName) {\n-    return new LLCRealtimeSegmentZKMetadata(_propertyStore.get(\n-          ZKMetadataProvider.constructPropertyStorePathForSegment(realtimeTableName, segmentName), null, AccessOption.PERSISTENT));\n+    ZNRecord znRecord = _propertyStore.get(ZKMetadataProvider.constructPropertyStorePathForSegment(realtimeTableName, segmentName), null, AccessOption.PERSISTENT);\n+    if (znRecord == null) {\n+      LOGGER.error(\"Segment metadata not found for table {}, segment {}. (can happen during table drop)\");\n+      throw new RuntimeException(\"Segment metadata not found for table \" + realtimeTableName + \" segment \" + segmentName);\n+    }\n+    return new LLCRealtimeSegmentZKMetadata(znRecord);\n   }\n \n   private void completeCommittingSegments() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManager.java",
                "sha": "605197236b4c58a422242818fdd3a79868a8da04",
                "status": "modified"
            },
            {
                "additions": 47,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionManager.java",
                "changes": 69,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionManager.java?ref=dc88ec2dcabea304e98cb4b52fadfdaf385b9f36",
                "deletions": 22,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionManager.java",
                "patch": "@@ -117,11 +117,6 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n         final String realtimeTableName = TableNameBuilder.REALTIME_TABLE_NAME_BUILDER.forTable(segmentName.getTableName());\n         LLCRealtimeSegmentZKMetadata segmentMetadata = _segmentManager.getRealtimeSegmentZKMetadata(\n             realtimeTableName, segmentName.getSegmentName());\n-        if (segmentMetadata == null) {\n-          // It is possible that we are in the process of reverting configuration back to high-level consumers.\n-          LOGGER.warn(\"Segment metadata not found for {}\", segmentNameStr);\n-          throw new RuntimeException(\"Segment metadata not found for \" + segmentNameStr);\n-        }\n         if (segmentMetadata.getStatus().equals(CommonConstants.Segment.Realtime.Status.DONE)) {\n           // Best to go through the state machine for this case as well, so that all code regarding state handling is in one place\n           // Also good for synchronization, because it is possible that multiple threads take this path, and we don't want\n@@ -139,8 +134,8 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n         _fsmMap.put(segmentNameStr, fsm);\n       } catch (Exception e) {\n         // Server gone wonky. Segment does not exist in propstore\n-        LOGGER.error(\"Exception reading segment read from propertystore {}\", segmentNameStr, e);\n-        throw new RuntimeException(\"Segment read from propertystore \" + segmentNameStr, e);\n+        LOGGER.error(\"Exception creating FSM for segment {}\", segmentNameStr, e);\n+        throw new RuntimeException(\"Exception creating FSM for segment \" + segmentNameStr, e);\n       }\n     }\n     return fsm;\n@@ -159,9 +154,15 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n     final long offset = reqParams.getOffset();\n \n     LLCSegmentName segmentName = new LLCSegmentName(segmentNameStr);\n-    SegmentCompletionFSM fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_CONSUMED);\n-    SegmentCompletionProtocol.Response response = fsm.segmentConsumed(instanceId, offset);\n-    if (fsm.isDone()) {\n+    SegmentCompletionProtocol.Response response = SegmentCompletionProtocol.RESP_FAILED;\n+    SegmentCompletionFSM fsm = null;\n+    try {\n+      fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_CONSUMED);\n+      response = fsm.segmentConsumed(instanceId, offset);\n+    } catch (Exception e) {\n+      // Return failed response\n+    }\n+    if (fsm != null && fsm.isDone()) {\n       LOGGER.info(\"Removing FSM (if present):{}\", fsm.toString());\n       _fsmMap.remove(segmentNameStr);\n     }\n@@ -187,9 +188,15 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n     final String instanceId = reqParams.getInstanceId();\n     final long offset = reqParams.getOffset();\n     LLCSegmentName segmentName = new LLCSegmentName(segmentNameStr);\n-    SegmentCompletionFSM fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n-    SegmentCompletionProtocol.Response response = fsm.segmentCommitStart(instanceId, offset);\n-    if (fsm.isDone()) {\n+    SegmentCompletionFSM fsm = null;\n+    SegmentCompletionProtocol.Response response = SegmentCompletionProtocol.RESP_FAILED;\n+    try {\n+      fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n+      response = fsm.segmentCommitStart(instanceId, offset);\n+    } catch (Exception e) {\n+      // Return failed response\n+    }\n+    if (fsm != null && fsm.isDone()) {\n       LOGGER.info(\"Removing FSM (if present):{}\", fsm.toString());\n       _fsmMap.remove(segmentNameStr);\n     }\n@@ -205,9 +212,15 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n     final long offset = reqParams.getOffset();\n     final int extTimeSec = reqParams.getExtraTimeSec();\n     LLCSegmentName segmentName = new LLCSegmentName(segmentNameStr);\n-    SegmentCompletionFSM fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n-    SegmentCompletionProtocol.Response response = fsm.extendBuildTime(instanceId, offset, extTimeSec);\n-    if (fsm.isDone()) {\n+    SegmentCompletionFSM fsm = null;\n+    SegmentCompletionProtocol.Response response = SegmentCompletionProtocol.RESP_FAILED;\n+    try {\n+      fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n+      response = fsm.extendBuildTime(instanceId, offset, extTimeSec);\n+    } catch (Exception e) {\n+      // Return failed response\n+    }\n+    if (fsm != null && fsm.isDone()) {\n       LOGGER.info(\"Removing FSM (if present):{}\", fsm.toString());\n       _fsmMap.remove(segmentNameStr);\n     }\n@@ -229,9 +242,15 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n     final long offset = reqParams.getOffset();\n     final String reason = reqParams.getReason();\n     LLCSegmentName segmentName = new LLCSegmentName(segmentNameStr);\n-    SegmentCompletionFSM fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_STOPPED_CONSUMING);\n-    SegmentCompletionProtocol.Response response = fsm.stoppedConsuming(instanceId, offset, reason);\n-    if (fsm.isDone()) {\n+    SegmentCompletionFSM fsm = null;\n+    SegmentCompletionProtocol.Response response = SegmentCompletionProtocol.RESP_FAILED;\n+    try {\n+      fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_STOPPED_CONSUMING);\n+      response = fsm.stoppedConsuming(instanceId, offset, reason);\n+    } catch (Exception e) {\n+      // Return failed response\n+    }\n+    if (fsm != null && fsm.isDone()) {\n       LOGGER.info(\"Removing FSM (if present):{}\", fsm.toString());\n       _fsmMap.remove(segmentNameStr);\n     }\n@@ -256,9 +275,15 @@ private synchronized SegmentCompletionFSM lookupOrCreateFsm(final LLCSegmentName\n     final String instanceId = reqParams.getInstanceId();\n     final long offset = reqParams.getOffset();\n     LLCSegmentName segmentName = new LLCSegmentName(segmentNameStr);\n-    SegmentCompletionFSM fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n-    SegmentCompletionProtocol.Response response = fsm.segmentCommitEnd(instanceId, offset, success);\n-    if (fsm.isDone()) {\n+    SegmentCompletionFSM fsm = null;\n+    SegmentCompletionProtocol.Response response = SegmentCompletionProtocol.RESP_FAILED;\n+    try {\n+      fsm = lookupOrCreateFsm(segmentName, SegmentCompletionProtocol.MSG_TYPE_COMMIT);\n+      response = fsm.segmentCommitEnd(instanceId, offset, success);\n+    } catch (Exception e) {\n+      // Return failed response\n+    }\n+    if (fsm != null && fsm.isDone()) {\n       LOGGER.info(\"Removing FSM (if present):{}\", fsm.toString());\n       _fsmMap.remove(segmentNameStr);\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionManager.java",
                "sha": "64a7c9fcd30eb7406f3c1a81a815b679d945ddc1",
                "status": "modified"
            },
            {
                "additions": 12,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionTest.java?ref=dc88ec2dcabea304e98cb4b52fadfdaf385b9f36",
                "deletions": 0,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionTest.java",
                "patch": "@@ -249,6 +249,18 @@ public void testHappyPath() throws Exception {\n     testHappyPath(5L);\n   }\n \n+  @Test\n+  public void testExceptionInConsumedMessage() throws Exception {\n+    segmentManager._segmentMetadata = null;\n+\n+    SegmentCompletionProtocol.Response response;\n+    Request.Params params;\n+    segmentCompletionMgr._secconds = 10;\n+    params = new Request.Params().withInstanceId(s1).withOffset(s1Offset).withSegmentName(segmentNameStr);\n+    response = segmentCompletionMgr.segmentConsumed(params);\n+    Assert.assertEquals(response.getStatus(), ControllerResponseStatus.FAILED);\n+  }\n+\n   public void testHappyPath(long startTime) throws  Exception {\n     SegmentCompletionProtocol.Response response;\n     Request.Params params;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/dc88ec2dcabea304e98cb4b52fadfdaf385b9f36/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/core/realtime/SegmentCompletionTest.java",
                "sha": "dc782d4f65a234d547a5f8d6e835fca6176ba8b9",
                "status": "modified"
            }
        ],
        "message": "[PINOT-4768] Handle exceptions when a table gets dropped while committing an LLC segment (#1275)\n\n* [PINOT-4768] Handle exceptions when a table gets dropped while committing an LLC segment\r\n\r\nWe handle all exceptions inside the segment completion manager, and return a failed response.\r\n\r\nAdded unit test\r\n\r\n* Changed exception and error string message\r\n\r\n* Fixed the exception to be a RuntimeException instead of NPE\r\n\r\nThere are multiple points that call to get the segment metadata and they cannot handle null\r\nfor the metadata. One (normal) condition in which this can happen is:\r\n\r\n  table getting dropped AND (segment completing OR validation manager auto-createing segments)\r\n\r\nOther cases are manual edits of zknodes to remove metadata nodes (not expected)\r\n\r\nAdded an appropriate log message and turned the exception into RuntimeException instead of\r\nNPE",
        "parent": "https://github.com/apache/incubator-pinot/commit/d5128a74c1fea51087521e2e6adf9be64ee75b21",
        "patched_files": [
            "PinotLLCRealtimeSegmentManager.java",
            "SegmentCompletionManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "SegmentCompletionTest.java",
            "PinotLLCRealtimeSegmentManagerTest.java"
        ]
    },
    "incubator-pinot_dd2e6c5": {
        "bug_id": "incubator-pinot_dd2e6c5",
        "commit": "https://github.com/apache/incubator-pinot/commit/dd2e6c5f55cfe03b2378103258c239ac8d6ccb27",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/dd2e6c5f55cfe03b2378103258c239ac8d6ccb27/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java?ref=dd2e6c5f55cfe03b2378103258c239ac8d6ccb27",
                "deletions": 0,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "patch": "@@ -192,7 +192,11 @@ public void setSchemaName(String schemaName) {\n \n   @JsonIgnore\n   public long getSchemaVersion() {\n+    if (schemaVersion == null) {\n+      return -1;\n+    }\n     return schemaVersion;\n+\n   }\n \n   public void setSchemaVersion(long schemaVersion) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/dd2e6c5f55cfe03b2378103258c239ac8d6ccb27/pinot-common/src/main/java/com/linkedin/pinot/common/data/Schema.java",
                "sha": "0bf566e391f7855ac0704f7fa503e0683c53a7b3",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/dd2e6c5f55cfe03b2378103258c239ac8d6ccb27/pinot-common/src/main/java/com/linkedin/pinot/common/metadata/ZKMetadataProvider.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/metadata/ZKMetadataProvider.java?ref=dd2e6c5f55cfe03b2378103258c239ac8d6ccb27",
                "deletions": 2,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/metadata/ZKMetadataProvider.java",
                "patch": "@@ -189,10 +189,10 @@ public static Boolean getClusterTenantIsolationEnabled(ZkHelixPropertyStore<ZNRe\n       if (znRecord.getSimpleFields().keySet().contains(CLUSTER_TENANT_ISOLATION_ENABLED_KEY)) {\n         return znRecord.getBooleanField(CLUSTER_TENANT_ISOLATION_ENABLED_KEY, true);\n       } else {\n-        return null;\n+        return true;\n       }\n     } else {\n-      return null;\n+      return true;\n     }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/dd2e6c5f55cfe03b2378103258c239ac8d6ccb27/pinot-common/src/main/java/com/linkedin/pinot/common/metadata/ZKMetadataProvider.java",
                "sha": "801350a4d47c13aedb5d28262d8f9137f7452bfc",
                "status": "modified"
            }
        ],
        "message": "fixing shema NPE\n\nRB=491262\nR=xiafu,mshrivas\nA=mshrivas",
        "parent": "https://github.com/apache/incubator-pinot/commit/4d7029b25563d718461445e7bed98e0f1ebd8a49",
        "patched_files": [
            "Schema.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestSchema.java"
        ]
    },
    "incubator-pinot_e299338": {
        "bug_id": "incubator-pinot_e299338",
        "commit": "https://github.com/apache/incubator-pinot/commit/e29933810a701e2e8c4690465ccb8774a0324180",
        "file": [
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-common/src/main/java/com/linkedin/pinot/common/response/ServerInstance.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/response/ServerInstance.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 0,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/response/ServerInstance.java",
                "patch": "@@ -48,6 +48,8 @@\n   /** IP Address. Not used in equals/hash-code generation **/\n   private final InetAddress _ipAddress;\n \n+  private final int _seq;\n+\n   /**\n    * Use this constructor if the name and port are embedded as string with \":\" as delimiter\n    *\n@@ -58,6 +60,10 @@ public ServerInstance(String namePortStr) {\n   }\n \n   public ServerInstance(String name, int port) {\n+    this(name, port, 0);\n+  }\n+\n+  public ServerInstance(String name, int port, int seq) {\n     super();\n     InetAddress ipAddr = null;\n     try {\n@@ -70,6 +76,7 @@ public ServerInstance(String name, int port) {\n     _ipAddress = ipAddr;\n     _hostname = _ipAddress != null ? _ipAddress.getHostName() : name;\n     _port = port;\n+    _seq = seq;\n   }\n \n   public String getHostname() {\n@@ -90,6 +97,7 @@ public int hashCode() {\n     int result = 1;\n     result = (prime * result) + (_hostname == null ? 0 : _hostname.hashCode());\n     result = (prime * result) + _port;\n+    result = (prime * result) + _seq;\n     return result;\n   }\n \n@@ -115,6 +123,9 @@ public boolean equals(Object obj) {\n     if (_port != other._port) {\n       return false;\n     }\n+    if (_seq != other._seq) {\n+      return false;\n+    }\n     return true;\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-common/src/main/java/com/linkedin/pinot/common/response/ServerInstance.java",
                "sha": "c9ce11ce541a568c1e769ffc8a375469c8771477",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 1,
                "filename": "pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "patch": "@@ -84,7 +84,7 @@ private static FilterQueryTree buildFilterQuery(Integer id, Map<Integer, FilterQ\n     List<Integer> children = q.getNestedFilterQueryIds();\n \n     List<FilterQueryTree> c = null;\n-    if (null != children) {\n+    if (null != children && !children.isEmpty()) {\n       c = new ArrayList<FilterQueryTree>();\n       for (final Integer i : children) {\n         final FilterQueryTree t = buildFilterQuery(i, queryMap);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-common/src/main/java/com/linkedin/pinot/common/utils/request/RequestUtils.java",
                "sha": "59a937fb2c86f2f4868ecb666230d532b5ebff01",
                "status": "modified"
            },
            {
                "additions": 14,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "changes": 27,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 13,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "patch": "@@ -37,6 +37,7 @@\n \n public class RealtimeColumnDataSource implements DataSource {\n \n+  private static final int REALTIME_DICTIONARY_INIT_ID = 1;\n   private final FieldSpec spec;\n   private final MutableDictionaryReader dictionary;\n   private final Map<Object, Pair<Long, Object>> docIdMap;\n@@ -165,7 +166,7 @@ public boolean setPredicate(Predicate predicate) {\n             notINHolder.or(invertedINdex.getDocIdSetFor(i));\n           }\n         }\n-\n+        filteredDocIdBitmap = notINHolder;\n         break;\n       case RANGE:\n         String rangeStart = \"\";\n@@ -187,24 +188,24 @@ public boolean setPredicate(Predicate predicate) {\n         final String upper = rangeString.split(\",\")[1].substring(0, rangeString.split(\",\")[1].length() - 1);\n \n         if (lower.equals(\"*\")) {\n-          rangeStart = dictionary.getString(0);\n+          rangeStart = dictionary.getString(REALTIME_DICTIONARY_INIT_ID);\n+          incLower = true;\n+        } else {\n+          rangeStart = lower;\n         }\n \n         if (upper.equals(\"*\")) {\n-          rangeEnd = dictionary.getString(dictionary.length() - 1);\n-        }\n-\n-        List<Integer> rangeCollector = new ArrayList<Integer>();\n-\n-        for (int i = 0; i < dictionary.length(); i++) {\n-          if (dictionary.inRange(rangeStart, rangeEnd, i, incLower, incUpper)) {\n-            rangeCollector.add(i);\n-          }\n+          rangeEnd = dictionary.getString(dictionary.length());\n+          incUpper = true;\n+        } else {\n+          rangeEnd = upper;\n         }\n \n         MutableRoaringBitmap rangeBitmap = new MutableRoaringBitmap();\n-        for (Integer dicId : rangeCollector) {\n-          rangeBitmap.or(invertedINdex.getDocIdSetFor(dicId));\n+        for (int dicId = 1; dicId <= dictionary.length(); dicId++) {\n+          if (dictionary.inRange(rangeStart, rangeEnd, dicId, incLower, incUpper)) {\n+            rangeBitmap.or(invertedINdex.getDocIdSetFor(dicId));\n+          }\n         }\n \n         filteredDocIdBitmap = rangeBitmap;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "sha": "16ff3fd2fb8659ee49dcb464c30233b89baf391b",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/dictionary/MutableDictionaryReader.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/dictionary/MutableDictionaryReader.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/dictionary/MutableDictionaryReader.java",
                "patch": "@@ -66,7 +66,7 @@ public int getInt(int dictionaryId) {\n \n   @Override\n   public String getString(int dictionaryId) {\n-    return ((String) dictionaryIdBiMap.get(new Integer(dictionaryId)));\n+    return dictionaryIdBiMap.get(new Integer(dictionaryId)).toString();\n   }\n \n   @Override",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/dictionary/MutableDictionaryReader.java",
                "sha": "aa908b576b48227dda2033e60aae3f60a580646f",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/data/source/ColumnDataSourceImpl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/data/source/ColumnDataSourceImpl.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/data/source/ColumnDataSourceImpl.java",
                "patch": "@@ -125,7 +125,6 @@ public boolean setPredicate(Predicate p) {\n             holderNEQ.or(invertedIndex.getImmutable(i));\n           }\n         }\n-\n         filteredBitmap = holderNEQ;\n         break;\n       case IN:\n@@ -202,7 +201,8 @@ public boolean setPredicate(Predicate p) {\n         }\n \n         if (rangeStartIndex > rangeEndIndex) {\n-          return false;\n+          filteredBitmap = new MutableRoaringBitmap();\n+          return true;\n         }\n \n         final MutableRoaringBitmap rangeBitmapHolder = invertedIndex.getMutable(rangeStartIndex);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/data/source/ColumnDataSourceImpl.java",
                "sha": "041274423368957a561579e5decf49ab13eab1c1",
                "status": "modified"
            },
            {
                "additions": 33,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-transport/src/main/java/com/linkedin/pinot/requestHandler/BrokerRequestHandler.java",
                "changes": 57,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-transport/src/main/java/com/linkedin/pinot/requestHandler/BrokerRequestHandler.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 24,
                "filename": "pinot-transport/src/main/java/com/linkedin/pinot/requestHandler/BrokerRequestHandler.java",
                "patch": "@@ -186,37 +186,44 @@ private BrokerRequest getRealtimeBrokerRequest(BrokerRequest request) {\n   }\n \n   private void attachTimeBoundary(String hybridResourceName, BrokerRequest offlineRequest, boolean isOfflineRequest) {\n-    TimeBoundaryInfo timeBoundaryInfo = _timeBoundaryService.getTimeBoundaryInfoFor(hybridResourceName);\n+    TimeBoundaryInfo timeBoundaryInfo = _timeBoundaryService.getTimeBoundaryInfoFor(\n+        BrokerRequestUtils.getOfflineResourceNameForResource(hybridResourceName));\n     if (timeBoundaryInfo == null || timeBoundaryInfo.getTimeColumn() == null || timeBoundaryInfo.getTimeValue() == null) {\n       return;\n     }\n     FilterQuery timeFilterQuery = new FilterQuery();\n     timeFilterQuery.setOperator(FilterOperator.RANGE);\n     timeFilterQuery.setColumn(timeBoundaryInfo.getTimeColumn());\n+    timeFilterQuery.setNestedFilterQueryIds(new ArrayList<Integer>());\n     List<String> values = new ArrayList<String>();\n     if (isOfflineRequest) {\n       values.add(\"(*,\" + timeBoundaryInfo.getTimeValue() + \")\");\n     } else {\n-      values.add(\"[\" + timeBoundaryInfo.getTimeValue() + \", *)\");\n+      values.add(\"[\" + timeBoundaryInfo.getTimeValue() + \",*)\");\n     }\n     timeFilterQuery.setValue(values);\n+    timeFilterQuery.setId(-1);\n     FilterQuery currentFilterQuery = offlineRequest.getFilterQuery();\n-\n-    FilterQuery andFilterQuery = new FilterQuery();\n-    andFilterQuery.setOperator(FilterOperator.AND);\n-    List<Integer> nestedFilterQueryIds = new ArrayList<Integer>();\n-    nestedFilterQueryIds.add(currentFilterQuery.getId());\n-    nestedFilterQueryIds.add(timeFilterQuery.getId());\n-    andFilterQuery.setNestedFilterQueryIds(nestedFilterQueryIds);\n-    andFilterQuery.setId(andFilterQuery.hashCode());\n-\n-    FilterQueryMap filterSubQueryMap = offlineRequest.getFilterSubQueryMap();\n-\n-    filterSubQueryMap.putToFilterQueryMap(timeFilterQuery.getId(), timeFilterQuery);\n-    filterSubQueryMap.putToFilterQueryMap(andFilterQuery.getId(), andFilterQuery);\n-\n-    offlineRequest.setFilterQuery(andFilterQuery);\n-    offlineRequest.setFilterSubQueryMap(filterSubQueryMap);\n+    if (currentFilterQuery != null) {\n+      FilterQuery andFilterQuery = new FilterQuery();\n+      andFilterQuery.setOperator(FilterOperator.AND);\n+      List<Integer> nestedFilterQueryIds = new ArrayList<Integer>();\n+      nestedFilterQueryIds.add(currentFilterQuery.getId());\n+      nestedFilterQueryIds.add(timeFilterQuery.getId());\n+      andFilterQuery.setNestedFilterQueryIds(nestedFilterQueryIds);\n+      andFilterQuery.setId(-2);\n+      FilterQueryMap filterSubQueryMap = offlineRequest.getFilterSubQueryMap();\n+      filterSubQueryMap.putToFilterQueryMap(timeFilterQuery.getId(), timeFilterQuery);\n+      filterSubQueryMap.putToFilterQueryMap(andFilterQuery.getId(), andFilterQuery);\n+\n+      offlineRequest.setFilterQuery(andFilterQuery);\n+      offlineRequest.setFilterSubQueryMap(filterSubQueryMap);\n+    } else {\n+      FilterQueryMap filterSubQueryMap = new FilterQueryMap();\n+      filterSubQueryMap.putToFilterQueryMap(timeFilterQuery.getId(), timeFilterQuery);\n+      offlineRequest.setFilterQuery(timeFilterQuery);\n+      offlineRequest.setFilterSubQueryMap(filterSubQueryMap);\n+    }\n   }\n \n   private Object getDataTableFromBrokerRequest(final BrokerRequest request, BucketingSelection overriddenSelection)\n@@ -225,7 +232,7 @@ private Object getDataTableFromBrokerRequest(final BrokerRequest request, Bucket\n     final long routingStartTime = System.nanoTime();\n     RoutingTableLookupRequest rtRequest = new RoutingTableLookupRequest(request.getQuerySource().getResourceName());\n     Map<ServerInstance, SegmentIdSet> segmentServices = _routingTable.findServers(rtRequest);\n-    if (segmentServices == null) {\n+    if (segmentServices == null || segmentServices.isEmpty()) {\n       LOGGER.info(\"Not found ServerInstances to Segments Mapping:\");\n       return null;\n     }\n@@ -320,11 +327,11 @@ private Object getDataTableFromBrokerRequestList(final BrokerRequest federatedBr\n       final long routingStartTime = System.nanoTime();\n       RoutingTableLookupRequest rtRequest = new RoutingTableLookupRequest(request.getQuerySource().getResourceName());\n       Map<ServerInstance, SegmentIdSet> segmentServices = _routingTable.findServers(rtRequest);\n-      if (segmentServices == null) {\n-        LOGGER.info(\"Not found ServerInstances to Segments Mapping:\");\n-        return null;\n+      if (segmentServices == null || segmentServices.isEmpty()) {\n+        LOGGER.info(\"Not found ServerInstances to Segments Mapping for resource - \" + rtRequest.getResourceName());\n+        continue;\n       }\n-      LOGGER.info(\"Find ServerInstances to Segments Mapping:\");\n+      LOGGER.info(\"Find ServerInstances to Segments Mapping for resource - \" + rtRequest.getResourceName());\n       for (ServerInstance serverInstance : segmentServices.keySet()) {\n         LOGGER.info(serverInstance + \" : \" + segmentServices.get(serverInstance));\n       }\n@@ -363,6 +370,7 @@ private Object getDataTableFromBrokerRequestList(final BrokerRequest federatedBr\n         Map<ServerInstance, Throwable> errors = response.getError();\n \n         if (null != responses) {\n+          int responseSeq = 0;\n           for (Entry<ServerInstance, ByteBuf> e : responses.entrySet()) {\n             try {\n               ByteBuf b = e.getValue();\n@@ -372,8 +380,9 @@ private Object getDataTableFromBrokerRequestList(final BrokerRequest federatedBr\n               }\n               b.readBytes(b2);\n               DataTable r2 = new DataTable(b2);\n+              // Hybrid requests may get response from same instance, so we need to distinguish them.\n               ServerInstance decoratedServerInstance =\n-                  new ServerInstance(e.getKey().getHostname() + \"_\" + request.hashCode(), e.getKey().getPort());\n+                  new ServerInstance(e.getKey().getHostname(), e.getKey().getPort(), (responseSeq++));\n               instanceResponseMap.put(decoratedServerInstance, r2);\n             } catch (Exception ex) {\n               LOGGER.error(\"Got exceptions in collect query result for instance \" + e.getKey() + \", error: \"",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-transport/src/main/java/com/linkedin/pinot/requestHandler/BrokerRequestHandler.java",
                "sha": "215855402a8eb9ab48951ac782fe04b097b3498a",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e29933810a701e2e8c4690465ccb8774a0324180/pinot-transport/src/main/java/com/linkedin/pinot/routing/HelixExternalViewBasedTimeBoundaryService.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-transport/src/main/java/com/linkedin/pinot/routing/HelixExternalViewBasedTimeBoundaryService.java?ref=e29933810a701e2e8c4690465ccb8774a0324180",
                "deletions": 5,
                "filename": "pinot-transport/src/main/java/com/linkedin/pinot/routing/HelixExternalViewBasedTimeBoundaryService.java",
                "patch": "@@ -58,17 +58,14 @@ public synchronized void updateTimeBoundaryService(ExternalView externalView) {\n     OfflineDataResourceZKMetadata offlineDataResourceZKMetadata = ZKMetadataProvider.getOfflineResourceZKMetadata(_propertyStore, resourceName);\n     TimeUnit resourceTimeUnit = getTimeUnitFromString(offlineDataResourceZKMetadata.getTimeType());\n \n-    if (offlineSegmentZKMetadatas.get(0).getTimeUnit() != null) {\n+    if (!offlineSegmentZKMetadatas.isEmpty() && offlineSegmentZKMetadatas.get(0).getTimeUnit() != null) {\n       long maxTimeValue = -1;\n       for (OfflineSegmentZKMetadata offlineSegmentZKMetadata : offlineSegmentZKMetadatas) {\n         long endTime = resourceTimeUnit.convert(offlineSegmentZKMetadata.getEndTime(), offlineSegmentZKMetadata.getTimeUnit());\n-        if (maxTimeValue < endTime) {\n-          maxTimeValue = endTime;\n-        }\n+        maxTimeValue = Math.max(maxTimeValue, endTime);\n       }\n \n       TimeBoundaryInfo timeBoundaryInfo = new TimeBoundaryInfo();\n-      offlineDataResourceZKMetadata.getTimeType();\n       timeBoundaryInfo.setTimeColumn(offlineDataResourceZKMetadata.getTimeColumnName());\n       timeBoundaryInfo.setTimeValue(Long.toString(maxTimeValue));\n       _timeBoundaryInfoMap.put(resourceName, timeBoundaryInfo);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e29933810a701e2e8c4690465ccb8774a0324180/pinot-transport/src/main/java/com/linkedin/pinot/routing/HelixExternalViewBasedTimeBoundaryService.java",
                "sha": "d57635109238aa5fc6f347763beb1e81672d8c1d",
                "status": "modified"
            }
        ],
        "message": "Bug fixing for federated broker test.\n1. fix logic for RealtimeColumnDataSource set range predicate as for\nrealtime dictionary, dictId is from 1 to dictionary size.\n2. in MutableDictionaryReader, getString is also used for other data\ntype dictionary, so change it to toString().\n3. fixing  offline ColumnDataSourceImpl would set filteredBitMap to null\nin Range query, which actually should be an empty bitMap.\nThis is the root cause of DummyBlock get called.\n4. fixing NPE in HelixExternalViewBasedTimeBoundaryService.\n5. fixing time filter attching logic in BrokerRequestHandler for no\nfilter request.\n6. changing attached time filters' ids to -1 and -2 to avoid potiential\nduplicated.\n\nRB=453859\nR=xiafu\nA=kgopalak,jfim",
        "parent": "https://github.com/apache/incubator-pinot/commit/2a3cfbb468cd58ca23fc6aebab5f7d8bcab31663",
        "patched_files": [
            "ServerInstance.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestServerInstance.java"
        ]
    },
    "incubator-pinot_e58f95d": {
        "bug_id": "incubator-pinot_e58f95d",
        "commit": "https://github.com/apache/incubator-pinot/commit/e58f95d5e303079127bb81ee9a37137802ad987b",
        "file": [
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e58f95d5e303079127bb81ee9a37137802ad987b/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/config/FileBasedInstanceDataManagerConfig.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/config/FileBasedInstanceDataManagerConfig.java?ref=e58f95d5e303079127bb81ee9a37137802ad987b",
                "deletions": 2,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/config/FileBasedInstanceDataManagerConfig.java",
                "patch": "@@ -15,14 +15,14 @@\n  */\n package com.linkedin.pinot.core.data.manager.config;\n \n-import com.linkedin.pinot.common.segment.ReadMode;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import org.apache.commons.configuration.Configuration;\n import org.apache.commons.configuration.ConfigurationException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import com.linkedin.pinot.common.segment.ReadMode;\n \n \n /**\n@@ -127,7 +127,7 @@ public ReadMode getReadMode() {\n       return ReadMode.valueOf(_instanceDataManagerConfiguration.getString(READ_MODE));\n     } catch (Exception e) {\n       LOGGER.warn(\"Caught exception file getting the read mode\", e);\n-      return null;\n+      return ReadMode.DEFAULT_MODE;\n     }\n \n   }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e58f95d5e303079127bb81ee9a37137802ad987b/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/config/FileBasedInstanceDataManagerConfig.java",
                "sha": "4d71747c7784b86fdcbaa5c3a63311e73afdb1b4",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/e58f95d5e303079127bb81ee9a37137802ad987b/pinot-core/src/test/java/com/linkedin/pinot/core/offline/OfflineTableDataManagerTest.java",
                "changes": 54,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/test/java/com/linkedin/pinot/core/offline/OfflineTableDataManagerTest.java?ref=e58f95d5e303079127bb81ee9a37137802ad987b",
                "deletions": 37,
                "filename": "pinot-core/src/test/java/com/linkedin/pinot/core/offline/OfflineTableDataManagerTest.java",
                "patch": "@@ -15,18 +15,6 @@\n  */\n package com.linkedin.pinot.core.offline;\n \n-import com.google.common.collect.ImmutableList;\n-import com.linkedin.pinot.common.metrics.ServerMetrics;\n-import com.linkedin.pinot.common.segment.ReadMode;\n-import com.linkedin.pinot.common.segment.SegmentMetadata;\n-import com.linkedin.pinot.core.data.manager.config.TableDataManagerConfig;\n-import com.linkedin.pinot.core.data.manager.offline.AbstractTableDataManager;\n-import com.linkedin.pinot.core.data.manager.offline.OfflineSegmentDataManager;\n-import com.linkedin.pinot.core.data.manager.offline.OfflineTableDataManager;\n-import com.linkedin.pinot.core.data.manager.offline.SegmentDataManager;\n-import com.linkedin.pinot.core.data.manager.offline.TableDataManager;\n-import com.linkedin.pinot.core.indexsegment.IndexSegment;\n-import com.yammer.metrics.core.MetricsRegistry;\n import java.io.File;\n import java.lang.reflect.Field;\n import java.util.ArrayList;\n@@ -47,7 +35,18 @@\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.BeforeSuite;\n import org.testng.annotations.Test;\n-\n+import com.google.common.collect.ImmutableList;\n+import com.linkedin.pinot.common.metrics.ServerMetrics;\n+import com.linkedin.pinot.common.segment.ReadMode;\n+import com.linkedin.pinot.common.segment.SegmentMetadata;\n+import com.linkedin.pinot.core.data.manager.config.TableDataManagerConfig;\n+import com.linkedin.pinot.core.data.manager.offline.AbstractTableDataManager;\n+import com.linkedin.pinot.core.data.manager.offline.OfflineSegmentDataManager;\n+import com.linkedin.pinot.core.data.manager.offline.OfflineTableDataManager;\n+import com.linkedin.pinot.core.data.manager.offline.SegmentDataManager;\n+import com.linkedin.pinot.core.data.manager.offline.TableDataManager;\n+import com.linkedin.pinot.core.indexsegment.IndexSegment;\n+import com.yammer.metrics.core.MetricsRegistry;\n import static org.mockito.Mockito.*;\n \n \n@@ -201,8 +200,6 @@ public void basicTest() throws Exception {\n \n   /*\n    * These tests simulate the access of segments via OfflineTableDataManager.\n-   * Two flavors are simulated : One to replace segments via OFFLINE/ONLINE transitions\n-   * and the other to replace segments via helix message.\n    *\n    * It creates 31 segments (0..30) to start with and adds them to the tableDataManager (hi = 30, lo = 0)\n    * It spawns 10 \"query\" threads, and one \"helix\" thread.\n@@ -216,21 +213,13 @@ public void basicTest() throws Exception {\n    * - Replaces a segment (a randomm one between (lo,hi), 60% of the time)\n    * and then waits for a random of 50-300ms before attempting one of the ops again.\n    */\n-  @Test\n-  public void testOfflineOnline() throws Exception {\n-    runStressTest(false);\n-  }\n \n   @Test\n   public void testReplace() throws Exception {\n-    runStressTest(true);\n-  }\n-\n-  private void runStressTest(boolean replaceSegments) throws  Exception {\n     _lo = 0;\n     _hi = 30;   // Total number of segments we have in the server.\n     final int numQueryThreads = 10;\n-    final int runTimeSec = 30;\n+    final int runTimeSec = 20;\n     // With the current parameters, 3k ops take about 15 seconds, create about 90 segments and drop about half of them\n     // Running with coverage, it provides complete coverage of the (relevant) lines in OfflineTableDataManager\n \n@@ -243,13 +232,13 @@ private void runStressTest(boolean replaceSegments) throws  Exception {\n       _allSegManagers.add(_internalSegMap.get(segName));\n     }\n \n-    runStorageServer(numQueryThreads, runTimeSec, tableDataManager, replaceSegments);  // replaces segments while online\n+    runStorageServer(numQueryThreads, runTimeSec, tableDataManager);  // replaces segments while online\n \n //    System.out.println(\"Nops = \" + _numQueries + \",nDrops=\" + _nDestroys + \",nCreates=\" + _allSegments.size());\n     tableDataManager.shutDown();\n   }\n \n-  private void runStorageServer(int numQueryThreads, int runTimeSec, TableDataManager tableDataManager, boolean replaceSegments) throws Exception {\n+  private void runStorageServer(int numQueryThreads, int runTimeSec, TableDataManager tableDataManager) throws Exception {\n     // Start 1 helix worker thread and as many query threads as configured.\n     List<Thread> queryThreads = new ArrayList<>(numQueryThreads);\n     for (int i = 0; i < numQueryThreads; i++) {\n@@ -259,7 +248,7 @@ private void runStorageServer(int numQueryThreads, int runTimeSec, TableDataMana\n       segUserThread.start();\n     }\n \n-    TestHelixWorker helixWorker = new TestHelixWorker(tableDataManager, replaceSegments);\n+    TestHelixWorker helixWorker = new TestHelixWorker(tableDataManager);\n     Thread helixWorkerThread = new Thread(helixWorker);\n     helixWorkerThread.start();\n     _masterThread = Thread.currentThread();\n@@ -390,17 +379,15 @@ public void run() {\n     private final int _maxSleepMs;\n     private final Random _random = new Random();\n     private final TableDataManager _tableDataManager;\n-    private final boolean _replaceSegments;\n \n-    private TestHelixWorker(TableDataManager tableDataManager, boolean replaceSegments) {\n+    private TestHelixWorker(TableDataManager tableDataManager) {\n       _tableDataManager = tableDataManager;\n \n       _removePercent = 20;\n       _addPercent = 20;\n       _replacePercent = 60;\n       _minSleepMs = 50;\n       _maxSleepMs = 300;\n-      _replaceSegments = replaceSegments;\n     }\n \n     @Override\n@@ -442,13 +429,6 @@ private void addSegment() {\n     private void replaceSegment() {\n       int segToReplace = _random.nextInt(_hi-_lo+1) + _lo;\n       final String segName = segmentPrefix + segToReplace;\n-      if (!_replaceSegments) {\n-        _tableDataManager.removeSegment(segName);\n-        try {\n-          Thread.sleep(4);\n-        } catch (InterruptedException e) {\n-        }\n-      }\n       _tableDataManager.addSegment(makeIndexSegment(segName, _random.nextInt()));\n       _allSegManagers.add(_internalSegMap.get(segName));\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/e58f95d5e303079127bb81ee9a37137802ad987b/pinot-core/src/test/java/com/linkedin/pinot/core/offline/OfflineTableDataManagerTest.java",
                "sha": "44393672279678a70f4f36d8013bd1e5ca719871",
                "status": "modified"
            }
        ],
        "message": "Fixed NPE in FileBased instance config, removed segment replace test via OFFLINE/ONLINE (no longer used) (#1638)",
        "parent": "https://github.com/apache/incubator-pinot/commit/362d4de73ac176f4de5b1018a464bc8eb8c88918",
        "patched_files": [
            "OfflineTableDataManager.java",
            "FileBasedInstanceDataManagerConfig.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "OfflineTableDataManagerTest.java"
        ]
    },
    "incubator-pinot_eccf573": {
        "bug_id": "incubator-pinot_eccf573",
        "commit": "https://github.com/apache/incubator-pinot/commit/eccf573a636de84e60c85cc331fea0afc172c90c",
        "file": [
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/queryquota/TableQueryQuotaManagerTest.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/test/java/org/apache/pinot/broker/queryquota/TableQueryQuotaManagerTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 9,
                "filename": "pinot-broker/src/test/java/org/apache/pinot/broker/queryquota/TableQueryQuotaManagerTest.java",
                "patch": "@@ -146,7 +146,7 @@ public void testOfflineTableWithNullQuotaButWithRealtimeTableConfigNullQpsConfig\n             .setRetentionTimeUnit(\"DAYS\").setRetentionTimeValue(\"1\").setSegmentPushType(\"APPEND\")\n             .setBrokerTenant(\"testBroker\").setServerTenant(\"testServer\").build();\n     ZKMetadataProvider\n-        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, TableConfig.toZnRecord(realtimeTableConfig));\n+        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, realtimeTableConfig.toZNRecord());\n \n     ExternalView brokerResource = generateBrokerResource(OFFLINE_TABLE_NAME);\n     TableConfig tableConfig = generateDefaultTableConfig(OFFLINE_TABLE_NAME);\n@@ -169,7 +169,7 @@ public void testOfflineTableWithNullQuotaButWithRealtimeTableConfigNotNullQpsCon\n             .setRetentionTimeUnit(\"DAYS\").setRetentionTimeValue(\"1\").setSegmentPushType(\"APPEND\")\n             .setBrokerTenant(\"testBroker\").setServerTenant(\"testServer\").build();\n     ZKMetadataProvider\n-        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, TableConfig.toZnRecord(realtimeTableConfig));\n+        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, realtimeTableConfig.toZNRecord());\n \n     ExternalView brokerResource = generateBrokerResource(REALTIME_TABLE_NAME);\n     TableConfig tableConfig = generateDefaultTableConfig(OFFLINE_TABLE_NAME);\n@@ -205,9 +205,8 @@ public void testBothTableHaveQpsQuotaConfig()\n             .setBrokerTenant(\"testBroker\").setServerTenant(\"testServer\").build();\n \n     ZKMetadataProvider\n-        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, TableConfig.toZnRecord(realtimeTableConfig));\n-    ZKMetadataProvider\n-        .setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, TableConfig.toZnRecord(offlineTableConfig));\n+        .setRealtimeTableConfig(_testPropertyStore, REALTIME_TABLE_NAME, realtimeTableConfig.toZNRecord());\n+    ZKMetadataProvider.setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, offlineTableConfig.toZNRecord());\n \n     // Since each table has 2 online brokers, per broker rate becomes 100.0 / 2 = 50.0\n     _tableQueryQuotaManager.initTableQueryQuota(offlineTableConfig, brokerResource);\n@@ -261,8 +260,7 @@ public void testRealtimeTableWithNullQuotaButWithOfflineTableConfigNullQpsConfig\n         new TableConfig.Builder(TableType.OFFLINE).setTableName(RAW_TABLE_NAME).setQuotaConfig(quotaConfig)\n             .setRetentionTimeUnit(\"DAYS\").setRetentionTimeValue(\"1\").setSegmentPushType(\"APPEND\")\n             .setBrokerTenant(\"testBroker\").setServerTenant(\"testServer\").build();\n-    ZKMetadataProvider\n-        .setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, TableConfig.toZnRecord(offlineTableConfig));\n+    ZKMetadataProvider.setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, offlineTableConfig.toZNRecord());\n \n     ExternalView brokerResource = generateBrokerResource(REALTIME_TABLE_NAME);\n     TableConfig tableConfig = generateDefaultTableConfig(REALTIME_TABLE_NAME);\n@@ -280,8 +278,7 @@ public void testRealtimeTableWithNullQuotaButWithOfflineTableConfigNotNullQpsCon\n         new TableConfig.Builder(TableType.OFFLINE).setTableName(RAW_TABLE_NAME).setQuotaConfig(quotaConfig)\n             .setRetentionTimeUnit(\"DAYS\").setRetentionTimeValue(\"1\").setSegmentPushType(\"APPEND\")\n             .setBrokerTenant(\"testBroker\").setServerTenant(\"testServer\").build();\n-    ZKMetadataProvider\n-        .setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, TableConfig.toZnRecord(offlineTableConfig));\n+    ZKMetadataProvider.setOfflineTableConfig(_testPropertyStore, OFFLINE_TABLE_NAME, offlineTableConfig.toZNRecord());\n \n     ExternalView brokerResource = generateBrokerResource(OFFLINE_TABLE_NAME);\n     TableConfig tableConfig = generateDefaultTableConfig(REALTIME_TABLE_NAME);",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/queryquota/TableQueryQuotaManagerTest.java",
                "sha": "1b5d7098a2dc800b69a149529bcfce8b0788de31",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/TimeBoundaryServiceTest.java",
                "changes": 3,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/test/java/org/apache/pinot/broker/routing/TimeBoundaryServiceTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 2,
                "filename": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/TimeBoundaryServiceTest.java",
                "patch": "@@ -125,7 +125,6 @@ private void addingTableToPropertyStore(String tableName)\n       throws Exception {\n     TableConfig tableConfig = new TableConfig.Builder(CommonConstants.Helix.TableType.OFFLINE).setTableName(tableName)\n         .setTimeColumnName(\"timestamp\").setTimeType(\"DAYS\").build();\n-    ZKMetadataProvider\n-        .setOfflineTableConfig(_propertyStore, tableConfig.getTableName(), TableConfig.toZnRecord(tableConfig));\n+    ZKMetadataProvider.setOfflineTableConfig(_propertyStore, tableConfig.getTableName(), tableConfig.toZNRecord());\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/TimeBoundaryServiceTest.java",
                "sha": "31e68398c685769e824701bbd7f79e399289373e",
                "status": "modified"
            },
            {
                "additions": 2,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/HighLevelConsumerRoutingTableBuilderTest.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/HighLevelConsumerRoutingTableBuilderTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 2,
                "filename": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/HighLevelConsumerRoutingTableBuilderTest.java",
                "patch": "@@ -49,8 +49,8 @@ public void testHlcRoutingTableBuilder() {\n \n     Random random = new Random();\n \n-    TableConfig tableConfig = new TableConfig();\n-    tableConfig.setTableName(\"tableName\");\n+    TableConfig tableConfig =\n+        new TableConfig.Builder(CommonConstants.Helix.TableType.REALTIME).setTableName(\"tableName\").build();\n     HighLevelConsumerBasedRoutingTableBuilder routingTableBuilder = new HighLevelConsumerBasedRoutingTableBuilder();\n     routingTableBuilder.init(new BaseConfiguration(), tableConfig, null, null);\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/HighLevelConsumerRoutingTableBuilderTest.java",
                "sha": "225f3f89ee07ca830286beaa4029901108280f51",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/LowLevelConsumerRoutingTableBuilderTest.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/LowLevelConsumerRoutingTableBuilderTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 6,
                "filename": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/LowLevelConsumerRoutingTableBuilderTest.java",
                "patch": "@@ -52,8 +52,8 @@ public void testAllOnlineRoutingTable() {\n     final int ITERATIONS = 50;\n     Random random = new Random();\n \n-    TableConfig tableConfig = new TableConfig();\n-    tableConfig.setTableName(\"tableName\");\n+    TableConfig tableConfig =\n+        new TableConfig.Builder(CommonConstants.Helix.TableType.REALTIME).setTableName(\"tableName\").build();\n     LowLevelConsumerRoutingTableBuilder routingTableBuilder = new LowLevelConsumerRoutingTableBuilder();\n     routingTableBuilder.init(new BaseConfiguration(), tableConfig, null, null);\n \n@@ -161,8 +161,8 @@ public void testMultipleConsumingSegments() {\n     final int ONLINE_SEGMENT_COUNT = 8;\n     final int CONSUMING_SEGMENT_COUNT = SEGMENT_COUNT - ONLINE_SEGMENT_COUNT;\n \n-    TableConfig tableConfig = new TableConfig();\n-    tableConfig.setTableName(\"tableName\");\n+    TableConfig tableConfig =\n+        new TableConfig.Builder(CommonConstants.Helix.TableType.REALTIME).setTableName(\"tableName\").build();\n     LowLevelConsumerRoutingTableBuilder routingTableBuilder = new LowLevelConsumerRoutingTableBuilder();\n     routingTableBuilder.init(new BaseConfiguration(), tableConfig, null, null);\n \n@@ -207,8 +207,8 @@ public void testShutdownInProgressServer() {\n     final int SEGMENT_COUNT = 10;\n     final int ONLINE_SEGMENT_COUNT = 8;\n \n-    TableConfig tableConfig = new TableConfig();\n-    tableConfig.setTableName(\"tableName\");\n+    TableConfig tableConfig =\n+        new TableConfig.Builder(CommonConstants.Helix.TableType.REALTIME).setTableName(\"tableName\").build();\n     LowLevelConsumerRoutingTableBuilder routingTableBuilder = new LowLevelConsumerRoutingTableBuilder();\n     routingTableBuilder.init(new BaseConfiguration(), tableConfig, null, null);\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-broker/src/test/java/org/apache/pinot/broker/routing/builder/LowLevelConsumerRoutingTableBuilderTest.java",
                "sha": "23be4be07ea7c1b5b8384c621fdf95d3e825db37",
                "status": "modified"
            },
            {
                "additions": 139,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-common/src/main/java/org/apache/pinot/common/config/TableConfig.java",
                "changes": 235,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/main/java/org/apache/pinot/common/config/TableConfig.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 96,
                "filename": "pinot-common/src/main/java/org/apache/pinot/common/config/TableConfig.java",
                "patch": "@@ -27,7 +27,6 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n-import javax.annotation.Nonnull;\n import javax.annotation.Nullable;\n import org.apache.helix.ZNRecord;\n import org.apache.pinot.common.data.StarTreeIndexSpec;\n@@ -51,6 +50,8 @@\n   public static final String TASK_CONFIG_KEY = \"task\";\n   public static final String ROUTING_CONFIG_KEY = \"routing\";\n \n+  private static final String FIELD_MISSING_MESSAGE_TEMPLATE = \"Mandatory field '%s' is missing\";\n+\n   @ConfigKey(\"name\")\n   @ConfigDoc(value = \"The name for the table.\", mandatory = true, exampleValue = \"myTable\")\n   private String _tableName;\n@@ -81,15 +82,17 @@\n   @NestedConfig\n   private RoutingConfig _routingConfig;\n \n+  /**\n+   * NOTE: DO NOT use this constructor, use builder instead. This constructor is for deserializer only.\n+   */\n   public TableConfig() {\n     // TODO: currently these 2 fields are annotated as non-null. Revisit to see whether that's necessary\n     _tenantConfig = new TenantConfig();\n     _customConfig = new TableCustomConfig();\n   }\n \n-  private TableConfig(@Nonnull String tableName, @Nonnull TableType tableType,\n-      @Nonnull SegmentsValidationAndRetentionConfig validationConfig, @Nonnull TenantConfig tenantConfig,\n-      @Nonnull IndexingConfig indexingConfig, @Nonnull TableCustomConfig customConfig,\n+  private TableConfig(String tableName, TableType tableType, SegmentsValidationAndRetentionConfig validationConfig,\n+      TenantConfig tenantConfig, IndexingConfig indexingConfig, TableCustomConfig customConfig,\n       @Nullable QuotaConfig quotaConfig, @Nullable TableTaskConfig taskConfig, @Nullable RoutingConfig routingConfig) {\n     _tableName = TableNameBuilder.forType(tableType).tableNameWithType(tableName);\n     _tableType = tableType;\n@@ -102,111 +105,147 @@ private TableConfig(@Nonnull String tableName, @Nonnull TableType tableType,\n     _routingConfig = routingConfig;\n   }\n \n-  // For backward compatible\n-  @Deprecated\n-  @Nonnull\n-  public static TableConfig init(@Nonnull String jsonConfigString)\n-      throws IOException {\n-    return fromJsonString(jsonConfigString);\n-  }\n-\n   public static TableConfig fromJsonString(String jsonString)\n       throws IOException {\n-    return fromJSONConfig(JsonUtils.stringToJsonNode(jsonString));\n+    return fromJsonConfig(JsonUtils.stringToJsonNode(jsonString));\n   }\n \n-  @Nonnull\n-  public static TableConfig fromJSONConfig(@Nonnull JsonNode jsonConfig)\n+  public static TableConfig fromJsonConfig(JsonNode jsonConfig)\n       throws IOException {\n-    TableType tableType = TableType.valueOf(jsonConfig.get(TABLE_TYPE_KEY).asText().toUpperCase());\n-    String tableName = TableNameBuilder.forType(tableType).tableNameWithType(jsonConfig.get(TABLE_NAME_KEY).asText());\n+    // Mandatory fields\n+    JsonNode jsonTableType = jsonConfig.get(TABLE_TYPE_KEY);\n+    Preconditions\n+        .checkState(jsonTableType != null && !jsonTableType.isNull(), FIELD_MISSING_MESSAGE_TEMPLATE, TABLE_TYPE_KEY);\n+    TableType tableType = TableType.valueOf(jsonTableType.asText().toUpperCase());\n+\n+    JsonNode jsonTableName = jsonConfig.get(TABLE_NAME_KEY);\n+    Preconditions\n+        .checkState(jsonTableName != null && !jsonTableName.isNull(), FIELD_MISSING_MESSAGE_TEMPLATE, TABLE_NAME_KEY);\n+    String tableName = TableNameBuilder.forType(tableType).tableNameWithType(jsonTableName.asText());\n \n     SegmentsValidationAndRetentionConfig validationConfig =\n         extractChildConfig(jsonConfig, VALIDATION_CONFIG_KEY, SegmentsValidationAndRetentionConfig.class);\n+    Preconditions.checkState(validationConfig != null, FIELD_MISSING_MESSAGE_TEMPLATE, VALIDATION_CONFIG_KEY);\n+\n     TenantConfig tenantConfig = extractChildConfig(jsonConfig, TENANT_CONFIG_KEY, TenantConfig.class);\n+    Preconditions.checkState(tenantConfig != null, FIELD_MISSING_MESSAGE_TEMPLATE, TENANT_CONFIG_KEY);\n+\n     IndexingConfig indexingConfig = extractChildConfig(jsonConfig, INDEXING_CONFIG_KEY, IndexingConfig.class);\n+    Preconditions.checkState(indexingConfig != null, FIELD_MISSING_MESSAGE_TEMPLATE, INDEXING_CONFIG_KEY);\n+\n     TableCustomConfig customConfig = extractChildConfig(jsonConfig, CUSTOM_CONFIG_KEY, TableCustomConfig.class);\n-    QuotaConfig quotaConfig = null;\n-    if (jsonConfig.has(QUOTA_CONFIG_KEY)) {\n-      quotaConfig = extractChildConfig(jsonConfig, QUOTA_CONFIG_KEY, QuotaConfig.class);\n+    Preconditions.checkState(customConfig != null, FIELD_MISSING_MESSAGE_TEMPLATE, CUSTOM_CONFIG_KEY);\n+\n+    // Optional fields\n+    QuotaConfig quotaConfig = extractChildConfig(jsonConfig, QUOTA_CONFIG_KEY, QuotaConfig.class);\n+    if (quotaConfig != null) {\n       quotaConfig.validate();\n     }\n-    TableTaskConfig taskConfig = null;\n-    if (jsonConfig.has(TASK_CONFIG_KEY)) {\n-      taskConfig = extractChildConfig(jsonConfig, TASK_CONFIG_KEY, TableTaskConfig.class);\n-    }\n-    RoutingConfig routingConfig = null;\n-    if (jsonConfig.has(ROUTING_CONFIG_KEY)) {\n-      routingConfig = extractChildConfig(jsonConfig, ROUTING_CONFIG_KEY, RoutingConfig.class);\n-    }\n+\n+    TableTaskConfig taskConfig = extractChildConfig(jsonConfig, TASK_CONFIG_KEY, TableTaskConfig.class);\n+\n+    RoutingConfig routingConfig = extractChildConfig(jsonConfig, ROUTING_CONFIG_KEY, RoutingConfig.class);\n \n     return new TableConfig(tableName, tableType, validationConfig, tenantConfig, indexingConfig, customConfig,\n         quotaConfig, taskConfig, routingConfig);\n   }\n \n   /**\n-   * Extracts the child config from the table config.\n+   * Extracts the child config from the table config. Returns {@code null} if child config does not exist.\n    * <p>\n    * NOTE: for historical reason, we support two kinds of nested config values: normal json and serialized json string\n    */\n+  @Nullable\n   private static <T> T extractChildConfig(JsonNode jsonConfig, String childConfigKey, Class<T> childConfigClass)\n       throws IOException {\n     JsonNode childConfigNode = jsonConfig.get(childConfigKey);\n+    if (childConfigNode == null || childConfigNode.isNull()) {\n+      return null;\n+    }\n     if (childConfigNode.isObject()) {\n       return JsonUtils.jsonNodeToObject(childConfigNode, childConfigClass);\n     } else {\n       return JsonUtils.stringToObject(childConfigNode.asText(), childConfigClass);\n     }\n   }\n \n-  @Nonnull\n-  public static JsonNode toJSONConfig(@Nonnull TableConfig tableConfig) {\n+  public ObjectNode toJsonConfig() {\n+    validate();\n+\n     ObjectNode jsonConfig = JsonUtils.newObjectNode();\n-    jsonConfig.put(TABLE_NAME_KEY, tableConfig._tableName);\n-    jsonConfig.put(TABLE_TYPE_KEY, tableConfig._tableType.toString());\n-    jsonConfig.set(VALIDATION_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._validationConfig));\n-    jsonConfig.set(TENANT_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._tenantConfig));\n-    jsonConfig.set(INDEXING_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._indexingConfig));\n-    jsonConfig.set(CUSTOM_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._customConfig));\n-    if (tableConfig._quotaConfig != null) {\n-      jsonConfig.set(QUOTA_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._quotaConfig));\n+\n+    // Mandatory fields\n+    jsonConfig.put(TABLE_NAME_KEY, _tableName);\n+    jsonConfig.put(TABLE_TYPE_KEY, _tableType.toString());\n+    jsonConfig.set(VALIDATION_CONFIG_KEY, JsonUtils.objectToJsonNode(_validationConfig));\n+    jsonConfig.set(TENANT_CONFIG_KEY, JsonUtils.objectToJsonNode(_tenantConfig));\n+    jsonConfig.set(INDEXING_CONFIG_KEY, JsonUtils.objectToJsonNode(_indexingConfig));\n+    jsonConfig.set(CUSTOM_CONFIG_KEY, JsonUtils.objectToJsonNode(_customConfig));\n+\n+    // Optional fields\n+    if (_quotaConfig != null) {\n+      jsonConfig.set(QUOTA_CONFIG_KEY, JsonUtils.objectToJsonNode(_quotaConfig));\n     }\n-    if (tableConfig._taskConfig != null) {\n-      jsonConfig.set(TASK_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._taskConfig));\n+    if (_taskConfig != null) {\n+      jsonConfig.set(TASK_CONFIG_KEY, JsonUtils.objectToJsonNode(_taskConfig));\n     }\n-    if (tableConfig._routingConfig != null) {\n-      jsonConfig.set(ROUTING_CONFIG_KEY, JsonUtils.objectToJsonNode(tableConfig._routingConfig));\n+    if (_routingConfig != null) {\n+      jsonConfig.set(ROUTING_CONFIG_KEY, JsonUtils.objectToJsonNode(_routingConfig));\n     }\n+\n     return jsonConfig;\n   }\n \n-  @Nonnull\n-  public static TableConfig fromZnRecord(@Nonnull ZNRecord znRecord)\n+  public String toJsonConfigString() {\n+    return toJsonConfig().toString();\n+  }\n+\n+  public static TableConfig fromZnRecord(ZNRecord znRecord)\n       throws IOException {\n     Map<String, String> simpleFields = znRecord.getSimpleFields();\n-    TableType tableType = TableType.valueOf(simpleFields.get(TABLE_TYPE_KEY).toUpperCase());\n-    String tableName = TableNameBuilder.forType(tableType).tableNameWithType(simpleFields.get(TABLE_NAME_KEY));\n+\n+    // Mandatory fields\n+    String tableTypeString = simpleFields.get(TABLE_TYPE_KEY);\n+    Preconditions.checkState(tableTypeString != null, FIELD_MISSING_MESSAGE_TEMPLATE, TABLE_TYPE_KEY);\n+    TableType tableType = TableType.valueOf(tableTypeString.toUpperCase());\n+\n+    String tableNameString = simpleFields.get(TABLE_NAME_KEY);\n+    Preconditions.checkState(tableNameString != null, FIELD_MISSING_MESSAGE_TEMPLATE, TABLE_NAME_KEY);\n+    String tableName = TableNameBuilder.forType(tableType).tableNameWithType(tableNameString);\n+\n+    String validationConfigString = simpleFields.get(VALIDATION_CONFIG_KEY);\n+    Preconditions.checkState(validationConfigString != null, FIELD_MISSING_MESSAGE_TEMPLATE, VALIDATION_CONFIG_KEY);\n     SegmentsValidationAndRetentionConfig validationConfig =\n-        JsonUtils.stringToObject(simpleFields.get(VALIDATION_CONFIG_KEY), SegmentsValidationAndRetentionConfig.class);\n-    TenantConfig tenantConfig = JsonUtils.stringToObject(simpleFields.get(TENANT_CONFIG_KEY), TenantConfig.class);\n-    IndexingConfig indexingConfig =\n-        JsonUtils.stringToObject(simpleFields.get(INDEXING_CONFIG_KEY), IndexingConfig.class);\n-    TableCustomConfig customConfig =\n-        JsonUtils.stringToObject(simpleFields.get(CUSTOM_CONFIG_KEY), TableCustomConfig.class);\n+        JsonUtils.stringToObject(validationConfigString, SegmentsValidationAndRetentionConfig.class);\n+\n+    String tenantConfigString = simpleFields.get(TENANT_CONFIG_KEY);\n+    Preconditions.checkState(tenantConfigString != null, FIELD_MISSING_MESSAGE_TEMPLATE, TENANT_CONFIG_KEY);\n+    TenantConfig tenantConfig = JsonUtils.stringToObject(tenantConfigString, TenantConfig.class);\n+\n+    String indexingConfigString = simpleFields.get(INDEXING_CONFIG_KEY);\n+    Preconditions.checkState(indexingConfigString != null, FIELD_MISSING_MESSAGE_TEMPLATE, INDEXING_CONFIG_KEY);\n+    IndexingConfig indexingConfig = JsonUtils.stringToObject(indexingConfigString, IndexingConfig.class);\n+\n+    String customConfigString = simpleFields.get(CUSTOM_CONFIG_KEY);\n+    Preconditions.checkState(customConfigString != null, FIELD_MISSING_MESSAGE_TEMPLATE, CUSTOM_CONFIG_KEY);\n+    TableCustomConfig customConfig = JsonUtils.stringToObject(customConfigString, TableCustomConfig.class);\n+\n+    // Optional fields\n     QuotaConfig quotaConfig = null;\n     String quotaConfigString = simpleFields.get(QUOTA_CONFIG_KEY);\n     if (quotaConfigString != null) {\n       quotaConfig = JsonUtils.stringToObject(quotaConfigString, QuotaConfig.class);\n       quotaConfig.validate();\n     }\n+\n     TableTaskConfig taskConfig = null;\n     String taskConfigString = simpleFields.get(TASK_CONFIG_KEY);\n     if (taskConfigString != null) {\n       taskConfig = JsonUtils.stringToObject(taskConfigString, TableTaskConfig.class);\n     }\n-    String routingConfigString = simpleFields.get(ROUTING_CONFIG_KEY);\n \n     RoutingConfig routingConfig = null;\n+    String routingConfigString = simpleFields.get(ROUTING_CONFIG_KEY);\n     if (routingConfigString != null) {\n       routingConfig = JsonUtils.stringToObject(routingConfigString, RoutingConfig.class);\n     }\n@@ -215,84 +254,94 @@ public static TableConfig fromZnRecord(@Nonnull ZNRecord znRecord)\n         quotaConfig, taskConfig, routingConfig);\n   }\n \n-  @Nonnull\n-  public static ZNRecord toZnRecord(@Nonnull TableConfig tableConfig) {\n-    ZNRecord znRecord = new ZNRecord(tableConfig.getTableName());\n+  public ZNRecord toZNRecord()\n+      throws JsonProcessingException {\n+    validate();\n+\n     Map<String, String> simpleFields = new HashMap<>();\n-    simpleFields.put(TABLE_NAME_KEY, tableConfig._tableName);\n-    simpleFields.put(TABLE_TYPE_KEY, tableConfig._tableType.toString());\n-    try {\n-      simpleFields.put(VALIDATION_CONFIG_KEY, JsonUtils.objectToString(tableConfig._validationConfig));\n-      simpleFields.put(TENANT_CONFIG_KEY, JsonUtils.objectToString(tableConfig._tenantConfig));\n-      simpleFields.put(INDEXING_CONFIG_KEY, JsonUtils.objectToString(tableConfig._indexingConfig));\n-      simpleFields.put(CUSTOM_CONFIG_KEY, JsonUtils.objectToString(tableConfig._customConfig));\n-      if (tableConfig._quotaConfig != null) {\n-        simpleFields.put(QUOTA_CONFIG_KEY, JsonUtils.objectToString(tableConfig._quotaConfig));\n-      }\n-      if (tableConfig._taskConfig != null) {\n-        simpleFields.put(TASK_CONFIG_KEY, JsonUtils.objectToString(tableConfig._taskConfig));\n-      }\n-      if (tableConfig._routingConfig != null) {\n-        simpleFields.put(ROUTING_CONFIG_KEY, JsonUtils.objectToString(tableConfig._routingConfig));\n-      }\n-    } catch (IOException e) {\n-      throw new RuntimeException(e);\n+\n+    // Mandatory fields\n+    simpleFields.put(TABLE_NAME_KEY, _tableName);\n+    simpleFields.put(TABLE_TYPE_KEY, _tableType.toString());\n+    simpleFields.put(VALIDATION_CONFIG_KEY, JsonUtils.objectToString(_validationConfig));\n+    simpleFields.put(TENANT_CONFIG_KEY, JsonUtils.objectToString(_tenantConfig));\n+    simpleFields.put(INDEXING_CONFIG_KEY, JsonUtils.objectToString(_indexingConfig));\n+    simpleFields.put(CUSTOM_CONFIG_KEY, JsonUtils.objectToString(_customConfig));\n+\n+    // Optional fields\n+    if (_quotaConfig != null) {\n+      simpleFields.put(QUOTA_CONFIG_KEY, JsonUtils.objectToString(_quotaConfig));\n+    }\n+    if (_taskConfig != null) {\n+      simpleFields.put(TASK_CONFIG_KEY, JsonUtils.objectToString(_taskConfig));\n     }\n+    if (_routingConfig != null) {\n+      simpleFields.put(ROUTING_CONFIG_KEY, JsonUtils.objectToString(_routingConfig));\n+    }\n+\n+    ZNRecord znRecord = new ZNRecord(_tableName);\n     znRecord.setSimpleFields(simpleFields);\n     return znRecord;\n   }\n \n-  @Nonnull\n+  /**\n+   * Validates the table config.\n+   * TODO: revisit to see whether all the following fields are mandatory\n+   */\n+  public void validate() {\n+    Preconditions.checkState(_tableName != null, \"Table name is missing\");\n+    Preconditions.checkState(_tableType != null, \"Table type is missing\");\n+    Preconditions.checkState(_validationConfig != null, \"Validation config is missing\");\n+    Preconditions.checkState(_tenantConfig != null, \"Tenant config is missing\");\n+    Preconditions.checkState(_indexingConfig != null, \"Indexing config is missing\");\n+    Preconditions.checkState(_customConfig != null, \"Custom config is missing\");\n+  }\n+\n   public String getTableName() {\n     return _tableName;\n   }\n \n-  public void setTableName(@Nonnull String tableName) {\n+  public void setTableName(String tableName) {\n     _tableName = tableName;\n   }\n \n-  @Nonnull\n   public TableType getTableType() {\n     return _tableType;\n   }\n \n-  public void setTableType(@Nonnull TableType tableType) {\n+  public void setTableType(TableType tableType) {\n     _tableType = tableType;\n   }\n \n-  @Nonnull\n   public SegmentsValidationAndRetentionConfig getValidationConfig() {\n     return _validationConfig;\n   }\n \n-  public void setValidationConfig(@Nonnull SegmentsValidationAndRetentionConfig validationConfig) {\n+  public void setValidationConfig(SegmentsValidationAndRetentionConfig validationConfig) {\n     _validationConfig = validationConfig;\n   }\n \n-  @Nonnull\n   public TenantConfig getTenantConfig() {\n     return _tenantConfig;\n   }\n \n-  public void setTenantConfig(@Nonnull TenantConfig tenantConfig) {\n+  public void setTenantConfig(TenantConfig tenantConfig) {\n     _tenantConfig = tenantConfig;\n   }\n \n-  @Nonnull\n   public IndexingConfig getIndexingConfig() {\n     return _indexingConfig;\n   }\n \n-  public void setIndexingConfig(@Nonnull IndexingConfig indexingConfig) {\n+  public void setIndexingConfig(IndexingConfig indexingConfig) {\n     _indexingConfig = indexingConfig;\n   }\n \n-  @Nonnull\n   public TableCustomConfig getCustomConfig() {\n     return _customConfig;\n   }\n \n-  public void setCustomConfig(@Nonnull TableCustomConfig customConfig) {\n+  public void setCustomConfig(TableCustomConfig customConfig) {\n     _customConfig = customConfig;\n   }\n \n@@ -301,7 +350,7 @@ public QuotaConfig getQuotaConfig() {\n     return _quotaConfig;\n   }\n \n-  public void setQuotaConfig(@Nullable QuotaConfig quotaConfig) {\n+  public void setQuotaConfig(QuotaConfig quotaConfig) {\n     _quotaConfig = quotaConfig;\n   }\n \n@@ -310,7 +359,7 @@ public TableTaskConfig getTaskConfig() {\n     return _taskConfig;\n   }\n \n-  public void setTaskConfig(@Nullable TableTaskConfig taskConfig) {\n+  public void setTaskConfig(TableTaskConfig taskConfig) {\n     _taskConfig = taskConfig;\n   }\n \n@@ -323,16 +372,10 @@ public void setRoutingConfig(RoutingConfig routingConfig) {\n     _routingConfig = routingConfig;\n   }\n \n-  @Nonnull\n-  public String toJSONConfigString()\n-      throws IOException {\n-    return toJSONConfig(this).toString();\n-  }\n-\n   @Override\n   public String toString() {\n     try {\n-      return JsonUtils.objectToPrettyString(toJSONConfig(this));\n+      return JsonUtils.objectToPrettyString(toJsonConfig());\n     } catch (JsonProcessingException e) {\n       throw new RuntimeException(e);\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-common/src/main/java/org/apache/pinot/common/config/TableConfig.java",
                "sha": "2f4ee1c3ff91f97c491d7a70c74c0734171e86bf",
                "status": "modified"
            },
            {
                "additions": 195,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-common/src/test/java/org/apache/pinot/common/config/TableConfigTest.java",
                "changes": 336,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-common/src/test/java/org/apache/pinot/common/config/TableConfigTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 141,
                "filename": "pinot-common/src/test/java/org/apache/pinot/common/config/TableConfigTest.java",
                "patch": "@@ -18,21 +18,95 @@\n  */\n package org.apache.pinot.common.config;\n \n-import com.fasterxml.jackson.databind.JsonNode;\n import com.fasterxml.jackson.databind.node.ObjectNode;\n import java.util.Collections;\n import java.util.HashSet;\n import java.util.Set;\n-import org.apache.helix.ZNRecord;\n import org.apache.pinot.common.data.StarTreeIndexSpec;\n import org.apache.pinot.common.utils.CommonConstants.Helix.TableType;\n import org.apache.pinot.startree.hll.HllConfig;\n-import org.testng.Assert;\n import org.testng.annotations.Test;\n \n+import static org.testng.Assert.*;\n+\n \n public class TableConfigTest {\n \n+  @Test\n+  public void testSerializeMandatoryFields()\n+      throws Exception {\n+    TableConfig tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setTableName(null);\n+    testSerializeMandatoryFields(tableConfig, \"Table name\");\n+\n+    tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setTableType(null);\n+    testSerializeMandatoryFields(tableConfig, \"Table type\");\n+\n+    tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setValidationConfig(null);\n+    testSerializeMandatoryFields(tableConfig, \"Validation config\");\n+\n+    tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setTenantConfig(null);\n+    testSerializeMandatoryFields(tableConfig, \"Tenant config\");\n+\n+    tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setIndexingConfig(null);\n+    testSerializeMandatoryFields(tableConfig, \"Indexing config\");\n+\n+    tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    tableConfig.setCustomConfig(null);\n+    testSerializeMandatoryFields(tableConfig, \"Custom config\");\n+  }\n+\n+  private void testSerializeMandatoryFields(TableConfig tableConfig, String expectedMessage)\n+      throws Exception {\n+    try {\n+      tableConfig.toJsonConfig();\n+      fail();\n+    } catch (IllegalStateException e) {\n+      assertTrue(e.getMessage().contains(expectedMessage));\n+    }\n+    try {\n+      tableConfig.toZNRecord();\n+      fail();\n+    } catch (IllegalStateException e) {\n+      assertTrue(e.getMessage().contains(expectedMessage));\n+    }\n+  }\n+\n+  @Test\n+  public void testDeserializeMandatoryFields()\n+      throws Exception {\n+    TableConfig tableConfig = new TableConfig.Builder(TableType.OFFLINE).setTableName(\"myTable\").build();\n+    ObjectNode jsonTableConfig = tableConfig.toJsonConfig();\n+    TableConfig.fromJsonConfig(jsonTableConfig);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.TABLE_TYPE_KEY);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.TABLE_NAME_KEY);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.VALIDATION_CONFIG_KEY);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.TENANT_CONFIG_KEY);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.INDEXING_CONFIG_KEY);\n+\n+    testDeserializeMandatoryFields(jsonTableConfig.deepCopy(), TableConfig.CUSTOM_CONFIG_KEY);\n+  }\n+\n+  private void testDeserializeMandatoryFields(ObjectNode jsonTableConfig, String mandatoryFieldKey)\n+      throws Exception {\n+    jsonTableConfig.remove(mandatoryFieldKey);\n+    try {\n+      TableConfig.fromJsonConfig(jsonTableConfig);\n+      fail();\n+    } catch (IllegalStateException e) {\n+      assertTrue(e.getMessage().contains(mandatoryFieldKey));\n+    }\n+  }\n+\n   @Test\n   public void testSerializeDeserialize()\n       throws Exception {\n@@ -41,136 +115,122 @@ public void testSerializeDeserialize()\n       // No quota config\n       TableConfig tableConfig = tableConfigBuilder.build();\n \n-      Assert.assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n-      Assert.assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n-      Assert.assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n-      Assert.assertNull(tableConfig.getQuotaConfig());\n+      assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n+      assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n+      assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n+      assertNull(tableConfig.getQuotaConfig());\n \n       // Serialize\n-      JsonNode jsonTableConfig = TableConfig.toJSONConfig(tableConfig);\n+      ObjectNode jsonTableConfig = tableConfig.toJsonConfig();\n       // All nested configs should be json objects instead of serialized strings\n-      Assert.assertTrue(jsonTableConfig.get(TableConfig.VALIDATION_CONFIG_KEY) instanceof ObjectNode);\n-      Assert.assertTrue(jsonTableConfig.get(TableConfig.TENANT_CONFIG_KEY) instanceof ObjectNode);\n-      Assert.assertTrue(jsonTableConfig.get(TableConfig.INDEXING_CONFIG_KEY) instanceof ObjectNode);\n-      Assert.assertTrue(jsonTableConfig.get(TableConfig.CUSTOM_CONFIG_KEY) instanceof ObjectNode);\n+      assertTrue(jsonTableConfig.get(TableConfig.VALIDATION_CONFIG_KEY) instanceof ObjectNode);\n+      assertTrue(jsonTableConfig.get(TableConfig.TENANT_CONFIG_KEY) instanceof ObjectNode);\n+      assertTrue(jsonTableConfig.get(TableConfig.INDEXING_CONFIG_KEY) instanceof ObjectNode);\n+      assertTrue(jsonTableConfig.get(TableConfig.CUSTOM_CONFIG_KEY) instanceof ObjectNode);\n \n       // De-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(jsonTableConfig);\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNull(tableConfigToCompare.getQuotaConfig());\n-      Assert.assertNull(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig());\n-      Assert.assertNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n-\n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNull(tableConfigToCompare.getQuotaConfig());\n-      Assert.assertNull(tableConfig.getValidationConfig().getReplicaGroupStrategyConfig());\n-      Assert.assertNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(jsonTableConfig);\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNull(tableConfigToCompare.getQuotaConfig());\n+      assertNull(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig());\n+      assertNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n+\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNull(tableConfigToCompare.getQuotaConfig());\n+      assertNull(tableConfig.getValidationConfig().getReplicaGroupStrategyConfig());\n+      assertNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n     }\n     {\n       // With quota config\n       QuotaConfig quotaConfig = new QuotaConfig();\n       quotaConfig.setStorage(\"30G\");\n       TableConfig tableConfig = tableConfigBuilder.setQuotaConfig(quotaConfig).build();\n \n-      Assert.assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n-      Assert.assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n-      Assert.assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n-      Assert.assertNotNull(tableConfig.getQuotaConfig());\n-      Assert.assertEquals(tableConfig.getQuotaConfig().getStorage(), \"30G\");\n-      Assert.assertNull(tableConfig.getQuotaConfig().getMaxQueriesPerSecond());\n+      assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n+      assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n+      assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n+      assertNotNull(tableConfig.getQuotaConfig());\n+      assertEquals(tableConfig.getQuotaConfig().getStorage(), \"30G\");\n+      assertNull(tableConfig.getQuotaConfig().getMaxQueriesPerSecond());\n \n       // With qps quota\n       quotaConfig.setMaxQueriesPerSecond(\"100.00\");\n       tableConfig = tableConfigBuilder.setQuotaConfig(quotaConfig).build();\n-      Assert.assertNotNull(tableConfig.getQuotaConfig());\n-      Assert.assertNotNull(tableConfig.getQuotaConfig().getMaxQueriesPerSecond());\n-      Assert.assertEquals(tableConfig.getQuotaConfig().getMaxQueriesPerSecond(), \"100.00\");\n+      assertNotNull(tableConfig.getQuotaConfig());\n+      assertNotNull(tableConfig.getQuotaConfig().getMaxQueriesPerSecond());\n+      assertEquals(tableConfig.getQuotaConfig().getMaxQueriesPerSecond(), \"100.00\");\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getQuotaConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getQuotaConfig().getStorage(), tableConfig.getQuotaConfig().getStorage());\n-\n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getQuotaConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getQuotaConfig().getStorage(), tableConfig.getQuotaConfig().getStorage());\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getQuotaConfig());\n+      assertEquals(tableConfigToCompare.getQuotaConfig().getStorage(), tableConfig.getQuotaConfig().getStorage());\n+\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getQuotaConfig());\n+      assertEquals(tableConfigToCompare.getQuotaConfig().getStorage(), tableConfig.getQuotaConfig().getStorage());\n     }\n     {\n       // With tenant config\n       TableConfig tableConfig =\n           tableConfigBuilder.setServerTenant(\"aServerTenant\").setBrokerTenant(\"aBrokerTenant\").build();\n \n-      Assert.assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n-      Assert.assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n-      Assert.assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n-      Assert.assertNotNull(tableConfig.getTenantConfig());\n-      Assert.assertEquals(tableConfig.getTenantConfig().getServer(), \"aServerTenant\");\n-      Assert.assertEquals(tableConfig.getTenantConfig().getBroker(), \"aBrokerTenant\");\n-      Assert.assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n+      assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n+      assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n+      assertEquals(tableConfig.getIndexingConfig().getLoadMode(), \"HEAP\");\n+      assertNotNull(tableConfig.getTenantConfig());\n+      assertEquals(tableConfig.getTenantConfig().getServer(), \"aServerTenant\");\n+      assertEquals(tableConfig.getTenantConfig().getBroker(), \"aBrokerTenant\");\n+      assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n-      Assert.assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n-\n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n-      Assert.assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getTenantConfig());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n+      assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n+\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getTenantConfig());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n+      assertNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n \n       TagOverrideConfig tagOverrideConfig = new TagOverrideConfig();\n       tagOverrideConfig.setRealtimeConsuming(\"aRTConsumingTag_REALTIME\");\n       tableConfig = tableConfigBuilder.setTagOverrideConfig(tagOverrideConfig).build();\n \n-      Assert.assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n-      Assert.assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n-      Assert.assertNotNull(tableConfig.getTenantConfig());\n-      Assert.assertEquals(tableConfig.getTenantConfig().getServer(), \"aServerTenant\");\n-      Assert.assertEquals(tableConfig.getTenantConfig().getBroker(), \"aBrokerTenant\");\n-      Assert.assertNotNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n-      Assert.assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig().getRealtimeConsuming(),\n+      assertEquals(tableConfig.getTableName(), \"myTable_OFFLINE\");\n+      assertEquals(tableConfig.getTableType(), TableType.OFFLINE);\n+      assertNotNull(tableConfig.getTenantConfig());\n+      assertEquals(tableConfig.getTenantConfig().getServer(), \"aServerTenant\");\n+      assertEquals(tableConfig.getTenantConfig().getBroker(), \"aBrokerTenant\");\n+      assertNotNull(tableConfig.getTenantConfig().getTagOverrideConfig());\n+      assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig().getRealtimeConsuming(),\n           \"aRTConsumingTag_REALTIME\");\n-      Assert.assertNull(tableConfig.getTenantConfig().getTagOverrideConfig().getRealtimeCompleted());\n+      assertNull(tableConfig.getTenantConfig().getTagOverrideConfig().getRealtimeCompleted());\n \n       // Serialize then de-serialize\n-      tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n-      Assert.assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig(),\n+      tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getTenantConfig());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n+      assertNotNull(tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n+      assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig(),\n           tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n \n-      znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n-      Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n-      Assert\n-          .assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n-      Assert.assertNotNull(tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n-      Assert.assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig(),\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n+      assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+      assertNotNull(tableConfigToCompare.getTenantConfig());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getServer(), tableConfig.getTenantConfig().getServer());\n+      assertEquals(tableConfigToCompare.getTenantConfig().getBroker(), tableConfig.getTenantConfig().getBroker());\n+      assertNotNull(tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n+      assertEquals(tableConfig.getTenantConfig().getTagOverrideConfig(),\n           tableConfigToCompare.getTenantConfig().getTagOverrideConfig());\n     }\n     {\n@@ -185,36 +245,32 @@ public void testSerializeDeserialize()\n       tableConfig.getValidationConfig().setReplicaGroupStrategyConfig(replicaGroupConfig);\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n       checkTableConfigWithAssignmentConfig(tableConfig, tableConfigToCompare);\n \n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n       checkTableConfigWithAssignmentConfig(tableConfig, tableConfigToCompare);\n     }\n     {\n       // With default StreamConsumptionConfig\n       TableConfig tableConfig = tableConfigBuilder.build();\n-      Assert.assertEquals(\n-          tableConfig.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n+      assertEquals(tableConfig.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n           \"UniformStreamPartitionAssignment\");\n \n       // with streamConsumptionConfig set\n       tableConfig =\n           tableConfigBuilder.setStreamPartitionAssignmentStrategy(\"BalancedStreamPartitionAssignment\").build();\n-      Assert.assertEquals(\n-          tableConfig.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n+      assertEquals(tableConfig.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n           \"BalancedStreamPartitionAssignment\");\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n-      Assert.assertEquals(\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n+      assertEquals(\n           tableConfigToCompare.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n           \"BalancedStreamPartitionAssignment\");\n \n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n-      Assert.assertEquals(\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n+      assertEquals(\n           tableConfigToCompare.getIndexingConfig().getStreamConsumptionConfig().getStreamPartitionAssignmentStrategy(),\n           \"BalancedStreamPartitionAssignment\");\n     }\n@@ -233,11 +289,10 @@ public void testSerializeDeserialize()\n       tableConfig.getIndexingConfig().setStarTreeIndexSpec(starTreeIndexSpec);\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n       checkTableConfigWithStarTreeConfig(tableConfig, tableConfigToCompare);\n \n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n       checkTableConfigWithStarTreeConfig(tableConfig, tableConfigToCompare);\n     }\n     {\n@@ -253,68 +308,67 @@ public void testSerializeDeserialize()\n \n       String hllConfigJson = hllConfig.toJsonString();\n       HllConfig newHllConfig = HllConfig.fromJsonString(hllConfigJson);\n-      Assert.assertEquals(hllConfig.getColumnsToDeriveHllFields(), newHllConfig.getColumnsToDeriveHllFields());\n-      Assert.assertEquals(hllConfig.getHllLog2m(), newHllConfig.getHllLog2m());\n-      Assert.assertEquals(hllConfig.getHllDeriveColumnSuffix(), newHllConfig.getHllDeriveColumnSuffix());\n+      assertEquals(hllConfig.getColumnsToDeriveHllFields(), newHllConfig.getColumnsToDeriveHllFields());\n+      assertEquals(hllConfig.getHllLog2m(), newHllConfig.getHllLog2m());\n+      assertEquals(hllConfig.getHllDeriveColumnSuffix(), newHllConfig.getHllDeriveColumnSuffix());\n \n       TableConfig tableConfig = tableConfigBuilder.build();\n       tableConfig.getValidationConfig().setHllConfig(hllConfig);\n \n       // Serialize then de-serialize\n-      TableConfig tableConfigToCompare = TableConfig.fromJSONConfig(TableConfig.toJSONConfig(tableConfig));\n+      TableConfig tableConfigToCompare = TableConfig.fromJsonConfig(tableConfig.toJsonConfig());\n       checkTableConfigWithHllConfig(tableConfig, tableConfigToCompare);\n \n-      ZNRecord znRecord = TableConfig.toZnRecord(tableConfig);\n-      tableConfigToCompare = TableConfig.fromZnRecord(znRecord);\n+      tableConfigToCompare = TableConfig.fromZnRecord(tableConfig.toZNRecord());\n       checkTableConfigWithHllConfig(tableConfig, tableConfigToCompare);\n     }\n   }\n \n   private void checkTableConfigWithAssignmentConfig(TableConfig tableConfig, TableConfig tableConfigToCompare) {\n     // Check that the segment assignment configuration does exist.\n-    Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-    Assert.assertNotNull(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig());\n-    Assert.assertEquals(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig(),\n+    assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+    assertNotNull(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig());\n+    assertEquals(tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig(),\n         tableConfig.getValidationConfig().getReplicaGroupStrategyConfig());\n \n     // Check that the configurations are correct.\n     ReplicaGroupStrategyConfig strategyConfig =\n         tableConfigToCompare.getValidationConfig().getReplicaGroupStrategyConfig();\n-    Assert.assertTrue(strategyConfig.getMirrorAssignmentAcrossReplicaGroups());\n-    Assert.assertEquals(strategyConfig.getNumInstancesPerPartition(), 5);\n-    Assert.assertEquals(strategyConfig.getPartitionColumn(), \"memberId\");\n+    assertTrue(strategyConfig.getMirrorAssignmentAcrossReplicaGroups());\n+    assertEquals(strategyConfig.getNumInstancesPerPartition(), 5);\n+    assertEquals(strategyConfig.getPartitionColumn(), \"memberId\");\n   }\n \n   private void checkTableConfigWithStarTreeConfig(TableConfig tableConfig, TableConfig tableConfigToCompare)\n       throws Exception {\n     // Check that the segment assignment configuration does exist.\n-    Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-    Assert.assertNotNull(tableConfigToCompare.getIndexingConfig().getStarTreeIndexSpec());\n+    assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+    assertNotNull(tableConfigToCompare.getIndexingConfig().getStarTreeIndexSpec());\n \n     // Check that the configurations are correct.\n     StarTreeIndexSpec starTreeIndexSpec = tableConfigToCompare.getIndexingConfig().getStarTreeIndexSpec();\n \n     Set<String> dims = new HashSet<>();\n     dims.add(\"dims\");\n \n-    Assert.assertEquals(starTreeIndexSpec.getDimensionsSplitOrder(), Collections.singletonList(\"dim\"));\n-    Assert.assertEquals(starTreeIndexSpec.getMaxLeafRecords(), 5);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipMaterializationCardinalityThreshold(), 1);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipMaterializationForDimensions(), dims);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipStarNodeCreationForDimensions(), dims);\n+    assertEquals(starTreeIndexSpec.getDimensionsSplitOrder(), Collections.singletonList(\"dim\"));\n+    assertEquals(starTreeIndexSpec.getMaxLeafRecords(), 5);\n+    assertEquals(starTreeIndexSpec.getSkipMaterializationCardinalityThreshold(), 1);\n+    assertEquals(starTreeIndexSpec.getSkipMaterializationForDimensions(), dims);\n+    assertEquals(starTreeIndexSpec.getSkipStarNodeCreationForDimensions(), dims);\n \n     starTreeIndexSpec = StarTreeIndexSpec.fromJsonString(starTreeIndexSpec.toJsonString());\n-    Assert.assertEquals(starTreeIndexSpec.getDimensionsSplitOrder(), Collections.singletonList(\"dim\"));\n-    Assert.assertEquals(starTreeIndexSpec.getMaxLeafRecords(), 5);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipMaterializationCardinalityThreshold(), 1);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipMaterializationForDimensions(), dims);\n-    Assert.assertEquals(starTreeIndexSpec.getSkipStarNodeCreationForDimensions(), dims);\n+    assertEquals(starTreeIndexSpec.getDimensionsSplitOrder(), Collections.singletonList(\"dim\"));\n+    assertEquals(starTreeIndexSpec.getMaxLeafRecords(), 5);\n+    assertEquals(starTreeIndexSpec.getSkipMaterializationCardinalityThreshold(), 1);\n+    assertEquals(starTreeIndexSpec.getSkipMaterializationForDimensions(), dims);\n+    assertEquals(starTreeIndexSpec.getSkipStarNodeCreationForDimensions(), dims);\n   }\n \n   private void checkTableConfigWithHllConfig(TableConfig tableConfig, TableConfig tableConfigToCompare) {\n     // Check that the segment assignment configuration does exist.\n-    Assert.assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n-    Assert.assertNotNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n+    assertEquals(tableConfigToCompare.getTableName(), tableConfig.getTableName());\n+    assertNotNull(tableConfigToCompare.getValidationConfig().getHllConfig());\n \n     // Check that the configurations are correct.\n     HllConfig hllConfig = tableConfigToCompare.getValidationConfig().getHllConfig();\n@@ -323,8 +377,8 @@ private void checkTableConfigWithHllConfig(TableConfig tableConfig, TableConfig\n     columns.add(\"column\");\n     columns.add(\"column2\");\n \n-    Assert.assertEquals(hllConfig.getColumnsToDeriveHllFields(), columns);\n-    Assert.assertEquals(hllConfig.getHllLog2m(), 9);\n-    Assert.assertEquals(hllConfig.getHllDeriveColumnSuffix(), \"suffix\");\n+    assertEquals(hllConfig.getColumnsToDeriveHllFields(), columns);\n+    assertEquals(hllConfig.getHllLog2m(), 9);\n+    assertEquals(hllConfig.getHllDeriveColumnSuffix(), \"suffix\");\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-common/src/test/java/org/apache/pinot/common/config/TableConfigTest.java",
                "sha": "38210942a5bd2025076bddf0569c7278bdae5528",
                "status": "modified"
            },
            {
                "additions": 74,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableConfigRestletResource.java",
                "changes": 140,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableConfigRestletResource.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 66,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableConfigRestletResource.java",
                "patch": "@@ -94,93 +94,101 @@ public Response readTableConfiguration(@PathParam(\"tableName\") String tableName,\n   @Produces(MediaType.APPLICATION_JSON)\n   @Path(\"/v2/tables\")\n   public Response createNewTable(String tableConfiguration) {\n-    CombinedConfig config = null;\n-\n     try {\n-      config = Deserializer.deserializeFromString(CombinedConfig.class, tableConfiguration);\n-    } catch (Exception e) {\n-      LOGGER.warn(\"Caught exception while deserializing the table configuration\", e);\n-      return Response.serverError().entity(e.getMessage()).type(MediaType.TEXT_PLAIN_TYPE).build();\n-    }\n+      CombinedConfig config;\n \n-    if (config == null) {\n-      LOGGER.warn(\"Failed to deserialize the table configuration: {}\", tableConfiguration);\n-      return Response.serverError().entity(\"Failed to deserialize the table configuration\")\n-          .type(MediaType.TEXT_PLAIN_TYPE).build();\n-    }\n+      try {\n+        config = Deserializer.deserializeFromString(CombinedConfig.class, tableConfiguration);\n+      } catch (Exception e) {\n+        LOGGER.warn(\"Caught exception while deserializing the table configuration\", e);\n+        return Response.serverError().entity(e.getMessage()).type(MediaType.TEXT_PLAIN_TYPE).build();\n+      }\n \n-    if (config.getSchema() != null) {\n-      _resourceManager.addOrUpdateSchema(config.getSchema());\n-    }\n+      if (config == null) {\n+        LOGGER.warn(\"Failed to deserialize the table configuration: {}\", tableConfiguration);\n+        return Response.serverError().entity(\"Failed to deserialize the table configuration\")\n+            .type(MediaType.TEXT_PLAIN_TYPE).build();\n+      }\n \n-    if (config.getOfflineTableConfig() != null) {\n-      _resourceManager.addTable(config.getOfflineTableConfig());\n-    }\n+      if (config.getSchema() != null) {\n+        _resourceManager.addOrUpdateSchema(config.getSchema());\n+      }\n \n-    if (config.getRealtimeTableConfig() != null) {\n-      _resourceManager.addTable(config.getRealtimeTableConfig());\n-    }\n+      if (config.getOfflineTableConfig() != null) {\n+        _resourceManager.addTable(config.getOfflineTableConfig());\n+      }\n \n-    return Response.ok().build();\n+      if (config.getRealtimeTableConfig() != null) {\n+        _resourceManager.addTable(config.getRealtimeTableConfig());\n+      }\n+\n+      return Response.ok().build();\n+    } catch (Exception e) {\n+      throw new ControllerApplicationException(LOGGER, e.getMessage(), Response.Status.INTERNAL_SERVER_ERROR, e);\n+    }\n   }\n \n   @PUT\n   @Produces(MediaType.APPLICATION_JSON)\n   @Path(\"/v2/tables/{tableName}\")\n   public Response updateTable(String tableConfiguration) {\n-    CombinedConfig config = null;\n-\n     try {\n-      config = Deserializer.deserializeFromString(CombinedConfig.class, tableConfiguration);\n-    } catch (Exception e) {\n-      LOGGER.warn(\"Caught exception while deserializing the table configuration\", e);\n-      return Response.serverError().entity(e.getMessage()).type(MediaType.TEXT_PLAIN_TYPE).build();\n-    }\n+      CombinedConfig config;\n \n-    if (config == null) {\n-      LOGGER.warn(\"Failed to deserialize the table configuration: {}\", tableConfiguration);\n-      return Response.serverError().entity(\"Failed to deserialize the table configuration\")\n-          .type(MediaType.TEXT_PLAIN_TYPE).build();\n-    }\n+      try {\n+        config = Deserializer.deserializeFromString(CombinedConfig.class, tableConfiguration);\n+      } catch (Exception e) {\n+        LOGGER.warn(\"Caught exception while deserializing the table configuration\", e);\n+        return Response.serverError().entity(e.getMessage()).type(MediaType.TEXT_PLAIN_TYPE).build();\n+      }\n \n-    if (config.getSchema() != null) {\n-      _resourceManager.addOrUpdateSchema(config.getSchema());\n-    }\n+      if (config == null) {\n+        LOGGER.warn(\"Failed to deserialize the table configuration: {}\", tableConfiguration);\n+        return Response.serverError().entity(\"Failed to deserialize the table configuration\")\n+            .type(MediaType.TEXT_PLAIN_TYPE).build();\n+      }\n \n-    if (config.getOfflineTableConfig() != null) {\n-      if (_resourceManager.getAllTables().contains(config.getOfflineTableConfig().getTableName())) {\n-        try {\n-          _resourceManager\n-              .setExistingTableConfig(config.getOfflineTableConfig(), config.getOfflineTableConfig().getTableName(),\n-                  CommonConstants.Helix.TableType.OFFLINE);\n-        } catch (IOException e) {\n-          LOGGER.warn(\"Failed to update the offline table configuration for table {}\", e,\n-              config.getOfflineTableConfig().getTableName());\n-          return Response.serverError().entity(\"Failed to update the offline table configuration\")\n-              .type(MediaType.TEXT_PLAIN_TYPE).build();\n+      if (config.getSchema() != null) {\n+        _resourceManager.addOrUpdateSchema(config.getSchema());\n+      }\n+\n+      if (config.getOfflineTableConfig() != null) {\n+        if (_resourceManager.getAllTables().contains(config.getOfflineTableConfig().getTableName())) {\n+          try {\n+            _resourceManager\n+                .setExistingTableConfig(config.getOfflineTableConfig(), config.getOfflineTableConfig().getTableName(),\n+                    CommonConstants.Helix.TableType.OFFLINE);\n+          } catch (IOException e) {\n+            LOGGER.warn(\"Failed to update the offline table configuration for table {}\", e,\n+                config.getOfflineTableConfig().getTableName());\n+            return Response.serverError().entity(\"Failed to update the offline table configuration\")\n+                .type(MediaType.TEXT_PLAIN_TYPE).build();\n+          }\n+        } else {\n+          _resourceManager.addTable(config.getOfflineTableConfig());\n         }\n-      } else {\n-        _resourceManager.addTable(config.getOfflineTableConfig());\n       }\n-    }\n \n-    if (config.getRealtimeTableConfig() != null) {\n-      if (_resourceManager.getAllTables().contains(config.getRealtimeTableConfig().getTableName())) {\n-        try {\n-          _resourceManager\n-              .setExistingTableConfig(config.getRealtimeTableConfig(), config.getRealtimeTableConfig().getTableName(),\n-                  CommonConstants.Helix.TableType.REALTIME);\n-        } catch (IOException e) {\n-          LOGGER.warn(\"Failed to update the realtime table configuration for table {}\", e,\n-              config.getRealtimeTableConfig().getTableName());\n-          return Response.serverError().entity(\"Failed to update the realtime table configuration\")\n-              .type(MediaType.TEXT_PLAIN_TYPE).build();\n+      if (config.getRealtimeTableConfig() != null) {\n+        if (_resourceManager.getAllTables().contains(config.getRealtimeTableConfig().getTableName())) {\n+          try {\n+            _resourceManager\n+                .setExistingTableConfig(config.getRealtimeTableConfig(), config.getRealtimeTableConfig().getTableName(),\n+                    CommonConstants.Helix.TableType.REALTIME);\n+          } catch (IOException e) {\n+            LOGGER.warn(\"Failed to update the realtime table configuration for table {}\", e,\n+                config.getRealtimeTableConfig().getTableName());\n+            return Response.serverError().entity(\"Failed to update the realtime table configuration\")\n+                .type(MediaType.TEXT_PLAIN_TYPE).build();\n+          }\n+        } else {\n+          _resourceManager.addTable(config.getRealtimeTableConfig());\n         }\n-      } else {\n-        _resourceManager.addTable(config.getRealtimeTableConfig());\n       }\n-    }\n \n-    return Response.ok().build();\n+      return Response.ok().build();\n+    } catch (Exception e) {\n+      throw new ControllerApplicationException(LOGGER, e.getMessage(), Response.Status.INTERNAL_SERVER_ERROR, e);\n+    }\n   }\n }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableConfigRestletResource.java",
                "sha": "01d5fdf7ffac74233d369bddf0cd8d2db7e41949",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableRestletResource.java",
                "changes": 12,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableRestletResource.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 7,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableRestletResource.java",
                "patch": "@@ -130,7 +130,7 @@ public SuccessResponse addTable(String tableConfigStr) {\n       } else if (e instanceof PinotHelixResourceManager.TableAlreadyExistsException) {\n         throw new ControllerApplicationException(LOGGER, e.getMessage(), Response.Status.CONFLICT, e);\n       } else {\n-        throw e;\n+        throw new ControllerApplicationException(LOGGER, e.getMessage(), Response.Status.INTERNAL_SERVER_ERROR, e);\n       }\n     }\n   }\n@@ -172,14 +172,14 @@ private String listTableConfigs(@Nonnull String tableName, @Nullable String tabl\n           && _pinotHelixResourceManager.hasOfflineTable(tableName)) {\n         TableConfig tableConfig = _pinotHelixResourceManager.getOfflineTableConfig(tableName);\n         Preconditions.checkNotNull(tableConfig);\n-        ret.set(CommonConstants.Helix.TableType.OFFLINE.name(), TableConfig.toJSONConfig(tableConfig));\n+        ret.set(CommonConstants.Helix.TableType.OFFLINE.name(), tableConfig.toJsonConfig());\n       }\n \n       if ((tableTypeStr == null || CommonConstants.Helix.TableType.REALTIME.name().equalsIgnoreCase(tableTypeStr))\n           && _pinotHelixResourceManager.hasRealtimeTable(tableName)) {\n         TableConfig tableConfig = _pinotHelixResourceManager.getRealtimeTableConfig(tableName);\n         Preconditions.checkNotNull(tableConfig);\n-        ret.set(CommonConstants.Helix.TableType.REALTIME.name(), TableConfig.toJSONConfig(tableConfig));\n+        ret.set(CommonConstants.Helix.TableType.REALTIME.name(), tableConfig.toJsonConfig());\n       }\n       return ret.toString();\n     } catch (Exception e) {\n@@ -325,11 +325,9 @@ public String checkTableConfig(String tableConfigStr) {\n       ObjectNode tableConfigValidateStr = JsonUtils.newObjectNode();\n       TableConfig tableConfig = TableConfig.fromJsonString(tableConfigStr);\n       if (tableConfig.getTableType() == CommonConstants.Helix.TableType.OFFLINE) {\n-        tableConfigValidateStr\n-            .set(CommonConstants.Helix.TableType.OFFLINE.name(), TableConfig.toJSONConfig(tableConfig));\n+        tableConfigValidateStr.set(CommonConstants.Helix.TableType.OFFLINE.name(), tableConfig.toJsonConfig());\n       } else {\n-        tableConfigValidateStr\n-            .set(CommonConstants.Helix.TableType.REALTIME.name(), TableConfig.toJSONConfig(tableConfig));\n+        tableConfigValidateStr.set(CommonConstants.Helix.TableType.REALTIME.name(), tableConfig.toJsonConfig());\n       }\n       return tableConfigValidateStr.toString();\n     } catch (Exception e) {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableRestletResource.java",
                "sha": "a3b45e564800e18d776a21bebd5159fc383dfbc0",
                "status": "modified"
            },
            {
                "additions": 6,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 7,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -1009,7 +1009,8 @@ public Schema getTableSchema(@Nonnull String tableName) {\n    * @throws InvalidTableConfigException\n    * @throws TableAlreadyExistsException for offline tables only if the table already exists\n    */\n-  public void addTable(@Nonnull TableConfig tableConfig) {\n+  public void addTable(@Nonnull TableConfig tableConfig)\n+      throws IOException {\n     final String tableNameWithType = tableConfig.getTableName();\n \n     TenantConfig tenantConfig;\n@@ -1086,8 +1087,7 @@ public void addTable(@Nonnull TableConfig tableConfig) {\n         LOGGER.info(\"successfully added the table : \" + tableNameWithType + \" to the cluster\");\n \n         // lets add table configs\n-        ZKMetadataProvider\n-            .setOfflineTableConfig(_propertyStore, tableNameWithType, TableConfig.toZnRecord(tableConfig));\n+        ZKMetadataProvider.setOfflineTableConfig(_propertyStore, tableNameWithType, tableConfig.toZNRecord());\n \n         _propertyStore.create(ZKMetadataProvider.constructPropertyStorePathForResource(tableNameWithType),\n             new ZNRecord(tableNameWithType), AccessOption.PERSISTENT);\n@@ -1109,8 +1109,7 @@ public void addTable(@Nonnull TableConfig tableConfig) {\n         }\n \n         // lets add table configs\n-        ZKMetadataProvider\n-            .setRealtimeTableConfig(_propertyStore, tableNameWithType, TableConfig.toZnRecord(tableConfig));\n+        ZKMetadataProvider.setRealtimeTableConfig(_propertyStore, tableNameWithType, tableConfig.toZNRecord());\n \n         /*\n          * PinotRealtimeSegmentManager sets up watches on table and segment path. When a table gets created,\n@@ -1248,13 +1247,13 @@ private void createHelixEntriesForHighLevelConsumer(TableConfig config, String r\n   public void setExistingTableConfig(TableConfig config, String tableNameWithType, TableType type)\n       throws IOException {\n     if (type == TableType.REALTIME) {\n-      ZKMetadataProvider.setRealtimeTableConfig(_propertyStore, tableNameWithType, TableConfig.toZnRecord(config));\n+      ZKMetadataProvider.setRealtimeTableConfig(_propertyStore, tableNameWithType, config.toZNRecord());\n       ensureRealtimeClusterIsSetUp(config, tableNameWithType, config.getIndexingConfig());\n     } else if (type == TableType.OFFLINE) {\n       // Update replica group partition assignment to the property store if applicable\n       updateReplicaGroupPartitionAssignment(config);\n \n-      ZKMetadataProvider.setOfflineTableConfig(_propertyStore, tableNameWithType, TableConfig.toZnRecord(config));\n+      ZKMetadataProvider.setOfflineTableConfig(_propertyStore, tableNameWithType, config.toZNRecord());\n       IdealState idealState = _helixAdmin.getResourceIdealState(_helixClusterName, tableNameWithType);\n       final String configReplication = config.getValidationConfig().getReplication();\n       if (configReplication != null && !config.getValidationConfig().getReplication()",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "5e15bff739afcabe254bd69db92a589aaea700c0",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/util/AutoAddInvertedIndex.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/util/AutoAddInvertedIndex.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/util/AutoAddInvertedIndex.java",
                "patch": "@@ -339,7 +339,7 @@ private boolean updateIndexConfig(String tableName, TableConfig tableConfig)\n     httpURLConnection.setRequestMethod(\"PUT\");\n \n     BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(httpURLConnection.getOutputStream(), \"UTF-8\"));\n-    writer.write(tableConfig.toJSONConfigString());\n+    writer.write(tableConfig.toJsonConfigString());\n     writer.flush();\n \n     BufferedReader reader = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream(), \"UTF-8\"));",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/main/java/org/apache/pinot/controller/util/AutoAddInvertedIndex.java",
                "sha": "26a5e464f0cbac822517e46934a0512566d5fccf",
                "status": "modified"
            },
            {
                "additions": 17,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "changes": 34,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTableRestletResourceTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 17,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "patch": "@@ -109,7 +109,7 @@ public void testCreateTable()\n     TableConfig offlineTableConfig = _offlineBuilder.build();\n     offlineTableConfig.setTableName(\"bad__table__name\");\n     try {\n-      sendPostRequest(_createTableUrl, offlineTableConfig.toJSONConfigString());\n+      sendPostRequest(_createTableUrl, offlineTableConfig.toJsonConfigString());\n       Assert.fail(\"Creation of an OFFLINE table with two underscores in the table name does not fail\");\n     } catch (IOException e) {\n       // Expected 400 Bad Request\n@@ -118,7 +118,7 @@ public void testCreateTable()\n \n     // Create an OFFLINE table with a valid name which should succeed\n     offlineTableConfig.setTableName(\"valid_table_name\");\n-    String offlineTableJSONConfigString = offlineTableConfig.toJSONConfigString();\n+    String offlineTableJSONConfigString = offlineTableConfig.toJsonConfigString();\n     sendPostRequest(_createTableUrl, offlineTableJSONConfigString);\n \n     // Create an OFFLINE table that already exists which should fail\n@@ -134,7 +134,7 @@ public void testCreateTable()\n     offlineTableConfig.getValidationConfig().setReplication(\"abc\");\n     offlineTableConfig.setTableName(\"invalid_replication_table\");\n     try {\n-      sendPostRequest(_createTableUrl, offlineTableConfig.toJSONConfigString());\n+      sendPostRequest(_createTableUrl, offlineTableConfig.toJsonConfigString());\n       Assert.fail(\"Creation of an invalid OFFLINE table does not fail\");\n     } catch (IOException e) {\n       // Expected 400 Bad Request\n@@ -146,7 +146,7 @@ public void testCreateTable()\n     TableConfig realtimeTableConfig = _realtimeBuilder.build();\n     realtimeTableConfig.setTableName(\"bad__table__name\");\n     try {\n-      sendPostRequest(_createTableUrl, realtimeTableConfig.toJSONConfigString());\n+      sendPostRequest(_createTableUrl, realtimeTableConfig.toJsonConfigString());\n       Assert.fail(\"Creation of a REALTIME table with two underscores in the table name does not fail\");\n     } catch (IOException e) {\n       // Expected 400 Bad Request\n@@ -157,7 +157,7 @@ public void testCreateTable()\n     _realtimeBuilder.setSchemaName(\"invalidSchemaName\");\n     TableConfig invalidConfig = _realtimeBuilder.build();\n     try {\n-      sendPostRequest(_createTableUrl, realtimeTableConfig.toJSONConfigString());\n+      sendPostRequest(_createTableUrl, realtimeTableConfig.toJsonConfigString());\n       Assert.fail(\"Creation of a REALTIME table without a valid schema does not fail\");\n     } catch (IOException e) {\n       // Expected 400 Bad Request\n@@ -171,13 +171,13 @@ public void testCreateTable()\n     _realtimeBuilder.setTableName(\"RT_TABLE\");\n     addDummySchema(schemaName);\n     TableConfig diffConfig = _realtimeBuilder.build();\n-    sendPostRequest(_createTableUrl, diffConfig.toJSONConfigString());\n+    sendPostRequest(_createTableUrl, diffConfig.toJsonConfigString());\n \n     // Create a REALTIME table with a valid name and schema which should succeed\n     _realtimeBuilder.setTableName(REALTIME_TABLE_NAME);\n     _realtimeBuilder.setSchemaName(REALTIME_TABLE_NAME);\n     TableConfig config = _realtimeBuilder.build();\n-    String realtimeTableJSONConfigString = config.toJSONConfigString();\n+    String realtimeTableJSONConfigString = config.toJsonConfigString();\n     sendPostRequest(_createTableUrl, realtimeTableJSONConfigString);\n \n     // TODO: check whether we should allow POST request to create REALTIME table that already exists\n@@ -195,7 +195,7 @@ public void testTableMinReplication()\n   private void testTableMinReplicationInternal(String tableName, int tableReplication)\n       throws Exception {\n     String tableJSONConfigString =\n-        _offlineBuilder.setTableName(tableName).setNumReplicas(tableReplication).build().toJSONConfigString();\n+        _offlineBuilder.setTableName(tableName).setNumReplicas(tableReplication).build().toJsonConfigString();\n     sendPostRequest(_createTableUrl, tableJSONConfigString);\n     // table creation should succeed\n     TableConfig tableConfig = getTableConfig(tableName, \"OFFLINE\");\n@@ -204,7 +204,7 @@ private void testTableMinReplicationInternal(String tableName, int tableReplicat\n \n     addDummySchema(tableName);\n     tableJSONConfigString =\n-        _realtimeBuilder.setTableName(tableName).setNumReplicas(tableReplication).build().toJSONConfigString();\n+        _realtimeBuilder.setTableName(tableName).setNumReplicas(tableReplication).build().toJsonConfigString();\n     sendPostRequest(_createTableUrl, tableJSONConfigString);\n     tableConfig = getTableConfig(tableName, \"REALTIME\");\n     Assert.assertEquals(tableConfig.getValidationConfig().getReplicationNumber(),\n@@ -217,15 +217,15 @@ private void testTableMinReplicationInternal(String tableName, int tableReplicat\n   private TableConfig getTableConfig(String tableName, String tableType)\n       throws Exception {\n     String tableConfigString = sendGetRequest(_controllerRequestURLBuilder.forTableGet(tableName));\n-    return TableConfig.fromJSONConfig(JsonUtils.stringToJsonNode(tableConfigString).get(tableType));\n+    return TableConfig.fromJsonConfig(JsonUtils.stringToJsonNode(tableConfigString).get(tableType));\n   }\n \n   @Test\n   public void testUpdateTableConfig()\n       throws Exception {\n     String tableName = \"updateTC\";\n     String tableJSONConfigString =\n-        _offlineBuilder.setTableName(tableName).setNumReplicas(2).build().toJSONConfigString();\n+        _offlineBuilder.setTableName(tableName).setNumReplicas(2).build().toJsonConfigString();\n     sendPostRequest(_createTableUrl, tableJSONConfigString);\n     // table creation should succeed\n     TableConfig tableConfig = getTableConfig(tableName, \"OFFLINE\");\n@@ -236,7 +236,7 @@ public void testUpdateTableConfig()\n     tableConfig.getValidationConfig().setRetentionTimeValue(\"10\");\n \n     JsonNode jsonResponse = JsonUtils.stringToJsonNode(\n-        sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJSONConfigString()));\n+        sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJsonConfigString()));\n     Assert.assertTrue(jsonResponse.has(\"status\"));\n \n     TableConfig modifiedConfig = getTableConfig(tableName, \"OFFLINE\");\n@@ -245,7 +245,7 @@ public void testUpdateTableConfig()\n \n     // Realtime\n     addDummySchema(tableName);\n-    tableJSONConfigString = _realtimeBuilder.setTableName(tableName).setNumReplicas(2).build().toJSONConfigString();\n+    tableJSONConfigString = _realtimeBuilder.setTableName(tableName).setNumReplicas(2).build().toJsonConfigString();\n     sendPostRequest(_createTableUrl, tableJSONConfigString);\n     tableConfig = getTableConfig(tableName, \"REALTIME\");\n     Assert.assertEquals(tableConfig.getValidationConfig().getRetentionTimeValue(), \"5\");\n@@ -255,15 +255,15 @@ public void testUpdateTableConfig()\n     QuotaConfig quota = new QuotaConfig();\n     quota.setStorage(\"10G\");\n     tableConfig.setQuotaConfig(quota);\n-    sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJSONConfigString());\n+    sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJsonConfigString());\n     modifiedConfig = getTableConfig(tableName, \"REALTIME\");\n     Assert.assertNotNull(modifiedConfig.getQuotaConfig());\n     Assert.assertEquals(modifiedConfig.getQuotaConfig().getStorage(), \"10G\");\n     Assert.assertNull(modifiedConfig.getQuotaConfig().getMaxQueriesPerSecond());\n \n     quota.setMaxQueriesPerSecond(\"100.00\");\n     tableConfig.setQuotaConfig(quota);\n-    sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJSONConfigString());\n+    sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJsonConfigString());\n     modifiedConfig = getTableConfig(tableName, \"REALTIME\");\n     Assert.assertNotNull(modifiedConfig.getQuotaConfig().getMaxQueriesPerSecond());\n     Assert.assertEquals(modifiedConfig.getQuotaConfig().getMaxQueriesPerSecond(), \"100.00\");\n@@ -273,7 +273,7 @@ public void testUpdateTableConfig()\n       // table does not exist\n       tableConfig.setTableName(\"noSuchTable_REALTIME\");\n       sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(\"noSuchTable\"),\n-          tableConfig.toJSONConfigString());\n+          tableConfig.toJsonConfigString());\n     } catch (Exception e) {\n       Assert.assertTrue(e instanceof FileNotFoundException);\n       notFoundException = true;\n@@ -304,7 +304,7 @@ public void rebalanceOfflineTable() {\n     // create the table\n     try {\n       TableConfig offlineTableConfig = _offlineBuilder.build();\n-      sendPostRequest(_createTableUrl, offlineTableConfig.toJSONConfigString());\n+      sendPostRequest(_createTableUrl, offlineTableConfig.toJsonConfigString());\n     } catch (Exception e) {\n       Assert.fail(\"Failed to create offline table \" + tableName + \"Error: \" + e.getMessage());\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTableRestletResourceTest.java",
                "sha": "5dbe2305ae5e8d0e1c49c3f8bdcfa9826061893c",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTenantRestletResourceTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTenantRestletResourceTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTenantRestletResourceTest.java",
                "patch": "@@ -93,7 +93,7 @@ public void testTableListForTenant()\n \n     TableConfig offlineTableConfig = _offlineBuilder.build();\n     offlineTableConfig.setTableName(\"mytable_OFFLINE\");\n-    String offlineTableJSONConfigString = offlineTableConfig.toJSONConfigString();\n+    String offlineTableJSONConfigString = offlineTableConfig.toJsonConfigString();\n     sendPostRequest(createTableUrl, offlineTableJSONConfigString);\n \n     // Try to make sure both kinds of tags work",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/api/resources/PinotTenantRestletResourceTest.java",
                "sha": "645b195c22de8e61126eb06126baab5373cc5ed9",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerInstanceToggleTest.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerInstanceToggleTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerInstanceToggleTest.java",
                "patch": "@@ -59,7 +59,7 @@ public void testInstanceToggle()\n     // Create an offline table\n     String tableJSONConfigString =\n         new TableConfig.Builder(CommonConstants.Helix.TableType.OFFLINE).setTableName(RAW_TABLE_NAME)\n-            .setNumReplicas(NUM_INSTANCES).build().toJSONConfigString();\n+            .setNumReplicas(NUM_INSTANCES).build().toJsonConfigString();\n     sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableJSONConfigString);\n     Assert.assertEquals(\n         _helixAdmin.getResourceIdealState(_helixClusterName, CommonConstants.Helix.BROKER_RESOURCE_INSTANCE)",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerInstanceToggleTest.java",
                "sha": "25855a84d70d8af2ba569738c9d5f679723a8f64",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerSentinelTestV2.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerSentinelTestV2.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerSentinelTestV2.java",
                "patch": "@@ -57,7 +57,7 @@ public void testOfflineTableLifeCycle()\n     String tableName = \"testTable\";\n     String tableJSONConfigString =\n         new TableConfig.Builder(CommonConstants.Helix.TableType.OFFLINE).setTableName(tableName).setNumReplicas(3)\n-            .build().toJSONConfigString();\n+            .build().toJsonConfigString();\n     sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableJSONConfigString);\n     Assert.assertEquals(\n         _helixAdmin.getResourceIdealState(_helixClusterName, CommonConstants.Helix.BROKER_RESOURCE_INSTANCE)",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-controller/src/test/java/org/apache/pinot/controller/helix/ControllerSentinelTestV2.java",
                "sha": "1411f147778bcdca9e7085d04e279aa2c5f2349f",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/DefaultControllerRestApi.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/DefaultControllerRestApi.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/DefaultControllerRestApi.java",
                "patch": "@@ -58,7 +58,7 @@ public TableConfig getTableConfig() {\n             .getRetrieveTableConfigHttpURI(pushLocation.getHost(), pushLocation.getPort(), _rawTableName));\n         JsonNode offlineJsonTableConfig = JsonUtils.stringToJsonNode(response.getResponse()).get(OFFLINE);\n         if (offlineJsonTableConfig != null) {\n-          TableConfig offlineTableConfig = TableConfig.fromJSONConfig(offlineJsonTableConfig);\n+          TableConfig offlineTableConfig = TableConfig.fromJsonConfig(offlineJsonTableConfig);\n           LOGGER.info(\"Got table config: {}\", offlineTableConfig);\n           return offlineTableConfig;\n         }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/DefaultControllerRestApi.java",
                "sha": "089ea6e0f87dc6e036c3ad5240467b48a287fd63",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/SegmentCreationJob.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/SegmentCreationJob.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/SegmentCreationJob.java",
                "patch": "@@ -157,7 +157,7 @@ public void run()\n     TableConfig tableConfig = getTableConfig();\n     if (tableConfig != null) {\n       validateTableConfig(tableConfig);\n-      jobConf.set(JobConfigConstants.TABLE_CONFIG, tableConfig.toJSONConfigString());\n+      jobConf.set(JobConfigConstants.TABLE_CONFIG, tableConfig.toJsonConfigString());\n     }\n     jobConf.set(JobConfigConstants.SCHEMA, getSchema().toSingleLineJsonString());\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-hadoop/src/main/java/org/apache/pinot/hadoop/job/SegmentCreationJob.java",
                "sha": "010be2473e09b12ea7db2569b3bc32f216610ebf",
                "status": "modified"
            },
            {
                "additions": 5,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 6,
                "filename": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java",
                "patch": "@@ -302,7 +302,7 @@ protected void addOfflineTable(String tableName, String timeColumnName, String t\n             invertedIndexColumns, bloomFilterColumns, taskConfig);\n \n     if (!isUsingNewConfigFormat()) {\n-      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJSONConfigString());\n+      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJsonConfigString());\n     } else {\n       _offlineTableConfig = tableConfig;\n     }\n@@ -317,16 +317,15 @@ protected void updateOfflineTable(String tableName, String timeColumnName, Strin\n             invertedIndexColumns, bloomFilterColumns, taskConfig);\n \n     if (!isUsingNewConfigFormat()) {\n-      sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJSONConfigString());\n+      sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tableName), tableConfig.toJsonConfigString());\n     } else {\n       _offlineTableConfig = tableConfig;\n     }\n   }\n \n   private static TableConfig getOfflineTableConfig(String tableName, String timeColumnName, String timeType,\n       String brokerTenant, String serverTenant, String loadMode, SegmentVersion segmentVersion,\n-      List<String> invertedIndexColumns, List<String> bloomFilterColumns, TableTaskConfig taskConfig)\n-      throws Exception {\n+      List<String> invertedIndexColumns, List<String> bloomFilterColumns, TableTaskConfig taskConfig) {\n     return new TableConfig.Builder(Helix.TableType.OFFLINE).setTableName(tableName).setTimeColumnName(timeColumnName)\n         .setTimeType(timeType).setNumReplicas(3).setBrokerTenant(brokerTenant).setServerTenant(serverTenant)\n         .setLoadMode(loadMode).setSegmentVersion(segmentVersion.toString())\n@@ -430,7 +429,7 @@ protected void addRealtimeTable(String tableName, boolean useLlc, String kafkaBr\n     _realtimeTableConfig = tableConfig;\n \n     if (!isUsingNewConfigFormat()) {\n-      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJSONConfigString());\n+      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJsonConfigString());\n     }\n   }\n \n@@ -443,7 +442,7 @@ protected void updateRealtimeTableConfig(String tablename, List<String> inverted\n     config.setBloomFilterColumns(bloomFilterCols);\n \n     sendPutRequest(_controllerRequestURLBuilder.forUpdateTableConfig(tablename),\n-        _realtimeTableConfig.toJSONConfigString());\n+        _realtimeTableConfig.toJsonConfigString());\n   }\n \n   protected void dropRealtimeTable(String tableName)",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java",
                "sha": "9dd75c2df092f9a019350bdbf752846e7871e709",
                "status": "modified"
            },
            {
                "additions": 18,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "changes": 18,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/OfflineClusterIntegrationTest.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 0,
                "filename": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "patch": "@@ -19,6 +19,7 @@\n package org.apache.pinot.integration.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n import com.google.common.base.Function;\n import com.google.common.collect.ImmutableList;\n import java.io.File;\n@@ -33,6 +34,7 @@\n import java.util.concurrent.TimeUnit;\n import javax.annotation.Nullable;\n import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.config.TableConfig;\n import org.apache.pinot.common.utils.CommonConstants;\n import org.apache.pinot.common.utils.JsonUtils;\n import org.apache.pinot.common.utils.ServiceStatus;\n@@ -150,6 +152,22 @@ public void testInstancesStarted() {\n     }\n   }\n \n+  @Test\n+  public void testInvalidTableConfig() {\n+    TableConfig tableConfig =\n+        new TableConfig.Builder(CommonConstants.Helix.TableType.OFFLINE).setTableName(\"badTable\").build();\n+    ObjectNode jsonConfig = tableConfig.toJsonConfig();\n+    // Remove a mandatory field\n+    jsonConfig.remove(TableConfig.VALIDATION_CONFIG_KEY);\n+    try {\n+      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), jsonConfig.toString());\n+      fail();\n+    } catch (IOException e) {\n+      // Should get response code 400 (BAD_REQUEST)\n+      assertTrue(e.getMessage().startsWith(\"Server returned HTTP response code: 400\"));\n+    }\n+  }\n+\n   @Test\n   public void testInvertedIndexTriggering()\n       throws Exception {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "sha": "172b2fa8396b2f04f59a15d2a006870f940f1a63",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-tools/src/main/java/org/apache/pinot/tools/query/comparison/ClusterStarter.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-tools/src/main/java/org/apache/pinot/tools/query/comparison/ClusterStarter.java?ref=eccf573a636de84e60c85cc331fea0afc172c90c",
                "deletions": 1,
                "filename": "pinot-tools/src/main/java/org/apache/pinot/tools/query/comparison/ClusterStarter.java",
                "patch": "@@ -206,7 +206,7 @@ private void addTable()\n     String tableJSONConfigString =\n         new TableConfig.Builder(CommonConstants.Helix.TableType.OFFLINE).setTableName(_tableName)\n             .setTimeColumnName(_timeColumnName).setTimeType(_timeUnit).setNumReplicas(3).setBrokerTenant(\"broker\")\n-            .setServerTenant(\"server\").build().toJSONConfigString();\n+            .setServerTenant(\"server\").build().toJsonConfigString();\n     sendPostRequest(ControllerRequestURLBuilder.baseUrl(controllerAddress).forTableCreate(), tableJSONConfigString);\n   }\n ",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/eccf573a636de84e60c85cc331fea0afc172c90c/pinot-tools/src/main/java/org/apache/pinot/tools/query/comparison/ClusterStarter.java",
                "sha": "18dedc42604aad41ed6e06744745618847e7e085",
                "status": "modified"
            }
        ],
        "message": "In TableConfig, add checks for mandatory fields (#3993)\n\nAdd explicit checks for mandatory fields when serialize/deserialize table config\r\nWithout the explicit checks, it will throw NPE, which is not clear and hard to debug\r\n\r\nAlso change the serialize APIs to be non-static\r\n\r\nAdd unit test and integration test for the changes",
        "parent": "https://github.com/apache/incubator-pinot/commit/d78a8075d64801b258d5634bbcb82121e5f3506f",
        "patched_files": [
            "LowLevelConsumerRoutingTableBuilder.java",
            "PinotTableRestletResource.java",
            "PinotTenantRestletResource.java",
            "PinotTableConfigRestletResource.java",
            "ClusterStarter.java",
            "DefaultControllerRestApi.java",
            "AutoAddInvertedIndex.java",
            "PinotHelixResourceManager.java",
            "TableConfig.java",
            "TimeBoundaryService.java",
            "TableQueryQuotaManager.java",
            "ControllerSentinelTestV2.java",
            "SegmentCreationJob.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TimeBoundaryServiceTest.java",
            "HighLevelConsumerRoutingTableBuilderTest.java",
            "PinotTableRestletResourceTest.java",
            "ControllerInstanceToggleTest.java",
            "TableConfigTest.java",
            "PinotTenantRestletResourceTest.java",
            "LowLevelConsumerRoutingTableBuilderTest.java",
            "PinotHelixResourceManagerTest.java",
            "ClusterTest.java",
            "OfflineClusterIntegrationTest.java",
            "TableQueryQuotaManagerTest.java"
        ]
    },
    "incubator-pinot_f248729": {
        "bug_id": "incubator-pinot_f248729",
        "commit": "https://github.com/apache/incubator-pinot/commit/f24872913f498cd21f3bf9a5a809f4d5ca74696a",
        "file": [
            {
                "additions": 7,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f24872913f498cd21f3bf9a5a809f4d5ca74696a/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java?ref=f24872913f498cd21f3bf9a5a809f4d5ca74696a",
                "deletions": 8,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "patch": "@@ -15,13 +15,6 @@\n  */\n package com.linkedin.pinot.controller.helix;\n \n-import com.linkedin.pinot.common.ZkTestUtils;\n-import com.linkedin.pinot.common.utils.ZkUtils;\n-import com.linkedin.pinot.controller.ControllerConf;\n-import com.linkedin.pinot.controller.ControllerStarter;\n-import com.linkedin.pinot.controller.helix.core.HelixSetupUtils;\n-import com.linkedin.pinot.controller.helix.starter.HelixConfig;\n-\n import java.io.BufferedReader;\n import java.io.BufferedWriter;\n import java.io.IOException;\n@@ -31,6 +24,7 @@\n import java.net.HttpURLConnection;\n import java.net.URL;\n import java.net.URLConnection;\n+\n import org.apache.helix.HelixAdmin;\n import org.apache.helix.HelixManager;\n import org.apache.helix.ZNRecord;\n@@ -41,6 +35,10 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.linkedin.pinot.common.ZkTestUtils;\n+import com.linkedin.pinot.controller.ControllerConf;\n+import com.linkedin.pinot.controller.ControllerStarter;\n+\n \n /**\n  * Base class for controller tests.\n@@ -114,8 +112,9 @@ protected void startController() {\n     if (_zkClient.exists(\"/\" + getHelixClusterName())) {\n       _zkClient.deleteRecursive(\"/\" + getHelixClusterName());\n     }\n-\n     _controllerStarter = ControllerTestUtils.startController(getHelixClusterName(), ZkTestUtils.DEFAULT_ZK_STR, config);\n+    _helixAdmin = _controllerStarter.getHelixResourceManager().getHelixAdmin();\n+    _propertyStore = _controllerStarter.getHelixResourceManager().getPropertyStore();\n   }\n \n   /**",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f24872913f498cd21f3bf9a5a809f4d5ca74696a/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/ControllerTest.java",
                "sha": "a569d3fc5067bd9be9e8a0c8ebc0cfffe5a90e57",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f24872913f498cd21f3bf9a5a809f4d5ca74696a/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/TestPinotResourceManager.java",
                "changes": 13,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/TestPinotResourceManager.java?ref=f24872913f498cd21f3bf9a5a809f4d5ca74696a",
                "deletions": 12,
                "filename": "pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/TestPinotResourceManager.java",
                "patch": "@@ -73,7 +73,7 @@ public void setUp() throws Exception {\n \n     /////////////////////////\n     _numInstance = 1;\n-    final List<HelixServerStarter> pinotHelixStarters = addInstancesToAutoJoinHelixCluster(_numInstance);\n+    ControllerRequestBuilderUtil.addFakeDataInstancesToAutoJoinHelixCluster(HELIX_CLUSTER_NAME, ZK_SERVER, _numInstance);\n     ControllerRequestBuilderUtil.addFakeBrokerInstancesToAutoJoinHelixCluster(HELIX_CLUSTER_NAME, ZK_SERVER, 1);\n     Thread.sleep(3000);\n     Assert.assertEquals(\n@@ -90,17 +90,6 @@ public void setUp() throws Exception {\n     _pinotResourceManager.handleAddTableToDataResource(addTableResource);\n   }\n \n-  private List<HelixServerStarter> addInstancesToAutoJoinHelixCluster(int numInstances) throws Exception {\n-    final List<HelixServerStarter> pinotHelixStarters = new ArrayList<HelixServerStarter>();\n-    for (int i = 0; i < numInstances; ++i) {\n-      final HelixServerStarter pinotHelixStarter =\n-          new HelixServerStarter(HELIX_CLUSTER_NAME, ZK_SERVER, new PropertiesConfiguration());\n-      pinotHelixStarters.add(pinotHelixStarter);\n-      Thread.sleep(1000);\n-    }\n-    return pinotHelixStarters;\n-  }\n-\n   @AfterTest\n   public void tearDown() {\n     _pinotResourceManager.stop();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f24872913f498cd21f3bf9a5a809f4d5ca74696a/pinot-controller/src/test/java/com/linkedin/pinot/controller/helix/TestPinotResourceManager.java",
                "sha": "d269e55b885f93974b93149f07d2ca7e37ea9bd9",
                "status": "modified"
            }
        ],
        "message": "Fixing NPE in ControllerSentinelTest.\nFixing TestPinotResourceMananger by using empty server instances.\n\nRB=470077\nR=xiafu\nA=dpatel",
        "parent": "https://github.com/apache/incubator-pinot/commit/3e45f310f6a6f47f6fce2a6404cd8c6a1b0f5553",
        "patched_files": [],
        "repo": "incubator-pinot",
        "unit_tests": [
            "TestPinotResourceManager.java",
            "ControllerTest.java"
        ]
    },
    "incubator-pinot_f70c106": {
        "bug_id": "incubator-pinot_f70c106",
        "commit": "https://github.com/apache/incubator-pinot/commit/f70c106010175490dfb5951245c5bf0d29d8a2b2",
        "file": [
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "patch": "@@ -116,7 +116,7 @@ public RealtimeSegmentDataManager(final RealtimeSegmentZKMetadata segmentMetadat\n     // lets create a new realtime segment\n     realtimeSegment = new RealtimeSegmentImpl(schema, FIVE_MILLION);\n     ((RealtimeSegmentImpl) (realtimeSegment)).setSegmentName(segmentMetadata.getSegmentName());\n-    ((RealtimeSegmentImpl) (realtimeSegment)).setSegmentMetadata(segmentMetadata);\n+    ((RealtimeSegmentImpl) (realtimeSegment)).setSegmentMetadata(segmentMetadata, this.schema);\n     notifier = realtimeResourceManager;\n \n     segmentStatusTask = new TimerTask() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/data/manager/realtime/RealtimeSegmentDataManager.java",
                "sha": "07811a16e7f0407c87d6e97aae8a2af6e7e19645",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/query/pruner/DataSchemaSegmentPruner.java",
                "changes": 19,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/query/pruner/DataSchemaSegmentPruner.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 8,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/query/pruner/DataSchemaSegmentPruner.java",
                "patch": "@@ -40,21 +40,24 @@ public boolean prune(IndexSegment segment, BrokerRequest brokerRequest) {\n     Schema schema = segment.getSegmentMetadata().getSchema();\n     if (brokerRequest.getSelections() != null) {\n       // Check selection columns\n-      for (String columnName : brokerRequest.getSelections().getSelectionColumns()) {\n-        if ((!columnName.equalsIgnoreCase(\"*\")) && (!schema.isExisted(columnName))) {\n-          return true;\n+      if (brokerRequest.getSelections().getSelectionColumns() != null) {\n+        for (String columnName : brokerRequest.getSelections().getSelectionColumns()) {\n+          if ((!columnName.equalsIgnoreCase(\"*\")) && (!schema.isExisted(columnName))) {\n+            return true;\n+          }\n         }\n       }\n-\n       // Check columns to do sorting,\n-      for (SelectionSort selectionOrder : brokerRequest.getSelections().getSelectionSortSequence()) {\n-        if (!schema.isExisted(selectionOrder.getColumn())) {\n-          return true;\n+      if (brokerRequest.getSelections().getSelectionSortSequence() != null) {\n+        for (SelectionSort selectionOrder : brokerRequest.getSelections().getSelectionSortSequence()) {\n+          if (!schema.isExisted(selectionOrder.getColumn())) {\n+            return true;\n+          }\n         }\n       }\n     }\n     // Check groupBy columns.\n-    if (brokerRequest.getGroupBy() != null) {\n+    if ((brokerRequest.getGroupBy() != null) && (brokerRequest.getGroupBy().getColumns() != null)) {\n       for (String columnName : brokerRequest.getGroupBy().getColumns()) {\n         if (!schema.isExisted(columnName)) {\n           return true;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/query/pruner/DataSchemaSegmentPruner.java",
                "sha": "a1a083aad91b1978e0db9759be0f257563785bac",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentImpl.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentImpl.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentImpl.java",
                "patch": "@@ -434,6 +434,10 @@ public void setSegmentMetadata(RealtimeSegmentZKMetadata segmentMetadata) {\n     _segmentMetadata = new SegmentMetadataImpl(segmentMetadata);\n   }\n \n+  public void setSegmentMetadata(RealtimeSegmentZKMetadata segmentMetadata, Schema schema) {\n+    _segmentMetadata = new SegmentMetadataImpl(segmentMetadata, schema);\n+  }\n+\n   @Override\n   public int getTotalDocs() {\n     return docIdSearchableOffset + 1;",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/RealtimeSegmentImpl.java",
                "sha": "ee417c939dff500ebe100f9f157e1a439e007320",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "changes": 2,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 1,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "patch": "@@ -205,7 +205,7 @@ private boolean evalPredicateWithDictAndInvIdx() {\n \n         final MutableRoaringBitmap notINHolder = new MutableRoaringBitmap();\n \n-        for (int i = 0; i < dictionary.length(); i++) {\n+        for (int i = 1; i < dictionary.length(); i++) {\n           if (!notInIds.contains(new Integer(i))) {\n             notINHolder.or(invertedINdex.getDocIdSetFor(i));\n           }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/realtime/impl/datasource/RealtimeColumnDataSource.java",
                "sha": "b59013a34c35f7f62561542349436b6a4dfe4122",
                "status": "modified"
            },
            {
                "additions": 11,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 0,
                "filename": "pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "patch": "@@ -151,6 +151,17 @@ public SegmentMetadataImpl(RealtimeSegmentZKMetadata segmentMetadata) {\n     _indexDir = null;\n   }\n \n+  public SegmentMetadataImpl(RealtimeSegmentZKMetadata segmentMetadata, Schema schema) {\n+    this(segmentMetadata);\n+    setSchema(schema);\n+  }\n+\n+  private void setSchema(Schema schema) {\n+    for (String columnName : schema.getColumnNames()) {\n+      _schema.addSchema(columnName, schema.getFieldSpecFor(columnName));\n+    }\n+  }\n+\n   private void setTimeIntervalAndGranularity() {\n     if (_segmentMetadataPropertiesConfiguration.containsKey(V1Constants.MetadataKeys.Segment.SEGMENT_START_TIME)\n         && _segmentMetadataPropertiesConfiguration.containsKey(V1Constants.MetadataKeys.Segment.SEGMENT_END_TIME)",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-core/src/main/java/com/linkedin/pinot/core/segment/index/SegmentMetadataImpl.java",
                "sha": "7b4ec891eff3d6afd2bc5ffd5980e0318aad2248",
                "status": "modified"
            },
            {
                "additions": 13,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/BaseClusterIntegrationTest.java",
                "changes": 23,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/BaseClusterIntegrationTest.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 10,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/BaseClusterIntegrationTest.java",
                "patch": "@@ -317,6 +317,18 @@ public void testMultipleQueries() throws Exception {\n \n   @Test\n   public void testHardcodedQuerySet() throws Exception {\n+    for (String query : getHardCodedQuerySet()) {\n+      try {\n+        System.out.println(query);\n+        runQuery(query, Collections.singletonList(query.replace(\"'myresource.mytable'\", \"mytable\")));\n+      } catch (Exception e) {\n+        // TODO: handle exception\n+      }\n+\n+    }\n+  }\n+\n+  protected String[] getHardCodedQuerySet() {\n     String[] queries = new String[] {\n         \"select count(*) from 'myresource.mytable'\",\n         \"select sum(DepDelay) from 'myresource.mytable'\",\n@@ -343,16 +355,7 @@ public void testHardcodedQuerySet() throws Exception {\n         \"select FlightNum, avg(ArrDelay) from 'myresource.mytable' group by FlightNum TOP 100\",\n         // \"select distinctCount(Carrier) from 'myresource.mytable' where TailNum = 'D942DN' TOP 100\"\n     };\n-\n-    for (String query : queries) {\n-      try {\n-        System.out.println(query);\n-        runQuery(query, Collections.singletonList(query.replace(\"'myresource.mytable'\", \"mytable\")));\n-      } catch (Exception e) {\n-        // TODO: handle exception\n-      }\n-\n-    }\n+    return queries;\n   }\n \n   protected long getCurrentServingNumDocs() {",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/BaseClusterIntegrationTest.java",
                "sha": "7d56bd328950e5a122aa4defb2dff3612395debd",
                "status": "modified"
            },
            {
                "additions": 1,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "changes": 29,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/OfflineClusterIntegrationTest.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 28,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "patch": "@@ -206,34 +206,7 @@ public void testMultipleQueries() throws Exception {\n   @Override\n   @Test\n   public void testHardcodedQuerySet() throws Exception {\n-    String[] queries = new String[] {\n-        \"select count(*) from 'myresource.mytable'\",\n-        \"select sum(DepDelay) from 'myresource.mytable'\",\n-        // \"select count(DepDelay) from 'myresource.mytable'\",\n-        \"select min(DepDelay) from 'myresource.mytable'\",\n-        \"select max(DepDelay) from 'myresource.mytable'\",\n-        \"select avg(DepDelay) from 'myresource.mytable'\",\n-        \"select Carrier, count(*) from 'myresource.mytable' group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where ArrDelay > 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where Cancelled = 1 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay >= 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay < 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where ArrDelay <= 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay >= 15 or ArrDelay >= 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay < 15 and ArrDelay <= 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay between 5 and 15 group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay in (2, 8, 42) group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where DepDelay not in (4, 16) group by Carrier TOP 100\",\n-        \"select Carrier, count(*) from 'myresource.mytable' where Cancelled <> 1 group by Carrier TOP 100\",\n-        \"select Carrier, min(ArrDelay) from 'myresource.mytable' group by Carrier TOP 100\",\n-        \"select Carrier, max(ArrDelay) from 'myresource.mytable' group by Carrier TOP 100\",\n-        \"select Carrier, sum(ArrDelay) from 'myresource.mytable' group by Carrier TOP 100\",\n-        \"select TailNum, avg(ArrDelay) from 'myresource.mytable' group by TailNum TOP 100\",\n-        \"select FlightNum, avg(ArrDelay) from 'myresource.mytable' group by FlightNum TOP 100\",\n-        // \"select distinctCount(Carrier) from 'myresource.mytable' where TailNum = 'D942DN' TOP 100\"\n-    };\n-\n-    for (String query : queries) {\n+    for (String query : getHardCodedQuerySet()) {\n       try {\n         System.out.println(query);\n         runQuery(query, Collections.singletonList(query.replace(\"'myresource.mytable'\", \"mytable\")));",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/OfflineClusterIntegrationTest.java",
                "sha": "26dc3f7938c81bc44671b20f2f55ccb82feb6ffb",
                "status": "modified"
            },
            {
                "additions": 15,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "changes": 16,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java?ref=f70c106010175490dfb5951245c5bf0d29d8a2b2",
                "deletions": 1,
                "filename": "pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "patch": "@@ -20,6 +20,7 @@\n import java.sql.ResultSet;\n import java.sql.Statement;\n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.List;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n@@ -86,7 +87,7 @@ public void setUp() throws Exception {\n \n     // Create Pinot resource and table\n     createRealtimeResource(\"myresource\", \"mytable\", \"DaysSinceEpoch\", \"daysSinceEpoch\", KafkaTestUtils.DEFAULT_ZK_STR,\n-        KAFKA_TOPIC,avroFiles.get(0));\n+        KAFKA_TOPIC, avroFiles.get(0));\n \n     // Load data into H2\n     ExecutorService executor = Executors.newCachedThreadPool();\n@@ -153,6 +154,19 @@ public void test1() {\n \n   }\n \n+  @Test\n+  public void testHardcodedQuerySet() throws Exception {\n+    for (String query : getHardCodedQuerySet()) {\n+      try {\n+        System.out.println(query);\n+        runQuery(query, Collections.singletonList(query.replace(\"'myresource.mytable'\", \"mytable\")));\n+      } catch (Exception e) {\n+        // TODO: handle exception\n+      }\n+\n+    }\n+  }\n+\n   @AfterClass\n   public void tearDown() throws Exception {\n     stopBroker();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f70c106010175490dfb5951245c5bf0d29d8a2b2/pinot-integration-tests/src/test/java/com/linkedin/pinot/integration/tests/RealtimeClusterIntegrationTest.java",
                "sha": "6ba9e0ded5663657ce6deec0c23cc6cc5a2fa35c",
                "status": "modified"
            }
        ],
        "message": "Fixing NPE from segment pruner by adding schema to realtime segment\nmetadata.\nFixing NPE from not in predicate.\nAdding hard coded query set to RealtimeClusterIntegrationTest.\n\nRB=470149\nR=xiafu\nA=jfim",
        "parent": "https://github.com/apache/incubator-pinot/commit/f95657831129b3cb9f0daaad670d6ad990b6b4a4",
        "patched_files": [
            "DataSchemaSegmentPruner.java",
            "RealtimeColumnDataSource.java",
            "RealtimeSegmentDataManager.java",
            "RealtimeSegmentImpl.java",
            "SegmentMetadataImpl.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "BaseClusterIntegrationTest.java",
            "OfflineClusterIntegrationTest.java",
            "RealtimeClusterIntegrationTest.java"
        ]
    },
    "incubator-pinot_f8a1ff2": {
        "bug_id": "incubator-pinot_f8a1ff2",
        "commit": "https://github.com/apache/incubator-pinot/commit/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518",
        "file": [
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotInstanceRestletResource.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotInstanceRestletResource.java?ref=f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518",
                "deletions": 3,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotInstanceRestletResource.java",
                "patch": "@@ -85,12 +85,13 @@ public Instances getAllInstances() {\n   @ApiOperation(value = \"Get instance information\", produces = MediaType.APPLICATION_JSON)\n   @ApiResponses(value = {@ApiResponse(code = 200, message = \"Success\"), @ApiResponse(code = 404, message = \"Instance not found\"), @ApiResponse(code = 500, message = \"Internal error\")})\n   public String getInstance(\n-      @ApiParam(value = \"Instance name\", required = true, example = \"Server_a.b.com_20000 | Broker_my.broker.com_30000\") @PathParam(\"instanceName\") String instanceName) {\n-    if (!pinotHelixResourceManager.instanceExists(instanceName)) {\n+      @ApiParam(value = \"Instance name\", required = true, example = \"Server_a.b.com_20000 | Broker_my.broker.com_30000\")\n+      @PathParam(\"instanceName\") String instanceName) {\n+    InstanceConfig instanceConfig = pinotHelixResourceManager.getHelixInstanceConfig(instanceName);\n+    if (instanceConfig == null) {\n       throw new ControllerApplicationException(LOGGER, \"Instance \" + instanceName + \" not found\",\n           Response.Status.NOT_FOUND);\n     }\n-    InstanceConfig instanceConfig = pinotHelixResourceManager.getHelixInstanceConfig(instanceName);\n     ObjectNode response = JsonUtils.newObjectNode();\n     response.put(\"instanceName\", instanceConfig.getInstanceName());\n     response.put(\"hostName\", instanceConfig.getHostName());",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotInstanceRestletResource.java",
                "sha": "6ff9f1600109708d9e8b3258dbfa37c8cba48e7b",
                "status": "modified"
            },
            {
                "additions": 4,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PqlQueryResource.java",
                "changes": 4,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PqlQueryResource.java?ref=f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518",
                "deletions": 0,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PqlQueryResource.java",
                "patch": "@@ -129,6 +129,10 @@ public String getQueryResponse(String pqlQuery, String traceEnabled, HttpHeaders\n     // Send query to a random broker.\n     String instanceId = instanceIds.get(RANDOM.nextInt(instanceIds.size()));\n     InstanceConfig instanceConfig = _pinotHelixResourceManager.getHelixInstanceConfig(instanceId);\n+    if (instanceConfig == null) {\n+      LOGGER.error(\"Instance {} not found\", instanceId);\n+      return QueryException.INTERNAL_ERROR.toString();\n+    }\n     String hostNameWithPrefix = instanceConfig.getHostName();\n     String url =\n         \"http://\" + hostNameWithPrefix.substring(hostNameWithPrefix.indexOf(\"_\") + 1) + \":\" + instanceConfig.getPort()",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PqlQueryResource.java",
                "sha": "325dc04f29bc5a67df21ee4421cf0a7554915981",
                "status": "modified"
            },
            {
                "additions": 9,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 15,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518",
                "deletions": 6,
                "filename": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -283,10 +283,9 @@ public HelixAdmin getHelixAdmin() {\n    * @param instanceId Instance Id\n    * @return Helix instance config\n    */\n-  @Nonnull\n   public InstanceConfig getHelixInstanceConfig(@Nonnull String instanceId) {\n     ZNRecord znRecord = _cacheInstanceConfigsDataAccessor.get(\"/\" + instanceId, null, AccessOption.PERSISTENT);\n-    return new InstanceConfig(znRecord);\n+    return znRecord != null ? new InstanceConfig(znRecord) : null;\n   }\n \n   /**\n@@ -2157,9 +2156,8 @@ public RebalanceResult rebalanceTable(final String rawTableName, TableType table\n    * @return True if instance exists in the Helix cluster, False otherwise.\n    */\n   public boolean instanceExists(String instanceName) {\n-    HelixDataAccessor helixDataAccessor = _helixZkManager.getHelixDataAccessor();\n-    InstanceConfig config = helixDataAccessor.getProperty(_keyBuilder.instanceConfig(instanceName));\n-    return (config != null);\n+    ZNRecord znRecord = _cacheInstanceConfigsDataAccessor.get(\"/\" + instanceName, null, AccessOption.PERSISTENT);\n+    return (znRecord != null);\n   }\n \n   public boolean isSingleTenantCluster() {\n@@ -2210,6 +2208,10 @@ public boolean isSingleTenantCluster() {\n     BiMap<String, String> endpointToInstance = HashBiMap.create(instances.size());\n     for (String instance : instances) {\n       InstanceConfig helixInstanceConfig = getHelixInstanceConfig(instance);\n+      if (helixInstanceConfig == null) {\n+        LOGGER.warn(\"Instance {} not found\", instance);\n+        continue;\n+      }\n       ZNRecord record = helixInstanceConfig.getRecord();\n       String[] hostnameSplit = helixInstanceConfig.getHostName().split(\"_\");\n       Preconditions.checkState(hostnameSplit.length >= 2);\n@@ -2239,13 +2241,14 @@ public static void main(String[] args) throws Exception {\n     final long externalViewOnlineToOfflineTimeoutMillis = 100L;\n     final boolean isSingleTenantCluster = false;\n     final boolean isUpdateStateModel = false;\n+    final boolean enableBatchMessageMode = false;\n     MetricsRegistry metricsRegistry = new MetricsRegistry();\n     final boolean dryRun = true;\n     final String tableName = \"testTable\";\n     final TableType tableType = TableType.OFFLINE;\n     PinotHelixResourceManager helixResourceManager =\n         new PinotHelixResourceManager(zkURL, helixClusterName, controllerInstanceId, localDiskDir,\n-            externalViewOnlineToOfflineTimeoutMillis, isSingleTenantCluster, isUpdateStateModel);\n+            externalViewOnlineToOfflineTimeoutMillis, isSingleTenantCluster, isUpdateStateModel, enableBatchMessageMode);\n     helixResourceManager.start();\n     ZNRecord record = helixResourceManager.rebalanceTable(tableName, dryRun, tableType);\n     ObjectMapper mapper = new ObjectMapper();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "ed9b60480010b9763b5273484c32b6547d900e23",
                "status": "modified"
            },
            {
                "additions": 0,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManagerTest.java",
                "changes": 7,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManagerTest.java?ref=f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518",
                "deletions": 7,
                "filename": "pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManagerTest.java",
                "patch": "@@ -19,7 +19,6 @@\n package org.apache.pinot.controller.helix.core;\n \n import com.google.common.collect.BiMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Random;\n import java.util.Set;\n@@ -265,12 +264,6 @@ public void testRetrieveMetadata()\n     }\n   }\n \n-  @Test\n-  public void testGetDataInstanceAdminEndpoints() {\n-    Set<String> fakeInstances = new HashSet<>();\n-    new Random().nextInt(NUM_INSTANCES);\n-  }\n-\n   @AfterClass\n   public void tearDown() {\n     stopController();",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f8a1ff2c106cb41bd1e1d89dadc2edc177f6c518/pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManagerTest.java",
                "sha": "6d3a76f8aeb8edf9a0a41d2f7e00873fb6f33d28",
                "status": "modified"
            }
        ],
        "message": "Better handle NPE from getting instance config (#3758)\n\n* Better handle NPE from getting instance config",
        "parent": "https://github.com/apache/incubator-pinot/commit/4a1c3732ced819fe277afbf298967149b50574cb",
        "patched_files": [
            "PinotInstanceRestletResource.java",
            "PqlQueryResource.java",
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java",
            "PinotInstanceRestletResourceTest.java"
        ]
    },
    "incubator-pinot_f975fcb": {
        "bug_id": "incubator-pinot_f975fcb",
        "commit": "https://github.com/apache/incubator-pinot/commit/f975fcbbcb8b7a03f90389c387e30ebf44bc6ba1",
        "file": [
            {
                "additions": 8,
                "blob_url": "https://github.com/apache/incubator-pinot/blob/f975fcbbcb8b7a03f90389c387e30ebf44bc6ba1/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "changes": 11,
                "contents_url": "https://api.github.com/repos/apache/incubator-pinot/contents/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java?ref=f975fcbbcb8b7a03f90389c387e30ebf44bc6ba1",
                "deletions": 3,
                "filename": "pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "patch": "@@ -464,15 +464,20 @@ public PinotResourceManagerResponse rebuildBrokerResourceFromHelixTags(final Str\n \n     try {\n       final TableType tableType = TableNameBuilder.getTableTypeFromTableName(tableName);\n+      AbstractTableConfig tableConfig;\n       if (tableType == TableType.OFFLINE) {\n-        tenantConfig = ZKMetadataProvider.getOfflineTableConfig(getPropertyStore(), tableName).getTenantConfig();\n+        tableConfig = ZKMetadataProvider.getOfflineTableConfig(getPropertyStore(), tableName);\n       } else if (tableType == TableType.REALTIME) {\n-        tenantConfig = ZKMetadataProvider.getRealtimeTableConfig(getPropertyStore(), tableName).getTenantConfig();\n+        tableConfig = ZKMetadataProvider.getRealtimeTableConfig(getPropertyStore(), tableName);\n       } else {\n         return new PinotResourceManagerResponse(\"Table \" + tableName + \" does not have a table type\", false);\n       }\n+      if (tableConfig == null) {\n+        return new PinotResourceManagerResponse(\"Table \" + tableName + \" does not exist\", false);\n+      }\n+      tenantConfig = tableConfig.getTenantConfig();\n     } catch (Exception e) {\n-      LOGGER.warn(\"Caught exception while rebuilding broker resource from Helix tags for table {}\", e, tableName);\n+      LOGGER.warn(\"Caught exception while getting tenant config for table {}\", tableName, e);\n       return new PinotResourceManagerResponse(\n           \"Failed to fetch broker tag for table \" + tableName + \" due to exception: \" + e.getMessage(), false);\n     }",
                "raw_url": "https://github.com/apache/incubator-pinot/raw/f975fcbbcb8b7a03f90389c387e30ebf44bc6ba1/pinot-controller/src/main/java/com/linkedin/pinot/controller/helix/core/PinotHelixResourceManager.java",
                "sha": "8f0703448383c707677a7557f4d50c90d4b587d9",
                "status": "modified"
            }
        ],
        "message": "Fix NPE and log message when rebuilding broker resource (#1125)",
        "parent": "https://github.com/apache/incubator-pinot/commit/7d1c7079c677d100e14bc87fed17a52b445162ea",
        "patched_files": [
            "PinotHelixResourceManager.java"
        ],
        "repo": "incubator-pinot",
        "unit_tests": [
            "PinotHelixResourceManagerTest.java"
        ]
    }
}