<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>VarByteChunkSingleValueWriter.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-server</a> &gt; <a href="../index.html" class="el_bundle">pinot-core</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.core.io.writer.impl.v1</a> &gt; <span class="el_source">VarByteChunkSingleValueWriter.java</span></div><h1>VarByteChunkSingleValueWriter.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.core.io.writer.impl.v1;

import com.linkedin.pinot.core.io.compression.ChunkCompressorFactory;
import java.io.File;
import java.io.IOException;
import java.nio.charset.Charset;
import javax.annotation.concurrent.NotThreadSafe;


/**
 * Class to write out variable length bytes into a single column.
 *
 * The layout of the file is as follows:
 * &lt;p&gt; Header Section: &lt;/p&gt;
 * &lt;ul&gt;
 *   &lt;li&gt; Integer: File format version. &lt;/li&gt;
 *   &lt;li&gt; Integer: Total number of chunks. &lt;/li&gt;
 *   &lt;li&gt; Integer: Number of docs per chunk. &lt;/li&gt;
 *   &lt;li&gt; Integer: Length of longest entry (in bytes). &lt;/li&gt;
 *   &lt;li&gt; Integer array: Integer offsets for all chunks in the data .&lt;/li&gt;
 * &lt;/ul&gt;
 *
 * &lt;p&gt; Individual Chunks: &lt;/p&gt;
 * &lt;ul&gt;
 *   &lt;li&gt; Integer offsets to start position of rows: For partial chunks, offset values are 0 for missing rows. &lt;/li&gt;
 *   &lt;li&gt; Data bytes. &lt;/li&gt;
 * &lt;/ul&gt;
 *
 * Only sequential writes are supported.
 */
@NotThreadSafe
public class VarByteChunkSingleValueWriter extends BaseChunkSingleValueWriter {

  private static final int INT_SIZE = Integer.SIZE / Byte.SIZE;
<span class="fc" id="L50">  private static final Charset UTF_8 = Charset.forName(&quot;UTF-8&quot;);</span>
  private static final int CURRENT_VERSION = 2;

  private final int _chunkHeaderSize;
  private int _chunkHeaderOffset;
  private int _chunkDataOffSet;

  /**
   * Constructor for the class.
   *
   * @param file File to write to.
   * @param compressionType Type of compression to use.
   * @param totalDocs Total number of docs to write.
   * @param numDocsPerChunk Number of documents per chunk.
   * @param lengthOfLongestEntry Length of longest entry (in bytes).
   * @throws IOException
   */
  public VarByteChunkSingleValueWriter(File file, ChunkCompressorFactory.CompressionType compressionType, int totalDocs,
      int numDocsPerChunk, int lengthOfLongestEntry)
      throws IOException {

<span class="fc" id="L71">    super(file, compressionType, totalDocs, numDocsPerChunk,</span>
        ((numDocsPerChunk * INT_SIZE) + (lengthOfLongestEntry * numDocsPerChunk)), // chunkSize
        lengthOfLongestEntry, CURRENT_VERSION);

<span class="fc" id="L75">    _chunkHeaderOffset = 0;</span>
<span class="fc" id="L76">    _chunkHeaderSize = numDocsPerChunk * INT_SIZE;</span>
<span class="fc" id="L77">    _chunkDataOffSet = _chunkHeaderSize;</span>
<span class="fc" id="L78">  }</span>

  @Override
  public void setString(int row, String string) {
<span class="fc" id="L82">    byte[] bytes = string.getBytes(UTF_8);</span>
<span class="fc" id="L83">    int length = bytes.length;</span>

<span class="fc" id="L85">    _chunkBuffer.putInt(_chunkHeaderOffset, _chunkDataOffSet);</span>
<span class="fc" id="L86">    _chunkHeaderOffset += INT_SIZE;</span>

<span class="fc" id="L88">    _chunkBuffer.position(_chunkDataOffSet);</span>
<span class="fc" id="L89">    _chunkBuffer.put(bytes);</span>
<span class="fc" id="L90">    _chunkDataOffSet += length;</span>

    // If buffer filled, then compress and write to file.
<span class="fc bfc" id="L93" title="All 2 branches covered.">    if (_chunkHeaderOffset == _chunkHeaderSize) {</span>
<span class="fc" id="L94">      writeChunk();</span>
    }
<span class="fc" id="L96">  }</span>

  @Override
  public void setBytes(int row, byte[] bytes) {
<span class="nc" id="L100">    throw new UnsupportedOperationException();</span>
  }

  @Override
  public void close()
      throws IOException {

    // Write the chunk if it is non-empty.
<span class="fc bfc" id="L108" title="All 2 branches covered.">    if (_chunkBuffer.position() &gt; 0) {</span>
<span class="fc" id="L109">      writeChunk();</span>
    }

    // Write the header and close the file.
<span class="fc" id="L113">    _header.flip();</span>
<span class="fc" id="L114">    _dataFile.write(_header, 0);</span>
<span class="fc" id="L115">    _dataFile.close();</span>
<span class="fc" id="L116">  }</span>

  /**
   * Helper method to compress and write the current chunk.
   * &lt;ul&gt;
   *   &lt;li&gt; Chunk header is of fixed size, so fills out any remaining offsets for partially filled chunks. &lt;/li&gt;
   *   &lt;li&gt; Compresses and writes the chunk to the data file. &lt;/li&gt;
   *   &lt;li&gt; Updates the header with the current chunks offset. &lt;/li&gt;
   *   &lt;li&gt; Clears up the buffers, so that they can be reused. &lt;/li&gt;
   * &lt;/ul&gt;
   *
   */
  protected void writeChunk() {
    // For partially filled chunks, we still need to clear the offsets for remaining rows, as we reuse this buffer.
<span class="fc bfc" id="L130" title="All 2 branches covered.">    for (int i = _chunkHeaderOffset; i &lt; _chunkHeaderSize; i += INT_SIZE) {</span>
<span class="fc" id="L131">      _chunkBuffer.putInt(i, 0);</span>
    }

<span class="fc" id="L134">    super.writeChunk();</span>

    // Reset the chunk offsets.
<span class="fc" id="L137">    _chunkHeaderOffset = 0;</span>
<span class="fc" id="L138">    _chunkDataOffSet = _chunkHeaderSize;</span>
<span class="fc" id="L139">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>